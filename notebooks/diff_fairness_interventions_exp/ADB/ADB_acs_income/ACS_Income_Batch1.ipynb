{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa1bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9037f36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d2dab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7099a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4745b675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f587a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd98731",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6360cec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b9918",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d60b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fff551",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecda20f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940cc9fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ef3dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8124be",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef16437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baeb0c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997b557",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6915e",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96e9ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18137ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n",
      "epoch 30; iter: 0; batch classifier loss: 0.112314; batch adversarial loss: 0.399407\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134619; batch adversarial loss: 0.496391\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131425; batch adversarial loss: 0.394610\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127734; batch adversarial loss: 0.388513\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141551; batch adversarial loss: 0.411855\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119961; batch adversarial loss: 0.351078\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112275; batch adversarial loss: 0.443305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132237; batch adversarial loss: 0.380467\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129410; batch adversarial loss: 0.388583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144341; batch adversarial loss: 0.371012\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140423; batch adversarial loss: 0.385632\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135441; batch adversarial loss: 0.351807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.145334; batch adversarial loss: 0.337181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.086243; batch adversarial loss: 0.342135\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113461; batch adversarial loss: 0.412005\n",
      "epoch 45; iter: 0; batch classifier loss: 0.148074; batch adversarial loss: 0.391283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098839; batch adversarial loss: 0.367619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110907; batch adversarial loss: 0.418281\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081004; batch adversarial loss: 0.447407\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129178; batch adversarial loss: 0.390481\n",
      "epoch 50; iter: 0; batch classifier loss: 0.101097; batch adversarial loss: 0.375671\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096681; batch adversarial loss: 0.286184\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086936; batch adversarial loss: 0.373791\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146299; batch adversarial loss: 0.385923\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114785; batch adversarial loss: 0.426653\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130776; batch adversarial loss: 0.343069\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090100; batch adversarial loss: 0.457666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063514; batch adversarial loss: 0.405698\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073810; batch adversarial loss: 0.329506\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084742; batch adversarial loss: 0.482012\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063208; batch adversarial loss: 0.341541\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064936; batch adversarial loss: 0.401304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053946; batch adversarial loss: 0.362634\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088491; batch adversarial loss: 0.402693\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093272; batch adversarial loss: 0.380115\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058534; batch adversarial loss: 0.361878\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063839; batch adversarial loss: 0.390018\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098903; batch adversarial loss: 0.391328\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071927; batch adversarial loss: 0.428503\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053446; batch adversarial loss: 0.363015\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059195; batch adversarial loss: 0.405840\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058073; batch adversarial loss: 0.448700\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063779; batch adversarial loss: 0.401666\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072324; batch adversarial loss: 0.391555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078189; batch adversarial loss: 0.468643\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075767; batch adversarial loss: 0.460788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058273; batch adversarial loss: 0.444220\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068744; batch adversarial loss: 0.441344\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080804; batch adversarial loss: 0.325072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066074; batch adversarial loss: 0.428025\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076613; batch adversarial loss: 0.430067\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077773; batch adversarial loss: 0.429069\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078200; batch adversarial loss: 0.424629\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042471; batch adversarial loss: 0.511020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085843; batch adversarial loss: 0.378730\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037795; batch adversarial loss: 0.379251\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056601; batch adversarial loss: 0.430033\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070072; batch adversarial loss: 0.444720\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043124; batch adversarial loss: 0.399170\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043247; batch adversarial loss: 0.438553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066892; batch adversarial loss: 0.372396\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039940; batch adversarial loss: 0.381593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041599; batch adversarial loss: 0.445117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.460746\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038578; batch adversarial loss: 0.349626\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053242; batch adversarial loss: 0.432840\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034579; batch adversarial loss: 0.440451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047742; batch adversarial loss: 0.398114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.047766; batch adversarial loss: 0.428536\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025104; batch adversarial loss: 0.429187\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036259; batch adversarial loss: 0.469390\n",
      "epoch 101; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.453388\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027533; batch adversarial loss: 0.352197\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024320; batch adversarial loss: 0.418282\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030466; batch adversarial loss: 0.453407\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029011; batch adversarial loss: 0.518729\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025773; batch adversarial loss: 0.467378\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074437; batch adversarial loss: 0.467281\n",
      "epoch 108; iter: 0; batch classifier loss: 0.022213; batch adversarial loss: 0.434316\n",
      "epoch 109; iter: 0; batch classifier loss: 0.015499; batch adversarial loss: 0.407059\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035983; batch adversarial loss: 0.451513\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024680; batch adversarial loss: 0.370480\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027909; batch adversarial loss: 0.403637\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030633; batch adversarial loss: 0.473047\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037376; batch adversarial loss: 0.457013\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041244; batch adversarial loss: 0.449009\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082725; batch adversarial loss: 0.420662\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043448; batch adversarial loss: 0.432889\n",
      "epoch 118; iter: 0; batch classifier loss: 0.141864; batch adversarial loss: 0.620588\n",
      "epoch 119; iter: 0; batch classifier loss: 0.123385; batch adversarial loss: 0.673193\n",
      "epoch 120; iter: 0; batch classifier loss: 0.163437; batch adversarial loss: 0.680339\n",
      "epoch 121; iter: 0; batch classifier loss: 0.096560; batch adversarial loss: 0.569655\n",
      "epoch 122; iter: 0; batch classifier loss: 0.153585; batch adversarial loss: 0.713145\n",
      "epoch 123; iter: 0; batch classifier loss: 0.100437; batch adversarial loss: 0.549426\n",
      "epoch 124; iter: 0; batch classifier loss: 0.079747; batch adversarial loss: 0.530082\n",
      "epoch 125; iter: 0; batch classifier loss: 0.150510; batch adversarial loss: 0.680425\n",
      "epoch 126; iter: 0; batch classifier loss: 0.185404; batch adversarial loss: 0.582474\n",
      "epoch 127; iter: 0; batch classifier loss: 0.162655; batch adversarial loss: 0.645437\n",
      "epoch 128; iter: 0; batch classifier loss: 0.248405; batch adversarial loss: 0.764143\n",
      "epoch 129; iter: 0; batch classifier loss: 0.185059; batch adversarial loss: 0.742794\n",
      "epoch 130; iter: 0; batch classifier loss: 0.077440; batch adversarial loss: 0.396049\n",
      "epoch 131; iter: 0; batch classifier loss: 0.093600; batch adversarial loss: 0.523017\n",
      "epoch 132; iter: 0; batch classifier loss: 0.135643; batch adversarial loss: 0.501184\n",
      "epoch 133; iter: 0; batch classifier loss: 0.171032; batch adversarial loss: 0.644711\n",
      "epoch 134; iter: 0; batch classifier loss: 0.173183; batch adversarial loss: 0.604510\n",
      "epoch 135; iter: 0; batch classifier loss: 0.225151; batch adversarial loss: 0.692266\n",
      "epoch 136; iter: 0; batch classifier loss: 0.099348; batch adversarial loss: 0.408067\n",
      "epoch 137; iter: 0; batch classifier loss: 0.191986; batch adversarial loss: 0.628484\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072657; batch adversarial loss: 0.448696\n",
      "epoch 139; iter: 0; batch classifier loss: 0.141427; batch adversarial loss: 0.558883\n",
      "epoch 140; iter: 0; batch classifier loss: 0.183381; batch adversarial loss: 0.571888\n",
      "epoch 141; iter: 0; batch classifier loss: 0.160162; batch adversarial loss: 0.567237\n",
      "epoch 142; iter: 0; batch classifier loss: 0.158892; batch adversarial loss: 0.564430\n",
      "epoch 143; iter: 0; batch classifier loss: 0.114813; batch adversarial loss: 0.532460\n",
      "epoch 144; iter: 0; batch classifier loss: 0.132150; batch adversarial loss: 0.467904\n",
      "epoch 145; iter: 0; batch classifier loss: 0.102552; batch adversarial loss: 0.400032\n",
      "epoch 146; iter: 0; batch classifier loss: 0.124979; batch adversarial loss: 0.525115\n",
      "epoch 147; iter: 0; batch classifier loss: 0.120652; batch adversarial loss: 0.513039\n",
      "epoch 148; iter: 0; batch classifier loss: 0.131657; batch adversarial loss: 0.499795\n",
      "epoch 149; iter: 0; batch classifier loss: 0.158405; batch adversarial loss: 0.578692\n",
      "epoch 150; iter: 0; batch classifier loss: 0.158397; batch adversarial loss: 0.513436\n",
      "epoch 151; iter: 0; batch classifier loss: 0.091924; batch adversarial loss: 0.416635\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148011; batch adversarial loss: 0.516302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.085717; batch adversarial loss: 0.482454\n",
      "epoch 154; iter: 0; batch classifier loss: 0.129312; batch adversarial loss: 0.439330\n",
      "epoch 155; iter: 0; batch classifier loss: 0.153021; batch adversarial loss: 0.463007\n",
      "epoch 156; iter: 0; batch classifier loss: 0.137190; batch adversarial loss: 0.497651\n",
      "epoch 157; iter: 0; batch classifier loss: 0.124385; batch adversarial loss: 0.429890\n",
      "epoch 158; iter: 0; batch classifier loss: 0.111870; batch adversarial loss: 0.540100\n",
      "epoch 159; iter: 0; batch classifier loss: 0.070174; batch adversarial loss: 0.454081\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045829; batch adversarial loss: 0.413128\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033770; batch adversarial loss: 0.471644\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045643; batch adversarial loss: 0.383613\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033893; batch adversarial loss: 0.469705\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.478565\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033618; batch adversarial loss: 0.504033\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039825; batch adversarial loss: 0.445544\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041003; batch adversarial loss: 0.497957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026420; batch adversarial loss: 0.384120\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044946; batch adversarial loss: 0.491308\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033014; batch adversarial loss: 0.492518\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028050; batch adversarial loss: 0.410519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.095007; batch adversarial loss: 0.489325\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027300; batch adversarial loss: 0.502171\n",
      "epoch 174; iter: 0; batch classifier loss: 0.052244; batch adversarial loss: 0.523925\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049900; batch adversarial loss: 0.341281\n",
      "epoch 176; iter: 0; batch classifier loss: 0.046908; batch adversarial loss: 0.386869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.054516; batch adversarial loss: 0.342940\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039400; batch adversarial loss: 0.437659\n",
      "epoch 179; iter: 0; batch classifier loss: 0.082414; batch adversarial loss: 0.424241\n",
      "epoch 180; iter: 0; batch classifier loss: 0.067479; batch adversarial loss: 0.419833\n",
      "epoch 181; iter: 0; batch classifier loss: 0.074796; batch adversarial loss: 0.495219\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049828; batch adversarial loss: 0.426644\n",
      "epoch 183; iter: 0; batch classifier loss: 0.059811; batch adversarial loss: 0.540694\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056696; batch adversarial loss: 0.493050\n",
      "epoch 185; iter: 0; batch classifier loss: 0.096756; batch adversarial loss: 0.404345\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053229; batch adversarial loss: 0.368534\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049703; batch adversarial loss: 0.359971\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029034; batch adversarial loss: 0.413719\n",
      "epoch 189; iter: 0; batch classifier loss: 0.081719; batch adversarial loss: 0.493721\n",
      "epoch 190; iter: 0; batch classifier loss: 0.063066; batch adversarial loss: 0.423557\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045230; batch adversarial loss: 0.398968\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036392; batch adversarial loss: 0.413912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.071789; batch adversarial loss: 0.455946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.048057; batch adversarial loss: 0.500540\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022803; batch adversarial loss: 0.395350\n",
      "epoch 196; iter: 0; batch classifier loss: 0.062055; batch adversarial loss: 0.412655\n",
      "epoch 197; iter: 0; batch classifier loss: 0.061345; batch adversarial loss: 0.422474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.065722; batch adversarial loss: 0.423661\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022015; batch adversarial loss: 0.475309\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705779; batch adversarial loss: 0.599245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387135; batch adversarial loss: 0.631903\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367052; batch adversarial loss: 0.553439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.308074; batch adversarial loss: 0.563265\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327338; batch adversarial loss: 0.540828\n",
      "epoch 5; iter: 0; batch classifier loss: 0.386136; batch adversarial loss: 0.492645\n",
      "epoch 6; iter: 0; batch classifier loss: 0.242976; batch adversarial loss: 0.607541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267485; batch adversarial loss: 0.508283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286240; batch adversarial loss: 0.583284\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243647; batch adversarial loss: 0.525654\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268702; batch adversarial loss: 0.528554\n",
      "epoch 11; iter: 0; batch classifier loss: 0.281110; batch adversarial loss: 0.507009\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251050; batch adversarial loss: 0.504094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242706; batch adversarial loss: 0.465394\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283048; batch adversarial loss: 0.468775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246976; batch adversarial loss: 0.508584\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285495; batch adversarial loss: 0.508829\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290335; batch adversarial loss: 0.566164\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187234; batch adversarial loss: 0.560238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297002; batch adversarial loss: 0.523491\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252464; batch adversarial loss: 0.491518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300773; batch adversarial loss: 0.522090\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242412; batch adversarial loss: 0.409062\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301620; batch adversarial loss: 0.470237\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289623; batch adversarial loss: 0.469715\n",
      "epoch 25; iter: 0; batch classifier loss: 0.335343; batch adversarial loss: 0.488583\n",
      "epoch 26; iter: 0; batch classifier loss: 0.349374; batch adversarial loss: 0.471158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273073; batch adversarial loss: 0.405162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206835; batch adversarial loss: 0.517197\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187463; batch adversarial loss: 0.427241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152307; batch adversarial loss: 0.469657\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120328; batch adversarial loss: 0.459173\n",
      "epoch 32; iter: 0; batch classifier loss: 0.084894; batch adversarial loss: 0.536016\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132696; batch adversarial loss: 0.452917\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144261; batch adversarial loss: 0.416218\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162967; batch adversarial loss: 0.501248\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098713; batch adversarial loss: 0.482374\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104129; batch adversarial loss: 0.430342\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117789; batch adversarial loss: 0.496087\n",
      "epoch 39; iter: 0; batch classifier loss: 0.050446; batch adversarial loss: 0.458558\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115081; batch adversarial loss: 0.384614\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140435; batch adversarial loss: 0.403107\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099894; batch adversarial loss: 0.475639\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096744; batch adversarial loss: 0.467991\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092071; batch adversarial loss: 0.428003\n",
      "epoch 45; iter: 0; batch classifier loss: 0.059305; batch adversarial loss: 0.442167\n",
      "epoch 46; iter: 0; batch classifier loss: 0.183459; batch adversarial loss: 0.432598\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125893; batch adversarial loss: 0.468236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121290; batch adversarial loss: 0.385654\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162737; batch adversarial loss: 0.525796\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132466; batch adversarial loss: 0.412730\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106723; batch adversarial loss: 0.436540\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080590; batch adversarial loss: 0.384071\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088600; batch adversarial loss: 0.499434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071913; batch adversarial loss: 0.440589\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108829; batch adversarial loss: 0.388118\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102834; batch adversarial loss: 0.386798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122327; batch adversarial loss: 0.419729\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074505; batch adversarial loss: 0.387255\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070760; batch adversarial loss: 0.442531\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099058; batch adversarial loss: 0.358290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114224; batch adversarial loss: 0.487437\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081474; batch adversarial loss: 0.431523\n",
      "epoch 63; iter: 0; batch classifier loss: 0.166675; batch adversarial loss: 0.442480\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098531; batch adversarial loss: 0.424473\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108183; batch adversarial loss: 0.414053\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138418; batch adversarial loss: 0.339516\n",
      "epoch 67; iter: 0; batch classifier loss: 0.166370; batch adversarial loss: 0.426021\n",
      "epoch 68; iter: 0; batch classifier loss: 0.131105; batch adversarial loss: 0.415860\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164383; batch adversarial loss: 0.427595\n",
      "epoch 70; iter: 0; batch classifier loss: 0.148725; batch adversarial loss: 0.544167\n",
      "epoch 71; iter: 0; batch classifier loss: 0.158873; batch adversarial loss: 0.411196\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064287; batch adversarial loss: 0.385672\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092108; batch adversarial loss: 0.493656\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100782; batch adversarial loss: 0.434301\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091464; batch adversarial loss: 0.389472\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096342; batch adversarial loss: 0.481022\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087022; batch adversarial loss: 0.374755\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122817; batch adversarial loss: 0.409744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089627; batch adversarial loss: 0.456257\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096442; batch adversarial loss: 0.505933\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132338; batch adversarial loss: 0.473267\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084816; batch adversarial loss: 0.445226\n",
      "epoch 83; iter: 0; batch classifier loss: 0.145518; batch adversarial loss: 0.419928\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091121; batch adversarial loss: 0.395926\n",
      "epoch 85; iter: 0; batch classifier loss: 0.116600; batch adversarial loss: 0.497872\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125639; batch adversarial loss: 0.476455\n",
      "epoch 87; iter: 0; batch classifier loss: 0.098537; batch adversarial loss: 0.401247\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076174; batch adversarial loss: 0.426984\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149402; batch adversarial loss: 0.458187\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097935; batch adversarial loss: 0.366887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200676; batch adversarial loss: 0.428471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.096869; batch adversarial loss: 0.439948\n",
      "epoch 93; iter: 0; batch classifier loss: 0.127055; batch adversarial loss: 0.522274\n",
      "epoch 94; iter: 0; batch classifier loss: 0.118094; batch adversarial loss: 0.489637\n",
      "epoch 95; iter: 0; batch classifier loss: 0.154673; batch adversarial loss: 0.494955\n",
      "epoch 96; iter: 0; batch classifier loss: 0.165138; batch adversarial loss: 0.416225\n",
      "epoch 97; iter: 0; batch classifier loss: 0.110318; batch adversarial loss: 0.470551\n",
      "epoch 98; iter: 0; batch classifier loss: 0.085130; batch adversarial loss: 0.403622\n",
      "epoch 99; iter: 0; batch classifier loss: 0.104437; batch adversarial loss: 0.456002\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071125; batch adversarial loss: 0.402784\n",
      "epoch 101; iter: 0; batch classifier loss: 0.148966; batch adversarial loss: 0.429473\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085214; batch adversarial loss: 0.489818\n",
      "epoch 103; iter: 0; batch classifier loss: 0.142445; batch adversarial loss: 0.438337\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070114; batch adversarial loss: 0.588766\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117454; batch adversarial loss: 0.434235\n",
      "epoch 106; iter: 0; batch classifier loss: 0.121152; batch adversarial loss: 0.350785\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057960; batch adversarial loss: 0.500437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.093409; batch adversarial loss: 0.445045\n",
      "epoch 109; iter: 0; batch classifier loss: 0.119906; batch adversarial loss: 0.452291\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050267; batch adversarial loss: 0.409580\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073106; batch adversarial loss: 0.383504\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074961; batch adversarial loss: 0.442004\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024423; batch adversarial loss: 0.484223\n",
      "epoch 114; iter: 0; batch classifier loss: 0.083392; batch adversarial loss: 0.450938\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070873; batch adversarial loss: 0.469412\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082860; batch adversarial loss: 0.456723\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059888; batch adversarial loss: 0.410013\n",
      "epoch 118; iter: 0; batch classifier loss: 0.101867; batch adversarial loss: 0.343974\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098942; batch adversarial loss: 0.462392\n",
      "epoch 120; iter: 0; batch classifier loss: 0.097014; batch adversarial loss: 0.275318\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057499; batch adversarial loss: 0.495003\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070124; batch adversarial loss: 0.513340\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047183; batch adversarial loss: 0.522669\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039541; batch adversarial loss: 0.487975\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036889; batch adversarial loss: 0.570822\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054448; batch adversarial loss: 0.428640\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036237; batch adversarial loss: 0.395037\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052371; batch adversarial loss: 0.415394\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066037; batch adversarial loss: 0.434119\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045442; batch adversarial loss: 0.430366\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035179; batch adversarial loss: 0.465994\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042156; batch adversarial loss: 0.339379\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053884; batch adversarial loss: 0.496121\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.395882\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025084; batch adversarial loss: 0.408486\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024285; batch adversarial loss: 0.445017\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059350; batch adversarial loss: 0.468832\n",
      "epoch 138; iter: 0; batch classifier loss: 0.080186; batch adversarial loss: 0.469890\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035770; batch adversarial loss: 0.540655\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.374037\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044904; batch adversarial loss: 0.423193\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036109; batch adversarial loss: 0.468965\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040196; batch adversarial loss: 0.453166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031383; batch adversarial loss: 0.458345\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044057; batch adversarial loss: 0.459937\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020253; batch adversarial loss: 0.457683\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.504102\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016237; batch adversarial loss: 0.493567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014454; batch adversarial loss: 0.416765\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048982; batch adversarial loss: 0.459243\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028244; batch adversarial loss: 0.410632\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051486; batch adversarial loss: 0.538774\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042658; batch adversarial loss: 0.423594\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017088; batch adversarial loss: 0.387488\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059032; batch adversarial loss: 0.465705\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049853; batch adversarial loss: 0.471641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030494; batch adversarial loss: 0.545285\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037600; batch adversarial loss: 0.407082\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.388348\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007688; batch adversarial loss: 0.455028\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006327; batch adversarial loss: 0.519890\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030533; batch adversarial loss: 0.504740\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046955; batch adversarial loss: 0.481254\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012378; batch adversarial loss: 0.452759\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016655; batch adversarial loss: 0.480147\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022784; batch adversarial loss: 0.479924\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024643; batch adversarial loss: 0.468396\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029561; batch adversarial loss: 0.526805\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052266; batch adversarial loss: 0.443783\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014563; batch adversarial loss: 0.440248\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032248; batch adversarial loss: 0.480814\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035691; batch adversarial loss: 0.389419\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029479; batch adversarial loss: 0.358214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025447; batch adversarial loss: 0.419049\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034327; batch adversarial loss: 0.491139\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029826; batch adversarial loss: 0.549019\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014235; batch adversarial loss: 0.469237\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020007; batch adversarial loss: 0.393526\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006409; batch adversarial loss: 0.547102\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007956; batch adversarial loss: 0.452340\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013754; batch adversarial loss: 0.427016\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020790; batch adversarial loss: 0.417396\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014769; batch adversarial loss: 0.378865\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039147; batch adversarial loss: 0.378002\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.515553\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021010; batch adversarial loss: 0.414729\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028242; batch adversarial loss: 0.405765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.016718; batch adversarial loss: 0.432957\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023759; batch adversarial loss: 0.452993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018082; batch adversarial loss: 0.413403\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.408124\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014670; batch adversarial loss: 0.489275\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032512; batch adversarial loss: 0.451231\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010183; batch adversarial loss: 0.456637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006557; batch adversarial loss: 0.391268\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017587; batch adversarial loss: 0.387829\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007812; batch adversarial loss: 0.467515\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021800; batch adversarial loss: 0.347454\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031017; batch adversarial loss: 0.485005\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699571; batch adversarial loss: 0.764285\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595876; batch adversarial loss: 0.694470\n",
      "epoch 2; iter: 0; batch classifier loss: 0.663027; batch adversarial loss: 0.688187\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541027; batch adversarial loss: 0.657691\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361210; batch adversarial loss: 0.578195\n",
      "epoch 5; iter: 0; batch classifier loss: 0.376739; batch adversarial loss: 0.567440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324952; batch adversarial loss: 0.597742\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360018; batch adversarial loss: 0.525528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.310165; batch adversarial loss: 0.547999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301995; batch adversarial loss: 0.525607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331539; batch adversarial loss: 0.505636\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240483; batch adversarial loss: 0.574595\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330718; batch adversarial loss: 0.480812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229695; batch adversarial loss: 0.570748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.228019; batch adversarial loss: 0.491406\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229321; batch adversarial loss: 0.507194\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227739; batch adversarial loss: 0.505451\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246721; batch adversarial loss: 0.491614\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211451; batch adversarial loss: 0.499306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205619; batch adversarial loss: 0.551312\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206837; batch adversarial loss: 0.501559\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237130; batch adversarial loss: 0.485970\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198247; batch adversarial loss: 0.504038\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152528; batch adversarial loss: 0.484556\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165421; batch adversarial loss: 0.535538\n",
      "epoch 25; iter: 0; batch classifier loss: 0.230787; batch adversarial loss: 0.450466\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166325; batch adversarial loss: 0.451322\n",
      "epoch 27; iter: 0; batch classifier loss: 0.124251; batch adversarial loss: 0.443907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151006; batch adversarial loss: 0.441349\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164977; batch adversarial loss: 0.439388\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161844; batch adversarial loss: 0.392444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.106994; batch adversarial loss: 0.488578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151587; batch adversarial loss: 0.430636\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139976; batch adversarial loss: 0.394570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178225; batch adversarial loss: 0.449960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129560; batch adversarial loss: 0.414735\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133132; batch adversarial loss: 0.499451\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153682; batch adversarial loss: 0.370735\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143368; batch adversarial loss: 0.374782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128437; batch adversarial loss: 0.485899\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110505; batch adversarial loss: 0.511045\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113490; batch adversarial loss: 0.470384\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110477; batch adversarial loss: 0.543414\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123472; batch adversarial loss: 0.418720\n",
      "epoch 44; iter: 0; batch classifier loss: 0.113718; batch adversarial loss: 0.448104\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110828; batch adversarial loss: 0.420354\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114918; batch adversarial loss: 0.489333\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103138; batch adversarial loss: 0.373563\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094062; batch adversarial loss: 0.492558\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103201; batch adversarial loss: 0.534338\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111875; batch adversarial loss: 0.440694\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175853; batch adversarial loss: 0.457612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096998; batch adversarial loss: 0.493681\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132186; batch adversarial loss: 0.373868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097751; batch adversarial loss: 0.556372\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104075; batch adversarial loss: 0.452443\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113899; batch adversarial loss: 0.544682\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089604; batch adversarial loss: 0.439894\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097661; batch adversarial loss: 0.494583\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113402; batch adversarial loss: 0.374909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075091; batch adversarial loss: 0.449399\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097471; batch adversarial loss: 0.385235\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078378; batch adversarial loss: 0.460344\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081781; batch adversarial loss: 0.470024\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097721; batch adversarial loss: 0.371649\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088880; batch adversarial loss: 0.491187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072453; batch adversarial loss: 0.454331\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064316; batch adversarial loss: 0.506660\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091503; batch adversarial loss: 0.523674\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098598; batch adversarial loss: 0.500916\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076440; batch adversarial loss: 0.490674\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125655; batch adversarial loss: 0.502275\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087195; batch adversarial loss: 0.425293\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068100; batch adversarial loss: 0.519622\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075274; batch adversarial loss: 0.486598\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050355; batch adversarial loss: 0.440179\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099835; batch adversarial loss: 0.466734\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086412; batch adversarial loss: 0.503218\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075042; batch adversarial loss: 0.464247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068800; batch adversarial loss: 0.440769\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038717; batch adversarial loss: 0.507322\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081133; batch adversarial loss: 0.427310\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093455; batch adversarial loss: 0.449682\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105445; batch adversarial loss: 0.537692\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065298; batch adversarial loss: 0.490160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.053435; batch adversarial loss: 0.455425\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106114; batch adversarial loss: 0.472389\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049155; batch adversarial loss: 0.386583\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087220; batch adversarial loss: 0.424821\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087227; batch adversarial loss: 0.399486\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066131; batch adversarial loss: 0.368281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028842; batch adversarial loss: 0.461325\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069354; batch adversarial loss: 0.379274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078546; batch adversarial loss: 0.469946\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061571; batch adversarial loss: 0.597128\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084519; batch adversarial loss: 0.475508\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066644; batch adversarial loss: 0.414062\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077499; batch adversarial loss: 0.373235\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050326; batch adversarial loss: 0.534600\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049246; batch adversarial loss: 0.496090\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081809; batch adversarial loss: 0.349142\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069463; batch adversarial loss: 0.507236\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062201; batch adversarial loss: 0.475052\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056963; batch adversarial loss: 0.385811\n",
      "epoch 104; iter: 0; batch classifier loss: 0.018629; batch adversarial loss: 0.537628\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037898; batch adversarial loss: 0.539212\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040472; batch adversarial loss: 0.505500\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.442295\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033838; batch adversarial loss: 0.433652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.019840; batch adversarial loss: 0.423153\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039196; batch adversarial loss: 0.483774\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036156; batch adversarial loss: 0.493011\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032376; batch adversarial loss: 0.474035\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035784; batch adversarial loss: 0.469326\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044277; batch adversarial loss: 0.411895\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045814; batch adversarial loss: 0.443834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063547; batch adversarial loss: 0.466344\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042174; batch adversarial loss: 0.403332\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026189; batch adversarial loss: 0.441029\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058163; batch adversarial loss: 0.414012\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070466; batch adversarial loss: 0.440472\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018463; batch adversarial loss: 0.489658\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032475; batch adversarial loss: 0.472334\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033634; batch adversarial loss: 0.476511\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013471; batch adversarial loss: 0.366746\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.522315\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031677; batch adversarial loss: 0.321906\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034583; batch adversarial loss: 0.528671\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020517; batch adversarial loss: 0.493965\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042521; batch adversarial loss: 0.404947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.419909\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018377; batch adversarial loss: 0.470424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056578; batch adversarial loss: 0.418648\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036828; batch adversarial loss: 0.486103\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016624; batch adversarial loss: 0.444489\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021852; batch adversarial loss: 0.453493\n",
      "epoch 136; iter: 0; batch classifier loss: 0.071933; batch adversarial loss: 0.518335\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016216; batch adversarial loss: 0.408757\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024050; batch adversarial loss: 0.395719\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015701; batch adversarial loss: 0.418449\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009156; batch adversarial loss: 0.469716\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021060; batch adversarial loss: 0.490582\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027112; batch adversarial loss: 0.397927\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026798; batch adversarial loss: 0.514926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.067482; batch adversarial loss: 0.403948\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030534; batch adversarial loss: 0.473075\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040230; batch adversarial loss: 0.517517\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028514; batch adversarial loss: 0.496922\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054561; batch adversarial loss: 0.426178\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011256; batch adversarial loss: 0.474127\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021170; batch adversarial loss: 0.420713\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048075; batch adversarial loss: 0.487765\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.463622\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057597; batch adversarial loss: 0.482906\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031212; batch adversarial loss: 0.430699\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014499; batch adversarial loss: 0.439390\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025498; batch adversarial loss: 0.472373\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027288; batch adversarial loss: 0.416969\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.428551\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.365672\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012745; batch adversarial loss: 0.437813\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030562; batch adversarial loss: 0.520943\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026215; batch adversarial loss: 0.348264\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023339; batch adversarial loss: 0.366542\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.474485\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036350; batch adversarial loss: 0.416074\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024059; batch adversarial loss: 0.506021\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039963; batch adversarial loss: 0.422957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.498110\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046665; batch adversarial loss: 0.455173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032641; batch adversarial loss: 0.485814\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016341; batch adversarial loss: 0.469748\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026613; batch adversarial loss: 0.446822\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033392; batch adversarial loss: 0.425446\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008452; batch adversarial loss: 0.528539\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025787; batch adversarial loss: 0.409286\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009926; batch adversarial loss: 0.462351\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.381788\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022745; batch adversarial loss: 0.444322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013582; batch adversarial loss: 0.453812\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033130; batch adversarial loss: 0.449345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.022983; batch adversarial loss: 0.557959\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020422; batch adversarial loss: 0.474420\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009591; batch adversarial loss: 0.446747\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022664; batch adversarial loss: 0.509772\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017702; batch adversarial loss: 0.419916\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017288; batch adversarial loss: 0.436987\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025079; batch adversarial loss: 0.443499\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019690; batch adversarial loss: 0.431970\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010647; batch adversarial loss: 0.434463\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013225; batch adversarial loss: 0.495616\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017370; batch adversarial loss: 0.469108\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007359; batch adversarial loss: 0.467080\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028888; batch adversarial loss: 0.443313\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.431746\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.423520\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023648; batch adversarial loss: 0.500021\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033952; batch adversarial loss: 0.574963\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009449; batch adversarial loss: 0.473629\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028225; batch adversarial loss: 0.467756\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679425; batch adversarial loss: 0.763869\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471570; batch adversarial loss: 0.801459\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395161; batch adversarial loss: 0.786356\n",
      "epoch 3; iter: 0; batch classifier loss: 0.333501; batch adversarial loss: 0.701043\n",
      "epoch 4; iter: 0; batch classifier loss: 0.434600; batch adversarial loss: 0.674027\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321178; batch adversarial loss: 0.645341\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336321; batch adversarial loss: 0.622688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270751; batch adversarial loss: 0.589932\n",
      "epoch 8; iter: 0; batch classifier loss: 0.362314; batch adversarial loss: 0.538705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292644; batch adversarial loss: 0.517046\n",
      "epoch 10; iter: 0; batch classifier loss: 0.220328; batch adversarial loss: 0.527691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313862; batch adversarial loss: 0.484222\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248973; batch adversarial loss: 0.499342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209499; batch adversarial loss: 0.489255\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180275; batch adversarial loss: 0.497316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193309; batch adversarial loss: 0.409785\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222718; batch adversarial loss: 0.484118\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217704; batch adversarial loss: 0.501587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.152774; batch adversarial loss: 0.504368\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197451; batch adversarial loss: 0.433955\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211860; batch adversarial loss: 0.428020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167608; batch adversarial loss: 0.425598\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189003; batch adversarial loss: 0.411844\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185391; batch adversarial loss: 0.405341\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203158; batch adversarial loss: 0.427103\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171984; batch adversarial loss: 0.399666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165405; batch adversarial loss: 0.434223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.182826; batch adversarial loss: 0.471548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.137636; batch adversarial loss: 0.402572\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164400; batch adversarial loss: 0.406481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126757; batch adversarial loss: 0.414979\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155394; batch adversarial loss: 0.362357\n",
      "epoch 32; iter: 0; batch classifier loss: 0.150144; batch adversarial loss: 0.432185\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133061; batch adversarial loss: 0.406044\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159416; batch adversarial loss: 0.406037\n",
      "epoch 35; iter: 0; batch classifier loss: 0.163138; batch adversarial loss: 0.505520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188978; batch adversarial loss: 0.342891\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128383; batch adversarial loss: 0.493564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138757; batch adversarial loss: 0.426761\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118158; batch adversarial loss: 0.441677\n",
      "epoch 40; iter: 0; batch classifier loss: 0.118478; batch adversarial loss: 0.390135\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105255; batch adversarial loss: 0.385765\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131376; batch adversarial loss: 0.422069\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100516; batch adversarial loss: 0.444203\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092972; batch adversarial loss: 0.386868\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105307; batch adversarial loss: 0.357138\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102649; batch adversarial loss: 0.449377\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106469; batch adversarial loss: 0.378954\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090979; batch adversarial loss: 0.334707\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084599; batch adversarial loss: 0.378873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107249; batch adversarial loss: 0.468890\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083769; batch adversarial loss: 0.436791\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097434; batch adversarial loss: 0.331162\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107322; batch adversarial loss: 0.382383\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110200; batch adversarial loss: 0.321475\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079332; batch adversarial loss: 0.493396\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091432; batch adversarial loss: 0.371385\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067445; batch adversarial loss: 0.466553\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086322; batch adversarial loss: 0.351415\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075159; batch adversarial loss: 0.367769\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098292; batch adversarial loss: 0.414817\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101136; batch adversarial loss: 0.384606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097916; batch adversarial loss: 0.446336\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124748; batch adversarial loss: 0.362591\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056249; batch adversarial loss: 0.457443\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087092; batch adversarial loss: 0.375966\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110520; batch adversarial loss: 0.520820\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065229; batch adversarial loss: 0.469474\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069167; batch adversarial loss: 0.495120\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075969; batch adversarial loss: 0.442201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068198; batch adversarial loss: 0.396850\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060002; batch adversarial loss: 0.497671\n",
      "epoch 72; iter: 0; batch classifier loss: 0.124535; batch adversarial loss: 0.512240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070396; batch adversarial loss: 0.463557\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054866; batch adversarial loss: 0.420451\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089195; batch adversarial loss: 0.439988\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055888; batch adversarial loss: 0.379094\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090467; batch adversarial loss: 0.421589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.038299; batch adversarial loss: 0.489404\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051480; batch adversarial loss: 0.354581\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103258; batch adversarial loss: 0.538084\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036432; batch adversarial loss: 0.317306\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061483; batch adversarial loss: 0.460874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072272; batch adversarial loss: 0.423268\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037220; batch adversarial loss: 0.388647\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045329; batch adversarial loss: 0.467500\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040440; batch adversarial loss: 0.448422\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064966; batch adversarial loss: 0.538862\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035741; batch adversarial loss: 0.459460\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051313; batch adversarial loss: 0.467958\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.472412\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055803; batch adversarial loss: 0.554036\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082107; batch adversarial loss: 0.407774\n",
      "epoch 93; iter: 0; batch classifier loss: 0.030860; batch adversarial loss: 0.475581\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.384289\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077661; batch adversarial loss: 0.493970\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081444; batch adversarial loss: 0.552501\n",
      "epoch 97; iter: 0; batch classifier loss: 0.091371; batch adversarial loss: 0.580534\n",
      "epoch 98; iter: 0; batch classifier loss: 0.110845; batch adversarial loss: 0.618179\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111596; batch adversarial loss: 0.608300\n",
      "epoch 100; iter: 0; batch classifier loss: 0.151555; batch adversarial loss: 0.591756\n",
      "epoch 101; iter: 0; batch classifier loss: 0.135798; batch adversarial loss: 0.505228\n",
      "epoch 102; iter: 0; batch classifier loss: 0.148759; batch adversarial loss: 0.703239\n",
      "epoch 103; iter: 0; batch classifier loss: 0.180685; batch adversarial loss: 0.632428\n",
      "epoch 104; iter: 0; batch classifier loss: 0.155702; batch adversarial loss: 0.577111\n",
      "epoch 105; iter: 0; batch classifier loss: 0.157182; batch adversarial loss: 0.566414\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108911; batch adversarial loss: 0.536048\n",
      "epoch 107; iter: 0; batch classifier loss: 0.196919; batch adversarial loss: 0.638833\n",
      "epoch 108; iter: 0; batch classifier loss: 0.132413; batch adversarial loss: 0.584762\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095087; batch adversarial loss: 0.375450\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126541; batch adversarial loss: 0.536404\n",
      "epoch 111; iter: 0; batch classifier loss: 0.171836; batch adversarial loss: 0.547045\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080967; batch adversarial loss: 0.505650\n",
      "epoch 113; iter: 0; batch classifier loss: 0.129893; batch adversarial loss: 0.589267\n",
      "epoch 114; iter: 0; batch classifier loss: 0.167731; batch adversarial loss: 0.533724\n",
      "epoch 115; iter: 0; batch classifier loss: 0.125199; batch adversarial loss: 0.539605\n",
      "epoch 116; iter: 0; batch classifier loss: 0.186451; batch adversarial loss: 0.524423\n",
      "epoch 117; iter: 0; batch classifier loss: 0.104794; batch adversarial loss: 0.456070\n",
      "epoch 118; iter: 0; batch classifier loss: 0.175376; batch adversarial loss: 0.552369\n",
      "epoch 119; iter: 0; batch classifier loss: 0.153871; batch adversarial loss: 0.497079\n",
      "epoch 120; iter: 0; batch classifier loss: 0.150012; batch adversarial loss: 0.487281\n",
      "epoch 121; iter: 0; batch classifier loss: 0.076353; batch adversarial loss: 0.439786\n",
      "epoch 122; iter: 0; batch classifier loss: 0.117883; batch adversarial loss: 0.511352\n",
      "epoch 123; iter: 0; batch classifier loss: 0.198438; batch adversarial loss: 0.578096\n",
      "epoch 124; iter: 0; batch classifier loss: 0.130444; batch adversarial loss: 0.532319\n",
      "epoch 125; iter: 0; batch classifier loss: 0.207885; batch adversarial loss: 0.529840\n",
      "epoch 126; iter: 0; batch classifier loss: 0.133257; batch adversarial loss: 0.514792\n",
      "epoch 127; iter: 0; batch classifier loss: 0.134960; batch adversarial loss: 0.532916\n",
      "epoch 128; iter: 0; batch classifier loss: 0.145253; batch adversarial loss: 0.589457\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077436; batch adversarial loss: 0.465858\n",
      "epoch 130; iter: 0; batch classifier loss: 0.134517; batch adversarial loss: 0.414521\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078506; batch adversarial loss: 0.370250\n",
      "epoch 132; iter: 0; batch classifier loss: 0.118685; batch adversarial loss: 0.538981\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.362033\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036676; batch adversarial loss: 0.495189\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061541; batch adversarial loss: 0.529404\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025911; batch adversarial loss: 0.490157\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.481415\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042562; batch adversarial loss: 0.472896\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043045; batch adversarial loss: 0.428393\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041965; batch adversarial loss: 0.483723\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055386; batch adversarial loss: 0.394521\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065196; batch adversarial loss: 0.443800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041134; batch adversarial loss: 0.399804\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039362; batch adversarial loss: 0.447482\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062931; batch adversarial loss: 0.382738\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037140; batch adversarial loss: 0.478799\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057192; batch adversarial loss: 0.467204\n",
      "epoch 148; iter: 0; batch classifier loss: 0.079020; batch adversarial loss: 0.468780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.075438; batch adversarial loss: 0.499924\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043660; batch adversarial loss: 0.462759\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059088; batch adversarial loss: 0.489747\n",
      "epoch 152; iter: 0; batch classifier loss: 0.073406; batch adversarial loss: 0.480689\n",
      "epoch 153; iter: 0; batch classifier loss: 0.103991; batch adversarial loss: 0.448408\n",
      "epoch 154; iter: 0; batch classifier loss: 0.087542; batch adversarial loss: 0.424516\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040766; batch adversarial loss: 0.431087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.059491; batch adversarial loss: 0.410132\n",
      "epoch 157; iter: 0; batch classifier loss: 0.060826; batch adversarial loss: 0.491204\n",
      "epoch 158; iter: 0; batch classifier loss: 0.058600; batch adversarial loss: 0.374255\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054950; batch adversarial loss: 0.579909\n",
      "epoch 160; iter: 0; batch classifier loss: 0.095433; batch adversarial loss: 0.515530\n",
      "epoch 161; iter: 0; batch classifier loss: 0.121703; batch adversarial loss: 0.523236\n",
      "epoch 162; iter: 0; batch classifier loss: 0.065193; batch adversarial loss: 0.523600\n",
      "epoch 163; iter: 0; batch classifier loss: 0.074857; batch adversarial loss: 0.416019\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052034; batch adversarial loss: 0.450286\n",
      "epoch 165; iter: 0; batch classifier loss: 0.080286; batch adversarial loss: 0.489111\n",
      "epoch 166; iter: 0; batch classifier loss: 0.058825; batch adversarial loss: 0.480616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054475; batch adversarial loss: 0.554668\n",
      "epoch 168; iter: 0; batch classifier loss: 0.058285; batch adversarial loss: 0.396799\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043231; batch adversarial loss: 0.436523\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043223; batch adversarial loss: 0.467752\n",
      "epoch 171; iter: 0; batch classifier loss: 0.069676; batch adversarial loss: 0.340203\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019482; batch adversarial loss: 0.522254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045607; batch adversarial loss: 0.529344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.045736; batch adversarial loss: 0.470819\n",
      "epoch 175; iter: 0; batch classifier loss: 0.051956; batch adversarial loss: 0.451257\n",
      "epoch 176; iter: 0; batch classifier loss: 0.065930; batch adversarial loss: 0.408662\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043585; batch adversarial loss: 0.509034\n",
      "epoch 178; iter: 0; batch classifier loss: 0.060071; batch adversarial loss: 0.434449\n",
      "epoch 179; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.348380\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049189; batch adversarial loss: 0.534166\n",
      "epoch 181; iter: 0; batch classifier loss: 0.084653; batch adversarial loss: 0.482648\n",
      "epoch 182; iter: 0; batch classifier loss: 0.088623; batch adversarial loss: 0.425720\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034218; batch adversarial loss: 0.527187\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058012; batch adversarial loss: 0.429034\n",
      "epoch 185; iter: 0; batch classifier loss: 0.056654; batch adversarial loss: 0.506173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037218; batch adversarial loss: 0.374892\n",
      "epoch 187; iter: 0; batch classifier loss: 0.072562; batch adversarial loss: 0.514161\n",
      "epoch 188; iter: 0; batch classifier loss: 0.072063; batch adversarial loss: 0.327642\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060477; batch adversarial loss: 0.574423\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043755; batch adversarial loss: 0.427455\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031620; batch adversarial loss: 0.453430\n",
      "epoch 192; iter: 0; batch classifier loss: 0.076677; batch adversarial loss: 0.517591\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033553; batch adversarial loss: 0.426091\n",
      "epoch 194; iter: 0; batch classifier loss: 0.051004; batch adversarial loss: 0.509527\n",
      "epoch 195; iter: 0; batch classifier loss: 0.066727; batch adversarial loss: 0.427504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038124; batch adversarial loss: 0.459172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043589; batch adversarial loss: 0.444640\n",
      "epoch 198; iter: 0; batch classifier loss: 0.071086; batch adversarial loss: 0.483208\n",
      "epoch 199; iter: 0; batch classifier loss: 0.079320; batch adversarial loss: 0.407760\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694534; batch adversarial loss: 0.974476\n",
      "epoch 1; iter: 0; batch classifier loss: 0.713857; batch adversarial loss: 1.049789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.984732; batch adversarial loss: 1.098265\n",
      "epoch 3; iter: 0; batch classifier loss: 1.002460; batch adversarial loss: 0.962813\n",
      "epoch 4; iter: 0; batch classifier loss: 1.139527; batch adversarial loss: 0.914535\n",
      "epoch 5; iter: 0; batch classifier loss: 1.112548; batch adversarial loss: 0.828739\n",
      "epoch 6; iter: 0; batch classifier loss: 0.875998; batch adversarial loss: 0.727872\n",
      "epoch 7; iter: 0; batch classifier loss: 0.839169; batch adversarial loss: 0.665206\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615158; batch adversarial loss: 0.592237\n",
      "epoch 9; iter: 0; batch classifier loss: 0.683230; batch adversarial loss: 0.582922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470736; batch adversarial loss: 0.589362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332450; batch adversarial loss: 0.541156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.290550; batch adversarial loss: 0.553429\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274570; batch adversarial loss: 0.496201\n",
      "epoch 14; iter: 0; batch classifier loss: 0.259499; batch adversarial loss: 0.505181\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271682; batch adversarial loss: 0.513174\n",
      "epoch 16; iter: 0; batch classifier loss: 0.232673; batch adversarial loss: 0.467594\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328184; batch adversarial loss: 0.513215\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271943; batch adversarial loss: 0.477915\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217434; batch adversarial loss: 0.492603\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252089; batch adversarial loss: 0.518592\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233786; batch adversarial loss: 0.510520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.232668; batch adversarial loss: 0.473526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199220; batch adversarial loss: 0.466139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206659; batch adversarial loss: 0.433399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257251; batch adversarial loss: 0.430661\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208053; batch adversarial loss: 0.410543\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183322; batch adversarial loss: 0.556470\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189679; batch adversarial loss: 0.447625\n",
      "epoch 29; iter: 0; batch classifier loss: 0.226953; batch adversarial loss: 0.405142\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177066; batch adversarial loss: 0.461938\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222365; batch adversarial loss: 0.464501\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237687; batch adversarial loss: 0.414820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241508; batch adversarial loss: 0.451683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150197; batch adversarial loss: 0.447242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.170846; batch adversarial loss: 0.444854\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153022; batch adversarial loss: 0.420075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132347; batch adversarial loss: 0.450001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.175018; batch adversarial loss: 0.482774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204884; batch adversarial loss: 0.433010\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180294; batch adversarial loss: 0.419994\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149838; batch adversarial loss: 0.441129\n",
      "epoch 42; iter: 0; batch classifier loss: 0.170252; batch adversarial loss: 0.450802\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179572; batch adversarial loss: 0.486730\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171749; batch adversarial loss: 0.432523\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121377; batch adversarial loss: 0.437002\n",
      "epoch 46; iter: 0; batch classifier loss: 0.176285; batch adversarial loss: 0.405063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128313; batch adversarial loss: 0.440438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195149; batch adversarial loss: 0.438779\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074617; batch adversarial loss: 0.468378\n",
      "epoch 50; iter: 0; batch classifier loss: 0.169809; batch adversarial loss: 0.463207\n",
      "epoch 51; iter: 0; batch classifier loss: 0.213626; batch adversarial loss: 0.424032\n",
      "epoch 52; iter: 0; batch classifier loss: 0.171749; batch adversarial loss: 0.420909\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163069; batch adversarial loss: 0.511704\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216254; batch adversarial loss: 0.548613\n",
      "epoch 55; iter: 0; batch classifier loss: 0.165155; batch adversarial loss: 0.469639\n",
      "epoch 56; iter: 0; batch classifier loss: 0.200215; batch adversarial loss: 0.479693\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124462; batch adversarial loss: 0.423918\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133135; batch adversarial loss: 0.524471\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129788; batch adversarial loss: 0.362246\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093995; batch adversarial loss: 0.449569\n",
      "epoch 61; iter: 0; batch classifier loss: 0.150826; batch adversarial loss: 0.526226\n",
      "epoch 62; iter: 0; batch classifier loss: 0.110143; batch adversarial loss: 0.330000\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128003; batch adversarial loss: 0.532972\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129101; batch adversarial loss: 0.364200\n",
      "epoch 65; iter: 0; batch classifier loss: 0.119782; batch adversarial loss: 0.484478\n",
      "epoch 66; iter: 0; batch classifier loss: 0.168757; batch adversarial loss: 0.432869\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091243; batch adversarial loss: 0.523440\n",
      "epoch 68; iter: 0; batch classifier loss: 0.112764; batch adversarial loss: 0.522417\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146451; batch adversarial loss: 0.419528\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130377; batch adversarial loss: 0.465605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.158825; batch adversarial loss: 0.471734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.152702; batch adversarial loss: 0.394893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.122197; batch adversarial loss: 0.495642\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143513; batch adversarial loss: 0.456651\n",
      "epoch 75; iter: 0; batch classifier loss: 0.136361; batch adversarial loss: 0.371273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.136253; batch adversarial loss: 0.380985\n",
      "epoch 77; iter: 0; batch classifier loss: 0.168044; batch adversarial loss: 0.478340\n",
      "epoch 78; iter: 0; batch classifier loss: 0.157930; batch adversarial loss: 0.417327\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110704; batch adversarial loss: 0.440717\n",
      "epoch 80; iter: 0; batch classifier loss: 0.113480; batch adversarial loss: 0.367475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116736; batch adversarial loss: 0.427962\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115663; batch adversarial loss: 0.482094\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107317; batch adversarial loss: 0.459879\n",
      "epoch 84; iter: 0; batch classifier loss: 0.142044; batch adversarial loss: 0.471093\n",
      "epoch 85; iter: 0; batch classifier loss: 0.113297; batch adversarial loss: 0.442773\n",
      "epoch 86; iter: 0; batch classifier loss: 0.144059; batch adversarial loss: 0.490511\n",
      "epoch 87; iter: 0; batch classifier loss: 0.135773; batch adversarial loss: 0.426272\n",
      "epoch 88; iter: 0; batch classifier loss: 0.167015; batch adversarial loss: 0.407212\n",
      "epoch 89; iter: 0; batch classifier loss: 0.112686; batch adversarial loss: 0.449792\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066877; batch adversarial loss: 0.520750\n",
      "epoch 91; iter: 0; batch classifier loss: 0.104823; batch adversarial loss: 0.403020\n",
      "epoch 92; iter: 0; batch classifier loss: 0.124679; batch adversarial loss: 0.412662\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104104; batch adversarial loss: 0.447589\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125279; batch adversarial loss: 0.427565\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098693; batch adversarial loss: 0.342799\n",
      "epoch 96; iter: 0; batch classifier loss: 0.121425; batch adversarial loss: 0.535387\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095153; batch adversarial loss: 0.529199\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052295; batch adversarial loss: 0.431700\n",
      "epoch 99; iter: 0; batch classifier loss: 0.138605; batch adversarial loss: 0.433466\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108391; batch adversarial loss: 0.436738\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105932; batch adversarial loss: 0.526582\n",
      "epoch 102; iter: 0; batch classifier loss: 0.080528; batch adversarial loss: 0.493784\n",
      "epoch 103; iter: 0; batch classifier loss: 0.124333; batch adversarial loss: 0.435665\n",
      "epoch 104; iter: 0; batch classifier loss: 0.145136; batch adversarial loss: 0.431014\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089134; batch adversarial loss: 0.431113\n",
      "epoch 106; iter: 0; batch classifier loss: 0.129224; batch adversarial loss: 0.390489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079436; batch adversarial loss: 0.458726\n",
      "epoch 108; iter: 0; batch classifier loss: 0.104592; batch adversarial loss: 0.513694\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082673; batch adversarial loss: 0.454384\n",
      "epoch 110; iter: 0; batch classifier loss: 0.098841; batch adversarial loss: 0.502848\n",
      "epoch 111; iter: 0; batch classifier loss: 0.133523; batch adversarial loss: 0.468344\n",
      "epoch 112; iter: 0; batch classifier loss: 0.090672; batch adversarial loss: 0.465324\n",
      "epoch 113; iter: 0; batch classifier loss: 0.127695; batch adversarial loss: 0.483030\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072846; batch adversarial loss: 0.448847\n",
      "epoch 115; iter: 0; batch classifier loss: 0.109992; batch adversarial loss: 0.471425\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085532; batch adversarial loss: 0.493373\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055230; batch adversarial loss: 0.424639\n",
      "epoch 118; iter: 0; batch classifier loss: 0.120433; batch adversarial loss: 0.489674\n",
      "epoch 119; iter: 0; batch classifier loss: 0.142951; batch adversarial loss: 0.536592\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117364; batch adversarial loss: 0.437118\n",
      "epoch 121; iter: 0; batch classifier loss: 0.104654; batch adversarial loss: 0.406406\n",
      "epoch 122; iter: 0; batch classifier loss: 0.106228; batch adversarial loss: 0.494908\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050119; batch adversarial loss: 0.496128\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071323; batch adversarial loss: 0.452820\n",
      "epoch 125; iter: 0; batch classifier loss: 0.092952; batch adversarial loss: 0.438850\n",
      "epoch 126; iter: 0; batch classifier loss: 0.075844; batch adversarial loss: 0.448572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064799; batch adversarial loss: 0.399191\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087749; batch adversarial loss: 0.460074\n",
      "epoch 129; iter: 0; batch classifier loss: 0.118428; batch adversarial loss: 0.435239\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066853; batch adversarial loss: 0.391712\n",
      "epoch 131; iter: 0; batch classifier loss: 0.073390; batch adversarial loss: 0.454794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.101219; batch adversarial loss: 0.461081\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083063; batch adversarial loss: 0.417984\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064611; batch adversarial loss: 0.358854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.076336; batch adversarial loss: 0.463223\n",
      "epoch 136; iter: 0; batch classifier loss: 0.097937; batch adversarial loss: 0.362909\n",
      "epoch 137; iter: 0; batch classifier loss: 0.092082; batch adversarial loss: 0.367652\n",
      "epoch 138; iter: 0; batch classifier loss: 0.069152; batch adversarial loss: 0.499908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039387; batch adversarial loss: 0.507645\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071983; batch adversarial loss: 0.510521\n",
      "epoch 141; iter: 0; batch classifier loss: 0.062898; batch adversarial loss: 0.453772\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052406; batch adversarial loss: 0.397791\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051471; batch adversarial loss: 0.533143\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058589; batch adversarial loss: 0.484134\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039691; batch adversarial loss: 0.565388\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036446; batch adversarial loss: 0.500459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030741; batch adversarial loss: 0.541630\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050419; batch adversarial loss: 0.406831\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069223; batch adversarial loss: 0.373416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054584; batch adversarial loss: 0.441016\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025888; batch adversarial loss: 0.508314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043461; batch adversarial loss: 0.549026\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.384582\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031278; batch adversarial loss: 0.450763\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042669; batch adversarial loss: 0.493756\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017840; batch adversarial loss: 0.538953\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041931; batch adversarial loss: 0.546577\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042122; batch adversarial loss: 0.413600\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044985; batch adversarial loss: 0.547682\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015795; batch adversarial loss: 0.554658\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036511; batch adversarial loss: 0.472183\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030533; batch adversarial loss: 0.418598\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016794; batch adversarial loss: 0.484631\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012632; batch adversarial loss: 0.506899\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038093; batch adversarial loss: 0.450432\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037275; batch adversarial loss: 0.411471\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.479211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.020307; batch adversarial loss: 0.501180\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010490; batch adversarial loss: 0.377362\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037193; batch adversarial loss: 0.525710\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034924; batch adversarial loss: 0.472117\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019581; batch adversarial loss: 0.507358\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032776; batch adversarial loss: 0.423590\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023498; batch adversarial loss: 0.408116\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031343; batch adversarial loss: 0.414389\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047426; batch adversarial loss: 0.526766\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037723; batch adversarial loss: 0.463105\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037711; batch adversarial loss: 0.423986\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019807; batch adversarial loss: 0.463661\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022333; batch adversarial loss: 0.356681\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012032; batch adversarial loss: 0.452161\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024537; batch adversarial loss: 0.470970\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.397597\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038868; batch adversarial loss: 0.473642\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020501; batch adversarial loss: 0.348771\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012671; batch adversarial loss: 0.385986\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011656; batch adversarial loss: 0.480288\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024025; batch adversarial loss: 0.436681\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015498; batch adversarial loss: 0.408688\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048674; batch adversarial loss: 0.381581\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015681; batch adversarial loss: 0.373317\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019410; batch adversarial loss: 0.543120\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011336; batch adversarial loss: 0.469671\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016404; batch adversarial loss: 0.466573\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023302; batch adversarial loss: 0.490049\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014667; batch adversarial loss: 0.502375\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016176; batch adversarial loss: 0.486356\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021391; batch adversarial loss: 0.537280\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022169; batch adversarial loss: 0.413639\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702054; batch adversarial loss: 0.586223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477042; batch adversarial loss: 0.612043\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458766; batch adversarial loss: 0.601617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.435170; batch adversarial loss: 0.611925\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470640; batch adversarial loss: 0.603641\n",
      "epoch 5; iter: 0; batch classifier loss: 0.430932; batch adversarial loss: 0.556200\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495471; batch adversarial loss: 0.626536\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535994; batch adversarial loss: 0.581244\n",
      "epoch 8; iter: 0; batch classifier loss: 0.666715; batch adversarial loss: 0.585943\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523452; batch adversarial loss: 0.509781\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593591; batch adversarial loss: 0.539476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.382790; batch adversarial loss: 0.487521\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357986; batch adversarial loss: 0.493337\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341998; batch adversarial loss: 0.542316\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264479; batch adversarial loss: 0.568286\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313956; batch adversarial loss: 0.505764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.291331; batch adversarial loss: 0.420187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281713; batch adversarial loss: 0.481012\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271805; batch adversarial loss: 0.527212\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334988; batch adversarial loss: 0.474067\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220080; batch adversarial loss: 0.431834\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254801; batch adversarial loss: 0.482925\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273995; batch adversarial loss: 0.464753\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206052; batch adversarial loss: 0.467834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204192; batch adversarial loss: 0.455117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177179; batch adversarial loss: 0.431654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198237; batch adversarial loss: 0.505378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.121307; batch adversarial loss: 0.461895\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179520; batch adversarial loss: 0.410953\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180345; batch adversarial loss: 0.430040\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167303; batch adversarial loss: 0.410867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172442; batch adversarial loss: 0.407649\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208643; batch adversarial loss: 0.480687\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143148; batch adversarial loss: 0.462950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169325; batch adversarial loss: 0.401885\n",
      "epoch 35; iter: 0; batch classifier loss: 0.221238; batch adversarial loss: 0.373685\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150548; batch adversarial loss: 0.400355\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128227; batch adversarial loss: 0.515680\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165145; batch adversarial loss: 0.452603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182793; batch adversarial loss: 0.339833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100743; batch adversarial loss: 0.555472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.163722; batch adversarial loss: 0.546148\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083674; batch adversarial loss: 0.515296\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129200; batch adversarial loss: 0.418036\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127039; batch adversarial loss: 0.500349\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119163; batch adversarial loss: 0.426431\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107044; batch adversarial loss: 0.413399\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127612; batch adversarial loss: 0.408879\n",
      "epoch 48; iter: 0; batch classifier loss: 0.066508; batch adversarial loss: 0.425997\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146895; batch adversarial loss: 0.468336\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111868; batch adversarial loss: 0.323553\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096063; batch adversarial loss: 0.470804\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163409; batch adversarial loss: 0.413461\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088526; batch adversarial loss: 0.448222\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073615; batch adversarial loss: 0.421583\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113785; batch adversarial loss: 0.466488\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187771; batch adversarial loss: 0.398171\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119196; batch adversarial loss: 0.470289\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096628; batch adversarial loss: 0.410074\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136264; batch adversarial loss: 0.533110\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091722; batch adversarial loss: 0.344226\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119506; batch adversarial loss: 0.443005\n",
      "epoch 62; iter: 0; batch classifier loss: 0.112164; batch adversarial loss: 0.457035\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114087; batch adversarial loss: 0.498100\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067057; batch adversarial loss: 0.405218\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083457; batch adversarial loss: 0.473283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.108112; batch adversarial loss: 0.351929\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098091; batch adversarial loss: 0.415333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103021; batch adversarial loss: 0.459851\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048218; batch adversarial loss: 0.456569\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095554; batch adversarial loss: 0.403673\n",
      "epoch 71; iter: 0; batch classifier loss: 0.160487; batch adversarial loss: 0.390872\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078798; batch adversarial loss: 0.390978\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070695; batch adversarial loss: 0.421419\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081150; batch adversarial loss: 0.342550\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099159; batch adversarial loss: 0.444727\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072333; batch adversarial loss: 0.534914\n",
      "epoch 77; iter: 0; batch classifier loss: 0.164137; batch adversarial loss: 0.354753\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090044; batch adversarial loss: 0.415009\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069135; batch adversarial loss: 0.400493\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056990; batch adversarial loss: 0.563482\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050971; batch adversarial loss: 0.470244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077432; batch adversarial loss: 0.490712\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043180; batch adversarial loss: 0.572040\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068483; batch adversarial loss: 0.380305\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091672; batch adversarial loss: 0.578265\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103604; batch adversarial loss: 0.418704\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104105; batch adversarial loss: 0.510149\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052257; batch adversarial loss: 0.343622\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110620; batch adversarial loss: 0.401393\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079003; batch adversarial loss: 0.470569\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060914; batch adversarial loss: 0.475427\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084959; batch adversarial loss: 0.438681\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070383; batch adversarial loss: 0.406367\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085206; batch adversarial loss: 0.338534\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046163; batch adversarial loss: 0.349095\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037319; batch adversarial loss: 0.536630\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076614; batch adversarial loss: 0.388943\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039390; batch adversarial loss: 0.407839\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057325; batch adversarial loss: 0.424386\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039009; batch adversarial loss: 0.583984\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069878; batch adversarial loss: 0.394081\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067218; batch adversarial loss: 0.474516\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063540; batch adversarial loss: 0.484031\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054690; batch adversarial loss: 0.520973\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064028; batch adversarial loss: 0.474415\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056329; batch adversarial loss: 0.523654\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039751; batch adversarial loss: 0.520788\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046242; batch adversarial loss: 0.517456\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064856; batch adversarial loss: 0.400171\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030261; batch adversarial loss: 0.474344\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040101; batch adversarial loss: 0.467417\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041215; batch adversarial loss: 0.395589\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053618; batch adversarial loss: 0.454823\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.569287\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041581; batch adversarial loss: 0.421022\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047801; batch adversarial loss: 0.454644\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059428; batch adversarial loss: 0.541618\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042935; batch adversarial loss: 0.442320\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.446484\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037153; batch adversarial loss: 0.344753\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043275; batch adversarial loss: 0.491650\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026004; batch adversarial loss: 0.389909\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019451; batch adversarial loss: 0.537343\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035361; batch adversarial loss: 0.447463\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034145; batch adversarial loss: 0.527259\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034434; batch adversarial loss: 0.452815\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034921; batch adversarial loss: 0.542942\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049634; batch adversarial loss: 0.424093\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039734; batch adversarial loss: 0.522637\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029877; batch adversarial loss: 0.497978\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028463; batch adversarial loss: 0.571042\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033076; batch adversarial loss: 0.538413\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052274; batch adversarial loss: 0.462546\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043100; batch adversarial loss: 0.422656\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055715; batch adversarial loss: 0.438174\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048517; batch adversarial loss: 0.463517\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035954; batch adversarial loss: 0.480587\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.423393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018699; batch adversarial loss: 0.456165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040668; batch adversarial loss: 0.449584\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038052; batch adversarial loss: 0.411807\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041862; batch adversarial loss: 0.521144\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052463; batch adversarial loss: 0.510254\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.400582\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024449; batch adversarial loss: 0.400466\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022445; batch adversarial loss: 0.444418\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014020; batch adversarial loss: 0.478506\n",
      "epoch 148; iter: 0; batch classifier loss: 0.079920; batch adversarial loss: 0.464431\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016493; batch adversarial loss: 0.436594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022707; batch adversarial loss: 0.378915\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.434392\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028539; batch adversarial loss: 0.432762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014557; batch adversarial loss: 0.440732\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017587; batch adversarial loss: 0.497666\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019733; batch adversarial loss: 0.553038\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028690; batch adversarial loss: 0.453339\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009427; batch adversarial loss: 0.521888\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015385; batch adversarial loss: 0.451243\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007341; batch adversarial loss: 0.488213\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019863; batch adversarial loss: 0.419564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037702; batch adversarial loss: 0.382805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.432441\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022550; batch adversarial loss: 0.412876\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016239; batch adversarial loss: 0.505515\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009660; batch adversarial loss: 0.388097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013621; batch adversarial loss: 0.501315\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018794; batch adversarial loss: 0.541128\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022108; batch adversarial loss: 0.495575\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061321; batch adversarial loss: 0.495878\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033044; batch adversarial loss: 0.471017\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008898; batch adversarial loss: 0.386971\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014996; batch adversarial loss: 0.502781\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038910; batch adversarial loss: 0.429361\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016693; batch adversarial loss: 0.445632\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020246; batch adversarial loss: 0.450130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.051063; batch adversarial loss: 0.466721\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015960; batch adversarial loss: 0.429878\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043431; batch adversarial loss: 0.442005\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033985; batch adversarial loss: 0.431127\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021816; batch adversarial loss: 0.475359\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007176; batch adversarial loss: 0.455655\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038897; batch adversarial loss: 0.418860\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007719; batch adversarial loss: 0.446705\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017902; batch adversarial loss: 0.419147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021025; batch adversarial loss: 0.477111\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025701; batch adversarial loss: 0.453608\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027634; batch adversarial loss: 0.432043\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012815; batch adversarial loss: 0.463620\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022143; batch adversarial loss: 0.443579\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022512; batch adversarial loss: 0.470388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012444; batch adversarial loss: 0.352914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019191; batch adversarial loss: 0.572306\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016199; batch adversarial loss: 0.454866\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005567; batch adversarial loss: 0.447065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021209; batch adversarial loss: 0.469732\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026557; batch adversarial loss: 0.439508\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030639; batch adversarial loss: 0.432953\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006441; batch adversarial loss: 0.474670\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021472; batch adversarial loss: 0.377358\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669747; batch adversarial loss: 0.905937\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637424; batch adversarial loss: 1.091254\n",
      "epoch 2; iter: 0; batch classifier loss: 0.924024; batch adversarial loss: 1.131337\n",
      "epoch 3; iter: 0; batch classifier loss: 1.003756; batch adversarial loss: 1.030951\n",
      "epoch 4; iter: 0; batch classifier loss: 1.172853; batch adversarial loss: 0.992422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.997736; batch adversarial loss: 0.854143\n",
      "epoch 6; iter: 0; batch classifier loss: 0.938248; batch adversarial loss: 0.806956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.840065; batch adversarial loss: 0.739981\n",
      "epoch 8; iter: 0; batch classifier loss: 0.691792; batch adversarial loss: 0.695317\n",
      "epoch 9; iter: 0; batch classifier loss: 0.638521; batch adversarial loss: 0.611805\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571559; batch adversarial loss: 0.540582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.435476; batch adversarial loss: 0.561639\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404522; batch adversarial loss: 0.494994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339438; batch adversarial loss: 0.497503\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307621; batch adversarial loss: 0.530383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295667; batch adversarial loss: 0.471799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289753; batch adversarial loss: 0.520143\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262875; batch adversarial loss: 0.473945\n",
      "epoch 18; iter: 0; batch classifier loss: 0.253558; batch adversarial loss: 0.491590\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265091; batch adversarial loss: 0.492182\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234258; batch adversarial loss: 0.417723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216964; batch adversarial loss: 0.505594\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250000; batch adversarial loss: 0.440961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239077; batch adversarial loss: 0.442762\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225370; batch adversarial loss: 0.456978\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232747; batch adversarial loss: 0.403504\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166034; batch adversarial loss: 0.432665\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196528; batch adversarial loss: 0.491220\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182517; batch adversarial loss: 0.442786\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241184; batch adversarial loss: 0.448192\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187946; batch adversarial loss: 0.512785\n",
      "epoch 31; iter: 0; batch classifier loss: 0.259996; batch adversarial loss: 0.457572\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199688; batch adversarial loss: 0.478562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185555; batch adversarial loss: 0.432799\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175279; batch adversarial loss: 0.457665\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190744; batch adversarial loss: 0.432872\n",
      "epoch 36; iter: 0; batch classifier loss: 0.185533; batch adversarial loss: 0.441135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166103; batch adversarial loss: 0.418207\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178679; batch adversarial loss: 0.486672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.160732; batch adversarial loss: 0.453017\n",
      "epoch 40; iter: 0; batch classifier loss: 0.209050; batch adversarial loss: 0.430425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202895; batch adversarial loss: 0.468225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.162201; batch adversarial loss: 0.433252\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156645; batch adversarial loss: 0.404131\n",
      "epoch 44; iter: 0; batch classifier loss: 0.146411; batch adversarial loss: 0.513614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122943; batch adversarial loss: 0.467399\n",
      "epoch 46; iter: 0; batch classifier loss: 0.180395; batch adversarial loss: 0.495797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.124137; batch adversarial loss: 0.448508\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209715; batch adversarial loss: 0.386611\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152585; batch adversarial loss: 0.543882\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190552; batch adversarial loss: 0.449473\n",
      "epoch 51; iter: 0; batch classifier loss: 0.172988; batch adversarial loss: 0.435275\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175880; batch adversarial loss: 0.515223\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183837; batch adversarial loss: 0.353050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102934; batch adversarial loss: 0.466800\n",
      "epoch 55; iter: 0; batch classifier loss: 0.196191; batch adversarial loss: 0.473839\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092535; batch adversarial loss: 0.398118\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136688; batch adversarial loss: 0.455316\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133610; batch adversarial loss: 0.445703\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129357; batch adversarial loss: 0.415142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.172616; batch adversarial loss: 0.442219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136000; batch adversarial loss: 0.494667\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084682; batch adversarial loss: 0.408700\n",
      "epoch 63; iter: 0; batch classifier loss: 0.147743; batch adversarial loss: 0.407928\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157293; batch adversarial loss: 0.507233\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110371; batch adversarial loss: 0.535255\n",
      "epoch 66; iter: 0; batch classifier loss: 0.142847; batch adversarial loss: 0.386481\n",
      "epoch 67; iter: 0; batch classifier loss: 0.175115; batch adversarial loss: 0.467047\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176645; batch adversarial loss: 0.459493\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113167; batch adversarial loss: 0.468022\n",
      "epoch 70; iter: 0; batch classifier loss: 0.105751; batch adversarial loss: 0.487868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113930; batch adversarial loss: 0.416163\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129361; batch adversarial loss: 0.496612\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139289; batch adversarial loss: 0.527970\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110371; batch adversarial loss: 0.370416\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098077; batch adversarial loss: 0.492345\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103069; batch adversarial loss: 0.534570\n",
      "epoch 77; iter: 0; batch classifier loss: 0.135289; batch adversarial loss: 0.419773\n",
      "epoch 78; iter: 0; batch classifier loss: 0.132025; batch adversarial loss: 0.563438\n",
      "epoch 79; iter: 0; batch classifier loss: 0.146384; batch adversarial loss: 0.523921\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101315; batch adversarial loss: 0.542974\n",
      "epoch 81; iter: 0; batch classifier loss: 0.145830; batch adversarial loss: 0.422834\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074846; batch adversarial loss: 0.483512\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123376; batch adversarial loss: 0.368902\n",
      "epoch 84; iter: 0; batch classifier loss: 0.140823; batch adversarial loss: 0.380248\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109004; batch adversarial loss: 0.425645\n",
      "epoch 86; iter: 0; batch classifier loss: 0.085708; batch adversarial loss: 0.445264\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088947; batch adversarial loss: 0.509932\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075524; batch adversarial loss: 0.490389\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101514; batch adversarial loss: 0.461878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117831; batch adversarial loss: 0.435612\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181382; batch adversarial loss: 0.519402\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102793; batch adversarial loss: 0.499861\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078759; batch adversarial loss: 0.424733\n",
      "epoch 94; iter: 0; batch classifier loss: 0.119693; batch adversarial loss: 0.434669\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083825; batch adversarial loss: 0.485564\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093359; batch adversarial loss: 0.415814\n",
      "epoch 97; iter: 0; batch classifier loss: 0.116835; batch adversarial loss: 0.420349\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071990; batch adversarial loss: 0.378292\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078660; batch adversarial loss: 0.483528\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066329; batch adversarial loss: 0.470279\n",
      "epoch 101; iter: 0; batch classifier loss: 0.100461; batch adversarial loss: 0.383027\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068755; batch adversarial loss: 0.434624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.110393; batch adversarial loss: 0.554499\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067306; batch adversarial loss: 0.409399\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075757; batch adversarial loss: 0.506822\n",
      "epoch 106; iter: 0; batch classifier loss: 0.094639; batch adversarial loss: 0.470328\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066807; batch adversarial loss: 0.366607\n",
      "epoch 108; iter: 0; batch classifier loss: 0.104857; batch adversarial loss: 0.330234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.438196\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083405; batch adversarial loss: 0.424003\n",
      "epoch 111; iter: 0; batch classifier loss: 0.096073; batch adversarial loss: 0.457116\n",
      "epoch 112; iter: 0; batch classifier loss: 0.090832; batch adversarial loss: 0.458874\n",
      "epoch 113; iter: 0; batch classifier loss: 0.097515; batch adversarial loss: 0.516810\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080806; batch adversarial loss: 0.406934\n",
      "epoch 115; iter: 0; batch classifier loss: 0.082054; batch adversarial loss: 0.459000\n",
      "epoch 116; iter: 0; batch classifier loss: 0.077276; batch adversarial loss: 0.420741\n",
      "epoch 117; iter: 0; batch classifier loss: 0.092771; batch adversarial loss: 0.492146\n",
      "epoch 118; iter: 0; batch classifier loss: 0.082096; batch adversarial loss: 0.427184\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063460; batch adversarial loss: 0.544110\n",
      "epoch 120; iter: 0; batch classifier loss: 0.082740; batch adversarial loss: 0.533409\n",
      "epoch 121; iter: 0; batch classifier loss: 0.098781; batch adversarial loss: 0.527451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048928; batch adversarial loss: 0.514448\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050385; batch adversarial loss: 0.441360\n",
      "epoch 124; iter: 0; batch classifier loss: 0.085106; batch adversarial loss: 0.394987\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070245; batch adversarial loss: 0.459446\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072871; batch adversarial loss: 0.431866\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060283; batch adversarial loss: 0.523876\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.486670\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065799; batch adversarial loss: 0.495212\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088198; batch adversarial loss: 0.465689\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040332; batch adversarial loss: 0.509301\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053938; batch adversarial loss: 0.418525\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028928; batch adversarial loss: 0.437824\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040154; batch adversarial loss: 0.445558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035159; batch adversarial loss: 0.523300\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060713; batch adversarial loss: 0.510785\n",
      "epoch 137; iter: 0; batch classifier loss: 0.089375; batch adversarial loss: 0.492399\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042291; batch adversarial loss: 0.401119\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038302; batch adversarial loss: 0.425349\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036227; batch adversarial loss: 0.444696\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027792; batch adversarial loss: 0.504480\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027906; batch adversarial loss: 0.426404\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032958; batch adversarial loss: 0.479589\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050690; batch adversarial loss: 0.415316\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037549; batch adversarial loss: 0.464631\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027543; batch adversarial loss: 0.298007\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024033; batch adversarial loss: 0.513769\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029191; batch adversarial loss: 0.466759\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021417; batch adversarial loss: 0.476262\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035303; batch adversarial loss: 0.386896\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011025; batch adversarial loss: 0.525189\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011532; batch adversarial loss: 0.510575\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048576; batch adversarial loss: 0.493071\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009602; batch adversarial loss: 0.575181\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017095; batch adversarial loss: 0.524219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.035454; batch adversarial loss: 0.409023\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019426; batch adversarial loss: 0.478060\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008837; batch adversarial loss: 0.442573\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016103; batch adversarial loss: 0.444064\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.509519\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012729; batch adversarial loss: 0.356448\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012889; batch adversarial loss: 0.464916\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009533; batch adversarial loss: 0.484054\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012323; batch adversarial loss: 0.429035\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013019; batch adversarial loss: 0.479623\n",
      "epoch 166; iter: 0; batch classifier loss: 0.076549; batch adversarial loss: 0.508677\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012410; batch adversarial loss: 0.496060\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015016; batch adversarial loss: 0.420195\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040504; batch adversarial loss: 0.458573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015882; batch adversarial loss: 0.422892\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020951; batch adversarial loss: 0.420867\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034135; batch adversarial loss: 0.524192\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019600; batch adversarial loss: 0.461512\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.422988\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.320700\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017709; batch adversarial loss: 0.466874\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028584; batch adversarial loss: 0.433567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008784; batch adversarial loss: 0.524931\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039388; batch adversarial loss: 0.434211\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019011; batch adversarial loss: 0.473295\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008420; batch adversarial loss: 0.416726\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010710; batch adversarial loss: 0.517678\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008100; batch adversarial loss: 0.465585\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018077; batch adversarial loss: 0.425979\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023827; batch adversarial loss: 0.424189\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014928; batch adversarial loss: 0.466135\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015975; batch adversarial loss: 0.507607\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014585; batch adversarial loss: 0.427718\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004132; batch adversarial loss: 0.437489\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013375; batch adversarial loss: 0.446137\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012941; batch adversarial loss: 0.459318\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011861; batch adversarial loss: 0.471947\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013682; batch adversarial loss: 0.515843\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015676; batch adversarial loss: 0.531840\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012542; batch adversarial loss: 0.453782\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.514114\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011263; batch adversarial loss: 0.431821\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006260; batch adversarial loss: 0.429143\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024761; batch adversarial loss: 0.377788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721478; batch adversarial loss: 0.633763\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375565; batch adversarial loss: 0.653216\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432368; batch adversarial loss: 0.611262\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372608; batch adversarial loss: 0.610551\n",
      "epoch 4; iter: 0; batch classifier loss: 0.416809; batch adversarial loss: 0.594775\n",
      "epoch 5; iter: 0; batch classifier loss: 0.448753; batch adversarial loss: 0.575364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.468233; batch adversarial loss: 0.602211\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454164; batch adversarial loss: 0.549150\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465577; batch adversarial loss: 0.499440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374465; batch adversarial loss: 0.563073\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407008; batch adversarial loss: 0.527251\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345107; batch adversarial loss: 0.527443\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401142; batch adversarial loss: 0.501822\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374377; batch adversarial loss: 0.555742\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404262; batch adversarial loss: 0.469608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355943; batch adversarial loss: 0.564286\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312230; batch adversarial loss: 0.485749\n",
      "epoch 17; iter: 0; batch classifier loss: 0.228567; batch adversarial loss: 0.553705\n",
      "epoch 18; iter: 0; batch classifier loss: 0.270973; batch adversarial loss: 0.448502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255439; batch adversarial loss: 0.569295\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314770; batch adversarial loss: 0.468856\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324880; batch adversarial loss: 0.478110\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254447; batch adversarial loss: 0.479261\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266362; batch adversarial loss: 0.536655\n",
      "epoch 24; iter: 0; batch classifier loss: 0.260822; batch adversarial loss: 0.475360\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286075; batch adversarial loss: 0.426077\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255432; batch adversarial loss: 0.455100\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213260; batch adversarial loss: 0.567798\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257592; batch adversarial loss: 0.403677\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215516; batch adversarial loss: 0.491716\n",
      "epoch 30; iter: 0; batch classifier loss: 0.243374; batch adversarial loss: 0.422804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249072; batch adversarial loss: 0.549467\n",
      "epoch 32; iter: 0; batch classifier loss: 0.283623; batch adversarial loss: 0.439562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.293660; batch adversarial loss: 0.393149\n",
      "epoch 34; iter: 0; batch classifier loss: 0.315870; batch adversarial loss: 0.481364\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226165; batch adversarial loss: 0.438500\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257118; batch adversarial loss: 0.473612\n",
      "epoch 37; iter: 0; batch classifier loss: 0.231153; batch adversarial loss: 0.513450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.180402; batch adversarial loss: 0.472629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327197; batch adversarial loss: 0.393977\n",
      "epoch 40; iter: 0; batch classifier loss: 0.282134; batch adversarial loss: 0.446902\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215299; batch adversarial loss: 0.505568\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251118; batch adversarial loss: 0.461362\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270652; batch adversarial loss: 0.497160\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259995; batch adversarial loss: 0.435915\n",
      "epoch 45; iter: 0; batch classifier loss: 0.217630; batch adversarial loss: 0.472692\n",
      "epoch 46; iter: 0; batch classifier loss: 0.258845; batch adversarial loss: 0.518648\n",
      "epoch 47; iter: 0; batch classifier loss: 0.168568; batch adversarial loss: 0.433140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079687; batch adversarial loss: 0.454059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090158; batch adversarial loss: 0.329718\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109117; batch adversarial loss: 0.387141\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094308; batch adversarial loss: 0.541107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.073893; batch adversarial loss: 0.457782\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084274; batch adversarial loss: 0.340423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133394; batch adversarial loss: 0.438108\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077228; batch adversarial loss: 0.349693\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065713; batch adversarial loss: 0.414899\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078588; batch adversarial loss: 0.432003\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068682; batch adversarial loss: 0.477995\n",
      "epoch 59; iter: 0; batch classifier loss: 0.051248; batch adversarial loss: 0.394212\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091687; batch adversarial loss: 0.388672\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067991; batch adversarial loss: 0.414856\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073135; batch adversarial loss: 0.363280\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078571; batch adversarial loss: 0.467451\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105670; batch adversarial loss: 0.482025\n",
      "epoch 65; iter: 0; batch classifier loss: 0.051587; batch adversarial loss: 0.334589\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086371; batch adversarial loss: 0.461405\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060115; batch adversarial loss: 0.425290\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107264; batch adversarial loss: 0.429071\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063608; batch adversarial loss: 0.484422\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102389; batch adversarial loss: 0.428333\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083586; batch adversarial loss: 0.336599\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110586; batch adversarial loss: 0.464336\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042326; batch adversarial loss: 0.449612\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069655; batch adversarial loss: 0.389073\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050370; batch adversarial loss: 0.391259\n",
      "epoch 76; iter: 0; batch classifier loss: 0.038533; batch adversarial loss: 0.346164\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084859; batch adversarial loss: 0.443942\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066628; batch adversarial loss: 0.433102\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076087; batch adversarial loss: 0.513684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.031987; batch adversarial loss: 0.429976\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047386; batch adversarial loss: 0.431151\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054932; batch adversarial loss: 0.340154\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075390; batch adversarial loss: 0.425714\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075621; batch adversarial loss: 0.381195\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110574; batch adversarial loss: 0.418005\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073419; batch adversarial loss: 0.330231\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.423261\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086851; batch adversarial loss: 0.399238\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052307; batch adversarial loss: 0.328660\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073051; batch adversarial loss: 0.351209\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055528; batch adversarial loss: 0.387796\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057172; batch adversarial loss: 0.421689\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056416; batch adversarial loss: 0.421289\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047181; batch adversarial loss: 0.495172\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060701; batch adversarial loss: 0.495199\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047022; batch adversarial loss: 0.393872\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076113; batch adversarial loss: 0.416603\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042788; batch adversarial loss: 0.411515\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054909; batch adversarial loss: 0.466671\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092740; batch adversarial loss: 0.432577\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053366; batch adversarial loss: 0.464698\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089189; batch adversarial loss: 0.434534\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069929; batch adversarial loss: 0.448248\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065752; batch adversarial loss: 0.470525\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049769; batch adversarial loss: 0.375544\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030253; batch adversarial loss: 0.427292\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056670; batch adversarial loss: 0.363593\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054630; batch adversarial loss: 0.428918\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066717; batch adversarial loss: 0.395025\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074766; batch adversarial loss: 0.441473\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056868; batch adversarial loss: 0.326486\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044351; batch adversarial loss: 0.394017\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068851; batch adversarial loss: 0.370877\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062437; batch adversarial loss: 0.521080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070286; batch adversarial loss: 0.361350\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065915; batch adversarial loss: 0.421138\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060321; batch adversarial loss: 0.436201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038633; batch adversarial loss: 0.502731\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046086; batch adversarial loss: 0.421637\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038553; batch adversarial loss: 0.526997\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042166; batch adversarial loss: 0.417796\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054918; batch adversarial loss: 0.507991\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038728; batch adversarial loss: 0.359417\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067714; batch adversarial loss: 0.428542\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063908; batch adversarial loss: 0.458886\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068450; batch adversarial loss: 0.404826\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045931; batch adversarial loss: 0.454167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058659; batch adversarial loss: 0.510139\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053236; batch adversarial loss: 0.461223\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042230; batch adversarial loss: 0.416162\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045497; batch adversarial loss: 0.510741\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059911; batch adversarial loss: 0.458977\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051207; batch adversarial loss: 0.436738\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.457324\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045427; batch adversarial loss: 0.424246\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043283; batch adversarial loss: 0.423064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.442584\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035268; batch adversarial loss: 0.441844\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052719; batch adversarial loss: 0.416759\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052580; batch adversarial loss: 0.486242\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036617; batch adversarial loss: 0.485137\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037216; batch adversarial loss: 0.502134\n",
      "epoch 143; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.362330\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035419; batch adversarial loss: 0.434589\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039446; batch adversarial loss: 0.424965\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046115; batch adversarial loss: 0.422618\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034609; batch adversarial loss: 0.421142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.044635; batch adversarial loss: 0.350654\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029508; batch adversarial loss: 0.406075\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032213; batch adversarial loss: 0.428967\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043819; batch adversarial loss: 0.478159\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051207; batch adversarial loss: 0.553166\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024192; batch adversarial loss: 0.433722\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020367; batch adversarial loss: 0.426675\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046339; batch adversarial loss: 0.443339\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.526942\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042198; batch adversarial loss: 0.413487\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024622; batch adversarial loss: 0.393911\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.460191\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010566; batch adversarial loss: 0.493431\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021762; batch adversarial loss: 0.551890\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.395551\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019809; batch adversarial loss: 0.468428\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019717; batch adversarial loss: 0.392952\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023526; batch adversarial loss: 0.444734\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.397734\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054738; batch adversarial loss: 0.415697\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028779; batch adversarial loss: 0.492342\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037116; batch adversarial loss: 0.475576\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023335; batch adversarial loss: 0.379711\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033790; batch adversarial loss: 0.355018\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034321; batch adversarial loss: 0.403438\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036503; batch adversarial loss: 0.452790\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022464; batch adversarial loss: 0.454232\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012863; batch adversarial loss: 0.513338\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039776; batch adversarial loss: 0.387261\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033905; batch adversarial loss: 0.492984\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028583; batch adversarial loss: 0.462740\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013998; batch adversarial loss: 0.497487\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009122; batch adversarial loss: 0.471565\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013641; batch adversarial loss: 0.414310\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008242; batch adversarial loss: 0.405429\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018012; batch adversarial loss: 0.406273\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041471; batch adversarial loss: 0.398225\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020850; batch adversarial loss: 0.356317\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022096; batch adversarial loss: 0.527096\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033157; batch adversarial loss: 0.445307\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022320; batch adversarial loss: 0.486026\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018562; batch adversarial loss: 0.425962\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016769; batch adversarial loss: 0.507646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031708; batch adversarial loss: 0.362401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015018; batch adversarial loss: 0.414050\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009360; batch adversarial loss: 0.412585\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047229; batch adversarial loss: 0.412731\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028554; batch adversarial loss: 0.494866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007496; batch adversarial loss: 0.433516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.432648\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013009; batch adversarial loss: 0.306196\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036414; batch adversarial loss: 0.513697\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662364; batch adversarial loss: 0.781442\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429785; batch adversarial loss: 0.755328\n",
      "epoch 2; iter: 0; batch classifier loss: 0.355040; batch adversarial loss: 0.737363\n",
      "epoch 3; iter: 0; batch classifier loss: 0.445622; batch adversarial loss: 0.704977\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324635; batch adversarial loss: 0.665597\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345420; batch adversarial loss: 0.663737\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329279; batch adversarial loss: 0.594220\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287645; batch adversarial loss: 0.583480\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307130; batch adversarial loss: 0.535746\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275734; batch adversarial loss: 0.537322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.356090; batch adversarial loss: 0.501100\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219713; batch adversarial loss: 0.490725\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267541; batch adversarial loss: 0.517637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.204559; batch adversarial loss: 0.425627\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206109; batch adversarial loss: 0.489121\n",
      "epoch 15; iter: 0; batch classifier loss: 0.149759; batch adversarial loss: 0.484820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203297; batch adversarial loss: 0.473973\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203079; batch adversarial loss: 0.442980\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206974; batch adversarial loss: 0.409207\n",
      "epoch 19; iter: 0; batch classifier loss: 0.128507; batch adversarial loss: 0.520566\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157724; batch adversarial loss: 0.495495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.206883; batch adversarial loss: 0.408160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.139901; batch adversarial loss: 0.423620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140106; batch adversarial loss: 0.461430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.134570; batch adversarial loss: 0.416690\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174262; batch adversarial loss: 0.402716\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130011; batch adversarial loss: 0.424682\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120785; batch adversarial loss: 0.469884\n",
      "epoch 28; iter: 0; batch classifier loss: 0.115500; batch adversarial loss: 0.420021\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187666; batch adversarial loss: 0.444755\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151878; batch adversarial loss: 0.448227\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173593; batch adversarial loss: 0.401644\n",
      "epoch 32; iter: 0; batch classifier loss: 0.114889; batch adversarial loss: 0.499052\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161006; batch adversarial loss: 0.372683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188116; batch adversarial loss: 0.477866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153912; batch adversarial loss: 0.368422\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140761; batch adversarial loss: 0.464777\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143417; batch adversarial loss: 0.410103\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138525; batch adversarial loss: 0.435603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.117539; batch adversarial loss: 0.378869\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128774; batch adversarial loss: 0.488047\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106200; batch adversarial loss: 0.387677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126404; batch adversarial loss: 0.411655\n",
      "epoch 43; iter: 0; batch classifier loss: 0.140677; batch adversarial loss: 0.402686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.161896; batch adversarial loss: 0.397751\n",
      "epoch 45; iter: 0; batch classifier loss: 0.152920; batch adversarial loss: 0.413009\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082628; batch adversarial loss: 0.434268\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122044; batch adversarial loss: 0.393290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.146169; batch adversarial loss: 0.387955\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151117; batch adversarial loss: 0.437759\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119588; batch adversarial loss: 0.429551\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129402; batch adversarial loss: 0.301250\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103996; batch adversarial loss: 0.396267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102486; batch adversarial loss: 0.468077\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132356; batch adversarial loss: 0.415625\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076237; batch adversarial loss: 0.520382\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098809; batch adversarial loss: 0.380417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143271; batch adversarial loss: 0.442936\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088969; batch adversarial loss: 0.366757\n",
      "epoch 59; iter: 0; batch classifier loss: 0.080042; batch adversarial loss: 0.377939\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.379296\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099035; batch adversarial loss: 0.381002\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057533; batch adversarial loss: 0.497519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077718; batch adversarial loss: 0.357338\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075889; batch adversarial loss: 0.393417\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069133; batch adversarial loss: 0.452418\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071760; batch adversarial loss: 0.393674\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078818; batch adversarial loss: 0.351754\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063392; batch adversarial loss: 0.355586\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093305; batch adversarial loss: 0.373341\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062010; batch adversarial loss: 0.380276\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056068; batch adversarial loss: 0.482500\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049156; batch adversarial loss: 0.342926\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064314; batch adversarial loss: 0.435880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063366; batch adversarial loss: 0.449026\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062984; batch adversarial loss: 0.414569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055924; batch adversarial loss: 0.436791\n",
      "epoch 77; iter: 0; batch classifier loss: 0.049543; batch adversarial loss: 0.427156\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044571; batch adversarial loss: 0.348045\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055812; batch adversarial loss: 0.452196\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056952; batch adversarial loss: 0.419089\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060109; batch adversarial loss: 0.518402\n",
      "epoch 82; iter: 0; batch classifier loss: 0.026915; batch adversarial loss: 0.372513\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063220; batch adversarial loss: 0.415828\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066365; batch adversarial loss: 0.441134\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039435; batch adversarial loss: 0.342669\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057457; batch adversarial loss: 0.502970\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040020; batch adversarial loss: 0.429738\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040855; batch adversarial loss: 0.393935\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057800; batch adversarial loss: 0.359326\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039940; batch adversarial loss: 0.550300\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051154; batch adversarial loss: 0.387239\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070051; batch adversarial loss: 0.429546\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055229; batch adversarial loss: 0.470162\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037025; batch adversarial loss: 0.424412\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042634; batch adversarial loss: 0.403829\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078014; batch adversarial loss: 0.510049\n",
      "epoch 97; iter: 0; batch classifier loss: 0.081650; batch adversarial loss: 0.551940\n",
      "epoch 98; iter: 0; batch classifier loss: 0.134571; batch adversarial loss: 0.676731\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079087; batch adversarial loss: 0.598913\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116430; batch adversarial loss: 0.689648\n",
      "epoch 101; iter: 0; batch classifier loss: 0.139139; batch adversarial loss: 0.569387\n",
      "epoch 102; iter: 0; batch classifier loss: 0.169013; batch adversarial loss: 0.659131\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064821; batch adversarial loss: 0.422489\n",
      "epoch 104; iter: 0; batch classifier loss: 0.111824; batch adversarial loss: 0.616443\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054110; batch adversarial loss: 0.358810\n",
      "epoch 106; iter: 0; batch classifier loss: 0.154742; batch adversarial loss: 0.685921\n",
      "epoch 107; iter: 0; batch classifier loss: 0.159447; batch adversarial loss: 0.776394\n",
      "epoch 108; iter: 0; batch classifier loss: 0.144164; batch adversarial loss: 0.564179\n",
      "epoch 109; iter: 0; batch classifier loss: 0.130882; batch adversarial loss: 0.574500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.117271; batch adversarial loss: 0.544262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.149979; batch adversarial loss: 0.572078\n",
      "epoch 112; iter: 0; batch classifier loss: 0.113178; batch adversarial loss: 0.476000\n",
      "epoch 113; iter: 0; batch classifier loss: 0.159356; batch adversarial loss: 0.641633\n",
      "epoch 114; iter: 0; batch classifier loss: 0.185919; batch adversarial loss: 0.688277\n",
      "epoch 115; iter: 0; batch classifier loss: 0.194127; batch adversarial loss: 0.559686\n",
      "epoch 116; iter: 0; batch classifier loss: 0.167570; batch adversarial loss: 0.636671\n",
      "epoch 117; iter: 0; batch classifier loss: 0.141251; batch adversarial loss: 0.597085\n",
      "epoch 118; iter: 0; batch classifier loss: 0.129902; batch adversarial loss: 0.575546\n",
      "epoch 119; iter: 0; batch classifier loss: 0.106690; batch adversarial loss: 0.509786\n",
      "epoch 120; iter: 0; batch classifier loss: 0.182054; batch adversarial loss: 0.587939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.141504; batch adversarial loss: 0.553852\n",
      "epoch 122; iter: 0; batch classifier loss: 0.144256; batch adversarial loss: 0.556396\n",
      "epoch 123; iter: 0; batch classifier loss: 0.187834; batch adversarial loss: 0.505178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.099294; batch adversarial loss: 0.455900\n",
      "epoch 125; iter: 0; batch classifier loss: 0.141356; batch adversarial loss: 0.563581\n",
      "epoch 126; iter: 0; batch classifier loss: 0.120588; batch adversarial loss: 0.442336\n",
      "epoch 127; iter: 0; batch classifier loss: 0.099456; batch adversarial loss: 0.491682\n",
      "epoch 128; iter: 0; batch classifier loss: 0.120934; batch adversarial loss: 0.493697\n",
      "epoch 129; iter: 0; batch classifier loss: 0.177705; batch adversarial loss: 0.565299\n",
      "epoch 130; iter: 0; batch classifier loss: 0.111345; batch adversarial loss: 0.517335\n",
      "epoch 131; iter: 0; batch classifier loss: 0.098555; batch adversarial loss: 0.561178\n",
      "epoch 132; iter: 0; batch classifier loss: 0.086527; batch adversarial loss: 0.450656\n",
      "epoch 133; iter: 0; batch classifier loss: 0.120237; batch adversarial loss: 0.469590\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081021; batch adversarial loss: 0.420977\n",
      "epoch 135; iter: 0; batch classifier loss: 0.071925; batch adversarial loss: 0.457093\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034241; batch adversarial loss: 0.424316\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045217; batch adversarial loss: 0.427225\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045527; batch adversarial loss: 0.490749\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032539; batch adversarial loss: 0.537467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.024592; batch adversarial loss: 0.401259\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030472; batch adversarial loss: 0.459333\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025584; batch adversarial loss: 0.514994\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055648; batch adversarial loss: 0.457201\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065735; batch adversarial loss: 0.438855\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047016; batch adversarial loss: 0.438204\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.520454\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044716; batch adversarial loss: 0.458693\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026182; batch adversarial loss: 0.483495\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045572; batch adversarial loss: 0.495927\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048266; batch adversarial loss: 0.371869\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048992; batch adversarial loss: 0.396724\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035910; batch adversarial loss: 0.316524\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050917; batch adversarial loss: 0.426933\n",
      "epoch 154; iter: 0; batch classifier loss: 0.049522; batch adversarial loss: 0.413614\n",
      "epoch 155; iter: 0; batch classifier loss: 0.067813; batch adversarial loss: 0.431806\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018484; batch adversarial loss: 0.538149\n",
      "epoch 157; iter: 0; batch classifier loss: 0.062422; batch adversarial loss: 0.523727\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048059; batch adversarial loss: 0.484138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.076118; batch adversarial loss: 0.441268\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045612; batch adversarial loss: 0.431065\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027223; batch adversarial loss: 0.394185\n",
      "epoch 162; iter: 0; batch classifier loss: 0.053257; batch adversarial loss: 0.591212\n",
      "epoch 163; iter: 0; batch classifier loss: 0.047648; batch adversarial loss: 0.392715\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047576; batch adversarial loss: 0.405231\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045977; batch adversarial loss: 0.484770\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031914; batch adversarial loss: 0.479555\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027876; batch adversarial loss: 0.514216\n",
      "epoch 168; iter: 0; batch classifier loss: 0.063352; batch adversarial loss: 0.488746\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038124; batch adversarial loss: 0.437829\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030175; batch adversarial loss: 0.534187\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046089; batch adversarial loss: 0.457741\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018563; batch adversarial loss: 0.438503\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058543; batch adversarial loss: 0.488035\n",
      "epoch 174; iter: 0; batch classifier loss: 0.060227; batch adversarial loss: 0.470716\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031197; batch adversarial loss: 0.444666\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054088; batch adversarial loss: 0.500948\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029953; batch adversarial loss: 0.399050\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048171; batch adversarial loss: 0.499140\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040417; batch adversarial loss: 0.515019\n",
      "epoch 180; iter: 0; batch classifier loss: 0.042853; batch adversarial loss: 0.454867\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031214; batch adversarial loss: 0.446336\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027469; batch adversarial loss: 0.455647\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028994; batch adversarial loss: 0.422743\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025499; batch adversarial loss: 0.473443\n",
      "epoch 185; iter: 0; batch classifier loss: 0.051575; batch adversarial loss: 0.487694\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027280; batch adversarial loss: 0.484229\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028126; batch adversarial loss: 0.465604\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044745; batch adversarial loss: 0.494770\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060939; batch adversarial loss: 0.444846\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017921; batch adversarial loss: 0.453752\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010063; batch adversarial loss: 0.417868\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.431937\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043281; batch adversarial loss: 0.384254\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035495; batch adversarial loss: 0.499244\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034276; batch adversarial loss: 0.381507\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035389; batch adversarial loss: 0.471841\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019213; batch adversarial loss: 0.457472\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032885; batch adversarial loss: 0.460638\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048728; batch adversarial loss: 0.424610\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676091; batch adversarial loss: 0.603954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389248; batch adversarial loss: 0.623479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.494950; batch adversarial loss: 0.558995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410019; batch adversarial loss: 0.579480\n",
      "epoch 4; iter: 0; batch classifier loss: 0.285067; batch adversarial loss: 0.516642\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313623; batch adversarial loss: 0.509343\n",
      "epoch 6; iter: 0; batch classifier loss: 0.301676; batch adversarial loss: 0.505009\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252263; batch adversarial loss: 0.530574\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289427; batch adversarial loss: 0.563065\n",
      "epoch 9; iter: 0; batch classifier loss: 0.258774; batch adversarial loss: 0.511467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.214855; batch adversarial loss: 0.462565\n",
      "epoch 11; iter: 0; batch classifier loss: 0.178512; batch adversarial loss: 0.442379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.276617; batch adversarial loss: 0.538944\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239296; batch adversarial loss: 0.520467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.188076; batch adversarial loss: 0.503643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243337; batch adversarial loss: 0.477131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218313; batch adversarial loss: 0.512148\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217632; batch adversarial loss: 0.547099\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187990; batch adversarial loss: 0.497204\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252933; batch adversarial loss: 0.584922\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230456; batch adversarial loss: 0.535381\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212178; batch adversarial loss: 0.420199\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206812; batch adversarial loss: 0.521699\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209283; batch adversarial loss: 0.545211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282202; batch adversarial loss: 0.660319\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185086; batch adversarial loss: 0.426393\n",
      "epoch 26; iter: 0; batch classifier loss: 0.309350; batch adversarial loss: 0.532066\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285422; batch adversarial loss: 0.469228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273917; batch adversarial loss: 0.467543\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299645; batch adversarial loss: 0.473945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274107; batch adversarial loss: 0.525520\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153617; batch adversarial loss: 0.454950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165068; batch adversarial loss: 0.452987\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137429; batch adversarial loss: 0.434526\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145697; batch adversarial loss: 0.430882\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115935; batch adversarial loss: 0.430047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.090986; batch adversarial loss: 0.493653\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136536; batch adversarial loss: 0.466774\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097142; batch adversarial loss: 0.434830\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131372; batch adversarial loss: 0.439408\n",
      "epoch 40; iter: 0; batch classifier loss: 0.079322; batch adversarial loss: 0.452145\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113490; batch adversarial loss: 0.408072\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075842; batch adversarial loss: 0.489824\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083176; batch adversarial loss: 0.418218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102422; batch adversarial loss: 0.341730\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128922; batch adversarial loss: 0.473069\n",
      "epoch 46; iter: 0; batch classifier loss: 0.071848; batch adversarial loss: 0.412866\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113044; batch adversarial loss: 0.471633\n",
      "epoch 48; iter: 0; batch classifier loss: 0.055214; batch adversarial loss: 0.404517\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085996; batch adversarial loss: 0.429619\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063744; batch adversarial loss: 0.446917\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069006; batch adversarial loss: 0.496387\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085709; batch adversarial loss: 0.456458\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104198; batch adversarial loss: 0.449271\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097482; batch adversarial loss: 0.430430\n",
      "epoch 55; iter: 0; batch classifier loss: 0.051962; batch adversarial loss: 0.403326\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079379; batch adversarial loss: 0.438718\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087057; batch adversarial loss: 0.529652\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069904; batch adversarial loss: 0.371073\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098003; batch adversarial loss: 0.432961\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158880; batch adversarial loss: 0.410175\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074929; batch adversarial loss: 0.512513\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.495071\n",
      "epoch 63; iter: 0; batch classifier loss: 0.041554; batch adversarial loss: 0.402996\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067217; batch adversarial loss: 0.428060\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107514; batch adversarial loss: 0.435363\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108527; batch adversarial loss: 0.382474\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092670; batch adversarial loss: 0.473169\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073701; batch adversarial loss: 0.363690\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063414; batch adversarial loss: 0.414988\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081705; batch adversarial loss: 0.403182\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067455; batch adversarial loss: 0.436537\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056882; batch adversarial loss: 0.387454\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107907; batch adversarial loss: 0.531724\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099397; batch adversarial loss: 0.433314\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101951; batch adversarial loss: 0.470320\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133068; batch adversarial loss: 0.475805\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077797; batch adversarial loss: 0.370949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090758; batch adversarial loss: 0.473397\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068413; batch adversarial loss: 0.541212\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061998; batch adversarial loss: 0.403715\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077372; batch adversarial loss: 0.533861\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106870; batch adversarial loss: 0.556735\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047362; batch adversarial loss: 0.490229\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122838; batch adversarial loss: 0.380421\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.498948\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104332; batch adversarial loss: 0.503403\n",
      "epoch 87; iter: 0; batch classifier loss: 0.029485; batch adversarial loss: 0.405421\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054672; batch adversarial loss: 0.440959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060520; batch adversarial loss: 0.431571\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039905; batch adversarial loss: 0.545963\n",
      "epoch 91; iter: 0; batch classifier loss: 0.156229; batch adversarial loss: 0.369648\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050706; batch adversarial loss: 0.397191\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071041; batch adversarial loss: 0.445694\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084404; batch adversarial loss: 0.378408\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058376; batch adversarial loss: 0.428770\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052170; batch adversarial loss: 0.424746\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071481; batch adversarial loss: 0.454785\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064386; batch adversarial loss: 0.448292\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061729; batch adversarial loss: 0.558562\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094862; batch adversarial loss: 0.471741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049314; batch adversarial loss: 0.615892\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074087; batch adversarial loss: 0.420103\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068983; batch adversarial loss: 0.445637\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073403; batch adversarial loss: 0.468418\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058544; batch adversarial loss: 0.478884\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043903; batch adversarial loss: 0.377401\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101223; batch adversarial loss: 0.450250\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023031; batch adversarial loss: 0.481604\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046966; batch adversarial loss: 0.417185\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068923; batch adversarial loss: 0.471062\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022873; batch adversarial loss: 0.503274\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025965; batch adversarial loss: 0.376495\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057352; batch adversarial loss: 0.410114\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.431990\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071867; batch adversarial loss: 0.446034\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058874; batch adversarial loss: 0.446465\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053835; batch adversarial loss: 0.383775\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060663; batch adversarial loss: 0.391865\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048391; batch adversarial loss: 0.478689\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053053; batch adversarial loss: 0.548423\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065245; batch adversarial loss: 0.459287\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072433; batch adversarial loss: 0.423855\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069095; batch adversarial loss: 0.397497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.066593; batch adversarial loss: 0.507251\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034090; batch adversarial loss: 0.470360\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040571; batch adversarial loss: 0.468250\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040679; batch adversarial loss: 0.435240\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084822; batch adversarial loss: 0.484620\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031541; batch adversarial loss: 0.409866\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056400; batch adversarial loss: 0.468784\n",
      "epoch 131; iter: 0; batch classifier loss: 0.095247; batch adversarial loss: 0.455573\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017365; batch adversarial loss: 0.505276\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040134; batch adversarial loss: 0.347609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.022840; batch adversarial loss: 0.423893\n",
      "epoch 135; iter: 0; batch classifier loss: 0.055579; batch adversarial loss: 0.504959\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020318; batch adversarial loss: 0.407412\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054685; batch adversarial loss: 0.434071\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038943; batch adversarial loss: 0.502172\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035436; batch adversarial loss: 0.502601\n",
      "epoch 140; iter: 0; batch classifier loss: 0.072437; batch adversarial loss: 0.437495\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029049; batch adversarial loss: 0.486718\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027291; batch adversarial loss: 0.453212\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022722; batch adversarial loss: 0.380086\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037670; batch adversarial loss: 0.542166\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042352; batch adversarial loss: 0.521261\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029424; batch adversarial loss: 0.452699\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013014; batch adversarial loss: 0.483187\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035997; batch adversarial loss: 0.411765\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047009; batch adversarial loss: 0.565049\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027511; batch adversarial loss: 0.412715\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032623; batch adversarial loss: 0.540707\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046552; batch adversarial loss: 0.441383\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039127; batch adversarial loss: 0.581100\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040866; batch adversarial loss: 0.472216\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055142; batch adversarial loss: 0.428275\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050569; batch adversarial loss: 0.455250\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054522; batch adversarial loss: 0.485580\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037751; batch adversarial loss: 0.458801\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032145; batch adversarial loss: 0.500582\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032749; batch adversarial loss: 0.437492\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023065; batch adversarial loss: 0.387533\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022648; batch adversarial loss: 0.343020\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020691; batch adversarial loss: 0.368564\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.475204\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021419; batch adversarial loss: 0.324527\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041491; batch adversarial loss: 0.480871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012669; batch adversarial loss: 0.448538\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.441678\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029321; batch adversarial loss: 0.360656\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011628; batch adversarial loss: 0.399216\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011967; batch adversarial loss: 0.565379\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009064; batch adversarial loss: 0.441015\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041659; batch adversarial loss: 0.455474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.078552; batch adversarial loss: 0.362767\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014550; batch adversarial loss: 0.445876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030050; batch adversarial loss: 0.511014\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012865; batch adversarial loss: 0.479231\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027521; batch adversarial loss: 0.456253\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.448334\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039953; batch adversarial loss: 0.449207\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036331; batch adversarial loss: 0.480488\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.444437\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015836; batch adversarial loss: 0.448250\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034951; batch adversarial loss: 0.438411\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012699; batch adversarial loss: 0.540156\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026882; batch adversarial loss: 0.491963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025724; batch adversarial loss: 0.527395\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029874; batch adversarial loss: 0.370806\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037065; batch adversarial loss: 0.381325\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031490; batch adversarial loss: 0.462010\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010948; batch adversarial loss: 0.493148\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026599; batch adversarial loss: 0.485972\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017584; batch adversarial loss: 0.448102\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039096; batch adversarial loss: 0.412125\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026608; batch adversarial loss: 0.354756\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042498; batch adversarial loss: 0.456354\n",
      "epoch 197; iter: 0; batch classifier loss: 0.063410; batch adversarial loss: 0.545358\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032897; batch adversarial loss: 0.445047\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029247; batch adversarial loss: 0.414093\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685838; batch adversarial loss: 0.530187\n",
      "epoch 1; iter: 0; batch classifier loss: 0.501751; batch adversarial loss: 0.599483\n",
      "epoch 2; iter: 0; batch classifier loss: 0.506199; batch adversarial loss: 0.561244\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342404; batch adversarial loss: 0.617026\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402532; batch adversarial loss: 0.631782\n",
      "epoch 5; iter: 0; batch classifier loss: 0.477856; batch adversarial loss: 0.601486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494039; batch adversarial loss: 0.581343\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583023; batch adversarial loss: 0.616843\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581964; batch adversarial loss: 0.600371\n",
      "epoch 9; iter: 0; batch classifier loss: 0.630185; batch adversarial loss: 0.585903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.677783; batch adversarial loss: 0.531250\n",
      "epoch 11; iter: 0; batch classifier loss: 0.536307; batch adversarial loss: 0.539207\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401126; batch adversarial loss: 0.539106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354695; batch adversarial loss: 0.506122\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284799; batch adversarial loss: 0.442184\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250767; batch adversarial loss: 0.527892\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312157; batch adversarial loss: 0.458637\n",
      "epoch 17; iter: 0; batch classifier loss: 0.274021; batch adversarial loss: 0.521555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250134; batch adversarial loss: 0.455899\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260167; batch adversarial loss: 0.486954\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225448; batch adversarial loss: 0.486936\n",
      "epoch 21; iter: 0; batch classifier loss: 0.224613; batch adversarial loss: 0.605197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213444; batch adversarial loss: 0.459093\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236050; batch adversarial loss: 0.479918\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218123; batch adversarial loss: 0.492473\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228190; batch adversarial loss: 0.452835\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177475; batch adversarial loss: 0.511373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195099; batch adversarial loss: 0.482253\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197011; batch adversarial loss: 0.445523\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192625; batch adversarial loss: 0.527584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.166233; batch adversarial loss: 0.506393\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179000; batch adversarial loss: 0.406757\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202577; batch adversarial loss: 0.469877\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164039; batch adversarial loss: 0.449072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.195494; batch adversarial loss: 0.455127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180566; batch adversarial loss: 0.417256\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166646; batch adversarial loss: 0.381371\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177831; batch adversarial loss: 0.421345\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142561; batch adversarial loss: 0.463195\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197023; batch adversarial loss: 0.483450\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165657; batch adversarial loss: 0.398619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109492; batch adversarial loss: 0.493447\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169482; batch adversarial loss: 0.557837\n",
      "epoch 43; iter: 0; batch classifier loss: 0.155120; batch adversarial loss: 0.445817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.224905; batch adversarial loss: 0.390092\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163301; batch adversarial loss: 0.445022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.213332; batch adversarial loss: 0.449848\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234266; batch adversarial loss: 0.450116\n",
      "epoch 48; iter: 0; batch classifier loss: 0.133872; batch adversarial loss: 0.456596\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142353; batch adversarial loss: 0.494851\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181905; batch adversarial loss: 0.375147\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151612; batch adversarial loss: 0.377509\n",
      "epoch 52; iter: 0; batch classifier loss: 0.208428; batch adversarial loss: 0.510542\n",
      "epoch 53; iter: 0; batch classifier loss: 0.184825; batch adversarial loss: 0.456459\n",
      "epoch 54; iter: 0; batch classifier loss: 0.258516; batch adversarial loss: 0.517534\n",
      "epoch 55; iter: 0; batch classifier loss: 0.226092; batch adversarial loss: 0.397736\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153701; batch adversarial loss: 0.497655\n",
      "epoch 57; iter: 0; batch classifier loss: 0.222631; batch adversarial loss: 0.458942\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156367; batch adversarial loss: 0.423544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.242274; batch adversarial loss: 0.527965\n",
      "epoch 60; iter: 0; batch classifier loss: 0.177807; batch adversarial loss: 0.396160\n",
      "epoch 61; iter: 0; batch classifier loss: 0.217243; batch adversarial loss: 0.422520\n",
      "epoch 62; iter: 0; batch classifier loss: 0.213017; batch adversarial loss: 0.385500\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195167; batch adversarial loss: 0.360054\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213488; batch adversarial loss: 0.495950\n",
      "epoch 65; iter: 0; batch classifier loss: 0.230169; batch adversarial loss: 0.396744\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167544; batch adversarial loss: 0.446812\n",
      "epoch 67; iter: 0; batch classifier loss: 0.261848; batch adversarial loss: 0.458905\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101746; batch adversarial loss: 0.483129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087788; batch adversarial loss: 0.507747\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068412; batch adversarial loss: 0.378537\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067779; batch adversarial loss: 0.436090\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052301; batch adversarial loss: 0.466296\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085553; batch adversarial loss: 0.473830\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088127; batch adversarial loss: 0.479121\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102149; batch adversarial loss: 0.445970\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049559; batch adversarial loss: 0.506467\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047407; batch adversarial loss: 0.438584\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046208; batch adversarial loss: 0.466936\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051718; batch adversarial loss: 0.429116\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056891; batch adversarial loss: 0.386935\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042950; batch adversarial loss: 0.446244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043769; batch adversarial loss: 0.428284\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073935; batch adversarial loss: 0.406876\n",
      "epoch 84; iter: 0; batch classifier loss: 0.044695; batch adversarial loss: 0.556755\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035536; batch adversarial loss: 0.443451\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048391; batch adversarial loss: 0.488367\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063871; batch adversarial loss: 0.407827\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057812; batch adversarial loss: 0.455979\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098880; batch adversarial loss: 0.492789\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055416; batch adversarial loss: 0.480625\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049492; batch adversarial loss: 0.451519\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090613; batch adversarial loss: 0.360784\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079499; batch adversarial loss: 0.474644\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056956; batch adversarial loss: 0.345913\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083861; batch adversarial loss: 0.449187\n",
      "epoch 96; iter: 0; batch classifier loss: 0.022037; batch adversarial loss: 0.448886\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077356; batch adversarial loss: 0.450643\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058845; batch adversarial loss: 0.490557\n",
      "epoch 99; iter: 0; batch classifier loss: 0.020056; batch adversarial loss: 0.309686\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065398; batch adversarial loss: 0.398739\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054911; batch adversarial loss: 0.364004\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049813; batch adversarial loss: 0.437111\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055276; batch adversarial loss: 0.458715\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067745; batch adversarial loss: 0.382939\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032048; batch adversarial loss: 0.296138\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071977; batch adversarial loss: 0.385748\n",
      "epoch 107; iter: 0; batch classifier loss: 0.084681; batch adversarial loss: 0.436390\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028855; batch adversarial loss: 0.423474\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080170; batch adversarial loss: 0.406043\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048264; batch adversarial loss: 0.380143\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058685; batch adversarial loss: 0.423499\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047691; batch adversarial loss: 0.453664\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043700; batch adversarial loss: 0.417366\n",
      "epoch 114; iter: 0; batch classifier loss: 0.087189; batch adversarial loss: 0.409824\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037232; batch adversarial loss: 0.413995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037225; batch adversarial loss: 0.384185\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043469; batch adversarial loss: 0.402374\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069029; batch adversarial loss: 0.460444\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060964; batch adversarial loss: 0.416474\n",
      "epoch 120; iter: 0; batch classifier loss: 0.016691; batch adversarial loss: 0.487460\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040878; batch adversarial loss: 0.426119\n",
      "epoch 122; iter: 0; batch classifier loss: 0.084817; batch adversarial loss: 0.524223\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048270; batch adversarial loss: 0.401613\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035163; batch adversarial loss: 0.462516\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058102; batch adversarial loss: 0.480040\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038438; batch adversarial loss: 0.411824\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071382; batch adversarial loss: 0.408295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.068139; batch adversarial loss: 0.464820\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038982; batch adversarial loss: 0.427746\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028027; batch adversarial loss: 0.517230\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.448599\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063552; batch adversarial loss: 0.438408\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056806; batch adversarial loss: 0.376586\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041047; batch adversarial loss: 0.410934\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051478; batch adversarial loss: 0.403429\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065703; batch adversarial loss: 0.484715\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061025; batch adversarial loss: 0.397335\n",
      "epoch 138; iter: 0; batch classifier loss: 0.091780; batch adversarial loss: 0.307134\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038299; batch adversarial loss: 0.345831\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073567; batch adversarial loss: 0.502429\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053319; batch adversarial loss: 0.389302\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065757; batch adversarial loss: 0.481218\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052946; batch adversarial loss: 0.466532\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040256; batch adversarial loss: 0.400134\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065017; batch adversarial loss: 0.444192\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047397; batch adversarial loss: 0.502715\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052427; batch adversarial loss: 0.387906\n",
      "epoch 148; iter: 0; batch classifier loss: 0.071654; batch adversarial loss: 0.514161\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054706; batch adversarial loss: 0.448302\n",
      "epoch 150; iter: 0; batch classifier loss: 0.092068; batch adversarial loss: 0.426219\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039275; batch adversarial loss: 0.359604\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054192; batch adversarial loss: 0.422048\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041876; batch adversarial loss: 0.382981\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058265; batch adversarial loss: 0.490292\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057077; batch adversarial loss: 0.381358\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051552; batch adversarial loss: 0.469953\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046080; batch adversarial loss: 0.447207\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.380501\n",
      "epoch 159; iter: 0; batch classifier loss: 0.066293; batch adversarial loss: 0.437880\n",
      "epoch 160; iter: 0; batch classifier loss: 0.083524; batch adversarial loss: 0.442139\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029023; batch adversarial loss: 0.477803\n",
      "epoch 162; iter: 0; batch classifier loss: 0.069863; batch adversarial loss: 0.446516\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046091; batch adversarial loss: 0.453611\n",
      "epoch 164; iter: 0; batch classifier loss: 0.067874; batch adversarial loss: 0.373062\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031933; batch adversarial loss: 0.546756\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035946; batch adversarial loss: 0.401811\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038383; batch adversarial loss: 0.343624\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046221; batch adversarial loss: 0.445626\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037387; batch adversarial loss: 0.405897\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031870; batch adversarial loss: 0.461893\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022591; batch adversarial loss: 0.422949\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045917; batch adversarial loss: 0.367260\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026247; batch adversarial loss: 0.418135\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026082; batch adversarial loss: 0.390087\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016951; batch adversarial loss: 0.463558\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043049; batch adversarial loss: 0.389184\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045782; batch adversarial loss: 0.371603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030677; batch adversarial loss: 0.420428\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017650; batch adversarial loss: 0.419243\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037454; batch adversarial loss: 0.449146\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026303; batch adversarial loss: 0.457819\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053620; batch adversarial loss: 0.401664\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035734; batch adversarial loss: 0.467924\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022481; batch adversarial loss: 0.443775\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018233; batch adversarial loss: 0.431182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014623; batch adversarial loss: 0.473161\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032478; batch adversarial loss: 0.443819\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029055; batch adversarial loss: 0.420797\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059726; batch adversarial loss: 0.363883\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028925; batch adversarial loss: 0.395620\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016251; batch adversarial loss: 0.426487\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041685; batch adversarial loss: 0.398750\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016965; batch adversarial loss: 0.464701\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039684; batch adversarial loss: 0.407749\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020045; batch adversarial loss: 0.354869\n",
      "epoch 196; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.355700\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019027; batch adversarial loss: 0.464677\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022229; batch adversarial loss: 0.366464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014430; batch adversarial loss: 0.434472\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692998; batch adversarial loss: 0.671912\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464024; batch adversarial loss: 0.640719\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394136; batch adversarial loss: 0.615609\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359939; batch adversarial loss: 0.576134\n",
      "epoch 4; iter: 0; batch classifier loss: 0.317556; batch adversarial loss: 0.574960\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354912; batch adversarial loss: 0.535651\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320010; batch adversarial loss: 0.537667\n",
      "epoch 7; iter: 0; batch classifier loss: 0.340939; batch adversarial loss: 0.528068\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276140; batch adversarial loss: 0.532243\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245574; batch adversarial loss: 0.537933\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255543; batch adversarial loss: 0.504822\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321588; batch adversarial loss: 0.499248\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406021; batch adversarial loss: 0.520834\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494377; batch adversarial loss: 0.541060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423594; batch adversarial loss: 0.490404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575422; batch adversarial loss: 0.543818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569959; batch adversarial loss: 0.495918\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392829; batch adversarial loss: 0.525915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295877; batch adversarial loss: 0.424789\n",
      "epoch 19; iter: 0; batch classifier loss: 0.304273; batch adversarial loss: 0.467607\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207673; batch adversarial loss: 0.478037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186414; batch adversarial loss: 0.486197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237515; batch adversarial loss: 0.394257\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163124; batch adversarial loss: 0.523518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.199746; batch adversarial loss: 0.417776\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179351; batch adversarial loss: 0.479178\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228783; batch adversarial loss: 0.433969\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191148; batch adversarial loss: 0.359909\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156949; batch adversarial loss: 0.488151\n",
      "epoch 29; iter: 0; batch classifier loss: 0.211986; batch adversarial loss: 0.408399\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173481; batch adversarial loss: 0.452244\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158431; batch adversarial loss: 0.467648\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171097; batch adversarial loss: 0.320869\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143189; batch adversarial loss: 0.525146\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080337; batch adversarial loss: 0.407521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134761; batch adversarial loss: 0.444871\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117555; batch adversarial loss: 0.491776\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120521; batch adversarial loss: 0.392985\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129245; batch adversarial loss: 0.391637\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131389; batch adversarial loss: 0.549586\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143264; batch adversarial loss: 0.429386\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115790; batch adversarial loss: 0.534236\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122757; batch adversarial loss: 0.460714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087495; batch adversarial loss: 0.469252\n",
      "epoch 44; iter: 0; batch classifier loss: 0.145537; batch adversarial loss: 0.434116\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097462; batch adversarial loss: 0.478235\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060362; batch adversarial loss: 0.475988\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095213; batch adversarial loss: 0.465817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077406; batch adversarial loss: 0.517579\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099195; batch adversarial loss: 0.437420\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109298; batch adversarial loss: 0.437972\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098217; batch adversarial loss: 0.369071\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123516; batch adversarial loss: 0.433297\n",
      "epoch 53; iter: 0; batch classifier loss: 0.140518; batch adversarial loss: 0.549759\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115463; batch adversarial loss: 0.411792\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.333201\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133486; batch adversarial loss: 0.455332\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074006; batch adversarial loss: 0.287750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098234; batch adversarial loss: 0.350591\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158476; batch adversarial loss: 0.426023\n",
      "epoch 60; iter: 0; batch classifier loss: 0.109320; batch adversarial loss: 0.355956\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073960; batch adversarial loss: 0.419895\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111802; batch adversarial loss: 0.453549\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093192; batch adversarial loss: 0.487150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137131; batch adversarial loss: 0.344957\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087403; batch adversarial loss: 0.398002\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102169; batch adversarial loss: 0.454128\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060609; batch adversarial loss: 0.435148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091137; batch adversarial loss: 0.449481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145991; batch adversarial loss: 0.447524\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078571; batch adversarial loss: 0.439647\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066724; batch adversarial loss: 0.502569\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069202; batch adversarial loss: 0.486475\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104199; batch adversarial loss: 0.394870\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054726; batch adversarial loss: 0.461957\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144205; batch adversarial loss: 0.469416\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085185; batch adversarial loss: 0.490147\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121563; batch adversarial loss: 0.390115\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103726; batch adversarial loss: 0.518564\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055469; batch adversarial loss: 0.402178\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047612; batch adversarial loss: 0.348598\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083287; batch adversarial loss: 0.439761\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050097; batch adversarial loss: 0.469589\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080895; batch adversarial loss: 0.342949\n",
      "epoch 84; iter: 0; batch classifier loss: 0.083919; batch adversarial loss: 0.427796\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088925; batch adversarial loss: 0.490641\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084650; batch adversarial loss: 0.509595\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059846; batch adversarial loss: 0.464375\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051433; batch adversarial loss: 0.479960\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052088; batch adversarial loss: 0.443186\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038296; batch adversarial loss: 0.470516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064408; batch adversarial loss: 0.493875\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051344; batch adversarial loss: 0.457421\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096139; batch adversarial loss: 0.449161\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.455526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097658; batch adversarial loss: 0.434319\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103929; batch adversarial loss: 0.451988\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069248; batch adversarial loss: 0.391234\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040715; batch adversarial loss: 0.535704\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058176; batch adversarial loss: 0.470772\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046229; batch adversarial loss: 0.485750\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067499; batch adversarial loss: 0.538281\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063439; batch adversarial loss: 0.447411\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065695; batch adversarial loss: 0.478582\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043314; batch adversarial loss: 0.379670\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052444; batch adversarial loss: 0.460270\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071654; batch adversarial loss: 0.421605\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053254; batch adversarial loss: 0.448408\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039605; batch adversarial loss: 0.377566\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063227; batch adversarial loss: 0.441377\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043251; batch adversarial loss: 0.385406\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042429; batch adversarial loss: 0.441399\n",
      "epoch 112; iter: 0; batch classifier loss: 0.013830; batch adversarial loss: 0.430954\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039809; batch adversarial loss: 0.486371\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069557; batch adversarial loss: 0.475718\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031012; batch adversarial loss: 0.388739\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019313; batch adversarial loss: 0.345433\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028281; batch adversarial loss: 0.503155\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045104; batch adversarial loss: 0.427788\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023952; batch adversarial loss: 0.429729\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.509945\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050146; batch adversarial loss: 0.464862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.036469; batch adversarial loss: 0.485607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035987; batch adversarial loss: 0.491457\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050364; batch adversarial loss: 0.398328\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072555; batch adversarial loss: 0.415150\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027461; batch adversarial loss: 0.519789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031821; batch adversarial loss: 0.414989\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029015; batch adversarial loss: 0.527261\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031597; batch adversarial loss: 0.451390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025193; batch adversarial loss: 0.391362\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040638; batch adversarial loss: 0.459424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.491014\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026113; batch adversarial loss: 0.403480\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018772; batch adversarial loss: 0.350725\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045621; batch adversarial loss: 0.374171\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016821; batch adversarial loss: 0.410693\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024872; batch adversarial loss: 0.447057\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.398609\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018819; batch adversarial loss: 0.430511\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017314; batch adversarial loss: 0.408109\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029091; batch adversarial loss: 0.319579\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019796; batch adversarial loss: 0.398687\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049398; batch adversarial loss: 0.415940\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017174; batch adversarial loss: 0.469140\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034577; batch adversarial loss: 0.477360\n",
      "epoch 146; iter: 0; batch classifier loss: 0.057297; batch adversarial loss: 0.375691\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015736; batch adversarial loss: 0.380024\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027493; batch adversarial loss: 0.408353\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016908; batch adversarial loss: 0.443323\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037061; batch adversarial loss: 0.407219\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041864; batch adversarial loss: 0.455406\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019546; batch adversarial loss: 0.346063\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010259; batch adversarial loss: 0.412160\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024041; batch adversarial loss: 0.438312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.430852\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022948; batch adversarial loss: 0.366676\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024697; batch adversarial loss: 0.579706\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015738; batch adversarial loss: 0.482617\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017702; batch adversarial loss: 0.414391\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041681; batch adversarial loss: 0.398148\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031595; batch adversarial loss: 0.378517\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011936; batch adversarial loss: 0.382737\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036835; batch adversarial loss: 0.450296\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040925; batch adversarial loss: 0.378302\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010778; batch adversarial loss: 0.411093\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014375; batch adversarial loss: 0.393554\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008939; batch adversarial loss: 0.424897\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019182; batch adversarial loss: 0.431058\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009186; batch adversarial loss: 0.495766\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013392; batch adversarial loss: 0.492577\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.502236\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.526003\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015104; batch adversarial loss: 0.387665\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050832; batch adversarial loss: 0.409726\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041201; batch adversarial loss: 0.416432\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.398652\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036716; batch adversarial loss: 0.402045\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.459903\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028362; batch adversarial loss: 0.445673\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015260; batch adversarial loss: 0.396398\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015797; batch adversarial loss: 0.469518\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039838; batch adversarial loss: 0.380259\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027758; batch adversarial loss: 0.414267\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018513; batch adversarial loss: 0.432389\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016515; batch adversarial loss: 0.492624\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036369; batch adversarial loss: 0.326216\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036481; batch adversarial loss: 0.489394\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006068; batch adversarial loss: 0.424365\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.469497\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028476; batch adversarial loss: 0.426985\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021999; batch adversarial loss: 0.370657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037090; batch adversarial loss: 0.471986\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017699; batch adversarial loss: 0.516496\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017645; batch adversarial loss: 0.403878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010867; batch adversarial loss: 0.449763\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010675; batch adversarial loss: 0.410019\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011613; batch adversarial loss: 0.552802\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.457591\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009236; batch adversarial loss: 0.511930\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708033; batch adversarial loss: 0.768988\n",
      "epoch 1; iter: 0; batch classifier loss: 0.505231; batch adversarial loss: 0.720392\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571364; batch adversarial loss: 0.683341\n",
      "epoch 3; iter: 0; batch classifier loss: 0.482895; batch adversarial loss: 0.609816\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406835; batch adversarial loss: 0.607517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.329935; batch adversarial loss: 0.580514\n",
      "epoch 6; iter: 0; batch classifier loss: 0.431447; batch adversarial loss: 0.546861\n",
      "epoch 7; iter: 0; batch classifier loss: 0.346864; batch adversarial loss: 0.558083\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356297; batch adversarial loss: 0.562234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417871; batch adversarial loss: 0.530021\n",
      "epoch 10; iter: 0; batch classifier loss: 0.309780; batch adversarial loss: 0.557328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347661; batch adversarial loss: 0.494623\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337501; batch adversarial loss: 0.533836\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343589; batch adversarial loss: 0.481344\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369015; batch adversarial loss: 0.491944\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331067; batch adversarial loss: 0.441227\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330322; batch adversarial loss: 0.488984\n",
      "epoch 17; iter: 0; batch classifier loss: 0.378182; batch adversarial loss: 0.440589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.411102; batch adversarial loss: 0.450402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286533; batch adversarial loss: 0.447973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333365; batch adversarial loss: 0.500484\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271427; batch adversarial loss: 0.420508\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331716; batch adversarial loss: 0.458675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310937; batch adversarial loss: 0.469775\n",
      "epoch 24; iter: 0; batch classifier loss: 0.321220; batch adversarial loss: 0.551375\n",
      "epoch 25; iter: 0; batch classifier loss: 0.391874; batch adversarial loss: 0.424419\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296397; batch adversarial loss: 0.448565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.306447; batch adversarial loss: 0.493851\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229918; batch adversarial loss: 0.448461\n",
      "epoch 29; iter: 0; batch classifier loss: 0.273007; batch adversarial loss: 0.501043\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271464; batch adversarial loss: 0.418291\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276449; batch adversarial loss: 0.449366\n",
      "epoch 32; iter: 0; batch classifier loss: 0.277641; batch adversarial loss: 0.418965\n",
      "epoch 33; iter: 0; batch classifier loss: 0.246905; batch adversarial loss: 0.445573\n",
      "epoch 34; iter: 0; batch classifier loss: 0.298961; batch adversarial loss: 0.422249\n",
      "epoch 35; iter: 0; batch classifier loss: 0.284125; batch adversarial loss: 0.425869\n",
      "epoch 36; iter: 0; batch classifier loss: 0.325019; batch adversarial loss: 0.496747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.307976; batch adversarial loss: 0.351016\n",
      "epoch 38; iter: 0; batch classifier loss: 0.170809; batch adversarial loss: 0.493825\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221222; batch adversarial loss: 0.420063\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240264; batch adversarial loss: 0.439988\n",
      "epoch 41; iter: 0; batch classifier loss: 0.244565; batch adversarial loss: 0.430629\n",
      "epoch 42; iter: 0; batch classifier loss: 0.310569; batch adversarial loss: 0.477085\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219824; batch adversarial loss: 0.629583\n",
      "epoch 44; iter: 0; batch classifier loss: 0.243603; batch adversarial loss: 0.408175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.226480; batch adversarial loss: 0.447711\n",
      "epoch 46; iter: 0; batch classifier loss: 0.219934; batch adversarial loss: 0.502931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.268097; batch adversarial loss: 0.472812\n",
      "epoch 48; iter: 0; batch classifier loss: 0.279921; batch adversarial loss: 0.495979\n",
      "epoch 49; iter: 0; batch classifier loss: 0.257337; batch adversarial loss: 0.367237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.336269; batch adversarial loss: 0.427667\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231875; batch adversarial loss: 0.552685\n",
      "epoch 52; iter: 0; batch classifier loss: 0.264077; batch adversarial loss: 0.448923\n",
      "epoch 53; iter: 0; batch classifier loss: 0.288013; batch adversarial loss: 0.536779\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268860; batch adversarial loss: 0.401113\n",
      "epoch 55; iter: 0; batch classifier loss: 0.279775; batch adversarial loss: 0.556888\n",
      "epoch 56; iter: 0; batch classifier loss: 0.233077; batch adversarial loss: 0.469320\n",
      "epoch 57; iter: 0; batch classifier loss: 0.267493; batch adversarial loss: 0.445911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.269676; batch adversarial loss: 0.446281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.274154; batch adversarial loss: 0.373318\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112820; batch adversarial loss: 0.384885\n",
      "epoch 61; iter: 0; batch classifier loss: 0.116484; batch adversarial loss: 0.469907\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097932; batch adversarial loss: 0.420533\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137380; batch adversarial loss: 0.468919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.119413; batch adversarial loss: 0.439595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083370; batch adversarial loss: 0.414837\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118948; batch adversarial loss: 0.428481\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107860; batch adversarial loss: 0.458618\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197200; batch adversarial loss: 0.460200\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217509; batch adversarial loss: 0.505966\n",
      "epoch 70; iter: 0; batch classifier loss: 0.262259; batch adversarial loss: 0.468831\n",
      "epoch 71; iter: 0; batch classifier loss: 0.204662; batch adversarial loss: 0.494538\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176935; batch adversarial loss: 0.503923\n",
      "epoch 73; iter: 0; batch classifier loss: 0.225296; batch adversarial loss: 0.441203\n",
      "epoch 74; iter: 0; batch classifier loss: 0.163224; batch adversarial loss: 0.459063\n",
      "epoch 75; iter: 0; batch classifier loss: 0.211803; batch adversarial loss: 0.482801\n",
      "epoch 76; iter: 0; batch classifier loss: 0.121495; batch adversarial loss: 0.472989\n",
      "epoch 77; iter: 0; batch classifier loss: 0.196282; batch adversarial loss: 0.471023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211806; batch adversarial loss: 0.459125\n",
      "epoch 79; iter: 0; batch classifier loss: 0.219898; batch adversarial loss: 0.428001\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179988; batch adversarial loss: 0.391530\n",
      "epoch 81; iter: 0; batch classifier loss: 0.147041; batch adversarial loss: 0.433748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185548; batch adversarial loss: 0.485153\n",
      "epoch 83; iter: 0; batch classifier loss: 0.208331; batch adversarial loss: 0.459732\n",
      "epoch 84; iter: 0; batch classifier loss: 0.180287; batch adversarial loss: 0.516232\n",
      "epoch 85; iter: 0; batch classifier loss: 0.196511; batch adversarial loss: 0.356562\n",
      "epoch 86; iter: 0; batch classifier loss: 0.160368; batch adversarial loss: 0.406874\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101482; batch adversarial loss: 0.561072\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197336; batch adversarial loss: 0.529929\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093583; batch adversarial loss: 0.512954\n",
      "epoch 90; iter: 0; batch classifier loss: 0.100149; batch adversarial loss: 0.482591\n",
      "epoch 91; iter: 0; batch classifier loss: 0.120329; batch adversarial loss: 0.419441\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103461; batch adversarial loss: 0.439697\n",
      "epoch 93; iter: 0; batch classifier loss: 0.124163; batch adversarial loss: 0.492235\n",
      "epoch 94; iter: 0; batch classifier loss: 0.130572; batch adversarial loss: 0.374941\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048989; batch adversarial loss: 0.455548\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061250; batch adversarial loss: 0.417913\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047042; batch adversarial loss: 0.498671\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049401; batch adversarial loss: 0.417694\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067124; batch adversarial loss: 0.450534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040845; batch adversarial loss: 0.439483\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040305; batch adversarial loss: 0.538989\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056614; batch adversarial loss: 0.406597\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026657; batch adversarial loss: 0.446401\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063772; batch adversarial loss: 0.460555\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057790; batch adversarial loss: 0.398132\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055159; batch adversarial loss: 0.461741\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031830; batch adversarial loss: 0.461693\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038283; batch adversarial loss: 0.427652\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.516847\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062453; batch adversarial loss: 0.497738\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031708; batch adversarial loss: 0.495621\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075233; batch adversarial loss: 0.456535\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087090; batch adversarial loss: 0.457379\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034525; batch adversarial loss: 0.373306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025982; batch adversarial loss: 0.423344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.009647; batch adversarial loss: 0.392742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067139; batch adversarial loss: 0.415777\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050171; batch adversarial loss: 0.447594\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.421532\n",
      "epoch 120; iter: 0; batch classifier loss: 0.096337; batch adversarial loss: 0.365602\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057067; batch adversarial loss: 0.324080\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050656; batch adversarial loss: 0.480266\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014660; batch adversarial loss: 0.462497\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041750; batch adversarial loss: 0.408374\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041535; batch adversarial loss: 0.439693\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039732; batch adversarial loss: 0.436994\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037615; batch adversarial loss: 0.470887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036725; batch adversarial loss: 0.453776\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035583; batch adversarial loss: 0.340026\n",
      "epoch 130; iter: 0; batch classifier loss: 0.012703; batch adversarial loss: 0.435922\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035028; batch adversarial loss: 0.357725\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020902; batch adversarial loss: 0.437719\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046187; batch adversarial loss: 0.531610\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.452433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017132; batch adversarial loss: 0.504116\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070283; batch adversarial loss: 0.465741\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045550; batch adversarial loss: 0.407773\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030824; batch adversarial loss: 0.544738\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011724; batch adversarial loss: 0.416532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027243; batch adversarial loss: 0.418132\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029430; batch adversarial loss: 0.422883\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023897; batch adversarial loss: 0.455135\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023259; batch adversarial loss: 0.455252\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045208; batch adversarial loss: 0.575242\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015358; batch adversarial loss: 0.478255\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017106; batch adversarial loss: 0.460111\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037669; batch adversarial loss: 0.501360\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023776; batch adversarial loss: 0.466345\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035339; batch adversarial loss: 0.484882\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027942; batch adversarial loss: 0.476615\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010538; batch adversarial loss: 0.414654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014605; batch adversarial loss: 0.403447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018672; batch adversarial loss: 0.462227\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019282; batch adversarial loss: 0.419541\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053605; batch adversarial loss: 0.496907\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019496; batch adversarial loss: 0.355287\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030497; batch adversarial loss: 0.533059\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017342; batch adversarial loss: 0.406255\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031267; batch adversarial loss: 0.517520\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008566; batch adversarial loss: 0.504982\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013251; batch adversarial loss: 0.399676\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019724; batch adversarial loss: 0.471206\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017939; batch adversarial loss: 0.473809\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026012; batch adversarial loss: 0.503993\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010820; batch adversarial loss: 0.496890\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026708; batch adversarial loss: 0.395680\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015091; batch adversarial loss: 0.469755\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011670; batch adversarial loss: 0.489998\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004090; batch adversarial loss: 0.504963\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026250; batch adversarial loss: 0.371240\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023070; batch adversarial loss: 0.467310\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022098; batch adversarial loss: 0.387586\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019801; batch adversarial loss: 0.472267\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025468; batch adversarial loss: 0.457190\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005789; batch adversarial loss: 0.506678\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.398526\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012737; batch adversarial loss: 0.392474\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030667; batch adversarial loss: 0.431187\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009608; batch adversarial loss: 0.494872\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.408333\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018425; batch adversarial loss: 0.471927\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016750; batch adversarial loss: 0.437074\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.392380\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010176; batch adversarial loss: 0.456019\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008796; batch adversarial loss: 0.452952\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017377; batch adversarial loss: 0.478790\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013478; batch adversarial loss: 0.494553\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015221; batch adversarial loss: 0.511024\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012006; batch adversarial loss: 0.536206\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005924; batch adversarial loss: 0.443746\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011876; batch adversarial loss: 0.445019\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006624; batch adversarial loss: 0.338631\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005163; batch adversarial loss: 0.414436\n",
      "epoch 194; iter: 0; batch classifier loss: 0.001907; batch adversarial loss: 0.472794\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015187; batch adversarial loss: 0.395724\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019222; batch adversarial loss: 0.365617\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015758; batch adversarial loss: 0.521308\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012694; batch adversarial loss: 0.502248\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015593; batch adversarial loss: 0.382763\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730874; batch adversarial loss: 0.572431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.359170; batch adversarial loss: 0.621985\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413428; batch adversarial loss: 0.575349\n",
      "epoch 3; iter: 0; batch classifier loss: 0.443470; batch adversarial loss: 0.581063\n",
      "epoch 4; iter: 0; batch classifier loss: 0.332017; batch adversarial loss: 0.576723\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280529; batch adversarial loss: 0.538082\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321278; batch adversarial loss: 0.528366\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295681; batch adversarial loss: 0.534167\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325140; batch adversarial loss: 0.561519\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318471; batch adversarial loss: 0.535946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.365661; batch adversarial loss: 0.511238\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486937; batch adversarial loss: 0.592834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.555454; batch adversarial loss: 0.555229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573070; batch adversarial loss: 0.518679\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563047; batch adversarial loss: 0.463326\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381065; batch adversarial loss: 0.516716\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312811; batch adversarial loss: 0.534766\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273283; batch adversarial loss: 0.427164\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331216; batch adversarial loss: 0.458687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.196428; batch adversarial loss: 0.423862\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257225; batch adversarial loss: 0.392794\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246881; batch adversarial loss: 0.443388\n",
      "epoch 22; iter: 0; batch classifier loss: 0.202758; batch adversarial loss: 0.467947\n",
      "epoch 23; iter: 0; batch classifier loss: 0.237209; batch adversarial loss: 0.489012\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240753; batch adversarial loss: 0.450676\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231793; batch adversarial loss: 0.441431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193223; batch adversarial loss: 0.466867\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241333; batch adversarial loss: 0.448073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218896; batch adversarial loss: 0.405371\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196645; batch adversarial loss: 0.472230\n",
      "epoch 30; iter: 0; batch classifier loss: 0.183522; batch adversarial loss: 0.453122\n",
      "epoch 31; iter: 0; batch classifier loss: 0.271748; batch adversarial loss: 0.534448\n",
      "epoch 32; iter: 0; batch classifier loss: 0.232182; batch adversarial loss: 0.464923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221544; batch adversarial loss: 0.427947\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169861; batch adversarial loss: 0.498282\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205176; batch adversarial loss: 0.429340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.233694; batch adversarial loss: 0.464402\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216422; batch adversarial loss: 0.441704\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179054; batch adversarial loss: 0.560748\n",
      "epoch 39; iter: 0; batch classifier loss: 0.228525; batch adversarial loss: 0.422810\n",
      "epoch 40; iter: 0; batch classifier loss: 0.304186; batch adversarial loss: 0.450805\n",
      "epoch 41; iter: 0; batch classifier loss: 0.198553; batch adversarial loss: 0.446521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235292; batch adversarial loss: 0.433472\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219947; batch adversarial loss: 0.439993\n",
      "epoch 44; iter: 0; batch classifier loss: 0.277137; batch adversarial loss: 0.378122\n",
      "epoch 45; iter: 0; batch classifier loss: 0.238395; batch adversarial loss: 0.549356\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206747; batch adversarial loss: 0.454055\n",
      "epoch 47; iter: 0; batch classifier loss: 0.243332; batch adversarial loss: 0.445246\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209498; batch adversarial loss: 0.439585\n",
      "epoch 49; iter: 0; batch classifier loss: 0.239317; batch adversarial loss: 0.483775\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226706; batch adversarial loss: 0.439397\n",
      "epoch 51; iter: 0; batch classifier loss: 0.237234; batch adversarial loss: 0.444176\n",
      "epoch 52; iter: 0; batch classifier loss: 0.208731; batch adversarial loss: 0.533694\n",
      "epoch 53; iter: 0; batch classifier loss: 0.279673; batch adversarial loss: 0.454620\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268750; batch adversarial loss: 0.414081\n",
      "epoch 55; iter: 0; batch classifier loss: 0.236913; batch adversarial loss: 0.436621\n",
      "epoch 56; iter: 0; batch classifier loss: 0.224971; batch adversarial loss: 0.484715\n",
      "epoch 57; iter: 0; batch classifier loss: 0.204965; batch adversarial loss: 0.407512\n",
      "epoch 58; iter: 0; batch classifier loss: 0.220180; batch adversarial loss: 0.496575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.214558; batch adversarial loss: 0.500714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.286362; batch adversarial loss: 0.448874\n",
      "epoch 61; iter: 0; batch classifier loss: 0.276828; batch adversarial loss: 0.423397\n",
      "epoch 62; iter: 0; batch classifier loss: 0.227605; batch adversarial loss: 0.495058\n",
      "epoch 63; iter: 0; batch classifier loss: 0.303675; batch adversarial loss: 0.410646\n",
      "epoch 64; iter: 0; batch classifier loss: 0.276137; batch adversarial loss: 0.482115\n",
      "epoch 65; iter: 0; batch classifier loss: 0.349348; batch adversarial loss: 0.386643\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097135; batch adversarial loss: 0.409977\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100073; batch adversarial loss: 0.400717\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103932; batch adversarial loss: 0.508007\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075439; batch adversarial loss: 0.442927\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072189; batch adversarial loss: 0.590927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071730; batch adversarial loss: 0.435770\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045789; batch adversarial loss: 0.454603\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094297; batch adversarial loss: 0.477680\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080372; batch adversarial loss: 0.377810\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077711; batch adversarial loss: 0.468678\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059744; batch adversarial loss: 0.412355\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074121; batch adversarial loss: 0.508451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137259; batch adversarial loss: 0.459071\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081405; batch adversarial loss: 0.532838\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123901; batch adversarial loss: 0.458526\n",
      "epoch 81; iter: 0; batch classifier loss: 0.154122; batch adversarial loss: 0.442173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095550; batch adversarial loss: 0.562839\n",
      "epoch 83; iter: 0; batch classifier loss: 0.120255; batch adversarial loss: 0.377646\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089668; batch adversarial loss: 0.474741\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142205; batch adversarial loss: 0.491713\n",
      "epoch 86; iter: 0; batch classifier loss: 0.086129; batch adversarial loss: 0.491835\n",
      "epoch 87; iter: 0; batch classifier loss: 0.130641; batch adversarial loss: 0.375401\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067777; batch adversarial loss: 0.448833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091553; batch adversarial loss: 0.449535\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094900; batch adversarial loss: 0.418223\n",
      "epoch 91; iter: 0; batch classifier loss: 0.080188; batch adversarial loss: 0.368716\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033674; batch adversarial loss: 0.397697\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095369; batch adversarial loss: 0.477961\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028186; batch adversarial loss: 0.500064\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057957; batch adversarial loss: 0.499947\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066312; batch adversarial loss: 0.537324\n",
      "epoch 97; iter: 0; batch classifier loss: 0.121330; batch adversarial loss: 0.433650\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100326; batch adversarial loss: 0.486738\n",
      "epoch 99; iter: 0; batch classifier loss: 0.109667; batch adversarial loss: 0.476261\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070515; batch adversarial loss: 0.420469\n",
      "epoch 101; iter: 0; batch classifier loss: 0.086754; batch adversarial loss: 0.446037\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044966; batch adversarial loss: 0.518968\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062478; batch adversarial loss: 0.500906\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067283; batch adversarial loss: 0.463043\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056603; batch adversarial loss: 0.623711\n",
      "epoch 106; iter: 0; batch classifier loss: 0.080935; batch adversarial loss: 0.456274\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075877; batch adversarial loss: 0.472168\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075316; batch adversarial loss: 0.435594\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084435; batch adversarial loss: 0.359486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.082051; batch adversarial loss: 0.398282\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069510; batch adversarial loss: 0.390083\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044825; batch adversarial loss: 0.441056\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047813; batch adversarial loss: 0.384837\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056647; batch adversarial loss: 0.466403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.093714; batch adversarial loss: 0.441817\n",
      "epoch 116; iter: 0; batch classifier loss: 0.094603; batch adversarial loss: 0.468465\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.473174\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053032; batch adversarial loss: 0.442001\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055478; batch adversarial loss: 0.418106\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051318; batch adversarial loss: 0.502239\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094189; batch adversarial loss: 0.474473\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041079; batch adversarial loss: 0.572521\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059547; batch adversarial loss: 0.357830\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061486; batch adversarial loss: 0.430086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051470; batch adversarial loss: 0.355376\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022663; batch adversarial loss: 0.585813\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031294; batch adversarial loss: 0.545619\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039272; batch adversarial loss: 0.487990\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063247; batch adversarial loss: 0.454898\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020170; batch adversarial loss: 0.490165\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051106; batch adversarial loss: 0.474554\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025487; batch adversarial loss: 0.450818\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030344; batch adversarial loss: 0.538080\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031283; batch adversarial loss: 0.427059\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057417; batch adversarial loss: 0.457364\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024505; batch adversarial loss: 0.398295\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060092; batch adversarial loss: 0.460825\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059299; batch adversarial loss: 0.377533\n",
      "epoch 139; iter: 0; batch classifier loss: 0.059183; batch adversarial loss: 0.463723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.071502; batch adversarial loss: 0.420791\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.403965\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017982; batch adversarial loss: 0.425030\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010256; batch adversarial loss: 0.409348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038203; batch adversarial loss: 0.447546\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018008; batch adversarial loss: 0.452757\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.509059\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017338; batch adversarial loss: 0.429948\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038901; batch adversarial loss: 0.481897\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040824; batch adversarial loss: 0.354575\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036943; batch adversarial loss: 0.389154\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036906; batch adversarial loss: 0.494983\n",
      "epoch 152; iter: 0; batch classifier loss: 0.055357; batch adversarial loss: 0.513721\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016226; batch adversarial loss: 0.464796\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021022; batch adversarial loss: 0.495221\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022818; batch adversarial loss: 0.436359\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043950; batch adversarial loss: 0.392109\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041136; batch adversarial loss: 0.494638\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034679; batch adversarial loss: 0.461470\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030108; batch adversarial loss: 0.463107\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023948; batch adversarial loss: 0.413397\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014931; batch adversarial loss: 0.470666\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036697; batch adversarial loss: 0.447309\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.479128\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015994; batch adversarial loss: 0.436339\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008045; batch adversarial loss: 0.494430\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030226; batch adversarial loss: 0.442491\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.404950\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023173; batch adversarial loss: 0.394713\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.426320\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025858; batch adversarial loss: 0.433324\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011095; batch adversarial loss: 0.453702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025663; batch adversarial loss: 0.427093\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028415; batch adversarial loss: 0.533093\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039334; batch adversarial loss: 0.490424\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021419; batch adversarial loss: 0.452703\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027597; batch adversarial loss: 0.510085\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035653; batch adversarial loss: 0.381565\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013587; batch adversarial loss: 0.421781\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009546; batch adversarial loss: 0.446279\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026364; batch adversarial loss: 0.526878\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.415000\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010543; batch adversarial loss: 0.520021\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042426; batch adversarial loss: 0.473625\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025908; batch adversarial loss: 0.383433\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041805; batch adversarial loss: 0.370177\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018418; batch adversarial loss: 0.384944\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018906; batch adversarial loss: 0.455245\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016685; batch adversarial loss: 0.372008\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022924; batch adversarial loss: 0.440110\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009215; batch adversarial loss: 0.418729\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011406; batch adversarial loss: 0.379577\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012020; batch adversarial loss: 0.530021\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007332; batch adversarial loss: 0.480944\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011320; batch adversarial loss: 0.476685\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013704; batch adversarial loss: 0.462855\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006776; batch adversarial loss: 0.537221\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020180; batch adversarial loss: 0.455035\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012565; batch adversarial loss: 0.412953\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021357; batch adversarial loss: 0.442284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715276; batch adversarial loss: 0.892632\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576558; batch adversarial loss: 0.976635\n",
      "epoch 2; iter: 0; batch classifier loss: 0.724502; batch adversarial loss: 0.983539\n",
      "epoch 3; iter: 0; batch classifier loss: 0.876478; batch adversarial loss: 0.904286\n",
      "epoch 4; iter: 0; batch classifier loss: 0.903001; batch adversarial loss: 0.823475\n",
      "epoch 5; iter: 0; batch classifier loss: 1.147605; batch adversarial loss: 0.753622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 1.087944; batch adversarial loss: 0.678219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.845535; batch adversarial loss: 0.644196\n",
      "epoch 8; iter: 0; batch classifier loss: 0.755002; batch adversarial loss: 0.578756\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433129; batch adversarial loss: 0.578564\n",
      "epoch 10; iter: 0; batch classifier loss: 0.399411; batch adversarial loss: 0.544145\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358668; batch adversarial loss: 0.534267\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359688; batch adversarial loss: 0.491095\n",
      "epoch 13; iter: 0; batch classifier loss: 0.316423; batch adversarial loss: 0.509316\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349896; batch adversarial loss: 0.502846\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264825; batch adversarial loss: 0.551050\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363907; batch adversarial loss: 0.448309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.315319; batch adversarial loss: 0.471245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301416; batch adversarial loss: 0.530644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307476; batch adversarial loss: 0.516244\n",
      "epoch 20; iter: 0; batch classifier loss: 0.323267; batch adversarial loss: 0.467227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323401; batch adversarial loss: 0.507018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263281; batch adversarial loss: 0.496083\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184069; batch adversarial loss: 0.485844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.304175; batch adversarial loss: 0.469439\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303172; batch adversarial loss: 0.433606\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243435; batch adversarial loss: 0.489566\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243392; batch adversarial loss: 0.543034\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244489; batch adversarial loss: 0.471125\n",
      "epoch 29; iter: 0; batch classifier loss: 0.229962; batch adversarial loss: 0.516022\n",
      "epoch 30; iter: 0; batch classifier loss: 0.266545; batch adversarial loss: 0.454020\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283882; batch adversarial loss: 0.450489\n",
      "epoch 32; iter: 0; batch classifier loss: 0.285900; batch adversarial loss: 0.569556\n",
      "epoch 33; iter: 0; batch classifier loss: 0.245622; batch adversarial loss: 0.452176\n",
      "epoch 34; iter: 0; batch classifier loss: 0.322715; batch adversarial loss: 0.542401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168616; batch adversarial loss: 0.505721\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240409; batch adversarial loss: 0.525144\n",
      "epoch 37; iter: 0; batch classifier loss: 0.236722; batch adversarial loss: 0.491963\n",
      "epoch 38; iter: 0; batch classifier loss: 0.170670; batch adversarial loss: 0.392410\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207169; batch adversarial loss: 0.479350\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179118; batch adversarial loss: 0.533918\n",
      "epoch 41; iter: 0; batch classifier loss: 0.194145; batch adversarial loss: 0.563466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.215928; batch adversarial loss: 0.413870\n",
      "epoch 43; iter: 0; batch classifier loss: 0.178141; batch adversarial loss: 0.479754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235528; batch adversarial loss: 0.508647\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160140; batch adversarial loss: 0.505413\n",
      "epoch 46; iter: 0; batch classifier loss: 0.158778; batch adversarial loss: 0.401355\n",
      "epoch 47; iter: 0; batch classifier loss: 0.219155; batch adversarial loss: 0.411552\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120476; batch adversarial loss: 0.529088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.184613; batch adversarial loss: 0.365498\n",
      "epoch 50; iter: 0; batch classifier loss: 0.190672; batch adversarial loss: 0.459420\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154046; batch adversarial loss: 0.395706\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117273; batch adversarial loss: 0.395839\n",
      "epoch 53; iter: 0; batch classifier loss: 0.220727; batch adversarial loss: 0.504515\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155212; batch adversarial loss: 0.428492\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154606; batch adversarial loss: 0.467849\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185467; batch adversarial loss: 0.440785\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116052; batch adversarial loss: 0.644295\n",
      "epoch 58; iter: 0; batch classifier loss: 0.146882; batch adversarial loss: 0.446795\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126215; batch adversarial loss: 0.347166\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116818; batch adversarial loss: 0.409592\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063305; batch adversarial loss: 0.414881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.136684; batch adversarial loss: 0.459018\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077975; batch adversarial loss: 0.500480\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106106; batch adversarial loss: 0.575794\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132706; batch adversarial loss: 0.447652\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078643; batch adversarial loss: 0.500256\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118124; batch adversarial loss: 0.441154\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078867; batch adversarial loss: 0.425129\n",
      "epoch 69; iter: 0; batch classifier loss: 0.124108; batch adversarial loss: 0.412118\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081585; batch adversarial loss: 0.379073\n",
      "epoch 71; iter: 0; batch classifier loss: 0.131949; batch adversarial loss: 0.356743\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099962; batch adversarial loss: 0.379596\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168928; batch adversarial loss: 0.385495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088920; batch adversarial loss: 0.460166\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077743; batch adversarial loss: 0.485071\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093261; batch adversarial loss: 0.410624\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081211; batch adversarial loss: 0.444750\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073022; batch adversarial loss: 0.352271\n",
      "epoch 79; iter: 0; batch classifier loss: 0.129481; batch adversarial loss: 0.492709\n",
      "epoch 80; iter: 0; batch classifier loss: 0.042195; batch adversarial loss: 0.431045\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074964; batch adversarial loss: 0.433086\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074703; batch adversarial loss: 0.420780\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072893; batch adversarial loss: 0.434837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055321; batch adversarial loss: 0.417568\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083769; batch adversarial loss: 0.532846\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071816; batch adversarial loss: 0.476422\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054422; batch adversarial loss: 0.558201\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039673; batch adversarial loss: 0.497210\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052652; batch adversarial loss: 0.452830\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074891; batch adversarial loss: 0.480850\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038111; batch adversarial loss: 0.351679\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055950; batch adversarial loss: 0.494815\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037879; batch adversarial loss: 0.446595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046390; batch adversarial loss: 0.489763\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064001; batch adversarial loss: 0.557309\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070059; batch adversarial loss: 0.490396\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097011; batch adversarial loss: 0.425332\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033657; batch adversarial loss: 0.511146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036428; batch adversarial loss: 0.454205\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039743; batch adversarial loss: 0.426040\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030003; batch adversarial loss: 0.475968\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053516; batch adversarial loss: 0.519532\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052912; batch adversarial loss: 0.449174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.067679; batch adversarial loss: 0.562374\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034899; batch adversarial loss: 0.531417\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045306; batch adversarial loss: 0.453628\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029240; batch adversarial loss: 0.466016\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029670; batch adversarial loss: 0.478014\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045965; batch adversarial loss: 0.511019\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038927; batch adversarial loss: 0.457374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042488; batch adversarial loss: 0.444574\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052686; batch adversarial loss: 0.488116\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033631; batch adversarial loss: 0.488679\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029330; batch adversarial loss: 0.399994\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070771; batch adversarial loss: 0.445680\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035097; batch adversarial loss: 0.377179\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053310; batch adversarial loss: 0.501041\n",
      "epoch 118; iter: 0; batch classifier loss: 0.020553; batch adversarial loss: 0.456713\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016545; batch adversarial loss: 0.466128\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022126; batch adversarial loss: 0.438085\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044010; batch adversarial loss: 0.478928\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018270; batch adversarial loss: 0.500290\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020455; batch adversarial loss: 0.420732\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.499699\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022483; batch adversarial loss: 0.388596\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016480; batch adversarial loss: 0.436692\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024066; batch adversarial loss: 0.409883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030678; batch adversarial loss: 0.537159\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021041; batch adversarial loss: 0.436289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016059; batch adversarial loss: 0.488966\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.461466\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041676; batch adversarial loss: 0.467764\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035858; batch adversarial loss: 0.478551\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037965; batch adversarial loss: 0.491942\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028320; batch adversarial loss: 0.468709\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029706; batch adversarial loss: 0.509477\n",
      "epoch 137; iter: 0; batch classifier loss: 0.009998; batch adversarial loss: 0.516897\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034446; batch adversarial loss: 0.489939\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018368; batch adversarial loss: 0.543440\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023761; batch adversarial loss: 0.430501\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.476167\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022507; batch adversarial loss: 0.400381\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020854; batch adversarial loss: 0.452859\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031699; batch adversarial loss: 0.409853\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025148; batch adversarial loss: 0.397213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.370058\n",
      "epoch 147; iter: 0; batch classifier loss: 0.006655; batch adversarial loss: 0.464090\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022852; batch adversarial loss: 0.568905\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040411; batch adversarial loss: 0.415576\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036403; batch adversarial loss: 0.442914\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020435; batch adversarial loss: 0.491855\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011410; batch adversarial loss: 0.443945\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031083; batch adversarial loss: 0.466197\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010362; batch adversarial loss: 0.397328\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021731; batch adversarial loss: 0.491718\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023719; batch adversarial loss: 0.395365\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035803; batch adversarial loss: 0.363860\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024701; batch adversarial loss: 0.406042\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023137; batch adversarial loss: 0.424983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009525; batch adversarial loss: 0.399831\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019393; batch adversarial loss: 0.448321\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006963; batch adversarial loss: 0.347752\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012130; batch adversarial loss: 0.457234\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.447675\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011952; batch adversarial loss: 0.445599\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018586; batch adversarial loss: 0.483350\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005141; batch adversarial loss: 0.474656\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026482; batch adversarial loss: 0.543399\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015387; batch adversarial loss: 0.441128\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011138; batch adversarial loss: 0.383023\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038470; batch adversarial loss: 0.450156\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019951; batch adversarial loss: 0.453435\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027108; batch adversarial loss: 0.430176\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.574482\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003076; batch adversarial loss: 0.429086\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020421; batch adversarial loss: 0.536426\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013690; batch adversarial loss: 0.401020\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026098; batch adversarial loss: 0.409557\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004814; batch adversarial loss: 0.482063\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016122; batch adversarial loss: 0.494765\n",
      "epoch 181; iter: 0; batch classifier loss: 0.002547; batch adversarial loss: 0.516802\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014417; batch adversarial loss: 0.529696\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.442798\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042923; batch adversarial loss: 0.403814\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036485; batch adversarial loss: 0.440415\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016449; batch adversarial loss: 0.368787\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005518; batch adversarial loss: 0.448205\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016472; batch adversarial loss: 0.373831\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006012; batch adversarial loss: 0.423908\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016264; batch adversarial loss: 0.426213\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008516; batch adversarial loss: 0.425562\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037916; batch adversarial loss: 0.468021\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023403; batch adversarial loss: 0.441315\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017573; batch adversarial loss: 0.444065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022251; batch adversarial loss: 0.400183\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028801; batch adversarial loss: 0.445874\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005610; batch adversarial loss: 0.392588\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036464; batch adversarial loss: 0.359544\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007699; batch adversarial loss: 0.491431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.704536; batch adversarial loss: 1.056379\n",
      "epoch 1; iter: 0; batch classifier loss: 0.761728; batch adversarial loss: 1.306170\n",
      "epoch 2; iter: 0; batch classifier loss: 0.983383; batch adversarial loss: 1.317925\n",
      "epoch 3; iter: 0; batch classifier loss: 1.078404; batch adversarial loss: 1.191673\n",
      "epoch 4; iter: 0; batch classifier loss: 1.129815; batch adversarial loss: 1.097683\n",
      "epoch 5; iter: 0; batch classifier loss: 1.198486; batch adversarial loss: 1.006263\n",
      "epoch 6; iter: 0; batch classifier loss: 1.274329; batch adversarial loss: 0.930896\n",
      "epoch 7; iter: 0; batch classifier loss: 1.310336; batch adversarial loss: 0.847856\n",
      "epoch 8; iter: 0; batch classifier loss: 1.027049; batch adversarial loss: 0.756998\n",
      "epoch 9; iter: 0; batch classifier loss: 0.984982; batch adversarial loss: 0.722344\n",
      "epoch 10; iter: 0; batch classifier loss: 0.893442; batch adversarial loss: 0.653029\n",
      "epoch 11; iter: 0; batch classifier loss: 0.901074; batch adversarial loss: 0.644860\n",
      "epoch 12; iter: 0; batch classifier loss: 0.652080; batch adversarial loss: 0.540397\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609165; batch adversarial loss: 0.527219\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463388; batch adversarial loss: 0.490263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.369302; batch adversarial loss: 0.520012\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322142; batch adversarial loss: 0.483566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.305387; batch adversarial loss: 0.469966\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281961; batch adversarial loss: 0.452402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257057; batch adversarial loss: 0.494739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.223282; batch adversarial loss: 0.495126\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235342; batch adversarial loss: 0.483768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245142; batch adversarial loss: 0.497041\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284453; batch adversarial loss: 0.393368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293661; batch adversarial loss: 0.476110\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232853; batch adversarial loss: 0.478681\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190353; batch adversarial loss: 0.498315\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227002; batch adversarial loss: 0.434119\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206300; batch adversarial loss: 0.447927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209356; batch adversarial loss: 0.438332\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297731; batch adversarial loss: 0.421959\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222679; batch adversarial loss: 0.380977\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230255; batch adversarial loss: 0.432090\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249675; batch adversarial loss: 0.461902\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247800; batch adversarial loss: 0.455247\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226762; batch adversarial loss: 0.456976\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165515; batch adversarial loss: 0.521813\n",
      "epoch 37; iter: 0; batch classifier loss: 0.236417; batch adversarial loss: 0.501203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230110; batch adversarial loss: 0.377117\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269546; batch adversarial loss: 0.459078\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261704; batch adversarial loss: 0.442181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.271318; batch adversarial loss: 0.458451\n",
      "epoch 42; iter: 0; batch classifier loss: 0.259551; batch adversarial loss: 0.507417\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204298; batch adversarial loss: 0.465858\n",
      "epoch 44; iter: 0; batch classifier loss: 0.219282; batch adversarial loss: 0.402537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.221344; batch adversarial loss: 0.516328\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223604; batch adversarial loss: 0.433473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.186204; batch adversarial loss: 0.435966\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218901; batch adversarial loss: 0.468854\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221254; batch adversarial loss: 0.409691\n",
      "epoch 50; iter: 0; batch classifier loss: 0.245649; batch adversarial loss: 0.582414\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238894; batch adversarial loss: 0.435318\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238077; batch adversarial loss: 0.367649\n",
      "epoch 53; iter: 0; batch classifier loss: 0.271762; batch adversarial loss: 0.377647\n",
      "epoch 54; iter: 0; batch classifier loss: 0.170203; batch adversarial loss: 0.570862\n",
      "epoch 55; iter: 0; batch classifier loss: 0.219374; batch adversarial loss: 0.511200\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142511; batch adversarial loss: 0.572658\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162398; batch adversarial loss: 0.445219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.206409; batch adversarial loss: 0.474584\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171003; batch adversarial loss: 0.398801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186934; batch adversarial loss: 0.366801\n",
      "epoch 61; iter: 0; batch classifier loss: 0.195805; batch adversarial loss: 0.474487\n",
      "epoch 62; iter: 0; batch classifier loss: 0.209533; batch adversarial loss: 0.390707\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195073; batch adversarial loss: 0.468465\n",
      "epoch 64; iter: 0; batch classifier loss: 0.180621; batch adversarial loss: 0.371420\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184712; batch adversarial loss: 0.404202\n",
      "epoch 66; iter: 0; batch classifier loss: 0.224851; batch adversarial loss: 0.417337\n",
      "epoch 67; iter: 0; batch classifier loss: 0.275405; batch adversarial loss: 0.398467\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167786; batch adversarial loss: 0.479921\n",
      "epoch 69; iter: 0; batch classifier loss: 0.187443; batch adversarial loss: 0.448848\n",
      "epoch 70; iter: 0; batch classifier loss: 0.203365; batch adversarial loss: 0.470690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194746; batch adversarial loss: 0.359906\n",
      "epoch 72; iter: 0; batch classifier loss: 0.172475; batch adversarial loss: 0.483829\n",
      "epoch 73; iter: 0; batch classifier loss: 0.107051; batch adversarial loss: 0.459316\n",
      "epoch 74; iter: 0; batch classifier loss: 0.175737; batch adversarial loss: 0.379514\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183588; batch adversarial loss: 0.393211\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161827; batch adversarial loss: 0.368354\n",
      "epoch 77; iter: 0; batch classifier loss: 0.161162; batch adversarial loss: 0.434878\n",
      "epoch 78; iter: 0; batch classifier loss: 0.257986; batch adversarial loss: 0.451791\n",
      "epoch 79; iter: 0; batch classifier loss: 0.187139; batch adversarial loss: 0.470710\n",
      "epoch 80; iter: 0; batch classifier loss: 0.193662; batch adversarial loss: 0.458002\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181118; batch adversarial loss: 0.531755\n",
      "epoch 82; iter: 0; batch classifier loss: 0.173399; batch adversarial loss: 0.471823\n",
      "epoch 83; iter: 0; batch classifier loss: 0.186761; batch adversarial loss: 0.496076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.178556; batch adversarial loss: 0.367622\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170231; batch adversarial loss: 0.492186\n",
      "epoch 86; iter: 0; batch classifier loss: 0.167514; batch adversarial loss: 0.397328\n",
      "epoch 87; iter: 0; batch classifier loss: 0.175768; batch adversarial loss: 0.523479\n",
      "epoch 88; iter: 0; batch classifier loss: 0.193819; batch adversarial loss: 0.446485\n",
      "epoch 89; iter: 0; batch classifier loss: 0.250102; batch adversarial loss: 0.354192\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119896; batch adversarial loss: 0.448658\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193182; batch adversarial loss: 0.459958\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181952; batch adversarial loss: 0.499434\n",
      "epoch 93; iter: 0; batch classifier loss: 0.226412; batch adversarial loss: 0.367832\n",
      "epoch 94; iter: 0; batch classifier loss: 0.176982; batch adversarial loss: 0.467225\n",
      "epoch 95; iter: 0; batch classifier loss: 0.162893; batch adversarial loss: 0.422394\n",
      "epoch 96; iter: 0; batch classifier loss: 0.165084; batch adversarial loss: 0.395510\n",
      "epoch 97; iter: 0; batch classifier loss: 0.172775; batch adversarial loss: 0.419012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.142114; batch adversarial loss: 0.368648\n",
      "epoch 99; iter: 0; batch classifier loss: 0.209119; batch adversarial loss: 0.357439\n",
      "epoch 100; iter: 0; batch classifier loss: 0.221696; batch adversarial loss: 0.393779\n",
      "epoch 101; iter: 0; batch classifier loss: 0.199927; batch adversarial loss: 0.494774\n",
      "epoch 102; iter: 0; batch classifier loss: 0.215047; batch adversarial loss: 0.432688\n",
      "epoch 103; iter: 0; batch classifier loss: 0.146851; batch adversarial loss: 0.433313\n",
      "epoch 104; iter: 0; batch classifier loss: 0.159426; batch adversarial loss: 0.396265\n",
      "epoch 105; iter: 0; batch classifier loss: 0.130360; batch adversarial loss: 0.460819\n",
      "epoch 106; iter: 0; batch classifier loss: 0.276036; batch adversarial loss: 0.548773\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172214; batch adversarial loss: 0.471142\n",
      "epoch 108; iter: 0; batch classifier loss: 0.193278; batch adversarial loss: 0.445648\n",
      "epoch 109; iter: 0; batch classifier loss: 0.105727; batch adversarial loss: 0.524454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.153209; batch adversarial loss: 0.472394\n",
      "epoch 111; iter: 0; batch classifier loss: 0.213137; batch adversarial loss: 0.408292\n",
      "epoch 112; iter: 0; batch classifier loss: 0.192728; batch adversarial loss: 0.420267\n",
      "epoch 113; iter: 0; batch classifier loss: 0.222147; batch adversarial loss: 0.484134\n",
      "epoch 114; iter: 0; batch classifier loss: 0.235572; batch adversarial loss: 0.421406\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168781; batch adversarial loss: 0.446329\n",
      "epoch 116; iter: 0; batch classifier loss: 0.194210; batch adversarial loss: 0.420318\n",
      "epoch 117; iter: 0; batch classifier loss: 0.171471; batch adversarial loss: 0.511752\n",
      "epoch 118; iter: 0; batch classifier loss: 0.109223; batch adversarial loss: 0.331814\n",
      "epoch 119; iter: 0; batch classifier loss: 0.168605; batch adversarial loss: 0.357240\n",
      "epoch 120; iter: 0; batch classifier loss: 0.148502; batch adversarial loss: 0.459971\n",
      "epoch 121; iter: 0; batch classifier loss: 0.189718; batch adversarial loss: 0.421309\n",
      "epoch 122; iter: 0; batch classifier loss: 0.151142; batch adversarial loss: 0.586382\n",
      "epoch 123; iter: 0; batch classifier loss: 0.253746; batch adversarial loss: 0.497615\n",
      "epoch 124; iter: 0; batch classifier loss: 0.213793; batch adversarial loss: 0.407917\n",
      "epoch 125; iter: 0; batch classifier loss: 0.216160; batch adversarial loss: 0.317990\n",
      "epoch 126; iter: 0; batch classifier loss: 0.249639; batch adversarial loss: 0.408575\n",
      "epoch 127; iter: 0; batch classifier loss: 0.202747; batch adversarial loss: 0.395284\n",
      "epoch 128; iter: 0; batch classifier loss: 0.140864; batch adversarial loss: 0.459154\n",
      "epoch 129; iter: 0; batch classifier loss: 0.143160; batch adversarial loss: 0.343484\n",
      "epoch 130; iter: 0; batch classifier loss: 0.162019; batch adversarial loss: 0.394427\n",
      "epoch 131; iter: 0; batch classifier loss: 0.115542; batch adversarial loss: 0.420638\n",
      "epoch 132; iter: 0; batch classifier loss: 0.129767; batch adversarial loss: 0.473866\n",
      "epoch 133; iter: 0; batch classifier loss: 0.178951; batch adversarial loss: 0.383073\n",
      "epoch 134; iter: 0; batch classifier loss: 0.178300; batch adversarial loss: 0.368742\n",
      "epoch 135; iter: 0; batch classifier loss: 0.213669; batch adversarial loss: 0.382932\n",
      "epoch 136; iter: 0; batch classifier loss: 0.164687; batch adversarial loss: 0.447503\n",
      "epoch 137; iter: 0; batch classifier loss: 0.210499; batch adversarial loss: 0.498132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.119330; batch adversarial loss: 0.408437\n",
      "epoch 139; iter: 0; batch classifier loss: 0.163627; batch adversarial loss: 0.484164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.146884; batch adversarial loss: 0.459421\n",
      "epoch 141; iter: 0; batch classifier loss: 0.241295; batch adversarial loss: 0.472347\n",
      "epoch 142; iter: 0; batch classifier loss: 0.217636; batch adversarial loss: 0.472362\n",
      "epoch 143; iter: 0; batch classifier loss: 0.197034; batch adversarial loss: 0.433235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.240669; batch adversarial loss: 0.432503\n",
      "epoch 145; iter: 0; batch classifier loss: 0.210854; batch adversarial loss: 0.588135\n",
      "epoch 146; iter: 0; batch classifier loss: 0.268538; batch adversarial loss: 0.497223\n",
      "epoch 147; iter: 0; batch classifier loss: 0.160308; batch adversarial loss: 0.407935\n",
      "epoch 148; iter: 0; batch classifier loss: 0.193818; batch adversarial loss: 0.523078\n",
      "epoch 149; iter: 0; batch classifier loss: 0.165182; batch adversarial loss: 0.395113\n",
      "epoch 150; iter: 0; batch classifier loss: 0.201359; batch adversarial loss: 0.381812\n",
      "epoch 151; iter: 0; batch classifier loss: 0.182473; batch adversarial loss: 0.548899\n",
      "epoch 152; iter: 0; batch classifier loss: 0.117022; batch adversarial loss: 0.472317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.168874; batch adversarial loss: 0.459546\n",
      "epoch 154; iter: 0; batch classifier loss: 0.177356; batch adversarial loss: 0.433386\n",
      "epoch 155; iter: 0; batch classifier loss: 0.111978; batch adversarial loss: 0.548626\n",
      "epoch 156; iter: 0; batch classifier loss: 0.158730; batch adversarial loss: 0.472170\n",
      "epoch 157; iter: 0; batch classifier loss: 0.177082; batch adversarial loss: 0.484103\n",
      "epoch 158; iter: 0; batch classifier loss: 0.161418; batch adversarial loss: 0.370572\n",
      "epoch 159; iter: 0; batch classifier loss: 0.185683; batch adversarial loss: 0.357068\n",
      "epoch 160; iter: 0; batch classifier loss: 0.220983; batch adversarial loss: 0.457684\n",
      "epoch 161; iter: 0; batch classifier loss: 0.170505; batch adversarial loss: 0.409711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.120251; batch adversarial loss: 0.472052\n",
      "epoch 163; iter: 0; batch classifier loss: 0.220457; batch adversarial loss: 0.368687\n",
      "epoch 164; iter: 0; batch classifier loss: 0.197614; batch adversarial loss: 0.409435\n",
      "epoch 165; iter: 0; batch classifier loss: 0.127696; batch adversarial loss: 0.586598\n",
      "epoch 166; iter: 0; batch classifier loss: 0.150991; batch adversarial loss: 0.432523\n",
      "epoch 167; iter: 0; batch classifier loss: 0.211489; batch adversarial loss: 0.382375\n",
      "epoch 168; iter: 0; batch classifier loss: 0.159549; batch adversarial loss: 0.431887\n",
      "epoch 169; iter: 0; batch classifier loss: 0.253187; batch adversarial loss: 0.408100\n",
      "epoch 170; iter: 0; batch classifier loss: 0.193013; batch adversarial loss: 0.420810\n",
      "epoch 171; iter: 0; batch classifier loss: 0.140987; batch adversarial loss: 0.484888\n",
      "epoch 172; iter: 0; batch classifier loss: 0.184146; batch adversarial loss: 0.370464\n",
      "epoch 173; iter: 0; batch classifier loss: 0.226572; batch adversarial loss: 0.421055\n",
      "epoch 174; iter: 0; batch classifier loss: 0.180372; batch adversarial loss: 0.471713\n",
      "epoch 175; iter: 0; batch classifier loss: 0.236179; batch adversarial loss: 0.509840\n",
      "epoch 176; iter: 0; batch classifier loss: 0.248504; batch adversarial loss: 0.522859\n",
      "epoch 177; iter: 0; batch classifier loss: 0.253190; batch adversarial loss: 0.459362\n",
      "epoch 178; iter: 0; batch classifier loss: 0.228265; batch adversarial loss: 0.420967\n",
      "epoch 179; iter: 0; batch classifier loss: 0.167306; batch adversarial loss: 0.471999\n",
      "epoch 180; iter: 0; batch classifier loss: 0.215620; batch adversarial loss: 0.356795\n",
      "epoch 181; iter: 0; batch classifier loss: 0.176485; batch adversarial loss: 0.523769\n",
      "epoch 182; iter: 0; batch classifier loss: 0.153341; batch adversarial loss: 0.523055\n",
      "epoch 183; iter: 0; batch classifier loss: 0.182047; batch adversarial loss: 0.446541\n",
      "epoch 184; iter: 0; batch classifier loss: 0.229543; batch adversarial loss: 0.420707\n",
      "epoch 185; iter: 0; batch classifier loss: 0.118586; batch adversarial loss: 0.407922\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035611; batch adversarial loss: 0.404805\n",
      "epoch 187; iter: 0; batch classifier loss: 0.081455; batch adversarial loss: 0.498150\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058310; batch adversarial loss: 0.449814\n",
      "epoch 189; iter: 0; batch classifier loss: 0.055786; batch adversarial loss: 0.427456\n",
      "epoch 190; iter: 0; batch classifier loss: 0.055888; batch adversarial loss: 0.411573\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078330; batch adversarial loss: 0.450241\n",
      "epoch 192; iter: 0; batch classifier loss: 0.072895; batch adversarial loss: 0.453330\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049144; batch adversarial loss: 0.416827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.056262; batch adversarial loss: 0.409380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.073881; batch adversarial loss: 0.332875\n",
      "epoch 196; iter: 0; batch classifier loss: 0.074583; batch adversarial loss: 0.447633\n",
      "epoch 197; iter: 0; batch classifier loss: 0.062208; batch adversarial loss: 0.417018\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038400; batch adversarial loss: 0.374325\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056345; batch adversarial loss: 0.460282\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674986; batch adversarial loss: 0.676772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412302; batch adversarial loss: 0.642303\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415796; batch adversarial loss: 0.565497\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392482; batch adversarial loss: 0.543633\n",
      "epoch 4; iter: 0; batch classifier loss: 0.326619; batch adversarial loss: 0.551565\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330155; batch adversarial loss: 0.487567\n",
      "epoch 6; iter: 0; batch classifier loss: 0.275212; batch adversarial loss: 0.531592\n",
      "epoch 7; iter: 0; batch classifier loss: 0.249488; batch adversarial loss: 0.478465\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268834; batch adversarial loss: 0.524607\n",
      "epoch 9; iter: 0; batch classifier loss: 0.224544; batch adversarial loss: 0.450932\n",
      "epoch 10; iter: 0; batch classifier loss: 0.226214; batch adversarial loss: 0.485181\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260818; batch adversarial loss: 0.494682\n",
      "epoch 12; iter: 0; batch classifier loss: 0.212257; batch adversarial loss: 0.425431\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243341; batch adversarial loss: 0.531379\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179310; batch adversarial loss: 0.439057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171741; batch adversarial loss: 0.488713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210553; batch adversarial loss: 0.532842\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254188; batch adversarial loss: 0.569517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271445; batch adversarial loss: 0.536117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245986; batch adversarial loss: 0.621299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159484; batch adversarial loss: 0.423475\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197226; batch adversarial loss: 0.522905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230419; batch adversarial loss: 0.506845\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273684; batch adversarial loss: 0.570793\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201884; batch adversarial loss: 0.490137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291260; batch adversarial loss: 0.509596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.317147; batch adversarial loss: 0.559926\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250628; batch adversarial loss: 0.495971\n",
      "epoch 28; iter: 0; batch classifier loss: 0.260739; batch adversarial loss: 0.455769\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326425; batch adversarial loss: 0.462517\n",
      "epoch 30; iter: 0; batch classifier loss: 0.290952; batch adversarial loss: 0.465569\n",
      "epoch 31; iter: 0; batch classifier loss: 0.181873; batch adversarial loss: 0.493487\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152934; batch adversarial loss: 0.472116\n",
      "epoch 33; iter: 0; batch classifier loss: 0.095212; batch adversarial loss: 0.423876\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099841; batch adversarial loss: 0.442267\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210621; batch adversarial loss: 0.444107\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116150; batch adversarial loss: 0.459370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108508; batch adversarial loss: 0.412961\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117133; batch adversarial loss: 0.460840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124198; batch adversarial loss: 0.442124\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099029; batch adversarial loss: 0.550992\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105365; batch adversarial loss: 0.377241\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101672; batch adversarial loss: 0.533662\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088668; batch adversarial loss: 0.488249\n",
      "epoch 44; iter: 0; batch classifier loss: 0.076083; batch adversarial loss: 0.473484\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118961; batch adversarial loss: 0.436722\n",
      "epoch 46; iter: 0; batch classifier loss: 0.076889; batch adversarial loss: 0.460013\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090706; batch adversarial loss: 0.450439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101700; batch adversarial loss: 0.493109\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084550; batch adversarial loss: 0.422604\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063981; batch adversarial loss: 0.480880\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077907; batch adversarial loss: 0.398777\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078772; batch adversarial loss: 0.477404\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055706; batch adversarial loss: 0.469235\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079522; batch adversarial loss: 0.538645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098867; batch adversarial loss: 0.485827\n",
      "epoch 56; iter: 0; batch classifier loss: 0.041672; batch adversarial loss: 0.477325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113423; batch adversarial loss: 0.381947\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061402; batch adversarial loss: 0.425575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101044; batch adversarial loss: 0.354996\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104685; batch adversarial loss: 0.400797\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.433246\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088749; batch adversarial loss: 0.431373\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104027; batch adversarial loss: 0.438356\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116393; batch adversarial loss: 0.553457\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065254; batch adversarial loss: 0.467615\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115734; batch adversarial loss: 0.350339\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107782; batch adversarial loss: 0.447043\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087554; batch adversarial loss: 0.369978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114343; batch adversarial loss: 0.405900\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071297; batch adversarial loss: 0.504395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055304; batch adversarial loss: 0.506904\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088888; batch adversarial loss: 0.494159\n",
      "epoch 73; iter: 0; batch classifier loss: 0.077671; batch adversarial loss: 0.394141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081074; batch adversarial loss: 0.436999\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038245; batch adversarial loss: 0.442414\n",
      "epoch 76; iter: 0; batch classifier loss: 0.035096; batch adversarial loss: 0.495071\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102012; batch adversarial loss: 0.442519\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065808; batch adversarial loss: 0.437062\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074411; batch adversarial loss: 0.447757\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079683; batch adversarial loss: 0.380268\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055692; batch adversarial loss: 0.483589\n",
      "epoch 82; iter: 0; batch classifier loss: 0.101518; batch adversarial loss: 0.414136\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089126; batch adversarial loss: 0.489865\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061539; batch adversarial loss: 0.375973\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103684; batch adversarial loss: 0.401333\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068099; batch adversarial loss: 0.426803\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083314; batch adversarial loss: 0.419273\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040123; batch adversarial loss: 0.409923\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050128; batch adversarial loss: 0.480788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.450752\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052945; batch adversarial loss: 0.463569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.122615; batch adversarial loss: 0.517806\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064577; batch adversarial loss: 0.495129\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067764; batch adversarial loss: 0.579110\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098865; batch adversarial loss: 0.410492\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110307; batch adversarial loss: 0.408732\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046686; batch adversarial loss: 0.394743\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045994; batch adversarial loss: 0.442596\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080416; batch adversarial loss: 0.555553\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059754; batch adversarial loss: 0.431885\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075734; batch adversarial loss: 0.460882\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031371; batch adversarial loss: 0.543384\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058597; batch adversarial loss: 0.448418\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077564; batch adversarial loss: 0.497282\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050345; batch adversarial loss: 0.443112\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044966; batch adversarial loss: 0.434332\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067037; batch adversarial loss: 0.443780\n",
      "epoch 108; iter: 0; batch classifier loss: 0.084149; batch adversarial loss: 0.414178\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072303; batch adversarial loss: 0.427642\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041675; batch adversarial loss: 0.471220\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025287; batch adversarial loss: 0.444572\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070024; batch adversarial loss: 0.400751\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091004; batch adversarial loss: 0.517215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038665; batch adversarial loss: 0.469649\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044578; batch adversarial loss: 0.422834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073913; batch adversarial loss: 0.521745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027586; batch adversarial loss: 0.457053\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.426055\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057749; batch adversarial loss: 0.448525\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055562; batch adversarial loss: 0.473288\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060521; batch adversarial loss: 0.471130\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039802; batch adversarial loss: 0.392362\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047976; batch adversarial loss: 0.364648\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062250; batch adversarial loss: 0.389303\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033105; batch adversarial loss: 0.444209\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044571; batch adversarial loss: 0.501911\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035070; batch adversarial loss: 0.530298\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053844; batch adversarial loss: 0.422773\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054079; batch adversarial loss: 0.396347\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028792; batch adversarial loss: 0.468072\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046672; batch adversarial loss: 0.463735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025057; batch adversarial loss: 0.410799\n",
      "epoch 133; iter: 0; batch classifier loss: 0.107460; batch adversarial loss: 0.440425\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053846; batch adversarial loss: 0.485656\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046564; batch adversarial loss: 0.442534\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061635; batch adversarial loss: 0.472470\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058000; batch adversarial loss: 0.434552\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020777; batch adversarial loss: 0.446330\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038189; batch adversarial loss: 0.492132\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036177; batch adversarial loss: 0.477528\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041329; batch adversarial loss: 0.472123\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046831; batch adversarial loss: 0.457450\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054882; batch adversarial loss: 0.437820\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042790; batch adversarial loss: 0.515513\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063590; batch adversarial loss: 0.338565\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029578; batch adversarial loss: 0.374079\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024003; batch adversarial loss: 0.521854\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021655; batch adversarial loss: 0.406183\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.475495\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021747; batch adversarial loss: 0.451423\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045499; batch adversarial loss: 0.517916\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033708; batch adversarial loss: 0.358430\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033637; batch adversarial loss: 0.426546\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034774; batch adversarial loss: 0.485395\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032860; batch adversarial loss: 0.503038\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027759; batch adversarial loss: 0.477378\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044847; batch adversarial loss: 0.439396\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016668; batch adversarial loss: 0.471834\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020329; batch adversarial loss: 0.418633\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028689; batch adversarial loss: 0.468035\n",
      "epoch 161; iter: 0; batch classifier loss: 0.056315; batch adversarial loss: 0.480170\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014723; batch adversarial loss: 0.488529\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050479; batch adversarial loss: 0.413197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024938; batch adversarial loss: 0.459120\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034159; batch adversarial loss: 0.446401\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029831; batch adversarial loss: 0.446562\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017721; batch adversarial loss: 0.324993\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032725; batch adversarial loss: 0.355826\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016681; batch adversarial loss: 0.445142\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025258; batch adversarial loss: 0.448945\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009401; batch adversarial loss: 0.481993\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016465; batch adversarial loss: 0.405719\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036352; batch adversarial loss: 0.486167\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022761; batch adversarial loss: 0.500081\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020167; batch adversarial loss: 0.402807\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022959; batch adversarial loss: 0.487318\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030079; batch adversarial loss: 0.470745\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032575; batch adversarial loss: 0.475116\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021670; batch adversarial loss: 0.488436\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041808; batch adversarial loss: 0.339546\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027016; batch adversarial loss: 0.429504\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022775; batch adversarial loss: 0.384789\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027223; batch adversarial loss: 0.443928\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.589173\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014829; batch adversarial loss: 0.460173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016818; batch adversarial loss: 0.388632\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028663; batch adversarial loss: 0.397349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.038925; batch adversarial loss: 0.488270\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029438; batch adversarial loss: 0.408780\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036017; batch adversarial loss: 0.447960\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009543; batch adversarial loss: 0.457570\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032400; batch adversarial loss: 0.432991\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016808; batch adversarial loss: 0.450552\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031847; batch adversarial loss: 0.400666\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031557; batch adversarial loss: 0.431039\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008014; batch adversarial loss: 0.444066\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019469; batch adversarial loss: 0.432060\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040079; batch adversarial loss: 0.473063\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024267; batch adversarial loss: 0.347274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688874; batch adversarial loss: 0.643119\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451102; batch adversarial loss: 0.642605\n",
      "epoch 2; iter: 0; batch classifier loss: 0.494043; batch adversarial loss: 0.595400\n",
      "epoch 3; iter: 0; batch classifier loss: 0.532331; batch adversarial loss: 0.634238\n",
      "epoch 4; iter: 0; batch classifier loss: 0.529112; batch adversarial loss: 0.613353\n",
      "epoch 5; iter: 0; batch classifier loss: 0.490686; batch adversarial loss: 0.596035\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401674; batch adversarial loss: 0.544767\n",
      "epoch 7; iter: 0; batch classifier loss: 0.457049; batch adversarial loss: 0.557439\n",
      "epoch 8; iter: 0; batch classifier loss: 0.456640; batch adversarial loss: 0.526954\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490688; batch adversarial loss: 0.551069\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471662; batch adversarial loss: 0.522735\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447867; batch adversarial loss: 0.519913\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253812; batch adversarial loss: 0.490496\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317895; batch adversarial loss: 0.546636\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413963; batch adversarial loss: 0.526190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.369279; batch adversarial loss: 0.509799\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294980; batch adversarial loss: 0.545534\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297458; batch adversarial loss: 0.432645\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355712; batch adversarial loss: 0.442332\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347164; batch adversarial loss: 0.495197\n",
      "epoch 20; iter: 0; batch classifier loss: 0.292319; batch adversarial loss: 0.436003\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341242; batch adversarial loss: 0.441317\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339058; batch adversarial loss: 0.418016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.348483; batch adversarial loss: 0.464071\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360079; batch adversarial loss: 0.433357\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288165; batch adversarial loss: 0.436946\n",
      "epoch 26; iter: 0; batch classifier loss: 0.330964; batch adversarial loss: 0.458624\n",
      "epoch 27; iter: 0; batch classifier loss: 0.266476; batch adversarial loss: 0.563874\n",
      "epoch 28; iter: 0; batch classifier loss: 0.293100; batch adversarial loss: 0.451850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.284341; batch adversarial loss: 0.465634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.317532; batch adversarial loss: 0.442587\n",
      "epoch 31; iter: 0; batch classifier loss: 0.310347; batch adversarial loss: 0.435629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275876; batch adversarial loss: 0.448867\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196826; batch adversarial loss: 0.509196\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247685; batch adversarial loss: 0.507452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.246835; batch adversarial loss: 0.511081\n",
      "epoch 36; iter: 0; batch classifier loss: 0.262469; batch adversarial loss: 0.485317\n",
      "epoch 37; iter: 0; batch classifier loss: 0.263171; batch adversarial loss: 0.396132\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252116; batch adversarial loss: 0.425026\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336971; batch adversarial loss: 0.473832\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272730; batch adversarial loss: 0.486113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291284; batch adversarial loss: 0.426955\n",
      "epoch 42; iter: 0; batch classifier loss: 0.244785; batch adversarial loss: 0.530717\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241414; batch adversarial loss: 0.471731\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287718; batch adversarial loss: 0.493654\n",
      "epoch 45; iter: 0; batch classifier loss: 0.327570; batch adversarial loss: 0.423902\n",
      "epoch 46; iter: 0; batch classifier loss: 0.181394; batch adversarial loss: 0.506196\n",
      "epoch 47; iter: 0; batch classifier loss: 0.183954; batch adversarial loss: 0.554159\n",
      "epoch 48; iter: 0; batch classifier loss: 0.235898; batch adversarial loss: 0.493688\n",
      "epoch 49; iter: 0; batch classifier loss: 0.190452; batch adversarial loss: 0.434452\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204037; batch adversarial loss: 0.456892\n",
      "epoch 51; iter: 0; batch classifier loss: 0.279337; batch adversarial loss: 0.411553\n",
      "epoch 52; iter: 0; batch classifier loss: 0.245526; batch adversarial loss: 0.398000\n",
      "epoch 53; iter: 0; batch classifier loss: 0.228630; batch adversarial loss: 0.483394\n",
      "epoch 54; iter: 0; batch classifier loss: 0.268790; batch adversarial loss: 0.409856\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124199; batch adversarial loss: 0.396691\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099840; batch adversarial loss: 0.470321\n",
      "epoch 57; iter: 0; batch classifier loss: 0.147753; batch adversarial loss: 0.447732\n",
      "epoch 58; iter: 0; batch classifier loss: 0.272489; batch adversarial loss: 0.422122\n",
      "epoch 59; iter: 0; batch classifier loss: 0.189404; batch adversarial loss: 0.469587\n",
      "epoch 60; iter: 0; batch classifier loss: 0.167510; batch adversarial loss: 0.371481\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199104; batch adversarial loss: 0.509439\n",
      "epoch 62; iter: 0; batch classifier loss: 0.279977; batch adversarial loss: 0.372963\n",
      "epoch 63; iter: 0; batch classifier loss: 0.292073; batch adversarial loss: 0.384628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.220053; batch adversarial loss: 0.410279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.249004; batch adversarial loss: 0.446531\n",
      "epoch 66; iter: 0; batch classifier loss: 0.333120; batch adversarial loss: 0.409360\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130331; batch adversarial loss: 0.408781\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062810; batch adversarial loss: 0.408124\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079307; batch adversarial loss: 0.339021\n",
      "epoch 70; iter: 0; batch classifier loss: 0.049648; batch adversarial loss: 0.531198\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064557; batch adversarial loss: 0.515571\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075891; batch adversarial loss: 0.396721\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065627; batch adversarial loss: 0.510164\n",
      "epoch 74; iter: 0; batch classifier loss: 0.107058; batch adversarial loss: 0.408224\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085774; batch adversarial loss: 0.352194\n",
      "epoch 76; iter: 0; batch classifier loss: 0.194196; batch adversarial loss: 0.542191\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136493; batch adversarial loss: 0.424225\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119450; batch adversarial loss: 0.405142\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150604; batch adversarial loss: 0.320422\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088107; batch adversarial loss: 0.552704\n",
      "epoch 81; iter: 0; batch classifier loss: 0.151972; batch adversarial loss: 0.379565\n",
      "epoch 82; iter: 0; batch classifier loss: 0.131543; batch adversarial loss: 0.457955\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126388; batch adversarial loss: 0.461230\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071998; batch adversarial loss: 0.456564\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.415583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.047476; batch adversarial loss: 0.508796\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088749; batch adversarial loss: 0.442859\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062988; batch adversarial loss: 0.548143\n",
      "epoch 89; iter: 0; batch classifier loss: 0.090152; batch adversarial loss: 0.443620\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063904; batch adversarial loss: 0.505630\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044703; batch adversarial loss: 0.416416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081195; batch adversarial loss: 0.289564\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089488; batch adversarial loss: 0.473253\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051032; batch adversarial loss: 0.461256\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046685; batch adversarial loss: 0.478746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117879; batch adversarial loss: 0.527664\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050601; batch adversarial loss: 0.486506\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079360; batch adversarial loss: 0.442101\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074797; batch adversarial loss: 0.391174\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047795; batch adversarial loss: 0.458125\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042765; batch adversarial loss: 0.497742\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076007; batch adversarial loss: 0.364440\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037644; batch adversarial loss: 0.479812\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048383; batch adversarial loss: 0.489653\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065742; batch adversarial loss: 0.389433\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055991; batch adversarial loss: 0.419623\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036562; batch adversarial loss: 0.432105\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031414; batch adversarial loss: 0.404676\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029356; batch adversarial loss: 0.527776\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059091; batch adversarial loss: 0.482474\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056251; batch adversarial loss: 0.345165\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064589; batch adversarial loss: 0.410289\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053233; batch adversarial loss: 0.484258\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041266; batch adversarial loss: 0.391688\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039105; batch adversarial loss: 0.456640\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026359; batch adversarial loss: 0.466622\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050103; batch adversarial loss: 0.459277\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047949; batch adversarial loss: 0.414745\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042817; batch adversarial loss: 0.409707\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027759; batch adversarial loss: 0.339040\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032451; batch adversarial loss: 0.522393\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014372; batch adversarial loss: 0.343751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033103; batch adversarial loss: 0.468461\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021855; batch adversarial loss: 0.481016\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029840; batch adversarial loss: 0.417599\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034488; batch adversarial loss: 0.434190\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052718; batch adversarial loss: 0.460303\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041045; batch adversarial loss: 0.464061\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023253; batch adversarial loss: 0.510187\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013822; batch adversarial loss: 0.458062\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048226; batch adversarial loss: 0.433694\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019789; batch adversarial loss: 0.416722\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027335; batch adversarial loss: 0.394732\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.526854\n",
      "epoch 135; iter: 0; batch classifier loss: 0.009223; batch adversarial loss: 0.413105\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023322; batch adversarial loss: 0.501601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015482; batch adversarial loss: 0.460155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.403634\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009663; batch adversarial loss: 0.501823\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034185; batch adversarial loss: 0.383534\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010039; batch adversarial loss: 0.391453\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030816; batch adversarial loss: 0.485422\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027013; batch adversarial loss: 0.400494\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013826; batch adversarial loss: 0.553452\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029238; batch adversarial loss: 0.425838\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030156; batch adversarial loss: 0.354824\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018599; batch adversarial loss: 0.409858\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.439715\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013981; batch adversarial loss: 0.530666\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030274; batch adversarial loss: 0.478415\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.514641\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.430451\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022697; batch adversarial loss: 0.533061\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016903; batch adversarial loss: 0.509744\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.472792\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006005; batch adversarial loss: 0.515176\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013886; batch adversarial loss: 0.411990\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.379702\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020791; batch adversarial loss: 0.460576\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045055; batch adversarial loss: 0.401424\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013654; batch adversarial loss: 0.440417\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021345; batch adversarial loss: 0.390632\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014853; batch adversarial loss: 0.484317\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018937; batch adversarial loss: 0.505136\n",
      "epoch 165; iter: 0; batch classifier loss: 0.004579; batch adversarial loss: 0.477974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.525814\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008318; batch adversarial loss: 0.499298\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026023; batch adversarial loss: 0.411332\n",
      "epoch 169; iter: 0; batch classifier loss: 0.002439; batch adversarial loss: 0.391127\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013440; batch adversarial loss: 0.485078\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045571; batch adversarial loss: 0.356729\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012975; batch adversarial loss: 0.445048\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008636; batch adversarial loss: 0.367278\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007260; batch adversarial loss: 0.453577\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.471180\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013184; batch adversarial loss: 0.542591\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028930; batch adversarial loss: 0.341810\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.505834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003594; batch adversarial loss: 0.499863\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028111; batch adversarial loss: 0.436061\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010577; batch adversarial loss: 0.444233\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026227; batch adversarial loss: 0.481424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 183; iter: 0; batch classifier loss: 0.013690; batch adversarial loss: 0.361775\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.422128\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018567; batch adversarial loss: 0.405884\n",
      "epoch 186; iter: 0; batch classifier loss: 0.063170; batch adversarial loss: 0.458070\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008610; batch adversarial loss: 0.459310\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007516; batch adversarial loss: 0.465708\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005862; batch adversarial loss: 0.446504\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012447; batch adversarial loss: 0.485628\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019042; batch adversarial loss: 0.447417\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004887; batch adversarial loss: 0.465438\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030872; batch adversarial loss: 0.449287\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020324; batch adversarial loss: 0.393368\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013616; batch adversarial loss: 0.460993\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018969; batch adversarial loss: 0.509613\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020601; batch adversarial loss: 0.455372\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008143; batch adversarial loss: 0.429552\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009204; batch adversarial loss: 0.465689\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695510; batch adversarial loss: 0.563622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466707; batch adversarial loss: 0.605360\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411000; batch adversarial loss: 0.586238\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392867; batch adversarial loss: 0.560558\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377152; batch adversarial loss: 0.561065\n",
      "epoch 5; iter: 0; batch classifier loss: 0.252607; batch adversarial loss: 0.594295\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323971; batch adversarial loss: 0.499094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.263279; batch adversarial loss: 0.527992\n",
      "epoch 8; iter: 0; batch classifier loss: 0.251769; batch adversarial loss: 0.513101\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305019; batch adversarial loss: 0.566425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291628; batch adversarial loss: 0.567525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267669; batch adversarial loss: 0.521116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305240; batch adversarial loss: 0.496174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305603; batch adversarial loss: 0.547331\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166441; batch adversarial loss: 0.471237\n",
      "epoch 15; iter: 0; batch classifier loss: 0.197649; batch adversarial loss: 0.468365\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242333; batch adversarial loss: 0.555736\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233311; batch adversarial loss: 0.504035\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256676; batch adversarial loss: 0.498049\n",
      "epoch 19; iter: 0; batch classifier loss: 0.282818; batch adversarial loss: 0.524793\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314008; batch adversarial loss: 0.501975\n",
      "epoch 21; iter: 0; batch classifier loss: 0.337385; batch adversarial loss: 0.577713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269839; batch adversarial loss: 0.619452\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285077; batch adversarial loss: 0.425140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244743; batch adversarial loss: 0.458515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328605; batch adversarial loss: 0.549303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145201; batch adversarial loss: 0.456274\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241357; batch adversarial loss: 0.476545\n",
      "epoch 28; iter: 0; batch classifier loss: 0.284718; batch adversarial loss: 0.539777\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306826; batch adversarial loss: 0.395089\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315683; batch adversarial loss: 0.508510\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145870; batch adversarial loss: 0.463556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.161615; batch adversarial loss: 0.448155\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142360; batch adversarial loss: 0.452340\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118886; batch adversarial loss: 0.543185\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108224; batch adversarial loss: 0.408799\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126096; batch adversarial loss: 0.433933\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207735; batch adversarial loss: 0.441651\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093731; batch adversarial loss: 0.465662\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143075; batch adversarial loss: 0.388460\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119553; batch adversarial loss: 0.570488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117586; batch adversarial loss: 0.373868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113149; batch adversarial loss: 0.468402\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116173; batch adversarial loss: 0.460955\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123759; batch adversarial loss: 0.456678\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124263; batch adversarial loss: 0.516099\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101500; batch adversarial loss: 0.410041\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201316; batch adversarial loss: 0.365687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098964; batch adversarial loss: 0.486191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085500; batch adversarial loss: 0.511148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.161286; batch adversarial loss: 0.455693\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109027; batch adversarial loss: 0.454445\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137370; batch adversarial loss: 0.546710\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127286; batch adversarial loss: 0.515515\n",
      "epoch 54; iter: 0; batch classifier loss: 0.051049; batch adversarial loss: 0.391875\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092115; batch adversarial loss: 0.486515\n",
      "epoch 56; iter: 0; batch classifier loss: 0.173799; batch adversarial loss: 0.493267\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084773; batch adversarial loss: 0.480147\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125892; batch adversarial loss: 0.410935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110884; batch adversarial loss: 0.347889\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134069; batch adversarial loss: 0.428049\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112156; batch adversarial loss: 0.370859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070388; batch adversarial loss: 0.449646\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063466; batch adversarial loss: 0.345919\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128973; batch adversarial loss: 0.521748\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101010; batch adversarial loss: 0.457987\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121599; batch adversarial loss: 0.406926\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143280; batch adversarial loss: 0.429887\n",
      "epoch 68; iter: 0; batch classifier loss: 0.191428; batch adversarial loss: 0.401383\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121886; batch adversarial loss: 0.439342\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136888; batch adversarial loss: 0.444108\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091927; batch adversarial loss: 0.491921\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109809; batch adversarial loss: 0.558742\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089965; batch adversarial loss: 0.463086\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106236; batch adversarial loss: 0.433966\n",
      "epoch 75; iter: 0; batch classifier loss: 0.149403; batch adversarial loss: 0.378119\n",
      "epoch 76; iter: 0; batch classifier loss: 0.117589; batch adversarial loss: 0.480364\n",
      "epoch 77; iter: 0; batch classifier loss: 0.098047; batch adversarial loss: 0.440041\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113054; batch adversarial loss: 0.383109\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131739; batch adversarial loss: 0.455593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.081717; batch adversarial loss: 0.496161\n",
      "epoch 81; iter: 0; batch classifier loss: 0.130078; batch adversarial loss: 0.440425\n",
      "epoch 82; iter: 0; batch classifier loss: 0.122468; batch adversarial loss: 0.418974\n",
      "epoch 83; iter: 0; batch classifier loss: 0.109587; batch adversarial loss: 0.447423\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132504; batch adversarial loss: 0.454237\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090582; batch adversarial loss: 0.457368\n",
      "epoch 86; iter: 0; batch classifier loss: 0.133522; batch adversarial loss: 0.489209\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104013; batch adversarial loss: 0.418596\n",
      "epoch 88; iter: 0; batch classifier loss: 0.106500; batch adversarial loss: 0.394590\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092639; batch adversarial loss: 0.475180\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089684; batch adversarial loss: 0.471512\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122854; batch adversarial loss: 0.550289\n",
      "epoch 92; iter: 0; batch classifier loss: 0.129029; batch adversarial loss: 0.508366\n",
      "epoch 93; iter: 0; batch classifier loss: 0.125201; batch adversarial loss: 0.393463\n",
      "epoch 94; iter: 0; batch classifier loss: 0.116451; batch adversarial loss: 0.434809\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099127; batch adversarial loss: 0.378415\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087161; batch adversarial loss: 0.416306\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152014; batch adversarial loss: 0.473533\n",
      "epoch 98; iter: 0; batch classifier loss: 0.103242; batch adversarial loss: 0.452445\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081241; batch adversarial loss: 0.476818\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094687; batch adversarial loss: 0.377439\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072165; batch adversarial loss: 0.413722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079297; batch adversarial loss: 0.506864\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078199; batch adversarial loss: 0.486343\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078220; batch adversarial loss: 0.438415\n",
      "epoch 105; iter: 0; batch classifier loss: 0.106675; batch adversarial loss: 0.382083\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063486; batch adversarial loss: 0.474608\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051457; batch adversarial loss: 0.445385\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070145; batch adversarial loss: 0.438359\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079758; batch adversarial loss: 0.366956\n",
      "epoch 110; iter: 0; batch classifier loss: 0.134590; batch adversarial loss: 0.372262\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069281; batch adversarial loss: 0.457310\n",
      "epoch 112; iter: 0; batch classifier loss: 0.083823; batch adversarial loss: 0.483311\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067732; batch adversarial loss: 0.428046\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071100; batch adversarial loss: 0.380088\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060178; batch adversarial loss: 0.345852\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071159; batch adversarial loss: 0.426977\n",
      "epoch 117; iter: 0; batch classifier loss: 0.091498; batch adversarial loss: 0.444177\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074849; batch adversarial loss: 0.482139\n",
      "epoch 119; iter: 0; batch classifier loss: 0.095854; batch adversarial loss: 0.440717\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034286; batch adversarial loss: 0.431048\n",
      "epoch 121; iter: 0; batch classifier loss: 0.077992; batch adversarial loss: 0.522071\n",
      "epoch 122; iter: 0; batch classifier loss: 0.090328; batch adversarial loss: 0.457453\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075435; batch adversarial loss: 0.470442\n",
      "epoch 124; iter: 0; batch classifier loss: 0.100320; batch adversarial loss: 0.455258\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038808; batch adversarial loss: 0.323295\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043376; batch adversarial loss: 0.447147\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060714; batch adversarial loss: 0.423601\n",
      "epoch 128; iter: 0; batch classifier loss: 0.059988; batch adversarial loss: 0.418750\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058952; batch adversarial loss: 0.381163\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016134; batch adversarial loss: 0.508093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.081139; batch adversarial loss: 0.309527\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035343; batch adversarial loss: 0.385569\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033207; batch adversarial loss: 0.404114\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058841; batch adversarial loss: 0.455172\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065676; batch adversarial loss: 0.432929\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037093; batch adversarial loss: 0.416923\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028109; batch adversarial loss: 0.397219\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031016; batch adversarial loss: 0.441595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.062317; batch adversarial loss: 0.382835\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038825; batch adversarial loss: 0.405133\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025051; batch adversarial loss: 0.438755\n",
      "epoch 142; iter: 0; batch classifier loss: 0.075233; batch adversarial loss: 0.449684\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028137; batch adversarial loss: 0.427207\n",
      "epoch 144; iter: 0; batch classifier loss: 0.055582; batch adversarial loss: 0.327473\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037880; batch adversarial loss: 0.519060\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054165; batch adversarial loss: 0.478960\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050709; batch adversarial loss: 0.530582\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040371; batch adversarial loss: 0.387203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050707; batch adversarial loss: 0.390267\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.414784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033899; batch adversarial loss: 0.365882\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020439; batch adversarial loss: 0.406786\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047586; batch adversarial loss: 0.442591\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048183; batch adversarial loss: 0.438608\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041561; batch adversarial loss: 0.493057\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037800; batch adversarial loss: 0.482033\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056384; batch adversarial loss: 0.393358\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045730; batch adversarial loss: 0.449079\n",
      "epoch 159; iter: 0; batch classifier loss: 0.056034; batch adversarial loss: 0.382402\n",
      "epoch 160; iter: 0; batch classifier loss: 0.040627; batch adversarial loss: 0.437521\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014336; batch adversarial loss: 0.477077\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.406413\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038024; batch adversarial loss: 0.407706\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037842; batch adversarial loss: 0.360395\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019042; batch adversarial loss: 0.528104\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044204; batch adversarial loss: 0.489738\n",
      "epoch 167; iter: 0; batch classifier loss: 0.062531; batch adversarial loss: 0.493600\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023250; batch adversarial loss: 0.499645\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027509; batch adversarial loss: 0.397629\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018158; batch adversarial loss: 0.520037\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055745; batch adversarial loss: 0.457817\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020172; batch adversarial loss: 0.415104\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030978; batch adversarial loss: 0.599070\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040521; batch adversarial loss: 0.476225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.077627; batch adversarial loss: 0.398519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.054270; batch adversarial loss: 0.324220\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011200; batch adversarial loss: 0.494030\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050641; batch adversarial loss: 0.484634\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020951; batch adversarial loss: 0.535951\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026536; batch adversarial loss: 0.359078\n",
      "epoch 181; iter: 0; batch classifier loss: 0.065878; batch adversarial loss: 0.397261\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014922; batch adversarial loss: 0.362127\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035021; batch adversarial loss: 0.445558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014974; batch adversarial loss: 0.520880\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026596; batch adversarial loss: 0.480205\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040384; batch adversarial loss: 0.469853\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035184; batch adversarial loss: 0.457669\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.418223\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042813; batch adversarial loss: 0.429210\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034833; batch adversarial loss: 0.476050\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034617; batch adversarial loss: 0.387815\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024116; batch adversarial loss: 0.386819\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031202; batch adversarial loss: 0.429977\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030554; batch adversarial loss: 0.338407\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015271; batch adversarial loss: 0.404063\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.491706\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011207; batch adversarial loss: 0.390426\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039542; batch adversarial loss: 0.400660\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.468936\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701020; batch adversarial loss: 0.573275\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502058; batch adversarial loss: 0.595936\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442321; batch adversarial loss: 0.583483\n",
      "epoch 3; iter: 0; batch classifier loss: 0.387707; batch adversarial loss: 0.538273\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340206; batch adversarial loss: 0.540095\n",
      "epoch 5; iter: 0; batch classifier loss: 0.273721; batch adversarial loss: 0.567683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.346108; batch adversarial loss: 0.534610\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334550; batch adversarial loss: 0.475289\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381516; batch adversarial loss: 0.553765\n",
      "epoch 9; iter: 0; batch classifier loss: 0.298037; batch adversarial loss: 0.510177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324392; batch adversarial loss: 0.550685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389578; batch adversarial loss: 0.547991\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461423; batch adversarial loss: 0.523950\n",
      "epoch 13; iter: 0; batch classifier loss: 0.508830; batch adversarial loss: 0.528021\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548718; batch adversarial loss: 0.529269\n",
      "epoch 15; iter: 0; batch classifier loss: 0.548102; batch adversarial loss: 0.434058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.400368; batch adversarial loss: 0.515870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260215; batch adversarial loss: 0.498774\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278494; batch adversarial loss: 0.441601\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210850; batch adversarial loss: 0.463389\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157037; batch adversarial loss: 0.464384\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187789; batch adversarial loss: 0.447452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.179536; batch adversarial loss: 0.524459\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211763; batch adversarial loss: 0.475211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166989; batch adversarial loss: 0.499349\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180519; batch adversarial loss: 0.507807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176262; batch adversarial loss: 0.424200\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160348; batch adversarial loss: 0.477162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.152265; batch adversarial loss: 0.494215\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129568; batch adversarial loss: 0.570983\n",
      "epoch 30; iter: 0; batch classifier loss: 0.112883; batch adversarial loss: 0.456518\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119400; batch adversarial loss: 0.462041\n",
      "epoch 32; iter: 0; batch classifier loss: 0.107328; batch adversarial loss: 0.525465\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120527; batch adversarial loss: 0.501559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161840; batch adversarial loss: 0.414528\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093252; batch adversarial loss: 0.414937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155079; batch adversarial loss: 0.504157\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143145; batch adversarial loss: 0.450627\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131654; batch adversarial loss: 0.464102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129308; batch adversarial loss: 0.328856\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107946; batch adversarial loss: 0.443292\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088102; batch adversarial loss: 0.495875\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105552; batch adversarial loss: 0.434516\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080209; batch adversarial loss: 0.521225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094847; batch adversarial loss: 0.526758\n",
      "epoch 45; iter: 0; batch classifier loss: 0.136862; batch adversarial loss: 0.360225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112424; batch adversarial loss: 0.339913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105731; batch adversarial loss: 0.502843\n",
      "epoch 48; iter: 0; batch classifier loss: 0.184563; batch adversarial loss: 0.413218\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064700; batch adversarial loss: 0.418979\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146748; batch adversarial loss: 0.372839\n",
      "epoch 51; iter: 0; batch classifier loss: 0.179943; batch adversarial loss: 0.445606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.135216; batch adversarial loss: 0.409604\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117025; batch adversarial loss: 0.492395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075908; batch adversarial loss: 0.426816\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091664; batch adversarial loss: 0.372642\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134899; batch adversarial loss: 0.453362\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095143; batch adversarial loss: 0.548825\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081791; batch adversarial loss: 0.441822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122822; batch adversarial loss: 0.481604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054200; batch adversarial loss: 0.505413\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097562; batch adversarial loss: 0.428296\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123060; batch adversarial loss: 0.458608\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128828; batch adversarial loss: 0.466170\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082548; batch adversarial loss: 0.443711\n",
      "epoch 65; iter: 0; batch classifier loss: 0.169274; batch adversarial loss: 0.501216\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085282; batch adversarial loss: 0.523249\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111416; batch adversarial loss: 0.438695\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082161; batch adversarial loss: 0.433745\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053780; batch adversarial loss: 0.428692\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080219; batch adversarial loss: 0.388123\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104683; batch adversarial loss: 0.438728\n",
      "epoch 72; iter: 0; batch classifier loss: 0.127947; batch adversarial loss: 0.384430\n",
      "epoch 73; iter: 0; batch classifier loss: 0.108682; batch adversarial loss: 0.480241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.126070; batch adversarial loss: 0.495122\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116882; batch adversarial loss: 0.463753\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132475; batch adversarial loss: 0.439476\n",
      "epoch 77; iter: 0; batch classifier loss: 0.116199; batch adversarial loss: 0.504928\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087162; batch adversarial loss: 0.496813\n",
      "epoch 79; iter: 0; batch classifier loss: 0.176584; batch adversarial loss: 0.380895\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102278; batch adversarial loss: 0.455249\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117043; batch adversarial loss: 0.469990\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110810; batch adversarial loss: 0.564653\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099627; batch adversarial loss: 0.469961\n",
      "epoch 84; iter: 0; batch classifier loss: 0.123955; batch adversarial loss: 0.438425\n",
      "epoch 85; iter: 0; batch classifier loss: 0.121028; batch adversarial loss: 0.474052\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074671; batch adversarial loss: 0.446827\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106622; batch adversarial loss: 0.415156\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082856; batch adversarial loss: 0.405896\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145277; batch adversarial loss: 0.428754\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094633; batch adversarial loss: 0.506108\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122698; batch adversarial loss: 0.459704\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080743; batch adversarial loss: 0.421153\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077956; batch adversarial loss: 0.411564\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076068; batch adversarial loss: 0.450905\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103067; batch adversarial loss: 0.429024\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093953; batch adversarial loss: 0.427493\n",
      "epoch 97; iter: 0; batch classifier loss: 0.102039; batch adversarial loss: 0.380966\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096792; batch adversarial loss: 0.498940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058568; batch adversarial loss: 0.469677\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053182; batch adversarial loss: 0.444983\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061574; batch adversarial loss: 0.439044\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051938; batch adversarial loss: 0.393263\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086507; batch adversarial loss: 0.420388\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073729; batch adversarial loss: 0.390910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.103836; batch adversarial loss: 0.423511\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053596; batch adversarial loss: 0.419078\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034912; batch adversarial loss: 0.467812\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060048; batch adversarial loss: 0.373704\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069694; batch adversarial loss: 0.436347\n",
      "epoch 110; iter: 0; batch classifier loss: 0.093137; batch adversarial loss: 0.437976\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034014; batch adversarial loss: 0.561138\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053112; batch adversarial loss: 0.462360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048806; batch adversarial loss: 0.417089\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067184; batch adversarial loss: 0.526888\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057008; batch adversarial loss: 0.432575\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044945; batch adversarial loss: 0.443362\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040109; batch adversarial loss: 0.471266\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076050; batch adversarial loss: 0.505604\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072074; batch adversarial loss: 0.442150\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040997; batch adversarial loss: 0.433923\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039289; batch adversarial loss: 0.447792\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028664; batch adversarial loss: 0.397557\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017492; batch adversarial loss: 0.348228\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067575; batch adversarial loss: 0.434510\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022808; batch adversarial loss: 0.306691\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039777; batch adversarial loss: 0.433323\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019842; batch adversarial loss: 0.449546\n",
      "epoch 128; iter: 0; batch classifier loss: 0.095095; batch adversarial loss: 0.501732\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063438; batch adversarial loss: 0.505208\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041328; batch adversarial loss: 0.416071\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046537; batch adversarial loss: 0.381899\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035640; batch adversarial loss: 0.525649\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049563; batch adversarial loss: 0.457917\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026114; batch adversarial loss: 0.313165\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011868; batch adversarial loss: 0.486653\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024737; batch adversarial loss: 0.464808\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049139; batch adversarial loss: 0.388430\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016564; batch adversarial loss: 0.385105\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017609; batch adversarial loss: 0.395670\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029038; batch adversarial loss: 0.416317\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033481; batch adversarial loss: 0.412151\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040847; batch adversarial loss: 0.385391\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048089; batch adversarial loss: 0.406660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039663; batch adversarial loss: 0.533634\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039671; batch adversarial loss: 0.410396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.062324; batch adversarial loss: 0.361699\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024207; batch adversarial loss: 0.591160\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032593; batch adversarial loss: 0.526137\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009612; batch adversarial loss: 0.492682\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038128; batch adversarial loss: 0.411035\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041745; batch adversarial loss: 0.371202\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016026; batch adversarial loss: 0.453503\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022690; batch adversarial loss: 0.461339\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025052; batch adversarial loss: 0.443772\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027701; batch adversarial loss: 0.395034\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016427; batch adversarial loss: 0.573471\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052811; batch adversarial loss: 0.347190\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032048; batch adversarial loss: 0.542425\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043705; batch adversarial loss: 0.443127\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028285; batch adversarial loss: 0.436352\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014139; batch adversarial loss: 0.431668\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012508; batch adversarial loss: 0.410583\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033166; batch adversarial loss: 0.425414\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012414; batch adversarial loss: 0.457208\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027255; batch adversarial loss: 0.430171\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033738; batch adversarial loss: 0.477143\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010505; batch adversarial loss: 0.397624\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048314; batch adversarial loss: 0.345932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035786; batch adversarial loss: 0.327063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.437194\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004661; batch adversarial loss: 0.474703\n",
      "epoch 172; iter: 0; batch classifier loss: 0.046371; batch adversarial loss: 0.421906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014793; batch adversarial loss: 0.393229\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019733; batch adversarial loss: 0.403489\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023290; batch adversarial loss: 0.491235\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015741; batch adversarial loss: 0.465781\n",
      "epoch 177; iter: 0; batch classifier loss: 0.053961; batch adversarial loss: 0.484880\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010473; batch adversarial loss: 0.546033\n",
      "epoch 179; iter: 0; batch classifier loss: 0.049281; batch adversarial loss: 0.439843\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021690; batch adversarial loss: 0.395912\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007912; batch adversarial loss: 0.428530\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033797; batch adversarial loss: 0.424780\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048816; batch adversarial loss: 0.457274\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022418; batch adversarial loss: 0.434706\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005504; batch adversarial loss: 0.473711\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010083; batch adversarial loss: 0.470066\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003844; batch adversarial loss: 0.403424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004362; batch adversarial loss: 0.379073\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010868; batch adversarial loss: 0.359667\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024331; batch adversarial loss: 0.456850\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007037; batch adversarial loss: 0.434770\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017580; batch adversarial loss: 0.417263\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009463; batch adversarial loss: 0.421945\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022559; batch adversarial loss: 0.394826\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046974; batch adversarial loss: 0.444647\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003007; batch adversarial loss: 0.414528\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005262; batch adversarial loss: 0.513954\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019152; batch adversarial loss: 0.393625\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024457; batch adversarial loss: 0.482274\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694637; batch adversarial loss: 0.746310\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512008; batch adversarial loss: 0.696388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468440; batch adversarial loss: 0.650955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367577; batch adversarial loss: 0.604930\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379777; batch adversarial loss: 0.571976\n",
      "epoch 5; iter: 0; batch classifier loss: 0.294226; batch adversarial loss: 0.577365\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395539; batch adversarial loss: 0.584492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309390; batch adversarial loss: 0.546483\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345793; batch adversarial loss: 0.523513\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348170; batch adversarial loss: 0.547923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.330934; batch adversarial loss: 0.462240\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264615; batch adversarial loss: 0.542678\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277374; batch adversarial loss: 0.514905\n",
      "epoch 13; iter: 0; batch classifier loss: 0.216720; batch adversarial loss: 0.578045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.216576; batch adversarial loss: 0.522644\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289715; batch adversarial loss: 0.501830\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204533; batch adversarial loss: 0.513986\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291908; batch adversarial loss: 0.457630\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217336; batch adversarial loss: 0.599398\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244200; batch adversarial loss: 0.385826\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219334; batch adversarial loss: 0.480484\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218658; batch adversarial loss: 0.586082\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258476; batch adversarial loss: 0.524142\n",
      "epoch 23; iter: 0; batch classifier loss: 0.290057; batch adversarial loss: 0.478956\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214945; batch adversarial loss: 0.468215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213464; batch adversarial loss: 0.524213\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247423; batch adversarial loss: 0.485845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.234361; batch adversarial loss: 0.524940\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173033; batch adversarial loss: 0.485284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.274064; batch adversarial loss: 0.469946\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254747; batch adversarial loss: 0.488675\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226711; batch adversarial loss: 0.436039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242165; batch adversarial loss: 0.487815\n",
      "epoch 33; iter: 0; batch classifier loss: 0.178731; batch adversarial loss: 0.433779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224789; batch adversarial loss: 0.477250\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254073; batch adversarial loss: 0.471117\n",
      "epoch 36; iter: 0; batch classifier loss: 0.176641; batch adversarial loss: 0.569993\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208016; batch adversarial loss: 0.401488\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219153; batch adversarial loss: 0.519903\n",
      "epoch 39; iter: 0; batch classifier loss: 0.232435; batch adversarial loss: 0.413198\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214827; batch adversarial loss: 0.445803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.194654; batch adversarial loss: 0.413552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150036; batch adversarial loss: 0.415712\n",
      "epoch 43; iter: 0; batch classifier loss: 0.234887; batch adversarial loss: 0.461796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.187442; batch adversarial loss: 0.529147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159241; batch adversarial loss: 0.496391\n",
      "epoch 46; iter: 0; batch classifier loss: 0.167062; batch adversarial loss: 0.471567\n",
      "epoch 47; iter: 0; batch classifier loss: 0.204013; batch adversarial loss: 0.363726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214376; batch adversarial loss: 0.506749\n",
      "epoch 49; iter: 0; batch classifier loss: 0.201478; batch adversarial loss: 0.543407\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204222; batch adversarial loss: 0.472655\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186955; batch adversarial loss: 0.483223\n",
      "epoch 52; iter: 0; batch classifier loss: 0.182011; batch adversarial loss: 0.497088\n",
      "epoch 53; iter: 0; batch classifier loss: 0.145619; batch adversarial loss: 0.484499\n",
      "epoch 54; iter: 0; batch classifier loss: 0.198277; batch adversarial loss: 0.586857\n",
      "epoch 55; iter: 0; batch classifier loss: 0.220367; batch adversarial loss: 0.399226\n",
      "epoch 56; iter: 0; batch classifier loss: 0.225702; batch adversarial loss: 0.445578\n",
      "epoch 57; iter: 0; batch classifier loss: 0.192711; batch adversarial loss: 0.458815\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178425; batch adversarial loss: 0.493820\n",
      "epoch 59; iter: 0; batch classifier loss: 0.168570; batch adversarial loss: 0.448393\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149537; batch adversarial loss: 0.506676\n",
      "epoch 61; iter: 0; batch classifier loss: 0.195517; batch adversarial loss: 0.458675\n",
      "epoch 62; iter: 0; batch classifier loss: 0.174319; batch adversarial loss: 0.459352\n",
      "epoch 63; iter: 0; batch classifier loss: 0.151617; batch adversarial loss: 0.420632\n",
      "epoch 64; iter: 0; batch classifier loss: 0.220489; batch adversarial loss: 0.375860\n",
      "epoch 65; iter: 0; batch classifier loss: 0.220421; batch adversarial loss: 0.458333\n",
      "epoch 66; iter: 0; batch classifier loss: 0.218577; batch adversarial loss: 0.437502\n",
      "epoch 67; iter: 0; batch classifier loss: 0.141180; batch adversarial loss: 0.423277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.151259; batch adversarial loss: 0.454867\n",
      "epoch 69; iter: 0; batch classifier loss: 0.177631; batch adversarial loss: 0.507552\n",
      "epoch 70; iter: 0; batch classifier loss: 0.164822; batch adversarial loss: 0.483673\n",
      "epoch 71; iter: 0; batch classifier loss: 0.210082; batch adversarial loss: 0.483124\n",
      "epoch 72; iter: 0; batch classifier loss: 0.213272; batch adversarial loss: 0.433620\n",
      "epoch 73; iter: 0; batch classifier loss: 0.153525; batch adversarial loss: 0.528806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192438; batch adversarial loss: 0.411758\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102297; batch adversarial loss: 0.509812\n",
      "epoch 76; iter: 0; batch classifier loss: 0.152657; batch adversarial loss: 0.397772\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110832; batch adversarial loss: 0.419428\n",
      "epoch 78; iter: 0; batch classifier loss: 0.143097; batch adversarial loss: 0.481582\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112913; batch adversarial loss: 0.370590\n",
      "epoch 80; iter: 0; batch classifier loss: 0.136090; batch adversarial loss: 0.459935\n",
      "epoch 81; iter: 0; batch classifier loss: 0.134211; batch adversarial loss: 0.434191\n",
      "epoch 82; iter: 0; batch classifier loss: 0.117661; batch adversarial loss: 0.480384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080503; batch adversarial loss: 0.396805\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068253; batch adversarial loss: 0.461993\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058692; batch adversarial loss: 0.463814\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072655; batch adversarial loss: 0.491207\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059714; batch adversarial loss: 0.422072\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074984; batch adversarial loss: 0.460131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065061; batch adversarial loss: 0.425655\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067059; batch adversarial loss: 0.494376\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068630; batch adversarial loss: 0.407278\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068133; batch adversarial loss: 0.419843\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053646; batch adversarial loss: 0.446541\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068191; batch adversarial loss: 0.408413\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075798; batch adversarial loss: 0.489832\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058968; batch adversarial loss: 0.499805\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.425341\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033523; batch adversarial loss: 0.387668\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043326; batch adversarial loss: 0.501941\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034083; batch adversarial loss: 0.461032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102749; batch adversarial loss: 0.516527\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055191; batch adversarial loss: 0.461766\n",
      "epoch 103; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.442595\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038751; batch adversarial loss: 0.455379\n",
      "epoch 105; iter: 0; batch classifier loss: 0.014527; batch adversarial loss: 0.509123\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029850; batch adversarial loss: 0.467332\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041260; batch adversarial loss: 0.433428\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049597; batch adversarial loss: 0.432524\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035931; batch adversarial loss: 0.424597\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068003; batch adversarial loss: 0.432572\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050833; batch adversarial loss: 0.500924\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042069; batch adversarial loss: 0.413645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052408; batch adversarial loss: 0.404675\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033285; batch adversarial loss: 0.429992\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034037; batch adversarial loss: 0.373033\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059124; batch adversarial loss: 0.508160\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.411902\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041858; batch adversarial loss: 0.388469\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026509; batch adversarial loss: 0.526471\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024651; batch adversarial loss: 0.348943\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035365; batch adversarial loss: 0.427552\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076893; batch adversarial loss: 0.480925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043292; batch adversarial loss: 0.469279\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036726; batch adversarial loss: 0.516759\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041684; batch adversarial loss: 0.485292\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024016; batch adversarial loss: 0.398134\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026393; batch adversarial loss: 0.566140\n",
      "epoch 128; iter: 0; batch classifier loss: 0.011404; batch adversarial loss: 0.511692\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019336; batch adversarial loss: 0.506987\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023125; batch adversarial loss: 0.410527\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013691; batch adversarial loss: 0.402215\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.457075\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033869; batch adversarial loss: 0.508208\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031876; batch adversarial loss: 0.387588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014389; batch adversarial loss: 0.524306\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014799; batch adversarial loss: 0.404375\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032450; batch adversarial loss: 0.452868\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041395; batch adversarial loss: 0.494071\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026207; batch adversarial loss: 0.526439\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021857; batch adversarial loss: 0.497327\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038091; batch adversarial loss: 0.428016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018814; batch adversarial loss: 0.435719\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021622; batch adversarial loss: 0.412550\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049945; batch adversarial loss: 0.502077\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049065; batch adversarial loss: 0.483651\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014864; batch adversarial loss: 0.502945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029829; batch adversarial loss: 0.583403\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014043; batch adversarial loss: 0.455157\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010690; batch adversarial loss: 0.459818\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018696; batch adversarial loss: 0.529273\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010311; batch adversarial loss: 0.544023\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046555; batch adversarial loss: 0.435186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055229; batch adversarial loss: 0.422774\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019280; batch adversarial loss: 0.505358\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040292; batch adversarial loss: 0.463067\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041407; batch adversarial loss: 0.525979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010848; batch adversarial loss: 0.455502\n",
      "epoch 158; iter: 0; batch classifier loss: 0.051259; batch adversarial loss: 0.468331\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006575; batch adversarial loss: 0.518569\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.540661\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014645; batch adversarial loss: 0.416614\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021352; batch adversarial loss: 0.451322\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017419; batch adversarial loss: 0.476384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.028785; batch adversarial loss: 0.482893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034850; batch adversarial loss: 0.436734\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025534; batch adversarial loss: 0.412989\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014658; batch adversarial loss: 0.438551\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015100; batch adversarial loss: 0.557558\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.384322\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023040; batch adversarial loss: 0.453515\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016581; batch adversarial loss: 0.472598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007061; batch adversarial loss: 0.386130\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018868; batch adversarial loss: 0.479638\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040841; batch adversarial loss: 0.524465\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030983; batch adversarial loss: 0.524987\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012323; batch adversarial loss: 0.418119\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009738; batch adversarial loss: 0.505287\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036354; batch adversarial loss: 0.431434\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005779; batch adversarial loss: 0.390740\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006964; batch adversarial loss: 0.417933\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024186; batch adversarial loss: 0.447311\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036396; batch adversarial loss: 0.441908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.061167; batch adversarial loss: 0.448231\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.467357\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035155; batch adversarial loss: 0.453455\n",
      "epoch 186; iter: 0; batch classifier loss: 0.067474; batch adversarial loss: 0.460803\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025100; batch adversarial loss: 0.444950\n",
      "epoch 188; iter: 0; batch classifier loss: 0.002892; batch adversarial loss: 0.518840\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016775; batch adversarial loss: 0.437454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027204; batch adversarial loss: 0.549992\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012283; batch adversarial loss: 0.547949\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013442; batch adversarial loss: 0.516903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008676; batch adversarial loss: 0.400680\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006143; batch adversarial loss: 0.463085\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.553543\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014480; batch adversarial loss: 0.334228\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017288; batch adversarial loss: 0.549298\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018106; batch adversarial loss: 0.437120\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038468; batch adversarial loss: 0.447193\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730283; batch adversarial loss: 0.681603\n",
      "epoch 1; iter: 0; batch classifier loss: 0.497492; batch adversarial loss: 0.658386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.390497; batch adversarial loss: 0.624606\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382615; batch adversarial loss: 0.566866\n",
      "epoch 4; iter: 0; batch classifier loss: 0.315719; batch adversarial loss: 0.572738\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313766; batch adversarial loss: 0.550100\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285841; batch adversarial loss: 0.522671\n",
      "epoch 7; iter: 0; batch classifier loss: 0.223609; batch adversarial loss: 0.499848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261776; batch adversarial loss: 0.534554\n",
      "epoch 9; iter: 0; batch classifier loss: 0.227463; batch adversarial loss: 0.508121\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251385; batch adversarial loss: 0.507094\n",
      "epoch 11; iter: 0; batch classifier loss: 0.204484; batch adversarial loss: 0.445665\n",
      "epoch 12; iter: 0; batch classifier loss: 0.155364; batch adversarial loss: 0.451409\n",
      "epoch 13; iter: 0; batch classifier loss: 0.149575; batch adversarial loss: 0.514805\n",
      "epoch 14; iter: 0; batch classifier loss: 0.181638; batch adversarial loss: 0.408969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.171387; batch adversarial loss: 0.418450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187142; batch adversarial loss: 0.460086\n",
      "epoch 17; iter: 0; batch classifier loss: 0.156692; batch adversarial loss: 0.431232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184169; batch adversarial loss: 0.402771\n",
      "epoch 19; iter: 0; batch classifier loss: 0.156942; batch adversarial loss: 0.414860\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159695; batch adversarial loss: 0.406725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.141933; batch adversarial loss: 0.469740\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177816; batch adversarial loss: 0.397334\n",
      "epoch 23; iter: 0; batch classifier loss: 0.130617; batch adversarial loss: 0.436825\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184745; batch adversarial loss: 0.396033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172796; batch adversarial loss: 0.478096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160523; batch adversarial loss: 0.437750\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120493; batch adversarial loss: 0.351316\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212197; batch adversarial loss: 0.396149\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141701; batch adversarial loss: 0.408325\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137275; batch adversarial loss: 0.480018\n",
      "epoch 31; iter: 0; batch classifier loss: 0.093510; batch adversarial loss: 0.373267\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110309; batch adversarial loss: 0.369688\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180513; batch adversarial loss: 0.412488\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100437; batch adversarial loss: 0.382243\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106422; batch adversarial loss: 0.415165\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141795; batch adversarial loss: 0.474934\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146137; batch adversarial loss: 0.412003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106603; batch adversarial loss: 0.429972\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087764; batch adversarial loss: 0.433274\n",
      "epoch 40; iter: 0; batch classifier loss: 0.195401; batch adversarial loss: 0.464981\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150878; batch adversarial loss: 0.436396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106781; batch adversarial loss: 0.378188\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096332; batch adversarial loss: 0.349728\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118457; batch adversarial loss: 0.461733\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104049; batch adversarial loss: 0.433866\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106271; batch adversarial loss: 0.301761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094127; batch adversarial loss: 0.419433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.139268; batch adversarial loss: 0.514196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121674; batch adversarial loss: 0.455364\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116284; batch adversarial loss: 0.450182\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113253; batch adversarial loss: 0.438696\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096108; batch adversarial loss: 0.477644\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090616; batch adversarial loss: 0.469227\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108746; batch adversarial loss: 0.497689\n",
      "epoch 55; iter: 0; batch classifier loss: 0.130758; batch adversarial loss: 0.429415\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070974; batch adversarial loss: 0.438691\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108867; batch adversarial loss: 0.422542\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094433; batch adversarial loss: 0.365187\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084078; batch adversarial loss: 0.369354\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092894; batch adversarial loss: 0.444627\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097221; batch adversarial loss: 0.430315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.104605; batch adversarial loss: 0.399076\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094714; batch adversarial loss: 0.445841\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087534; batch adversarial loss: 0.397434\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105610; batch adversarial loss: 0.407169\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074171; batch adversarial loss: 0.396220\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076877; batch adversarial loss: 0.485130\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132629; batch adversarial loss: 0.366516\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076865; batch adversarial loss: 0.431530\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086617; batch adversarial loss: 0.502877\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102796; batch adversarial loss: 0.435036\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094076; batch adversarial loss: 0.341191\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112165; batch adversarial loss: 0.452254\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101242; batch adversarial loss: 0.433268\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076633; batch adversarial loss: 0.469026\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075474; batch adversarial loss: 0.440225\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072842; batch adversarial loss: 0.426804\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060089; batch adversarial loss: 0.287069\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070547; batch adversarial loss: 0.434053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.112083; batch adversarial loss: 0.443897\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079060; batch adversarial loss: 0.341642\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063397; batch adversarial loss: 0.476613\n",
      "epoch 83; iter: 0; batch classifier loss: 0.038234; batch adversarial loss: 0.368585\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079081; batch adversarial loss: 0.454406\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074970; batch adversarial loss: 0.488553\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050709; batch adversarial loss: 0.382457\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071505; batch adversarial loss: 0.453473\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088225; batch adversarial loss: 0.326696\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068855; batch adversarial loss: 0.476817\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074788; batch adversarial loss: 0.446887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074688; batch adversarial loss: 0.446619\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049690; batch adversarial loss: 0.391899\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067697; batch adversarial loss: 0.459282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052545; batch adversarial loss: 0.362170\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062197; batch adversarial loss: 0.331958\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088902; batch adversarial loss: 0.440378\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051739; batch adversarial loss: 0.424065\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.469008\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056562; batch adversarial loss: 0.448551\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060334; batch adversarial loss: 0.430597\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064864; batch adversarial loss: 0.411313\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074901; batch adversarial loss: 0.420997\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093434; batch adversarial loss: 0.413521\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067070; batch adversarial loss: 0.392107\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061067; batch adversarial loss: 0.410661\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055023; batch adversarial loss: 0.405778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044209; batch adversarial loss: 0.422735\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042058; batch adversarial loss: 0.465948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041200; batch adversarial loss: 0.429990\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051490; batch adversarial loss: 0.397572\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059611; batch adversarial loss: 0.372987\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034531; batch adversarial loss: 0.522082\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061490; batch adversarial loss: 0.401577\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066456; batch adversarial loss: 0.415618\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051781; batch adversarial loss: 0.518109\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060666; batch adversarial loss: 0.440497\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050722; batch adversarial loss: 0.409595\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044524; batch adversarial loss: 0.467429\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080651; batch adversarial loss: 0.441077\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025691; batch adversarial loss: 0.488456\n",
      "epoch 121; iter: 0; batch classifier loss: 0.103893; batch adversarial loss: 0.369394\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024609; batch adversarial loss: 0.377467\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030616; batch adversarial loss: 0.515365\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036612; batch adversarial loss: 0.485206\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017200; batch adversarial loss: 0.426024\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026384; batch adversarial loss: 0.477164\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039389; batch adversarial loss: 0.444581\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.397190\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025203; batch adversarial loss: 0.368647\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045710; batch adversarial loss: 0.475017\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048092; batch adversarial loss: 0.514290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010425; batch adversarial loss: 0.481070\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027503; batch adversarial loss: 0.461967\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025434; batch adversarial loss: 0.432699\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027468; batch adversarial loss: 0.406912\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031574; batch adversarial loss: 0.539390\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016316; batch adversarial loss: 0.465430\n",
      "epoch 138; iter: 0; batch classifier loss: 0.077262; batch adversarial loss: 0.500766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.061550; batch adversarial loss: 0.442879\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031457; batch adversarial loss: 0.443671\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021000; batch adversarial loss: 0.439818\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037824; batch adversarial loss: 0.440468\n",
      "epoch 143; iter: 0; batch classifier loss: 0.071089; batch adversarial loss: 0.470254\n",
      "epoch 144; iter: 0; batch classifier loss: 0.067227; batch adversarial loss: 0.539416\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.574511\n",
      "epoch 146; iter: 0; batch classifier loss: 0.101157; batch adversarial loss: 0.586858\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035857; batch adversarial loss: 0.560438\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034541; batch adversarial loss: 0.448309\n",
      "epoch 149; iter: 0; batch classifier loss: 0.087614; batch adversarial loss: 0.570426\n",
      "epoch 150; iter: 0; batch classifier loss: 0.101892; batch adversarial loss: 0.683412\n",
      "epoch 151; iter: 0; batch classifier loss: 0.110481; batch adversarial loss: 0.635586\n",
      "epoch 152; iter: 0; batch classifier loss: 0.104236; batch adversarial loss: 0.547634\n",
      "epoch 153; iter: 0; batch classifier loss: 0.120365; batch adversarial loss: 0.657432\n",
      "epoch 154; iter: 0; batch classifier loss: 0.113166; batch adversarial loss: 0.586619\n",
      "epoch 155; iter: 0; batch classifier loss: 0.256659; batch adversarial loss: 0.711068\n",
      "epoch 156; iter: 0; batch classifier loss: 0.123078; batch adversarial loss: 0.598960\n",
      "epoch 157; iter: 0; batch classifier loss: 0.088493; batch adversarial loss: 0.496924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.069158; batch adversarial loss: 0.477679\n",
      "epoch 159; iter: 0; batch classifier loss: 0.181563; batch adversarial loss: 0.641302\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063121; batch adversarial loss: 0.530503\n",
      "epoch 161; iter: 0; batch classifier loss: 0.116110; batch adversarial loss: 0.570648\n",
      "epoch 162; iter: 0; batch classifier loss: 0.155467; batch adversarial loss: 0.485392\n",
      "epoch 163; iter: 0; batch classifier loss: 0.112108; batch adversarial loss: 0.537554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.068940; batch adversarial loss: 0.416772\n",
      "epoch 165; iter: 0; batch classifier loss: 0.088271; batch adversarial loss: 0.516506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.056850; batch adversarial loss: 0.480200\n",
      "epoch 167; iter: 0; batch classifier loss: 0.098796; batch adversarial loss: 0.510267\n",
      "epoch 168; iter: 0; batch classifier loss: 0.128965; batch adversarial loss: 0.684050\n",
      "epoch 169; iter: 0; batch classifier loss: 0.215579; batch adversarial loss: 0.686368\n",
      "epoch 170; iter: 0; batch classifier loss: 0.127821; batch adversarial loss: 0.510562\n",
      "epoch 171; iter: 0; batch classifier loss: 0.215551; batch adversarial loss: 0.699029\n",
      "epoch 172; iter: 0; batch classifier loss: 0.162455; batch adversarial loss: 0.600879\n",
      "epoch 173; iter: 0; batch classifier loss: 0.124410; batch adversarial loss: 0.522797\n",
      "epoch 174; iter: 0; batch classifier loss: 0.107540; batch adversarial loss: 0.529397\n",
      "epoch 175; iter: 0; batch classifier loss: 0.117694; batch adversarial loss: 0.484848\n",
      "epoch 176; iter: 0; batch classifier loss: 0.150069; batch adversarial loss: 0.605937\n",
      "epoch 177; iter: 0; batch classifier loss: 0.153860; batch adversarial loss: 0.535834\n",
      "epoch 178; iter: 0; batch classifier loss: 0.081426; batch adversarial loss: 0.498294\n",
      "epoch 179; iter: 0; batch classifier loss: 0.089369; batch adversarial loss: 0.455588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.126325; batch adversarial loss: 0.570858\n",
      "epoch 181; iter: 0; batch classifier loss: 0.083107; batch adversarial loss: 0.480598\n",
      "epoch 182; iter: 0; batch classifier loss: 0.093002; batch adversarial loss: 0.446662\n",
      "epoch 183; iter: 0; batch classifier loss: 0.080113; batch adversarial loss: 0.454980\n",
      "epoch 184; iter: 0; batch classifier loss: 0.081128; batch adversarial loss: 0.433452\n",
      "epoch 185; iter: 0; batch classifier loss: 0.064971; batch adversarial loss: 0.396012\n",
      "epoch 186; iter: 0; batch classifier loss: 0.100137; batch adversarial loss: 0.460278\n",
      "epoch 187; iter: 0; batch classifier loss: 0.122237; batch adversarial loss: 0.489727\n",
      "epoch 188; iter: 0; batch classifier loss: 0.135691; batch adversarial loss: 0.632834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.098246; batch adversarial loss: 0.446990\n",
      "epoch 190; iter: 0; batch classifier loss: 0.095126; batch adversarial loss: 0.521374\n",
      "epoch 191; iter: 0; batch classifier loss: 0.061742; batch adversarial loss: 0.372729\n",
      "epoch 192; iter: 0; batch classifier loss: 0.119673; batch adversarial loss: 0.461506\n",
      "epoch 193; iter: 0; batch classifier loss: 0.082824; batch adversarial loss: 0.484240\n",
      "epoch 194; iter: 0; batch classifier loss: 0.056033; batch adversarial loss: 0.478380\n",
      "epoch 195; iter: 0; batch classifier loss: 0.101376; batch adversarial loss: 0.421330\n",
      "epoch 196; iter: 0; batch classifier loss: 0.122673; batch adversarial loss: 0.565093\n",
      "epoch 197; iter: 0; batch classifier loss: 0.103368; batch adversarial loss: 0.540199\n",
      "epoch 198; iter: 0; batch classifier loss: 0.059735; batch adversarial loss: 0.423465\n",
      "epoch 199; iter: 0; batch classifier loss: 0.109843; batch adversarial loss: 0.460540\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672668; batch adversarial loss: 0.768097\n",
      "epoch 1; iter: 0; batch classifier loss: 0.379022; batch adversarial loss: 0.785950\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420780; batch adversarial loss: 0.750941\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318740; batch adversarial loss: 0.727473\n",
      "epoch 4; iter: 0; batch classifier loss: 0.428025; batch adversarial loss: 0.676756\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350557; batch adversarial loss: 0.632961\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323426; batch adversarial loss: 0.578708\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306518; batch adversarial loss: 0.585272\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253036; batch adversarial loss: 0.584881\n",
      "epoch 9; iter: 0; batch classifier loss: 0.263976; batch adversarial loss: 0.524728\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273827; batch adversarial loss: 0.508397\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225913; batch adversarial loss: 0.470638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308322; batch adversarial loss: 0.495007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215514; batch adversarial loss: 0.520244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218061; batch adversarial loss: 0.435064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256036; batch adversarial loss: 0.482523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.201475; batch adversarial loss: 0.405055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.165246; batch adversarial loss: 0.437593\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190735; batch adversarial loss: 0.464584\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253140; batch adversarial loss: 0.401021\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172527; batch adversarial loss: 0.417191\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200224; batch adversarial loss: 0.432918\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235423; batch adversarial loss: 0.389875\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214230; batch adversarial loss: 0.387125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158226; batch adversarial loss: 0.400012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171544; batch adversarial loss: 0.391994\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169929; batch adversarial loss: 0.333933\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177766; batch adversarial loss: 0.392594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168364; batch adversarial loss: 0.440397\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135039; batch adversarial loss: 0.335288\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148244; batch adversarial loss: 0.448545\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141922; batch adversarial loss: 0.362345\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159365; batch adversarial loss: 0.426053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112402; batch adversarial loss: 0.373450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159049; batch adversarial loss: 0.325683\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140164; batch adversarial loss: 0.473853\n",
      "epoch 36; iter: 0; batch classifier loss: 0.177415; batch adversarial loss: 0.417920\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132853; batch adversarial loss: 0.367491\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097971; batch adversarial loss: 0.419174\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116558; batch adversarial loss: 0.392430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.162414; batch adversarial loss: 0.381391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108740; batch adversarial loss: 0.386640\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120439; batch adversarial loss: 0.471933\n",
      "epoch 43; iter: 0; batch classifier loss: 0.175900; batch adversarial loss: 0.395853\n",
      "epoch 44; iter: 0; batch classifier loss: 0.067342; batch adversarial loss: 0.405441\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085505; batch adversarial loss: 0.365318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161315; batch adversarial loss: 0.410565\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089830; batch adversarial loss: 0.380268\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107544; batch adversarial loss: 0.429082\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076727; batch adversarial loss: 0.346227\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097571; batch adversarial loss: 0.426457\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135511; batch adversarial loss: 0.350463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073886; batch adversarial loss: 0.507702\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079482; batch adversarial loss: 0.504138\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084459; batch adversarial loss: 0.409586\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091311; batch adversarial loss: 0.440260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.097897; batch adversarial loss: 0.447251\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077831; batch adversarial loss: 0.415107\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077830; batch adversarial loss: 0.382548\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067794; batch adversarial loss: 0.576957\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086950; batch adversarial loss: 0.457679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089107; batch adversarial loss: 0.441486\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071841; batch adversarial loss: 0.423028\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076521; batch adversarial loss: 0.367377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076003; batch adversarial loss: 0.388309\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110250; batch adversarial loss: 0.358315\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092573; batch adversarial loss: 0.308743\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056170; batch adversarial loss: 0.414248\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070565; batch adversarial loss: 0.339007\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075092; batch adversarial loss: 0.486398\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074307; batch adversarial loss: 0.403849\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081211; batch adversarial loss: 0.410669\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083136; batch adversarial loss: 0.447796\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059432; batch adversarial loss: 0.339861\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046094; batch adversarial loss: 0.463767\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058293; batch adversarial loss: 0.417244\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109376; batch adversarial loss: 0.379621\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087498; batch adversarial loss: 0.424925\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053904; batch adversarial loss: 0.437992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047429; batch adversarial loss: 0.504850\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068194; batch adversarial loss: 0.462907\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087692; batch adversarial loss: 0.474777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065344; batch adversarial loss: 0.440170\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072368; batch adversarial loss: 0.362737\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082594; batch adversarial loss: 0.362777\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090658; batch adversarial loss: 0.390682\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065030; batch adversarial loss: 0.312164\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047158; batch adversarial loss: 0.469623\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.425757\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081607; batch adversarial loss: 0.387698\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052917; batch adversarial loss: 0.480162\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052503; batch adversarial loss: 0.448748\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048435; batch adversarial loss: 0.352942\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040049; batch adversarial loss: 0.321156\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062978; batch adversarial loss: 0.433526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107707; batch adversarial loss: 0.507814\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050799; batch adversarial loss: 0.340459\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047821; batch adversarial loss: 0.447763\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044941; batch adversarial loss: 0.451389\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058797; batch adversarial loss: 0.392162\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039652; batch adversarial loss: 0.344201\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051596; batch adversarial loss: 0.411874\n",
      "epoch 102; iter: 0; batch classifier loss: 0.045638; batch adversarial loss: 0.427834\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.326482\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063565; batch adversarial loss: 0.381106\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031763; batch adversarial loss: 0.394920\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034520; batch adversarial loss: 0.452218\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020898; batch adversarial loss: 0.434266\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073594; batch adversarial loss: 0.398028\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050021; batch adversarial loss: 0.333582\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026207; batch adversarial loss: 0.390840\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022852; batch adversarial loss: 0.326013\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055925; batch adversarial loss: 0.413983\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027625; batch adversarial loss: 0.389695\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023379; batch adversarial loss: 0.497976\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013760; batch adversarial loss: 0.443770\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.475189\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024970; batch adversarial loss: 0.438331\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047077; batch adversarial loss: 0.377212\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030823; batch adversarial loss: 0.506762\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060630; batch adversarial loss: 0.486557\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026753; batch adversarial loss: 0.418890\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062037; batch adversarial loss: 0.403713\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088939; batch adversarial loss: 0.562846\n",
      "epoch 124; iter: 0; batch classifier loss: 0.106210; batch adversarial loss: 0.563449\n",
      "epoch 125; iter: 0; batch classifier loss: 0.079812; batch adversarial loss: 0.649027\n",
      "epoch 126; iter: 0; batch classifier loss: 0.134721; batch adversarial loss: 0.790136\n",
      "epoch 127; iter: 0; batch classifier loss: 0.103081; batch adversarial loss: 0.547242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.135733; batch adversarial loss: 0.626869\n",
      "epoch 129; iter: 0; batch classifier loss: 0.069478; batch adversarial loss: 0.559416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.133764; batch adversarial loss: 0.706507\n",
      "epoch 131; iter: 0; batch classifier loss: 0.111057; batch adversarial loss: 0.583735\n",
      "epoch 132; iter: 0; batch classifier loss: 0.122853; batch adversarial loss: 0.632827\n",
      "epoch 133; iter: 0; batch classifier loss: 0.133813; batch adversarial loss: 0.550679\n",
      "epoch 134; iter: 0; batch classifier loss: 0.246962; batch adversarial loss: 0.810863\n",
      "epoch 135; iter: 0; batch classifier loss: 0.104857; batch adversarial loss: 0.484816\n",
      "epoch 136; iter: 0; batch classifier loss: 0.196680; batch adversarial loss: 0.677948\n",
      "epoch 137; iter: 0; batch classifier loss: 0.132520; batch adversarial loss: 0.681954\n",
      "epoch 138; iter: 0; batch classifier loss: 0.156014; batch adversarial loss: 0.555321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.231919; batch adversarial loss: 0.756527\n",
      "epoch 140; iter: 0; batch classifier loss: 0.156605; batch adversarial loss: 0.598866\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069881; batch adversarial loss: 0.383797\n",
      "epoch 142; iter: 0; batch classifier loss: 0.189110; batch adversarial loss: 0.698670\n",
      "epoch 143; iter: 0; batch classifier loss: 0.196231; batch adversarial loss: 0.615054\n",
      "epoch 144; iter: 0; batch classifier loss: 0.112643; batch adversarial loss: 0.522370\n",
      "epoch 145; iter: 0; batch classifier loss: 0.187500; batch adversarial loss: 0.661436\n",
      "epoch 146; iter: 0; batch classifier loss: 0.122148; batch adversarial loss: 0.667113\n",
      "epoch 147; iter: 0; batch classifier loss: 0.146341; batch adversarial loss: 0.624931\n",
      "epoch 148; iter: 0; batch classifier loss: 0.143400; batch adversarial loss: 0.567817\n",
      "epoch 149; iter: 0; batch classifier loss: 0.135769; batch adversarial loss: 0.504943\n",
      "epoch 150; iter: 0; batch classifier loss: 0.177226; batch adversarial loss: 0.604975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.079760; batch adversarial loss: 0.362553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.088706; batch adversarial loss: 0.454429\n",
      "epoch 153; iter: 0; batch classifier loss: 0.150177; batch adversarial loss: 0.594405\n",
      "epoch 154; iter: 0; batch classifier loss: 0.122195; batch adversarial loss: 0.527269\n",
      "epoch 155; iter: 0; batch classifier loss: 0.104401; batch adversarial loss: 0.487850\n",
      "epoch 156; iter: 0; batch classifier loss: 0.162329; batch adversarial loss: 0.582382\n",
      "epoch 157; iter: 0; batch classifier loss: 0.144451; batch adversarial loss: 0.503686\n",
      "epoch 158; iter: 0; batch classifier loss: 0.115216; batch adversarial loss: 0.457169\n",
      "epoch 159; iter: 0; batch classifier loss: 0.140747; batch adversarial loss: 0.505435\n",
      "epoch 160; iter: 0; batch classifier loss: 0.088054; batch adversarial loss: 0.443790\n",
      "epoch 161; iter: 0; batch classifier loss: 0.127607; batch adversarial loss: 0.596808\n",
      "epoch 162; iter: 0; batch classifier loss: 0.107105; batch adversarial loss: 0.456227\n",
      "epoch 163; iter: 0; batch classifier loss: 0.134574; batch adversarial loss: 0.562482\n",
      "epoch 164; iter: 0; batch classifier loss: 0.188043; batch adversarial loss: 0.590304\n",
      "epoch 165; iter: 0; batch classifier loss: 0.079028; batch adversarial loss: 0.563099\n",
      "epoch 166; iter: 0; batch classifier loss: 0.080559; batch adversarial loss: 0.379541\n",
      "epoch 167; iter: 0; batch classifier loss: 0.095113; batch adversarial loss: 0.475830\n",
      "epoch 168; iter: 0; batch classifier loss: 0.068554; batch adversarial loss: 0.407495\n",
      "epoch 169; iter: 0; batch classifier loss: 0.103618; batch adversarial loss: 0.468319\n",
      "epoch 170; iter: 0; batch classifier loss: 0.094654; batch adversarial loss: 0.503978\n",
      "epoch 171; iter: 0; batch classifier loss: 0.077619; batch adversarial loss: 0.425739\n",
      "epoch 172; iter: 0; batch classifier loss: 0.121543; batch adversarial loss: 0.498201\n",
      "epoch 173; iter: 0; batch classifier loss: 0.070682; batch adversarial loss: 0.435692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.432292\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028542; batch adversarial loss: 0.420997\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.528636\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.431956\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026271; batch adversarial loss: 0.566711\n",
      "epoch 179; iter: 0; batch classifier loss: 0.047783; batch adversarial loss: 0.504341\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037344; batch adversarial loss: 0.465566\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025200; batch adversarial loss: 0.368667\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027697; batch adversarial loss: 0.476979\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021274; batch adversarial loss: 0.455583\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033188; batch adversarial loss: 0.499799\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044511; batch adversarial loss: 0.559052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030482; batch adversarial loss: 0.421997\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032360; batch adversarial loss: 0.467506\n",
      "epoch 188; iter: 0; batch classifier loss: 0.110496; batch adversarial loss: 0.470453\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053027; batch adversarial loss: 0.370057\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039477; batch adversarial loss: 0.427732\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030346; batch adversarial loss: 0.432808\n",
      "epoch 192; iter: 0; batch classifier loss: 0.066746; batch adversarial loss: 0.517155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.073402; batch adversarial loss: 0.481602\n",
      "epoch 194; iter: 0; batch classifier loss: 0.053801; batch adversarial loss: 0.504600\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044526; batch adversarial loss: 0.449580\n",
      "epoch 196; iter: 0; batch classifier loss: 0.063511; batch adversarial loss: 0.420008\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045892; batch adversarial loss: 0.422276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.108660; batch adversarial loss: 0.404252\n",
      "epoch 199; iter: 0; batch classifier loss: 0.140414; batch adversarial loss: 0.379481\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710030; batch adversarial loss: 0.635391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.401261; batch adversarial loss: 0.628018\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396854; batch adversarial loss: 0.598874\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330387; batch adversarial loss: 0.597461\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349221; batch adversarial loss: 0.555281\n",
      "epoch 5; iter: 0; batch classifier loss: 0.241761; batch adversarial loss: 0.545006\n",
      "epoch 6; iter: 0; batch classifier loss: 0.259250; batch adversarial loss: 0.556606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284401; batch adversarial loss: 0.543340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.229660; batch adversarial loss: 0.463847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286297; batch adversarial loss: 0.533265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.198784; batch adversarial loss: 0.452135\n",
      "epoch 11; iter: 0; batch classifier loss: 0.188242; batch adversarial loss: 0.501765\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256664; batch adversarial loss: 0.545895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278362; batch adversarial loss: 0.531158\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238362; batch adversarial loss: 0.489231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.160731; batch adversarial loss: 0.523732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324605; batch adversarial loss: 0.569989\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172129; batch adversarial loss: 0.465170\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147418; batch adversarial loss: 0.453379\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219828; batch adversarial loss: 0.467455\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184253; batch adversarial loss: 0.546802\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205704; batch adversarial loss: 0.479993\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200818; batch adversarial loss: 0.491236\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235678; batch adversarial loss: 0.483363\n",
      "epoch 24; iter: 0; batch classifier loss: 0.359115; batch adversarial loss: 0.540256\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384296; batch adversarial loss: 0.504154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424615; batch adversarial loss: 0.499080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358407; batch adversarial loss: 0.462343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.251708; batch adversarial loss: 0.529441\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162588; batch adversarial loss: 0.519444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148871; batch adversarial loss: 0.371046\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124585; batch adversarial loss: 0.466475\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135897; batch adversarial loss: 0.467288\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123427; batch adversarial loss: 0.384763\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143549; batch adversarial loss: 0.473781\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120488; batch adversarial loss: 0.427479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133261; batch adversarial loss: 0.509038\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175355; batch adversarial loss: 0.445486\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113881; batch adversarial loss: 0.464109\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138383; batch adversarial loss: 0.366585\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130673; batch adversarial loss: 0.489868\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156574; batch adversarial loss: 0.458448\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086652; batch adversarial loss: 0.396137\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078251; batch adversarial loss: 0.496218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121475; batch adversarial loss: 0.431083\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142149; batch adversarial loss: 0.407548\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126147; batch adversarial loss: 0.417677\n",
      "epoch 47; iter: 0; batch classifier loss: 0.140003; batch adversarial loss: 0.495549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.140690; batch adversarial loss: 0.461487\n",
      "epoch 49; iter: 0; batch classifier loss: 0.140338; batch adversarial loss: 0.469002\n",
      "epoch 50; iter: 0; batch classifier loss: 0.144225; batch adversarial loss: 0.451689\n",
      "epoch 51; iter: 0; batch classifier loss: 0.127160; batch adversarial loss: 0.386113\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106647; batch adversarial loss: 0.433281\n",
      "epoch 53; iter: 0; batch classifier loss: 0.197200; batch adversarial loss: 0.456064\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112276; batch adversarial loss: 0.506835\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108173; batch adversarial loss: 0.446544\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120631; batch adversarial loss: 0.479879\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100356; batch adversarial loss: 0.431450\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130394; batch adversarial loss: 0.497874\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143439; batch adversarial loss: 0.518248\n",
      "epoch 60; iter: 0; batch classifier loss: 0.133278; batch adversarial loss: 0.470269\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113693; batch adversarial loss: 0.438139\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121740; batch adversarial loss: 0.397270\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131335; batch adversarial loss: 0.483145\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106162; batch adversarial loss: 0.440386\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106206; batch adversarial loss: 0.531184\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107810; batch adversarial loss: 0.405370\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122232; batch adversarial loss: 0.436268\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125075; batch adversarial loss: 0.483521\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076674; batch adversarial loss: 0.452796\n",
      "epoch 70; iter: 0; batch classifier loss: 0.092737; batch adversarial loss: 0.372271\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085937; batch adversarial loss: 0.531628\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129756; batch adversarial loss: 0.432663\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135510; batch adversarial loss: 0.408678\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160716; batch adversarial loss: 0.490457\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141894; batch adversarial loss: 0.482715\n",
      "epoch 76; iter: 0; batch classifier loss: 0.140297; batch adversarial loss: 0.538504\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086313; batch adversarial loss: 0.472523\n",
      "epoch 78; iter: 0; batch classifier loss: 0.133505; batch adversarial loss: 0.490818\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078424; batch adversarial loss: 0.418189\n",
      "epoch 80; iter: 0; batch classifier loss: 0.123853; batch adversarial loss: 0.427629\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066615; batch adversarial loss: 0.347321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.117100; batch adversarial loss: 0.529384\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121939; batch adversarial loss: 0.444795\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084541; batch adversarial loss: 0.414262\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088708; batch adversarial loss: 0.451618\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108089; batch adversarial loss: 0.408563\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099542; batch adversarial loss: 0.425698\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071916; batch adversarial loss: 0.512782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081951; batch adversarial loss: 0.393594\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075762; batch adversarial loss: 0.413286\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076385; batch adversarial loss: 0.499425\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057826; batch adversarial loss: 0.476885\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136090; batch adversarial loss: 0.398595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.108740; batch adversarial loss: 0.389477\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054184; batch adversarial loss: 0.553830\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046528; batch adversarial loss: 0.502271\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069629; batch adversarial loss: 0.469833\n",
      "epoch 98; iter: 0; batch classifier loss: 0.123859; batch adversarial loss: 0.404388\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042284; batch adversarial loss: 0.462147\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088639; batch adversarial loss: 0.375656\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057645; batch adversarial loss: 0.427620\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078625; batch adversarial loss: 0.428506\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056128; batch adversarial loss: 0.552364\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047937; batch adversarial loss: 0.442901\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055778; batch adversarial loss: 0.504711\n",
      "epoch 106; iter: 0; batch classifier loss: 0.098817; batch adversarial loss: 0.421376\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070730; batch adversarial loss: 0.488196\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058012; batch adversarial loss: 0.430077\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050238; batch adversarial loss: 0.427795\n",
      "epoch 110; iter: 0; batch classifier loss: 0.113012; batch adversarial loss: 0.485615\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074717; batch adversarial loss: 0.485536\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027741; batch adversarial loss: 0.467284\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028661; batch adversarial loss: 0.440880\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049588; batch adversarial loss: 0.447198\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062681; batch adversarial loss: 0.381524\n",
      "epoch 116; iter: 0; batch classifier loss: 0.064637; batch adversarial loss: 0.442367\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048782; batch adversarial loss: 0.485241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048355; batch adversarial loss: 0.482605\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041799; batch adversarial loss: 0.460127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053511; batch adversarial loss: 0.448053\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026838; batch adversarial loss: 0.552343\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019087; batch adversarial loss: 0.431027\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035930; batch adversarial loss: 0.475550\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035040; batch adversarial loss: 0.523455\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062166; batch adversarial loss: 0.483743\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031494; batch adversarial loss: 0.490813\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019668; batch adversarial loss: 0.411537\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034724; batch adversarial loss: 0.418485\n",
      "epoch 129; iter: 0; batch classifier loss: 0.010587; batch adversarial loss: 0.408946\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062331; batch adversarial loss: 0.391047\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047367; batch adversarial loss: 0.499800\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010242; batch adversarial loss: 0.448354\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020556; batch adversarial loss: 0.488236\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029473; batch adversarial loss: 0.373053\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039428; batch adversarial loss: 0.474645\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015416; batch adversarial loss: 0.488934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025812; batch adversarial loss: 0.393638\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023093; batch adversarial loss: 0.418792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050076; batch adversarial loss: 0.468157\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031357; batch adversarial loss: 0.398232\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044603; batch adversarial loss: 0.418249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020761; batch adversarial loss: 0.390816\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035996; batch adversarial loss: 0.448418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.035402; batch adversarial loss: 0.457797\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045006; batch adversarial loss: 0.471391\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032911; batch adversarial loss: 0.443031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024072; batch adversarial loss: 0.446609\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038639; batch adversarial loss: 0.434049\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029411; batch adversarial loss: 0.462142\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052927; batch adversarial loss: 0.449051\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027150; batch adversarial loss: 0.451877\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062550; batch adversarial loss: 0.476018\n",
      "epoch 153; iter: 0; batch classifier loss: 0.061641; batch adversarial loss: 0.486528\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036498; batch adversarial loss: 0.415615\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.527957\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028222; batch adversarial loss: 0.478008\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018849; batch adversarial loss: 0.442456\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013579; batch adversarial loss: 0.484261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025298; batch adversarial loss: 0.501937\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030348; batch adversarial loss: 0.501039\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034717; batch adversarial loss: 0.472024\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024128; batch adversarial loss: 0.386464\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027717; batch adversarial loss: 0.445832\n",
      "epoch 164; iter: 0; batch classifier loss: 0.068843; batch adversarial loss: 0.435860\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014284; batch adversarial loss: 0.431918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013371; batch adversarial loss: 0.490122\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008976; batch adversarial loss: 0.421884\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038870; batch adversarial loss: 0.427238\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018749; batch adversarial loss: 0.454079\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046517; batch adversarial loss: 0.460612\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044506; batch adversarial loss: 0.384070\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010765; batch adversarial loss: 0.481080\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035446; batch adversarial loss: 0.494854\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025039; batch adversarial loss: 0.403847\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015469; batch adversarial loss: 0.429202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010530; batch adversarial loss: 0.479641\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037719; batch adversarial loss: 0.528922\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024880; batch adversarial loss: 0.470908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014354; batch adversarial loss: 0.504559\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035064; batch adversarial loss: 0.421580\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024067; batch adversarial loss: 0.465687\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011634; batch adversarial loss: 0.556455\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021956; batch adversarial loss: 0.484645\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030652; batch adversarial loss: 0.525346\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014900; batch adversarial loss: 0.452648\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014069; batch adversarial loss: 0.474676\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009228; batch adversarial loss: 0.493336\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024678; batch adversarial loss: 0.450697\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044636; batch adversarial loss: 0.406085\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025823; batch adversarial loss: 0.387570\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010215; batch adversarial loss: 0.387493\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023039; batch adversarial loss: 0.447147\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040410; batch adversarial loss: 0.436200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036313; batch adversarial loss: 0.465101\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022430; batch adversarial loss: 0.379132\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021788; batch adversarial loss: 0.457156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027547; batch adversarial loss: 0.519939\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023430; batch adversarial loss: 0.362349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011390; batch adversarial loss: 0.427570\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707945; batch adversarial loss: 0.562488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522545; batch adversarial loss: 0.598510\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383670; batch adversarial loss: 0.622437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380028; batch adversarial loss: 0.628905\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295707; batch adversarial loss: 0.544067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409233; batch adversarial loss: 0.568878\n",
      "epoch 6; iter: 0; batch classifier loss: 0.352652; batch adversarial loss: 0.635722\n",
      "epoch 7; iter: 0; batch classifier loss: 0.425664; batch adversarial loss: 0.608250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361077; batch adversarial loss: 0.580540\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520686; batch adversarial loss: 0.560742\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574727; batch adversarial loss: 0.557171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595038; batch adversarial loss: 0.573425\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487714; batch adversarial loss: 0.572178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395552; batch adversarial loss: 0.452479\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376623; batch adversarial loss: 0.498455\n",
      "epoch 15; iter: 0; batch classifier loss: 0.299567; batch adversarial loss: 0.485033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261325; batch adversarial loss: 0.469953\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281714; batch adversarial loss: 0.458660\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237922; batch adversarial loss: 0.569583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206977; batch adversarial loss: 0.509282\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200358; batch adversarial loss: 0.455856\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262154; batch adversarial loss: 0.420304\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245776; batch adversarial loss: 0.484808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196649; batch adversarial loss: 0.454102\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307268; batch adversarial loss: 0.458517\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180518; batch adversarial loss: 0.470168\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187154; batch adversarial loss: 0.511432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174737; batch adversarial loss: 0.387512\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127784; batch adversarial loss: 0.512376\n",
      "epoch 29; iter: 0; batch classifier loss: 0.201530; batch adversarial loss: 0.426664\n",
      "epoch 30; iter: 0; batch classifier loss: 0.251946; batch adversarial loss: 0.377298\n",
      "epoch 31; iter: 0; batch classifier loss: 0.203307; batch adversarial loss: 0.484505\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149375; batch adversarial loss: 0.440439\n",
      "epoch 33; iter: 0; batch classifier loss: 0.104185; batch adversarial loss: 0.442669\n",
      "epoch 34; iter: 0; batch classifier loss: 0.169262; batch adversarial loss: 0.415948\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146056; batch adversarial loss: 0.477763\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169257; batch adversarial loss: 0.487547\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147339; batch adversarial loss: 0.419154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164685; batch adversarial loss: 0.455019\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129245; batch adversarial loss: 0.500884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.123521; batch adversarial loss: 0.469333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150287; batch adversarial loss: 0.484502\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169444; batch adversarial loss: 0.470082\n",
      "epoch 43; iter: 0; batch classifier loss: 0.144459; batch adversarial loss: 0.460786\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129223; batch adversarial loss: 0.566692\n",
      "epoch 45; iter: 0; batch classifier loss: 0.162528; batch adversarial loss: 0.451002\n",
      "epoch 46; iter: 0; batch classifier loss: 0.217923; batch adversarial loss: 0.471418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.189385; batch adversarial loss: 0.452992\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109486; batch adversarial loss: 0.398432\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135655; batch adversarial loss: 0.430801\n",
      "epoch 50; iter: 0; batch classifier loss: 0.233514; batch adversarial loss: 0.381732\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173001; batch adversarial loss: 0.458523\n",
      "epoch 52; iter: 0; batch classifier loss: 0.176050; batch adversarial loss: 0.411297\n",
      "epoch 53; iter: 0; batch classifier loss: 0.167646; batch adversarial loss: 0.484331\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108744; batch adversarial loss: 0.517053\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128634; batch adversarial loss: 0.498006\n",
      "epoch 56; iter: 0; batch classifier loss: 0.125940; batch adversarial loss: 0.484601\n",
      "epoch 57; iter: 0; batch classifier loss: 0.181324; batch adversarial loss: 0.445682\n",
      "epoch 58; iter: 0; batch classifier loss: 0.186834; batch adversarial loss: 0.515621\n",
      "epoch 59; iter: 0; batch classifier loss: 0.243230; batch adversarial loss: 0.439840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155273; batch adversarial loss: 0.487666\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118855; batch adversarial loss: 0.510331\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120069; batch adversarial loss: 0.427891\n",
      "epoch 63; iter: 0; batch classifier loss: 0.188768; batch adversarial loss: 0.477966\n",
      "epoch 64; iter: 0; batch classifier loss: 0.163088; batch adversarial loss: 0.516971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.179693; batch adversarial loss: 0.459167\n",
      "epoch 66; iter: 0; batch classifier loss: 0.174046; batch adversarial loss: 0.441510\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156086; batch adversarial loss: 0.460525\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176970; batch adversarial loss: 0.472825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.178590; batch adversarial loss: 0.310145\n",
      "epoch 70; iter: 0; batch classifier loss: 0.154060; batch adversarial loss: 0.398969\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115926; batch adversarial loss: 0.431514\n",
      "epoch 72; iter: 0; batch classifier loss: 0.152116; batch adversarial loss: 0.434760\n",
      "epoch 73; iter: 0; batch classifier loss: 0.141154; batch adversarial loss: 0.409679\n",
      "epoch 74; iter: 0; batch classifier loss: 0.127816; batch adversarial loss: 0.470260\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112839; batch adversarial loss: 0.495626\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108308; batch adversarial loss: 0.370505\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136613; batch adversarial loss: 0.496183\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136558; batch adversarial loss: 0.459553\n",
      "epoch 79; iter: 0; batch classifier loss: 0.193472; batch adversarial loss: 0.472341\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090191; batch adversarial loss: 0.421563\n",
      "epoch 81; iter: 0; batch classifier loss: 0.156152; batch adversarial loss: 0.508867\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178697; batch adversarial loss: 0.508214\n",
      "epoch 83; iter: 0; batch classifier loss: 0.138406; batch adversarial loss: 0.469102\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141140; batch adversarial loss: 0.530751\n",
      "epoch 85; iter: 0; batch classifier loss: 0.144398; batch adversarial loss: 0.371149\n",
      "epoch 86; iter: 0; batch classifier loss: 0.162608; batch adversarial loss: 0.422903\n",
      "epoch 87; iter: 0; batch classifier loss: 0.143627; batch adversarial loss: 0.471298\n",
      "epoch 88; iter: 0; batch classifier loss: 0.105015; batch adversarial loss: 0.532952\n",
      "epoch 89; iter: 0; batch classifier loss: 0.140998; batch adversarial loss: 0.519459\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119279; batch adversarial loss: 0.431252\n",
      "epoch 91; iter: 0; batch classifier loss: 0.137378; batch adversarial loss: 0.530682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.202794; batch adversarial loss: 0.296944\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201137; batch adversarial loss: 0.372126\n",
      "epoch 94; iter: 0; batch classifier loss: 0.147620; batch adversarial loss: 0.473765\n",
      "epoch 95; iter: 0; batch classifier loss: 0.142798; batch adversarial loss: 0.531602\n",
      "epoch 96; iter: 0; batch classifier loss: 0.192969; batch adversarial loss: 0.458318\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126104; batch adversarial loss: 0.368845\n",
      "epoch 98; iter: 0; batch classifier loss: 0.166561; batch adversarial loss: 0.455991\n",
      "epoch 99; iter: 0; batch classifier loss: 0.128584; batch adversarial loss: 0.384462\n",
      "epoch 100; iter: 0; batch classifier loss: 0.184256; batch adversarial loss: 0.309711\n",
      "epoch 101; iter: 0; batch classifier loss: 0.149405; batch adversarial loss: 0.447827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.114027; batch adversarial loss: 0.507284\n",
      "epoch 103; iter: 0; batch classifier loss: 0.133741; batch adversarial loss: 0.409163\n",
      "epoch 104; iter: 0; batch classifier loss: 0.182148; batch adversarial loss: 0.385083\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117612; batch adversarial loss: 0.421324\n",
      "epoch 106; iter: 0; batch classifier loss: 0.104634; batch adversarial loss: 0.485350\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131431; batch adversarial loss: 0.455700\n",
      "epoch 108; iter: 0; batch classifier loss: 0.088144; batch adversarial loss: 0.420934\n",
      "epoch 109; iter: 0; batch classifier loss: 0.096041; batch adversarial loss: 0.420609\n",
      "epoch 110; iter: 0; batch classifier loss: 0.139563; batch adversarial loss: 0.383331\n",
      "epoch 111; iter: 0; batch classifier loss: 0.093150; batch adversarial loss: 0.437721\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116392; batch adversarial loss: 0.483127\n",
      "epoch 113; iter: 0; batch classifier loss: 0.101448; batch adversarial loss: 0.454226\n",
      "epoch 114; iter: 0; batch classifier loss: 0.097712; batch adversarial loss: 0.520857\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070137; batch adversarial loss: 0.380335\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034546; batch adversarial loss: 0.407630\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047679; batch adversarial loss: 0.426653\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085176; batch adversarial loss: 0.456378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072486; batch adversarial loss: 0.601632\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060656; batch adversarial loss: 0.445679\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074468; batch adversarial loss: 0.377611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062432; batch adversarial loss: 0.438846\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055237; batch adversarial loss: 0.528830\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071847; batch adversarial loss: 0.498553\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033303; batch adversarial loss: 0.405520\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057324; batch adversarial loss: 0.357020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053128; batch adversarial loss: 0.380222\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032880; batch adversarial loss: 0.422014\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025545; batch adversarial loss: 0.376591\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053038; batch adversarial loss: 0.464776\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068620; batch adversarial loss: 0.502698\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019403; batch adversarial loss: 0.470080\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027687; batch adversarial loss: 0.485465\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038096; batch adversarial loss: 0.564168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029954; batch adversarial loss: 0.413270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.023264; batch adversarial loss: 0.461710\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018905; batch adversarial loss: 0.505158\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040682; batch adversarial loss: 0.492831\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037850; batch adversarial loss: 0.438972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027931; batch adversarial loss: 0.454990\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036583; batch adversarial loss: 0.429166\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060560; batch adversarial loss: 0.408097\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016449; batch adversarial loss: 0.511876\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024588; batch adversarial loss: 0.425483\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028172; batch adversarial loss: 0.401014\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.454901\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026070; batch adversarial loss: 0.466223\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048576; batch adversarial loss: 0.482895\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024013; batch adversarial loss: 0.441143\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015191; batch adversarial loss: 0.511612\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.485316\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023159; batch adversarial loss: 0.429251\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038430; batch adversarial loss: 0.462898\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031927; batch adversarial loss: 0.456329\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010069; batch adversarial loss: 0.483935\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012882; batch adversarial loss: 0.436878\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050454; batch adversarial loss: 0.325697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.421737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017345; batch adversarial loss: 0.428979\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013187; batch adversarial loss: 0.389488\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025342; batch adversarial loss: 0.436032\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011224; batch adversarial loss: 0.427776\n",
      "epoch 163; iter: 0; batch classifier loss: 0.067088; batch adversarial loss: 0.420277\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029054; batch adversarial loss: 0.397136\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017095; batch adversarial loss: 0.480261\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021321; batch adversarial loss: 0.452651\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009573; batch adversarial loss: 0.460653\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012348; batch adversarial loss: 0.424764\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.401399\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045187; batch adversarial loss: 0.386823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015570; batch adversarial loss: 0.509252\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010755; batch adversarial loss: 0.462906\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018772; batch adversarial loss: 0.429172\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006931; batch adversarial loss: 0.377633\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016534; batch adversarial loss: 0.378878\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009102; batch adversarial loss: 0.416025\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029074; batch adversarial loss: 0.380267\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023513; batch adversarial loss: 0.417455\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.526446\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018475; batch adversarial loss: 0.383100\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033544; batch adversarial loss: 0.467391\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009247; batch adversarial loss: 0.418756\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014443; batch adversarial loss: 0.457136\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012615; batch adversarial loss: 0.447406\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012701; batch adversarial loss: 0.414039\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013659; batch adversarial loss: 0.532367\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025546; batch adversarial loss: 0.449478\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006176; batch adversarial loss: 0.421997\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011978; batch adversarial loss: 0.476132\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007226; batch adversarial loss: 0.460886\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005540; batch adversarial loss: 0.501813\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006595; batch adversarial loss: 0.482141\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026476; batch adversarial loss: 0.410862\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.555748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006630; batch adversarial loss: 0.445385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014089; batch adversarial loss: 0.394885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024554; batch adversarial loss: 0.404880\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010080; batch adversarial loss: 0.430116\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025757; batch adversarial loss: 0.516776\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711289; batch adversarial loss: 0.483737\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428041; batch adversarial loss: 0.515678\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410604; batch adversarial loss: 0.549358\n",
      "epoch 3; iter: 0; batch classifier loss: 0.354963; batch adversarial loss: 0.583414\n",
      "epoch 4; iter: 0; batch classifier loss: 0.360137; batch adversarial loss: 0.612430\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337488; batch adversarial loss: 0.498453\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365794; batch adversarial loss: 0.579756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393130; batch adversarial loss: 0.560535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.326266; batch adversarial loss: 0.553778\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387503; batch adversarial loss: 0.604559\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370084; batch adversarial loss: 0.541044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451151; batch adversarial loss: 0.494421\n",
      "epoch 12; iter: 0; batch classifier loss: 0.464971; batch adversarial loss: 0.564690\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593817; batch adversarial loss: 0.495996\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543821; batch adversarial loss: 0.504914\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424426; batch adversarial loss: 0.523324\n",
      "epoch 16; iter: 0; batch classifier loss: 0.400626; batch adversarial loss: 0.587938\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221435; batch adversarial loss: 0.437956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.223239; batch adversarial loss: 0.490988\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201307; batch adversarial loss: 0.483728\n",
      "epoch 20; iter: 0; batch classifier loss: 0.190258; batch adversarial loss: 0.387292\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164446; batch adversarial loss: 0.397892\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216624; batch adversarial loss: 0.503562\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211686; batch adversarial loss: 0.418740\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155694; batch adversarial loss: 0.440584\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160146; batch adversarial loss: 0.470510\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285635; batch adversarial loss: 0.405145\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165065; batch adversarial loss: 0.504664\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171236; batch adversarial loss: 0.500295\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133496; batch adversarial loss: 0.499073\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187321; batch adversarial loss: 0.485850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130154; batch adversarial loss: 0.379560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.214524; batch adversarial loss: 0.404353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114577; batch adversarial loss: 0.453638\n",
      "epoch 34; iter: 0; batch classifier loss: 0.121004; batch adversarial loss: 0.481400\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138381; batch adversarial loss: 0.514449\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151125; batch adversarial loss: 0.462165\n",
      "epoch 37; iter: 0; batch classifier loss: 0.098783; batch adversarial loss: 0.425903\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103084; batch adversarial loss: 0.420093\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084471; batch adversarial loss: 0.425340\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096334; batch adversarial loss: 0.499325\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138550; batch adversarial loss: 0.483000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086846; batch adversarial loss: 0.427106\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106160; batch adversarial loss: 0.358921\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141046; batch adversarial loss: 0.417490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081765; batch adversarial loss: 0.502442\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136424; batch adversarial loss: 0.401387\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085523; batch adversarial loss: 0.471675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109565; batch adversarial loss: 0.469644\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093585; batch adversarial loss: 0.364183\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087768; batch adversarial loss: 0.429007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085402; batch adversarial loss: 0.536714\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076814; batch adversarial loss: 0.456630\n",
      "epoch 53; iter: 0; batch classifier loss: 0.069288; batch adversarial loss: 0.569731\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097195; batch adversarial loss: 0.480510\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081746; batch adversarial loss: 0.390832\n",
      "epoch 56; iter: 0; batch classifier loss: 0.144755; batch adversarial loss: 0.484817\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066090; batch adversarial loss: 0.484702\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087210; batch adversarial loss: 0.374532\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103302; batch adversarial loss: 0.420315\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085545; batch adversarial loss: 0.591836\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126024; batch adversarial loss: 0.478672\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086937; batch adversarial loss: 0.428706\n",
      "epoch 63; iter: 0; batch classifier loss: 0.064751; batch adversarial loss: 0.417583\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124079; batch adversarial loss: 0.526204\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071518; batch adversarial loss: 0.445286\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109113; batch adversarial loss: 0.507103\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099902; batch adversarial loss: 0.506896\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093553; batch adversarial loss: 0.489363\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080930; batch adversarial loss: 0.527201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075437; batch adversarial loss: 0.432679\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128465; batch adversarial loss: 0.493356\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079569; batch adversarial loss: 0.496123\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092334; batch adversarial loss: 0.469860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106420; batch adversarial loss: 0.452999\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096062; batch adversarial loss: 0.424397\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122309; batch adversarial loss: 0.360663\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060849; batch adversarial loss: 0.423186\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106128; batch adversarial loss: 0.442980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107448; batch adversarial loss: 0.452098\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082580; batch adversarial loss: 0.578553\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066823; batch adversarial loss: 0.443246\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081017; batch adversarial loss: 0.490627\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080050; batch adversarial loss: 0.439574\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089300; batch adversarial loss: 0.508623\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148722; batch adversarial loss: 0.404206\n",
      "epoch 86; iter: 0; batch classifier loss: 0.096675; batch adversarial loss: 0.548066\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069370; batch adversarial loss: 0.432325\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084073; batch adversarial loss: 0.553563\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050469; batch adversarial loss: 0.380983\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054962; batch adversarial loss: 0.441649\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060218; batch adversarial loss: 0.439128\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105985; batch adversarial loss: 0.453341\n",
      "epoch 93; iter: 0; batch classifier loss: 0.028635; batch adversarial loss: 0.524195\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048128; batch adversarial loss: 0.416585\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064874; batch adversarial loss: 0.452500\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077226; batch adversarial loss: 0.372747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072485; batch adversarial loss: 0.430071\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089525; batch adversarial loss: 0.454517\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085609; batch adversarial loss: 0.428555\n",
      "epoch 100; iter: 0; batch classifier loss: 0.099835; batch adversarial loss: 0.474830\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075111; batch adversarial loss: 0.447944\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037953; batch adversarial loss: 0.416442\n",
      "epoch 103; iter: 0; batch classifier loss: 0.095652; batch adversarial loss: 0.409267\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050379; batch adversarial loss: 0.473314\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040306; batch adversarial loss: 0.517092\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058555; batch adversarial loss: 0.404913\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047648; batch adversarial loss: 0.525307\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078640; batch adversarial loss: 0.439985\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053686; batch adversarial loss: 0.430226\n",
      "epoch 110; iter: 0; batch classifier loss: 0.078723; batch adversarial loss: 0.473625\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041404; batch adversarial loss: 0.388514\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042139; batch adversarial loss: 0.487549\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060083; batch adversarial loss: 0.520899\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073730; batch adversarial loss: 0.402988\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044518; batch adversarial loss: 0.481031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046051; batch adversarial loss: 0.387462\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.496973\n",
      "epoch 118; iter: 0; batch classifier loss: 0.014337; batch adversarial loss: 0.423087\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054140; batch adversarial loss: 0.389812\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054221; batch adversarial loss: 0.382035\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038640; batch adversarial loss: 0.488202\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043876; batch adversarial loss: 0.500687\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031050; batch adversarial loss: 0.462812\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.544785\n",
      "epoch 125; iter: 0; batch classifier loss: 0.102296; batch adversarial loss: 0.389166\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031566; batch adversarial loss: 0.418917\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.450490\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049993; batch adversarial loss: 0.353275\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045002; batch adversarial loss: 0.572974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.021120; batch adversarial loss: 0.487165\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030512; batch adversarial loss: 0.356160\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043694; batch adversarial loss: 0.502532\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012905; batch adversarial loss: 0.481181\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009603; batch adversarial loss: 0.487751\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012016; batch adversarial loss: 0.501518\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017840; batch adversarial loss: 0.464134\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025630; batch adversarial loss: 0.444128\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021237; batch adversarial loss: 0.478314\n",
      "epoch 139; iter: 0; batch classifier loss: 0.074687; batch adversarial loss: 0.404743\n",
      "epoch 140; iter: 0; batch classifier loss: 0.093973; batch adversarial loss: 0.440091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023287; batch adversarial loss: 0.385577\n",
      "epoch 142; iter: 0; batch classifier loss: 0.072167; batch adversarial loss: 0.420714\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015096; batch adversarial loss: 0.476398\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026515; batch adversarial loss: 0.485286\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029056; batch adversarial loss: 0.423334\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.366085\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038093; batch adversarial loss: 0.400330\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013010; batch adversarial loss: 0.464511\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032345; batch adversarial loss: 0.518043\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028684; batch adversarial loss: 0.435055\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021766; batch adversarial loss: 0.506374\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013970; batch adversarial loss: 0.463720\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021847; batch adversarial loss: 0.491477\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.326268\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024248; batch adversarial loss: 0.420189\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018813; batch adversarial loss: 0.428112\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011758; batch adversarial loss: 0.508988\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026241; batch adversarial loss: 0.410369\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016395; batch adversarial loss: 0.473005\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022751; batch adversarial loss: 0.365626\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018726; batch adversarial loss: 0.368731\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026456; batch adversarial loss: 0.416037\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022508; batch adversarial loss: 0.485222\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044751; batch adversarial loss: 0.389543\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008880; batch adversarial loss: 0.472096\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038828; batch adversarial loss: 0.386574\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018311; batch adversarial loss: 0.366750\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026447; batch adversarial loss: 0.410532\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025755; batch adversarial loss: 0.433602\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022515; batch adversarial loss: 0.401745\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046423; batch adversarial loss: 0.434985\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055179; batch adversarial loss: 0.480349\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018703; batch adversarial loss: 0.353875\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004095; batch adversarial loss: 0.378017\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018076; batch adversarial loss: 0.480330\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012441; batch adversarial loss: 0.444443\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017704; batch adversarial loss: 0.411712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005598; batch adversarial loss: 0.489546\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008952; batch adversarial loss: 0.388743\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016206; batch adversarial loss: 0.419676\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034413; batch adversarial loss: 0.322860\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029104; batch adversarial loss: 0.464510\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012130; batch adversarial loss: 0.503058\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007819; batch adversarial loss: 0.413770\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020005; batch adversarial loss: 0.483204\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011615; batch adversarial loss: 0.485802\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035747; batch adversarial loss: 0.385041\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041508; batch adversarial loss: 0.379607\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011905; batch adversarial loss: 0.420821\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006157; batch adversarial loss: 0.552617\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011053; batch adversarial loss: 0.470591\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008064; batch adversarial loss: 0.456155\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010706; batch adversarial loss: 0.352604\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007051; batch adversarial loss: 0.575052\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010275; batch adversarial loss: 0.520898\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037400; batch adversarial loss: 0.361257\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003919; batch adversarial loss: 0.398358\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005070; batch adversarial loss: 0.467819\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013951; batch adversarial loss: 0.443231\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704117; batch adversarial loss: 0.820986\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487843; batch adversarial loss: 0.763601\n",
      "epoch 2; iter: 0; batch classifier loss: 0.513329; batch adversarial loss: 0.733406\n",
      "epoch 3; iter: 0; batch classifier loss: 0.773816; batch adversarial loss: 0.698351\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624786; batch adversarial loss: 0.631785\n",
      "epoch 5; iter: 0; batch classifier loss: 0.487822; batch adversarial loss: 0.613904\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387477; batch adversarial loss: 0.583009\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383120; batch adversarial loss: 0.562382\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474024; batch adversarial loss: 0.549140\n",
      "epoch 9; iter: 0; batch classifier loss: 0.429536; batch adversarial loss: 0.576881\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388581; batch adversarial loss: 0.550852\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404608; batch adversarial loss: 0.546624\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353449; batch adversarial loss: 0.531969\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371098; batch adversarial loss: 0.502891\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287280; batch adversarial loss: 0.504899\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341152; batch adversarial loss: 0.462984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451266; batch adversarial loss: 0.501774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352442; batch adversarial loss: 0.493533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376096; batch adversarial loss: 0.532332\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432741; batch adversarial loss: 0.470283\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314169; batch adversarial loss: 0.443408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387032; batch adversarial loss: 0.512939\n",
      "epoch 22; iter: 0; batch classifier loss: 0.293843; batch adversarial loss: 0.450815\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354483; batch adversarial loss: 0.468854\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377401; batch adversarial loss: 0.486310\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429481; batch adversarial loss: 0.533373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.326372; batch adversarial loss: 0.513656\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341833; batch adversarial loss: 0.458506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291782; batch adversarial loss: 0.465897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244356; batch adversarial loss: 0.561582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324702; batch adversarial loss: 0.408557\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233393; batch adversarial loss: 0.476613\n",
      "epoch 32; iter: 0; batch classifier loss: 0.259459; batch adversarial loss: 0.455691\n",
      "epoch 33; iter: 0; batch classifier loss: 0.238739; batch adversarial loss: 0.485310\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276087; batch adversarial loss: 0.524507\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178193; batch adversarial loss: 0.491700\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344321; batch adversarial loss: 0.464693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.314428; batch adversarial loss: 0.388079\n",
      "epoch 38; iter: 0; batch classifier loss: 0.320879; batch adversarial loss: 0.481871\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354371; batch adversarial loss: 0.367229\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259121; batch adversarial loss: 0.419241\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206648; batch adversarial loss: 0.435495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229841; batch adversarial loss: 0.432787\n",
      "epoch 43; iter: 0; batch classifier loss: 0.256574; batch adversarial loss: 0.480879\n",
      "epoch 44; iter: 0; batch classifier loss: 0.289085; batch adversarial loss: 0.506695\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218373; batch adversarial loss: 0.457527\n",
      "epoch 46; iter: 0; batch classifier loss: 0.277960; batch adversarial loss: 0.502487\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179989; batch adversarial loss: 0.416054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.184926; batch adversarial loss: 0.483275\n",
      "epoch 49; iter: 0; batch classifier loss: 0.231474; batch adversarial loss: 0.435114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.313976; batch adversarial loss: 0.450954\n",
      "epoch 51; iter: 0; batch classifier loss: 0.201586; batch adversarial loss: 0.462338\n",
      "epoch 52; iter: 0; batch classifier loss: 0.246779; batch adversarial loss: 0.376766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169659; batch adversarial loss: 0.448525\n",
      "epoch 54; iter: 0; batch classifier loss: 0.280659; batch adversarial loss: 0.364511\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215188; batch adversarial loss: 0.457373\n",
      "epoch 56; iter: 0; batch classifier loss: 0.306722; batch adversarial loss: 0.423918\n",
      "epoch 57; iter: 0; batch classifier loss: 0.195034; batch adversarial loss: 0.496189\n",
      "epoch 58; iter: 0; batch classifier loss: 0.233911; batch adversarial loss: 0.507282\n",
      "epoch 59; iter: 0; batch classifier loss: 0.318301; batch adversarial loss: 0.458475\n",
      "epoch 60; iter: 0; batch classifier loss: 0.202590; batch adversarial loss: 0.508476\n",
      "epoch 61; iter: 0; batch classifier loss: 0.262820; batch adversarial loss: 0.457876\n",
      "epoch 62; iter: 0; batch classifier loss: 0.223019; batch adversarial loss: 0.460284\n",
      "epoch 63; iter: 0; batch classifier loss: 0.184763; batch adversarial loss: 0.470908\n",
      "epoch 64; iter: 0; batch classifier loss: 0.192703; batch adversarial loss: 0.446757\n",
      "epoch 65; iter: 0; batch classifier loss: 0.242946; batch adversarial loss: 0.507971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205963; batch adversarial loss: 0.385425\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214775; batch adversarial loss: 0.458972\n",
      "epoch 68; iter: 0; batch classifier loss: 0.164668; batch adversarial loss: 0.373239\n",
      "epoch 69; iter: 0; batch classifier loss: 0.210458; batch adversarial loss: 0.384260\n",
      "epoch 70; iter: 0; batch classifier loss: 0.231872; batch adversarial loss: 0.482922\n",
      "epoch 71; iter: 0; batch classifier loss: 0.143096; batch adversarial loss: 0.520943\n",
      "epoch 72; iter: 0; batch classifier loss: 0.205242; batch adversarial loss: 0.372341\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191772; batch adversarial loss: 0.373825\n",
      "epoch 74; iter: 0; batch classifier loss: 0.232686; batch adversarial loss: 0.471834\n",
      "epoch 75; iter: 0; batch classifier loss: 0.178916; batch adversarial loss: 0.446140\n",
      "epoch 76; iter: 0; batch classifier loss: 0.201139; batch adversarial loss: 0.618108\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252733; batch adversarial loss: 0.458824\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101067; batch adversarial loss: 0.545581\n",
      "epoch 79; iter: 0; batch classifier loss: 0.127160; batch adversarial loss: 0.485039\n",
      "epoch 80; iter: 0; batch classifier loss: 0.171520; batch adversarial loss: 0.469367\n",
      "epoch 81; iter: 0; batch classifier loss: 0.267083; batch adversarial loss: 0.373943\n",
      "epoch 82; iter: 0; batch classifier loss: 0.162568; batch adversarial loss: 0.471774\n",
      "epoch 83; iter: 0; batch classifier loss: 0.236059; batch adversarial loss: 0.457962\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184979; batch adversarial loss: 0.372922\n",
      "epoch 85; iter: 0; batch classifier loss: 0.217668; batch adversarial loss: 0.397815\n",
      "epoch 86; iter: 0; batch classifier loss: 0.236935; batch adversarial loss: 0.434658\n",
      "epoch 87; iter: 0; batch classifier loss: 0.210645; batch adversarial loss: 0.458597\n",
      "epoch 88; iter: 0; batch classifier loss: 0.164893; batch adversarial loss: 0.458782\n",
      "epoch 89; iter: 0; batch classifier loss: 0.150165; batch adversarial loss: 0.348259\n",
      "epoch 90; iter: 0; batch classifier loss: 0.180432; batch adversarial loss: 0.546544\n",
      "epoch 91; iter: 0; batch classifier loss: 0.214305; batch adversarial loss: 0.445895\n",
      "epoch 92; iter: 0; batch classifier loss: 0.223305; batch adversarial loss: 0.360487\n",
      "epoch 93; iter: 0; batch classifier loss: 0.196997; batch adversarial loss: 0.397018\n",
      "epoch 94; iter: 0; batch classifier loss: 0.216852; batch adversarial loss: 0.458871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.253823; batch adversarial loss: 0.446177\n",
      "epoch 96; iter: 0; batch classifier loss: 0.185298; batch adversarial loss: 0.434141\n",
      "epoch 97; iter: 0; batch classifier loss: 0.283008; batch adversarial loss: 0.384949\n",
      "epoch 98; iter: 0; batch classifier loss: 0.103008; batch adversarial loss: 0.421903\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074798; batch adversarial loss: 0.471287\n",
      "epoch 100; iter: 0; batch classifier loss: 0.145347; batch adversarial loss: 0.442288\n",
      "epoch 101; iter: 0; batch classifier loss: 0.153575; batch adversarial loss: 0.472200\n",
      "epoch 102; iter: 0; batch classifier loss: 0.163818; batch adversarial loss: 0.346151\n",
      "epoch 103; iter: 0; batch classifier loss: 0.192165; batch adversarial loss: 0.422989\n",
      "epoch 104; iter: 0; batch classifier loss: 0.222197; batch adversarial loss: 0.459244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.202963; batch adversarial loss: 0.446077\n",
      "epoch 106; iter: 0; batch classifier loss: 0.174118; batch adversarial loss: 0.533665\n",
      "epoch 107; iter: 0; batch classifier loss: 0.283559; batch adversarial loss: 0.457873\n",
      "epoch 108; iter: 0; batch classifier loss: 0.184423; batch adversarial loss: 0.521105\n",
      "epoch 109; iter: 0; batch classifier loss: 0.211719; batch adversarial loss: 0.446083\n",
      "epoch 110; iter: 0; batch classifier loss: 0.227771; batch adversarial loss: 0.433389\n",
      "epoch 111; iter: 0; batch classifier loss: 0.260680; batch adversarial loss: 0.409574\n",
      "epoch 112; iter: 0; batch classifier loss: 0.212866; batch adversarial loss: 0.445451\n",
      "epoch 113; iter: 0; batch classifier loss: 0.212361; batch adversarial loss: 0.494899\n",
      "epoch 114; iter: 0; batch classifier loss: 0.191470; batch adversarial loss: 0.458559\n",
      "epoch 115; iter: 0; batch classifier loss: 0.254771; batch adversarial loss: 0.446644\n",
      "epoch 116; iter: 0; batch classifier loss: 0.198139; batch adversarial loss: 0.520156\n",
      "epoch 117; iter: 0; batch classifier loss: 0.221336; batch adversarial loss: 0.372456\n",
      "epoch 118; iter: 0; batch classifier loss: 0.157398; batch adversarial loss: 0.470175\n",
      "epoch 119; iter: 0; batch classifier loss: 0.257907; batch adversarial loss: 0.459322\n",
      "epoch 120; iter: 0; batch classifier loss: 0.164156; batch adversarial loss: 0.545832\n",
      "epoch 121; iter: 0; batch classifier loss: 0.200263; batch adversarial loss: 0.470183\n",
      "epoch 122; iter: 0; batch classifier loss: 0.210075; batch adversarial loss: 0.471334\n",
      "epoch 123; iter: 0; batch classifier loss: 0.198008; batch adversarial loss: 0.458847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.210218; batch adversarial loss: 0.458140\n",
      "epoch 125; iter: 0; batch classifier loss: 0.218250; batch adversarial loss: 0.448130\n",
      "epoch 126; iter: 0; batch classifier loss: 0.230435; batch adversarial loss: 0.508878\n",
      "epoch 127; iter: 0; batch classifier loss: 0.206317; batch adversarial loss: 0.470000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.216317; batch adversarial loss: 0.386500\n",
      "epoch 129; iter: 0; batch classifier loss: 0.176850; batch adversarial loss: 0.383376\n",
      "epoch 130; iter: 0; batch classifier loss: 0.256172; batch adversarial loss: 0.445342\n",
      "epoch 131; iter: 0; batch classifier loss: 0.169352; batch adversarial loss: 0.507732\n",
      "epoch 132; iter: 0; batch classifier loss: 0.208079; batch adversarial loss: 0.420404\n",
      "epoch 133; iter: 0; batch classifier loss: 0.178038; batch adversarial loss: 0.435233\n",
      "epoch 134; iter: 0; batch classifier loss: 0.193451; batch adversarial loss: 0.410222\n",
      "epoch 135; iter: 0; batch classifier loss: 0.094505; batch adversarial loss: 0.456100\n",
      "epoch 136; iter: 0; batch classifier loss: 0.084198; batch adversarial loss: 0.487754\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055992; batch adversarial loss: 0.500484\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054989; batch adversarial loss: 0.397130\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060621; batch adversarial loss: 0.478492\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029739; batch adversarial loss: 0.504272\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.467708\n",
      "epoch 142; iter: 0; batch classifier loss: 0.078503; batch adversarial loss: 0.441960\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039457; batch adversarial loss: 0.401154\n",
      "epoch 144; iter: 0; batch classifier loss: 0.088275; batch adversarial loss: 0.599446\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038205; batch adversarial loss: 0.388959\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031923; batch adversarial loss: 0.425693\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038810; batch adversarial loss: 0.522209\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027072; batch adversarial loss: 0.513156\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033742; batch adversarial loss: 0.548870\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038477; batch adversarial loss: 0.391007\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035996; batch adversarial loss: 0.437497\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017847; batch adversarial loss: 0.549038\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020890; batch adversarial loss: 0.411651\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023611; batch adversarial loss: 0.450441\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015633; batch adversarial loss: 0.541221\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054811; batch adversarial loss: 0.391132\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017228; batch adversarial loss: 0.498011\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033598; batch adversarial loss: 0.419891\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017907; batch adversarial loss: 0.439580\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008363; batch adversarial loss: 0.440122\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036801; batch adversarial loss: 0.434593\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021854; batch adversarial loss: 0.428970\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016084; batch adversarial loss: 0.397011\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008919; batch adversarial loss: 0.645593\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029492; batch adversarial loss: 0.434946\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.492170\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026091; batch adversarial loss: 0.627906\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037735; batch adversarial loss: 0.390840\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014362; batch adversarial loss: 0.390021\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022036; batch adversarial loss: 0.460449\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032501; batch adversarial loss: 0.378342\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018695; batch adversarial loss: 0.468466\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014874; batch adversarial loss: 0.330212\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.516996\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006259; batch adversarial loss: 0.466898\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020249; batch adversarial loss: 0.364232\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012245; batch adversarial loss: 0.471925\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037891; batch adversarial loss: 0.399835\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015782; batch adversarial loss: 0.415130\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035630; batch adversarial loss: 0.411745\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024514; batch adversarial loss: 0.527625\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014145; batch adversarial loss: 0.373099\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010207; batch adversarial loss: 0.515647\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022203; batch adversarial loss: 0.410922\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039808; batch adversarial loss: 0.451479\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020099; batch adversarial loss: 0.460498\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012252; batch adversarial loss: 0.457096\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008175; batch adversarial loss: 0.302181\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028649; batch adversarial loss: 0.406718\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032659; batch adversarial loss: 0.421445\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036078; batch adversarial loss: 0.538421\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006239; batch adversarial loss: 0.513848\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008939; batch adversarial loss: 0.550719\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.439724\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013440; batch adversarial loss: 0.482391\n",
      "epoch 196; iter: 0; batch classifier loss: 0.058401; batch adversarial loss: 0.413571\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008549; batch adversarial loss: 0.395130\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038438; batch adversarial loss: 0.462272\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033045; batch adversarial loss: 0.421488\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719680; batch adversarial loss: 0.663990\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480724; batch adversarial loss: 0.641104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375992; batch adversarial loss: 0.592113\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371822; batch adversarial loss: 0.583241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.234302; batch adversarial loss: 0.539058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316000; batch adversarial loss: 0.578851\n",
      "epoch 6; iter: 0; batch classifier loss: 0.189886; batch adversarial loss: 0.527253\n",
      "epoch 7; iter: 0; batch classifier loss: 0.209227; batch adversarial loss: 0.516709\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268811; batch adversarial loss: 0.490518\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261370; batch adversarial loss: 0.551828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.272303; batch adversarial loss: 0.499541\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251484; batch adversarial loss: 0.441528\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251855; batch adversarial loss: 0.438106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278554; batch adversarial loss: 0.495904\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248974; batch adversarial loss: 0.486932\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229488; batch adversarial loss: 0.485500\n",
      "epoch 16; iter: 0; batch classifier loss: 0.162867; batch adversarial loss: 0.465932\n",
      "epoch 17; iter: 0; batch classifier loss: 0.162709; batch adversarial loss: 0.544785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231931; batch adversarial loss: 0.380802\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192126; batch adversarial loss: 0.495943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.154716; batch adversarial loss: 0.507636\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190155; batch adversarial loss: 0.488487\n",
      "epoch 22; iter: 0; batch classifier loss: 0.142641; batch adversarial loss: 0.517631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196515; batch adversarial loss: 0.498866\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240588; batch adversarial loss: 0.505800\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240312; batch adversarial loss: 0.423966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.282871; batch adversarial loss: 0.477095\n",
      "epoch 27; iter: 0; batch classifier loss: 0.410985; batch adversarial loss: 0.476487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.296366; batch adversarial loss: 0.450223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227320; batch adversarial loss: 0.500036\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158331; batch adversarial loss: 0.577148\n",
      "epoch 31; iter: 0; batch classifier loss: 0.096325; batch adversarial loss: 0.561870\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119342; batch adversarial loss: 0.523645\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124417; batch adversarial loss: 0.485510\n",
      "epoch 34; iter: 0; batch classifier loss: 0.147239; batch adversarial loss: 0.415316\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108472; batch adversarial loss: 0.515618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.090713; batch adversarial loss: 0.433282\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115997; batch adversarial loss: 0.476513\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103912; batch adversarial loss: 0.448539\n",
      "epoch 39; iter: 0; batch classifier loss: 0.075442; batch adversarial loss: 0.485322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124902; batch adversarial loss: 0.438855\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086945; batch adversarial loss: 0.436679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113073; batch adversarial loss: 0.412085\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088993; batch adversarial loss: 0.520581\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124592; batch adversarial loss: 0.425377\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158768; batch adversarial loss: 0.467187\n",
      "epoch 46; iter: 0; batch classifier loss: 0.186828; batch adversarial loss: 0.446942\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115379; batch adversarial loss: 0.440821\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108761; batch adversarial loss: 0.473376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118377; batch adversarial loss: 0.366245\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113886; batch adversarial loss: 0.513133\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085522; batch adversarial loss: 0.407149\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105932; batch adversarial loss: 0.464541\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077785; batch adversarial loss: 0.452418\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149985; batch adversarial loss: 0.398285\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085686; batch adversarial loss: 0.492478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.063255; batch adversarial loss: 0.452791\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090000; batch adversarial loss: 0.433986\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064476; batch adversarial loss: 0.443274\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067904; batch adversarial loss: 0.529691\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158660; batch adversarial loss: 0.436681\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109902; batch adversarial loss: 0.418612\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142397; batch adversarial loss: 0.420358\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149119; batch adversarial loss: 0.459818\n",
      "epoch 64; iter: 0; batch classifier loss: 0.131532; batch adversarial loss: 0.414655\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107663; batch adversarial loss: 0.510893\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090662; batch adversarial loss: 0.445032\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056324; batch adversarial loss: 0.395313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093051; batch adversarial loss: 0.415284\n",
      "epoch 69; iter: 0; batch classifier loss: 0.121337; batch adversarial loss: 0.357007\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109863; batch adversarial loss: 0.472388\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087957; batch adversarial loss: 0.448807\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074330; batch adversarial loss: 0.401472\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138033; batch adversarial loss: 0.385991\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090364; batch adversarial loss: 0.501744\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086273; batch adversarial loss: 0.502087\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148178; batch adversarial loss: 0.435894\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095538; batch adversarial loss: 0.388905\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072078; batch adversarial loss: 0.383175\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.388548\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077416; batch adversarial loss: 0.471100\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061600; batch adversarial loss: 0.523754\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121027; batch adversarial loss: 0.495477\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069469; batch adversarial loss: 0.569803\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086987; batch adversarial loss: 0.456155\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090673; batch adversarial loss: 0.400496\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081174; batch adversarial loss: 0.391282\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106719; batch adversarial loss: 0.368950\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082185; batch adversarial loss: 0.501960\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054377; batch adversarial loss: 0.454224\n",
      "epoch 90; iter: 0; batch classifier loss: 0.114881; batch adversarial loss: 0.456202\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072343; batch adversarial loss: 0.442704\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045563; batch adversarial loss: 0.440060\n",
      "epoch 93; iter: 0; batch classifier loss: 0.108882; batch adversarial loss: 0.482611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048003; batch adversarial loss: 0.420519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050739; batch adversarial loss: 0.433389\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032146; batch adversarial loss: 0.460304\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074353; batch adversarial loss: 0.520356\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071107; batch adversarial loss: 0.387531\n",
      "epoch 99; iter: 0; batch classifier loss: 0.090330; batch adversarial loss: 0.407950\n",
      "epoch 100; iter: 0; batch classifier loss: 0.125677; batch adversarial loss: 0.460100\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052896; batch adversarial loss: 0.467074\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024799; batch adversarial loss: 0.470002\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041301; batch adversarial loss: 0.511017\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057626; batch adversarial loss: 0.294904\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053786; batch adversarial loss: 0.449190\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072777; batch adversarial loss: 0.454439\n",
      "epoch 107; iter: 0; batch classifier loss: 0.089449; batch adversarial loss: 0.457600\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055343; batch adversarial loss: 0.477530\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067986; batch adversarial loss: 0.427546\n",
      "epoch 110; iter: 0; batch classifier loss: 0.095175; batch adversarial loss: 0.459226\n",
      "epoch 111; iter: 0; batch classifier loss: 0.084217; batch adversarial loss: 0.444473\n",
      "epoch 112; iter: 0; batch classifier loss: 0.106175; batch adversarial loss: 0.453580\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040472; batch adversarial loss: 0.458864\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048837; batch adversarial loss: 0.433963\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065794; batch adversarial loss: 0.457355\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039505; batch adversarial loss: 0.397437\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023594; batch adversarial loss: 0.424273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.091029; batch adversarial loss: 0.479337\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047137; batch adversarial loss: 0.427338\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045975; batch adversarial loss: 0.481256\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082213; batch adversarial loss: 0.460626\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030916; batch adversarial loss: 0.352315\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034189; batch adversarial loss: 0.360715\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017902; batch adversarial loss: 0.377577\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054599; batch adversarial loss: 0.439243\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046779; batch adversarial loss: 0.552038\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035700; batch adversarial loss: 0.465532\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026719; batch adversarial loss: 0.458190\n",
      "epoch 129; iter: 0; batch classifier loss: 0.079097; batch adversarial loss: 0.398981\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045645; batch adversarial loss: 0.422186\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051528; batch adversarial loss: 0.428378\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074651; batch adversarial loss: 0.391761\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059395; batch adversarial loss: 0.424918\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067479; batch adversarial loss: 0.416940\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052024; batch adversarial loss: 0.434603\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033766; batch adversarial loss: 0.501166\n",
      "epoch 137; iter: 0; batch classifier loss: 0.076006; batch adversarial loss: 0.551803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016152; batch adversarial loss: 0.446532\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029667; batch adversarial loss: 0.461641\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047079; batch adversarial loss: 0.476727\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029486; batch adversarial loss: 0.472494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023902; batch adversarial loss: 0.545694\n",
      "epoch 143; iter: 0; batch classifier loss: 0.081371; batch adversarial loss: 0.397742\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024046; batch adversarial loss: 0.382418\n",
      "epoch 145; iter: 0; batch classifier loss: 0.066903; batch adversarial loss: 0.461608\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.416720\n",
      "epoch 147; iter: 0; batch classifier loss: 0.073766; batch adversarial loss: 0.507062\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028584; batch adversarial loss: 0.362387\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036850; batch adversarial loss: 0.515132\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027332; batch adversarial loss: 0.484806\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043275; batch adversarial loss: 0.491382\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013234; batch adversarial loss: 0.442254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030403; batch adversarial loss: 0.455597\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025628; batch adversarial loss: 0.435690\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030169; batch adversarial loss: 0.443985\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014782; batch adversarial loss: 0.416906\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057215; batch adversarial loss: 0.495797\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063135; batch adversarial loss: 0.427634\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028943; batch adversarial loss: 0.407318\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036743; batch adversarial loss: 0.359861\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055269; batch adversarial loss: 0.404563\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033582; batch adversarial loss: 0.414511\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043909; batch adversarial loss: 0.516152\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018194; batch adversarial loss: 0.542547\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041330; batch adversarial loss: 0.381960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043878; batch adversarial loss: 0.385524\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050868; batch adversarial loss: 0.403604\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011795; batch adversarial loss: 0.362466\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028265; batch adversarial loss: 0.403310\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.495563\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043915; batch adversarial loss: 0.339782\n",
      "epoch 172; iter: 0; batch classifier loss: 0.080979; batch adversarial loss: 0.394605\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006426; batch adversarial loss: 0.391593\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012952; batch adversarial loss: 0.472984\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036785; batch adversarial loss: 0.446456\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009646; batch adversarial loss: 0.450337\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021025; batch adversarial loss: 0.447567\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040959; batch adversarial loss: 0.379190\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015945; batch adversarial loss: 0.459700\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034190; batch adversarial loss: 0.439538\n",
      "epoch 181; iter: 0; batch classifier loss: 0.041667; batch adversarial loss: 0.441473\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030263; batch adversarial loss: 0.412067\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037832; batch adversarial loss: 0.508844\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035089; batch adversarial loss: 0.399363\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032167; batch adversarial loss: 0.433544\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015505; batch adversarial loss: 0.430751\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040183; batch adversarial loss: 0.396453\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.515762\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050126; batch adversarial loss: 0.437154\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026792; batch adversarial loss: 0.429626\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025001; batch adversarial loss: 0.444119\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022316; batch adversarial loss: 0.486020\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041006; batch adversarial loss: 0.465997\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022681; batch adversarial loss: 0.443297\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023774; batch adversarial loss: 0.443281\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033848; batch adversarial loss: 0.543181\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016064; batch adversarial loss: 0.385853\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032789; batch adversarial loss: 0.437713\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022482; batch adversarial loss: 0.416508\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677487; batch adversarial loss: 0.548629\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468839; batch adversarial loss: 0.608791\n",
      "epoch 2; iter: 0; batch classifier loss: 0.471577; batch adversarial loss: 0.569176\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347850; batch adversarial loss: 0.586452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384882; batch adversarial loss: 0.569695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461332; batch adversarial loss: 0.567108\n",
      "epoch 6; iter: 0; batch classifier loss: 0.478779; batch adversarial loss: 0.561442\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435150; batch adversarial loss: 0.602785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482039; batch adversarial loss: 0.523044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506279; batch adversarial loss: 0.574110\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436640; batch adversarial loss: 0.567198\n",
      "epoch 11; iter: 0; batch classifier loss: 0.647478; batch adversarial loss: 0.495004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.612851; batch adversarial loss: 0.492505\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382089; batch adversarial loss: 0.522584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.275459; batch adversarial loss: 0.463560\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314312; batch adversarial loss: 0.493153\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231150; batch adversarial loss: 0.479283\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329586; batch adversarial loss: 0.440526\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273903; batch adversarial loss: 0.442318\n",
      "epoch 19; iter: 0; batch classifier loss: 0.268256; batch adversarial loss: 0.442435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236259; batch adversarial loss: 0.441323\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188219; batch adversarial loss: 0.454557\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231070; batch adversarial loss: 0.451280\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235485; batch adversarial loss: 0.417712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169019; batch adversarial loss: 0.448276\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171236; batch adversarial loss: 0.455057\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194496; batch adversarial loss: 0.417076\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184844; batch adversarial loss: 0.514856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163391; batch adversarial loss: 0.395921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233651; batch adversarial loss: 0.418626\n",
      "epoch 30; iter: 0; batch classifier loss: 0.143191; batch adversarial loss: 0.466847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186338; batch adversarial loss: 0.472151\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164516; batch adversarial loss: 0.450163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123965; batch adversarial loss: 0.559194\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131288; batch adversarial loss: 0.429281\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110665; batch adversarial loss: 0.452121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115689; batch adversarial loss: 0.378962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123762; batch adversarial loss: 0.441384\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164991; batch adversarial loss: 0.500297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148783; batch adversarial loss: 0.541115\n",
      "epoch 40; iter: 0; batch classifier loss: 0.174991; batch adversarial loss: 0.407031\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143840; batch adversarial loss: 0.408279\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099889; batch adversarial loss: 0.475055\n",
      "epoch 43; iter: 0; batch classifier loss: 0.127527; batch adversarial loss: 0.444169\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079371; batch adversarial loss: 0.536022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122689; batch adversarial loss: 0.520923\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135480; batch adversarial loss: 0.404309\n",
      "epoch 47; iter: 0; batch classifier loss: 0.163373; batch adversarial loss: 0.454086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094314; batch adversarial loss: 0.497446\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135614; batch adversarial loss: 0.423375\n",
      "epoch 50; iter: 0; batch classifier loss: 0.171409; batch adversarial loss: 0.483462\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134246; batch adversarial loss: 0.447856\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139055; batch adversarial loss: 0.399286\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088728; batch adversarial loss: 0.454899\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136278; batch adversarial loss: 0.458974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125916; batch adversarial loss: 0.506818\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101961; batch adversarial loss: 0.385842\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110566; batch adversarial loss: 0.386484\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084876; batch adversarial loss: 0.474093\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161105; batch adversarial loss: 0.540070\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131053; batch adversarial loss: 0.430554\n",
      "epoch 61; iter: 0; batch classifier loss: 0.146810; batch adversarial loss: 0.510698\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121030; batch adversarial loss: 0.541418\n",
      "epoch 63; iter: 0; batch classifier loss: 0.148288; batch adversarial loss: 0.425815\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105452; batch adversarial loss: 0.605648\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103889; batch adversarial loss: 0.495018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096382; batch adversarial loss: 0.538109\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092959; batch adversarial loss: 0.480523\n",
      "epoch 68; iter: 0; batch classifier loss: 0.137117; batch adversarial loss: 0.467785\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048521; batch adversarial loss: 0.502859\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144558; batch adversarial loss: 0.492886\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077519; batch adversarial loss: 0.522637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095343; batch adversarial loss: 0.431379\n",
      "epoch 73; iter: 0; batch classifier loss: 0.124378; batch adversarial loss: 0.469339\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073150; batch adversarial loss: 0.520150\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100836; batch adversarial loss: 0.448014\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073716; batch adversarial loss: 0.448111\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091964; batch adversarial loss: 0.416108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080918; batch adversarial loss: 0.525876\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073920; batch adversarial loss: 0.511488\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085691; batch adversarial loss: 0.409796\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103020; batch adversarial loss: 0.403117\n",
      "epoch 82; iter: 0; batch classifier loss: 0.131321; batch adversarial loss: 0.390517\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111356; batch adversarial loss: 0.458827\n",
      "epoch 84; iter: 0; batch classifier loss: 0.127528; batch adversarial loss: 0.476177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.049352; batch adversarial loss: 0.495529\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051943; batch adversarial loss: 0.518077\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083580; batch adversarial loss: 0.481151\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070995; batch adversarial loss: 0.452315\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085144; batch adversarial loss: 0.476088\n",
      "epoch 90; iter: 0; batch classifier loss: 0.030276; batch adversarial loss: 0.413353\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075655; batch adversarial loss: 0.424894\n",
      "epoch 92; iter: 0; batch classifier loss: 0.126068; batch adversarial loss: 0.391621\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047745; batch adversarial loss: 0.494445\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085840; batch adversarial loss: 0.423519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079818; batch adversarial loss: 0.452363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068454; batch adversarial loss: 0.449460\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059615; batch adversarial loss: 0.434071\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064191; batch adversarial loss: 0.466942\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088521; batch adversarial loss: 0.453636\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095588; batch adversarial loss: 0.432152\n",
      "epoch 101; iter: 0; batch classifier loss: 0.094569; batch adversarial loss: 0.467533\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048326; batch adversarial loss: 0.410550\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054075; batch adversarial loss: 0.456000\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061792; batch adversarial loss: 0.490580\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049476; batch adversarial loss: 0.498615\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055180; batch adversarial loss: 0.441057\n",
      "epoch 107; iter: 0; batch classifier loss: 0.103498; batch adversarial loss: 0.538365\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033638; batch adversarial loss: 0.479130\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041947; batch adversarial loss: 0.417279\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092852; batch adversarial loss: 0.440269\n",
      "epoch 111; iter: 0; batch classifier loss: 0.087861; batch adversarial loss: 0.373676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.041959; batch adversarial loss: 0.416329\n",
      "epoch 113; iter: 0; batch classifier loss: 0.097402; batch adversarial loss: 0.313459\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050451; batch adversarial loss: 0.474987\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041586; batch adversarial loss: 0.474203\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020600; batch adversarial loss: 0.499031\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058658; batch adversarial loss: 0.421125\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042138; batch adversarial loss: 0.338133\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057947; batch adversarial loss: 0.489690\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045362; batch adversarial loss: 0.340608\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049055; batch adversarial loss: 0.488569\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036744; batch adversarial loss: 0.454055\n",
      "epoch 123; iter: 0; batch classifier loss: 0.013655; batch adversarial loss: 0.538424\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032764; batch adversarial loss: 0.493765\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037610; batch adversarial loss: 0.411387\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032531; batch adversarial loss: 0.377901\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042125; batch adversarial loss: 0.446678\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036254; batch adversarial loss: 0.524371\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039193; batch adversarial loss: 0.476829\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057554; batch adversarial loss: 0.457643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.485523\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041557; batch adversarial loss: 0.499838\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044281; batch adversarial loss: 0.386050\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017094; batch adversarial loss: 0.581465\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030970; batch adversarial loss: 0.471767\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032275; batch adversarial loss: 0.281793\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025551; batch adversarial loss: 0.470123\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056410; batch adversarial loss: 0.507549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037219; batch adversarial loss: 0.376325\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045200; batch adversarial loss: 0.500546\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022002; batch adversarial loss: 0.442921\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025494; batch adversarial loss: 0.443064\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012197; batch adversarial loss: 0.503850\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026917; batch adversarial loss: 0.503289\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050979; batch adversarial loss: 0.441435\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048427; batch adversarial loss: 0.265247\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028210; batch adversarial loss: 0.443246\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021426; batch adversarial loss: 0.426514\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040921; batch adversarial loss: 0.536151\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046488; batch adversarial loss: 0.443060\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017300; batch adversarial loss: 0.386725\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018097; batch adversarial loss: 0.477946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.040200; batch adversarial loss: 0.507024\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029931; batch adversarial loss: 0.308208\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024497; batch adversarial loss: 0.421901\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052166; batch adversarial loss: 0.419799\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029215; batch adversarial loss: 0.488428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034884; batch adversarial loss: 0.437842\n",
      "epoch 159; iter: 0; batch classifier loss: 0.055977; batch adversarial loss: 0.404392\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025073; batch adversarial loss: 0.438534\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018929; batch adversarial loss: 0.431149\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006795; batch adversarial loss: 0.576484\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039337; batch adversarial loss: 0.373976\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028347; batch adversarial loss: 0.448390\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023564; batch adversarial loss: 0.494633\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020622; batch adversarial loss: 0.390723\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033881; batch adversarial loss: 0.413480\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032301; batch adversarial loss: 0.382158\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030217; batch adversarial loss: 0.422006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014337; batch adversarial loss: 0.484092\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039844; batch adversarial loss: 0.464158\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023282; batch adversarial loss: 0.427435\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025664; batch adversarial loss: 0.434783\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040302; batch adversarial loss: 0.568008\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006856; batch adversarial loss: 0.339937\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022970; batch adversarial loss: 0.458858\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.464027\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008797; batch adversarial loss: 0.470405\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038756; batch adversarial loss: 0.388254\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043893; batch adversarial loss: 0.471728\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021533; batch adversarial loss: 0.507091\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.395835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026457; batch adversarial loss: 0.404094\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013349; batch adversarial loss: 0.530375\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045667; batch adversarial loss: 0.407851\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055995; batch adversarial loss: 0.372690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011505; batch adversarial loss: 0.436899\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005224; batch adversarial loss: 0.478116\n",
      "epoch 189; iter: 0; batch classifier loss: 0.061163; batch adversarial loss: 0.401164\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.456658\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010700; batch adversarial loss: 0.449495\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010329; batch adversarial loss: 0.449907\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020225; batch adversarial loss: 0.381670\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010018; batch adversarial loss: 0.443938\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023551; batch adversarial loss: 0.457955\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017742; batch adversarial loss: 0.489544\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018369; batch adversarial loss: 0.389923\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006633; batch adversarial loss: 0.524102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016441; batch adversarial loss: 0.426940\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680940; batch adversarial loss: 0.786123\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512766; batch adversarial loss: 0.708267\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399004; batch adversarial loss: 0.702974\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372841; batch adversarial loss: 0.659361\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357954; batch adversarial loss: 0.646909\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321821; batch adversarial loss: 0.596059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.442298; batch adversarial loss: 0.565583\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280844; batch adversarial loss: 0.555758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.267155; batch adversarial loss: 0.552273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250047; batch adversarial loss: 0.484375\n",
      "epoch 10; iter: 0; batch classifier loss: 0.206219; batch adversarial loss: 0.485710\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269448; batch adversarial loss: 0.443644\n",
      "epoch 12; iter: 0; batch classifier loss: 0.188639; batch adversarial loss: 0.471790\n",
      "epoch 13; iter: 0; batch classifier loss: 0.177279; batch adversarial loss: 0.467257\n",
      "epoch 14; iter: 0; batch classifier loss: 0.168690; batch adversarial loss: 0.524617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204175; batch adversarial loss: 0.497493\n",
      "epoch 16; iter: 0; batch classifier loss: 0.181562; batch adversarial loss: 0.413086\n",
      "epoch 17; iter: 0; batch classifier loss: 0.149405; batch adversarial loss: 0.409669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153719; batch adversarial loss: 0.407140\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179488; batch adversarial loss: 0.411480\n",
      "epoch 20; iter: 0; batch classifier loss: 0.145839; batch adversarial loss: 0.399002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164997; batch adversarial loss: 0.336147\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175269; batch adversarial loss: 0.455476\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151920; batch adversarial loss: 0.383774\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220251; batch adversarial loss: 0.391779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.126282; batch adversarial loss: 0.413709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130090; batch adversarial loss: 0.388021\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159663; batch adversarial loss: 0.357833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153702; batch adversarial loss: 0.361409\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190558; batch adversarial loss: 0.445376\n",
      "epoch 30; iter: 0; batch classifier loss: 0.156281; batch adversarial loss: 0.374158\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205492; batch adversarial loss: 0.444315\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198001; batch adversarial loss: 0.376276\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111146; batch adversarial loss: 0.373730\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170598; batch adversarial loss: 0.378393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124251; batch adversarial loss: 0.373347\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160072; batch adversarial loss: 0.409037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.142847; batch adversarial loss: 0.325983\n",
      "epoch 38; iter: 0; batch classifier loss: 0.093541; batch adversarial loss: 0.474997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105535; batch adversarial loss: 0.405837\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081286; batch adversarial loss: 0.384047\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099458; batch adversarial loss: 0.364423\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120835; batch adversarial loss: 0.430132\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102763; batch adversarial loss: 0.379356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109074; batch adversarial loss: 0.392363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.057040; batch adversarial loss: 0.314779\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115137; batch adversarial loss: 0.492883\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088522; batch adversarial loss: 0.433154\n",
      "epoch 48; iter: 0; batch classifier loss: 0.059638; batch adversarial loss: 0.331378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.056978; batch adversarial loss: 0.461360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105391; batch adversarial loss: 0.466557\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115893; batch adversarial loss: 0.466686\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086573; batch adversarial loss: 0.367371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089941; batch adversarial loss: 0.397586\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068033; batch adversarial loss: 0.401418\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110714; batch adversarial loss: 0.473607\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090055; batch adversarial loss: 0.441463\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062378; batch adversarial loss: 0.422927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095928; batch adversarial loss: 0.389206\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074564; batch adversarial loss: 0.533575\n",
      "epoch 60; iter: 0; batch classifier loss: 0.051885; batch adversarial loss: 0.398075\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072659; batch adversarial loss: 0.385807\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082886; batch adversarial loss: 0.395568\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079556; batch adversarial loss: 0.415853\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065707; batch adversarial loss: 0.496206\n",
      "epoch 65; iter: 0; batch classifier loss: 0.037604; batch adversarial loss: 0.508431\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078925; batch adversarial loss: 0.443565\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058745; batch adversarial loss: 0.388660\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080938; batch adversarial loss: 0.317375\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060437; batch adversarial loss: 0.435779\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054469; batch adversarial loss: 0.457711\n",
      "epoch 71; iter: 0; batch classifier loss: 0.040333; batch adversarial loss: 0.513205\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047394; batch adversarial loss: 0.459403\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050155; batch adversarial loss: 0.470450\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040853; batch adversarial loss: 0.416502\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047838; batch adversarial loss: 0.491279\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042433; batch adversarial loss: 0.467181\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045576; batch adversarial loss: 0.482242\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059427; batch adversarial loss: 0.571735\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063711; batch adversarial loss: 0.415221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.041483; batch adversarial loss: 0.469857\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055196; batch adversarial loss: 0.405359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.020867; batch adversarial loss: 0.433256\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037025; batch adversarial loss: 0.446684\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055874; batch adversarial loss: 0.429812\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037135; batch adversarial loss: 0.469532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036992; batch adversarial loss: 0.404348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037484; batch adversarial loss: 0.296977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.029222; batch adversarial loss: 0.467452\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033694; batch adversarial loss: 0.305062\n",
      "epoch 90; iter: 0; batch classifier loss: 0.018463; batch adversarial loss: 0.483866\n",
      "epoch 91; iter: 0; batch classifier loss: 0.027786; batch adversarial loss: 0.459540\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035143; batch adversarial loss: 0.411917\n",
      "epoch 93; iter: 0; batch classifier loss: 0.023893; batch adversarial loss: 0.433438\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037292; batch adversarial loss: 0.482602\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064880; batch adversarial loss: 0.462742\n",
      "epoch 96; iter: 0; batch classifier loss: 0.023766; batch adversarial loss: 0.463656\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050018; batch adversarial loss: 0.489870\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039660; batch adversarial loss: 0.601957\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043793; batch adversarial loss: 0.509915\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049345; batch adversarial loss: 0.440396\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071340; batch adversarial loss: 0.629674\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041603; batch adversarial loss: 0.529598\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036967; batch adversarial loss: 0.499191\n",
      "epoch 104; iter: 0; batch classifier loss: 0.105372; batch adversarial loss: 0.515762\n",
      "epoch 105; iter: 0; batch classifier loss: 0.136643; batch adversarial loss: 0.563189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.054084; batch adversarial loss: 0.373142\n",
      "epoch 107; iter: 0; batch classifier loss: 0.116201; batch adversarial loss: 0.607044\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078766; batch adversarial loss: 0.416140\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067822; batch adversarial loss: 0.542996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126415; batch adversarial loss: 0.596266\n",
      "epoch 111; iter: 0; batch classifier loss: 0.117507; batch adversarial loss: 0.541790\n",
      "epoch 112; iter: 0; batch classifier loss: 0.117970; batch adversarial loss: 0.547582\n",
      "epoch 113; iter: 0; batch classifier loss: 0.117957; batch adversarial loss: 0.484791\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058920; batch adversarial loss: 0.473852\n",
      "epoch 115; iter: 0; batch classifier loss: 0.153042; batch adversarial loss: 0.618678\n",
      "epoch 116; iter: 0; batch classifier loss: 0.116185; batch adversarial loss: 0.558762\n",
      "epoch 117; iter: 0; batch classifier loss: 0.172038; batch adversarial loss: 0.656125\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077644; batch adversarial loss: 0.528859\n",
      "epoch 119; iter: 0; batch classifier loss: 0.108396; batch adversarial loss: 0.515676\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068806; batch adversarial loss: 0.501660\n",
      "epoch 121; iter: 0; batch classifier loss: 0.124278; batch adversarial loss: 0.621803\n",
      "epoch 122; iter: 0; batch classifier loss: 0.122192; batch adversarial loss: 0.541743\n",
      "epoch 123; iter: 0; batch classifier loss: 0.100970; batch adversarial loss: 0.575945\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059981; batch adversarial loss: 0.493317\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062876; batch adversarial loss: 0.404172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056881; batch adversarial loss: 0.355218\n",
      "epoch 127; iter: 0; batch classifier loss: 0.120987; batch adversarial loss: 0.571574\n",
      "epoch 128; iter: 0; batch classifier loss: 0.136011; batch adversarial loss: 0.560335\n",
      "epoch 129; iter: 0; batch classifier loss: 0.099074; batch adversarial loss: 0.511751\n",
      "epoch 130; iter: 0; batch classifier loss: 0.103135; batch adversarial loss: 0.513085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.092484; batch adversarial loss: 0.524028\n",
      "epoch 132; iter: 0; batch classifier loss: 0.077845; batch adversarial loss: 0.489391\n",
      "epoch 133; iter: 0; batch classifier loss: 0.092277; batch adversarial loss: 0.346266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.128086; batch adversarial loss: 0.535536\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046061; batch adversarial loss: 0.368136\n",
      "epoch 136; iter: 0; batch classifier loss: 0.102316; batch adversarial loss: 0.470366\n",
      "epoch 137; iter: 0; batch classifier loss: 0.082219; batch adversarial loss: 0.415422\n",
      "epoch 138; iter: 0; batch classifier loss: 0.121903; batch adversarial loss: 0.523047\n",
      "epoch 139; iter: 0; batch classifier loss: 0.097228; batch adversarial loss: 0.345331\n",
      "epoch 140; iter: 0; batch classifier loss: 0.158480; batch adversarial loss: 0.447636\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045901; batch adversarial loss: 0.408047\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023261; batch adversarial loss: 0.440789\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025156; batch adversarial loss: 0.481280\n",
      "epoch 144; iter: 0; batch classifier loss: 0.015979; batch adversarial loss: 0.368505\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025267; batch adversarial loss: 0.480427\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037701; batch adversarial loss: 0.460422\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016022; batch adversarial loss: 0.491160\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047696; batch adversarial loss: 0.511944\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031739; batch adversarial loss: 0.508226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044962; batch adversarial loss: 0.552947\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037650; batch adversarial loss: 0.501996\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022999; batch adversarial loss: 0.599449\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016300; batch adversarial loss: 0.491928\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029453; batch adversarial loss: 0.415001\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031576; batch adversarial loss: 0.524030\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044018; batch adversarial loss: 0.425846\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032800; batch adversarial loss: 0.493653\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038837; batch adversarial loss: 0.442976\n",
      "epoch 159; iter: 0; batch classifier loss: 0.077010; batch adversarial loss: 0.415900\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058888; batch adversarial loss: 0.457897\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046829; batch adversarial loss: 0.396333\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.441391\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057101; batch adversarial loss: 0.448523\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056233; batch adversarial loss: 0.415614\n",
      "epoch 165; iter: 0; batch classifier loss: 0.057816; batch adversarial loss: 0.466842\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033087; batch adversarial loss: 0.447143\n",
      "epoch 167; iter: 0; batch classifier loss: 0.095338; batch adversarial loss: 0.400785\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066257; batch adversarial loss: 0.490584\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044034; batch adversarial loss: 0.433326\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047169; batch adversarial loss: 0.378711\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020440; batch adversarial loss: 0.451008\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009844; batch adversarial loss: 0.456991\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023202; batch adversarial loss: 0.475180\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.457381\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040551; batch adversarial loss: 0.392294\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043945; batch adversarial loss: 0.502594\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008770; batch adversarial loss: 0.501332\n",
      "epoch 178; iter: 0; batch classifier loss: 0.053101; batch adversarial loss: 0.471961\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039418; batch adversarial loss: 0.392704\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.466768\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046824; batch adversarial loss: 0.369089\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031710; batch adversarial loss: 0.396586\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017512; batch adversarial loss: 0.394544\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035060; batch adversarial loss: 0.469119\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040133; batch adversarial loss: 0.475083\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035692; batch adversarial loss: 0.354242\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016685; batch adversarial loss: 0.478374\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048306; batch adversarial loss: 0.491049\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.460086\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014183; batch adversarial loss: 0.507053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027911; batch adversarial loss: 0.416270\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037449; batch adversarial loss: 0.386908\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047890; batch adversarial loss: 0.408056\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031423; batch adversarial loss: 0.529985\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025617; batch adversarial loss: 0.531333\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024636; batch adversarial loss: 0.369290\n",
      "epoch 197; iter: 0; batch classifier loss: 0.050835; batch adversarial loss: 0.446257\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015222; batch adversarial loss: 0.414898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035418; batch adversarial loss: 0.422370\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704662; batch adversarial loss: 1.011535\n",
      "epoch 1; iter: 0; batch classifier loss: 0.751314; batch adversarial loss: 1.063362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.904206; batch adversarial loss: 1.078606\n",
      "epoch 3; iter: 0; batch classifier loss: 1.108629; batch adversarial loss: 1.065062\n",
      "epoch 4; iter: 0; batch classifier loss: 0.927322; batch adversarial loss: 0.920208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.867325; batch adversarial loss: 0.823901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.870927; batch adversarial loss: 0.748070\n",
      "epoch 7; iter: 0; batch classifier loss: 0.814396; batch adversarial loss: 0.696141\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602523; batch adversarial loss: 0.656004\n",
      "epoch 9; iter: 0; batch classifier loss: 0.659364; batch adversarial loss: 0.647053\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531512; batch adversarial loss: 0.573295\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425639; batch adversarial loss: 0.586778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422028; batch adversarial loss: 0.545482\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309476; batch adversarial loss: 0.509576\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339352; batch adversarial loss: 0.464133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325629; batch adversarial loss: 0.548150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249209; batch adversarial loss: 0.564813\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290553; batch adversarial loss: 0.511538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229623; batch adversarial loss: 0.552009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265815; batch adversarial loss: 0.514560\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254590; batch adversarial loss: 0.554832\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216119; batch adversarial loss: 0.525740\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218675; batch adversarial loss: 0.467902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248460; batch adversarial loss: 0.475673\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191024; batch adversarial loss: 0.517919\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257420; batch adversarial loss: 0.389058\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194054; batch adversarial loss: 0.421303\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202622; batch adversarial loss: 0.441299\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177463; batch adversarial loss: 0.530788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272780; batch adversarial loss: 0.426662\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219161; batch adversarial loss: 0.464424\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192216; batch adversarial loss: 0.424764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182922; batch adversarial loss: 0.477232\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185374; batch adversarial loss: 0.449070\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198552; batch adversarial loss: 0.482499\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159316; batch adversarial loss: 0.369492\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151773; batch adversarial loss: 0.547950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160198; batch adversarial loss: 0.506231\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166725; batch adversarial loss: 0.457061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187232; batch adversarial loss: 0.499848\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172201; batch adversarial loss: 0.546676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153331; batch adversarial loss: 0.477808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213276; batch adversarial loss: 0.468284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209528; batch adversarial loss: 0.524014\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125866; batch adversarial loss: 0.414938\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159074; batch adversarial loss: 0.392046\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111977; batch adversarial loss: 0.462894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201036; batch adversarial loss: 0.470778\n",
      "epoch 48; iter: 0; batch classifier loss: 0.168965; batch adversarial loss: 0.514750\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144596; batch adversarial loss: 0.481791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.241229; batch adversarial loss: 0.496984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160442; batch adversarial loss: 0.448076\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143539; batch adversarial loss: 0.430050\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169874; batch adversarial loss: 0.414780\n",
      "epoch 54; iter: 0; batch classifier loss: 0.184446; batch adversarial loss: 0.309506\n",
      "epoch 55; iter: 0; batch classifier loss: 0.143005; batch adversarial loss: 0.424408\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122990; batch adversarial loss: 0.526829\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094728; batch adversarial loss: 0.545471\n",
      "epoch 58; iter: 0; batch classifier loss: 0.138912; batch adversarial loss: 0.514663\n",
      "epoch 59; iter: 0; batch classifier loss: 0.156227; batch adversarial loss: 0.463079\n",
      "epoch 60; iter: 0; batch classifier loss: 0.128265; batch adversarial loss: 0.463408\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092559; batch adversarial loss: 0.442392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.159182; batch adversarial loss: 0.470561\n",
      "epoch 63; iter: 0; batch classifier loss: 0.134403; batch adversarial loss: 0.477175\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122344; batch adversarial loss: 0.556376\n",
      "epoch 65; iter: 0; batch classifier loss: 0.117663; batch adversarial loss: 0.467418\n",
      "epoch 66; iter: 0; batch classifier loss: 0.166841; batch adversarial loss: 0.466688\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110585; batch adversarial loss: 0.492457\n",
      "epoch 68; iter: 0; batch classifier loss: 0.137131; batch adversarial loss: 0.489748\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128334; batch adversarial loss: 0.401314\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122394; batch adversarial loss: 0.381353\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103076; batch adversarial loss: 0.431723\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085018; batch adversarial loss: 0.422854\n",
      "epoch 73; iter: 0; batch classifier loss: 0.157880; batch adversarial loss: 0.474259\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092598; batch adversarial loss: 0.483817\n",
      "epoch 75; iter: 0; batch classifier loss: 0.160275; batch adversarial loss: 0.406846\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061375; batch adversarial loss: 0.521666\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110303; batch adversarial loss: 0.396380\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079093; batch adversarial loss: 0.475898\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131162; batch adversarial loss: 0.472579\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133368; batch adversarial loss: 0.461747\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101538; batch adversarial loss: 0.439440\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106163; batch adversarial loss: 0.506748\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067366; batch adversarial loss: 0.474138\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082022; batch adversarial loss: 0.461030\n",
      "epoch 85; iter: 0; batch classifier loss: 0.115815; batch adversarial loss: 0.430751\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113901; batch adversarial loss: 0.372876\n",
      "epoch 87; iter: 0; batch classifier loss: 0.119733; batch adversarial loss: 0.453706\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102497; batch adversarial loss: 0.446932\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128644; batch adversarial loss: 0.505067\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146918; batch adversarial loss: 0.448437\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114081; batch adversarial loss: 0.473509\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.383875\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085848; batch adversarial loss: 0.375005\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077664; batch adversarial loss: 0.409229\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084650; batch adversarial loss: 0.485996\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110484; batch adversarial loss: 0.499917\n",
      "epoch 97; iter: 0; batch classifier loss: 0.152773; batch adversarial loss: 0.465861\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083881; batch adversarial loss: 0.470012\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107848; batch adversarial loss: 0.371895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.058087; batch adversarial loss: 0.400594\n",
      "epoch 101; iter: 0; batch classifier loss: 0.119733; batch adversarial loss: 0.489990\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085125; batch adversarial loss: 0.466603\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074476; batch adversarial loss: 0.509260\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053784; batch adversarial loss: 0.462644\n",
      "epoch 105; iter: 0; batch classifier loss: 0.104668; batch adversarial loss: 0.353494\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101161; batch adversarial loss: 0.438526\n",
      "epoch 107; iter: 0; batch classifier loss: 0.125481; batch adversarial loss: 0.433124\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077594; batch adversarial loss: 0.445892\n",
      "epoch 109; iter: 0; batch classifier loss: 0.094441; batch adversarial loss: 0.470627\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058459; batch adversarial loss: 0.377068\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046848; batch adversarial loss: 0.499591\n",
      "epoch 112; iter: 0; batch classifier loss: 0.082069; batch adversarial loss: 0.397183\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040190; batch adversarial loss: 0.583645\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072958; batch adversarial loss: 0.534645\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066003; batch adversarial loss: 0.452149\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027160; batch adversarial loss: 0.439941\n",
      "epoch 117; iter: 0; batch classifier loss: 0.106469; batch adversarial loss: 0.472283\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051680; batch adversarial loss: 0.478093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031340; batch adversarial loss: 0.395371\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030628; batch adversarial loss: 0.541653\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046206; batch adversarial loss: 0.508119\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059853; batch adversarial loss: 0.422353\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046573; batch adversarial loss: 0.409502\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035041; batch adversarial loss: 0.482048\n",
      "epoch 125; iter: 0; batch classifier loss: 0.104917; batch adversarial loss: 0.385282\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050892; batch adversarial loss: 0.421473\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061897; batch adversarial loss: 0.424456\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.538500\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033379; batch adversarial loss: 0.508797\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035878; batch adversarial loss: 0.431332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029609; batch adversarial loss: 0.533228\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019414; batch adversarial loss: 0.404168\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021976; batch adversarial loss: 0.482991\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035162; batch adversarial loss: 0.452233\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029442; batch adversarial loss: 0.437380\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045312; batch adversarial loss: 0.518562\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024692; batch adversarial loss: 0.535581\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039638; batch adversarial loss: 0.476714\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033054; batch adversarial loss: 0.468532\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011800; batch adversarial loss: 0.458981\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023234; batch adversarial loss: 0.388651\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029684; batch adversarial loss: 0.469190\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033977; batch adversarial loss: 0.454242\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008234; batch adversarial loss: 0.432483\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020835; batch adversarial loss: 0.450115\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028800; batch adversarial loss: 0.383451\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048852; batch adversarial loss: 0.363125\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023059; batch adversarial loss: 0.508285\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011958; batch adversarial loss: 0.459923\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028341; batch adversarial loss: 0.432132\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013156; batch adversarial loss: 0.417819\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025313; batch adversarial loss: 0.587186\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014082; batch adversarial loss: 0.521937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010176; batch adversarial loss: 0.385297\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012085; batch adversarial loss: 0.452138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022159; batch adversarial loss: 0.480879\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023104; batch adversarial loss: 0.504158\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017999; batch adversarial loss: 0.511898\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010329; batch adversarial loss: 0.460652\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.480002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014768; batch adversarial loss: 0.495241\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030095; batch adversarial loss: 0.432794\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008760; batch adversarial loss: 0.439268\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010811; batch adversarial loss: 0.490736\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034099; batch adversarial loss: 0.386886\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012400; batch adversarial loss: 0.500744\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011845; batch adversarial loss: 0.426078\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010667; batch adversarial loss: 0.404973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015778; batch adversarial loss: 0.424293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023545; batch adversarial loss: 0.458557\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028820; batch adversarial loss: 0.433411\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022529; batch adversarial loss: 0.501595\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025185; batch adversarial loss: 0.351335\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.504470\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006559; batch adversarial loss: 0.353815\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044818; batch adversarial loss: 0.437243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020271; batch adversarial loss: 0.424228\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009637; batch adversarial loss: 0.400182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024802; batch adversarial loss: 0.508096\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004476; batch adversarial loss: 0.471245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005494; batch adversarial loss: 0.482921\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006007; batch adversarial loss: 0.569044\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015038; batch adversarial loss: 0.491713\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006066; batch adversarial loss: 0.585209\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017381; batch adversarial loss: 0.533467\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021164; batch adversarial loss: 0.452061\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005099; batch adversarial loss: 0.459604\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031318; batch adversarial loss: 0.433788\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006907; batch adversarial loss: 0.441760\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008425; batch adversarial loss: 0.355123\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015743; batch adversarial loss: 0.530673\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024801; batch adversarial loss: 0.453383\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011377; batch adversarial loss: 0.501217\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014117; batch adversarial loss: 0.531289\n",
      "epoch 195; iter: 0; batch classifier loss: 0.002486; batch adversarial loss: 0.489744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.005266; batch adversarial loss: 0.432524\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029564; batch adversarial loss: 0.409602\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004928; batch adversarial loss: 0.519238\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013632; batch adversarial loss: 0.436087\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708580; batch adversarial loss: 0.569127\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443295; batch adversarial loss: 0.625083\n",
      "epoch 2; iter: 0; batch classifier loss: 0.297263; batch adversarial loss: 0.596064\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374624; batch adversarial loss: 0.547251\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353875; batch adversarial loss: 0.546980\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353993; batch adversarial loss: 0.544751\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328959; batch adversarial loss: 0.542454\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310575; batch adversarial loss: 0.518493\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482836; batch adversarial loss: 0.585872\n",
      "epoch 9; iter: 0; batch classifier loss: 0.423832; batch adversarial loss: 0.570432\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592988; batch adversarial loss: 0.526083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.654227; batch adversarial loss: 0.607424\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551116; batch adversarial loss: 0.500781\n",
      "epoch 13; iter: 0; batch classifier loss: 0.482305; batch adversarial loss: 0.498214\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292450; batch adversarial loss: 0.485541\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340430; batch adversarial loss: 0.456573\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358363; batch adversarial loss: 0.495822\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295100; batch adversarial loss: 0.469941\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233634; batch adversarial loss: 0.445816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.229641; batch adversarial loss: 0.415391\n",
      "epoch 20; iter: 0; batch classifier loss: 0.258339; batch adversarial loss: 0.461309\n",
      "epoch 21; iter: 0; batch classifier loss: 0.178521; batch adversarial loss: 0.417737\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193289; batch adversarial loss: 0.388863\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222466; batch adversarial loss: 0.456766\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233478; batch adversarial loss: 0.456658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306425; batch adversarial loss: 0.521415\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250583; batch adversarial loss: 0.457374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.255771; batch adversarial loss: 0.389587\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194090; batch adversarial loss: 0.481111\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206986; batch adversarial loss: 0.511478\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181430; batch adversarial loss: 0.484202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.158170; batch adversarial loss: 0.474411\n",
      "epoch 32; iter: 0; batch classifier loss: 0.170695; batch adversarial loss: 0.456620\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174802; batch adversarial loss: 0.475078\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192391; batch adversarial loss: 0.414143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.192010; batch adversarial loss: 0.431108\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154627; batch adversarial loss: 0.556249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157249; batch adversarial loss: 0.357819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.171007; batch adversarial loss: 0.440266\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185203; batch adversarial loss: 0.358156\n",
      "epoch 40; iter: 0; batch classifier loss: 0.189095; batch adversarial loss: 0.502136\n",
      "epoch 41; iter: 0; batch classifier loss: 0.183718; batch adversarial loss: 0.366943\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149355; batch adversarial loss: 0.453989\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164997; batch adversarial loss: 0.426252\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186582; batch adversarial loss: 0.379595\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108195; batch adversarial loss: 0.565093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152210; batch adversarial loss: 0.386522\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202763; batch adversarial loss: 0.390227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.164097; batch adversarial loss: 0.444416\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152986; batch adversarial loss: 0.446153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188153; batch adversarial loss: 0.483449\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171399; batch adversarial loss: 0.539770\n",
      "epoch 52; iter: 0; batch classifier loss: 0.244833; batch adversarial loss: 0.332027\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124605; batch adversarial loss: 0.469632\n",
      "epoch 54; iter: 0; batch classifier loss: 0.177302; batch adversarial loss: 0.459898\n",
      "epoch 55; iter: 0; batch classifier loss: 0.144581; batch adversarial loss: 0.375680\n",
      "epoch 56; iter: 0; batch classifier loss: 0.198515; batch adversarial loss: 0.511145\n",
      "epoch 57; iter: 0; batch classifier loss: 0.176827; batch adversarial loss: 0.433820\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170347; batch adversarial loss: 0.331430\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171353; batch adversarial loss: 0.536246\n",
      "epoch 60; iter: 0; batch classifier loss: 0.144994; batch adversarial loss: 0.473695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103156; batch adversarial loss: 0.459364\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179419; batch adversarial loss: 0.462828\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175806; batch adversarial loss: 0.407011\n",
      "epoch 64; iter: 0; batch classifier loss: 0.181939; batch adversarial loss: 0.434644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.162837; batch adversarial loss: 0.422538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.163066; batch adversarial loss: 0.510168\n",
      "epoch 67; iter: 0; batch classifier loss: 0.165725; batch adversarial loss: 0.368419\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175761; batch adversarial loss: 0.424311\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164004; batch adversarial loss: 0.380738\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122987; batch adversarial loss: 0.421646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.160875; batch adversarial loss: 0.497218\n",
      "epoch 72; iter: 0; batch classifier loss: 0.162451; batch adversarial loss: 0.572370\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198760; batch adversarial loss: 0.421059\n",
      "epoch 74; iter: 0; batch classifier loss: 0.198325; batch adversarial loss: 0.394197\n",
      "epoch 75; iter: 0; batch classifier loss: 0.196522; batch adversarial loss: 0.408317\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170726; batch adversarial loss: 0.394543\n",
      "epoch 77; iter: 0; batch classifier loss: 0.133004; batch adversarial loss: 0.407760\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135480; batch adversarial loss: 0.395204\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132079; batch adversarial loss: 0.380167\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118851; batch adversarial loss: 0.433399\n",
      "epoch 81; iter: 0; batch classifier loss: 0.136670; batch adversarial loss: 0.588256\n",
      "epoch 82; iter: 0; batch classifier loss: 0.137633; batch adversarial loss: 0.498752\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122446; batch adversarial loss: 0.470225\n",
      "epoch 84; iter: 0; batch classifier loss: 0.211005; batch adversarial loss: 0.394613\n",
      "epoch 85; iter: 0; batch classifier loss: 0.193194; batch adversarial loss: 0.421823\n",
      "epoch 86; iter: 0; batch classifier loss: 0.147115; batch adversarial loss: 0.458689\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186673; batch adversarial loss: 0.455201\n",
      "epoch 88; iter: 0; batch classifier loss: 0.156718; batch adversarial loss: 0.475365\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124922; batch adversarial loss: 0.429061\n",
      "epoch 90; iter: 0; batch classifier loss: 0.164378; batch adversarial loss: 0.466276\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098613; batch adversarial loss: 0.500647\n",
      "epoch 92; iter: 0; batch classifier loss: 0.143831; batch adversarial loss: 0.392500\n",
      "epoch 93; iter: 0; batch classifier loss: 0.151773; batch adversarial loss: 0.406214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.118718; batch adversarial loss: 0.494286\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092619; batch adversarial loss: 0.517605\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112661; batch adversarial loss: 0.403542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.127710; batch adversarial loss: 0.409084\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058388; batch adversarial loss: 0.427704\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074132; batch adversarial loss: 0.444596\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089544; batch adversarial loss: 0.458097\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060300; batch adversarial loss: 0.431707\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071703; batch adversarial loss: 0.471800\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066939; batch adversarial loss: 0.416893\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051803; batch adversarial loss: 0.455332\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045159; batch adversarial loss: 0.431098\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055173; batch adversarial loss: 0.451329\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066483; batch adversarial loss: 0.459550\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059817; batch adversarial loss: 0.394943\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074320; batch adversarial loss: 0.441131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056606; batch adversarial loss: 0.460910\n",
      "epoch 111; iter: 0; batch classifier loss: 0.119798; batch adversarial loss: 0.416542\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072844; batch adversarial loss: 0.414117\n",
      "epoch 113; iter: 0; batch classifier loss: 0.078529; batch adversarial loss: 0.388924\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053881; batch adversarial loss: 0.441768\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034416; batch adversarial loss: 0.544639\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039113; batch adversarial loss: 0.459162\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041758; batch adversarial loss: 0.446879\n",
      "epoch 118; iter: 0; batch classifier loss: 0.096763; batch adversarial loss: 0.483437\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032106; batch adversarial loss: 0.438597\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033773; batch adversarial loss: 0.479917\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039049; batch adversarial loss: 0.429615\n",
      "epoch 122; iter: 0; batch classifier loss: 0.065119; batch adversarial loss: 0.398420\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070492; batch adversarial loss: 0.326244\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070356; batch adversarial loss: 0.429614\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026370; batch adversarial loss: 0.528574\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050651; batch adversarial loss: 0.522261\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047150; batch adversarial loss: 0.421967\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028474; batch adversarial loss: 0.496967\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039931; batch adversarial loss: 0.447594\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022930; batch adversarial loss: 0.494739\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025114; batch adversarial loss: 0.439734\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034797; batch adversarial loss: 0.450011\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027135; batch adversarial loss: 0.465949\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019293; batch adversarial loss: 0.413092\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033885; batch adversarial loss: 0.416628\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042562; batch adversarial loss: 0.384136\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.475759\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046004; batch adversarial loss: 0.473379\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011611; batch adversarial loss: 0.512781\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022596; batch adversarial loss: 0.368757\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025484; batch adversarial loss: 0.446105\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011547; batch adversarial loss: 0.425430\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035488; batch adversarial loss: 0.377614\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010650; batch adversarial loss: 0.458864\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012829; batch adversarial loss: 0.426124\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023596; batch adversarial loss: 0.461434\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026944; batch adversarial loss: 0.459497\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017521; batch adversarial loss: 0.444516\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013513; batch adversarial loss: 0.428727\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026692; batch adversarial loss: 0.459328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018101; batch adversarial loss: 0.421165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017436; batch adversarial loss: 0.493057\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039554; batch adversarial loss: 0.435901\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024407; batch adversarial loss: 0.540067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025083; batch adversarial loss: 0.410840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.417223\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030322; batch adversarial loss: 0.380320\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054222; batch adversarial loss: 0.439322\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032060; batch adversarial loss: 0.530141\n",
      "epoch 160; iter: 0; batch classifier loss: 0.068131; batch adversarial loss: 0.446796\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019679; batch adversarial loss: 0.417678\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008187; batch adversarial loss: 0.455080\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014829; batch adversarial loss: 0.429917\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012805; batch adversarial loss: 0.560195\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.451626\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023387; batch adversarial loss: 0.390426\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032920; batch adversarial loss: 0.476799\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012353; batch adversarial loss: 0.514565\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025784; batch adversarial loss: 0.456838\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010686; batch adversarial loss: 0.423424\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018555; batch adversarial loss: 0.434049\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014342; batch adversarial loss: 0.403915\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027181; batch adversarial loss: 0.419174\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033795; batch adversarial loss: 0.391982\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019785; batch adversarial loss: 0.377022\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007675; batch adversarial loss: 0.483976\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026319; batch adversarial loss: 0.453986\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023110; batch adversarial loss: 0.477224\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017286; batch adversarial loss: 0.329707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038944; batch adversarial loss: 0.446547\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023661; batch adversarial loss: 0.456158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027010; batch adversarial loss: 0.446178\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020888; batch adversarial loss: 0.500791\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023969; batch adversarial loss: 0.463216\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007214; batch adversarial loss: 0.522467\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030091; batch adversarial loss: 0.406415\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.502091\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004047; batch adversarial loss: 0.419888\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007261; batch adversarial loss: 0.423307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.011490; batch adversarial loss: 0.421216\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023609; batch adversarial loss: 0.465506\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019306; batch adversarial loss: 0.447002\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003665; batch adversarial loss: 0.437936\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020844; batch adversarial loss: 0.405673\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030552; batch adversarial loss: 0.395037\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009795; batch adversarial loss: 0.463624\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011975; batch adversarial loss: 0.345700\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022787; batch adversarial loss: 0.435709\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026069; batch adversarial loss: 0.442306\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697551; batch adversarial loss: 0.806246\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443064; batch adversarial loss: 0.771661\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422123; batch adversarial loss: 0.716735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380361; batch adversarial loss: 0.696331\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303434; batch adversarial loss: 0.641879\n",
      "epoch 5; iter: 0; batch classifier loss: 0.318149; batch adversarial loss: 0.628628\n",
      "epoch 6; iter: 0; batch classifier loss: 0.379641; batch adversarial loss: 0.605164\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316310; batch adversarial loss: 0.585573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268474; batch adversarial loss: 0.553850\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278926; batch adversarial loss: 0.514971\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358087; batch adversarial loss: 0.484035\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319772; batch adversarial loss: 0.457228\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277603; batch adversarial loss: 0.509981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274001; batch adversarial loss: 0.441253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.201747; batch adversarial loss: 0.431745\n",
      "epoch 15; iter: 0; batch classifier loss: 0.245600; batch adversarial loss: 0.414348\n",
      "epoch 16; iter: 0; batch classifier loss: 0.291703; batch adversarial loss: 0.404510\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224463; batch adversarial loss: 0.422287\n",
      "epoch 18; iter: 0; batch classifier loss: 0.218900; batch adversarial loss: 0.355747\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227013; batch adversarial loss: 0.495026\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243407; batch adversarial loss: 0.375259\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193964; batch adversarial loss: 0.373041\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214384; batch adversarial loss: 0.414177\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251247; batch adversarial loss: 0.397586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220480; batch adversarial loss: 0.370604\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150840; batch adversarial loss: 0.352464\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218288; batch adversarial loss: 0.427358\n",
      "epoch 27; iter: 0; batch classifier loss: 0.216999; batch adversarial loss: 0.411576\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184471; batch adversarial loss: 0.378236\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157975; batch adversarial loss: 0.355643\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186368; batch adversarial loss: 0.444435\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152325; batch adversarial loss: 0.456620\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202184; batch adversarial loss: 0.376905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143261; batch adversarial loss: 0.327687\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133569; batch adversarial loss: 0.355139\n",
      "epoch 35; iter: 0; batch classifier loss: 0.149347; batch adversarial loss: 0.375514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172082; batch adversarial loss: 0.453488\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145422; batch adversarial loss: 0.365630\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099979; batch adversarial loss: 0.412986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104089; batch adversarial loss: 0.421805\n",
      "epoch 40; iter: 0; batch classifier loss: 0.141890; batch adversarial loss: 0.397479\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119268; batch adversarial loss: 0.303152\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104859; batch adversarial loss: 0.476522\n",
      "epoch 43; iter: 0; batch classifier loss: 0.115296; batch adversarial loss: 0.349639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118892; batch adversarial loss: 0.399419\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084344; batch adversarial loss: 0.359940\n",
      "epoch 46; iter: 0; batch classifier loss: 0.170465; batch adversarial loss: 0.368643\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073031; batch adversarial loss: 0.414094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121482; batch adversarial loss: 0.355454\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100881; batch adversarial loss: 0.369729\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117043; batch adversarial loss: 0.462265\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085859; batch adversarial loss: 0.419174\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083505; batch adversarial loss: 0.452905\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073661; batch adversarial loss: 0.384624\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094237; batch adversarial loss: 0.453299\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123434; batch adversarial loss: 0.441155\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062933; batch adversarial loss: 0.482071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073087; batch adversarial loss: 0.409773\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066955; batch adversarial loss: 0.349831\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120345; batch adversarial loss: 0.410154\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057761; batch adversarial loss: 0.311998\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075193; batch adversarial loss: 0.389827\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094960; batch adversarial loss: 0.435546\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085371; batch adversarial loss: 0.409011\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062618; batch adversarial loss: 0.408207\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074556; batch adversarial loss: 0.430196\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078233; batch adversarial loss: 0.436252\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066274; batch adversarial loss: 0.439633\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074940; batch adversarial loss: 0.467948\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056469; batch adversarial loss: 0.414606\n",
      "epoch 70; iter: 0; batch classifier loss: 0.045560; batch adversarial loss: 0.394091\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070579; batch adversarial loss: 0.423568\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069072; batch adversarial loss: 0.376636\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079040; batch adversarial loss: 0.395765\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099688; batch adversarial loss: 0.431410\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063161; batch adversarial loss: 0.385735\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110491; batch adversarial loss: 0.391383\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101341; batch adversarial loss: 0.359867\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040063; batch adversarial loss: 0.350291\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066090; batch adversarial loss: 0.346637\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082706; batch adversarial loss: 0.425917\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056952; batch adversarial loss: 0.392562\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067509; batch adversarial loss: 0.358733\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086151; batch adversarial loss: 0.478509\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071584; batch adversarial loss: 0.356914\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067389; batch adversarial loss: 0.408848\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038228; batch adversarial loss: 0.441564\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062699; batch adversarial loss: 0.404022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.069649; batch adversarial loss: 0.368524\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037024; batch adversarial loss: 0.450142\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047187; batch adversarial loss: 0.484473\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056448; batch adversarial loss: 0.366778\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052309; batch adversarial loss: 0.443669\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065398; batch adversarial loss: 0.439042\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077065; batch adversarial loss: 0.473106\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073662; batch adversarial loss: 0.449161\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054612; batch adversarial loss: 0.424541\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048305; batch adversarial loss: 0.410336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071998; batch adversarial loss: 0.415601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067839; batch adversarial loss: 0.484081\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068836; batch adversarial loss: 0.336715\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072532; batch adversarial loss: 0.404121\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046431; batch adversarial loss: 0.505632\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043291; batch adversarial loss: 0.347464\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068103; batch adversarial loss: 0.370458\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028414; batch adversarial loss: 0.351692\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032312; batch adversarial loss: 0.483311\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046397; batch adversarial loss: 0.424257\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027153; batch adversarial loss: 0.388547\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043183; batch adversarial loss: 0.391798\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067548; batch adversarial loss: 0.420919\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.399130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042609; batch adversarial loss: 0.437803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021212; batch adversarial loss: 0.388303\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.430033\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041045; batch adversarial loss: 0.506015\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051811; batch adversarial loss: 0.340680\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035967; batch adversarial loss: 0.518650\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.389242\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035225; batch adversarial loss: 0.423395\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025561; batch adversarial loss: 0.420773\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036512; batch adversarial loss: 0.459193\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030378; batch adversarial loss: 0.453931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032995; batch adversarial loss: 0.486043\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035784; batch adversarial loss: 0.443848\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049799; batch adversarial loss: 0.471786\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033343; batch adversarial loss: 0.400573\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043933; batch adversarial loss: 0.474932\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050837; batch adversarial loss: 0.367874\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029267; batch adversarial loss: 0.415623\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020767; batch adversarial loss: 0.406618\n",
      "epoch 131; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.423660\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036262; batch adversarial loss: 0.450164\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027918; batch adversarial loss: 0.387774\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033431; batch adversarial loss: 0.519049\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039540; batch adversarial loss: 0.468806\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011011; batch adversarial loss: 0.522625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.321219\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010373; batch adversarial loss: 0.609300\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013781; batch adversarial loss: 0.467282\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017086; batch adversarial loss: 0.392132\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033749; batch adversarial loss: 0.429568\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033886; batch adversarial loss: 0.495622\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040856; batch adversarial loss: 0.458402\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051655; batch adversarial loss: 0.514499\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016757; batch adversarial loss: 0.461904\n",
      "epoch 146; iter: 0; batch classifier loss: 0.057793; batch adversarial loss: 0.450703\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037937; batch adversarial loss: 0.395071\n",
      "epoch 148; iter: 0; batch classifier loss: 0.101048; batch adversarial loss: 0.571101\n",
      "epoch 149; iter: 0; batch classifier loss: 0.092731; batch adversarial loss: 0.493856\n",
      "epoch 150; iter: 0; batch classifier loss: 0.130043; batch adversarial loss: 0.773100\n",
      "epoch 151; iter: 0; batch classifier loss: 0.099148; batch adversarial loss: 0.526957\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052368; batch adversarial loss: 0.484281\n",
      "epoch 153; iter: 0; batch classifier loss: 0.115523; batch adversarial loss: 0.860796\n",
      "epoch 154; iter: 0; batch classifier loss: 0.172996; batch adversarial loss: 0.798576\n",
      "epoch 155; iter: 0; batch classifier loss: 0.104791; batch adversarial loss: 0.577297\n",
      "epoch 156; iter: 0; batch classifier loss: 0.134471; batch adversarial loss: 0.761230\n",
      "epoch 157; iter: 0; batch classifier loss: 0.159047; batch adversarial loss: 0.679613\n",
      "epoch 158; iter: 0; batch classifier loss: 0.141229; batch adversarial loss: 0.679968\n",
      "epoch 159; iter: 0; batch classifier loss: 0.168805; batch adversarial loss: 0.767094\n",
      "epoch 160; iter: 0; batch classifier loss: 0.092740; batch adversarial loss: 0.575002\n",
      "epoch 161; iter: 0; batch classifier loss: 0.164967; batch adversarial loss: 0.656036\n",
      "epoch 162; iter: 0; batch classifier loss: 0.158892; batch adversarial loss: 0.638580\n",
      "epoch 163; iter: 0; batch classifier loss: 0.235190; batch adversarial loss: 0.657501\n",
      "epoch 164; iter: 0; batch classifier loss: 0.280614; batch adversarial loss: 0.852616\n",
      "epoch 165; iter: 0; batch classifier loss: 0.189761; batch adversarial loss: 0.613316\n",
      "epoch 166; iter: 0; batch classifier loss: 0.190494; batch adversarial loss: 0.819316\n",
      "epoch 167; iter: 0; batch classifier loss: 0.255439; batch adversarial loss: 0.756220\n",
      "epoch 168; iter: 0; batch classifier loss: 0.138521; batch adversarial loss: 0.617036\n",
      "epoch 169; iter: 0; batch classifier loss: 0.153017; batch adversarial loss: 0.653545\n",
      "epoch 170; iter: 0; batch classifier loss: 0.183704; batch adversarial loss: 0.716558\n",
      "epoch 171; iter: 0; batch classifier loss: 0.137185; batch adversarial loss: 0.627011\n",
      "epoch 172; iter: 0; batch classifier loss: 0.069585; batch adversarial loss: 0.456890\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181146; batch adversarial loss: 0.605853\n",
      "epoch 174; iter: 0; batch classifier loss: 0.209679; batch adversarial loss: 0.639925\n",
      "epoch 175; iter: 0; batch classifier loss: 0.156710; batch adversarial loss: 0.542478\n",
      "epoch 176; iter: 0; batch classifier loss: 0.145458; batch adversarial loss: 0.515040\n",
      "epoch 177; iter: 0; batch classifier loss: 0.132264; batch adversarial loss: 0.482933\n",
      "epoch 178; iter: 0; batch classifier loss: 0.114395; batch adversarial loss: 0.495586\n",
      "epoch 179; iter: 0; batch classifier loss: 0.201685; batch adversarial loss: 0.634718\n",
      "epoch 180; iter: 0; batch classifier loss: 0.100900; batch adversarial loss: 0.444147\n",
      "epoch 181; iter: 0; batch classifier loss: 0.204557; batch adversarial loss: 0.600654\n",
      "epoch 182; iter: 0; batch classifier loss: 0.128814; batch adversarial loss: 0.497658\n",
      "epoch 183; iter: 0; batch classifier loss: 0.093307; batch adversarial loss: 0.535738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.129879; batch adversarial loss: 0.467549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.164704; batch adversarial loss: 0.509280\n",
      "epoch 186; iter: 0; batch classifier loss: 0.090143; batch adversarial loss: 0.425034\n",
      "epoch 187; iter: 0; batch classifier loss: 0.144245; batch adversarial loss: 0.560416\n",
      "epoch 188; iter: 0; batch classifier loss: 0.167497; batch adversarial loss: 0.593600\n",
      "epoch 189; iter: 0; batch classifier loss: 0.104955; batch adversarial loss: 0.421743\n",
      "epoch 190; iter: 0; batch classifier loss: 0.209387; batch adversarial loss: 0.547223\n",
      "epoch 191; iter: 0; batch classifier loss: 0.107225; batch adversarial loss: 0.503773\n",
      "epoch 192; iter: 0; batch classifier loss: 0.122056; batch adversarial loss: 0.506362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.143842; batch adversarial loss: 0.418285\n",
      "epoch 194; iter: 0; batch classifier loss: 0.110934; batch adversarial loss: 0.469968\n",
      "epoch 195; iter: 0; batch classifier loss: 0.130536; batch adversarial loss: 0.512310\n",
      "epoch 196; iter: 0; batch classifier loss: 0.128488; batch adversarial loss: 0.577068\n",
      "epoch 197; iter: 0; batch classifier loss: 0.114838; batch adversarial loss: 0.508463\n",
      "epoch 198; iter: 0; batch classifier loss: 0.132785; batch adversarial loss: 0.507557\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045507; batch adversarial loss: 0.364196\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652684; batch adversarial loss: 0.696656\n",
      "epoch 1; iter: 0; batch classifier loss: 0.520652; batch adversarial loss: 0.661925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.370489; batch adversarial loss: 0.622111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367485; batch adversarial loss: 0.595676\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369454; batch adversarial loss: 0.538392\n",
      "epoch 5; iter: 0; batch classifier loss: 0.233751; batch adversarial loss: 0.528441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.238408; batch adversarial loss: 0.518866\n",
      "epoch 7; iter: 0; batch classifier loss: 0.238786; batch adversarial loss: 0.543472\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298184; batch adversarial loss: 0.540499\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236848; batch adversarial loss: 0.523492\n",
      "epoch 10; iter: 0; batch classifier loss: 0.211031; batch adversarial loss: 0.514798\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290351; batch adversarial loss: 0.502445\n",
      "epoch 12; iter: 0; batch classifier loss: 0.222274; batch adversarial loss: 0.504528\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227966; batch adversarial loss: 0.481396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268652; batch adversarial loss: 0.559903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228946; batch adversarial loss: 0.453881\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290530; batch adversarial loss: 0.502902\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224247; batch adversarial loss: 0.545450\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214533; batch adversarial loss: 0.531399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324413; batch adversarial loss: 0.514751\n",
      "epoch 20; iter: 0; batch classifier loss: 0.301100; batch adversarial loss: 0.515223\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341671; batch adversarial loss: 0.531774\n",
      "epoch 22; iter: 0; batch classifier loss: 0.403090; batch adversarial loss: 0.571739\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351610; batch adversarial loss: 0.457684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.374746; batch adversarial loss: 0.429082\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241787; batch adversarial loss: 0.452983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184731; batch adversarial loss: 0.447714\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118594; batch adversarial loss: 0.487286\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173140; batch adversarial loss: 0.379752\n",
      "epoch 29; iter: 0; batch classifier loss: 0.117416; batch adversarial loss: 0.354165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.077421; batch adversarial loss: 0.495433\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143659; batch adversarial loss: 0.472495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117204; batch adversarial loss: 0.429966\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121009; batch adversarial loss: 0.474388\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137700; batch adversarial loss: 0.477740\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126099; batch adversarial loss: 0.525692\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125563; batch adversarial loss: 0.589850\n",
      "epoch 37; iter: 0; batch classifier loss: 0.103327; batch adversarial loss: 0.522466\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111891; batch adversarial loss: 0.396293\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122348; batch adversarial loss: 0.515197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099644; batch adversarial loss: 0.440013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149070; batch adversarial loss: 0.503715\n",
      "epoch 42; iter: 0; batch classifier loss: 0.085356; batch adversarial loss: 0.493106\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151441; batch adversarial loss: 0.363495\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175208; batch adversarial loss: 0.383693\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113035; batch adversarial loss: 0.425249\n",
      "epoch 46; iter: 0; batch classifier loss: 0.071893; batch adversarial loss: 0.454614\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077615; batch adversarial loss: 0.496796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122635; batch adversarial loss: 0.424754\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106389; batch adversarial loss: 0.419123\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106924; batch adversarial loss: 0.405184\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121894; batch adversarial loss: 0.433541\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085241; batch adversarial loss: 0.437846\n",
      "epoch 53; iter: 0; batch classifier loss: 0.136591; batch adversarial loss: 0.401955\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117759; batch adversarial loss: 0.463863\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182617; batch adversarial loss: 0.408031\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095677; batch adversarial loss: 0.460160\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097056; batch adversarial loss: 0.475751\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124753; batch adversarial loss: 0.406923\n",
      "epoch 59; iter: 0; batch classifier loss: 0.125930; batch adversarial loss: 0.532515\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086767; batch adversarial loss: 0.350100\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124733; batch adversarial loss: 0.429741\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084996; batch adversarial loss: 0.513861\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126336; batch adversarial loss: 0.400889\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068672; batch adversarial loss: 0.422344\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108312; batch adversarial loss: 0.366298\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090458; batch adversarial loss: 0.510630\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138930; batch adversarial loss: 0.409973\n",
      "epoch 68; iter: 0; batch classifier loss: 0.124692; batch adversarial loss: 0.540886\n",
      "epoch 69; iter: 0; batch classifier loss: 0.118763; batch adversarial loss: 0.470546\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078902; batch adversarial loss: 0.471342\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077885; batch adversarial loss: 0.481806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109395; batch adversarial loss: 0.460971\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114060; batch adversarial loss: 0.491525\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081089; batch adversarial loss: 0.546801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061671; batch adversarial loss: 0.429946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126130; batch adversarial loss: 0.513635\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087420; batch adversarial loss: 0.521414\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102262; batch adversarial loss: 0.498275\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098277; batch adversarial loss: 0.458580\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061752; batch adversarial loss: 0.452809\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115757; batch adversarial loss: 0.471687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.077791; batch adversarial loss: 0.460184\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039598; batch adversarial loss: 0.450483\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075915; batch adversarial loss: 0.481950\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.447857\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076669; batch adversarial loss: 0.437925\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056874; batch adversarial loss: 0.467977\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058596; batch adversarial loss: 0.427924\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067924; batch adversarial loss: 0.588778\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071257; batch adversarial loss: 0.482987\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045024; batch adversarial loss: 0.449093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054088; batch adversarial loss: 0.488197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056824; batch adversarial loss: 0.385997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.114172; batch adversarial loss: 0.435336\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037059; batch adversarial loss: 0.530220\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035531; batch adversarial loss: 0.489628\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069839; batch adversarial loss: 0.493105\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036383; batch adversarial loss: 0.491950\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062816; batch adversarial loss: 0.447945\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068171; batch adversarial loss: 0.468756\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042116; batch adversarial loss: 0.486907\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091741; batch adversarial loss: 0.424940\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055889; batch adversarial loss: 0.443409\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062580; batch adversarial loss: 0.406928\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060083; batch adversarial loss: 0.451919\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030708; batch adversarial loss: 0.509579\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053115; batch adversarial loss: 0.462681\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040929; batch adversarial loss: 0.494051\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055074; batch adversarial loss: 0.466201\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057432; batch adversarial loss: 0.521776\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054130; batch adversarial loss: 0.440203\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030646; batch adversarial loss: 0.474602\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070266; batch adversarial loss: 0.428155\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053217; batch adversarial loss: 0.415224\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061880; batch adversarial loss: 0.487245\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065080; batch adversarial loss: 0.501931\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031518; batch adversarial loss: 0.545066\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051706; batch adversarial loss: 0.456311\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068040; batch adversarial loss: 0.550954\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027580; batch adversarial loss: 0.554200\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027076; batch adversarial loss: 0.440074\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069033; batch adversarial loss: 0.453954\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030627; batch adversarial loss: 0.516066\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042602; batch adversarial loss: 0.417752\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050265; batch adversarial loss: 0.497806\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066175; batch adversarial loss: 0.471056\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096671; batch adversarial loss: 0.527242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023897; batch adversarial loss: 0.495420\n",
      "epoch 129; iter: 0; batch classifier loss: 0.080862; batch adversarial loss: 0.479881\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029359; batch adversarial loss: 0.451958\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046264; batch adversarial loss: 0.416776\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022526; batch adversarial loss: 0.459034\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036240; batch adversarial loss: 0.490944\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052521; batch adversarial loss: 0.467816\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042909; batch adversarial loss: 0.443146\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022779; batch adversarial loss: 0.480694\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014286; batch adversarial loss: 0.443084\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048663; batch adversarial loss: 0.436490\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025470; batch adversarial loss: 0.424889\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022046; batch adversarial loss: 0.390769\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044313; batch adversarial loss: 0.488413\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031121; batch adversarial loss: 0.487198\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024015; batch adversarial loss: 0.383364\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049043; batch adversarial loss: 0.394503\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018725; batch adversarial loss: 0.357215\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028360; batch adversarial loss: 0.415305\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010196; batch adversarial loss: 0.408936\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048325; batch adversarial loss: 0.435420\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038349; batch adversarial loss: 0.416044\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014869; batch adversarial loss: 0.395010\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055354; batch adversarial loss: 0.432592\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040777; batch adversarial loss: 0.506109\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012694; batch adversarial loss: 0.385032\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.405530\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028231; batch adversarial loss: 0.409795\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038672; batch adversarial loss: 0.501493\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024343; batch adversarial loss: 0.388928\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020776; batch adversarial loss: 0.421349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015845; batch adversarial loss: 0.483489\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022468; batch adversarial loss: 0.433850\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006554; batch adversarial loss: 0.470036\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061772; batch adversarial loss: 0.465629\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044903; batch adversarial loss: 0.467019\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033865; batch adversarial loss: 0.409512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010152; batch adversarial loss: 0.504918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035934; batch adversarial loss: 0.497598\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020850; batch adversarial loss: 0.436245\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014858; batch adversarial loss: 0.437976\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027864; batch adversarial loss: 0.372300\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014362; batch adversarial loss: 0.493779\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033037; batch adversarial loss: 0.497385\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049517; batch adversarial loss: 0.460880\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036169; batch adversarial loss: 0.440922\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015999; batch adversarial loss: 0.568608\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022722; batch adversarial loss: 0.446250\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027107; batch adversarial loss: 0.463420\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015712; batch adversarial loss: 0.476066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.016936; batch adversarial loss: 0.459586\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043122; batch adversarial loss: 0.405345\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010697; batch adversarial loss: 0.504143\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013678; batch adversarial loss: 0.464184\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.428579\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028373; batch adversarial loss: 0.448929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044136; batch adversarial loss: 0.528016\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010710; batch adversarial loss: 0.461359\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044869; batch adversarial loss: 0.416503\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023129; batch adversarial loss: 0.443078\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012736; batch adversarial loss: 0.417410\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026778; batch adversarial loss: 0.555401\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019600; batch adversarial loss: 0.459054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.073020; batch adversarial loss: 0.444670\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038818; batch adversarial loss: 0.488508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006918; batch adversarial loss: 0.407600\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.544738\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011786; batch adversarial loss: 0.402872\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031239; batch adversarial loss: 0.504635\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016449; batch adversarial loss: 0.423020\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012287; batch adversarial loss: 0.418218\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022236; batch adversarial loss: 0.423157\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691155; batch adversarial loss: 0.618386\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470731; batch adversarial loss: 0.628621\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458930; batch adversarial loss: 0.623072\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511632; batch adversarial loss: 0.617992\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501223; batch adversarial loss: 0.636619\n",
      "epoch 5; iter: 0; batch classifier loss: 0.528576; batch adversarial loss: 0.597835\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639364; batch adversarial loss: 0.541976\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624748; batch adversarial loss: 0.555584\n",
      "epoch 8; iter: 0; batch classifier loss: 0.425335; batch adversarial loss: 0.549551\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384133; batch adversarial loss: 0.544969\n",
      "epoch 10; iter: 0; batch classifier loss: 0.376067; batch adversarial loss: 0.578187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364250; batch adversarial loss: 0.540724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.465331; batch adversarial loss: 0.503139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406730; batch adversarial loss: 0.515075\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354527; batch adversarial loss: 0.482747\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379649; batch adversarial loss: 0.473462\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345557; batch adversarial loss: 0.472975\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352892; batch adversarial loss: 0.525553\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302863; batch adversarial loss: 0.531859\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299135; batch adversarial loss: 0.533701\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257186; batch adversarial loss: 0.456871\n",
      "epoch 21; iter: 0; batch classifier loss: 0.284847; batch adversarial loss: 0.425220\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273067; batch adversarial loss: 0.484904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.320180; batch adversarial loss: 0.464402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360261; batch adversarial loss: 0.414777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351833; batch adversarial loss: 0.414455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243096; batch adversarial loss: 0.494562\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291740; batch adversarial loss: 0.412798\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231613; batch adversarial loss: 0.469050\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242166; batch adversarial loss: 0.563513\n",
      "epoch 30; iter: 0; batch classifier loss: 0.277052; batch adversarial loss: 0.427076\n",
      "epoch 31; iter: 0; batch classifier loss: 0.274617; batch adversarial loss: 0.391496\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210593; batch adversarial loss: 0.492892\n",
      "epoch 33; iter: 0; batch classifier loss: 0.231034; batch adversarial loss: 0.443150\n",
      "epoch 34; iter: 0; batch classifier loss: 0.272953; batch adversarial loss: 0.496719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239804; batch adversarial loss: 0.499451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.181158; batch adversarial loss: 0.527689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208276; batch adversarial loss: 0.479676\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247944; batch adversarial loss: 0.439793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.256182; batch adversarial loss: 0.405430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216352; batch adversarial loss: 0.423220\n",
      "epoch 41; iter: 0; batch classifier loss: 0.193635; batch adversarial loss: 0.528196\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253558; batch adversarial loss: 0.461483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209337; batch adversarial loss: 0.517335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.292983; batch adversarial loss: 0.470465\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125602; batch adversarial loss: 0.494597\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107568; batch adversarial loss: 0.446052\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085556; batch adversarial loss: 0.485916\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142901; batch adversarial loss: 0.460986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225771; batch adversarial loss: 0.543350\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127313; batch adversarial loss: 0.423729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.147713; batch adversarial loss: 0.435695\n",
      "epoch 52; iter: 0; batch classifier loss: 0.282562; batch adversarial loss: 0.519514\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186317; batch adversarial loss: 0.520865\n",
      "epoch 54; iter: 0; batch classifier loss: 0.145219; batch adversarial loss: 0.458462\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142984; batch adversarial loss: 0.533480\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160089; batch adversarial loss: 0.483380\n",
      "epoch 57; iter: 0; batch classifier loss: 0.192215; batch adversarial loss: 0.495925\n",
      "epoch 58; iter: 0; batch classifier loss: 0.197827; batch adversarial loss: 0.520129\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212810; batch adversarial loss: 0.409853\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123177; batch adversarial loss: 0.421830\n",
      "epoch 61; iter: 0; batch classifier loss: 0.160752; batch adversarial loss: 0.396081\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146517; batch adversarial loss: 0.410759\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157250; batch adversarial loss: 0.496689\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112905; batch adversarial loss: 0.422305\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174343; batch adversarial loss: 0.469219\n",
      "epoch 66; iter: 0; batch classifier loss: 0.267814; batch adversarial loss: 0.459652\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124068; batch adversarial loss: 0.533706\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116885; batch adversarial loss: 0.460791\n",
      "epoch 69; iter: 0; batch classifier loss: 0.182262; batch adversarial loss: 0.548335\n",
      "epoch 70; iter: 0; batch classifier loss: 0.170823; batch adversarial loss: 0.433772\n",
      "epoch 71; iter: 0; batch classifier loss: 0.106611; batch adversarial loss: 0.471220\n",
      "epoch 72; iter: 0; batch classifier loss: 0.257557; batch adversarial loss: 0.309201\n",
      "epoch 73; iter: 0; batch classifier loss: 0.210598; batch adversarial loss: 0.447209\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123744; batch adversarial loss: 0.470376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121708; batch adversarial loss: 0.408093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.128676; batch adversarial loss: 0.392618\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138212; batch adversarial loss: 0.457866\n",
      "epoch 78; iter: 0; batch classifier loss: 0.196947; batch adversarial loss: 0.522331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098735; batch adversarial loss: 0.484048\n",
      "epoch 80; iter: 0; batch classifier loss: 0.232460; batch adversarial loss: 0.446385\n",
      "epoch 81; iter: 0; batch classifier loss: 0.150743; batch adversarial loss: 0.473394\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109371; batch adversarial loss: 0.482772\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121593; batch adversarial loss: 0.484444\n",
      "epoch 84; iter: 0; batch classifier loss: 0.156902; batch adversarial loss: 0.520495\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150453; batch adversarial loss: 0.434112\n",
      "epoch 86; iter: 0; batch classifier loss: 0.207211; batch adversarial loss: 0.408732\n",
      "epoch 87; iter: 0; batch classifier loss: 0.168447; batch adversarial loss: 0.470767\n",
      "epoch 88; iter: 0; batch classifier loss: 0.146229; batch adversarial loss: 0.384556\n",
      "epoch 89; iter: 0; batch classifier loss: 0.119726; batch adversarial loss: 0.484351\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118649; batch adversarial loss: 0.483027\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166180; batch adversarial loss: 0.471716\n",
      "epoch 92; iter: 0; batch classifier loss: 0.201082; batch adversarial loss: 0.459666\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201169; batch adversarial loss: 0.445793\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187106; batch adversarial loss: 0.446055\n",
      "epoch 95; iter: 0; batch classifier loss: 0.171666; batch adversarial loss: 0.495390\n",
      "epoch 96; iter: 0; batch classifier loss: 0.204668; batch adversarial loss: 0.495404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.158120; batch adversarial loss: 0.495098\n",
      "epoch 98; iter: 0; batch classifier loss: 0.207909; batch adversarial loss: 0.446821\n",
      "epoch 99; iter: 0; batch classifier loss: 0.147743; batch adversarial loss: 0.445591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.168512; batch adversarial loss: 0.496267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.199397; batch adversarial loss: 0.433364\n",
      "epoch 102; iter: 0; batch classifier loss: 0.181146; batch adversarial loss: 0.371783\n",
      "epoch 103; iter: 0; batch classifier loss: 0.107377; batch adversarial loss: 0.446471\n",
      "epoch 104; iter: 0; batch classifier loss: 0.122998; batch adversarial loss: 0.497090\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073520; batch adversarial loss: 0.445602\n",
      "epoch 106; iter: 0; batch classifier loss: 0.135247; batch adversarial loss: 0.481924\n",
      "epoch 107; iter: 0; batch classifier loss: 0.107385; batch adversarial loss: 0.456104\n",
      "epoch 108; iter: 0; batch classifier loss: 0.123978; batch adversarial loss: 0.370303\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141869; batch adversarial loss: 0.432339\n",
      "epoch 110; iter: 0; batch classifier loss: 0.099260; batch adversarial loss: 0.502757\n",
      "epoch 111; iter: 0; batch classifier loss: 0.087205; batch adversarial loss: 0.404742\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072095; batch adversarial loss: 0.319002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054529; batch adversarial loss: 0.492908\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067085; batch adversarial loss: 0.474001\n",
      "epoch 115; iter: 0; batch classifier loss: 0.116286; batch adversarial loss: 0.342105\n",
      "epoch 116; iter: 0; batch classifier loss: 0.109387; batch adversarial loss: 0.419285\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047704; batch adversarial loss: 0.459893\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061149; batch adversarial loss: 0.429565\n",
      "epoch 119; iter: 0; batch classifier loss: 0.070370; batch adversarial loss: 0.442074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.093570; batch adversarial loss: 0.430360\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058627; batch adversarial loss: 0.408764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039682; batch adversarial loss: 0.419076\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029844; batch adversarial loss: 0.374045\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047917; batch adversarial loss: 0.441668\n",
      "epoch 125; iter: 0; batch classifier loss: 0.104244; batch adversarial loss: 0.487818\n",
      "epoch 126; iter: 0; batch classifier loss: 0.074634; batch adversarial loss: 0.466379\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029571; batch adversarial loss: 0.417409\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048033; batch adversarial loss: 0.503182\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049785; batch adversarial loss: 0.415848\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036476; batch adversarial loss: 0.396828\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040660; batch adversarial loss: 0.502548\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048999; batch adversarial loss: 0.466886\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032735; batch adversarial loss: 0.483735\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025899; batch adversarial loss: 0.392411\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031495; batch adversarial loss: 0.410330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046534; batch adversarial loss: 0.501011\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026809; batch adversarial loss: 0.464712\n",
      "epoch 138; iter: 0; batch classifier loss: 0.067078; batch adversarial loss: 0.447119\n",
      "epoch 139; iter: 0; batch classifier loss: 0.069369; batch adversarial loss: 0.424587\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028718; batch adversarial loss: 0.380326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037762; batch adversarial loss: 0.493578\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020737; batch adversarial loss: 0.495871\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041061; batch adversarial loss: 0.413302\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029066; batch adversarial loss: 0.409522\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043938; batch adversarial loss: 0.497148\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061592; batch adversarial loss: 0.361480\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052735; batch adversarial loss: 0.472236\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029150; batch adversarial loss: 0.556293\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038992; batch adversarial loss: 0.495843\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042847; batch adversarial loss: 0.467746\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.462061\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025808; batch adversarial loss: 0.413404\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043349; batch adversarial loss: 0.521670\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028843; batch adversarial loss: 0.442168\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050408; batch adversarial loss: 0.448566\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019052; batch adversarial loss: 0.427106\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008595; batch adversarial loss: 0.493809\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010516; batch adversarial loss: 0.469813\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016316; batch adversarial loss: 0.379638\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017580; batch adversarial loss: 0.361194\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033295; batch adversarial loss: 0.395585\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046179; batch adversarial loss: 0.430873\n",
      "epoch 163; iter: 0; batch classifier loss: 0.049988; batch adversarial loss: 0.538778\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012819; batch adversarial loss: 0.419522\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026368; batch adversarial loss: 0.415686\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029537; batch adversarial loss: 0.387354\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026458; batch adversarial loss: 0.502975\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032935; batch adversarial loss: 0.466151\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010114; batch adversarial loss: 0.468880\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038390; batch adversarial loss: 0.541566\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008658; batch adversarial loss: 0.444292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.032748; batch adversarial loss: 0.475426\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018895; batch adversarial loss: 0.380809\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030364; batch adversarial loss: 0.365821\n",
      "epoch 175; iter: 0; batch classifier loss: 0.032108; batch adversarial loss: 0.439611\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020025; batch adversarial loss: 0.558717\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020335; batch adversarial loss: 0.527409\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046078; batch adversarial loss: 0.561038\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011001; batch adversarial loss: 0.486418\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024420; batch adversarial loss: 0.474790\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033100; batch adversarial loss: 0.499915\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027100; batch adversarial loss: 0.509035\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017529; batch adversarial loss: 0.518298\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007584; batch adversarial loss: 0.489368\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011487; batch adversarial loss: 0.382197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005846; batch adversarial loss: 0.421713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.460233\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025893; batch adversarial loss: 0.426312\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005077; batch adversarial loss: 0.457632\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012456; batch adversarial loss: 0.408338\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020906; batch adversarial loss: 0.397356\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023129; batch adversarial loss: 0.514505\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031264; batch adversarial loss: 0.566160\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006495; batch adversarial loss: 0.406175\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029901; batch adversarial loss: 0.458724\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016720; batch adversarial loss: 0.449928\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017246; batch adversarial loss: 0.470041\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030982; batch adversarial loss: 0.494057\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015409; batch adversarial loss: 0.388034\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676326; batch adversarial loss: 0.701092\n",
      "epoch 1; iter: 0; batch classifier loss: 0.549846; batch adversarial loss: 0.675959\n",
      "epoch 2; iter: 0; batch classifier loss: 0.485398; batch adversarial loss: 0.640695\n",
      "epoch 3; iter: 0; batch classifier loss: 0.421114; batch adversarial loss: 0.587192\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320828; batch adversarial loss: 0.576890\n",
      "epoch 5; iter: 0; batch classifier loss: 0.304652; batch adversarial loss: 0.548267\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315582; batch adversarial loss: 0.531401\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327253; batch adversarial loss: 0.500332\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325004; batch adversarial loss: 0.532442\n",
      "epoch 9; iter: 0; batch classifier loss: 0.259763; batch adversarial loss: 0.506694\n",
      "epoch 10; iter: 0; batch classifier loss: 0.192550; batch adversarial loss: 0.494787\n",
      "epoch 11; iter: 0; batch classifier loss: 0.250356; batch adversarial loss: 0.476732\n",
      "epoch 12; iter: 0; batch classifier loss: 0.188124; batch adversarial loss: 0.501390\n",
      "epoch 13; iter: 0; batch classifier loss: 0.208220; batch adversarial loss: 0.421346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.150072; batch adversarial loss: 0.472162\n",
      "epoch 15; iter: 0; batch classifier loss: 0.148453; batch adversarial loss: 0.440443\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178701; batch adversarial loss: 0.490879\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183848; batch adversarial loss: 0.438306\n",
      "epoch 18; iter: 0; batch classifier loss: 0.107578; batch adversarial loss: 0.560131\n",
      "epoch 19; iter: 0; batch classifier loss: 0.123645; batch adversarial loss: 0.456928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133789; batch adversarial loss: 0.543774\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135296; batch adversarial loss: 0.469746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226159; batch adversarial loss: 0.474144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164477; batch adversarial loss: 0.383238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.132386; batch adversarial loss: 0.415900\n",
      "epoch 25; iter: 0; batch classifier loss: 0.126298; batch adversarial loss: 0.448288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159496; batch adversarial loss: 0.529175\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167469; batch adversarial loss: 0.539227\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190714; batch adversarial loss: 0.517979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220546; batch adversarial loss: 0.389044\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171172; batch adversarial loss: 0.391065\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244776; batch adversarial loss: 0.419125\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200330; batch adversarial loss: 0.409999\n",
      "epoch 33; iter: 0; batch classifier loss: 0.328358; batch adversarial loss: 0.499330\n",
      "epoch 34; iter: 0; batch classifier loss: 0.220498; batch adversarial loss: 0.394448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146992; batch adversarial loss: 0.490102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134876; batch adversarial loss: 0.450354\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074960; batch adversarial loss: 0.384755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125168; batch adversarial loss: 0.390046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.068682; batch adversarial loss: 0.429635\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083261; batch adversarial loss: 0.450848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.055817; batch adversarial loss: 0.537695\n",
      "epoch 42; iter: 0; batch classifier loss: 0.068131; batch adversarial loss: 0.399236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.053882; batch adversarial loss: 0.538032\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091182; batch adversarial loss: 0.475248\n",
      "epoch 45; iter: 0; batch classifier loss: 0.058082; batch adversarial loss: 0.471394\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104980; batch adversarial loss: 0.454794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.065648; batch adversarial loss: 0.423687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091206; batch adversarial loss: 0.448338\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109559; batch adversarial loss: 0.421434\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066153; batch adversarial loss: 0.384664\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085173; batch adversarial loss: 0.489022\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070328; batch adversarial loss: 0.539286\n",
      "epoch 53; iter: 0; batch classifier loss: 0.053664; batch adversarial loss: 0.536979\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083621; batch adversarial loss: 0.390047\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098694; batch adversarial loss: 0.442978\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080927; batch adversarial loss: 0.465983\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085058; batch adversarial loss: 0.456662\n",
      "epoch 58; iter: 0; batch classifier loss: 0.055851; batch adversarial loss: 0.356761\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097805; batch adversarial loss: 0.549836\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071371; batch adversarial loss: 0.435372\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071686; batch adversarial loss: 0.406343\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086179; batch adversarial loss: 0.449477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.046839; batch adversarial loss: 0.403391\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069043; batch adversarial loss: 0.490961\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073530; batch adversarial loss: 0.519949\n",
      "epoch 66; iter: 0; batch classifier loss: 0.063054; batch adversarial loss: 0.447974\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070289; batch adversarial loss: 0.399213\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064885; batch adversarial loss: 0.573577\n",
      "epoch 69; iter: 0; batch classifier loss: 0.062501; batch adversarial loss: 0.381476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.102520; batch adversarial loss: 0.409550\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064970; batch adversarial loss: 0.411786\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058490; batch adversarial loss: 0.407672\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048095; batch adversarial loss: 0.486100\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098991; batch adversarial loss: 0.501537\n",
      "epoch 75; iter: 0; batch classifier loss: 0.033871; batch adversarial loss: 0.467165\n",
      "epoch 76; iter: 0; batch classifier loss: 0.095434; batch adversarial loss: 0.457384\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041583; batch adversarial loss: 0.478640\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043491; batch adversarial loss: 0.422840\n",
      "epoch 79; iter: 0; batch classifier loss: 0.037345; batch adversarial loss: 0.432932\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064631; batch adversarial loss: 0.407379\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076300; batch adversarial loss: 0.471086\n",
      "epoch 82; iter: 0; batch classifier loss: 0.122220; batch adversarial loss: 0.404143\n",
      "epoch 83; iter: 0; batch classifier loss: 0.046087; batch adversarial loss: 0.451526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055835; batch adversarial loss: 0.525224\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057598; batch adversarial loss: 0.559953\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035256; batch adversarial loss: 0.478765\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048889; batch adversarial loss: 0.512229\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042987; batch adversarial loss: 0.441807\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030439; batch adversarial loss: 0.462527\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043007; batch adversarial loss: 0.434854\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095972; batch adversarial loss: 0.372396\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040631; batch adversarial loss: 0.507826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050024; batch adversarial loss: 0.402182\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044779; batch adversarial loss: 0.502907\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076639; batch adversarial loss: 0.359255\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028774; batch adversarial loss: 0.372218\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059463; batch adversarial loss: 0.485990\n",
      "epoch 98; iter: 0; batch classifier loss: 0.027300; batch adversarial loss: 0.534868\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062642; batch adversarial loss: 0.381907\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054685; batch adversarial loss: 0.407438\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050155; batch adversarial loss: 0.394918\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058455; batch adversarial loss: 0.539139\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058787; batch adversarial loss: 0.447286\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.399095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044413; batch adversarial loss: 0.454004\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022398; batch adversarial loss: 0.471598\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028104; batch adversarial loss: 0.451112\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039296; batch adversarial loss: 0.412426\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025883; batch adversarial loss: 0.458818\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052626; batch adversarial loss: 0.450858\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044282; batch adversarial loss: 0.453393\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042152; batch adversarial loss: 0.432056\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016388; batch adversarial loss: 0.478572\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048270; batch adversarial loss: 0.418358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023696; batch adversarial loss: 0.481595\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.395381\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035374; batch adversarial loss: 0.450996\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036368; batch adversarial loss: 0.527534\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016188; batch adversarial loss: 0.518618\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069482; batch adversarial loss: 0.411037\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048156; batch adversarial loss: 0.486197\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021500; batch adversarial loss: 0.482821\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.511941\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038879; batch adversarial loss: 0.530836\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018290; batch adversarial loss: 0.470494\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034100; batch adversarial loss: 0.451194\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037128; batch adversarial loss: 0.440085\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039503; batch adversarial loss: 0.497808\n",
      "epoch 129; iter: 0; batch classifier loss: 0.105147; batch adversarial loss: 0.520573\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050758; batch adversarial loss: 0.496827\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017282; batch adversarial loss: 0.546520\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023593; batch adversarial loss: 0.442041\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048985; batch adversarial loss: 0.470870\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046896; batch adversarial loss: 0.417118\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031208; batch adversarial loss: 0.416140\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.425636\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037348; batch adversarial loss: 0.430379\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019832; batch adversarial loss: 0.464404\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010567; batch adversarial loss: 0.469865\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051051; batch adversarial loss: 0.416856\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019570; batch adversarial loss: 0.395731\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026163; batch adversarial loss: 0.383040\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046728; batch adversarial loss: 0.445854\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020666; batch adversarial loss: 0.410454\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024598; batch adversarial loss: 0.437950\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044010; batch adversarial loss: 0.467763\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040184; batch adversarial loss: 0.579074\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028390; batch adversarial loss: 0.405901\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045335; batch adversarial loss: 0.382176\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005573; batch adversarial loss: 0.387170\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013908; batch adversarial loss: 0.466008\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017621; batch adversarial loss: 0.553482\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011180; batch adversarial loss: 0.504302\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043130; batch adversarial loss: 0.433101\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018385; batch adversarial loss: 0.517691\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.415462\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050700; batch adversarial loss: 0.409458\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014899; batch adversarial loss: 0.366434\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027053; batch adversarial loss: 0.564299\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046949; batch adversarial loss: 0.448899\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013038; batch adversarial loss: 0.433144\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010735; batch adversarial loss: 0.456847\n",
      "epoch 163; iter: 0; batch classifier loss: 0.002481; batch adversarial loss: 0.465968\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.469815\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051653; batch adversarial loss: 0.499114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.393405\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022656; batch adversarial loss: 0.384671\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041130; batch adversarial loss: 0.442700\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012501; batch adversarial loss: 0.446361\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020561; batch adversarial loss: 0.454879\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007299; batch adversarial loss: 0.435478\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011273; batch adversarial loss: 0.471257\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017096; batch adversarial loss: 0.454803\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037762; batch adversarial loss: 0.542175\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036574; batch adversarial loss: 0.473237\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022187; batch adversarial loss: 0.442310\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.478563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014545; batch adversarial loss: 0.416527\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015313; batch adversarial loss: 0.426944\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031563; batch adversarial loss: 0.440241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005549; batch adversarial loss: 0.363842\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018525; batch adversarial loss: 0.482872\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023071; batch adversarial loss: 0.359229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011958; batch adversarial loss: 0.516381\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006809; batch adversarial loss: 0.416093\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018706; batch adversarial loss: 0.494654\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015260; batch adversarial loss: 0.488416\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049716; batch adversarial loss: 0.357487\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034848; batch adversarial loss: 0.377375\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026078; batch adversarial loss: 0.410806\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041871; batch adversarial loss: 0.465368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013008; batch adversarial loss: 0.454281\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043816; batch adversarial loss: 0.465335\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019306; batch adversarial loss: 0.444599\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016375; batch adversarial loss: 0.380536\n",
      "epoch 196; iter: 0; batch classifier loss: 0.052191; batch adversarial loss: 0.406566\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005565; batch adversarial loss: 0.450606\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016553; batch adversarial loss: 0.481433\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007269; batch adversarial loss: 0.456825\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697362; batch adversarial loss: 0.742601\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463174; batch adversarial loss: 0.727078\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380368; batch adversarial loss: 0.728327\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397794; batch adversarial loss: 0.696999\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367859; batch adversarial loss: 0.673882\n",
      "epoch 5; iter: 0; batch classifier loss: 0.374839; batch adversarial loss: 0.603027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284279; batch adversarial loss: 0.570302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.349227; batch adversarial loss: 0.526931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293980; batch adversarial loss: 0.526816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.303819; batch adversarial loss: 0.558889\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253778; batch adversarial loss: 0.495247\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311624; batch adversarial loss: 0.460221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.243986; batch adversarial loss: 0.445750\n",
      "epoch 13; iter: 0; batch classifier loss: 0.231245; batch adversarial loss: 0.421392\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200738; batch adversarial loss: 0.479918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192545; batch adversarial loss: 0.465944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.167173; batch adversarial loss: 0.482513\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185373; batch adversarial loss: 0.472584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191905; batch adversarial loss: 0.439512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.183649; batch adversarial loss: 0.459492\n",
      "epoch 20; iter: 0; batch classifier loss: 0.152240; batch adversarial loss: 0.479170\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155370; batch adversarial loss: 0.451053\n",
      "epoch 22; iter: 0; batch classifier loss: 0.121891; batch adversarial loss: 0.457249\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150134; batch adversarial loss: 0.401213\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158535; batch adversarial loss: 0.422902\n",
      "epoch 25; iter: 0; batch classifier loss: 0.134811; batch adversarial loss: 0.362090\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116983; batch adversarial loss: 0.494497\n",
      "epoch 27; iter: 0; batch classifier loss: 0.108814; batch adversarial loss: 0.408708\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124047; batch adversarial loss: 0.457984\n",
      "epoch 29; iter: 0; batch classifier loss: 0.094602; batch adversarial loss: 0.441604\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131253; batch adversarial loss: 0.344996\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153817; batch adversarial loss: 0.404535\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129091; batch adversarial loss: 0.347290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134488; batch adversarial loss: 0.510624\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114862; batch adversarial loss: 0.338159\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106716; batch adversarial loss: 0.369350\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110235; batch adversarial loss: 0.434661\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132842; batch adversarial loss: 0.427041\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138842; batch adversarial loss: 0.389500\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118048; batch adversarial loss: 0.417229\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121367; batch adversarial loss: 0.460309\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090927; batch adversarial loss: 0.404090\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110024; batch adversarial loss: 0.413523\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080314; batch adversarial loss: 0.395897\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083685; batch adversarial loss: 0.418097\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085263; batch adversarial loss: 0.449016\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107143; batch adversarial loss: 0.342393\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128507; batch adversarial loss: 0.322142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113486; batch adversarial loss: 0.459823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.104778; batch adversarial loss: 0.456923\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074721; batch adversarial loss: 0.328586\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095276; batch adversarial loss: 0.359476\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112958; batch adversarial loss: 0.478146\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099532; batch adversarial loss: 0.519451\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080405; batch adversarial loss: 0.489181\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061803; batch adversarial loss: 0.329881\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112585; batch adversarial loss: 0.436621\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101422; batch adversarial loss: 0.442174\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064700; batch adversarial loss: 0.431249\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066712; batch adversarial loss: 0.383832\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058960; batch adversarial loss: 0.434825\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051794; batch adversarial loss: 0.429137\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080275; batch adversarial loss: 0.507724\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149228; batch adversarial loss: 0.411551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.082362; batch adversarial loss: 0.394534\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091572; batch adversarial loss: 0.382830\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096212; batch adversarial loss: 0.398517\n",
      "epoch 67; iter: 0; batch classifier loss: 0.048884; batch adversarial loss: 0.429894\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045136; batch adversarial loss: 0.419298\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081633; batch adversarial loss: 0.373163\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099589; batch adversarial loss: 0.375609\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126241; batch adversarial loss: 0.373117\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055527; batch adversarial loss: 0.434348\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048014; batch adversarial loss: 0.357713\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089912; batch adversarial loss: 0.406555\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083247; batch adversarial loss: 0.399860\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063445; batch adversarial loss: 0.354784\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058497; batch adversarial loss: 0.419322\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085639; batch adversarial loss: 0.465616\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063267; batch adversarial loss: 0.400898\n",
      "epoch 80; iter: 0; batch classifier loss: 0.082771; batch adversarial loss: 0.424225\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059663; batch adversarial loss: 0.455669\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053570; batch adversarial loss: 0.401884\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065762; batch adversarial loss: 0.353518\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065347; batch adversarial loss: 0.399736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061627; batch adversarial loss: 0.438985\n",
      "epoch 86; iter: 0; batch classifier loss: 0.029184; batch adversarial loss: 0.475699\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036125; batch adversarial loss: 0.445098\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056993; batch adversarial loss: 0.417771\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058184; batch adversarial loss: 0.410018\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047010; batch adversarial loss: 0.542313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036069; batch adversarial loss: 0.410793\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052241; batch adversarial loss: 0.458881\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035309; batch adversarial loss: 0.384141\n",
      "epoch 94; iter: 0; batch classifier loss: 0.027453; batch adversarial loss: 0.429119\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051921; batch adversarial loss: 0.415150\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040218; batch adversarial loss: 0.457370\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050304; batch adversarial loss: 0.369718\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035836; batch adversarial loss: 0.452402\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031837; batch adversarial loss: 0.484743\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036721; batch adversarial loss: 0.384288\n",
      "epoch 101; iter: 0; batch classifier loss: 0.037936; batch adversarial loss: 0.543965\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060302; batch adversarial loss: 0.440377\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044839; batch adversarial loss: 0.438844\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043133; batch adversarial loss: 0.522047\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029750; batch adversarial loss: 0.459543\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047362; batch adversarial loss: 0.442122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031513; batch adversarial loss: 0.463449\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080876; batch adversarial loss: 0.659867\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026251; batch adversarial loss: 0.540940\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025467; batch adversarial loss: 0.525533\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032472; batch adversarial loss: 0.428044\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043640; batch adversarial loss: 0.507098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063009; batch adversarial loss: 0.557528\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066051; batch adversarial loss: 0.562301\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053554; batch adversarial loss: 0.363420\n",
      "epoch 116; iter: 0; batch classifier loss: 0.097965; batch adversarial loss: 0.623023\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059999; batch adversarial loss: 0.453451\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076975; batch adversarial loss: 0.546187\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120966; batch adversarial loss: 0.541811\n",
      "epoch 120; iter: 0; batch classifier loss: 0.146585; batch adversarial loss: 0.601506\n",
      "epoch 121; iter: 0; batch classifier loss: 0.151112; batch adversarial loss: 0.691638\n",
      "epoch 122; iter: 0; batch classifier loss: 0.145012; batch adversarial loss: 0.665552\n",
      "epoch 123; iter: 0; batch classifier loss: 0.081069; batch adversarial loss: 0.558288\n",
      "epoch 124; iter: 0; batch classifier loss: 0.135431; batch adversarial loss: 0.579691\n",
      "epoch 125; iter: 0; batch classifier loss: 0.216417; batch adversarial loss: 0.704600\n",
      "epoch 126; iter: 0; batch classifier loss: 0.154100; batch adversarial loss: 0.601576\n",
      "epoch 127; iter: 0; batch classifier loss: 0.180681; batch adversarial loss: 0.750872\n",
      "epoch 128; iter: 0; batch classifier loss: 0.130154; batch adversarial loss: 0.544141\n",
      "epoch 129; iter: 0; batch classifier loss: 0.137548; batch adversarial loss: 0.619597\n",
      "epoch 130; iter: 0; batch classifier loss: 0.179087; batch adversarial loss: 0.592924\n",
      "epoch 131; iter: 0; batch classifier loss: 0.118813; batch adversarial loss: 0.507316\n",
      "epoch 132; iter: 0; batch classifier loss: 0.187689; batch adversarial loss: 0.585133\n",
      "epoch 133; iter: 0; batch classifier loss: 0.099654; batch adversarial loss: 0.490213\n",
      "epoch 134; iter: 0; batch classifier loss: 0.115666; batch adversarial loss: 0.439752\n",
      "epoch 135; iter: 0; batch classifier loss: 0.235318; batch adversarial loss: 0.654339\n",
      "epoch 136; iter: 0; batch classifier loss: 0.104216; batch adversarial loss: 0.541829\n",
      "epoch 137; iter: 0; batch classifier loss: 0.125757; batch adversarial loss: 0.491763\n",
      "epoch 138; iter: 0; batch classifier loss: 0.114119; batch adversarial loss: 0.611878\n",
      "epoch 139; iter: 0; batch classifier loss: 0.123555; batch adversarial loss: 0.515205\n",
      "epoch 140; iter: 0; batch classifier loss: 0.108767; batch adversarial loss: 0.470575\n",
      "epoch 141; iter: 0; batch classifier loss: 0.141402; batch adversarial loss: 0.577641\n",
      "epoch 142; iter: 0; batch classifier loss: 0.126000; batch adversarial loss: 0.541706\n",
      "epoch 143; iter: 0; batch classifier loss: 0.127308; batch adversarial loss: 0.469293\n",
      "epoch 144; iter: 0; batch classifier loss: 0.068453; batch adversarial loss: 0.459448\n",
      "epoch 145; iter: 0; batch classifier loss: 0.150277; batch adversarial loss: 0.507068\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063863; batch adversarial loss: 0.423509\n",
      "epoch 147; iter: 0; batch classifier loss: 0.121842; batch adversarial loss: 0.484806\n",
      "epoch 148; iter: 0; batch classifier loss: 0.109175; batch adversarial loss: 0.389453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.092539; batch adversarial loss: 0.534111\n",
      "epoch 150; iter: 0; batch classifier loss: 0.102892; batch adversarial loss: 0.504659\n",
      "epoch 151; iter: 0; batch classifier loss: 0.143403; batch adversarial loss: 0.523401\n",
      "epoch 152; iter: 0; batch classifier loss: 0.096549; batch adversarial loss: 0.379946\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066773; batch adversarial loss: 0.363901\n",
      "epoch 154; iter: 0; batch classifier loss: 0.071840; batch adversarial loss: 0.398974\n",
      "epoch 155; iter: 0; batch classifier loss: 0.092824; batch adversarial loss: 0.371483\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029922; batch adversarial loss: 0.407748\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046095; batch adversarial loss: 0.492428\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047067; batch adversarial loss: 0.514797\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018289; batch adversarial loss: 0.401677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.025957; batch adversarial loss: 0.495967\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043924; batch adversarial loss: 0.524047\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055269; batch adversarial loss: 0.477510\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024735; batch adversarial loss: 0.422814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038891; batch adversarial loss: 0.469114\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034751; batch adversarial loss: 0.488411\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024859; batch adversarial loss: 0.554346\n",
      "epoch 167; iter: 0; batch classifier loss: 0.088255; batch adversarial loss: 0.387055\n",
      "epoch 168; iter: 0; batch classifier loss: 0.080995; batch adversarial loss: 0.520094\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030050; batch adversarial loss: 0.491827\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019056; batch adversarial loss: 0.379507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.053304; batch adversarial loss: 0.498197\n",
      "epoch 172; iter: 0; batch classifier loss: 0.050620; batch adversarial loss: 0.377916\n",
      "epoch 173; iter: 0; batch classifier loss: 0.078133; batch adversarial loss: 0.414692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046521; batch adversarial loss: 0.546729\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058147; batch adversarial loss: 0.411028\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044841; batch adversarial loss: 0.397443\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043410; batch adversarial loss: 0.406576\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035272; batch adversarial loss: 0.487994\n",
      "epoch 179; iter: 0; batch classifier loss: 0.066828; batch adversarial loss: 0.448777\n",
      "epoch 180; iter: 0; batch classifier loss: 0.079687; batch adversarial loss: 0.420551\n",
      "epoch 181; iter: 0; batch classifier loss: 0.080353; batch adversarial loss: 0.401899\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043443; batch adversarial loss: 0.369391\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056132; batch adversarial loss: 0.441758\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049078; batch adversarial loss: 0.406069\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053809; batch adversarial loss: 0.454841\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041781; batch adversarial loss: 0.454828\n",
      "epoch 187; iter: 0; batch classifier loss: 0.074972; batch adversarial loss: 0.536718\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037822; batch adversarial loss: 0.481521\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031570; batch adversarial loss: 0.524935\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045106; batch adversarial loss: 0.538778\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025605; batch adversarial loss: 0.441106\n",
      "epoch 192; iter: 0; batch classifier loss: 0.067216; batch adversarial loss: 0.445564\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044951; batch adversarial loss: 0.494789\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041655; batch adversarial loss: 0.486504\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054329; batch adversarial loss: 0.447805\n",
      "epoch 196; iter: 0; batch classifier loss: 0.075799; batch adversarial loss: 0.436153\n",
      "epoch 197; iter: 0; batch classifier loss: 0.048350; batch adversarial loss: 0.517390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.071902; batch adversarial loss: 0.441597\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032235; batch adversarial loss: 0.413290\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674630; batch adversarial loss: 0.798010\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410674; batch adversarial loss: 0.752928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410480; batch adversarial loss: 0.701211\n",
      "epoch 3; iter: 0; batch classifier loss: 0.389668; batch adversarial loss: 0.658658\n",
      "epoch 4; iter: 0; batch classifier loss: 0.490901; batch adversarial loss: 0.617343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280003; batch adversarial loss: 0.597135\n",
      "epoch 6; iter: 0; batch classifier loss: 0.263170; batch adversarial loss: 0.593865\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285885; batch adversarial loss: 0.546057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.287283; batch adversarial loss: 0.557078\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254361; batch adversarial loss: 0.535549\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264644; batch adversarial loss: 0.537757\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271934; batch adversarial loss: 0.506076\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261310; batch adversarial loss: 0.513047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376129; batch adversarial loss: 0.559664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281638; batch adversarial loss: 0.543499\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273848; batch adversarial loss: 0.463573\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328654; batch adversarial loss: 0.535935\n",
      "epoch 17; iter: 0; batch classifier loss: 0.558975; batch adversarial loss: 0.455983\n",
      "epoch 18; iter: 0; batch classifier loss: 0.379769; batch adversarial loss: 0.504591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331634; batch adversarial loss: 0.545069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294375; batch adversarial loss: 0.488921\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288624; batch adversarial loss: 0.476616\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258170; batch adversarial loss: 0.485509\n",
      "epoch 23; iter: 0; batch classifier loss: 0.150998; batch adversarial loss: 0.497530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199162; batch adversarial loss: 0.487034\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177049; batch adversarial loss: 0.450197\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201503; batch adversarial loss: 0.544183\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220813; batch adversarial loss: 0.436154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.263710; batch adversarial loss: 0.488094\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242392; batch adversarial loss: 0.454623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296562; batch adversarial loss: 0.574812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176142; batch adversarial loss: 0.502877\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181179; batch adversarial loss: 0.512788\n",
      "epoch 33; iter: 0; batch classifier loss: 0.205734; batch adversarial loss: 0.512022\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165709; batch adversarial loss: 0.467054\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196610; batch adversarial loss: 0.468049\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186339; batch adversarial loss: 0.430066\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160459; batch adversarial loss: 0.507374\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288997; batch adversarial loss: 0.483975\n",
      "epoch 39; iter: 0; batch classifier loss: 0.199148; batch adversarial loss: 0.473291\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224237; batch adversarial loss: 0.375731\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230322; batch adversarial loss: 0.430143\n",
      "epoch 42; iter: 0; batch classifier loss: 0.159687; batch adversarial loss: 0.448381\n",
      "epoch 43; iter: 0; batch classifier loss: 0.188062; batch adversarial loss: 0.502760\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214592; batch adversarial loss: 0.430331\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185724; batch adversarial loss: 0.474302\n",
      "epoch 46; iter: 0; batch classifier loss: 0.237890; batch adversarial loss: 0.480728\n",
      "epoch 47; iter: 0; batch classifier loss: 0.191608; batch adversarial loss: 0.404981\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211795; batch adversarial loss: 0.462666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.240797; batch adversarial loss: 0.438701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.252868; batch adversarial loss: 0.436687\n",
      "epoch 51; iter: 0; batch classifier loss: 0.223648; batch adversarial loss: 0.468254\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158261; batch adversarial loss: 0.389374\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204707; batch adversarial loss: 0.487031\n",
      "epoch 54; iter: 0; batch classifier loss: 0.179553; batch adversarial loss: 0.501482\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186268; batch adversarial loss: 0.461967\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138333; batch adversarial loss: 0.456720\n",
      "epoch 57; iter: 0; batch classifier loss: 0.220439; batch adversarial loss: 0.449038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.204803; batch adversarial loss: 0.377957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.241402; batch adversarial loss: 0.572882\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209113; batch adversarial loss: 0.376430\n",
      "epoch 61; iter: 0; batch classifier loss: 0.230979; batch adversarial loss: 0.378777\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211286; batch adversarial loss: 0.542153\n",
      "epoch 63; iter: 0; batch classifier loss: 0.213403; batch adversarial loss: 0.412188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212070; batch adversarial loss: 0.482105\n",
      "epoch 65; iter: 0; batch classifier loss: 0.150144; batch adversarial loss: 0.572935\n",
      "epoch 66; iter: 0; batch classifier loss: 0.186499; batch adversarial loss: 0.486560\n",
      "epoch 67; iter: 0; batch classifier loss: 0.186726; batch adversarial loss: 0.470040\n",
      "epoch 68; iter: 0; batch classifier loss: 0.261279; batch adversarial loss: 0.518894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200773; batch adversarial loss: 0.543332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.178885; batch adversarial loss: 0.507496\n",
      "epoch 71; iter: 0; batch classifier loss: 0.219973; batch adversarial loss: 0.447298\n",
      "epoch 72; iter: 0; batch classifier loss: 0.238441; batch adversarial loss: 0.494433\n",
      "epoch 73; iter: 0; batch classifier loss: 0.210544; batch adversarial loss: 0.423613\n",
      "epoch 74; iter: 0; batch classifier loss: 0.212186; batch adversarial loss: 0.459854\n",
      "epoch 75; iter: 0; batch classifier loss: 0.209929; batch adversarial loss: 0.422955\n",
      "epoch 76; iter: 0; batch classifier loss: 0.232553; batch adversarial loss: 0.483346\n",
      "epoch 77; iter: 0; batch classifier loss: 0.163749; batch adversarial loss: 0.530711\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211102; batch adversarial loss: 0.458842\n",
      "epoch 79; iter: 0; batch classifier loss: 0.234982; batch adversarial loss: 0.411374\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165852; batch adversarial loss: 0.482731\n",
      "epoch 81; iter: 0; batch classifier loss: 0.201304; batch adversarial loss: 0.482684\n",
      "epoch 82; iter: 0; batch classifier loss: 0.227458; batch adversarial loss: 0.387398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.129999; batch adversarial loss: 0.446185\n",
      "epoch 84; iter: 0; batch classifier loss: 0.218501; batch adversarial loss: 0.435666\n",
      "epoch 85; iter: 0; batch classifier loss: 0.150684; batch adversarial loss: 0.503290\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128679; batch adversarial loss: 0.423221\n",
      "epoch 87; iter: 0; batch classifier loss: 0.149126; batch adversarial loss: 0.445338\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140151; batch adversarial loss: 0.487970\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126074; batch adversarial loss: 0.578334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.128328; batch adversarial loss: 0.436220\n",
      "epoch 91; iter: 0; batch classifier loss: 0.129398; batch adversarial loss: 0.483283\n",
      "epoch 92; iter: 0; batch classifier loss: 0.125014; batch adversarial loss: 0.513383\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147865; batch adversarial loss: 0.494889\n",
      "epoch 94; iter: 0; batch classifier loss: 0.146194; batch adversarial loss: 0.537560\n",
      "epoch 95; iter: 0; batch classifier loss: 0.146671; batch adversarial loss: 0.430529\n",
      "epoch 96; iter: 0; batch classifier loss: 0.127376; batch adversarial loss: 0.560041\n",
      "epoch 97; iter: 0; batch classifier loss: 0.122226; batch adversarial loss: 0.457783\n",
      "epoch 98; iter: 0; batch classifier loss: 0.091121; batch adversarial loss: 0.502975\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092265; batch adversarial loss: 0.445879\n",
      "epoch 100; iter: 0; batch classifier loss: 0.112149; batch adversarial loss: 0.364748\n",
      "epoch 101; iter: 0; batch classifier loss: 0.122831; batch adversarial loss: 0.504589\n",
      "epoch 102; iter: 0; batch classifier loss: 0.106400; batch adversarial loss: 0.495288\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040421; batch adversarial loss: 0.457895\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030896; batch adversarial loss: 0.445912\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068483; batch adversarial loss: 0.507314\n",
      "epoch 106; iter: 0; batch classifier loss: 0.098132; batch adversarial loss: 0.388662\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062637; batch adversarial loss: 0.503369\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065241; batch adversarial loss: 0.478824\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050803; batch adversarial loss: 0.533020\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060266; batch adversarial loss: 0.493673\n",
      "epoch 111; iter: 0; batch classifier loss: 0.094205; batch adversarial loss: 0.363818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.404459\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028857; batch adversarial loss: 0.392599\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039595; batch adversarial loss: 0.487370\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044519; batch adversarial loss: 0.493481\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042692; batch adversarial loss: 0.481665\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032529; batch adversarial loss: 0.546564\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.431312\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050171; batch adversarial loss: 0.462800\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020782; batch adversarial loss: 0.442993\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049064; batch adversarial loss: 0.426668\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030084; batch adversarial loss: 0.473036\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.512862\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048508; batch adversarial loss: 0.490725\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013102; batch adversarial loss: 0.468794\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021919; batch adversarial loss: 0.466684\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027277; batch adversarial loss: 0.496766\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027995; batch adversarial loss: 0.418571\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030306; batch adversarial loss: 0.435121\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059650; batch adversarial loss: 0.400760\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053143; batch adversarial loss: 0.462440\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047250; batch adversarial loss: 0.442667\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017337; batch adversarial loss: 0.513917\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025719; batch adversarial loss: 0.478079\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024869; batch adversarial loss: 0.426346\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011970; batch adversarial loss: 0.456429\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020277; batch adversarial loss: 0.386894\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017428; batch adversarial loss: 0.460893\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028861; batch adversarial loss: 0.442262\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023064; batch adversarial loss: 0.394156\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042405; batch adversarial loss: 0.372973\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022184; batch adversarial loss: 0.468276\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040397; batch adversarial loss: 0.555801\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019037; batch adversarial loss: 0.468620\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.486303\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022022; batch adversarial loss: 0.383868\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048699; batch adversarial loss: 0.503846\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.464812\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.457025\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035800; batch adversarial loss: 0.529524\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011733; batch adversarial loss: 0.477214\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016707; batch adversarial loss: 0.501190\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020330; batch adversarial loss: 0.503977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.017030; batch adversarial loss: 0.393625\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021678; batch adversarial loss: 0.475355\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.479008\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040457; batch adversarial loss: 0.460372\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036896; batch adversarial loss: 0.438455\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013699; batch adversarial loss: 0.473601\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053415; batch adversarial loss: 0.461204\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018518; batch adversarial loss: 0.388628\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010703; batch adversarial loss: 0.439294\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018740; batch adversarial loss: 0.511537\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009370; batch adversarial loss: 0.389514\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029552; batch adversarial loss: 0.424370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.439365\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011737; batch adversarial loss: 0.386243\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024929; batch adversarial loss: 0.468143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014573; batch adversarial loss: 0.495304\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054327; batch adversarial loss: 0.432706\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012960; batch adversarial loss: 0.532013\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019847; batch adversarial loss: 0.444510\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019342; batch adversarial loss: 0.627520\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023492; batch adversarial loss: 0.346448\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037300; batch adversarial loss: 0.434203\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031344; batch adversarial loss: 0.403566\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025892; batch adversarial loss: 0.513667\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020200; batch adversarial loss: 0.385995\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008412; batch adversarial loss: 0.447480\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023656; batch adversarial loss: 0.444178\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021583; batch adversarial loss: 0.516012\n",
      "epoch 182; iter: 0; batch classifier loss: 0.072404; batch adversarial loss: 0.439825\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014712; batch adversarial loss: 0.391768\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028693; batch adversarial loss: 0.456045\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033532; batch adversarial loss: 0.489616\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015123; batch adversarial loss: 0.459831\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036112; batch adversarial loss: 0.520081\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030316; batch adversarial loss: 0.416724\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025907; batch adversarial loss: 0.463049\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016110; batch adversarial loss: 0.410280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020725; batch adversarial loss: 0.542596\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.483062\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034445; batch adversarial loss: 0.453858\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015318; batch adversarial loss: 0.450338\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026926; batch adversarial loss: 0.379781\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024610; batch adversarial loss: 0.405533\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027247; batch adversarial loss: 0.445005\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044425; batch adversarial loss: 0.432300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039070; batch adversarial loss: 0.398286\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673976; batch adversarial loss: 0.627555\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422590; batch adversarial loss: 0.624098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401958; batch adversarial loss: 0.568248\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331014; batch adversarial loss: 0.552629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328637; batch adversarial loss: 0.539940\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341233; batch adversarial loss: 0.532435\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316839; batch adversarial loss: 0.544869\n",
      "epoch 7; iter: 0; batch classifier loss: 0.234223; batch adversarial loss: 0.524571\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285267; batch adversarial loss: 0.482202\n",
      "epoch 9; iter: 0; batch classifier loss: 0.325291; batch adversarial loss: 0.502356\n",
      "epoch 10; iter: 0; batch classifier loss: 0.239231; batch adversarial loss: 0.495398\n",
      "epoch 11; iter: 0; batch classifier loss: 0.181651; batch adversarial loss: 0.425118\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230739; batch adversarial loss: 0.569550\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235673; batch adversarial loss: 0.444464\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234187; batch adversarial loss: 0.531666\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216977; batch adversarial loss: 0.421972\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207729; batch adversarial loss: 0.442233\n",
      "epoch 17; iter: 0; batch classifier loss: 0.257674; batch adversarial loss: 0.532632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213661; batch adversarial loss: 0.502193\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307600; batch adversarial loss: 0.622787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236247; batch adversarial loss: 0.561203\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172827; batch adversarial loss: 0.502944\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187718; batch adversarial loss: 0.535859\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200212; batch adversarial loss: 0.450635\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227585; batch adversarial loss: 0.461151\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233191; batch adversarial loss: 0.535829\n",
      "epoch 26; iter: 0; batch classifier loss: 0.242754; batch adversarial loss: 0.484488\n",
      "epoch 27; iter: 0; batch classifier loss: 0.266750; batch adversarial loss: 0.577687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349514; batch adversarial loss: 0.516261\n",
      "epoch 29; iter: 0; batch classifier loss: 0.355424; batch adversarial loss: 0.466839\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296655; batch adversarial loss: 0.468566\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135561; batch adversarial loss: 0.440586\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147575; batch adversarial loss: 0.484164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143912; batch adversarial loss: 0.396350\n",
      "epoch 34; iter: 0; batch classifier loss: 0.090107; batch adversarial loss: 0.503647\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130973; batch adversarial loss: 0.479980\n",
      "epoch 36; iter: 0; batch classifier loss: 0.104496; batch adversarial loss: 0.451373\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127338; batch adversarial loss: 0.471936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089556; batch adversarial loss: 0.468931\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132517; batch adversarial loss: 0.398591\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087016; batch adversarial loss: 0.414090\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105379; batch adversarial loss: 0.589049\n",
      "epoch 42; iter: 0; batch classifier loss: 0.083703; batch adversarial loss: 0.555680\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107658; batch adversarial loss: 0.489083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109215; batch adversarial loss: 0.482794\n",
      "epoch 45; iter: 0; batch classifier loss: 0.058231; batch adversarial loss: 0.432683\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090366; batch adversarial loss: 0.425792\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073939; batch adversarial loss: 0.471691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116613; batch adversarial loss: 0.454793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109313; batch adversarial loss: 0.420239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.100750; batch adversarial loss: 0.390969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111381; batch adversarial loss: 0.451610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086070; batch adversarial loss: 0.445839\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089528; batch adversarial loss: 0.457196\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144410; batch adversarial loss: 0.427083\n",
      "epoch 55; iter: 0; batch classifier loss: 0.136205; batch adversarial loss: 0.396185\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081957; batch adversarial loss: 0.497481\n",
      "epoch 57; iter: 0; batch classifier loss: 0.185859; batch adversarial loss: 0.471008\n",
      "epoch 58; iter: 0; batch classifier loss: 0.140699; batch adversarial loss: 0.476767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143698; batch adversarial loss: 0.464453\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115989; batch adversarial loss: 0.415873\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120986; batch adversarial loss: 0.518792\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144611; batch adversarial loss: 0.479258\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127813; batch adversarial loss: 0.451238\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120693; batch adversarial loss: 0.455707\n",
      "epoch 65; iter: 0; batch classifier loss: 0.220378; batch adversarial loss: 0.412426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.142594; batch adversarial loss: 0.444583\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114639; batch adversarial loss: 0.448638\n",
      "epoch 68; iter: 0; batch classifier loss: 0.164811; batch adversarial loss: 0.452058\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092249; batch adversarial loss: 0.462754\n",
      "epoch 70; iter: 0; batch classifier loss: 0.201982; batch adversarial loss: 0.442305\n",
      "epoch 71; iter: 0; batch classifier loss: 0.172210; batch adversarial loss: 0.421596\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143274; batch adversarial loss: 0.358017\n",
      "epoch 73; iter: 0; batch classifier loss: 0.219656; batch adversarial loss: 0.463793\n",
      "epoch 74; iter: 0; batch classifier loss: 0.138245; batch adversarial loss: 0.425193\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105835; batch adversarial loss: 0.448646\n",
      "epoch 76; iter: 0; batch classifier loss: 0.169792; batch adversarial loss: 0.445425\n",
      "epoch 77; iter: 0; batch classifier loss: 0.124168; batch adversarial loss: 0.473328\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108612; batch adversarial loss: 0.587889\n",
      "epoch 79; iter: 0; batch classifier loss: 0.177787; batch adversarial loss: 0.434579\n",
      "epoch 80; iter: 0; batch classifier loss: 0.151312; batch adversarial loss: 0.544786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.128763; batch adversarial loss: 0.484116\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104183; batch adversarial loss: 0.497324\n",
      "epoch 83; iter: 0; batch classifier loss: 0.138441; batch adversarial loss: 0.581719\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089932; batch adversarial loss: 0.449266\n",
      "epoch 85; iter: 0; batch classifier loss: 0.165062; batch adversarial loss: 0.420516\n",
      "epoch 86; iter: 0; batch classifier loss: 0.110640; batch adversarial loss: 0.479756\n",
      "epoch 87; iter: 0; batch classifier loss: 0.211820; batch adversarial loss: 0.408515\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157716; batch adversarial loss: 0.516721\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120234; batch adversarial loss: 0.441050\n",
      "epoch 90; iter: 0; batch classifier loss: 0.150759; batch adversarial loss: 0.372993\n",
      "epoch 91; iter: 0; batch classifier loss: 0.134856; batch adversarial loss: 0.495851\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084354; batch adversarial loss: 0.528709\n",
      "epoch 93; iter: 0; batch classifier loss: 0.174090; batch adversarial loss: 0.413635\n",
      "epoch 94; iter: 0; batch classifier loss: 0.193405; batch adversarial loss: 0.494680\n",
      "epoch 95; iter: 0; batch classifier loss: 0.156951; batch adversarial loss: 0.494477\n",
      "epoch 96; iter: 0; batch classifier loss: 0.161488; batch adversarial loss: 0.503156\n",
      "epoch 97; iter: 0; batch classifier loss: 0.169988; batch adversarial loss: 0.469753\n",
      "epoch 98; iter: 0; batch classifier loss: 0.143130; batch adversarial loss: 0.454859\n",
      "epoch 99; iter: 0; batch classifier loss: 0.123495; batch adversarial loss: 0.457673\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089321; batch adversarial loss: 0.427266\n",
      "epoch 101; iter: 0; batch classifier loss: 0.153780; batch adversarial loss: 0.470217\n",
      "epoch 102; iter: 0; batch classifier loss: 0.157158; batch adversarial loss: 0.457956\n",
      "epoch 103; iter: 0; batch classifier loss: 0.107006; batch adversarial loss: 0.423303\n",
      "epoch 104; iter: 0; batch classifier loss: 0.118864; batch adversarial loss: 0.511135\n",
      "epoch 105; iter: 0; batch classifier loss: 0.158351; batch adversarial loss: 0.407390\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101033; batch adversarial loss: 0.440213\n",
      "epoch 107; iter: 0; batch classifier loss: 0.098054; batch adversarial loss: 0.411291\n",
      "epoch 108; iter: 0; batch classifier loss: 0.105020; batch adversarial loss: 0.434597\n",
      "epoch 109; iter: 0; batch classifier loss: 0.084255; batch adversarial loss: 0.602585\n",
      "epoch 110; iter: 0; batch classifier loss: 0.164155; batch adversarial loss: 0.425836\n",
      "epoch 111; iter: 0; batch classifier loss: 0.111262; batch adversarial loss: 0.469093\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080762; batch adversarial loss: 0.521902\n",
      "epoch 113; iter: 0; batch classifier loss: 0.093695; batch adversarial loss: 0.412721\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086124; batch adversarial loss: 0.380770\n",
      "epoch 115; iter: 0; batch classifier loss: 0.101134; batch adversarial loss: 0.463015\n",
      "epoch 116; iter: 0; batch classifier loss: 0.086015; batch adversarial loss: 0.428369\n",
      "epoch 117; iter: 0; batch classifier loss: 0.120485; batch adversarial loss: 0.473360\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085142; batch adversarial loss: 0.515494\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046111; batch adversarial loss: 0.527097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.088478; batch adversarial loss: 0.479161\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049061; batch adversarial loss: 0.455416\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057880; batch adversarial loss: 0.413754\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034400; batch adversarial loss: 0.402213\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058075; batch adversarial loss: 0.464332\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040290; batch adversarial loss: 0.470995\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042244; batch adversarial loss: 0.463987\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038169; batch adversarial loss: 0.529046\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056801; batch adversarial loss: 0.459490\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065459; batch adversarial loss: 0.476221\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057253; batch adversarial loss: 0.584130\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050446; batch adversarial loss: 0.493086\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056529; batch adversarial loss: 0.504269\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027494; batch adversarial loss: 0.496167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.068043; batch adversarial loss: 0.452987\n",
      "epoch 135; iter: 0; batch classifier loss: 0.074727; batch adversarial loss: 0.458795\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047638; batch adversarial loss: 0.474019\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057711; batch adversarial loss: 0.411811\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034453; batch adversarial loss: 0.377594\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030955; batch adversarial loss: 0.518856\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020486; batch adversarial loss: 0.442664\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036884; batch adversarial loss: 0.442056\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049106; batch adversarial loss: 0.479491\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027616; batch adversarial loss: 0.449742\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027574; batch adversarial loss: 0.423860\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063901; batch adversarial loss: 0.387242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.043013; batch adversarial loss: 0.445294\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037273; batch adversarial loss: 0.387436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044519; batch adversarial loss: 0.424458\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039916; batch adversarial loss: 0.399833\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054808; batch adversarial loss: 0.531639\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025272; batch adversarial loss: 0.433753\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021278; batch adversarial loss: 0.459152\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049309; batch adversarial loss: 0.387283\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027909; batch adversarial loss: 0.427525\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014994; batch adversarial loss: 0.436791\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016590; batch adversarial loss: 0.499437\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021603; batch adversarial loss: 0.531514\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045770; batch adversarial loss: 0.401884\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019355; batch adversarial loss: 0.483162\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021628; batch adversarial loss: 0.443481\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039275; batch adversarial loss: 0.478121\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041327; batch adversarial loss: 0.528936\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023370; batch adversarial loss: 0.515901\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022219; batch adversarial loss: 0.438938\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038331; batch adversarial loss: 0.541738\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026513; batch adversarial loss: 0.373096\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024459; batch adversarial loss: 0.413386\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026150; batch adversarial loss: 0.484047\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018500; batch adversarial loss: 0.537011\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028251; batch adversarial loss: 0.415275\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017297; batch adversarial loss: 0.411045\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029567; batch adversarial loss: 0.481380\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021066; batch adversarial loss: 0.462774\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.437946\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.522357\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035012; batch adversarial loss: 0.485633\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022363; batch adversarial loss: 0.466613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021006; batch adversarial loss: 0.453708\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027608; batch adversarial loss: 0.415553\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018067; batch adversarial loss: 0.440484\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018660; batch adversarial loss: 0.446534\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036980; batch adversarial loss: 0.473166\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017663; batch adversarial loss: 0.432484\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021965; batch adversarial loss: 0.431728\n",
      "epoch 185; iter: 0; batch classifier loss: 0.073755; batch adversarial loss: 0.446487\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048560; batch adversarial loss: 0.518184\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040704; batch adversarial loss: 0.453001\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039464; batch adversarial loss: 0.355582\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022474; batch adversarial loss: 0.351768\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011213; batch adversarial loss: 0.519560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031054; batch adversarial loss: 0.501969\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017818; batch adversarial loss: 0.437489\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037877; batch adversarial loss: 0.469255\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033628; batch adversarial loss: 0.443847\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028391; batch adversarial loss: 0.563984\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025503; batch adversarial loss: 0.394363\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.549685\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017790; batch adversarial loss: 0.386263\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.448137\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700883; batch adversarial loss: 0.620939\n",
      "epoch 1; iter: 0; batch classifier loss: 0.366260; batch adversarial loss: 0.645442\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338134; batch adversarial loss: 0.616001\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444354; batch adversarial loss: 0.575235\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377525; batch adversarial loss: 0.606289\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340791; batch adversarial loss: 0.569447\n",
      "epoch 6; iter: 0; batch classifier loss: 0.400282; batch adversarial loss: 0.554822\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336135; batch adversarial loss: 0.581805\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497027; batch adversarial loss: 0.582468\n",
      "epoch 9; iter: 0; batch classifier loss: 0.656161; batch adversarial loss: 0.552028\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585283; batch adversarial loss: 0.580861\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553744; batch adversarial loss: 0.470140\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405556; batch adversarial loss: 0.552609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372748; batch adversarial loss: 0.491993\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351465; batch adversarial loss: 0.458060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247864; batch adversarial loss: 0.529893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.269622; batch adversarial loss: 0.515814\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335068; batch adversarial loss: 0.488547\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279946; batch adversarial loss: 0.482534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205573; batch adversarial loss: 0.457969\n",
      "epoch 20; iter: 0; batch classifier loss: 0.345316; batch adversarial loss: 0.448713\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249920; batch adversarial loss: 0.430451\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180927; batch adversarial loss: 0.450495\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207700; batch adversarial loss: 0.430821\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283098; batch adversarial loss: 0.467894\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247820; batch adversarial loss: 0.452960\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172021; batch adversarial loss: 0.535255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.231420; batch adversarial loss: 0.362212\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207139; batch adversarial loss: 0.440076\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261947; batch adversarial loss: 0.418233\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210044; batch adversarial loss: 0.420695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.216783; batch adversarial loss: 0.471830\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238638; batch adversarial loss: 0.430757\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191256; batch adversarial loss: 0.470093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284514; batch adversarial loss: 0.485444\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206069; batch adversarial loss: 0.392070\n",
      "epoch 36; iter: 0; batch classifier loss: 0.230531; batch adversarial loss: 0.389037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232871; batch adversarial loss: 0.514991\n",
      "epoch 38; iter: 0; batch classifier loss: 0.197808; batch adversarial loss: 0.442819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165452; batch adversarial loss: 0.470922\n",
      "epoch 40; iter: 0; batch classifier loss: 0.254569; batch adversarial loss: 0.378029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199961; batch adversarial loss: 0.461761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.176376; batch adversarial loss: 0.557982\n",
      "epoch 43; iter: 0; batch classifier loss: 0.216352; batch adversarial loss: 0.513014\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211103; batch adversarial loss: 0.484013\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227438; batch adversarial loss: 0.544469\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175309; batch adversarial loss: 0.437443\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206442; batch adversarial loss: 0.424090\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226878; batch adversarial loss: 0.435842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227290; batch adversarial loss: 0.362962\n",
      "epoch 50; iter: 0; batch classifier loss: 0.211553; batch adversarial loss: 0.506690\n",
      "epoch 51; iter: 0; batch classifier loss: 0.261685; batch adversarial loss: 0.495447\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091986; batch adversarial loss: 0.444299\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088862; batch adversarial loss: 0.447870\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099143; batch adversarial loss: 0.468311\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090458; batch adversarial loss: 0.422371\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083000; batch adversarial loss: 0.480493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.054911; batch adversarial loss: 0.527656\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095144; batch adversarial loss: 0.486600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073212; batch adversarial loss: 0.436808\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079854; batch adversarial loss: 0.429626\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070177; batch adversarial loss: 0.547419\n",
      "epoch 62; iter: 0; batch classifier loss: 0.070894; batch adversarial loss: 0.319520\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094640; batch adversarial loss: 0.424843\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149176; batch adversarial loss: 0.463205\n",
      "epoch 65; iter: 0; batch classifier loss: 0.049513; batch adversarial loss: 0.471797\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089072; batch adversarial loss: 0.475994\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093228; batch adversarial loss: 0.458320\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084721; batch adversarial loss: 0.437475\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103605; batch adversarial loss: 0.418827\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097365; batch adversarial loss: 0.468675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073092; batch adversarial loss: 0.399927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078708; batch adversarial loss: 0.350821\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057933; batch adversarial loss: 0.441469\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051796; batch adversarial loss: 0.386094\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062813; batch adversarial loss: 0.397256\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077628; batch adversarial loss: 0.476166\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103994; batch adversarial loss: 0.420473\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054006; batch adversarial loss: 0.368849\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058624; batch adversarial loss: 0.435003\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087524; batch adversarial loss: 0.479510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041766; batch adversarial loss: 0.400119\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073702; batch adversarial loss: 0.392480\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081209; batch adversarial loss: 0.473456\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055100; batch adversarial loss: 0.388395\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068341; batch adversarial loss: 0.421908\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051777; batch adversarial loss: 0.466273\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056721; batch adversarial loss: 0.434402\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071779; batch adversarial loss: 0.439238\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071706; batch adversarial loss: 0.484292\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060239; batch adversarial loss: 0.400863\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069610; batch adversarial loss: 0.512823\n",
      "epoch 92; iter: 0; batch classifier loss: 0.146142; batch adversarial loss: 0.478285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038244; batch adversarial loss: 0.412362\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069634; batch adversarial loss: 0.420705\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088606; batch adversarial loss: 0.483137\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048371; batch adversarial loss: 0.470065\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039649; batch adversarial loss: 0.435711\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074479; batch adversarial loss: 0.496993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038270; batch adversarial loss: 0.376573\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056650; batch adversarial loss: 0.377142\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071498; batch adversarial loss: 0.423959\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069835; batch adversarial loss: 0.386338\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054826; batch adversarial loss: 0.462734\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066513; batch adversarial loss: 0.412686\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071770; batch adversarial loss: 0.412839\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062148; batch adversarial loss: 0.478873\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086829; batch adversarial loss: 0.339229\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031280; batch adversarial loss: 0.471208\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069577; batch adversarial loss: 0.404963\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073642; batch adversarial loss: 0.408443\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063145; batch adversarial loss: 0.466130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042149; batch adversarial loss: 0.338866\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033279; batch adversarial loss: 0.383714\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046713; batch adversarial loss: 0.418155\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048542; batch adversarial loss: 0.450138\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041348; batch adversarial loss: 0.386724\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042274; batch adversarial loss: 0.415532\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052150; batch adversarial loss: 0.411842\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058783; batch adversarial loss: 0.410372\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063223; batch adversarial loss: 0.429815\n",
      "epoch 121; iter: 0; batch classifier loss: 0.109497; batch adversarial loss: 0.404769\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042439; batch adversarial loss: 0.361289\n",
      "epoch 123; iter: 0; batch classifier loss: 0.091605; batch adversarial loss: 0.365655\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037062; batch adversarial loss: 0.392530\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069732; batch adversarial loss: 0.444344\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056208; batch adversarial loss: 0.482578\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.425815\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048192; batch adversarial loss: 0.368428\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041615; batch adversarial loss: 0.303339\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049227; batch adversarial loss: 0.472769\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052938; batch adversarial loss: 0.422133\n",
      "epoch 132; iter: 0; batch classifier loss: 0.074709; batch adversarial loss: 0.381934\n",
      "epoch 133; iter: 0; batch classifier loss: 0.070909; batch adversarial loss: 0.537460\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052623; batch adversarial loss: 0.319280\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046337; batch adversarial loss: 0.472096\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054631; batch adversarial loss: 0.453368\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032337; batch adversarial loss: 0.376188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.032384; batch adversarial loss: 0.423213\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057387; batch adversarial loss: 0.439717\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054879; batch adversarial loss: 0.365932\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.501370\n",
      "epoch 142; iter: 0; batch classifier loss: 0.079254; batch adversarial loss: 0.416513\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051730; batch adversarial loss: 0.344842\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056777; batch adversarial loss: 0.416392\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024683; batch adversarial loss: 0.414481\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033917; batch adversarial loss: 0.441317\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039691; batch adversarial loss: 0.466568\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058105; batch adversarial loss: 0.413936\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059540; batch adversarial loss: 0.412377\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.462719\n",
      "epoch 151; iter: 0; batch classifier loss: 0.064058; batch adversarial loss: 0.376517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041136; batch adversarial loss: 0.459657\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036363; batch adversarial loss: 0.404782\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056572; batch adversarial loss: 0.435278\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.445541\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.476795\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026009; batch adversarial loss: 0.377095\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044144; batch adversarial loss: 0.486686\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.529222\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030366; batch adversarial loss: 0.497183\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024983; batch adversarial loss: 0.424327\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046407; batch adversarial loss: 0.507048\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045788; batch adversarial loss: 0.365815\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031127; batch adversarial loss: 0.489173\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034107; batch adversarial loss: 0.396622\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062999; batch adversarial loss: 0.369504\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034260; batch adversarial loss: 0.428165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030399; batch adversarial loss: 0.425936\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027707; batch adversarial loss: 0.337338\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021508; batch adversarial loss: 0.396992\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020350; batch adversarial loss: 0.484918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030759; batch adversarial loss: 0.471134\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024268; batch adversarial loss: 0.441925\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022811; batch adversarial loss: 0.526598\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017530; batch adversarial loss: 0.460110\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010334; batch adversarial loss: 0.475991\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020732; batch adversarial loss: 0.485326\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011525; batch adversarial loss: 0.384223\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035452; batch adversarial loss: 0.438152\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015820; batch adversarial loss: 0.443276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030366; batch adversarial loss: 0.418262\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.356558\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028304; batch adversarial loss: 0.395060\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.446913\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012826; batch adversarial loss: 0.413379\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015337; batch adversarial loss: 0.483628\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039188; batch adversarial loss: 0.424167\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016570; batch adversarial loss: 0.407135\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027615; batch adversarial loss: 0.412416\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004498; batch adversarial loss: 0.518688\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.377223\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007828; batch adversarial loss: 0.496424\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019438; batch adversarial loss: 0.416465\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018766; batch adversarial loss: 0.539420\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022978; batch adversarial loss: 0.342506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018306; batch adversarial loss: 0.470013\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026697; batch adversarial loss: 0.389574\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017755; batch adversarial loss: 0.494075\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020406; batch adversarial loss: 0.504608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705175; batch adversarial loss: 0.755517\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423000; batch adversarial loss: 0.710005\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422636; batch adversarial loss: 0.670891\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468020; batch adversarial loss: 0.634885\n",
      "epoch 4; iter: 0; batch classifier loss: 0.323342; batch adversarial loss: 0.600603\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349822; batch adversarial loss: 0.573738\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404574; batch adversarial loss: 0.566654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327134; batch adversarial loss: 0.566316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.411808; batch adversarial loss: 0.573542\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472923; batch adversarial loss: 0.551169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469454; batch adversarial loss: 0.540091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.446958; batch adversarial loss: 0.565994\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426267; batch adversarial loss: 0.529379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394847; batch adversarial loss: 0.526285\n",
      "epoch 14; iter: 0; batch classifier loss: 0.388071; batch adversarial loss: 0.494022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366102; batch adversarial loss: 0.527368\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364283; batch adversarial loss: 0.498030\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328123; batch adversarial loss: 0.458129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350958; batch adversarial loss: 0.507456\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316773; batch adversarial loss: 0.520055\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367878; batch adversarial loss: 0.454263\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312485; batch adversarial loss: 0.557329\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304965; batch adversarial loss: 0.495515\n",
      "epoch 23; iter: 0; batch classifier loss: 0.257436; batch adversarial loss: 0.503942\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324975; batch adversarial loss: 0.505735\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271419; batch adversarial loss: 0.479886\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250292; batch adversarial loss: 0.513285\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291690; batch adversarial loss: 0.467759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.245899; batch adversarial loss: 0.496574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179104; batch adversarial loss: 0.568323\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265846; batch adversarial loss: 0.533334\n",
      "epoch 31; iter: 0; batch classifier loss: 0.291143; batch adversarial loss: 0.506582\n",
      "epoch 32; iter: 0; batch classifier loss: 0.254818; batch adversarial loss: 0.510290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.220484; batch adversarial loss: 0.495381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.210913; batch adversarial loss: 0.410504\n",
      "epoch 35; iter: 0; batch classifier loss: 0.154954; batch adversarial loss: 0.487560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162059; batch adversarial loss: 0.483908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.220771; batch adversarial loss: 0.472136\n",
      "epoch 38; iter: 0; batch classifier loss: 0.204401; batch adversarial loss: 0.487622\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249283; batch adversarial loss: 0.512743\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212231; batch adversarial loss: 0.465939\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227298; batch adversarial loss: 0.451074\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232350; batch adversarial loss: 0.409313\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150998; batch adversarial loss: 0.475389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.198168; batch adversarial loss: 0.463632\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195745; batch adversarial loss: 0.506065\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126563; batch adversarial loss: 0.572900\n",
      "epoch 47; iter: 0; batch classifier loss: 0.167187; batch adversarial loss: 0.490408\n",
      "epoch 48; iter: 0; batch classifier loss: 0.241207; batch adversarial loss: 0.415916\n",
      "epoch 49; iter: 0; batch classifier loss: 0.243505; batch adversarial loss: 0.449150\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119106; batch adversarial loss: 0.522427\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146339; batch adversarial loss: 0.471941\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164786; batch adversarial loss: 0.458157\n",
      "epoch 53; iter: 0; batch classifier loss: 0.217713; batch adversarial loss: 0.484847\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185797; batch adversarial loss: 0.503764\n",
      "epoch 55; iter: 0; batch classifier loss: 0.187399; batch adversarial loss: 0.455882\n",
      "epoch 56; iter: 0; batch classifier loss: 0.183982; batch adversarial loss: 0.471744\n",
      "epoch 57; iter: 0; batch classifier loss: 0.206649; batch adversarial loss: 0.472551\n",
      "epoch 58; iter: 0; batch classifier loss: 0.243908; batch adversarial loss: 0.398719\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147372; batch adversarial loss: 0.486771\n",
      "epoch 60; iter: 0; batch classifier loss: 0.224415; batch adversarial loss: 0.373157\n",
      "epoch 61; iter: 0; batch classifier loss: 0.232647; batch adversarial loss: 0.507573\n",
      "epoch 62; iter: 0; batch classifier loss: 0.190361; batch adversarial loss: 0.507569\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207106; batch adversarial loss: 0.507380\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118589; batch adversarial loss: 0.395334\n",
      "epoch 65; iter: 0; batch classifier loss: 0.149128; batch adversarial loss: 0.544992\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115804; batch adversarial loss: 0.355067\n",
      "epoch 67; iter: 0; batch classifier loss: 0.156620; batch adversarial loss: 0.496891\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222255; batch adversarial loss: 0.412585\n",
      "epoch 69; iter: 0; batch classifier loss: 0.132140; batch adversarial loss: 0.431143\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173244; batch adversarial loss: 0.523425\n",
      "epoch 71; iter: 0; batch classifier loss: 0.184760; batch adversarial loss: 0.420336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159924; batch adversarial loss: 0.543351\n",
      "epoch 73; iter: 0; batch classifier loss: 0.199538; batch adversarial loss: 0.434472\n",
      "epoch 74; iter: 0; batch classifier loss: 0.175406; batch adversarial loss: 0.424152\n",
      "epoch 75; iter: 0; batch classifier loss: 0.133584; batch adversarial loss: 0.372887\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123483; batch adversarial loss: 0.498360\n",
      "epoch 77; iter: 0; batch classifier loss: 0.150068; batch adversarial loss: 0.507574\n",
      "epoch 78; iter: 0; batch classifier loss: 0.137438; batch adversarial loss: 0.383178\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150563; batch adversarial loss: 0.482101\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121775; batch adversarial loss: 0.457423\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105801; batch adversarial loss: 0.393062\n",
      "epoch 82; iter: 0; batch classifier loss: 0.137975; batch adversarial loss: 0.472015\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143538; batch adversarial loss: 0.419281\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094840; batch adversarial loss: 0.536730\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087267; batch adversarial loss: 0.393130\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060188; batch adversarial loss: 0.393026\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090225; batch adversarial loss: 0.376375\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100034; batch adversarial loss: 0.359299\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041530; batch adversarial loss: 0.388032\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046584; batch adversarial loss: 0.394764\n",
      "epoch 91; iter: 0; batch classifier loss: 0.117831; batch adversarial loss: 0.395332\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047221; batch adversarial loss: 0.518902\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079639; batch adversarial loss: 0.352531\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059103; batch adversarial loss: 0.478345\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076885; batch adversarial loss: 0.452474\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036862; batch adversarial loss: 0.431786\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075016; batch adversarial loss: 0.442293\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058369; batch adversarial loss: 0.430875\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035718; batch adversarial loss: 0.405600\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035218; batch adversarial loss: 0.522572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047025; batch adversarial loss: 0.467672\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071163; batch adversarial loss: 0.513010\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032655; batch adversarial loss: 0.431699\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034429; batch adversarial loss: 0.409851\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041599; batch adversarial loss: 0.422883\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071078; batch adversarial loss: 0.463625\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047908; batch adversarial loss: 0.441840\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028106; batch adversarial loss: 0.495735\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033419; batch adversarial loss: 0.493880\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035775; batch adversarial loss: 0.435735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034402; batch adversarial loss: 0.407938\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049660; batch adversarial loss: 0.455519\n",
      "epoch 113; iter: 0; batch classifier loss: 0.026721; batch adversarial loss: 0.480276\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023574; batch adversarial loss: 0.391865\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025797; batch adversarial loss: 0.419030\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041090; batch adversarial loss: 0.428726\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059772; batch adversarial loss: 0.421032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033711; batch adversarial loss: 0.447679\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034242; batch adversarial loss: 0.481590\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028668; batch adversarial loss: 0.409208\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029955; batch adversarial loss: 0.388820\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034602; batch adversarial loss: 0.376096\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024997; batch adversarial loss: 0.394232\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.458625\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027498; batch adversarial loss: 0.447184\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020289; batch adversarial loss: 0.378899\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019170; batch adversarial loss: 0.584822\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026233; batch adversarial loss: 0.386231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018092; batch adversarial loss: 0.393780\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017933; batch adversarial loss: 0.418912\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051334; batch adversarial loss: 0.487296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.013319; batch adversarial loss: 0.464916\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014433; batch adversarial loss: 0.516235\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023172; batch adversarial loss: 0.474544\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026934; batch adversarial loss: 0.512462\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013672; batch adversarial loss: 0.470896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.006806; batch adversarial loss: 0.419784\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018908; batch adversarial loss: 0.368623\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026500; batch adversarial loss: 0.492588\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022011; batch adversarial loss: 0.431606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028138; batch adversarial loss: 0.427833\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024656; batch adversarial loss: 0.458110\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021748; batch adversarial loss: 0.396125\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029204; batch adversarial loss: 0.430739\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018618; batch adversarial loss: 0.402876\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010005; batch adversarial loss: 0.413037\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025815; batch adversarial loss: 0.516917\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025340; batch adversarial loss: 0.360110\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007319; batch adversarial loss: 0.460689\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015495; batch adversarial loss: 0.513455\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023722; batch adversarial loss: 0.472676\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043088; batch adversarial loss: 0.328497\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010529; batch adversarial loss: 0.478614\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037210; batch adversarial loss: 0.455041\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022068; batch adversarial loss: 0.413229\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014731; batch adversarial loss: 0.431662\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.500339\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033829; batch adversarial loss: 0.414337\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013372; batch adversarial loss: 0.532596\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017827; batch adversarial loss: 0.413093\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017276; batch adversarial loss: 0.450288\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024021; batch adversarial loss: 0.453309\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.466421\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009221; batch adversarial loss: 0.464272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005206; batch adversarial loss: 0.405791\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014823; batch adversarial loss: 0.442572\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019231; batch adversarial loss: 0.480369\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.426518\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036081; batch adversarial loss: 0.400951\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011103; batch adversarial loss: 0.497257\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006271; batch adversarial loss: 0.468672\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.436723\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007962; batch adversarial loss: 0.495489\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031424; batch adversarial loss: 0.430870\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003893; batch adversarial loss: 0.376928\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013788; batch adversarial loss: 0.529319\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037526; batch adversarial loss: 0.513810\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041143; batch adversarial loss: 0.376818\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013703; batch adversarial loss: 0.423382\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024211; batch adversarial loss: 0.508531\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007095; batch adversarial loss: 0.421407\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015934; batch adversarial loss: 0.409396\n",
      "epoch 183; iter: 0; batch classifier loss: 0.055624; batch adversarial loss: 0.422152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012604; batch adversarial loss: 0.548611\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017125; batch adversarial loss: 0.547228\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015614; batch adversarial loss: 0.469475\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018160; batch adversarial loss: 0.470216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020438; batch adversarial loss: 0.380671\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030842; batch adversarial loss: 0.454831\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017436; batch adversarial loss: 0.396610\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007333; batch adversarial loss: 0.399155\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011715; batch adversarial loss: 0.513037\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028955; batch adversarial loss: 0.439246\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022613; batch adversarial loss: 0.610331\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016281; batch adversarial loss: 0.420710\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017924; batch adversarial loss: 0.398638\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005799; batch adversarial loss: 0.427837\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023402; batch adversarial loss: 0.420249\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013529; batch adversarial loss: 0.412040\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693316; batch adversarial loss: 0.642960\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470890; batch adversarial loss: 0.634835\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412864; batch adversarial loss: 0.584470\n",
      "epoch 3; iter: 0; batch classifier loss: 0.286153; batch adversarial loss: 0.570228\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339462; batch adversarial loss: 0.548022\n",
      "epoch 5; iter: 0; batch classifier loss: 0.304658; batch adversarial loss: 0.535346\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328762; batch adversarial loss: 0.518975\n",
      "epoch 7; iter: 0; batch classifier loss: 0.243289; batch adversarial loss: 0.519757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.320967; batch adversarial loss: 0.478894\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287558; batch adversarial loss: 0.462677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.213506; batch adversarial loss: 0.523439\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301600; batch adversarial loss: 0.525745\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244223; batch adversarial loss: 0.497547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229102; batch adversarial loss: 0.458062\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192471; batch adversarial loss: 0.481830\n",
      "epoch 15; iter: 0; batch classifier loss: 0.142194; batch adversarial loss: 0.471664\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292973; batch adversarial loss: 0.517363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.173763; batch adversarial loss: 0.543120\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170667; batch adversarial loss: 0.441169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174658; batch adversarial loss: 0.475403\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210653; batch adversarial loss: 0.476146\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186242; batch adversarial loss: 0.563979\n",
      "epoch 22; iter: 0; batch classifier loss: 0.247324; batch adversarial loss: 0.513144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181470; batch adversarial loss: 0.556933\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263785; batch adversarial loss: 0.504808\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161095; batch adversarial loss: 0.426612\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202913; batch adversarial loss: 0.523246\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194663; batch adversarial loss: 0.519801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.162914; batch adversarial loss: 0.497958\n",
      "epoch 29; iter: 0; batch classifier loss: 0.201380; batch adversarial loss: 0.531850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205205; batch adversarial loss: 0.500456\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233832; batch adversarial loss: 0.456023\n",
      "epoch 32; iter: 0; batch classifier loss: 0.271423; batch adversarial loss: 0.576452\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241508; batch adversarial loss: 0.496029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.217591; batch adversarial loss: 0.510739\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270994; batch adversarial loss: 0.459039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189258; batch adversarial loss: 0.433674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162149; batch adversarial loss: 0.458006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150254; batch adversarial loss: 0.408407\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079896; batch adversarial loss: 0.442162\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134095; batch adversarial loss: 0.505719\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130355; batch adversarial loss: 0.424045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101755; batch adversarial loss: 0.548056\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150793; batch adversarial loss: 0.466716\n",
      "epoch 44; iter: 0; batch classifier loss: 0.066602; batch adversarial loss: 0.459748\n",
      "epoch 45; iter: 0; batch classifier loss: 0.071087; batch adversarial loss: 0.551730\n",
      "epoch 46; iter: 0; batch classifier loss: 0.070061; batch adversarial loss: 0.462473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084077; batch adversarial loss: 0.470134\n",
      "epoch 48; iter: 0; batch classifier loss: 0.079921; batch adversarial loss: 0.434343\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084182; batch adversarial loss: 0.518748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102171; batch adversarial loss: 0.489697\n",
      "epoch 51; iter: 0; batch classifier loss: 0.136918; batch adversarial loss: 0.498285\n",
      "epoch 52; iter: 0; batch classifier loss: 0.055165; batch adversarial loss: 0.582396\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094988; batch adversarial loss: 0.522882\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074227; batch adversarial loss: 0.531885\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063131; batch adversarial loss: 0.483529\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101211; batch adversarial loss: 0.505927\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103637; batch adversarial loss: 0.488513\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112769; batch adversarial loss: 0.331298\n",
      "epoch 59; iter: 0; batch classifier loss: 0.048227; batch adversarial loss: 0.474065\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084382; batch adversarial loss: 0.471085\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064918; batch adversarial loss: 0.502955\n",
      "epoch 62; iter: 0; batch classifier loss: 0.055755; batch adversarial loss: 0.517428\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067423; batch adversarial loss: 0.469597\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105477; batch adversarial loss: 0.512263\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070008; batch adversarial loss: 0.463557\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068425; batch adversarial loss: 0.448073\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088930; batch adversarial loss: 0.352003\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085116; batch adversarial loss: 0.406310\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080855; batch adversarial loss: 0.402775\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054636; batch adversarial loss: 0.454395\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127799; batch adversarial loss: 0.393185\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055088; batch adversarial loss: 0.408380\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116980; batch adversarial loss: 0.362720\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081569; batch adversarial loss: 0.449757\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073440; batch adversarial loss: 0.442997\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077571; batch adversarial loss: 0.424165\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056545; batch adversarial loss: 0.444957\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087601; batch adversarial loss: 0.418415\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075408; batch adversarial loss: 0.359171\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090565; batch adversarial loss: 0.459328\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070521; batch adversarial loss: 0.559553\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065944; batch adversarial loss: 0.499477\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050814; batch adversarial loss: 0.512973\n",
      "epoch 84; iter: 0; batch classifier loss: 0.145349; batch adversarial loss: 0.491278\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079065; batch adversarial loss: 0.418234\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072738; batch adversarial loss: 0.526957\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079930; batch adversarial loss: 0.419863\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076571; batch adversarial loss: 0.412398\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091888; batch adversarial loss: 0.493056\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146571; batch adversarial loss: 0.467294\n",
      "epoch 91; iter: 0; batch classifier loss: 0.098993; batch adversarial loss: 0.566758\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073611; batch adversarial loss: 0.486578\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119202; batch adversarial loss: 0.375994\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041500; batch adversarial loss: 0.574347\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083640; batch adversarial loss: 0.422910\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068452; batch adversarial loss: 0.516997\n",
      "epoch 97; iter: 0; batch classifier loss: 0.111460; batch adversarial loss: 0.402158\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065057; batch adversarial loss: 0.437011\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031434; batch adversarial loss: 0.388590\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048844; batch adversarial loss: 0.374539\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.481529\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057756; batch adversarial loss: 0.380892\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078940; batch adversarial loss: 0.425876\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025411; batch adversarial loss: 0.537109\n",
      "epoch 105; iter: 0; batch classifier loss: 0.085723; batch adversarial loss: 0.542151\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092378; batch adversarial loss: 0.323692\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031354; batch adversarial loss: 0.477710\n",
      "epoch 108; iter: 0; batch classifier loss: 0.090918; batch adversarial loss: 0.433705\n",
      "epoch 109; iter: 0; batch classifier loss: 0.072873; batch adversarial loss: 0.472493\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047097; batch adversarial loss: 0.449382\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069884; batch adversarial loss: 0.446846\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060179; batch adversarial loss: 0.446499\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064854; batch adversarial loss: 0.474727\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055825; batch adversarial loss: 0.375074\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045707; batch adversarial loss: 0.428207\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055249; batch adversarial loss: 0.466316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067430; batch adversarial loss: 0.433165\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063277; batch adversarial loss: 0.409025\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032528; batch adversarial loss: 0.437156\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060936; batch adversarial loss: 0.405201\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055411; batch adversarial loss: 0.419157\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045820; batch adversarial loss: 0.508695\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054003; batch adversarial loss: 0.456035\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021873; batch adversarial loss: 0.512599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040453; batch adversarial loss: 0.420058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.108387; batch adversarial loss: 0.498490\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.464979\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030626; batch adversarial loss: 0.395219\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036811; batch adversarial loss: 0.472211\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057746; batch adversarial loss: 0.430570\n",
      "epoch 131; iter: 0; batch classifier loss: 0.105785; batch adversarial loss: 0.420326\n",
      "epoch 132; iter: 0; batch classifier loss: 0.084261; batch adversarial loss: 0.413145\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020218; batch adversarial loss: 0.456468\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.370068\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030593; batch adversarial loss: 0.390179\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046575; batch adversarial loss: 0.432434\n",
      "epoch 137; iter: 0; batch classifier loss: 0.073904; batch adversarial loss: 0.417262\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024798; batch adversarial loss: 0.512140\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065410; batch adversarial loss: 0.538736\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029954; batch adversarial loss: 0.373705\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019572; batch adversarial loss: 0.488990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035763; batch adversarial loss: 0.469805\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046783; batch adversarial loss: 0.423597\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048686; batch adversarial loss: 0.532651\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035964; batch adversarial loss: 0.460394\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045349; batch adversarial loss: 0.488453\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034276; batch adversarial loss: 0.432817\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043335; batch adversarial loss: 0.522610\n",
      "epoch 149; iter: 0; batch classifier loss: 0.061318; batch adversarial loss: 0.466121\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039512; batch adversarial loss: 0.471532\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013457; batch adversarial loss: 0.416746\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019979; batch adversarial loss: 0.468546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046457; batch adversarial loss: 0.410836\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044017; batch adversarial loss: 0.440275\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035399; batch adversarial loss: 0.601846\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041623; batch adversarial loss: 0.479647\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049259; batch adversarial loss: 0.527718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026597; batch adversarial loss: 0.503859\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022355; batch adversarial loss: 0.524989\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032013; batch adversarial loss: 0.498900\n",
      "epoch 161; iter: 0; batch classifier loss: 0.066017; batch adversarial loss: 0.584255\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039796; batch adversarial loss: 0.479732\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029744; batch adversarial loss: 0.441329\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010357; batch adversarial loss: 0.454709\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.451496\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017869; batch adversarial loss: 0.377801\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010600; batch adversarial loss: 0.388315\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030513; batch adversarial loss: 0.466383\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034560; batch adversarial loss: 0.542485\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024543; batch adversarial loss: 0.429974\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040733; batch adversarial loss: 0.420262\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029838; batch adversarial loss: 0.425759\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024830; batch adversarial loss: 0.359140\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041852; batch adversarial loss: 0.454576\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029855; batch adversarial loss: 0.473401\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025954; batch adversarial loss: 0.395580\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028369; batch adversarial loss: 0.384576\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021880; batch adversarial loss: 0.414333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.506144\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038073; batch adversarial loss: 0.462241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027891; batch adversarial loss: 0.403473\n",
      "epoch 182; iter: 0; batch classifier loss: 0.067483; batch adversarial loss: 0.525810\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023931; batch adversarial loss: 0.391690\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024074; batch adversarial loss: 0.543267\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046851; batch adversarial loss: 0.420671\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.487290\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014612; batch adversarial loss: 0.440771\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016004; batch adversarial loss: 0.577853\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022521; batch adversarial loss: 0.476835\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034341; batch adversarial loss: 0.449574\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.349979\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013470; batch adversarial loss: 0.423756\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038812; batch adversarial loss: 0.418017\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.417447\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016622; batch adversarial loss: 0.384284\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.446336\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053083; batch adversarial loss: 0.436396\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018767; batch adversarial loss: 0.440127\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013838; batch adversarial loss: 0.501950\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712519; batch adversarial loss: 0.594830\n",
      "epoch 1; iter: 0; batch classifier loss: 0.497788; batch adversarial loss: 0.600620\n",
      "epoch 2; iter: 0; batch classifier loss: 0.386815; batch adversarial loss: 0.582539\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403072; batch adversarial loss: 0.564797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369509; batch adversarial loss: 0.500900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.310067; batch adversarial loss: 0.597661\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285227; batch adversarial loss: 0.587021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312145; batch adversarial loss: 0.504415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.258914; batch adversarial loss: 0.491044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300749; batch adversarial loss: 0.520247\n",
      "epoch 10; iter: 0; batch classifier loss: 0.220891; batch adversarial loss: 0.450028\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291701; batch adversarial loss: 0.542461\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267584; batch adversarial loss: 0.490583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229213; batch adversarial loss: 0.539683\n",
      "epoch 14; iter: 0; batch classifier loss: 0.187941; batch adversarial loss: 0.427982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.184667; batch adversarial loss: 0.470780\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203187; batch adversarial loss: 0.508952\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317538; batch adversarial loss: 0.521665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241506; batch adversarial loss: 0.474426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205254; batch adversarial loss: 0.566214\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187604; batch adversarial loss: 0.550498\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182121; batch adversarial loss: 0.436134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.116864; batch adversarial loss: 0.446396\n",
      "epoch 23; iter: 0; batch classifier loss: 0.168662; batch adversarial loss: 0.459821\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145128; batch adversarial loss: 0.419515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177619; batch adversarial loss: 0.437731\n",
      "epoch 26; iter: 0; batch classifier loss: 0.139718; batch adversarial loss: 0.418205\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181974; batch adversarial loss: 0.359081\n",
      "epoch 28; iter: 0; batch classifier loss: 0.128020; batch adversarial loss: 0.602910\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157971; batch adversarial loss: 0.370643\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144602; batch adversarial loss: 0.452560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157779; batch adversarial loss: 0.409619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133376; batch adversarial loss: 0.440462\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172088; batch adversarial loss: 0.417264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.129489; batch adversarial loss: 0.447768\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118490; batch adversarial loss: 0.603742\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102124; batch adversarial loss: 0.422606\n",
      "epoch 37; iter: 0; batch classifier loss: 0.160640; batch adversarial loss: 0.383755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157043; batch adversarial loss: 0.462538\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104176; batch adversarial loss: 0.426299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.166688; batch adversarial loss: 0.414324\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153959; batch adversarial loss: 0.381941\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134458; batch adversarial loss: 0.369868\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187167; batch adversarial loss: 0.396504\n",
      "epoch 44; iter: 0; batch classifier loss: 0.157297; batch adversarial loss: 0.460511\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115865; batch adversarial loss: 0.461934\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136272; batch adversarial loss: 0.394591\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122346; batch adversarial loss: 0.448215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144355; batch adversarial loss: 0.368643\n",
      "epoch 49; iter: 0; batch classifier loss: 0.163825; batch adversarial loss: 0.449643\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083122; batch adversarial loss: 0.520932\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154033; batch adversarial loss: 0.367813\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109891; batch adversarial loss: 0.520697\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094144; batch adversarial loss: 0.413569\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102051; batch adversarial loss: 0.435128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.145289; batch adversarial loss: 0.504183\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118613; batch adversarial loss: 0.347930\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119398; batch adversarial loss: 0.437761\n",
      "epoch 58; iter: 0; batch classifier loss: 0.210502; batch adversarial loss: 0.395020\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105296; batch adversarial loss: 0.516720\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148501; batch adversarial loss: 0.538406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110742; batch adversarial loss: 0.554838\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100596; batch adversarial loss: 0.454589\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111402; batch adversarial loss: 0.426559\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124731; batch adversarial loss: 0.509089\n",
      "epoch 65; iter: 0; batch classifier loss: 0.141895; batch adversarial loss: 0.410935\n",
      "epoch 66; iter: 0; batch classifier loss: 0.101908; batch adversarial loss: 0.369395\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154284; batch adversarial loss: 0.499358\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134963; batch adversarial loss: 0.474779\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105192; batch adversarial loss: 0.439741\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118494; batch adversarial loss: 0.474067\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097963; batch adversarial loss: 0.476521\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149507; batch adversarial loss: 0.384581\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083245; batch adversarial loss: 0.408796\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103710; batch adversarial loss: 0.460283\n",
      "epoch 75; iter: 0; batch classifier loss: 0.125835; batch adversarial loss: 0.442952\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120921; batch adversarial loss: 0.541009\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106074; batch adversarial loss: 0.481971\n",
      "epoch 78; iter: 0; batch classifier loss: 0.101921; batch adversarial loss: 0.462820\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076981; batch adversarial loss: 0.515560\n",
      "epoch 80; iter: 0; batch classifier loss: 0.124302; batch adversarial loss: 0.445972\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070978; batch adversarial loss: 0.478408\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110079; batch adversarial loss: 0.518825\n",
      "epoch 83; iter: 0; batch classifier loss: 0.139583; batch adversarial loss: 0.404061\n",
      "epoch 84; iter: 0; batch classifier loss: 0.131682; batch adversarial loss: 0.478005\n",
      "epoch 85; iter: 0; batch classifier loss: 0.136046; batch adversarial loss: 0.501007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087630; batch adversarial loss: 0.417048\n",
      "epoch 87; iter: 0; batch classifier loss: 0.104695; batch adversarial loss: 0.395829\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075046; batch adversarial loss: 0.428688\n",
      "epoch 89; iter: 0; batch classifier loss: 0.108516; batch adversarial loss: 0.435745\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062936; batch adversarial loss: 0.361634\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066680; batch adversarial loss: 0.521852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.096565; batch adversarial loss: 0.389707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.099350; batch adversarial loss: 0.442446\n",
      "epoch 94; iter: 0; batch classifier loss: 0.054057; batch adversarial loss: 0.490616\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063423; batch adversarial loss: 0.441854\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058739; batch adversarial loss: 0.357534\n",
      "epoch 97; iter: 0; batch classifier loss: 0.095466; batch adversarial loss: 0.479311\n",
      "epoch 98; iter: 0; batch classifier loss: 0.122385; batch adversarial loss: 0.345040\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088724; batch adversarial loss: 0.412187\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048155; batch adversarial loss: 0.427870\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097426; batch adversarial loss: 0.426872\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042739; batch adversarial loss: 0.466903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054632; batch adversarial loss: 0.431973\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068966; batch adversarial loss: 0.415913\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058189; batch adversarial loss: 0.427762\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051038; batch adversarial loss: 0.415850\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035317; batch adversarial loss: 0.354409\n",
      "epoch 108; iter: 0; batch classifier loss: 0.094207; batch adversarial loss: 0.467684\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055890; batch adversarial loss: 0.369434\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061190; batch adversarial loss: 0.446449\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064264; batch adversarial loss: 0.421538\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064213; batch adversarial loss: 0.424414\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023146; batch adversarial loss: 0.439880\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048125; batch adversarial loss: 0.447629\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056923; batch adversarial loss: 0.485116\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032583; batch adversarial loss: 0.466936\n",
      "epoch 117; iter: 0; batch classifier loss: 0.120714; batch adversarial loss: 0.459838\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041619; batch adversarial loss: 0.486460\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.436922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.049341; batch adversarial loss: 0.389714\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040191; batch adversarial loss: 0.383556\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036605; batch adversarial loss: 0.375409\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026289; batch adversarial loss: 0.412680\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039081; batch adversarial loss: 0.409292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037389; batch adversarial loss: 0.386779\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018628; batch adversarial loss: 0.517789\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026895; batch adversarial loss: 0.505670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019695; batch adversarial loss: 0.477261\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023551; batch adversarial loss: 0.464936\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025086; batch adversarial loss: 0.498671\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035560; batch adversarial loss: 0.405912\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058457; batch adversarial loss: 0.442296\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027049; batch adversarial loss: 0.502871\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024331; batch adversarial loss: 0.414514\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038274; batch adversarial loss: 0.453888\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010573; batch adversarial loss: 0.405096\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025277; batch adversarial loss: 0.408276\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032869; batch adversarial loss: 0.520595\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.470164\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019939; batch adversarial loss: 0.360765\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061818; batch adversarial loss: 0.391468\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014357; batch adversarial loss: 0.568956\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042052; batch adversarial loss: 0.467065\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030230; batch adversarial loss: 0.441233\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032914; batch adversarial loss: 0.359097\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029279; batch adversarial loss: 0.422540\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.454250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.080565; batch adversarial loss: 0.375852\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038679; batch adversarial loss: 0.321514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.391414\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021712; batch adversarial loss: 0.418098\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038459; batch adversarial loss: 0.410442\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023921; batch adversarial loss: 0.486235\n",
      "epoch 154; iter: 0; batch classifier loss: 0.039988; batch adversarial loss: 0.482170\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018212; batch adversarial loss: 0.382863\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038619; batch adversarial loss: 0.438036\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009607; batch adversarial loss: 0.404342\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016310; batch adversarial loss: 0.483734\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009680; batch adversarial loss: 0.528443\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018434; batch adversarial loss: 0.469809\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017349; batch adversarial loss: 0.509128\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022369; batch adversarial loss: 0.342410\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032959; batch adversarial loss: 0.431709\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029760; batch adversarial loss: 0.544101\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024276; batch adversarial loss: 0.418366\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018387; batch adversarial loss: 0.383147\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031562; batch adversarial loss: 0.351646\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016113; batch adversarial loss: 0.491623\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010878; batch adversarial loss: 0.473283\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009551; batch adversarial loss: 0.474335\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018947; batch adversarial loss: 0.517861\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042869; batch adversarial loss: 0.447813\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044930; batch adversarial loss: 0.485864\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.384593\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011655; batch adversarial loss: 0.405616\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014182; batch adversarial loss: 0.488528\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040536; batch adversarial loss: 0.436593\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039038; batch adversarial loss: 0.402749\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033965; batch adversarial loss: 0.493783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010205; batch adversarial loss: 0.393241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.318942\n",
      "epoch 182; iter: 0; batch classifier loss: 0.055931; batch adversarial loss: 0.338513\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011064; batch adversarial loss: 0.409405\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019808; batch adversarial loss: 0.359437\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008003; batch adversarial loss: 0.339550\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027555; batch adversarial loss: 0.439155\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014781; batch adversarial loss: 0.404359\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014918; batch adversarial loss: 0.511995\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023871; batch adversarial loss: 0.452221\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009978; batch adversarial loss: 0.484334\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036390; batch adversarial loss: 0.423088\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027054; batch adversarial loss: 0.465225\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026107; batch adversarial loss: 0.373185\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024128; batch adversarial loss: 0.483368\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045810; batch adversarial loss: 0.493551\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007309; batch adversarial loss: 0.436350\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029997; batch adversarial loss: 0.344784\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041229; batch adversarial loss: 0.465311\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019055; batch adversarial loss: 0.466947\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689145; batch adversarial loss: 0.743505\n",
      "epoch 1; iter: 0; batch classifier loss: 0.506215; batch adversarial loss: 0.709925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.363691; batch adversarial loss: 0.686815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400084; batch adversarial loss: 0.657038\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406624; batch adversarial loss: 0.640278\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382301; batch adversarial loss: 0.559189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318930; batch adversarial loss: 0.563099\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283797; batch adversarial loss: 0.555468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.264875; batch adversarial loss: 0.536289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233465; batch adversarial loss: 0.492854\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232539; batch adversarial loss: 0.483828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253343; batch adversarial loss: 0.512729\n",
      "epoch 12; iter: 0; batch classifier loss: 0.215187; batch adversarial loss: 0.463882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214611; batch adversarial loss: 0.481126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179253; batch adversarial loss: 0.474273\n",
      "epoch 15; iter: 0; batch classifier loss: 0.211226; batch adversarial loss: 0.455406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.136452; batch adversarial loss: 0.454662\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189002; batch adversarial loss: 0.422990\n",
      "epoch 18; iter: 0; batch classifier loss: 0.129242; batch adversarial loss: 0.477639\n",
      "epoch 19; iter: 0; batch classifier loss: 0.108567; batch adversarial loss: 0.453449\n",
      "epoch 20; iter: 0; batch classifier loss: 0.140605; batch adversarial loss: 0.430333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.131795; batch adversarial loss: 0.468668\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145906; batch adversarial loss: 0.477036\n",
      "epoch 23; iter: 0; batch classifier loss: 0.124872; batch adversarial loss: 0.497216\n",
      "epoch 24; iter: 0; batch classifier loss: 0.126540; batch adversarial loss: 0.400085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.099958; batch adversarial loss: 0.546234\n",
      "epoch 26; iter: 0; batch classifier loss: 0.105578; batch adversarial loss: 0.395639\n",
      "epoch 27; iter: 0; batch classifier loss: 0.100373; batch adversarial loss: 0.453556\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174115; batch adversarial loss: 0.459180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152169; batch adversarial loss: 0.594844\n",
      "epoch 30; iter: 0; batch classifier loss: 0.114134; batch adversarial loss: 0.488489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.061253; batch adversarial loss: 0.475754\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131916; batch adversarial loss: 0.443422\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161495; batch adversarial loss: 0.492349\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145297; batch adversarial loss: 0.424194\n",
      "epoch 35; iter: 0; batch classifier loss: 0.124721; batch adversarial loss: 0.545343\n",
      "epoch 36; iter: 0; batch classifier loss: 0.145562; batch adversarial loss: 0.517097\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153363; batch adversarial loss: 0.501753\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161438; batch adversarial loss: 0.503004\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173126; batch adversarial loss: 0.584154\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143645; batch adversarial loss: 0.574738\n",
      "epoch 41; iter: 0; batch classifier loss: 0.069564; batch adversarial loss: 0.399896\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129517; batch adversarial loss: 0.494029\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099148; batch adversarial loss: 0.496549\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132175; batch adversarial loss: 0.441346\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129854; batch adversarial loss: 0.426555\n",
      "epoch 46; iter: 0; batch classifier loss: 0.130791; batch adversarial loss: 0.464481\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122321; batch adversarial loss: 0.440835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136124; batch adversarial loss: 0.495431\n",
      "epoch 49; iter: 0; batch classifier loss: 0.209103; batch adversarial loss: 0.441086\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117456; batch adversarial loss: 0.433831\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070767; batch adversarial loss: 0.416876\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076123; batch adversarial loss: 0.501370\n",
      "epoch 53; iter: 0; batch classifier loss: 0.049492; batch adversarial loss: 0.418260\n",
      "epoch 54; iter: 0; batch classifier loss: 0.078854; batch adversarial loss: 0.467844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.053818; batch adversarial loss: 0.439427\n",
      "epoch 56; iter: 0; batch classifier loss: 0.056444; batch adversarial loss: 0.524173\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082406; batch adversarial loss: 0.400369\n",
      "epoch 58; iter: 0; batch classifier loss: 0.055110; batch adversarial loss: 0.463038\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067045; batch adversarial loss: 0.486369\n",
      "epoch 60; iter: 0; batch classifier loss: 0.026719; batch adversarial loss: 0.435700\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074030; batch adversarial loss: 0.384833\n",
      "epoch 62; iter: 0; batch classifier loss: 0.032491; batch adversarial loss: 0.492783\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051240; batch adversarial loss: 0.455962\n",
      "epoch 64; iter: 0; batch classifier loss: 0.045806; batch adversarial loss: 0.453709\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080806; batch adversarial loss: 0.349267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057527; batch adversarial loss: 0.374817\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082388; batch adversarial loss: 0.402199\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070620; batch adversarial loss: 0.369498\n",
      "epoch 69; iter: 0; batch classifier loss: 0.118090; batch adversarial loss: 0.387518\n",
      "epoch 70; iter: 0; batch classifier loss: 0.032911; batch adversarial loss: 0.371031\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058470; batch adversarial loss: 0.519684\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041899; batch adversarial loss: 0.441707\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071341; batch adversarial loss: 0.469885\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079877; batch adversarial loss: 0.441881\n",
      "epoch 75; iter: 0; batch classifier loss: 0.031198; batch adversarial loss: 0.388171\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067506; batch adversarial loss: 0.548282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045348; batch adversarial loss: 0.356616\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081907; batch adversarial loss: 0.402072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054153; batch adversarial loss: 0.474656\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075629; batch adversarial loss: 0.531581\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062037; batch adversarial loss: 0.474456\n",
      "epoch 82; iter: 0; batch classifier loss: 0.029558; batch adversarial loss: 0.392576\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089659; batch adversarial loss: 0.443661\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062920; batch adversarial loss: 0.381148\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070290; batch adversarial loss: 0.445081\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071843; batch adversarial loss: 0.472065\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086966; batch adversarial loss: 0.486165\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086675; batch adversarial loss: 0.369965\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081327; batch adversarial loss: 0.444728\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.450201\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081669; batch adversarial loss: 0.489263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094046; batch adversarial loss: 0.393832\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039723; batch adversarial loss: 0.444308\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068284; batch adversarial loss: 0.465125\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047428; batch adversarial loss: 0.562163\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051763; batch adversarial loss: 0.461612\n",
      "epoch 97; iter: 0; batch classifier loss: 0.135674; batch adversarial loss: 0.510381\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063612; batch adversarial loss: 0.557912\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059384; batch adversarial loss: 0.602567\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052210; batch adversarial loss: 0.391441\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066626; batch adversarial loss: 0.401681\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087888; batch adversarial loss: 0.378858\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047226; batch adversarial loss: 0.455675\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037713; batch adversarial loss: 0.414586\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041906; batch adversarial loss: 0.362296\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031948; batch adversarial loss: 0.453959\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027263; batch adversarial loss: 0.383615\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048662; batch adversarial loss: 0.458838\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054477; batch adversarial loss: 0.402691\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040370; batch adversarial loss: 0.383871\n",
      "epoch 111; iter: 0; batch classifier loss: 0.099552; batch adversarial loss: 0.447507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058761; batch adversarial loss: 0.481001\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058306; batch adversarial loss: 0.450358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.067982; batch adversarial loss: 0.434729\n",
      "epoch 115; iter: 0; batch classifier loss: 0.083708; batch adversarial loss: 0.470970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027256; batch adversarial loss: 0.423881\n",
      "epoch 117; iter: 0; batch classifier loss: 0.059859; batch adversarial loss: 0.371095\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060506; batch adversarial loss: 0.539225\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035484; batch adversarial loss: 0.410411\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023290; batch adversarial loss: 0.440292\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046413; batch adversarial loss: 0.437177\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027382; batch adversarial loss: 0.453084\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.476901\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030621; batch adversarial loss: 0.375030\n",
      "epoch 125; iter: 0; batch classifier loss: 0.063557; batch adversarial loss: 0.399854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031391; batch adversarial loss: 0.363418\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033999; batch adversarial loss: 0.534083\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049050; batch adversarial loss: 0.415251\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063292; batch adversarial loss: 0.410405\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050154; batch adversarial loss: 0.442656\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030895; batch adversarial loss: 0.347786\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048890; batch adversarial loss: 0.463020\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030840; batch adversarial loss: 0.444471\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029596; batch adversarial loss: 0.366570\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032309; batch adversarial loss: 0.401248\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068860; batch adversarial loss: 0.405934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015769; batch adversarial loss: 0.503368\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072607; batch adversarial loss: 0.440381\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050855; batch adversarial loss: 0.534471\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044696; batch adversarial loss: 0.444647\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026411; batch adversarial loss: 0.589900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028026; batch adversarial loss: 0.408253\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009729; batch adversarial loss: 0.426897\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033794; batch adversarial loss: 0.450136\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054499; batch adversarial loss: 0.362521\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029743; batch adversarial loss: 0.455537\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030448; batch adversarial loss: 0.476979\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022777; batch adversarial loss: 0.454617\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013363; batch adversarial loss: 0.399048\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016745; batch adversarial loss: 0.412183\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012762; batch adversarial loss: 0.442101\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030534; batch adversarial loss: 0.299158\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028869; batch adversarial loss: 0.409389\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018490; batch adversarial loss: 0.416462\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032120; batch adversarial loss: 0.531005\n",
      "epoch 156; iter: 0; batch classifier loss: 0.060803; batch adversarial loss: 0.438905\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.494443\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010267; batch adversarial loss: 0.527275\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017344; batch adversarial loss: 0.436425\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026626; batch adversarial loss: 0.474139\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039144; batch adversarial loss: 0.445203\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011889; batch adversarial loss: 0.463356\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038016; batch adversarial loss: 0.495258\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015183; batch adversarial loss: 0.414915\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014536; batch adversarial loss: 0.507853\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025539; batch adversarial loss: 0.404506\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013427; batch adversarial loss: 0.510621\n",
      "epoch 168; iter: 0; batch classifier loss: 0.051831; batch adversarial loss: 0.511500\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023769; batch adversarial loss: 0.375347\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022757; batch adversarial loss: 0.417375\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030228; batch adversarial loss: 0.477537\n",
      "epoch 172; iter: 0; batch classifier loss: 0.050566; batch adversarial loss: 0.428329\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010540; batch adversarial loss: 0.555359\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034686; batch adversarial loss: 0.472037\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018065; batch adversarial loss: 0.334080\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028001; batch adversarial loss: 0.359255\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011111; batch adversarial loss: 0.450551\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005711; batch adversarial loss: 0.484249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029473; batch adversarial loss: 0.585534\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020001; batch adversarial loss: 0.401480\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019663; batch adversarial loss: 0.480421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019164; batch adversarial loss: 0.500178\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011570; batch adversarial loss: 0.338468\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015476; batch adversarial loss: 0.435040\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042080; batch adversarial loss: 0.498286\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021188; batch adversarial loss: 0.498320\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032911; batch adversarial loss: 0.410156\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011921; batch adversarial loss: 0.410250\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012957; batch adversarial loss: 0.437826\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012196; batch adversarial loss: 0.536087\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013039; batch adversarial loss: 0.486445\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006080; batch adversarial loss: 0.427436\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005688; batch adversarial loss: 0.462593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006089; batch adversarial loss: 0.461849\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.534527\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014822; batch adversarial loss: 0.505808\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003237; batch adversarial loss: 0.510511\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019121; batch adversarial loss: 0.486055\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005255; batch adversarial loss: 0.414331\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706359; batch adversarial loss: 0.631263\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422766; batch adversarial loss: 0.607213\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433516; batch adversarial loss: 0.648749\n",
      "epoch 3; iter: 0; batch classifier loss: 0.413819; batch adversarial loss: 0.598043\n",
      "epoch 4; iter: 0; batch classifier loss: 0.371059; batch adversarial loss: 0.595932\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363354; batch adversarial loss: 0.562115\n",
      "epoch 6; iter: 0; batch classifier loss: 0.350393; batch adversarial loss: 0.578792\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456072; batch adversarial loss: 0.574763\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305153; batch adversarial loss: 0.575245\n",
      "epoch 9; iter: 0; batch classifier loss: 0.325619; batch adversarial loss: 0.540456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.277006; batch adversarial loss: 0.506798\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320513; batch adversarial loss: 0.535249\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280744; batch adversarial loss: 0.505867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315899; batch adversarial loss: 0.422714\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265333; batch adversarial loss: 0.433918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.269053; batch adversarial loss: 0.508223\n",
      "epoch 16; iter: 0; batch classifier loss: 0.320481; batch adversarial loss: 0.495847\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300001; batch adversarial loss: 0.463255\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213556; batch adversarial loss: 0.405708\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260466; batch adversarial loss: 0.507362\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302304; batch adversarial loss: 0.438051\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261014; batch adversarial loss: 0.388583\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257746; batch adversarial loss: 0.574370\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207066; batch adversarial loss: 0.365801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186201; batch adversarial loss: 0.489050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211527; batch adversarial loss: 0.433189\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177628; batch adversarial loss: 0.482385\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217901; batch adversarial loss: 0.460412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.230412; batch adversarial loss: 0.438532\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143100; batch adversarial loss: 0.488336\n",
      "epoch 30; iter: 0; batch classifier loss: 0.249350; batch adversarial loss: 0.481298\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202605; batch adversarial loss: 0.484249\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208750; batch adversarial loss: 0.487413\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152416; batch adversarial loss: 0.385764\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202399; batch adversarial loss: 0.417383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183866; batch adversarial loss: 0.474708\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187609; batch adversarial loss: 0.458868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166989; batch adversarial loss: 0.403956\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249373; batch adversarial loss: 0.382282\n",
      "epoch 39; iter: 0; batch classifier loss: 0.218928; batch adversarial loss: 0.450465\n",
      "epoch 40; iter: 0; batch classifier loss: 0.181121; batch adversarial loss: 0.457097\n",
      "epoch 41; iter: 0; batch classifier loss: 0.207636; batch adversarial loss: 0.501609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217037; batch adversarial loss: 0.438287\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227865; batch adversarial loss: 0.466356\n",
      "epoch 44; iter: 0; batch classifier loss: 0.204377; batch adversarial loss: 0.402874\n",
      "epoch 45; iter: 0; batch classifier loss: 0.232885; batch adversarial loss: 0.435522\n",
      "epoch 46; iter: 0; batch classifier loss: 0.267342; batch adversarial loss: 0.450015\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211834; batch adversarial loss: 0.520573\n",
      "epoch 48; iter: 0; batch classifier loss: 0.268347; batch adversarial loss: 0.384969\n",
      "epoch 49; iter: 0; batch classifier loss: 0.252228; batch adversarial loss: 0.463382\n",
      "epoch 50; iter: 0; batch classifier loss: 0.221988; batch adversarial loss: 0.447851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165498; batch adversarial loss: 0.483491\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217378; batch adversarial loss: 0.312167\n",
      "epoch 53; iter: 0; batch classifier loss: 0.148932; batch adversarial loss: 0.384705\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162693; batch adversarial loss: 0.444498\n",
      "epoch 55; iter: 0; batch classifier loss: 0.163550; batch adversarial loss: 0.382264\n",
      "epoch 56; iter: 0; batch classifier loss: 0.262321; batch adversarial loss: 0.484489\n",
      "epoch 57; iter: 0; batch classifier loss: 0.232428; batch adversarial loss: 0.472109\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198103; batch adversarial loss: 0.508475\n",
      "epoch 59; iter: 0; batch classifier loss: 0.216059; batch adversarial loss: 0.421811\n",
      "epoch 60; iter: 0; batch classifier loss: 0.140798; batch adversarial loss: 0.408770\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109477; batch adversarial loss: 0.445587\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154355; batch adversarial loss: 0.368827\n",
      "epoch 63; iter: 0; batch classifier loss: 0.140557; batch adversarial loss: 0.434024\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212738; batch adversarial loss: 0.431804\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184966; batch adversarial loss: 0.383706\n",
      "epoch 66; iter: 0; batch classifier loss: 0.213856; batch adversarial loss: 0.357270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.250484; batch adversarial loss: 0.458775\n",
      "epoch 68; iter: 0; batch classifier loss: 0.179049; batch adversarial loss: 0.357652\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147117; batch adversarial loss: 0.522245\n",
      "epoch 70; iter: 0; batch classifier loss: 0.221113; batch adversarial loss: 0.534834\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076410; batch adversarial loss: 0.521849\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092574; batch adversarial loss: 0.457493\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066266; batch adversarial loss: 0.540058\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091901; batch adversarial loss: 0.440700\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070959; batch adversarial loss: 0.434063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062477; batch adversarial loss: 0.413875\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078033; batch adversarial loss: 0.353685\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066239; batch adversarial loss: 0.508150\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093935; batch adversarial loss: 0.407369\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090488; batch adversarial loss: 0.401848\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101274; batch adversarial loss: 0.367824\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121803; batch adversarial loss: 0.389617\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058554; batch adversarial loss: 0.489286\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064309; batch adversarial loss: 0.340515\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046165; batch adversarial loss: 0.505923\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054774; batch adversarial loss: 0.316657\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041959; batch adversarial loss: 0.418949\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087953; batch adversarial loss: 0.371823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.397334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072627; batch adversarial loss: 0.590313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100981; batch adversarial loss: 0.447909\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079212; batch adversarial loss: 0.411927\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076869; batch adversarial loss: 0.468135\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079968; batch adversarial loss: 0.482475\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043752; batch adversarial loss: 0.485571\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057259; batch adversarial loss: 0.449230\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057686; batch adversarial loss: 0.425549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088668; batch adversarial loss: 0.397304\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044037; batch adversarial loss: 0.450824\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056818; batch adversarial loss: 0.426678\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066457; batch adversarial loss: 0.406321\n",
      "epoch 102; iter: 0; batch classifier loss: 0.098742; batch adversarial loss: 0.358741\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073901; batch adversarial loss: 0.401247\n",
      "epoch 104; iter: 0; batch classifier loss: 0.122830; batch adversarial loss: 0.456651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079978; batch adversarial loss: 0.404008\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059145; batch adversarial loss: 0.407040\n",
      "epoch 107; iter: 0; batch classifier loss: 0.106743; batch adversarial loss: 0.418476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.064891; batch adversarial loss: 0.432251\n",
      "epoch 109; iter: 0; batch classifier loss: 0.096853; batch adversarial loss: 0.548101\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065116; batch adversarial loss: 0.358687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085418; batch adversarial loss: 0.354686\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056063; batch adversarial loss: 0.395013\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059857; batch adversarial loss: 0.372857\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078508; batch adversarial loss: 0.447760\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065003; batch adversarial loss: 0.383031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047593; batch adversarial loss: 0.395270\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040207; batch adversarial loss: 0.304080\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063855; batch adversarial loss: 0.534761\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053822; batch adversarial loss: 0.446785\n",
      "epoch 120; iter: 0; batch classifier loss: 0.122766; batch adversarial loss: 0.423882\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060227; batch adversarial loss: 0.440643\n",
      "epoch 122; iter: 0; batch classifier loss: 0.079467; batch adversarial loss: 0.479379\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059081; batch adversarial loss: 0.440060\n",
      "epoch 124; iter: 0; batch classifier loss: 0.106254; batch adversarial loss: 0.453005\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055715; batch adversarial loss: 0.511684\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051802; batch adversarial loss: 0.406815\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061960; batch adversarial loss: 0.422831\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071340; batch adversarial loss: 0.475399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060851; batch adversarial loss: 0.413415\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063582; batch adversarial loss: 0.437988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047516; batch adversarial loss: 0.394226\n",
      "epoch 132; iter: 0; batch classifier loss: 0.110126; batch adversarial loss: 0.400148\n",
      "epoch 133; iter: 0; batch classifier loss: 0.079270; batch adversarial loss: 0.433642\n",
      "epoch 134; iter: 0; batch classifier loss: 0.086892; batch adversarial loss: 0.489281\n",
      "epoch 135; iter: 0; batch classifier loss: 0.084186; batch adversarial loss: 0.485897\n",
      "epoch 136; iter: 0; batch classifier loss: 0.069343; batch adversarial loss: 0.439209\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059170; batch adversarial loss: 0.366115\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068512; batch adversarial loss: 0.456577\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.395491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042466; batch adversarial loss: 0.491121\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037905; batch adversarial loss: 0.408243\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060425; batch adversarial loss: 0.382326\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046771; batch adversarial loss: 0.360961\n",
      "epoch 144; iter: 0; batch classifier loss: 0.083137; batch adversarial loss: 0.482199\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076460; batch adversarial loss: 0.398955\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043737; batch adversarial loss: 0.472678\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058935; batch adversarial loss: 0.421891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045947; batch adversarial loss: 0.429001\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063085; batch adversarial loss: 0.388564\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.372423\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037394; batch adversarial loss: 0.387771\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.348123\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052890; batch adversarial loss: 0.425950\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031324; batch adversarial loss: 0.344353\n",
      "epoch 155; iter: 0; batch classifier loss: 0.067590; batch adversarial loss: 0.391065\n",
      "epoch 156; iter: 0; batch classifier loss: 0.054983; batch adversarial loss: 0.468762\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038343; batch adversarial loss: 0.422932\n",
      "epoch 158; iter: 0; batch classifier loss: 0.081366; batch adversarial loss: 0.371268\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031127; batch adversarial loss: 0.492018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049335; batch adversarial loss: 0.416245\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019969; batch adversarial loss: 0.329069\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050540; batch adversarial loss: 0.426492\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.423375\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033351; batch adversarial loss: 0.394555\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045709; batch adversarial loss: 0.496265\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018821; batch adversarial loss: 0.458703\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029166; batch adversarial loss: 0.355220\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034434; batch adversarial loss: 0.413557\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032523; batch adversarial loss: 0.454463\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044144; batch adversarial loss: 0.455323\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049340; batch adversarial loss: 0.416502\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034243; batch adversarial loss: 0.486714\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034370; batch adversarial loss: 0.405694\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031005; batch adversarial loss: 0.493210\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025971; batch adversarial loss: 0.383114\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021756; batch adversarial loss: 0.475543\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032672; batch adversarial loss: 0.424353\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035232; batch adversarial loss: 0.436113\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039670; batch adversarial loss: 0.408151\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018194; batch adversarial loss: 0.470780\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034652; batch adversarial loss: 0.478764\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015232; batch adversarial loss: 0.434722\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029482; batch adversarial loss: 0.394470\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023637; batch adversarial loss: 0.461466\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052640; batch adversarial loss: 0.418711\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036920; batch adversarial loss: 0.417685\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028673; batch adversarial loss: 0.406824\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023215; batch adversarial loss: 0.308793\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033445; batch adversarial loss: 0.478719\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021113; batch adversarial loss: 0.418120\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017140; batch adversarial loss: 0.404551\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013871; batch adversarial loss: 0.436858\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021588; batch adversarial loss: 0.404584\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.506615\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045240; batch adversarial loss: 0.423165\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034925; batch adversarial loss: 0.422535\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032898; batch adversarial loss: 0.448970\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015200; batch adversarial loss: 0.468852\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015558; batch adversarial loss: 0.464387\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705838; batch adversarial loss: 0.633627\n",
      "epoch 1; iter: 0; batch classifier loss: 0.410442; batch adversarial loss: 0.628138\n",
      "epoch 2; iter: 0; batch classifier loss: 0.520984; batch adversarial loss: 0.598558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344924; batch adversarial loss: 0.609795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.446217; batch adversarial loss: 0.601131\n",
      "epoch 5; iter: 0; batch classifier loss: 0.467872; batch adversarial loss: 0.562625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547159; batch adversarial loss: 0.584374\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493124; batch adversarial loss: 0.566167\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583641; batch adversarial loss: 0.538829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386458; batch adversarial loss: 0.543097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409268; batch adversarial loss: 0.551333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347658; batch adversarial loss: 0.499379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402532; batch adversarial loss: 0.494661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357249; batch adversarial loss: 0.550123\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280685; batch adversarial loss: 0.469164\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314892; batch adversarial loss: 0.485553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267183; batch adversarial loss: 0.474845\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346357; batch adversarial loss: 0.440145\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277787; batch adversarial loss: 0.559515\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342793; batch adversarial loss: 0.417664\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227998; batch adversarial loss: 0.489664\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275057; batch adversarial loss: 0.476230\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289497; batch adversarial loss: 0.481384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220664; batch adversarial loss: 0.456176\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207282; batch adversarial loss: 0.483581\n",
      "epoch 25; iter: 0; batch classifier loss: 0.208207; batch adversarial loss: 0.469228\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233131; batch adversarial loss: 0.465030\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235134; batch adversarial loss: 0.443671\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160409; batch adversarial loss: 0.553144\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231835; batch adversarial loss: 0.479860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.190949; batch adversarial loss: 0.460393\n",
      "epoch 31; iter: 0; batch classifier loss: 0.246776; batch adversarial loss: 0.353059\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218795; batch adversarial loss: 0.514164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217858; batch adversarial loss: 0.429914\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230912; batch adversarial loss: 0.419064\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210033; batch adversarial loss: 0.468118\n",
      "epoch 36; iter: 0; batch classifier loss: 0.166650; batch adversarial loss: 0.515304\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214138; batch adversarial loss: 0.484282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259407; batch adversarial loss: 0.495269\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176191; batch adversarial loss: 0.491224\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210359; batch adversarial loss: 0.440680\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236163; batch adversarial loss: 0.498408\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232226; batch adversarial loss: 0.485444\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179365; batch adversarial loss: 0.420559\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156318; batch adversarial loss: 0.425166\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183159; batch adversarial loss: 0.471545\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252052; batch adversarial loss: 0.397474\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179056; batch adversarial loss: 0.483997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223187; batch adversarial loss: 0.410964\n",
      "epoch 49; iter: 0; batch classifier loss: 0.262748; batch adversarial loss: 0.448391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125663; batch adversarial loss: 0.446566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106019; batch adversarial loss: 0.520522\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091480; batch adversarial loss: 0.370504\n",
      "epoch 53; iter: 0; batch classifier loss: 0.141845; batch adversarial loss: 0.357567\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119010; batch adversarial loss: 0.476074\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063535; batch adversarial loss: 0.381084\n",
      "epoch 56; iter: 0; batch classifier loss: 0.156443; batch adversarial loss: 0.423701\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167661; batch adversarial loss: 0.476223\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170050; batch adversarial loss: 0.434536\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072990; batch adversarial loss: 0.456940\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182069; batch adversarial loss: 0.560318\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079599; batch adversarial loss: 0.520795\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101620; batch adversarial loss: 0.585669\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097091; batch adversarial loss: 0.499677\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178235; batch adversarial loss: 0.459875\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079475; batch adversarial loss: 0.478934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.143658; batch adversarial loss: 0.420597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.141979; batch adversarial loss: 0.393073\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150543; batch adversarial loss: 0.319742\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065863; batch adversarial loss: 0.382203\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097526; batch adversarial loss: 0.419977\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103411; batch adversarial loss: 0.497899\n",
      "epoch 72; iter: 0; batch classifier loss: 0.127766; batch adversarial loss: 0.442983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130947; batch adversarial loss: 0.470805\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082173; batch adversarial loss: 0.423517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.127578; batch adversarial loss: 0.367954\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077108; batch adversarial loss: 0.527019\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047994; batch adversarial loss: 0.460627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109315; batch adversarial loss: 0.483732\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094921; batch adversarial loss: 0.512827\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070493; batch adversarial loss: 0.440997\n",
      "epoch 81; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.383072\n",
      "epoch 82; iter: 0; batch classifier loss: 0.152735; batch adversarial loss: 0.431878\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072043; batch adversarial loss: 0.439829\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075636; batch adversarial loss: 0.464120\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077223; batch adversarial loss: 0.489648\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087024; batch adversarial loss: 0.354494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072123; batch adversarial loss: 0.469868\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040766; batch adversarial loss: 0.520551\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048205; batch adversarial loss: 0.479473\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116882; batch adversarial loss: 0.526716\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039698; batch adversarial loss: 0.421379\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063905; batch adversarial loss: 0.378220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067359; batch adversarial loss: 0.364282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078540; batch adversarial loss: 0.355573\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085788; batch adversarial loss: 0.448979\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.478985\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090207; batch adversarial loss: 0.411286\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047632; batch adversarial loss: 0.504902\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081622; batch adversarial loss: 0.336620\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048165; batch adversarial loss: 0.445851\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.392956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.052763; batch adversarial loss: 0.417107\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045120; batch adversarial loss: 0.471969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076352; batch adversarial loss: 0.460320\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049597; batch adversarial loss: 0.394628\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045281; batch adversarial loss: 0.422253\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029911; batch adversarial loss: 0.466387\n",
      "epoch 108; iter: 0; batch classifier loss: 0.097223; batch adversarial loss: 0.443655\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028316; batch adversarial loss: 0.444360\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052810; batch adversarial loss: 0.353576\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049640; batch adversarial loss: 0.418805\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026780; batch adversarial loss: 0.491520\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038103; batch adversarial loss: 0.350863\n",
      "epoch 114; iter: 0; batch classifier loss: 0.100692; batch adversarial loss: 0.427981\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047927; batch adversarial loss: 0.408248\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059898; batch adversarial loss: 0.456706\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039583; batch adversarial loss: 0.378232\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039554; batch adversarial loss: 0.446126\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025113; batch adversarial loss: 0.406876\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036257; batch adversarial loss: 0.410819\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048284; batch adversarial loss: 0.461802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.092868; batch adversarial loss: 0.400861\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056323; batch adversarial loss: 0.439108\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014686; batch adversarial loss: 0.466853\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057859; batch adversarial loss: 0.466507\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040209; batch adversarial loss: 0.479655\n",
      "epoch 127; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.493958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040656; batch adversarial loss: 0.430776\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050384; batch adversarial loss: 0.415087\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028907; batch adversarial loss: 0.473150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039019; batch adversarial loss: 0.488558\n",
      "epoch 132; iter: 0; batch classifier loss: 0.008736; batch adversarial loss: 0.488562\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033816; batch adversarial loss: 0.312210\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029028; batch adversarial loss: 0.494919\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033910; batch adversarial loss: 0.441598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013559; batch adversarial loss: 0.516566\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049691; batch adversarial loss: 0.566430\n",
      "epoch 138; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.408768\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030329; batch adversarial loss: 0.358480\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017875; batch adversarial loss: 0.382519\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018193; batch adversarial loss: 0.562315\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029423; batch adversarial loss: 0.451352\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020196; batch adversarial loss: 0.387636\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057518; batch adversarial loss: 0.433401\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034149; batch adversarial loss: 0.417542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025927; batch adversarial loss: 0.396902\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007712; batch adversarial loss: 0.392224\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011190; batch adversarial loss: 0.498866\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035050; batch adversarial loss: 0.419378\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018612; batch adversarial loss: 0.441474\n",
      "epoch 151; iter: 0; batch classifier loss: 0.007673; batch adversarial loss: 0.577741\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016515; batch adversarial loss: 0.434405\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010176; batch adversarial loss: 0.353954\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014811; batch adversarial loss: 0.458779\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030808; batch adversarial loss: 0.372745\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010746; batch adversarial loss: 0.386858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014909; batch adversarial loss: 0.392623\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020386; batch adversarial loss: 0.435187\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.386320\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063210; batch adversarial loss: 0.503968\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038058; batch adversarial loss: 0.383060\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014514; batch adversarial loss: 0.443007\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007038; batch adversarial loss: 0.430852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024079; batch adversarial loss: 0.483319\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007906; batch adversarial loss: 0.335960\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029167; batch adversarial loss: 0.338815\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022541; batch adversarial loss: 0.479002\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013947; batch adversarial loss: 0.427192\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020811; batch adversarial loss: 0.381923\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008299; batch adversarial loss: 0.507573\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010461; batch adversarial loss: 0.431722\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007596; batch adversarial loss: 0.497342\n",
      "epoch 173; iter: 0; batch classifier loss: 0.004288; batch adversarial loss: 0.408926\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036197; batch adversarial loss: 0.519199\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037881; batch adversarial loss: 0.446860\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016525; batch adversarial loss: 0.362845\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008032; batch adversarial loss: 0.395544\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015861; batch adversarial loss: 0.477702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023542; batch adversarial loss: 0.502379\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020939; batch adversarial loss: 0.445990\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029446; batch adversarial loss: 0.374294\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007511; batch adversarial loss: 0.465040\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016238; batch adversarial loss: 0.402079\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012826; batch adversarial loss: 0.406042\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024722; batch adversarial loss: 0.355693\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008047; batch adversarial loss: 0.375259\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014548; batch adversarial loss: 0.401175\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012632; batch adversarial loss: 0.338083\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007313; batch adversarial loss: 0.361214\n",
      "epoch 190; iter: 0; batch classifier loss: 0.042578; batch adversarial loss: 0.460388\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004388; batch adversarial loss: 0.407692\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027582; batch adversarial loss: 0.515289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034784; batch adversarial loss: 0.518972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020460; batch adversarial loss: 0.536786\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012520; batch adversarial loss: 0.482018\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014782; batch adversarial loss: 0.400157\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013220; batch adversarial loss: 0.595988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.022793; batch adversarial loss: 0.355391\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030542; batch adversarial loss: 0.430607\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687690; batch adversarial loss: 0.619949\n",
      "epoch 1; iter: 0; batch classifier loss: 0.454424; batch adversarial loss: 0.649955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619992; batch adversarial loss: 0.645460\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423803; batch adversarial loss: 0.641304\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393367; batch adversarial loss: 0.624861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.445118; batch adversarial loss: 0.654552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.420744; batch adversarial loss: 0.585609\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389939; batch adversarial loss: 0.546982\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368161; batch adversarial loss: 0.560819\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417408; batch adversarial loss: 0.503770\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422296; batch adversarial loss: 0.503703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346569; batch adversarial loss: 0.521265\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289107; batch adversarial loss: 0.544159\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327649; batch adversarial loss: 0.508902\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325132; batch adversarial loss: 0.482561\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261800; batch adversarial loss: 0.497472\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332837; batch adversarial loss: 0.520975\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262880; batch adversarial loss: 0.544294\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259227; batch adversarial loss: 0.533735\n",
      "epoch 19; iter: 0; batch classifier loss: 0.367568; batch adversarial loss: 0.485587\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239293; batch adversarial loss: 0.490105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291644; batch adversarial loss: 0.434034\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236978; batch adversarial loss: 0.496732\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187671; batch adversarial loss: 0.456677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203960; batch adversarial loss: 0.575989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203923; batch adversarial loss: 0.494306\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255338; batch adversarial loss: 0.495784\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256774; batch adversarial loss: 0.450457\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227911; batch adversarial loss: 0.462960\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220580; batch adversarial loss: 0.463379\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264822; batch adversarial loss: 0.516086\n",
      "epoch 31; iter: 0; batch classifier loss: 0.213816; batch adversarial loss: 0.467973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257092; batch adversarial loss: 0.447579\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217745; batch adversarial loss: 0.476033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233608; batch adversarial loss: 0.456340\n",
      "epoch 35; iter: 0; batch classifier loss: 0.211932; batch adversarial loss: 0.563411\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216872; batch adversarial loss: 0.356108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.231243; batch adversarial loss: 0.406254\n",
      "epoch 38; iter: 0; batch classifier loss: 0.216137; batch adversarial loss: 0.507737\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268172; batch adversarial loss: 0.430331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.255989; batch adversarial loss: 0.457359\n",
      "epoch 41; iter: 0; batch classifier loss: 0.320569; batch adversarial loss: 0.565332\n",
      "epoch 42; iter: 0; batch classifier loss: 0.233429; batch adversarial loss: 0.447685\n",
      "epoch 43; iter: 0; batch classifier loss: 0.284431; batch adversarial loss: 0.435682\n",
      "epoch 44; iter: 0; batch classifier loss: 0.222947; batch adversarial loss: 0.495509\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194587; batch adversarial loss: 0.517929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317917; batch adversarial loss: 0.366871\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132373; batch adversarial loss: 0.470198\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109377; batch adversarial loss: 0.482813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.052271; batch adversarial loss: 0.501322\n",
      "epoch 50; iter: 0; batch classifier loss: 0.048169; batch adversarial loss: 0.439394\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081235; batch adversarial loss: 0.594329\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094516; batch adversarial loss: 0.445293\n",
      "epoch 53; iter: 0; batch classifier loss: 0.083638; batch adversarial loss: 0.411755\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073975; batch adversarial loss: 0.502132\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068094; batch adversarial loss: 0.434427\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082674; batch adversarial loss: 0.497702\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070539; batch adversarial loss: 0.479662\n",
      "epoch 58; iter: 0; batch classifier loss: 0.143828; batch adversarial loss: 0.397081\n",
      "epoch 59; iter: 0; batch classifier loss: 0.143926; batch adversarial loss: 0.552558\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092046; batch adversarial loss: 0.439796\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096214; batch adversarial loss: 0.477828\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085924; batch adversarial loss: 0.442090\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116932; batch adversarial loss: 0.476018\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099227; batch adversarial loss: 0.380459\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075190; batch adversarial loss: 0.449715\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061298; batch adversarial loss: 0.317505\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095719; batch adversarial loss: 0.472811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084528; batch adversarial loss: 0.476757\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102987; batch adversarial loss: 0.433336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082410; batch adversarial loss: 0.453914\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062968; batch adversarial loss: 0.440749\n",
      "epoch 72; iter: 0; batch classifier loss: 0.134114; batch adversarial loss: 0.483998\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091291; batch adversarial loss: 0.489099\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068336; batch adversarial loss: 0.467458\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074933; batch adversarial loss: 0.407201\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124294; batch adversarial loss: 0.414416\n",
      "epoch 77; iter: 0; batch classifier loss: 0.137362; batch adversarial loss: 0.444946\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083237; batch adversarial loss: 0.410134\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101099; batch adversarial loss: 0.421132\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089405; batch adversarial loss: 0.420031\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123524; batch adversarial loss: 0.411318\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116600; batch adversarial loss: 0.496999\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067603; batch adversarial loss: 0.465118\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077178; batch adversarial loss: 0.447173\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067311; batch adversarial loss: 0.442913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083209; batch adversarial loss: 0.519103\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053891; batch adversarial loss: 0.448495\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070207; batch adversarial loss: 0.385341\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084553; batch adversarial loss: 0.625255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090054; batch adversarial loss: 0.476442\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044684; batch adversarial loss: 0.377776\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051173; batch adversarial loss: 0.515129\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078273; batch adversarial loss: 0.523633\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044994; batch adversarial loss: 0.436693\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055408; batch adversarial loss: 0.419219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.065010; batch adversarial loss: 0.466298\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084818; batch adversarial loss: 0.520545\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060051; batch adversarial loss: 0.397617\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042595; batch adversarial loss: 0.439247\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066137; batch adversarial loss: 0.379324\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051718; batch adversarial loss: 0.399546\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046254; batch adversarial loss: 0.454464\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061018; batch adversarial loss: 0.476992\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051560; batch adversarial loss: 0.384187\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032305; batch adversarial loss: 0.444774\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071102; batch adversarial loss: 0.420066\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036636; batch adversarial loss: 0.453909\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030690; batch adversarial loss: 0.430590\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033508; batch adversarial loss: 0.438419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048341; batch adversarial loss: 0.492518\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045109; batch adversarial loss: 0.448061\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047468; batch adversarial loss: 0.508061\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029419; batch adversarial loss: 0.431054\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029078; batch adversarial loss: 0.431807\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033239; batch adversarial loss: 0.337080\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036497; batch adversarial loss: 0.384444\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036826; batch adversarial loss: 0.526654\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.464758\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045179; batch adversarial loss: 0.465218\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021637; batch adversarial loss: 0.565064\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016696; batch adversarial loss: 0.539210\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023672; batch adversarial loss: 0.414631\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039326; batch adversarial loss: 0.378913\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021769; batch adversarial loss: 0.361099\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015241; batch adversarial loss: 0.406264\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034578; batch adversarial loss: 0.462257\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016080; batch adversarial loss: 0.461245\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025458; batch adversarial loss: 0.344087\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017191; batch adversarial loss: 0.514634\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038483; batch adversarial loss: 0.334491\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017300; batch adversarial loss: 0.432779\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046787; batch adversarial loss: 0.447637\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030698; batch adversarial loss: 0.540106\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018024; batch adversarial loss: 0.417504\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029713; batch adversarial loss: 0.470002\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020802; batch adversarial loss: 0.458006\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016182; batch adversarial loss: 0.387174\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052145; batch adversarial loss: 0.426447\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015383; batch adversarial loss: 0.512419\n",
      "epoch 140; iter: 0; batch classifier loss: 0.010973; batch adversarial loss: 0.393424\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028619; batch adversarial loss: 0.392257\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029323; batch adversarial loss: 0.489549\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029745; batch adversarial loss: 0.433529\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020686; batch adversarial loss: 0.455579\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020502; batch adversarial loss: 0.440456\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023720; batch adversarial loss: 0.514755\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018300; batch adversarial loss: 0.438896\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.525792\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023379; batch adversarial loss: 0.419779\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043277; batch adversarial loss: 0.440617\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009430; batch adversarial loss: 0.501138\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027358; batch adversarial loss: 0.410325\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017780; batch adversarial loss: 0.427560\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016884; batch adversarial loss: 0.557818\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031693; batch adversarial loss: 0.422390\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039528; batch adversarial loss: 0.370845\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016820; batch adversarial loss: 0.429491\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007761; batch adversarial loss: 0.337754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011845; batch adversarial loss: 0.444416\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034268; batch adversarial loss: 0.351666\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014916; batch adversarial loss: 0.485925\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038109; batch adversarial loss: 0.450831\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.459225\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042809; batch adversarial loss: 0.449226\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016623; batch adversarial loss: 0.403479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017710; batch adversarial loss: 0.441011\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014506; batch adversarial loss: 0.543822\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023259; batch adversarial loss: 0.440121\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017447; batch adversarial loss: 0.511041\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016631; batch adversarial loss: 0.412191\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010428; batch adversarial loss: 0.509006\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013304; batch adversarial loss: 0.514620\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024667; batch adversarial loss: 0.467856\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.413519\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020283; batch adversarial loss: 0.462396\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016244; batch adversarial loss: 0.455494\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017455; batch adversarial loss: 0.552752\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026157; batch adversarial loss: 0.414466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016674; batch adversarial loss: 0.364266\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035606; batch adversarial loss: 0.417266\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007196; batch adversarial loss: 0.416061\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009582; batch adversarial loss: 0.495908\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023462; batch adversarial loss: 0.433583\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013246; batch adversarial loss: 0.438511\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025049; batch adversarial loss: 0.503210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009008; batch adversarial loss: 0.577997\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012212; batch adversarial loss: 0.436603\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019245; batch adversarial loss: 0.463525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037629; batch adversarial loss: 0.441164\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020576; batch adversarial loss: 0.500514\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009953; batch adversarial loss: 0.363909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.026670; batch adversarial loss: 0.453957\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012270; batch adversarial loss: 0.383595\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022852; batch adversarial loss: 0.538046\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016429; batch adversarial loss: 0.550442\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028864; batch adversarial loss: 0.430614\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017262; batch adversarial loss: 0.524876\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011250; batch adversarial loss: 0.543627\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013110; batch adversarial loss: 0.337588\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712514; batch adversarial loss: 0.796394\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629882; batch adversarial loss: 0.799126\n",
      "epoch 2; iter: 0; batch classifier loss: 0.706401; batch adversarial loss: 0.769343\n",
      "epoch 3; iter: 0; batch classifier loss: 0.682592; batch adversarial loss: 0.721760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.580753; batch adversarial loss: 0.653082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512840; batch adversarial loss: 0.646794\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358995; batch adversarial loss: 0.613806\n",
      "epoch 7; iter: 0; batch classifier loss: 0.331968; batch adversarial loss: 0.595337\n",
      "epoch 8; iter: 0; batch classifier loss: 0.357680; batch adversarial loss: 0.517803\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363949; batch adversarial loss: 0.547302\n",
      "epoch 10; iter: 0; batch classifier loss: 0.311361; batch adversarial loss: 0.542968\n",
      "epoch 11; iter: 0; batch classifier loss: 0.254166; batch adversarial loss: 0.494043\n",
      "epoch 12; iter: 0; batch classifier loss: 0.317845; batch adversarial loss: 0.554168\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220440; batch adversarial loss: 0.556235\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229306; batch adversarial loss: 0.473587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.241668; batch adversarial loss: 0.470118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266494; batch adversarial loss: 0.490788\n",
      "epoch 17; iter: 0; batch classifier loss: 0.206264; batch adversarial loss: 0.496461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227528; batch adversarial loss: 0.423826\n",
      "epoch 19; iter: 0; batch classifier loss: 0.166701; batch adversarial loss: 0.526166\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232035; batch adversarial loss: 0.409561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.142848; batch adversarial loss: 0.451123\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224401; batch adversarial loss: 0.523696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.192584; batch adversarial loss: 0.419563\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202592; batch adversarial loss: 0.451851\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138196; batch adversarial loss: 0.520421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.114106; batch adversarial loss: 0.501462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.115653; batch adversarial loss: 0.469589\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179467; batch adversarial loss: 0.481302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208401; batch adversarial loss: 0.521524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202235; batch adversarial loss: 0.425782\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123104; batch adversarial loss: 0.546012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162963; batch adversarial loss: 0.496082\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109116; batch adversarial loss: 0.452871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161310; batch adversarial loss: 0.475643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.097303; batch adversarial loss: 0.523935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163269; batch adversarial loss: 0.494536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122786; batch adversarial loss: 0.544433\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128211; batch adversarial loss: 0.469854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124987; batch adversarial loss: 0.510361\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123919; batch adversarial loss: 0.489479\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099602; batch adversarial loss: 0.514682\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136479; batch adversarial loss: 0.487368\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123060; batch adversarial loss: 0.474973\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123359; batch adversarial loss: 0.459482\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105784; batch adversarial loss: 0.537827\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082009; batch adversarial loss: 0.505647\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101453; batch adversarial loss: 0.352125\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117297; batch adversarial loss: 0.416410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096572; batch adversarial loss: 0.473162\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111242; batch adversarial loss: 0.539028\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097646; batch adversarial loss: 0.492682\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090382; batch adversarial loss: 0.430611\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119609; batch adversarial loss: 0.471558\n",
      "epoch 54; iter: 0; batch classifier loss: 0.137083; batch adversarial loss: 0.390780\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114569; batch adversarial loss: 0.526945\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075001; batch adversarial loss: 0.506137\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085204; batch adversarial loss: 0.430861\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087792; batch adversarial loss: 0.483783\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141340; batch adversarial loss: 0.403708\n",
      "epoch 60; iter: 0; batch classifier loss: 0.173055; batch adversarial loss: 0.462799\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108342; batch adversarial loss: 0.442082\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087536; batch adversarial loss: 0.457967\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085262; batch adversarial loss: 0.564587\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123860; batch adversarial loss: 0.506628\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055170; batch adversarial loss: 0.448402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068904; batch adversarial loss: 0.408765\n",
      "epoch 67; iter: 0; batch classifier loss: 0.155556; batch adversarial loss: 0.515736\n",
      "epoch 68; iter: 0; batch classifier loss: 0.063939; batch adversarial loss: 0.408236\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083848; batch adversarial loss: 0.422507\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125039; batch adversarial loss: 0.455582\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084819; batch adversarial loss: 0.530893\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097809; batch adversarial loss: 0.365567\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104131; batch adversarial loss: 0.561368\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070912; batch adversarial loss: 0.489924\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068540; batch adversarial loss: 0.418295\n",
      "epoch 76; iter: 0; batch classifier loss: 0.092824; batch adversarial loss: 0.450925\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093503; batch adversarial loss: 0.393023\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083075; batch adversarial loss: 0.502360\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079989; batch adversarial loss: 0.420403\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064224; batch adversarial loss: 0.497179\n",
      "epoch 81; iter: 0; batch classifier loss: 0.013507; batch adversarial loss: 0.537526\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089476; batch adversarial loss: 0.426646\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060075; batch adversarial loss: 0.480272\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061288; batch adversarial loss: 0.523747\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067034; batch adversarial loss: 0.488019\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047233; batch adversarial loss: 0.565885\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051505; batch adversarial loss: 0.490720\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056147; batch adversarial loss: 0.434389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.075755; batch adversarial loss: 0.388849\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068602; batch adversarial loss: 0.522765\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070174; batch adversarial loss: 0.488891\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082431; batch adversarial loss: 0.569555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044565; batch adversarial loss: 0.473915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062842; batch adversarial loss: 0.429530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072531; batch adversarial loss: 0.485133\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075065; batch adversarial loss: 0.520253\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065105; batch adversarial loss: 0.480892\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045422; batch adversarial loss: 0.486017\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041298; batch adversarial loss: 0.409323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057256; batch adversarial loss: 0.459800\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064165; batch adversarial loss: 0.374693\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028153; batch adversarial loss: 0.423703\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072388; batch adversarial loss: 0.435793\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089292; batch adversarial loss: 0.415483\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064969; batch adversarial loss: 0.509285\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069415; batch adversarial loss: 0.402266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069499; batch adversarial loss: 0.311189\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053798; batch adversarial loss: 0.545857\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022154; batch adversarial loss: 0.520045\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069631; batch adversarial loss: 0.490461\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059237; batch adversarial loss: 0.550610\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049197; batch adversarial loss: 0.397098\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077525; batch adversarial loss: 0.440239\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.503576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054384; batch adversarial loss: 0.386440\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057242; batch adversarial loss: 0.440062\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036946; batch adversarial loss: 0.480996\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028616; batch adversarial loss: 0.407291\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050030; batch adversarial loss: 0.599453\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030354; batch adversarial loss: 0.480576\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036613; batch adversarial loss: 0.398892\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046600; batch adversarial loss: 0.429339\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041643; batch adversarial loss: 0.505565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051843; batch adversarial loss: 0.400470\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039542; batch adversarial loss: 0.538301\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022373; batch adversarial loss: 0.476386\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045444; batch adversarial loss: 0.519589\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056985; batch adversarial loss: 0.470298\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051492; batch adversarial loss: 0.458293\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024275; batch adversarial loss: 0.511653\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034540; batch adversarial loss: 0.421124\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.412599\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029063; batch adversarial loss: 0.385153\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025988; batch adversarial loss: 0.414821\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034742; batch adversarial loss: 0.367908\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027401; batch adversarial loss: 0.414657\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053466; batch adversarial loss: 0.416781\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023476; batch adversarial loss: 0.446476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055305; batch adversarial loss: 0.513242\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050161; batch adversarial loss: 0.454089\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032544; batch adversarial loss: 0.379177\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013633; batch adversarial loss: 0.464006\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018247; batch adversarial loss: 0.578979\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017611; batch adversarial loss: 0.432701\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017338; batch adversarial loss: 0.452196\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036211; batch adversarial loss: 0.337507\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023476; batch adversarial loss: 0.498645\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030944; batch adversarial loss: 0.416747\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018196; batch adversarial loss: 0.428569\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022447; batch adversarial loss: 0.435525\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032580; batch adversarial loss: 0.480348\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.420739\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020019; batch adversarial loss: 0.431794\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029154; batch adversarial loss: 0.394196\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011764; batch adversarial loss: 0.436785\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036576; batch adversarial loss: 0.456027\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020710; batch adversarial loss: 0.368377\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042330; batch adversarial loss: 0.490723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020457; batch adversarial loss: 0.528668\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028669; batch adversarial loss: 0.491417\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020241; batch adversarial loss: 0.414052\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027581; batch adversarial loss: 0.409198\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009969; batch adversarial loss: 0.375377\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033080; batch adversarial loss: 0.540585\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010440; batch adversarial loss: 0.631564\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017265; batch adversarial loss: 0.511194\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014599; batch adversarial loss: 0.401473\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022201; batch adversarial loss: 0.490596\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038748; batch adversarial loss: 0.438823\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024933; batch adversarial loss: 0.408206\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016406; batch adversarial loss: 0.429769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029749; batch adversarial loss: 0.409780\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017551; batch adversarial loss: 0.484169\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036550; batch adversarial loss: 0.521216\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016378; batch adversarial loss: 0.465529\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011183; batch adversarial loss: 0.541656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017679; batch adversarial loss: 0.454546\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019009; batch adversarial loss: 0.434165\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026766; batch adversarial loss: 0.413414\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041128; batch adversarial loss: 0.446165\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018039; batch adversarial loss: 0.392685\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010498; batch adversarial loss: 0.479481\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005452; batch adversarial loss: 0.478334\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036126; batch adversarial loss: 0.416290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.017657; batch adversarial loss: 0.523315\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033338; batch adversarial loss: 0.536063\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023079; batch adversarial loss: 0.514978\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015086; batch adversarial loss: 0.404773\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041219; batch adversarial loss: 0.511472\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034335; batch adversarial loss: 0.522427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019223; batch adversarial loss: 0.478610\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037132; batch adversarial loss: 0.366454\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040621; batch adversarial loss: 0.488200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026849; batch adversarial loss: 0.404132\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019611; batch adversarial loss: 0.472004\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023391; batch adversarial loss: 0.458421\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012778; batch adversarial loss: 0.429712\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005929; batch adversarial loss: 0.408432\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045931; batch adversarial loss: 0.429944\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688673; batch adversarial loss: 0.727088\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486079; batch adversarial loss: 0.686928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.418755; batch adversarial loss: 0.657487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404226; batch adversarial loss: 0.613485\n",
      "epoch 4; iter: 0; batch classifier loss: 0.341824; batch adversarial loss: 0.571399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337343; batch adversarial loss: 0.558863\n",
      "epoch 6; iter: 0; batch classifier loss: 0.341469; batch adversarial loss: 0.533872\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328823; batch adversarial loss: 0.518876\n",
      "epoch 8; iter: 0; batch classifier loss: 0.254314; batch adversarial loss: 0.519761\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287222; batch adversarial loss: 0.489022\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243468; batch adversarial loss: 0.535717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256379; batch adversarial loss: 0.524493\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242210; batch adversarial loss: 0.553945\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209396; batch adversarial loss: 0.470133\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224294; batch adversarial loss: 0.464504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199374; batch adversarial loss: 0.465914\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221507; batch adversarial loss: 0.428507\n",
      "epoch 17; iter: 0; batch classifier loss: 0.133553; batch adversarial loss: 0.419949\n",
      "epoch 18; iter: 0; batch classifier loss: 0.139118; batch adversarial loss: 0.377108\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191120; batch adversarial loss: 0.405786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.126541; batch adversarial loss: 0.490311\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188208; batch adversarial loss: 0.412002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200096; batch adversarial loss: 0.420822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167072; batch adversarial loss: 0.372912\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164709; batch adversarial loss: 0.397512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185548; batch adversarial loss: 0.463828\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183273; batch adversarial loss: 0.425870\n",
      "epoch 27; iter: 0; batch classifier loss: 0.119155; batch adversarial loss: 0.479533\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135382; batch adversarial loss: 0.363535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125503; batch adversarial loss: 0.445742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.107679; batch adversarial loss: 0.414038\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163321; batch adversarial loss: 0.401044\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120377; batch adversarial loss: 0.496878\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126658; batch adversarial loss: 0.441399\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130914; batch adversarial loss: 0.482305\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137619; batch adversarial loss: 0.431282\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110178; batch adversarial loss: 0.419760\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108460; batch adversarial loss: 0.476011\n",
      "epoch 38; iter: 0; batch classifier loss: 0.081967; batch adversarial loss: 0.442824\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088933; batch adversarial loss: 0.434372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140949; batch adversarial loss: 0.479085\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149555; batch adversarial loss: 0.441555\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108274; batch adversarial loss: 0.493725\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121630; batch adversarial loss: 0.368252\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085683; batch adversarial loss: 0.483914\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084971; batch adversarial loss: 0.423740\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088500; batch adversarial loss: 0.449103\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079161; batch adversarial loss: 0.416785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078064; batch adversarial loss: 0.407228\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071226; batch adversarial loss: 0.458883\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098691; batch adversarial loss: 0.396843\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090032; batch adversarial loss: 0.478118\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112165; batch adversarial loss: 0.378710\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093220; batch adversarial loss: 0.461765\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067579; batch adversarial loss: 0.453275\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102406; batch adversarial loss: 0.494325\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108909; batch adversarial loss: 0.535858\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072348; batch adversarial loss: 0.477950\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097302; batch adversarial loss: 0.340654\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064084; batch adversarial loss: 0.392736\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068808; batch adversarial loss: 0.401783\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106102; batch adversarial loss: 0.449036\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090544; batch adversarial loss: 0.531242\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089984; batch adversarial loss: 0.416937\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115813; batch adversarial loss: 0.457895\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063301; batch adversarial loss: 0.525962\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077975; batch adversarial loss: 0.438537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059829; batch adversarial loss: 0.419778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079431; batch adversarial loss: 0.412678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.040066; batch adversarial loss: 0.423740\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094492; batch adversarial loss: 0.402266\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067172; batch adversarial loss: 0.476252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059128; batch adversarial loss: 0.460301\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063745; batch adversarial loss: 0.466795\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079005; batch adversarial loss: 0.346905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057155; batch adversarial loss: 0.471965\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062516; batch adversarial loss: 0.391188\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050284; batch adversarial loss: 0.508819\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066677; batch adversarial loss: 0.389485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092764; batch adversarial loss: 0.411296\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057738; batch adversarial loss: 0.453969\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060648; batch adversarial loss: 0.413519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.062511; batch adversarial loss: 0.527695\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080628; batch adversarial loss: 0.482380\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062462; batch adversarial loss: 0.452525\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061837; batch adversarial loss: 0.454825\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061042; batch adversarial loss: 0.446223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066195; batch adversarial loss: 0.355569\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061466; batch adversarial loss: 0.465779\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054585; batch adversarial loss: 0.411191\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071807; batch adversarial loss: 0.427377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055220; batch adversarial loss: 0.490761\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049889; batch adversarial loss: 0.446575\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067066; batch adversarial loss: 0.427997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057262; batch adversarial loss: 0.501003\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044194; batch adversarial loss: 0.524050\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086754; batch adversarial loss: 0.418002\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076418; batch adversarial loss: 0.419656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050962; batch adversarial loss: 0.473281\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057145; batch adversarial loss: 0.422728\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036699; batch adversarial loss: 0.532461\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042125; batch adversarial loss: 0.391942\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068627; batch adversarial loss: 0.481629\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050677; batch adversarial loss: 0.428794\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049350; batch adversarial loss: 0.479894\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034836; batch adversarial loss: 0.354187\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041368; batch adversarial loss: 0.335809\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056461; batch adversarial loss: 0.496097\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040777; batch adversarial loss: 0.482199\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043389; batch adversarial loss: 0.441727\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015389; batch adversarial loss: 0.483785\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019571; batch adversarial loss: 0.486605\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039952; batch adversarial loss: 0.444951\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034955; batch adversarial loss: 0.476409\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048566; batch adversarial loss: 0.504276\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020446; batch adversarial loss: 0.513146\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060705; batch adversarial loss: 0.507120\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022552; batch adversarial loss: 0.434786\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052951; batch adversarial loss: 0.459180\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017972; batch adversarial loss: 0.490694\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029491; batch adversarial loss: 0.450796\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048879; batch adversarial loss: 0.454245\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036676; batch adversarial loss: 0.451650\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021355; batch adversarial loss: 0.529760\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019720; batch adversarial loss: 0.441712\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032958; batch adversarial loss: 0.608172\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032158; batch adversarial loss: 0.441843\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032157; batch adversarial loss: 0.424856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070264; batch adversarial loss: 0.438254\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.542599\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028679; batch adversarial loss: 0.505226\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050691; batch adversarial loss: 0.504601\n",
      "epoch 132; iter: 0; batch classifier loss: 0.127808; batch adversarial loss: 0.605999\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078645; batch adversarial loss: 0.591340\n",
      "epoch 134; iter: 0; batch classifier loss: 0.118280; batch adversarial loss: 0.594017\n",
      "epoch 135; iter: 0; batch classifier loss: 0.104387; batch adversarial loss: 0.563994\n",
      "epoch 136; iter: 0; batch classifier loss: 0.130210; batch adversarial loss: 0.675365\n",
      "epoch 137; iter: 0; batch classifier loss: 0.140477; batch adversarial loss: 0.660375\n",
      "epoch 138; iter: 0; batch classifier loss: 0.124971; batch adversarial loss: 0.578439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.210411; batch adversarial loss: 0.804467\n",
      "epoch 140; iter: 0; batch classifier loss: 0.145085; batch adversarial loss: 0.679061\n",
      "epoch 141; iter: 0; batch classifier loss: 0.099033; batch adversarial loss: 0.587441\n",
      "epoch 142; iter: 0; batch classifier loss: 0.176903; batch adversarial loss: 0.770693\n",
      "epoch 143; iter: 0; batch classifier loss: 0.120626; batch adversarial loss: 0.499238\n",
      "epoch 144; iter: 0; batch classifier loss: 0.183249; batch adversarial loss: 0.766251\n",
      "epoch 145; iter: 0; batch classifier loss: 0.112305; batch adversarial loss: 0.583879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.131073; batch adversarial loss: 0.551013\n",
      "epoch 147; iter: 0; batch classifier loss: 0.163439; batch adversarial loss: 0.576748\n",
      "epoch 148; iter: 0; batch classifier loss: 0.133923; batch adversarial loss: 0.506857\n",
      "epoch 149; iter: 0; batch classifier loss: 0.224268; batch adversarial loss: 0.699249\n",
      "epoch 150; iter: 0; batch classifier loss: 0.206860; batch adversarial loss: 0.751410\n",
      "epoch 151; iter: 0; batch classifier loss: 0.132478; batch adversarial loss: 0.527129\n",
      "epoch 152; iter: 0; batch classifier loss: 0.089856; batch adversarial loss: 0.446205\n",
      "epoch 153; iter: 0; batch classifier loss: 0.103702; batch adversarial loss: 0.533762\n",
      "epoch 154; iter: 0; batch classifier loss: 0.154965; batch adversarial loss: 0.555500\n",
      "epoch 155; iter: 0; batch classifier loss: 0.145854; batch adversarial loss: 0.557050\n",
      "epoch 156; iter: 0; batch classifier loss: 0.205136; batch adversarial loss: 0.694299\n",
      "epoch 157; iter: 0; batch classifier loss: 0.142023; batch adversarial loss: 0.533727\n",
      "epoch 158; iter: 0; batch classifier loss: 0.122329; batch adversarial loss: 0.514572\n",
      "epoch 159; iter: 0; batch classifier loss: 0.206286; batch adversarial loss: 0.588829\n",
      "epoch 160; iter: 0; batch classifier loss: 0.129734; batch adversarial loss: 0.577336\n",
      "epoch 161; iter: 0; batch classifier loss: 0.176483; batch adversarial loss: 0.568938\n",
      "epoch 162; iter: 0; batch classifier loss: 0.194724; batch adversarial loss: 0.596355\n",
      "epoch 163; iter: 0; batch classifier loss: 0.119093; batch adversarial loss: 0.525471\n",
      "epoch 164; iter: 0; batch classifier loss: 0.150166; batch adversarial loss: 0.467045\n",
      "epoch 165; iter: 0; batch classifier loss: 0.106350; batch adversarial loss: 0.436685\n",
      "epoch 166; iter: 0; batch classifier loss: 0.140731; batch adversarial loss: 0.421934\n",
      "epoch 167; iter: 0; batch classifier loss: 0.169406; batch adversarial loss: 0.555985\n",
      "epoch 168; iter: 0; batch classifier loss: 0.090290; batch adversarial loss: 0.460648\n",
      "epoch 169; iter: 0; batch classifier loss: 0.128033; batch adversarial loss: 0.561022\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195671; batch adversarial loss: 0.680792\n",
      "epoch 171; iter: 0; batch classifier loss: 0.129389; batch adversarial loss: 0.529590\n",
      "epoch 172; iter: 0; batch classifier loss: 0.099573; batch adversarial loss: 0.496011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.128298; batch adversarial loss: 0.545049\n",
      "epoch 174; iter: 0; batch classifier loss: 0.067747; batch adversarial loss: 0.383987\n",
      "epoch 175; iter: 0; batch classifier loss: 0.085174; batch adversarial loss: 0.389068\n",
      "epoch 176; iter: 0; batch classifier loss: 0.170657; batch adversarial loss: 0.507779\n",
      "epoch 177; iter: 0; batch classifier loss: 0.099123; batch adversarial loss: 0.411519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.081990; batch adversarial loss: 0.454720\n",
      "epoch 179; iter: 0; batch classifier loss: 0.052900; batch adversarial loss: 0.514093\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034516; batch adversarial loss: 0.566663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047120; batch adversarial loss: 0.457312\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045114; batch adversarial loss: 0.404325\n",
      "epoch 183; iter: 0; batch classifier loss: 0.061913; batch adversarial loss: 0.503052\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029301; batch adversarial loss: 0.463493\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.487717\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052353; batch adversarial loss: 0.487768\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022629; batch adversarial loss: 0.530238\n",
      "epoch 188; iter: 0; batch classifier loss: 0.063360; batch adversarial loss: 0.505466\n",
      "epoch 189; iter: 0; batch classifier loss: 0.082776; batch adversarial loss: 0.429654\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037268; batch adversarial loss: 0.525031\n",
      "epoch 191; iter: 0; batch classifier loss: 0.065340; batch adversarial loss: 0.481119\n",
      "epoch 192; iter: 0; batch classifier loss: 0.093142; batch adversarial loss: 0.479721\n",
      "epoch 193; iter: 0; batch classifier loss: 0.089603; batch adversarial loss: 0.518745\n",
      "epoch 194; iter: 0; batch classifier loss: 0.053227; batch adversarial loss: 0.463267\n",
      "epoch 195; iter: 0; batch classifier loss: 0.064205; batch adversarial loss: 0.454374\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.525177\n",
      "epoch 197; iter: 0; batch classifier loss: 0.145081; batch adversarial loss: 0.466124\n",
      "epoch 198; iter: 0; batch classifier loss: 0.070861; batch adversarial loss: 0.401203\n",
      "epoch 199; iter: 0; batch classifier loss: 0.071957; batch adversarial loss: 0.450788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675955; batch adversarial loss: 0.558910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.333073; batch adversarial loss: 0.553516\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446385; batch adversarial loss: 0.570611\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397502; batch adversarial loss: 0.625090\n",
      "epoch 4; iter: 0; batch classifier loss: 0.417918; batch adversarial loss: 0.633447\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338943; batch adversarial loss: 0.570325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315728; batch adversarial loss: 0.560820\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352462; batch adversarial loss: 0.585809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355853; batch adversarial loss: 0.463817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371264; batch adversarial loss: 0.535954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408562; batch adversarial loss: 0.548214\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498001; batch adversarial loss: 0.525471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466657; batch adversarial loss: 0.654642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.651145; batch adversarial loss: 0.511627\n",
      "epoch 14; iter: 0; batch classifier loss: 0.426367; batch adversarial loss: 0.532052\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396697; batch adversarial loss: 0.448160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276327; batch adversarial loss: 0.409967\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172023; batch adversarial loss: 0.458693\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262070; batch adversarial loss: 0.480539\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236648; batch adversarial loss: 0.495301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192272; batch adversarial loss: 0.460683\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211008; batch adversarial loss: 0.439860\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197906; batch adversarial loss: 0.476187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207386; batch adversarial loss: 0.380024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218931; batch adversarial loss: 0.427168\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154283; batch adversarial loss: 0.536566\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176135; batch adversarial loss: 0.458146\n",
      "epoch 27; iter: 0; batch classifier loss: 0.227803; batch adversarial loss: 0.421123\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210072; batch adversarial loss: 0.475742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140264; batch adversarial loss: 0.511547\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201632; batch adversarial loss: 0.452033\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179882; batch adversarial loss: 0.460124\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230002; batch adversarial loss: 0.427708\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164281; batch adversarial loss: 0.480141\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180338; batch adversarial loss: 0.459383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181035; batch adversarial loss: 0.372860\n",
      "epoch 36; iter: 0; batch classifier loss: 0.184312; batch adversarial loss: 0.419347\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183315; batch adversarial loss: 0.450509\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218362; batch adversarial loss: 0.433156\n",
      "epoch 39; iter: 0; batch classifier loss: 0.219388; batch adversarial loss: 0.579520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.190155; batch adversarial loss: 0.440877\n",
      "epoch 41; iter: 0; batch classifier loss: 0.212243; batch adversarial loss: 0.423838\n",
      "epoch 42; iter: 0; batch classifier loss: 0.212395; batch adversarial loss: 0.450508\n",
      "epoch 43; iter: 0; batch classifier loss: 0.217804; batch adversarial loss: 0.468510\n",
      "epoch 44; iter: 0; batch classifier loss: 0.181815; batch adversarial loss: 0.481285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.273995; batch adversarial loss: 0.412519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252209; batch adversarial loss: 0.420464\n",
      "epoch 47; iter: 0; batch classifier loss: 0.176916; batch adversarial loss: 0.492308\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182517; batch adversarial loss: 0.385356\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285390; batch adversarial loss: 0.443206\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240639; batch adversarial loss: 0.370963\n",
      "epoch 51; iter: 0; batch classifier loss: 0.202760; batch adversarial loss: 0.380067\n",
      "epoch 52; iter: 0; batch classifier loss: 0.248418; batch adversarial loss: 0.360744\n",
      "epoch 53; iter: 0; batch classifier loss: 0.225509; batch adversarial loss: 0.431456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.194926; batch adversarial loss: 0.446983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.229629; batch adversarial loss: 0.446381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.227637; batch adversarial loss: 0.523320\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211406; batch adversarial loss: 0.509590\n",
      "epoch 58; iter: 0; batch classifier loss: 0.246595; batch adversarial loss: 0.421114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.222894; batch adversarial loss: 0.459609\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182822; batch adversarial loss: 0.407367\n",
      "epoch 61; iter: 0; batch classifier loss: 0.144099; batch adversarial loss: 0.484000\n",
      "epoch 62; iter: 0; batch classifier loss: 0.212136; batch adversarial loss: 0.471148\n",
      "epoch 63; iter: 0; batch classifier loss: 0.228675; batch adversarial loss: 0.433810\n",
      "epoch 64; iter: 0; batch classifier loss: 0.142979; batch adversarial loss: 0.420184\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168351; batch adversarial loss: 0.435052\n",
      "epoch 66; iter: 0; batch classifier loss: 0.225652; batch adversarial loss: 0.432836\n",
      "epoch 67; iter: 0; batch classifier loss: 0.163212; batch adversarial loss: 0.369120\n",
      "epoch 68; iter: 0; batch classifier loss: 0.183615; batch adversarial loss: 0.561291\n",
      "epoch 69; iter: 0; batch classifier loss: 0.274541; batch adversarial loss: 0.471735\n",
      "epoch 70; iter: 0; batch classifier loss: 0.177798; batch adversarial loss: 0.521914\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089595; batch adversarial loss: 0.522990\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119934; batch adversarial loss: 0.511454\n",
      "epoch 73; iter: 0; batch classifier loss: 0.228871; batch adversarial loss: 0.407791\n",
      "epoch 74; iter: 0; batch classifier loss: 0.267682; batch adversarial loss: 0.380749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.217727; batch adversarial loss: 0.435475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.208237; batch adversarial loss: 0.561005\n",
      "epoch 77; iter: 0; batch classifier loss: 0.213857; batch adversarial loss: 0.381750\n",
      "epoch 78; iter: 0; batch classifier loss: 0.212775; batch adversarial loss: 0.409064\n",
      "epoch 79; iter: 0; batch classifier loss: 0.193857; batch adversarial loss: 0.369081\n",
      "epoch 80; iter: 0; batch classifier loss: 0.225009; batch adversarial loss: 0.459614\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193813; batch adversarial loss: 0.472068\n",
      "epoch 82; iter: 0; batch classifier loss: 0.212135; batch adversarial loss: 0.471852\n",
      "epoch 83; iter: 0; batch classifier loss: 0.218796; batch adversarial loss: 0.407539\n",
      "epoch 84; iter: 0; batch classifier loss: 0.141919; batch adversarial loss: 0.369318\n",
      "epoch 85; iter: 0; batch classifier loss: 0.196848; batch adversarial loss: 0.446372\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206975; batch adversarial loss: 0.395784\n",
      "epoch 87; iter: 0; batch classifier loss: 0.160329; batch adversarial loss: 0.395779\n",
      "epoch 88; iter: 0; batch classifier loss: 0.250302; batch adversarial loss: 0.446527\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087351; batch adversarial loss: 0.369192\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084902; batch adversarial loss: 0.420301\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064508; batch adversarial loss: 0.546371\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066689; batch adversarial loss: 0.496043\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052450; batch adversarial loss: 0.408959\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049305; batch adversarial loss: 0.404693\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065512; batch adversarial loss: 0.384239\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053841; batch adversarial loss: 0.414397\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073953; batch adversarial loss: 0.383424\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069552; batch adversarial loss: 0.420105\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076724; batch adversarial loss: 0.455701\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064837; batch adversarial loss: 0.389369\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073033; batch adversarial loss: 0.439422\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.419963\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057445; batch adversarial loss: 0.467563\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070278; batch adversarial loss: 0.391061\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033407; batch adversarial loss: 0.401555\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069759; batch adversarial loss: 0.395040\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059177; batch adversarial loss: 0.435093\n",
      "epoch 108; iter: 0; batch classifier loss: 0.089115; batch adversarial loss: 0.458677\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063513; batch adversarial loss: 0.392585\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049990; batch adversarial loss: 0.532637\n",
      "epoch 111; iter: 0; batch classifier loss: 0.088331; batch adversarial loss: 0.410753\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092618; batch adversarial loss: 0.448861\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055565; batch adversarial loss: 0.455049\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072855; batch adversarial loss: 0.298975\n",
      "epoch 115; iter: 0; batch classifier loss: 0.082094; batch adversarial loss: 0.435130\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056966; batch adversarial loss: 0.428569\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038131; batch adversarial loss: 0.397037\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047349; batch adversarial loss: 0.359854\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023913; batch adversarial loss: 0.470184\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045854; batch adversarial loss: 0.477807\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041903; batch adversarial loss: 0.338602\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069585; batch adversarial loss: 0.443122\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037435; batch adversarial loss: 0.448801\n",
      "epoch 124; iter: 0; batch classifier loss: 0.107741; batch adversarial loss: 0.476404\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042321; batch adversarial loss: 0.545405\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058131; batch adversarial loss: 0.417442\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036957; batch adversarial loss: 0.390810\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053062; batch adversarial loss: 0.408621\n",
      "epoch 129; iter: 0; batch classifier loss: 0.080682; batch adversarial loss: 0.460852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046293; batch adversarial loss: 0.367601\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059995; batch adversarial loss: 0.327085\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061586; batch adversarial loss: 0.477813\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042430; batch adversarial loss: 0.420264\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036595; batch adversarial loss: 0.507927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053106; batch adversarial loss: 0.521358\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051950; batch adversarial loss: 0.434977\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038410; batch adversarial loss: 0.392502\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044377; batch adversarial loss: 0.476382\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051758; batch adversarial loss: 0.377604\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062396; batch adversarial loss: 0.407002\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050187; batch adversarial loss: 0.454235\n",
      "epoch 142; iter: 0; batch classifier loss: 0.063393; batch adversarial loss: 0.448857\n",
      "epoch 143; iter: 0; batch classifier loss: 0.074569; batch adversarial loss: 0.429139\n",
      "epoch 144; iter: 0; batch classifier loss: 0.063346; batch adversarial loss: 0.454337\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057187; batch adversarial loss: 0.411614\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061262; batch adversarial loss: 0.366987\n",
      "epoch 147; iter: 0; batch classifier loss: 0.056348; batch adversarial loss: 0.417570\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044255; batch adversarial loss: 0.370948\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039622; batch adversarial loss: 0.470603\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051800; batch adversarial loss: 0.423314\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044391; batch adversarial loss: 0.330747\n",
      "epoch 152; iter: 0; batch classifier loss: 0.085048; batch adversarial loss: 0.382696\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047814; batch adversarial loss: 0.409844\n",
      "epoch 154; iter: 0; batch classifier loss: 0.082508; batch adversarial loss: 0.420931\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062796; batch adversarial loss: 0.449878\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039087; batch adversarial loss: 0.403790\n",
      "epoch 157; iter: 0; batch classifier loss: 0.063551; batch adversarial loss: 0.501009\n",
      "epoch 158; iter: 0; batch classifier loss: 0.073194; batch adversarial loss: 0.483120\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052800; batch adversarial loss: 0.582363\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046521; batch adversarial loss: 0.400868\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042073; batch adversarial loss: 0.352412\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034344; batch adversarial loss: 0.369132\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057872; batch adversarial loss: 0.387404\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030269; batch adversarial loss: 0.391382\n",
      "epoch 165; iter: 0; batch classifier loss: 0.081815; batch adversarial loss: 0.346088\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068065; batch adversarial loss: 0.442595\n",
      "epoch 167; iter: 0; batch classifier loss: 0.063912; batch adversarial loss: 0.402584\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069277; batch adversarial loss: 0.422275\n",
      "epoch 169; iter: 0; batch classifier loss: 0.089391; batch adversarial loss: 0.396296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020163; batch adversarial loss: 0.313788\n",
      "epoch 171; iter: 0; batch classifier loss: 0.084536; batch adversarial loss: 0.434718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.051044; batch adversarial loss: 0.505303\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037368; batch adversarial loss: 0.442223\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048419; batch adversarial loss: 0.401847\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052134; batch adversarial loss: 0.358222\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047520; batch adversarial loss: 0.376995\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042835; batch adversarial loss: 0.344114\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042461; batch adversarial loss: 0.393466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041195; batch adversarial loss: 0.485678\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041054; batch adversarial loss: 0.458264\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040080; batch adversarial loss: 0.350172\n",
      "epoch 182; iter: 0; batch classifier loss: 0.048205; batch adversarial loss: 0.454503\n",
      "epoch 183; iter: 0; batch classifier loss: 0.049415; batch adversarial loss: 0.379172\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056171; batch adversarial loss: 0.298856\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046975; batch adversarial loss: 0.430510\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028759; batch adversarial loss: 0.341892\n",
      "epoch 187; iter: 0; batch classifier loss: 0.056072; batch adversarial loss: 0.452607\n",
      "epoch 188; iter: 0; batch classifier loss: 0.057749; batch adversarial loss: 0.415836\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033414; batch adversarial loss: 0.395429\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040655; batch adversarial loss: 0.391118\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028964; batch adversarial loss: 0.408192\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023509; batch adversarial loss: 0.388484\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038866; batch adversarial loss: 0.461631\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038731; batch adversarial loss: 0.456716\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030991; batch adversarial loss: 0.377330\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051474; batch adversarial loss: 0.411306\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045584; batch adversarial loss: 0.446475\n",
      "epoch 198; iter: 0; batch classifier loss: 0.046812; batch adversarial loss: 0.379469\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025121; batch adversarial loss: 0.302132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720027; batch adversarial loss: 0.902579\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424546; batch adversarial loss: 0.875921\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382536; batch adversarial loss: 0.819423\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388799; batch adversarial loss: 0.746245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.297918; batch adversarial loss: 0.751248\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350745; batch adversarial loss: 0.672826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390376; batch adversarial loss: 0.619205\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293389; batch adversarial loss: 0.627153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.272807; batch adversarial loss: 0.616571\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300386; batch adversarial loss: 0.596935\n",
      "epoch 10; iter: 0; batch classifier loss: 0.275121; batch adversarial loss: 0.576215\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297972; batch adversarial loss: 0.541585\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266990; batch adversarial loss: 0.554106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276909; batch adversarial loss: 0.501566\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263835; batch adversarial loss: 0.489175\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270048; batch adversarial loss: 0.466561\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222679; batch adversarial loss: 0.486429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217961; batch adversarial loss: 0.410902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248899; batch adversarial loss: 0.454802\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285574; batch adversarial loss: 0.443814\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255002; batch adversarial loss: 0.428304\n",
      "epoch 21; iter: 0; batch classifier loss: 0.237032; batch adversarial loss: 0.421047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.270094; batch adversarial loss: 0.423998\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279752; batch adversarial loss: 0.340205\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243002; batch adversarial loss: 0.455190\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205971; batch adversarial loss: 0.378705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233371; batch adversarial loss: 0.427352\n",
      "epoch 27; iter: 0; batch classifier loss: 0.228116; batch adversarial loss: 0.400852\n",
      "epoch 28; iter: 0; batch classifier loss: 0.281984; batch adversarial loss: 0.431637\n",
      "epoch 29; iter: 0; batch classifier loss: 0.214814; batch adversarial loss: 0.414138\n",
      "epoch 30; iter: 0; batch classifier loss: 0.194701; batch adversarial loss: 0.375141\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171929; batch adversarial loss: 0.374001\n",
      "epoch 32; iter: 0; batch classifier loss: 0.170927; batch adversarial loss: 0.393058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153958; batch adversarial loss: 0.293579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183630; batch adversarial loss: 0.438101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.172250; batch adversarial loss: 0.348841\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139372; batch adversarial loss: 0.454298\n",
      "epoch 37; iter: 0; batch classifier loss: 0.173109; batch adversarial loss: 0.432420\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157348; batch adversarial loss: 0.494484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113198; batch adversarial loss: 0.393865\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145775; batch adversarial loss: 0.394822\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122401; batch adversarial loss: 0.332095\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089578; batch adversarial loss: 0.421548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135750; batch adversarial loss: 0.463134\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122535; batch adversarial loss: 0.468733\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139649; batch adversarial loss: 0.425615\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090615; batch adversarial loss: 0.385440\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110077; batch adversarial loss: 0.375220\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092466; batch adversarial loss: 0.504648\n",
      "epoch 49; iter: 0; batch classifier loss: 0.117787; batch adversarial loss: 0.437409\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097152; batch adversarial loss: 0.504678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122372; batch adversarial loss: 0.457329\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122853; batch adversarial loss: 0.438703\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082223; batch adversarial loss: 0.379096\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108876; batch adversarial loss: 0.433653\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091787; batch adversarial loss: 0.362607\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085053; batch adversarial loss: 0.443308\n",
      "epoch 57; iter: 0; batch classifier loss: 0.060153; batch adversarial loss: 0.474138\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072735; batch adversarial loss: 0.412777\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116844; batch adversarial loss: 0.386962\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059925; batch adversarial loss: 0.335839\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093424; batch adversarial loss: 0.479638\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106531; batch adversarial loss: 0.382743\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093046; batch adversarial loss: 0.414906\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060014; batch adversarial loss: 0.413913\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075092; batch adversarial loss: 0.417748\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071588; batch adversarial loss: 0.431513\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080411; batch adversarial loss: 0.375319\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054231; batch adversarial loss: 0.455064\n",
      "epoch 69; iter: 0; batch classifier loss: 0.080143; batch adversarial loss: 0.407336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.093664; batch adversarial loss: 0.473232\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055414; batch adversarial loss: 0.466054\n",
      "epoch 72; iter: 0; batch classifier loss: 0.075888; batch adversarial loss: 0.438407\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065287; batch adversarial loss: 0.357571\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087289; batch adversarial loss: 0.438053\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094982; batch adversarial loss: 0.349557\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062060; batch adversarial loss: 0.420449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102142; batch adversarial loss: 0.378962\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043329; batch adversarial loss: 0.360821\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054565; batch adversarial loss: 0.426628\n",
      "epoch 80; iter: 0; batch classifier loss: 0.041259; batch adversarial loss: 0.382706\n",
      "epoch 81; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.356341\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071804; batch adversarial loss: 0.374575\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085688; batch adversarial loss: 0.349035\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045255; batch adversarial loss: 0.387752\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041086; batch adversarial loss: 0.350368\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057266; batch adversarial loss: 0.477872\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088321; batch adversarial loss: 0.405633\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042964; batch adversarial loss: 0.463869\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059921; batch adversarial loss: 0.436993\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057287; batch adversarial loss: 0.292027\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062515; batch adversarial loss: 0.378823\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057871; batch adversarial loss: 0.347023\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064055; batch adversarial loss: 0.373077\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043816; batch adversarial loss: 0.403782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056119; batch adversarial loss: 0.425654\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077451; batch adversarial loss: 0.417404\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060195; batch adversarial loss: 0.366618\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048940; batch adversarial loss: 0.447533\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057608; batch adversarial loss: 0.374908\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049445; batch adversarial loss: 0.451260\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063036; batch adversarial loss: 0.404737\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061400; batch adversarial loss: 0.415654\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063419; batch adversarial loss: 0.439635\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051261; batch adversarial loss: 0.399904\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052937; batch adversarial loss: 0.467309\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053280; batch adversarial loss: 0.448036\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027179; batch adversarial loss: 0.424389\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044423; batch adversarial loss: 0.351020\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039087; batch adversarial loss: 0.361050\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059550; batch adversarial loss: 0.380736\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045848; batch adversarial loss: 0.384729\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050482; batch adversarial loss: 0.355155\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028931; batch adversarial loss: 0.375729\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042234; batch adversarial loss: 0.397188\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036153; batch adversarial loss: 0.387993\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044917; batch adversarial loss: 0.376420\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056174; batch adversarial loss: 0.461445\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026541; batch adversarial loss: 0.418735\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027685; batch adversarial loss: 0.537782\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051264; batch adversarial loss: 0.477597\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.517697\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033307; batch adversarial loss: 0.458841\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017215; batch adversarial loss: 0.388915\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026192; batch adversarial loss: 0.462064\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027770; batch adversarial loss: 0.533999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033416; batch adversarial loss: 0.435238\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058472; batch adversarial loss: 0.405365\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054314; batch adversarial loss: 0.360388\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019311; batch adversarial loss: 0.462218\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030937; batch adversarial loss: 0.448309\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033027; batch adversarial loss: 0.415261\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032093; batch adversarial loss: 0.447488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043066; batch adversarial loss: 0.379703\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041037; batch adversarial loss: 0.411169\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014929; batch adversarial loss: 0.467340\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027157; batch adversarial loss: 0.397222\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021585; batch adversarial loss: 0.446782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013248; batch adversarial loss: 0.412109\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018498; batch adversarial loss: 0.368238\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024839; batch adversarial loss: 0.415021\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.372500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023228; batch adversarial loss: 0.384618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029752; batch adversarial loss: 0.439153\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033906; batch adversarial loss: 0.418066\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022754; batch adversarial loss: 0.402134\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020079; batch adversarial loss: 0.418244\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012727; batch adversarial loss: 0.411509\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014219; batch adversarial loss: 0.416537\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020416; batch adversarial loss: 0.494425\n",
      "epoch 150; iter: 0; batch classifier loss: 0.006890; batch adversarial loss: 0.361475\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025038; batch adversarial loss: 0.430843\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025963; batch adversarial loss: 0.521077\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028355; batch adversarial loss: 0.503051\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023509; batch adversarial loss: 0.461438\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032363; batch adversarial loss: 0.470927\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031567; batch adversarial loss: 0.448085\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.414709\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045446; batch adversarial loss: 0.529743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.077049; batch adversarial loss: 0.556018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052560; batch adversarial loss: 0.586179\n",
      "epoch 161; iter: 0; batch classifier loss: 0.076602; batch adversarial loss: 0.640819\n",
      "epoch 162; iter: 0; batch classifier loss: 0.079964; batch adversarial loss: 0.635677\n",
      "epoch 163; iter: 0; batch classifier loss: 0.124784; batch adversarial loss: 0.598155\n",
      "epoch 164; iter: 0; batch classifier loss: 0.072990; batch adversarial loss: 0.562512\n",
      "epoch 165; iter: 0; batch classifier loss: 0.106862; batch adversarial loss: 0.594699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.091162; batch adversarial loss: 0.567871\n",
      "epoch 167; iter: 0; batch classifier loss: 0.100259; batch adversarial loss: 0.460301\n",
      "epoch 168; iter: 0; batch classifier loss: 0.087468; batch adversarial loss: 0.514387\n",
      "epoch 169; iter: 0; batch classifier loss: 0.081108; batch adversarial loss: 0.545367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.101164; batch adversarial loss: 0.540476\n",
      "epoch 171; iter: 0; batch classifier loss: 0.103231; batch adversarial loss: 0.574374\n",
      "epoch 172; iter: 0; batch classifier loss: 0.194614; batch adversarial loss: 0.676717\n",
      "epoch 173; iter: 0; batch classifier loss: 0.100236; batch adversarial loss: 0.542147\n",
      "epoch 174; iter: 0; batch classifier loss: 0.128806; batch adversarial loss: 0.594134\n",
      "epoch 175; iter: 0; batch classifier loss: 0.113033; batch adversarial loss: 0.631315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.168881; batch adversarial loss: 0.684466\n",
      "epoch 177; iter: 0; batch classifier loss: 0.167608; batch adversarial loss: 0.619903\n",
      "epoch 178; iter: 0; batch classifier loss: 0.098489; batch adversarial loss: 0.535259\n",
      "epoch 179; iter: 0; batch classifier loss: 0.153152; batch adversarial loss: 0.569157\n",
      "epoch 180; iter: 0; batch classifier loss: 0.158973; batch adversarial loss: 0.672395\n",
      "epoch 181; iter: 0; batch classifier loss: 0.137231; batch adversarial loss: 0.484878\n",
      "epoch 182; iter: 0; batch classifier loss: 0.092525; batch adversarial loss: 0.475584\n",
      "epoch 183; iter: 0; batch classifier loss: 0.195890; batch adversarial loss: 0.601124\n",
      "epoch 184; iter: 0; batch classifier loss: 0.135837; batch adversarial loss: 0.554850\n",
      "epoch 185; iter: 0; batch classifier loss: 0.166478; batch adversarial loss: 0.578272\n",
      "epoch 186; iter: 0; batch classifier loss: 0.091788; batch adversarial loss: 0.545806\n",
      "epoch 187; iter: 0; batch classifier loss: 0.180144; batch adversarial loss: 0.596063\n",
      "epoch 188; iter: 0; batch classifier loss: 0.073557; batch adversarial loss: 0.433221\n",
      "epoch 189; iter: 0; batch classifier loss: 0.142620; batch adversarial loss: 0.555123\n",
      "epoch 190; iter: 0; batch classifier loss: 0.120305; batch adversarial loss: 0.529405\n",
      "epoch 191; iter: 0; batch classifier loss: 0.119083; batch adversarial loss: 0.527793\n",
      "epoch 192; iter: 0; batch classifier loss: 0.145624; batch adversarial loss: 0.522761\n",
      "epoch 193; iter: 0; batch classifier loss: 0.088849; batch adversarial loss: 0.395484\n",
      "epoch 194; iter: 0; batch classifier loss: 0.166884; batch adversarial loss: 0.533533\n",
      "epoch 195; iter: 0; batch classifier loss: 0.132035; batch adversarial loss: 0.543267\n",
      "epoch 196; iter: 0; batch classifier loss: 0.144635; batch adversarial loss: 0.489803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.173183; batch adversarial loss: 0.531409\n",
      "epoch 198; iter: 0; batch classifier loss: 0.150150; batch adversarial loss: 0.543256\n",
      "epoch 199; iter: 0; batch classifier loss: 0.199293; batch adversarial loss: 0.544051\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695151; batch adversarial loss: 0.961490\n",
      "epoch 1; iter: 0; batch classifier loss: 0.701538; batch adversarial loss: 1.087116\n",
      "epoch 2; iter: 0; batch classifier loss: 0.861369; batch adversarial loss: 1.116735\n",
      "epoch 3; iter: 0; batch classifier loss: 1.101344; batch adversarial loss: 1.059767\n",
      "epoch 4; iter: 0; batch classifier loss: 1.124979; batch adversarial loss: 0.956136\n",
      "epoch 5; iter: 0; batch classifier loss: 0.937424; batch adversarial loss: 0.814389\n",
      "epoch 6; iter: 0; batch classifier loss: 1.080967; batch adversarial loss: 0.795715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.832306; batch adversarial loss: 0.702579\n",
      "epoch 8; iter: 0; batch classifier loss: 0.745635; batch adversarial loss: 0.641770\n",
      "epoch 9; iter: 0; batch classifier loss: 0.726000; batch adversarial loss: 0.610882\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575865; batch adversarial loss: 0.564939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490629; batch adversarial loss: 0.550055\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410132; batch adversarial loss: 0.516878\n",
      "epoch 13; iter: 0; batch classifier loss: 0.313055; batch adversarial loss: 0.516896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285471; batch adversarial loss: 0.476483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308452; batch adversarial loss: 0.480569\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286859; batch adversarial loss: 0.499105\n",
      "epoch 17; iter: 0; batch classifier loss: 0.271719; batch adversarial loss: 0.551992\n",
      "epoch 18; iter: 0; batch classifier loss: 0.291470; batch adversarial loss: 0.489334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.178682; batch adversarial loss: 0.526925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284799; batch adversarial loss: 0.465434\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295024; batch adversarial loss: 0.522145\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216172; batch adversarial loss: 0.569024\n",
      "epoch 23; iter: 0; batch classifier loss: 0.257149; batch adversarial loss: 0.481649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230642; batch adversarial loss: 0.431014\n",
      "epoch 25; iter: 0; batch classifier loss: 0.142792; batch adversarial loss: 0.514017\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194145; batch adversarial loss: 0.425023\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173345; batch adversarial loss: 0.515536\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193765; batch adversarial loss: 0.424171\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206630; batch adversarial loss: 0.452918\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191612; batch adversarial loss: 0.380328\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152746; batch adversarial loss: 0.549673\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203733; batch adversarial loss: 0.470252\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216803; batch adversarial loss: 0.405891\n",
      "epoch 34; iter: 0; batch classifier loss: 0.127257; batch adversarial loss: 0.570554\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140989; batch adversarial loss: 0.493027\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131811; batch adversarial loss: 0.470187\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175697; batch adversarial loss: 0.424552\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169634; batch adversarial loss: 0.568958\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151042; batch adversarial loss: 0.543460\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097735; batch adversarial loss: 0.460807\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084149; batch adversarial loss: 0.468893\n",
      "epoch 42; iter: 0; batch classifier loss: 0.211863; batch adversarial loss: 0.472176\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172251; batch adversarial loss: 0.460366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112694; batch adversarial loss: 0.523530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132443; batch adversarial loss: 0.428553\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152542; batch adversarial loss: 0.461205\n",
      "epoch 47; iter: 0; batch classifier loss: 0.072006; batch adversarial loss: 0.473047\n",
      "epoch 48; iter: 0; batch classifier loss: 0.139848; batch adversarial loss: 0.463204\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136613; batch adversarial loss: 0.475859\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082386; batch adversarial loss: 0.467290\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095207; batch adversarial loss: 0.421888\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093747; batch adversarial loss: 0.403493\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168179; batch adversarial loss: 0.534516\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094332; batch adversarial loss: 0.527497\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115707; batch adversarial loss: 0.489727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076004; batch adversarial loss: 0.415780\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114134; batch adversarial loss: 0.445467\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093916; batch adversarial loss: 0.397180\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072613; batch adversarial loss: 0.467827\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101504; batch adversarial loss: 0.402758\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101275; batch adversarial loss: 0.429945\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076129; batch adversarial loss: 0.500081\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121012; batch adversarial loss: 0.481887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.073891; batch adversarial loss: 0.426144\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095496; batch adversarial loss: 0.452000\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076710; batch adversarial loss: 0.469523\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094248; batch adversarial loss: 0.418740\n",
      "epoch 68; iter: 0; batch classifier loss: 0.099091; batch adversarial loss: 0.458171\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077118; batch adversarial loss: 0.521130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095522; batch adversarial loss: 0.372227\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080412; batch adversarial loss: 0.523133\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098796; batch adversarial loss: 0.437757\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068161; batch adversarial loss: 0.583471\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054114; batch adversarial loss: 0.461007\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081000; batch adversarial loss: 0.443519\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065744; batch adversarial loss: 0.479810\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091115; batch adversarial loss: 0.415349\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082330; batch adversarial loss: 0.417577\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061767; batch adversarial loss: 0.447209\n",
      "epoch 80; iter: 0; batch classifier loss: 0.050706; batch adversarial loss: 0.468099\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042933; batch adversarial loss: 0.520463\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075312; batch adversarial loss: 0.456596\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067797; batch adversarial loss: 0.409321\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037089; batch adversarial loss: 0.505932\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058257; batch adversarial loss: 0.486735\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045560; batch adversarial loss: 0.386675\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060390; batch adversarial loss: 0.332969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.464145\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047492; batch adversarial loss: 0.478056\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041778; batch adversarial loss: 0.509717\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028781; batch adversarial loss: 0.448071\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066398; batch adversarial loss: 0.465045\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046431; batch adversarial loss: 0.390788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045098; batch adversarial loss: 0.387554\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072534; batch adversarial loss: 0.348453\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046062; batch adversarial loss: 0.531045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054255; batch adversarial loss: 0.549204\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048440; batch adversarial loss: 0.527711\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.541428\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074942; batch adversarial loss: 0.416075\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054496; batch adversarial loss: 0.422110\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049227; batch adversarial loss: 0.413373\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040365; batch adversarial loss: 0.419361\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037958; batch adversarial loss: 0.429693\n",
      "epoch 105; iter: 0; batch classifier loss: 0.079055; batch adversarial loss: 0.490070\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057363; batch adversarial loss: 0.446386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045867; batch adversarial loss: 0.420395\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082103; batch adversarial loss: 0.530482\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043165; batch adversarial loss: 0.466390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045621; batch adversarial loss: 0.385558\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047097; batch adversarial loss: 0.453297\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035812; batch adversarial loss: 0.374374\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.388590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051988; batch adversarial loss: 0.389546\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065123; batch adversarial loss: 0.441831\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046267; batch adversarial loss: 0.499482\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.505086\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029823; batch adversarial loss: 0.498581\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036890; batch adversarial loss: 0.395743\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061803; batch adversarial loss: 0.458314\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.496984\n",
      "epoch 122; iter: 0; batch classifier loss: 0.019365; batch adversarial loss: 0.522233\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.390016\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022625; batch adversarial loss: 0.611086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023973; batch adversarial loss: 0.549563\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032810; batch adversarial loss: 0.501094\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023217; batch adversarial loss: 0.490409\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045467; batch adversarial loss: 0.502591\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029773; batch adversarial loss: 0.549418\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037914; batch adversarial loss: 0.517401\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043774; batch adversarial loss: 0.427512\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015968; batch adversarial loss: 0.494692\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019519; batch adversarial loss: 0.500600\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031988; batch adversarial loss: 0.412052\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.464934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021294; batch adversarial loss: 0.534740\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016063; batch adversarial loss: 0.487674\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032587; batch adversarial loss: 0.506442\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017224; batch adversarial loss: 0.549047\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017539; batch adversarial loss: 0.425794\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.596660\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025592; batch adversarial loss: 0.532243\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016702; batch adversarial loss: 0.431867\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052138; batch adversarial loss: 0.443134\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025606; batch adversarial loss: 0.437752\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049339; batch adversarial loss: 0.437048\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033498; batch adversarial loss: 0.475783\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018043; batch adversarial loss: 0.496275\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012666; batch adversarial loss: 0.404494\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013146; batch adversarial loss: 0.443202\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020235; batch adversarial loss: 0.412868\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.507479\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018617; batch adversarial loss: 0.424544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.009262; batch adversarial loss: 0.440058\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026881; batch adversarial loss: 0.523155\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018993; batch adversarial loss: 0.365716\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024037; batch adversarial loss: 0.428050\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020616; batch adversarial loss: 0.372720\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015936; batch adversarial loss: 0.370929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.036449; batch adversarial loss: 0.430502\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016287; batch adversarial loss: 0.533511\n",
      "epoch 162; iter: 0; batch classifier loss: 0.073130; batch adversarial loss: 0.409350\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010982; batch adversarial loss: 0.407625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005942; batch adversarial loss: 0.445169\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012587; batch adversarial loss: 0.479788\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033364; batch adversarial loss: 0.413757\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017516; batch adversarial loss: 0.573361\n",
      "epoch 168; iter: 0; batch classifier loss: 0.002558; batch adversarial loss: 0.450000\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011596; batch adversarial loss: 0.464803\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007949; batch adversarial loss: 0.461439\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008956; batch adversarial loss: 0.428774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009191; batch adversarial loss: 0.487472\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.436989\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023774; batch adversarial loss: 0.438867\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012815; batch adversarial loss: 0.479727\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021787; batch adversarial loss: 0.416665\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010802; batch adversarial loss: 0.533270\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035734; batch adversarial loss: 0.460995\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018136; batch adversarial loss: 0.504290\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012397; batch adversarial loss: 0.422554\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035301; batch adversarial loss: 0.481473\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032630; batch adversarial loss: 0.489346\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013680; batch adversarial loss: 0.429606\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.441310\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006324; batch adversarial loss: 0.428922\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044989; batch adversarial loss: 0.417706\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033937; batch adversarial loss: 0.382947\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024737; batch adversarial loss: 0.538226\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026113; batch adversarial loss: 0.449826\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014092; batch adversarial loss: 0.448870\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023519; batch adversarial loss: 0.453430\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022243; batch adversarial loss: 0.551441\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016974; batch adversarial loss: 0.477458\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021488; batch adversarial loss: 0.519603\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023222; batch adversarial loss: 0.431434\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024293; batch adversarial loss: 0.487950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014566; batch adversarial loss: 0.531934\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008049; batch adversarial loss: 0.472471\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006459; batch adversarial loss: 0.375576\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718149; batch adversarial loss: 0.815300\n",
      "epoch 1; iter: 0; batch classifier loss: 0.488267; batch adversarial loss: 0.745684\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635801; batch adversarial loss: 0.735552\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617599; batch adversarial loss: 0.664450\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528100; batch adversarial loss: 0.643652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.456735; batch adversarial loss: 0.597491\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364440; batch adversarial loss: 0.580764\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379124; batch adversarial loss: 0.541007\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431529; batch adversarial loss: 0.547173\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437036; batch adversarial loss: 0.528816\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414672; batch adversarial loss: 0.507244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346832; batch adversarial loss: 0.516345\n",
      "epoch 12; iter: 0; batch classifier loss: 0.272434; batch adversarial loss: 0.534818\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297375; batch adversarial loss: 0.544408\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397459; batch adversarial loss: 0.484204\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345557; batch adversarial loss: 0.530581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344872; batch adversarial loss: 0.513552\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299862; batch adversarial loss: 0.469398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279909; batch adversarial loss: 0.490811\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284088; batch adversarial loss: 0.495897\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304850; batch adversarial loss: 0.495436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329646; batch adversarial loss: 0.541627\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242060; batch adversarial loss: 0.524694\n",
      "epoch 23; iter: 0; batch classifier loss: 0.274011; batch adversarial loss: 0.491223\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364078; batch adversarial loss: 0.474218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265836; batch adversarial loss: 0.491701\n",
      "epoch 26; iter: 0; batch classifier loss: 0.288035; batch adversarial loss: 0.461253\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341033; batch adversarial loss: 0.460019\n",
      "epoch 28; iter: 0; batch classifier loss: 0.279408; batch adversarial loss: 0.401993\n",
      "epoch 29; iter: 0; batch classifier loss: 0.283619; batch adversarial loss: 0.574677\n",
      "epoch 30; iter: 0; batch classifier loss: 0.266914; batch adversarial loss: 0.462374\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359369; batch adversarial loss: 0.391985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201316; batch adversarial loss: 0.521021\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264760; batch adversarial loss: 0.454565\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225195; batch adversarial loss: 0.515926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230077; batch adversarial loss: 0.412012\n",
      "epoch 36; iter: 0; batch classifier loss: 0.325405; batch adversarial loss: 0.431126\n",
      "epoch 37; iter: 0; batch classifier loss: 0.217960; batch adversarial loss: 0.481893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.292974; batch adversarial loss: 0.446632\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269273; batch adversarial loss: 0.425701\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270315; batch adversarial loss: 0.508044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291200; batch adversarial loss: 0.496919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.257723; batch adversarial loss: 0.520394\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159002; batch adversarial loss: 0.443565\n",
      "epoch 44; iter: 0; batch classifier loss: 0.244207; batch adversarial loss: 0.452391\n",
      "epoch 45; iter: 0; batch classifier loss: 0.165916; batch adversarial loss: 0.456001\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188549; batch adversarial loss: 0.494794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259465; batch adversarial loss: 0.459601\n",
      "epoch 48; iter: 0; batch classifier loss: 0.173804; batch adversarial loss: 0.519950\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225217; batch adversarial loss: 0.474015\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228349; batch adversarial loss: 0.508819\n",
      "epoch 51; iter: 0; batch classifier loss: 0.233515; batch adversarial loss: 0.559843\n",
      "epoch 52; iter: 0; batch classifier loss: 0.239381; batch adversarial loss: 0.506975\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222729; batch adversarial loss: 0.389289\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136452; batch adversarial loss: 0.470952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.164565; batch adversarial loss: 0.508209\n",
      "epoch 56; iter: 0; batch classifier loss: 0.249570; batch adversarial loss: 0.485667\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216525; batch adversarial loss: 0.470051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.186957; batch adversarial loss: 0.396828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.195483; batch adversarial loss: 0.570293\n",
      "epoch 60; iter: 0; batch classifier loss: 0.250401; batch adversarial loss: 0.436521\n",
      "epoch 61; iter: 0; batch classifier loss: 0.219305; batch adversarial loss: 0.497411\n",
      "epoch 62; iter: 0; batch classifier loss: 0.295735; batch adversarial loss: 0.336295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.255696; batch adversarial loss: 0.421847\n",
      "epoch 64; iter: 0; batch classifier loss: 0.148479; batch adversarial loss: 0.545461\n",
      "epoch 65; iter: 0; batch classifier loss: 0.189769; batch adversarial loss: 0.421075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.253667; batch adversarial loss: 0.458842\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135381; batch adversarial loss: 0.520987\n",
      "epoch 68; iter: 0; batch classifier loss: 0.222411; batch adversarial loss: 0.508575\n",
      "epoch 69; iter: 0; batch classifier loss: 0.103109; batch adversarial loss: 0.409271\n",
      "epoch 70; iter: 0; batch classifier loss: 0.177192; batch adversarial loss: 0.460244\n",
      "epoch 71; iter: 0; batch classifier loss: 0.163572; batch adversarial loss: 0.483604\n",
      "epoch 72; iter: 0; batch classifier loss: 0.210568; batch adversarial loss: 0.484077\n",
      "epoch 73; iter: 0; batch classifier loss: 0.150816; batch adversarial loss: 0.371785\n",
      "epoch 74; iter: 0; batch classifier loss: 0.252784; batch adversarial loss: 0.410236\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204793; batch adversarial loss: 0.421602\n",
      "epoch 76; iter: 0; batch classifier loss: 0.210079; batch adversarial loss: 0.408854\n",
      "epoch 77; iter: 0; batch classifier loss: 0.260548; batch adversarial loss: 0.384007\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136913; batch adversarial loss: 0.346529\n",
      "epoch 79; iter: 0; batch classifier loss: 0.136140; batch adversarial loss: 0.510087\n",
      "epoch 80; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.508685\n",
      "epoch 81; iter: 0; batch classifier loss: 0.159878; batch adversarial loss: 0.509873\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348634; batch adversarial loss: 0.396984\n",
      "epoch 83; iter: 0; batch classifier loss: 0.175170; batch adversarial loss: 0.458454\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119225; batch adversarial loss: 0.371718\n",
      "epoch 85; iter: 0; batch classifier loss: 0.184553; batch adversarial loss: 0.484220\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192481; batch adversarial loss: 0.473202\n",
      "epoch 87; iter: 0; batch classifier loss: 0.181004; batch adversarial loss: 0.534507\n",
      "epoch 88; iter: 0; batch classifier loss: 0.224541; batch adversarial loss: 0.397370\n",
      "epoch 89; iter: 0; batch classifier loss: 0.188288; batch adversarial loss: 0.535485\n",
      "epoch 90; iter: 0; batch classifier loss: 0.201107; batch adversarial loss: 0.470608\n",
      "epoch 91; iter: 0; batch classifier loss: 0.134930; batch adversarial loss: 0.508586\n",
      "epoch 92; iter: 0; batch classifier loss: 0.129749; batch adversarial loss: 0.470968\n",
      "epoch 93; iter: 0; batch classifier loss: 0.248825; batch adversarial loss: 0.495387\n",
      "epoch 94; iter: 0; batch classifier loss: 0.220311; batch adversarial loss: 0.445731\n",
      "epoch 95; iter: 0; batch classifier loss: 0.150711; batch adversarial loss: 0.621710\n",
      "epoch 96; iter: 0; batch classifier loss: 0.164312; batch adversarial loss: 0.334062\n",
      "epoch 97; iter: 0; batch classifier loss: 0.202223; batch adversarial loss: 0.434033\n",
      "epoch 98; iter: 0; batch classifier loss: 0.230118; batch adversarial loss: 0.460051\n",
      "epoch 99; iter: 0; batch classifier loss: 0.210020; batch adversarial loss: 0.447092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.180031; batch adversarial loss: 0.409837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.153402; batch adversarial loss: 0.408912\n",
      "epoch 102; iter: 0; batch classifier loss: 0.229833; batch adversarial loss: 0.546934\n",
      "epoch 103; iter: 0; batch classifier loss: 0.251321; batch adversarial loss: 0.408879\n",
      "epoch 104; iter: 0; batch classifier loss: 0.186295; batch adversarial loss: 0.483285\n",
      "epoch 105; iter: 0; batch classifier loss: 0.149399; batch adversarial loss: 0.434323\n",
      "epoch 106; iter: 0; batch classifier loss: 0.140446; batch adversarial loss: 0.485137\n",
      "epoch 107; iter: 0; batch classifier loss: 0.201296; batch adversarial loss: 0.497548\n",
      "epoch 108; iter: 0; batch classifier loss: 0.241569; batch adversarial loss: 0.571361\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141485; batch adversarial loss: 0.434288\n",
      "epoch 110; iter: 0; batch classifier loss: 0.195256; batch adversarial loss: 0.445242\n",
      "epoch 111; iter: 0; batch classifier loss: 0.240866; batch adversarial loss: 0.370726\n",
      "epoch 112; iter: 0; batch classifier loss: 0.183070; batch adversarial loss: 0.371040\n",
      "epoch 113; iter: 0; batch classifier loss: 0.145324; batch adversarial loss: 0.458390\n",
      "epoch 114; iter: 0; batch classifier loss: 0.153235; batch adversarial loss: 0.471849\n",
      "epoch 115; iter: 0; batch classifier loss: 0.151484; batch adversarial loss: 0.545265\n",
      "epoch 116; iter: 0; batch classifier loss: 0.137902; batch adversarial loss: 0.406747\n",
      "epoch 117; iter: 0; batch classifier loss: 0.113126; batch adversarial loss: 0.447246\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086999; batch adversarial loss: 0.445965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073674; batch adversarial loss: 0.564920\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048483; batch adversarial loss: 0.495264\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049603; batch adversarial loss: 0.413118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045240; batch adversarial loss: 0.434413\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041330; batch adversarial loss: 0.379823\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032276; batch adversarial loss: 0.483504\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068095; batch adversarial loss: 0.398043\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033706; batch adversarial loss: 0.442126\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033778; batch adversarial loss: 0.398185\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038783; batch adversarial loss: 0.478701\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024067; batch adversarial loss: 0.361663\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044147; batch adversarial loss: 0.351951\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022111; batch adversarial loss: 0.351875\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039361; batch adversarial loss: 0.438182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.408081\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045842; batch adversarial loss: 0.399317\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013356; batch adversarial loss: 0.429542\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028570; batch adversarial loss: 0.437892\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046317; batch adversarial loss: 0.350857\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033348; batch adversarial loss: 0.369630\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019518; batch adversarial loss: 0.381121\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017717; batch adversarial loss: 0.490952\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.432371\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021570; batch adversarial loss: 0.471456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031809; batch adversarial loss: 0.422819\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020793; batch adversarial loss: 0.391851\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025509; batch adversarial loss: 0.353890\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030525; batch adversarial loss: 0.512197\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007245; batch adversarial loss: 0.449394\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027749; batch adversarial loss: 0.370112\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010688; batch adversarial loss: 0.382945\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010562; batch adversarial loss: 0.450021\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.430217\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021590; batch adversarial loss: 0.487151\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034436; batch adversarial loss: 0.354506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.008726; batch adversarial loss: 0.447711\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011012; batch adversarial loss: 0.373610\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015579; batch adversarial loss: 0.456096\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020029; batch adversarial loss: 0.425299\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026671; batch adversarial loss: 0.443560\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028686; batch adversarial loss: 0.467431\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025362; batch adversarial loss: 0.506039\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024710; batch adversarial loss: 0.473202\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030406; batch adversarial loss: 0.448140\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011194; batch adversarial loss: 0.468005\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011393; batch adversarial loss: 0.465420\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008441; batch adversarial loss: 0.477695\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020910; batch adversarial loss: 0.465790\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005467; batch adversarial loss: 0.449284\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.511368\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008562; batch adversarial loss: 0.432066\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013635; batch adversarial loss: 0.378912\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050653; batch adversarial loss: 0.398914\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026015; batch adversarial loss: 0.450383\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034197; batch adversarial loss: 0.368345\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.456443\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005659; batch adversarial loss: 0.527472\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.409779\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011005; batch adversarial loss: 0.528682\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020732; batch adversarial loss: 0.473560\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033494; batch adversarial loss: 0.463224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010529; batch adversarial loss: 0.521037\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023880; batch adversarial loss: 0.430916\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010612; batch adversarial loss: 0.456186\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033599; batch adversarial loss: 0.348610\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005153; batch adversarial loss: 0.422000\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013659; batch adversarial loss: 0.407193\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008518; batch adversarial loss: 0.389120\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023828; batch adversarial loss: 0.525892\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018581; batch adversarial loss: 0.548658\n",
      "epoch 189; iter: 0; batch classifier loss: 0.003800; batch adversarial loss: 0.379535\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022144; batch adversarial loss: 0.480446\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005211; batch adversarial loss: 0.505878\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022506; batch adversarial loss: 0.465557\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007059; batch adversarial loss: 0.390112\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006505; batch adversarial loss: 0.408069\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003140; batch adversarial loss: 0.439411\n",
      "epoch 196; iter: 0; batch classifier loss: 0.003234; batch adversarial loss: 0.407805\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035849; batch adversarial loss: 0.495920\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016513; batch adversarial loss: 0.516763\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015494; batch adversarial loss: 0.457916\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723286; batch adversarial loss: 1.076769\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670488; batch adversarial loss: 1.124719\n",
      "epoch 2; iter: 0; batch classifier loss: 1.008344; batch adversarial loss: 1.253989\n",
      "epoch 3; iter: 0; batch classifier loss: 1.092919; batch adversarial loss: 1.119348\n",
      "epoch 4; iter: 0; batch classifier loss: 1.144662; batch adversarial loss: 1.020122\n",
      "epoch 5; iter: 0; batch classifier loss: 1.219527; batch adversarial loss: 0.962413\n",
      "epoch 6; iter: 0; batch classifier loss: 1.163258; batch adversarial loss: 0.833657\n",
      "epoch 7; iter: 0; batch classifier loss: 1.033089; batch adversarial loss: 0.777172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.873592; batch adversarial loss: 0.686298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.735089; batch adversarial loss: 0.678082\n",
      "epoch 10; iter: 0; batch classifier loss: 0.735823; batch adversarial loss: 0.629037\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551805; batch adversarial loss: 0.564288\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519507; batch adversarial loss: 0.524881\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348181; batch adversarial loss: 0.578120\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334929; batch adversarial loss: 0.498313\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264509; batch adversarial loss: 0.524162\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266978; batch adversarial loss: 0.419964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293062; batch adversarial loss: 0.465023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247204; batch adversarial loss: 0.419388\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265590; batch adversarial loss: 0.438432\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202020; batch adversarial loss: 0.461246\n",
      "epoch 21; iter: 0; batch classifier loss: 0.229939; batch adversarial loss: 0.485800\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254455; batch adversarial loss: 0.466808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207299; batch adversarial loss: 0.512734\n",
      "epoch 24; iter: 0; batch classifier loss: 0.199316; batch adversarial loss: 0.503006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202897; batch adversarial loss: 0.531106\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223196; batch adversarial loss: 0.453710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195218; batch adversarial loss: 0.566470\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202078; batch adversarial loss: 0.548617\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184910; batch adversarial loss: 0.467051\n",
      "epoch 30; iter: 0; batch classifier loss: 0.220703; batch adversarial loss: 0.449564\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156757; batch adversarial loss: 0.483226\n",
      "epoch 32; iter: 0; batch classifier loss: 0.234021; batch adversarial loss: 0.424931\n",
      "epoch 33; iter: 0; batch classifier loss: 0.199362; batch adversarial loss: 0.440576\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187960; batch adversarial loss: 0.514539\n",
      "epoch 35; iter: 0; batch classifier loss: 0.221603; batch adversarial loss: 0.458998\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158653; batch adversarial loss: 0.401029\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164108; batch adversarial loss: 0.348135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186846; batch adversarial loss: 0.370750\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229298; batch adversarial loss: 0.407574\n",
      "epoch 40; iter: 0; batch classifier loss: 0.173213; batch adversarial loss: 0.520828\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165892; batch adversarial loss: 0.439164\n",
      "epoch 42; iter: 0; batch classifier loss: 0.136954; batch adversarial loss: 0.485155\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183747; batch adversarial loss: 0.444087\n",
      "epoch 44; iter: 0; batch classifier loss: 0.135249; batch adversarial loss: 0.488174\n",
      "epoch 45; iter: 0; batch classifier loss: 0.193522; batch adversarial loss: 0.458234\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108725; batch adversarial loss: 0.471923\n",
      "epoch 47; iter: 0; batch classifier loss: 0.149818; batch adversarial loss: 0.444065\n",
      "epoch 48; iter: 0; batch classifier loss: 0.162328; batch adversarial loss: 0.517241\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152312; batch adversarial loss: 0.560907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.141090; batch adversarial loss: 0.447053\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121281; batch adversarial loss: 0.367634\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137367; batch adversarial loss: 0.417765\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120339; batch adversarial loss: 0.537454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140478; batch adversarial loss: 0.363242\n",
      "epoch 55; iter: 0; batch classifier loss: 0.263175; batch adversarial loss: 0.557026\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137612; batch adversarial loss: 0.422349\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125585; batch adversarial loss: 0.383882\n",
      "epoch 58; iter: 0; batch classifier loss: 0.220345; batch adversarial loss: 0.436426\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131716; batch adversarial loss: 0.445366\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129691; batch adversarial loss: 0.491232\n",
      "epoch 61; iter: 0; batch classifier loss: 0.171617; batch adversarial loss: 0.406170\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105889; batch adversarial loss: 0.426044\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138208; batch adversarial loss: 0.501212\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116804; batch adversarial loss: 0.350642\n",
      "epoch 65; iter: 0; batch classifier loss: 0.131671; batch adversarial loss: 0.547159\n",
      "epoch 66; iter: 0; batch classifier loss: 0.134316; batch adversarial loss: 0.430288\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134977; batch adversarial loss: 0.498453\n",
      "epoch 68; iter: 0; batch classifier loss: 0.162074; batch adversarial loss: 0.497330\n",
      "epoch 69; iter: 0; batch classifier loss: 0.172888; batch adversarial loss: 0.379870\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136780; batch adversarial loss: 0.483538\n",
      "epoch 71; iter: 0; batch classifier loss: 0.168658; batch adversarial loss: 0.438612\n",
      "epoch 72; iter: 0; batch classifier loss: 0.164597; batch adversarial loss: 0.463408\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135960; batch adversarial loss: 0.447080\n",
      "epoch 74; iter: 0; batch classifier loss: 0.163652; batch adversarial loss: 0.335808\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122011; batch adversarial loss: 0.434093\n",
      "epoch 76; iter: 0; batch classifier loss: 0.117196; batch adversarial loss: 0.489518\n",
      "epoch 77; iter: 0; batch classifier loss: 0.129995; batch adversarial loss: 0.414054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.150591; batch adversarial loss: 0.482149\n",
      "epoch 79; iter: 0; batch classifier loss: 0.165264; batch adversarial loss: 0.403438\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126940; batch adversarial loss: 0.499522\n",
      "epoch 81; iter: 0; batch classifier loss: 0.130061; batch adversarial loss: 0.475917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108384; batch adversarial loss: 0.397966\n",
      "epoch 83; iter: 0; batch classifier loss: 0.104316; batch adversarial loss: 0.464147\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065469; batch adversarial loss: 0.443426\n",
      "epoch 85; iter: 0; batch classifier loss: 0.169895; batch adversarial loss: 0.333121\n",
      "epoch 86; iter: 0; batch classifier loss: 0.197691; batch adversarial loss: 0.485564\n",
      "epoch 87; iter: 0; batch classifier loss: 0.165727; batch adversarial loss: 0.379490\n",
      "epoch 88; iter: 0; batch classifier loss: 0.159569; batch adversarial loss: 0.463702\n",
      "epoch 89; iter: 0; batch classifier loss: 0.157724; batch adversarial loss: 0.326814\n",
      "epoch 90; iter: 0; batch classifier loss: 0.135712; batch adversarial loss: 0.371465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087919; batch adversarial loss: 0.515621\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095372; batch adversarial loss: 0.444740\n",
      "epoch 93; iter: 0; batch classifier loss: 0.155265; batch adversarial loss: 0.380189\n",
      "epoch 94; iter: 0; batch classifier loss: 0.115417; batch adversarial loss: 0.472680\n",
      "epoch 95; iter: 0; batch classifier loss: 0.144767; batch adversarial loss: 0.444029\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088022; batch adversarial loss: 0.494807\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096758; batch adversarial loss: 0.423060\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084597; batch adversarial loss: 0.478564\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071650; batch adversarial loss: 0.536199\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088422; batch adversarial loss: 0.436471\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098671; batch adversarial loss: 0.452880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.130892; batch adversarial loss: 0.436759\n",
      "epoch 103; iter: 0; batch classifier loss: 0.120724; batch adversarial loss: 0.359938\n",
      "epoch 104; iter: 0; batch classifier loss: 0.101744; batch adversarial loss: 0.402277\n",
      "epoch 105; iter: 0; batch classifier loss: 0.108199; batch adversarial loss: 0.512216\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093821; batch adversarial loss: 0.511761\n",
      "epoch 107; iter: 0; batch classifier loss: 0.179064; batch adversarial loss: 0.460216\n",
      "epoch 108; iter: 0; batch classifier loss: 0.109008; batch adversarial loss: 0.412241\n",
      "epoch 109; iter: 0; batch classifier loss: 0.128590; batch adversarial loss: 0.365708\n",
      "epoch 110; iter: 0; batch classifier loss: 0.102430; batch adversarial loss: 0.408691\n",
      "epoch 111; iter: 0; batch classifier loss: 0.117262; batch adversarial loss: 0.386713\n",
      "epoch 112; iter: 0; batch classifier loss: 0.158593; batch adversarial loss: 0.394631\n",
      "epoch 113; iter: 0; batch classifier loss: 0.098324; batch adversarial loss: 0.536217\n",
      "epoch 114; iter: 0; batch classifier loss: 0.155212; batch adversarial loss: 0.354353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.124091; batch adversarial loss: 0.349913\n",
      "epoch 116; iter: 0; batch classifier loss: 0.132154; batch adversarial loss: 0.434596\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087160; batch adversarial loss: 0.427919\n",
      "epoch 118; iter: 0; batch classifier loss: 0.111288; batch adversarial loss: 0.393965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.086845; batch adversarial loss: 0.413552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.130948; batch adversarial loss: 0.546898\n",
      "epoch 121; iter: 0; batch classifier loss: 0.092665; batch adversarial loss: 0.398377\n",
      "epoch 122; iter: 0; batch classifier loss: 0.113883; batch adversarial loss: 0.514982\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079136; batch adversarial loss: 0.426384\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056157; batch adversarial loss: 0.403706\n",
      "epoch 125; iter: 0; batch classifier loss: 0.112593; batch adversarial loss: 0.471716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.104904; batch adversarial loss: 0.467713\n",
      "epoch 127; iter: 0; batch classifier loss: 0.093578; batch adversarial loss: 0.459659\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069995; batch adversarial loss: 0.520328\n",
      "epoch 129; iter: 0; batch classifier loss: 0.112688; batch adversarial loss: 0.472129\n",
      "epoch 130; iter: 0; batch classifier loss: 0.094858; batch adversarial loss: 0.388257\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150283; batch adversarial loss: 0.451469\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053148; batch adversarial loss: 0.509627\n",
      "epoch 133; iter: 0; batch classifier loss: 0.125374; batch adversarial loss: 0.477234\n",
      "epoch 134; iter: 0; batch classifier loss: 0.105254; batch adversarial loss: 0.444067\n",
      "epoch 135; iter: 0; batch classifier loss: 0.109018; batch adversarial loss: 0.389317\n",
      "epoch 136; iter: 0; batch classifier loss: 0.136689; batch adversarial loss: 0.379719\n",
      "epoch 137; iter: 0; batch classifier loss: 0.118778; batch adversarial loss: 0.487533\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050358; batch adversarial loss: 0.385510\n",
      "epoch 139; iter: 0; batch classifier loss: 0.085198; batch adversarial loss: 0.466177\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055032; batch adversarial loss: 0.480348\n",
      "epoch 141; iter: 0; batch classifier loss: 0.110452; batch adversarial loss: 0.530753\n",
      "epoch 142; iter: 0; batch classifier loss: 0.093719; batch adversarial loss: 0.393967\n",
      "epoch 143; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.441217\n",
      "epoch 144; iter: 0; batch classifier loss: 0.076433; batch adversarial loss: 0.492237\n",
      "epoch 145; iter: 0; batch classifier loss: 0.069214; batch adversarial loss: 0.467269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.087680; batch adversarial loss: 0.487109\n",
      "epoch 147; iter: 0; batch classifier loss: 0.114501; batch adversarial loss: 0.460791\n",
      "epoch 148; iter: 0; batch classifier loss: 0.103345; batch adversarial loss: 0.418787\n",
      "epoch 149; iter: 0; batch classifier loss: 0.122742; batch adversarial loss: 0.445231\n",
      "epoch 150; iter: 0; batch classifier loss: 0.073198; batch adversarial loss: 0.467500\n",
      "epoch 151; iter: 0; batch classifier loss: 0.098999; batch adversarial loss: 0.402296\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062262; batch adversarial loss: 0.497562\n",
      "epoch 153; iter: 0; batch classifier loss: 0.060510; batch adversarial loss: 0.435071\n",
      "epoch 154; iter: 0; batch classifier loss: 0.105652; batch adversarial loss: 0.430547\n",
      "epoch 155; iter: 0; batch classifier loss: 0.083641; batch adversarial loss: 0.438404\n",
      "epoch 156; iter: 0; batch classifier loss: 0.105168; batch adversarial loss: 0.437710\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051237; batch adversarial loss: 0.429867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053214; batch adversarial loss: 0.483172\n",
      "epoch 159; iter: 0; batch classifier loss: 0.119922; batch adversarial loss: 0.453557\n",
      "epoch 160; iter: 0; batch classifier loss: 0.089334; batch adversarial loss: 0.379753\n",
      "epoch 161; iter: 0; batch classifier loss: 0.106606; batch adversarial loss: 0.512317\n",
      "epoch 162; iter: 0; batch classifier loss: 0.115185; batch adversarial loss: 0.468627\n",
      "epoch 163; iter: 0; batch classifier loss: 0.098014; batch adversarial loss: 0.424420\n",
      "epoch 164; iter: 0; batch classifier loss: 0.111622; batch adversarial loss: 0.405218\n",
      "epoch 165; iter: 0; batch classifier loss: 0.145492; batch adversarial loss: 0.425276\n",
      "epoch 166; iter: 0; batch classifier loss: 0.083168; batch adversarial loss: 0.382093\n",
      "epoch 167; iter: 0; batch classifier loss: 0.082709; batch adversarial loss: 0.385936\n",
      "epoch 168; iter: 0; batch classifier loss: 0.114109; batch adversarial loss: 0.471788\n",
      "epoch 169; iter: 0; batch classifier loss: 0.153874; batch adversarial loss: 0.462576\n",
      "epoch 170; iter: 0; batch classifier loss: 0.116057; batch adversarial loss: 0.386907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.093323; batch adversarial loss: 0.366824\n",
      "epoch 172; iter: 0; batch classifier loss: 0.158282; batch adversarial loss: 0.425573\n",
      "epoch 173; iter: 0; batch classifier loss: 0.153189; batch adversarial loss: 0.439623\n",
      "epoch 174; iter: 0; batch classifier loss: 0.200838; batch adversarial loss: 0.427859\n",
      "epoch 175; iter: 0; batch classifier loss: 0.135050; batch adversarial loss: 0.406157\n",
      "epoch 176; iter: 0; batch classifier loss: 0.154692; batch adversarial loss: 0.444214\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149623; batch adversarial loss: 0.491179\n",
      "epoch 178; iter: 0; batch classifier loss: 0.209052; batch adversarial loss: 0.462053\n",
      "epoch 179; iter: 0; batch classifier loss: 0.116692; batch adversarial loss: 0.483664\n",
      "epoch 180; iter: 0; batch classifier loss: 0.243644; batch adversarial loss: 0.501211\n",
      "epoch 181; iter: 0; batch classifier loss: 0.214282; batch adversarial loss: 0.383433\n",
      "epoch 182; iter: 0; batch classifier loss: 0.246734; batch adversarial loss: 0.415642\n",
      "epoch 183; iter: 0; batch classifier loss: 0.252143; batch adversarial loss: 0.481592\n",
      "epoch 184; iter: 0; batch classifier loss: 0.296796; batch adversarial loss: 0.426498\n",
      "epoch 185; iter: 0; batch classifier loss: 0.242512; batch adversarial loss: 0.420409\n",
      "epoch 186; iter: 0; batch classifier loss: 0.218128; batch adversarial loss: 0.483959\n",
      "epoch 187; iter: 0; batch classifier loss: 0.292680; batch adversarial loss: 0.471968\n",
      "epoch 188; iter: 0; batch classifier loss: 0.221589; batch adversarial loss: 0.421363\n",
      "epoch 189; iter: 0; batch classifier loss: 0.250790; batch adversarial loss: 0.410898\n",
      "epoch 190; iter: 0; batch classifier loss: 0.361880; batch adversarial loss: 0.472279\n",
      "epoch 191; iter: 0; batch classifier loss: 0.250293; batch adversarial loss: 0.507231\n",
      "epoch 192; iter: 0; batch classifier loss: 0.267603; batch adversarial loss: 0.396872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.259944; batch adversarial loss: 0.545471\n",
      "epoch 194; iter: 0; batch classifier loss: 0.102963; batch adversarial loss: 0.458800\n",
      "epoch 195; iter: 0; batch classifier loss: 0.050074; batch adversarial loss: 0.394900\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032808; batch adversarial loss: 0.378826\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039530; batch adversarial loss: 0.469687\n",
      "epoch 198; iter: 0; batch classifier loss: 0.066380; batch adversarial loss: 0.452289\n",
      "epoch 199; iter: 0; batch classifier loss: 0.050526; batch adversarial loss: 0.523031\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722230; batch adversarial loss: 0.562426\n",
      "epoch 1; iter: 0; batch classifier loss: 0.564228; batch adversarial loss: 0.586649\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417547; batch adversarial loss: 0.564900\n",
      "epoch 3; iter: 0; batch classifier loss: 0.407374; batch adversarial loss: 0.559182\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408410; batch adversarial loss: 0.581461\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323589; batch adversarial loss: 0.582446\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368430; batch adversarial loss: 0.541839\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385668; batch adversarial loss: 0.503129\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276263; batch adversarial loss: 0.561713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.318708; batch adversarial loss: 0.514698\n",
      "epoch 10; iter: 0; batch classifier loss: 0.312454; batch adversarial loss: 0.543557\n",
      "epoch 11; iter: 0; batch classifier loss: 0.340889; batch adversarial loss: 0.542381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406043; batch adversarial loss: 0.541334\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310057; batch adversarial loss: 0.553131\n",
      "epoch 14; iter: 0; batch classifier loss: 0.609139; batch adversarial loss: 0.463325\n",
      "epoch 15; iter: 0; batch classifier loss: 0.535812; batch adversarial loss: 0.549604\n",
      "epoch 16; iter: 0; batch classifier loss: 0.435540; batch adversarial loss: 0.528902\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292445; batch adversarial loss: 0.484732\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237078; batch adversarial loss: 0.449194\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260842; batch adversarial loss: 0.423358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204573; batch adversarial loss: 0.420220\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169229; batch adversarial loss: 0.446111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.234426; batch adversarial loss: 0.433995\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165094; batch adversarial loss: 0.466522\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238218; batch adversarial loss: 0.423645\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162805; batch adversarial loss: 0.440977\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193182; batch adversarial loss: 0.418345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172823; batch adversarial loss: 0.463354\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172843; batch adversarial loss: 0.513165\n",
      "epoch 29; iter: 0; batch classifier loss: 0.194981; batch adversarial loss: 0.442458\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106447; batch adversarial loss: 0.402800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188022; batch adversarial loss: 0.442516\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231719; batch adversarial loss: 0.395034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146732; batch adversarial loss: 0.537073\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178000; batch adversarial loss: 0.473555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.174677; batch adversarial loss: 0.487443\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128024; batch adversarial loss: 0.435608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178770; batch adversarial loss: 0.354314\n",
      "epoch 38; iter: 0; batch classifier loss: 0.143556; batch adversarial loss: 0.432352\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148743; batch adversarial loss: 0.470231\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134712; batch adversarial loss: 0.485510\n",
      "epoch 41; iter: 0; batch classifier loss: 0.179439; batch adversarial loss: 0.481337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.179751; batch adversarial loss: 0.461374\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204988; batch adversarial loss: 0.452671\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163970; batch adversarial loss: 0.405537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207438; batch adversarial loss: 0.465887\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205275; batch adversarial loss: 0.395058\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202992; batch adversarial loss: 0.437835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210013; batch adversarial loss: 0.465539\n",
      "epoch 49; iter: 0; batch classifier loss: 0.166629; batch adversarial loss: 0.516088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141943; batch adversarial loss: 0.452372\n",
      "epoch 51; iter: 0; batch classifier loss: 0.224188; batch adversarial loss: 0.439512\n",
      "epoch 52; iter: 0; batch classifier loss: 0.261313; batch adversarial loss: 0.525572\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166618; batch adversarial loss: 0.472994\n",
      "epoch 54; iter: 0; batch classifier loss: 0.154129; batch adversarial loss: 0.495712\n",
      "epoch 55; iter: 0; batch classifier loss: 0.184119; batch adversarial loss: 0.482202\n",
      "epoch 56; iter: 0; batch classifier loss: 0.190848; batch adversarial loss: 0.421425\n",
      "epoch 57; iter: 0; batch classifier loss: 0.200407; batch adversarial loss: 0.427205\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162490; batch adversarial loss: 0.477537\n",
      "epoch 59; iter: 0; batch classifier loss: 0.231807; batch adversarial loss: 0.385161\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162614; batch adversarial loss: 0.430942\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191677; batch adversarial loss: 0.443921\n",
      "epoch 62; iter: 0; batch classifier loss: 0.245128; batch adversarial loss: 0.459225\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207969; batch adversarial loss: 0.447268\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154454; batch adversarial loss: 0.371435\n",
      "epoch 65; iter: 0; batch classifier loss: 0.232407; batch adversarial loss: 0.421224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.157405; batch adversarial loss: 0.360091\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200925; batch adversarial loss: 0.358287\n",
      "epoch 68; iter: 0; batch classifier loss: 0.242430; batch adversarial loss: 0.444444\n",
      "epoch 69; iter: 0; batch classifier loss: 0.197697; batch adversarial loss: 0.471705\n",
      "epoch 70; iter: 0; batch classifier loss: 0.261032; batch adversarial loss: 0.383451\n",
      "epoch 71; iter: 0; batch classifier loss: 0.139267; batch adversarial loss: 0.409458\n",
      "epoch 72; iter: 0; batch classifier loss: 0.168210; batch adversarial loss: 0.496862\n",
      "epoch 73; iter: 0; batch classifier loss: 0.245587; batch adversarial loss: 0.346158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.123457; batch adversarial loss: 0.408267\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082976; batch adversarial loss: 0.355827\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106896; batch adversarial loss: 0.499546\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127896; batch adversarial loss: 0.608040\n",
      "epoch 78; iter: 0; batch classifier loss: 0.168355; batch adversarial loss: 0.475305\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202419; batch adversarial loss: 0.408546\n",
      "epoch 80; iter: 0; batch classifier loss: 0.193677; batch adversarial loss: 0.457056\n",
      "epoch 81; iter: 0; batch classifier loss: 0.159999; batch adversarial loss: 0.447722\n",
      "epoch 82; iter: 0; batch classifier loss: 0.190498; batch adversarial loss: 0.496236\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142024; batch adversarial loss: 0.424674\n",
      "epoch 84; iter: 0; batch classifier loss: 0.299820; batch adversarial loss: 0.473765\n",
      "epoch 85; iter: 0; batch classifier loss: 0.174410; batch adversarial loss: 0.443784\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192371; batch adversarial loss: 0.472821\n",
      "epoch 87; iter: 0; batch classifier loss: 0.179125; batch adversarial loss: 0.396710\n",
      "epoch 88; iter: 0; batch classifier loss: 0.180146; batch adversarial loss: 0.473445\n",
      "epoch 89; iter: 0; batch classifier loss: 0.221781; batch adversarial loss: 0.407471\n",
      "epoch 90; iter: 0; batch classifier loss: 0.149356; batch adversarial loss: 0.496222\n",
      "epoch 91; iter: 0; batch classifier loss: 0.230158; batch adversarial loss: 0.381588\n",
      "epoch 92; iter: 0; batch classifier loss: 0.224041; batch adversarial loss: 0.421394\n",
      "epoch 93; iter: 0; batch classifier loss: 0.209264; batch adversarial loss: 0.499131\n",
      "epoch 94; iter: 0; batch classifier loss: 0.183683; batch adversarial loss: 0.446717\n",
      "epoch 95; iter: 0; batch classifier loss: 0.211270; batch adversarial loss: 0.484110\n",
      "epoch 96; iter: 0; batch classifier loss: 0.238002; batch adversarial loss: 0.420889\n",
      "epoch 97; iter: 0; batch classifier loss: 0.171334; batch adversarial loss: 0.421113\n",
      "epoch 98; iter: 0; batch classifier loss: 0.192000; batch adversarial loss: 0.396254\n",
      "epoch 99; iter: 0; batch classifier loss: 0.167734; batch adversarial loss: 0.459142\n",
      "epoch 100; iter: 0; batch classifier loss: 0.175504; batch adversarial loss: 0.458614\n",
      "epoch 101; iter: 0; batch classifier loss: 0.138956; batch adversarial loss: 0.471880\n",
      "epoch 102; iter: 0; batch classifier loss: 0.226391; batch adversarial loss: 0.509323\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094635; batch adversarial loss: 0.534994\n",
      "epoch 104; iter: 0; batch classifier loss: 0.167273; batch adversarial loss: 0.384494\n",
      "epoch 105; iter: 0; batch classifier loss: 0.167103; batch adversarial loss: 0.344103\n",
      "epoch 106; iter: 0; batch classifier loss: 0.275669; batch adversarial loss: 0.382334\n",
      "epoch 107; iter: 0; batch classifier loss: 0.225389; batch adversarial loss: 0.484378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.168996; batch adversarial loss: 0.433948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.123011; batch adversarial loss: 0.598636\n",
      "epoch 110; iter: 0; batch classifier loss: 0.181413; batch adversarial loss: 0.534082\n",
      "epoch 111; iter: 0; batch classifier loss: 0.186206; batch adversarial loss: 0.597160\n",
      "epoch 112; iter: 0; batch classifier loss: 0.160024; batch adversarial loss: 0.446628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.135684; batch adversarial loss: 0.433847\n",
      "epoch 114; iter: 0; batch classifier loss: 0.207262; batch adversarial loss: 0.447249\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168980; batch adversarial loss: 0.446475\n",
      "epoch 116; iter: 0; batch classifier loss: 0.161340; batch adversarial loss: 0.458942\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053871; batch adversarial loss: 0.509331\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060106; batch adversarial loss: 0.352060\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048399; batch adversarial loss: 0.468507\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041350; batch adversarial loss: 0.565629\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035343; batch adversarial loss: 0.439506\n",
      "epoch 122; iter: 0; batch classifier loss: 0.088512; batch adversarial loss: 0.378390\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056172; batch adversarial loss: 0.375390\n",
      "epoch 124; iter: 0; batch classifier loss: 0.070794; batch adversarial loss: 0.391829\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035541; batch adversarial loss: 0.423619\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040826; batch adversarial loss: 0.380286\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.497492\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028464; batch adversarial loss: 0.460602\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028492; batch adversarial loss: 0.453247\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056438; batch adversarial loss: 0.375721\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030427; batch adversarial loss: 0.435509\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044721; batch adversarial loss: 0.422782\n",
      "epoch 133; iter: 0; batch classifier loss: 0.063714; batch adversarial loss: 0.446083\n",
      "epoch 134; iter: 0; batch classifier loss: 0.070117; batch adversarial loss: 0.461918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060898; batch adversarial loss: 0.517195\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048086; batch adversarial loss: 0.458619\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060460; batch adversarial loss: 0.437264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.051340; batch adversarial loss: 0.467222\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054368; batch adversarial loss: 0.536334\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043647; batch adversarial loss: 0.393431\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048096; batch adversarial loss: 0.427768\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037119; batch adversarial loss: 0.423119\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036035; batch adversarial loss: 0.444057\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056603; batch adversarial loss: 0.415548\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.468224\n",
      "epoch 146; iter: 0; batch classifier loss: 0.069729; batch adversarial loss: 0.398601\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035424; batch adversarial loss: 0.435246\n",
      "epoch 148; iter: 0; batch classifier loss: 0.065989; batch adversarial loss: 0.517306\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048963; batch adversarial loss: 0.462448\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039545; batch adversarial loss: 0.434550\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048576; batch adversarial loss: 0.475316\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053760; batch adversarial loss: 0.339236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057235; batch adversarial loss: 0.386210\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056615; batch adversarial loss: 0.452809\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040308; batch adversarial loss: 0.384065\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038187; batch adversarial loss: 0.348673\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056816; batch adversarial loss: 0.335448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045367; batch adversarial loss: 0.420389\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028586; batch adversarial loss: 0.419549\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047321; batch adversarial loss: 0.406944\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044565; batch adversarial loss: 0.357977\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039025; batch adversarial loss: 0.396070\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034073; batch adversarial loss: 0.483346\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062513; batch adversarial loss: 0.479683\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045927; batch adversarial loss: 0.444376\n",
      "epoch 166; iter: 0; batch classifier loss: 0.074421; batch adversarial loss: 0.548794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037431; batch adversarial loss: 0.379553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040074; batch adversarial loss: 0.438820\n",
      "epoch 169; iter: 0; batch classifier loss: 0.060513; batch adversarial loss: 0.464108\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058970; batch adversarial loss: 0.469559\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046304; batch adversarial loss: 0.323276\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047572; batch adversarial loss: 0.375251\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048688; batch adversarial loss: 0.506910\n",
      "epoch 174; iter: 0; batch classifier loss: 0.070181; batch adversarial loss: 0.379090\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066503; batch adversarial loss: 0.410261\n",
      "epoch 176; iter: 0; batch classifier loss: 0.052288; batch adversarial loss: 0.372310\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046417; batch adversarial loss: 0.361275\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044520; batch adversarial loss: 0.471662\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045597; batch adversarial loss: 0.478159\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048044; batch adversarial loss: 0.502971\n",
      "epoch 181; iter: 0; batch classifier loss: 0.066796; batch adversarial loss: 0.400430\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049317; batch adversarial loss: 0.423860\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040818; batch adversarial loss: 0.344407\n",
      "epoch 184; iter: 0; batch classifier loss: 0.066661; batch adversarial loss: 0.406987\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060590; batch adversarial loss: 0.428383\n",
      "epoch 186; iter: 0; batch classifier loss: 0.069791; batch adversarial loss: 0.411696\n",
      "epoch 187; iter: 0; batch classifier loss: 0.058906; batch adversarial loss: 0.432807\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044450; batch adversarial loss: 0.439654\n",
      "epoch 189; iter: 0; batch classifier loss: 0.065652; batch adversarial loss: 0.410248\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031074; batch adversarial loss: 0.405255\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.443876\n",
      "epoch 192; iter: 0; batch classifier loss: 0.057150; batch adversarial loss: 0.379552\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043987; batch adversarial loss: 0.430208\n",
      "epoch 194; iter: 0; batch classifier loss: 0.050626; batch adversarial loss: 0.429363\n",
      "epoch 195; iter: 0; batch classifier loss: 0.055538; batch adversarial loss: 0.409504\n",
      "epoch 196; iter: 0; batch classifier loss: 0.060118; batch adversarial loss: 0.413747\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045492; batch adversarial loss: 0.370026\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054395; batch adversarial loss: 0.317980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.518306\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722417; batch adversarial loss: 0.654107\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518375; batch adversarial loss: 0.637622\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395489; batch adversarial loss: 0.628620\n",
      "epoch 3; iter: 0; batch classifier loss: 0.492838; batch adversarial loss: 0.616526\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510103; batch adversarial loss: 0.598784\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521141; batch adversarial loss: 0.591704\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512647; batch adversarial loss: 0.607463\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541653; batch adversarial loss: 0.562013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430982; batch adversarial loss: 0.547324\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314197; batch adversarial loss: 0.567697\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302088; batch adversarial loss: 0.569945\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458177; batch adversarial loss: 0.484133\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357925; batch adversarial loss: 0.466882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348963; batch adversarial loss: 0.541390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292885; batch adversarial loss: 0.509425\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338634; batch adversarial loss: 0.543394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.272319; batch adversarial loss: 0.472389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265496; batch adversarial loss: 0.540314\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238317; batch adversarial loss: 0.498119\n",
      "epoch 19; iter: 0; batch classifier loss: 0.267818; batch adversarial loss: 0.507019\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256954; batch adversarial loss: 0.487729\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263976; batch adversarial loss: 0.466776\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284891; batch adversarial loss: 0.495275\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222998; batch adversarial loss: 0.392412\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331204; batch adversarial loss: 0.464292\n",
      "epoch 25; iter: 0; batch classifier loss: 0.249048; batch adversarial loss: 0.528239\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232353; batch adversarial loss: 0.362427\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203184; batch adversarial loss: 0.446730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.258495; batch adversarial loss: 0.461143\n",
      "epoch 29; iter: 0; batch classifier loss: 0.273904; batch adversarial loss: 0.392755\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257774; batch adversarial loss: 0.491990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220329; batch adversarial loss: 0.504699\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246822; batch adversarial loss: 0.465376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.211800; batch adversarial loss: 0.538835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.234628; batch adversarial loss: 0.433128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232465; batch adversarial loss: 0.474047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.221026; batch adversarial loss: 0.512677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187432; batch adversarial loss: 0.454007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241701; batch adversarial loss: 0.447021\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133541; batch adversarial loss: 0.519213\n",
      "epoch 40; iter: 0; batch classifier loss: 0.180359; batch adversarial loss: 0.450683\n",
      "epoch 41; iter: 0; batch classifier loss: 0.271421; batch adversarial loss: 0.438999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.220239; batch adversarial loss: 0.549974\n",
      "epoch 43; iter: 0; batch classifier loss: 0.313163; batch adversarial loss: 0.414991\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174830; batch adversarial loss: 0.550828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133677; batch adversarial loss: 0.436086\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111264; batch adversarial loss: 0.436117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113054; batch adversarial loss: 0.348065\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114775; batch adversarial loss: 0.434377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100032; batch adversarial loss: 0.435615\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081496; batch adversarial loss: 0.484941\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071407; batch adversarial loss: 0.550567\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106334; batch adversarial loss: 0.442879\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138090; batch adversarial loss: 0.436031\n",
      "epoch 54; iter: 0; batch classifier loss: 0.211922; batch adversarial loss: 0.482901\n",
      "epoch 55; iter: 0; batch classifier loss: 0.170450; batch adversarial loss: 0.434870\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142961; batch adversarial loss: 0.507085\n",
      "epoch 57; iter: 0; batch classifier loss: 0.139102; batch adversarial loss: 0.407569\n",
      "epoch 58; iter: 0; batch classifier loss: 0.119715; batch adversarial loss: 0.407536\n",
      "epoch 59; iter: 0; batch classifier loss: 0.061741; batch adversarial loss: 0.501073\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063560; batch adversarial loss: 0.555958\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113736; batch adversarial loss: 0.444776\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084456; batch adversarial loss: 0.389583\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087557; batch adversarial loss: 0.453075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.113564; batch adversarial loss: 0.527779\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126905; batch adversarial loss: 0.401695\n",
      "epoch 66; iter: 0; batch classifier loss: 0.143381; batch adversarial loss: 0.487838\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111267; batch adversarial loss: 0.543448\n",
      "epoch 68; iter: 0; batch classifier loss: 0.125866; batch adversarial loss: 0.491639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141632; batch adversarial loss: 0.409731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061668; batch adversarial loss: 0.459904\n",
      "epoch 71; iter: 0; batch classifier loss: 0.121953; batch adversarial loss: 0.409625\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115705; batch adversarial loss: 0.428645\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084738; batch adversarial loss: 0.446865\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099587; batch adversarial loss: 0.508027\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104816; batch adversarial loss: 0.519210\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090779; batch adversarial loss: 0.475774\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106486; batch adversarial loss: 0.481321\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075220; batch adversarial loss: 0.523083\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101532; batch adversarial loss: 0.456200\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073133; batch adversarial loss: 0.476732\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117813; batch adversarial loss: 0.426534\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099032; batch adversarial loss: 0.473156\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077658; batch adversarial loss: 0.536092\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063719; batch adversarial loss: 0.508066\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080775; batch adversarial loss: 0.426659\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073479; batch adversarial loss: 0.458369\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054620; batch adversarial loss: 0.549965\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051070; batch adversarial loss: 0.370635\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052204; batch adversarial loss: 0.430082\n",
      "epoch 90; iter: 0; batch classifier loss: 0.027670; batch adversarial loss: 0.509533\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039091; batch adversarial loss: 0.444181\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087366; batch adversarial loss: 0.378461\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044814; batch adversarial loss: 0.436203\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049709; batch adversarial loss: 0.424165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049225; batch adversarial loss: 0.462534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029644; batch adversarial loss: 0.434938\n",
      "epoch 97; iter: 0; batch classifier loss: 0.018932; batch adversarial loss: 0.502760\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033081; batch adversarial loss: 0.464083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039795; batch adversarial loss: 0.447582\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064278; batch adversarial loss: 0.419901\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035363; batch adversarial loss: 0.540281\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033384; batch adversarial loss: 0.428539\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040900; batch adversarial loss: 0.486797\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046217; batch adversarial loss: 0.509741\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026413; batch adversarial loss: 0.481419\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042420; batch adversarial loss: 0.399546\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052000; batch adversarial loss: 0.480557\n",
      "epoch 108; iter: 0; batch classifier loss: 0.013725; batch adversarial loss: 0.441753\n",
      "epoch 109; iter: 0; batch classifier loss: 0.013113; batch adversarial loss: 0.541383\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041158; batch adversarial loss: 0.439358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026538; batch adversarial loss: 0.429157\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017170; batch adversarial loss: 0.497648\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.390507\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045919; batch adversarial loss: 0.477418\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024530; batch adversarial loss: 0.407491\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028117; batch adversarial loss: 0.472603\n",
      "epoch 117; iter: 0; batch classifier loss: 0.011264; batch adversarial loss: 0.440947\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025691; batch adversarial loss: 0.365393\n",
      "epoch 119; iter: 0; batch classifier loss: 0.010283; batch adversarial loss: 0.421730\n",
      "epoch 120; iter: 0; batch classifier loss: 0.020842; batch adversarial loss: 0.453080\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035458; batch adversarial loss: 0.489174\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034373; batch adversarial loss: 0.457435\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064587; batch adversarial loss: 0.500339\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020408; batch adversarial loss: 0.408960\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051327; batch adversarial loss: 0.481686\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031285; batch adversarial loss: 0.471534\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020574; batch adversarial loss: 0.472337\n",
      "epoch 128; iter: 0; batch classifier loss: 0.009152; batch adversarial loss: 0.451560\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021670; batch adversarial loss: 0.454804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031820; batch adversarial loss: 0.425204\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029781; batch adversarial loss: 0.474035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.028276; batch adversarial loss: 0.375906\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025790; batch adversarial loss: 0.529252\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009648; batch adversarial loss: 0.391739\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021704; batch adversarial loss: 0.478945\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012208; batch adversarial loss: 0.457755\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025269; batch adversarial loss: 0.471496\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034769; batch adversarial loss: 0.485516\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017920; batch adversarial loss: 0.457684\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031171; batch adversarial loss: 0.479691\n",
      "epoch 141; iter: 0; batch classifier loss: 0.008092; batch adversarial loss: 0.538543\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028805; batch adversarial loss: 0.351187\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031301; batch adversarial loss: 0.447636\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012219; batch adversarial loss: 0.436494\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026658; batch adversarial loss: 0.584224\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037160; batch adversarial loss: 0.536461\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013818; batch adversarial loss: 0.476245\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030028; batch adversarial loss: 0.464666\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017588; batch adversarial loss: 0.491095\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016041; batch adversarial loss: 0.429509\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018601; batch adversarial loss: 0.451132\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015507; batch adversarial loss: 0.485401\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035999; batch adversarial loss: 0.468624\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.455458\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011483; batch adversarial loss: 0.412870\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013425; batch adversarial loss: 0.462164\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015347; batch adversarial loss: 0.397286\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007789; batch adversarial loss: 0.469119\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007150; batch adversarial loss: 0.542487\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013185; batch adversarial loss: 0.468101\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053756; batch adversarial loss: 0.368574\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021628; batch adversarial loss: 0.532077\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010371; batch adversarial loss: 0.422129\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032330; batch adversarial loss: 0.456291\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019523; batch adversarial loss: 0.566009\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014051; batch adversarial loss: 0.477430\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004335; batch adversarial loss: 0.550706\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.479361\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019268; batch adversarial loss: 0.515524\n",
      "epoch 170; iter: 0; batch classifier loss: 0.004549; batch adversarial loss: 0.488258\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018718; batch adversarial loss: 0.429547\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032951; batch adversarial loss: 0.409965\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026760; batch adversarial loss: 0.434414\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041114; batch adversarial loss: 0.447405\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014317; batch adversarial loss: 0.524189\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025505; batch adversarial loss: 0.419875\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004254; batch adversarial loss: 0.358214\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036624; batch adversarial loss: 0.424643\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024084; batch adversarial loss: 0.406580\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015809; batch adversarial loss: 0.406950\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027843; batch adversarial loss: 0.470421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033177; batch adversarial loss: 0.459661\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005197; batch adversarial loss: 0.452400\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017942; batch adversarial loss: 0.423757\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006855; batch adversarial loss: 0.484120\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005764; batch adversarial loss: 0.489678\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018731; batch adversarial loss: 0.400304\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014831; batch adversarial loss: 0.470100\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016426; batch adversarial loss: 0.457268\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013715; batch adversarial loss: 0.528506\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014719; batch adversarial loss: 0.522190\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007599; batch adversarial loss: 0.465394\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.434362\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008742; batch adversarial loss: 0.505192\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008436; batch adversarial loss: 0.494928\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008983; batch adversarial loss: 0.531583\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008460; batch adversarial loss: 0.408352\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002846; batch adversarial loss: 0.459268\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002946; batch adversarial loss: 0.521352\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721727; batch adversarial loss: 0.893910\n",
      "epoch 1; iter: 0; batch classifier loss: 0.475461; batch adversarial loss: 1.034171\n",
      "epoch 2; iter: 0; batch classifier loss: 0.337467; batch adversarial loss: 1.004282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.292253; batch adversarial loss: 0.882419\n",
      "epoch 4; iter: 0; batch classifier loss: 0.263660; batch adversarial loss: 0.818708\n",
      "epoch 5; iter: 0; batch classifier loss: 0.301964; batch adversarial loss: 0.829050\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308486; batch adversarial loss: 0.756934\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272650; batch adversarial loss: 0.682370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282344; batch adversarial loss: 0.672354\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260016; batch adversarial loss: 0.679585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288472; batch adversarial loss: 0.622745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.277807; batch adversarial loss: 0.548825\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369990; batch adversarial loss: 0.553203\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275271; batch adversarial loss: 0.586863\n",
      "epoch 14; iter: 0; batch classifier loss: 0.218880; batch adversarial loss: 0.502565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208138; batch adversarial loss: 0.534393\n",
      "epoch 16; iter: 0; batch classifier loss: 0.256767; batch adversarial loss: 0.518261\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275886; batch adversarial loss: 0.494561\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260009; batch adversarial loss: 0.447010\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277426; batch adversarial loss: 0.493852\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227152; batch adversarial loss: 0.457382\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248873; batch adversarial loss: 0.471879\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175559; batch adversarial loss: 0.468583\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190044; batch adversarial loss: 0.405543\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182509; batch adversarial loss: 0.407897\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172330; batch adversarial loss: 0.449203\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168665; batch adversarial loss: 0.399102\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184554; batch adversarial loss: 0.341299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.159522; batch adversarial loss: 0.383081\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154562; batch adversarial loss: 0.451252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.133561; batch adversarial loss: 0.381880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132965; batch adversarial loss: 0.379286\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140526; batch adversarial loss: 0.485384\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161519; batch adversarial loss: 0.431358\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152304; batch adversarial loss: 0.520630\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136413; batch adversarial loss: 0.374000\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126643; batch adversarial loss: 0.437759\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120589; batch adversarial loss: 0.429480\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118407; batch adversarial loss: 0.445196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143374; batch adversarial loss: 0.411156\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123100; batch adversarial loss: 0.368310\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133429; batch adversarial loss: 0.403083\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152878; batch adversarial loss: 0.423334\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121871; batch adversarial loss: 0.480135\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117651; batch adversarial loss: 0.392286\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078048; batch adversarial loss: 0.421249\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081545; batch adversarial loss: 0.476805\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123523; batch adversarial loss: 0.414340\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082407; batch adversarial loss: 0.444390\n",
      "epoch 49; iter: 0; batch classifier loss: 0.166541; batch adversarial loss: 0.360730\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108357; batch adversarial loss: 0.374669\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070857; batch adversarial loss: 0.502457\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093152; batch adversarial loss: 0.401183\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064693; batch adversarial loss: 0.374716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093894; batch adversarial loss: 0.378042\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093117; batch adversarial loss: 0.366581\n",
      "epoch 56; iter: 0; batch classifier loss: 0.135223; batch adversarial loss: 0.444551\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086401; batch adversarial loss: 0.425124\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089856; batch adversarial loss: 0.500571\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079524; batch adversarial loss: 0.452613\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072886; batch adversarial loss: 0.328757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088614; batch adversarial loss: 0.358433\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090130; batch adversarial loss: 0.453547\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084166; batch adversarial loss: 0.389236\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124514; batch adversarial loss: 0.382330\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080224; batch adversarial loss: 0.390427\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095877; batch adversarial loss: 0.406128\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091795; batch adversarial loss: 0.433320\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068395; batch adversarial loss: 0.445751\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093321; batch adversarial loss: 0.356861\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083881; batch adversarial loss: 0.416151\n",
      "epoch 71; iter: 0; batch classifier loss: 0.085011; batch adversarial loss: 0.402384\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090251; batch adversarial loss: 0.422080\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063375; batch adversarial loss: 0.436568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054074; batch adversarial loss: 0.435973\n",
      "epoch 75; iter: 0; batch classifier loss: 0.046010; batch adversarial loss: 0.451989\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071184; batch adversarial loss: 0.368774\n",
      "epoch 77; iter: 0; batch classifier loss: 0.025220; batch adversarial loss: 0.424751\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043339; batch adversarial loss: 0.355039\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055643; batch adversarial loss: 0.429878\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083238; batch adversarial loss: 0.422331\n",
      "epoch 81; iter: 0; batch classifier loss: 0.031508; batch adversarial loss: 0.404354\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069277; batch adversarial loss: 0.346780\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059743; batch adversarial loss: 0.359026\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067684; batch adversarial loss: 0.389759\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054972; batch adversarial loss: 0.334633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.030925; batch adversarial loss: 0.394348\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040132; batch adversarial loss: 0.391003\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037567; batch adversarial loss: 0.426976\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.427515\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044191; batch adversarial loss: 0.443086\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078107; batch adversarial loss: 0.407038\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052263; batch adversarial loss: 0.419206\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054344; batch adversarial loss: 0.376232\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070296; batch adversarial loss: 0.323559\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062033; batch adversarial loss: 0.341289\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060632; batch adversarial loss: 0.433779\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037805; batch adversarial loss: 0.366626\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046262; batch adversarial loss: 0.498791\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040093; batch adversarial loss: 0.414054\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033139; batch adversarial loss: 0.437741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077445; batch adversarial loss: 0.502838\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038042; batch adversarial loss: 0.462665\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041619; batch adversarial loss: 0.483180\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028094; batch adversarial loss: 0.483615\n",
      "epoch 105; iter: 0; batch classifier loss: 0.018827; batch adversarial loss: 0.470363\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042003; batch adversarial loss: 0.387912\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061076; batch adversarial loss: 0.408558\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014002; batch adversarial loss: 0.503279\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036699; batch adversarial loss: 0.316663\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026314; batch adversarial loss: 0.450112\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021949; batch adversarial loss: 0.472594\n",
      "epoch 112; iter: 0; batch classifier loss: 0.020917; batch adversarial loss: 0.463284\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037594; batch adversarial loss: 0.520285\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.416776\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030612; batch adversarial loss: 0.439425\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026824; batch adversarial loss: 0.409942\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021810; batch adversarial loss: 0.451502\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042572; batch adversarial loss: 0.437806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037912; batch adversarial loss: 0.448520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025262; batch adversarial loss: 0.399633\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035847; batch adversarial loss: 0.503215\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037390; batch adversarial loss: 0.349059\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042606; batch adversarial loss: 0.416217\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057477; batch adversarial loss: 0.612334\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.553222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.054956; batch adversarial loss: 0.443961\n",
      "epoch 127; iter: 0; batch classifier loss: 0.095197; batch adversarial loss: 0.445203\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036502; batch adversarial loss: 0.541050\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019458; batch adversarial loss: 0.478165\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053724; batch adversarial loss: 0.505317\n",
      "epoch 131; iter: 0; batch classifier loss: 0.100664; batch adversarial loss: 0.473192\n",
      "epoch 132; iter: 0; batch classifier loss: 0.064441; batch adversarial loss: 0.535431\n",
      "epoch 133; iter: 0; batch classifier loss: 0.135743; batch adversarial loss: 0.602682\n",
      "epoch 134; iter: 0; batch classifier loss: 0.142286; batch adversarial loss: 0.554267\n",
      "epoch 135; iter: 0; batch classifier loss: 0.133614; batch adversarial loss: 0.559052\n",
      "epoch 136; iter: 0; batch classifier loss: 0.073129; batch adversarial loss: 0.450242\n",
      "epoch 137; iter: 0; batch classifier loss: 0.100954; batch adversarial loss: 0.560522\n",
      "epoch 138; iter: 0; batch classifier loss: 0.165874; batch adversarial loss: 0.695054\n",
      "epoch 139; iter: 0; batch classifier loss: 0.094275; batch adversarial loss: 0.547161\n",
      "epoch 140; iter: 0; batch classifier loss: 0.113854; batch adversarial loss: 0.495413\n",
      "epoch 141; iter: 0; batch classifier loss: 0.143003; batch adversarial loss: 0.622119\n",
      "epoch 142; iter: 0; batch classifier loss: 0.161216; batch adversarial loss: 0.601706\n",
      "epoch 143; iter: 0; batch classifier loss: 0.168616; batch adversarial loss: 0.602081\n",
      "epoch 144; iter: 0; batch classifier loss: 0.081347; batch adversarial loss: 0.478354\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061531; batch adversarial loss: 0.439185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.117259; batch adversarial loss: 0.490313\n",
      "epoch 147; iter: 0; batch classifier loss: 0.157035; batch adversarial loss: 0.553442\n",
      "epoch 148; iter: 0; batch classifier loss: 0.124126; batch adversarial loss: 0.567839\n",
      "epoch 149; iter: 0; batch classifier loss: 0.199708; batch adversarial loss: 0.721813\n",
      "epoch 150; iter: 0; batch classifier loss: 0.113966; batch adversarial loss: 0.365821\n",
      "epoch 151; iter: 0; batch classifier loss: 0.097805; batch adversarial loss: 0.481272\n",
      "epoch 152; iter: 0; batch classifier loss: 0.123220; batch adversarial loss: 0.464774\n",
      "epoch 153; iter: 0; batch classifier loss: 0.147755; batch adversarial loss: 0.532868\n",
      "epoch 154; iter: 0; batch classifier loss: 0.165097; batch adversarial loss: 0.480848\n",
      "epoch 155; iter: 0; batch classifier loss: 0.106154; batch adversarial loss: 0.493799\n",
      "epoch 156; iter: 0; batch classifier loss: 0.112421; batch adversarial loss: 0.460556\n",
      "epoch 157; iter: 0; batch classifier loss: 0.172547; batch adversarial loss: 0.636982\n",
      "epoch 158; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.406875\n",
      "epoch 159; iter: 0; batch classifier loss: 0.200475; batch adversarial loss: 0.535761\n",
      "epoch 160; iter: 0; batch classifier loss: 0.104689; batch adversarial loss: 0.491107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.144371; batch adversarial loss: 0.567846\n",
      "epoch 162; iter: 0; batch classifier loss: 0.095305; batch adversarial loss: 0.493930\n",
      "epoch 163; iter: 0; batch classifier loss: 0.198346; batch adversarial loss: 0.589538\n",
      "epoch 164; iter: 0; batch classifier loss: 0.071743; batch adversarial loss: 0.466073\n",
      "epoch 165; iter: 0; batch classifier loss: 0.076578; batch adversarial loss: 0.461058\n",
      "epoch 166; iter: 0; batch classifier loss: 0.126054; batch adversarial loss: 0.497419\n",
      "epoch 167; iter: 0; batch classifier loss: 0.110310; batch adversarial loss: 0.457276\n",
      "epoch 168; iter: 0; batch classifier loss: 0.091774; batch adversarial loss: 0.449786\n",
      "epoch 169; iter: 0; batch classifier loss: 0.153138; batch adversarial loss: 0.563436\n",
      "epoch 170; iter: 0; batch classifier loss: 0.129017; batch adversarial loss: 0.524234\n",
      "epoch 171; iter: 0; batch classifier loss: 0.087126; batch adversarial loss: 0.402217\n",
      "epoch 172; iter: 0; batch classifier loss: 0.115267; batch adversarial loss: 0.452242\n",
      "epoch 173; iter: 0; batch classifier loss: 0.127351; batch adversarial loss: 0.486994\n",
      "epoch 174; iter: 0; batch classifier loss: 0.112343; batch adversarial loss: 0.494561\n",
      "epoch 175; iter: 0; batch classifier loss: 0.142974; batch adversarial loss: 0.455083\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055772; batch adversarial loss: 0.503266\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041142; batch adversarial loss: 0.509816\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034077; batch adversarial loss: 0.421461\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040647; batch adversarial loss: 0.381632\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021064; batch adversarial loss: 0.402248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.056543; batch adversarial loss: 0.521467\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041789; batch adversarial loss: 0.466039\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054959; batch adversarial loss: 0.428043\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050548; batch adversarial loss: 0.474481\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035381; batch adversarial loss: 0.412522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022233; batch adversarial loss: 0.414758\n",
      "epoch 187; iter: 0; batch classifier loss: 0.059136; batch adversarial loss: 0.443644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.054609; batch adversarial loss: 0.417984\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029091; batch adversarial loss: 0.504771\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.411904\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015226; batch adversarial loss: 0.439419\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032446; batch adversarial loss: 0.427862\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029622; batch adversarial loss: 0.332153\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023324; batch adversarial loss: 0.383103\n",
      "epoch 195; iter: 0; batch classifier loss: 0.069379; batch adversarial loss: 0.417126\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038648; batch adversarial loss: 0.374367\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053621; batch adversarial loss: 0.403172\n",
      "epoch 198; iter: 0; batch classifier loss: 0.072527; batch adversarial loss: 0.361384\n",
      "epoch 199; iter: 0; batch classifier loss: 0.059170; batch adversarial loss: 0.478351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671863; batch adversarial loss: 0.523601\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440319; batch adversarial loss: 0.624929\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381579; batch adversarial loss: 0.662436\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383651; batch adversarial loss: 0.557015\n",
      "epoch 4; iter: 0; batch classifier loss: 0.339991; batch adversarial loss: 0.553134\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345571; batch adversarial loss: 0.603396\n",
      "epoch 6; iter: 0; batch classifier loss: 0.384667; batch adversarial loss: 0.559783\n",
      "epoch 7; iter: 0; batch classifier loss: 0.398271; batch adversarial loss: 0.613113\n",
      "epoch 8; iter: 0; batch classifier loss: 0.415906; batch adversarial loss: 0.528789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401354; batch adversarial loss: 0.571379\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510947; batch adversarial loss: 0.595245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.444610; batch adversarial loss: 0.515717\n",
      "epoch 12; iter: 0; batch classifier loss: 0.600734; batch adversarial loss: 0.517545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408019; batch adversarial loss: 0.501718\n",
      "epoch 14; iter: 0; batch classifier loss: 0.418640; batch adversarial loss: 0.454227\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361186; batch adversarial loss: 0.555921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236583; batch adversarial loss: 0.467012\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289218; batch adversarial loss: 0.499326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219215; batch adversarial loss: 0.453533\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198506; batch adversarial loss: 0.532069\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242950; batch adversarial loss: 0.426509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223717; batch adversarial loss: 0.475651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.188759; batch adversarial loss: 0.475100\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164438; batch adversarial loss: 0.475241\n",
      "epoch 24; iter: 0; batch classifier loss: 0.339810; batch adversarial loss: 0.423386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186477; batch adversarial loss: 0.485983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194638; batch adversarial loss: 0.542318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219264; batch adversarial loss: 0.486699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172025; batch adversarial loss: 0.513097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249447; batch adversarial loss: 0.357375\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166481; batch adversarial loss: 0.536023\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155141; batch adversarial loss: 0.454451\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210249; batch adversarial loss: 0.415935\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180785; batch adversarial loss: 0.410642\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197384; batch adversarial loss: 0.430237\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236545; batch adversarial loss: 0.482671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248298; batch adversarial loss: 0.425694\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165788; batch adversarial loss: 0.532403\n",
      "epoch 38; iter: 0; batch classifier loss: 0.246822; batch adversarial loss: 0.439330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332637; batch adversarial loss: 0.407117\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212476; batch adversarial loss: 0.452752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.213987; batch adversarial loss: 0.493426\n",
      "epoch 42; iter: 0; batch classifier loss: 0.240994; batch adversarial loss: 0.501532\n",
      "epoch 43; iter: 0; batch classifier loss: 0.272186; batch adversarial loss: 0.462424\n",
      "epoch 44; iter: 0; batch classifier loss: 0.210173; batch adversarial loss: 0.492381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.252727; batch adversarial loss: 0.440698\n",
      "epoch 46; iter: 0; batch classifier loss: 0.221313; batch adversarial loss: 0.471315\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184753; batch adversarial loss: 0.458941\n",
      "epoch 48; iter: 0; batch classifier loss: 0.290311; batch adversarial loss: 0.460874\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204170; batch adversarial loss: 0.385376\n",
      "epoch 50; iter: 0; batch classifier loss: 0.193531; batch adversarial loss: 0.486247\n",
      "epoch 51; iter: 0; batch classifier loss: 0.354625; batch adversarial loss: 0.422781\n",
      "epoch 52; iter: 0; batch classifier loss: 0.230261; batch adversarial loss: 0.482001\n",
      "epoch 53; iter: 0; batch classifier loss: 0.265671; batch adversarial loss: 0.458280\n",
      "epoch 54; iter: 0; batch classifier loss: 0.229454; batch adversarial loss: 0.487907\n",
      "epoch 55; iter: 0; batch classifier loss: 0.241682; batch adversarial loss: 0.410009\n",
      "epoch 56; iter: 0; batch classifier loss: 0.212930; batch adversarial loss: 0.447236\n",
      "epoch 57; iter: 0; batch classifier loss: 0.224816; batch adversarial loss: 0.460720\n",
      "epoch 58; iter: 0; batch classifier loss: 0.229438; batch adversarial loss: 0.508308\n",
      "epoch 59; iter: 0; batch classifier loss: 0.274418; batch adversarial loss: 0.470954\n",
      "epoch 60; iter: 0; batch classifier loss: 0.272147; batch adversarial loss: 0.434316\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097376; batch adversarial loss: 0.507461\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122217; batch adversarial loss: 0.456216\n",
      "epoch 63; iter: 0; batch classifier loss: 0.154976; batch adversarial loss: 0.382173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348690; batch adversarial loss: 0.447940\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250068; batch adversarial loss: 0.470357\n",
      "epoch 66; iter: 0; batch classifier loss: 0.225615; batch adversarial loss: 0.445789\n",
      "epoch 67; iter: 0; batch classifier loss: 0.177631; batch adversarial loss: 0.421223\n",
      "epoch 68; iter: 0; batch classifier loss: 0.216719; batch adversarial loss: 0.557976\n",
      "epoch 69; iter: 0; batch classifier loss: 0.205774; batch adversarial loss: 0.384317\n",
      "epoch 70; iter: 0; batch classifier loss: 0.270385; batch adversarial loss: 0.372564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.233172; batch adversarial loss: 0.434370\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140802; batch adversarial loss: 0.445420\n",
      "epoch 73; iter: 0; batch classifier loss: 0.211897; batch adversarial loss: 0.359776\n",
      "epoch 74; iter: 0; batch classifier loss: 0.202091; batch adversarial loss: 0.458986\n",
      "epoch 75; iter: 0; batch classifier loss: 0.164065; batch adversarial loss: 0.408513\n",
      "epoch 76; iter: 0; batch classifier loss: 0.192472; batch adversarial loss: 0.457737\n",
      "epoch 77; iter: 0; batch classifier loss: 0.279650; batch adversarial loss: 0.422350\n",
      "epoch 78; iter: 0; batch classifier loss: 0.181745; batch adversarial loss: 0.421570\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151966; batch adversarial loss: 0.346515\n",
      "epoch 80; iter: 0; batch classifier loss: 0.221542; batch adversarial loss: 0.472139\n",
      "epoch 81; iter: 0; batch classifier loss: 0.267605; batch adversarial loss: 0.433968\n",
      "epoch 82; iter: 0; batch classifier loss: 0.163585; batch adversarial loss: 0.409257\n",
      "epoch 83; iter: 0; batch classifier loss: 0.107256; batch adversarial loss: 0.420961\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087694; batch adversarial loss: 0.418443\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075617; batch adversarial loss: 0.467429\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061985; batch adversarial loss: 0.509400\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068732; batch adversarial loss: 0.475555\n",
      "epoch 88; iter: 0; batch classifier loss: 0.114113; batch adversarial loss: 0.466078\n",
      "epoch 89; iter: 0; batch classifier loss: 0.140701; batch adversarial loss: 0.380850\n",
      "epoch 90; iter: 0; batch classifier loss: 0.184079; batch adversarial loss: 0.384418\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122502; batch adversarial loss: 0.564898\n",
      "epoch 92; iter: 0; batch classifier loss: 0.199736; batch adversarial loss: 0.507980\n",
      "epoch 93; iter: 0; batch classifier loss: 0.137492; batch adversarial loss: 0.459860\n",
      "epoch 94; iter: 0; batch classifier loss: 0.248093; batch adversarial loss: 0.486015\n",
      "epoch 95; iter: 0; batch classifier loss: 0.179067; batch adversarial loss: 0.494034\n",
      "epoch 96; iter: 0; batch classifier loss: 0.231427; batch adversarial loss: 0.471669\n",
      "epoch 97; iter: 0; batch classifier loss: 0.238095; batch adversarial loss: 0.411225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.137960; batch adversarial loss: 0.507792\n",
      "epoch 99; iter: 0; batch classifier loss: 0.188187; batch adversarial loss: 0.506938\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205519; batch adversarial loss: 0.398958\n",
      "epoch 101; iter: 0; batch classifier loss: 0.191817; batch adversarial loss: 0.363433\n",
      "epoch 102; iter: 0; batch classifier loss: 0.227226; batch adversarial loss: 0.396104\n",
      "epoch 103; iter: 0; batch classifier loss: 0.137978; batch adversarial loss: 0.410138\n",
      "epoch 104; iter: 0; batch classifier loss: 0.250052; batch adversarial loss: 0.446651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.201765; batch adversarial loss: 0.434891\n",
      "epoch 106; iter: 0; batch classifier loss: 0.251145; batch adversarial loss: 0.409682\n",
      "epoch 107; iter: 0; batch classifier loss: 0.186195; batch adversarial loss: 0.471240\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063495; batch adversarial loss: 0.433572\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063221; batch adversarial loss: 0.370658\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040036; batch adversarial loss: 0.441704\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034336; batch adversarial loss: 0.424640\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045177; batch adversarial loss: 0.489661\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020952; batch adversarial loss: 0.566000\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037662; batch adversarial loss: 0.464575\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077865; batch adversarial loss: 0.364856\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.430521\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041867; batch adversarial loss: 0.526066\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031241; batch adversarial loss: 0.494866\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041228; batch adversarial loss: 0.395943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.038734; batch adversarial loss: 0.444720\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047753; batch adversarial loss: 0.362203\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067226; batch adversarial loss: 0.475215\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060156; batch adversarial loss: 0.398460\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058484; batch adversarial loss: 0.399838\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020608; batch adversarial loss: 0.456253\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057790; batch adversarial loss: 0.462256\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035171; batch adversarial loss: 0.464072\n",
      "epoch 128; iter: 0; batch classifier loss: 0.100203; batch adversarial loss: 0.452576\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040609; batch adversarial loss: 0.475269\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032313; batch adversarial loss: 0.469753\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037386; batch adversarial loss: 0.406649\n",
      "epoch 132; iter: 0; batch classifier loss: 0.067244; batch adversarial loss: 0.447112\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053904; batch adversarial loss: 0.455671\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051663; batch adversarial loss: 0.418120\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072843; batch adversarial loss: 0.368153\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047253; batch adversarial loss: 0.376726\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067739; batch adversarial loss: 0.384772\n",
      "epoch 138; iter: 0; batch classifier loss: 0.075211; batch adversarial loss: 0.432440\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042955; batch adversarial loss: 0.434590\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.366833\n",
      "epoch 141; iter: 0; batch classifier loss: 0.066710; batch adversarial loss: 0.386202\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042573; batch adversarial loss: 0.373980\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055636; batch adversarial loss: 0.488741\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045648; batch adversarial loss: 0.433985\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030802; batch adversarial loss: 0.319259\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038954; batch adversarial loss: 0.504377\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030229; batch adversarial loss: 0.433134\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029729; batch adversarial loss: 0.396877\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025464; batch adversarial loss: 0.364826\n",
      "epoch 150; iter: 0; batch classifier loss: 0.086565; batch adversarial loss: 0.445733\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060133; batch adversarial loss: 0.414262\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017579; batch adversarial loss: 0.429098\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066175; batch adversarial loss: 0.467073\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057348; batch adversarial loss: 0.461285\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037402; batch adversarial loss: 0.605410\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036455; batch adversarial loss: 0.468516\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016579; batch adversarial loss: 0.412718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030225; batch adversarial loss: 0.390002\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.379958\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047729; batch adversarial loss: 0.296067\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046069; batch adversarial loss: 0.451792\n",
      "epoch 162; iter: 0; batch classifier loss: 0.049058; batch adversarial loss: 0.523752\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048140; batch adversarial loss: 0.516930\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053912; batch adversarial loss: 0.513971\n",
      "epoch 165; iter: 0; batch classifier loss: 0.061850; batch adversarial loss: 0.429423\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034726; batch adversarial loss: 0.385087\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068312; batch adversarial loss: 0.467202\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039410; batch adversarial loss: 0.349229\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052594; batch adversarial loss: 0.369670\n",
      "epoch 170; iter: 0; batch classifier loss: 0.056262; batch adversarial loss: 0.531491\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029506; batch adversarial loss: 0.425725\n",
      "epoch 172; iter: 0; batch classifier loss: 0.056200; batch adversarial loss: 0.469950\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040304; batch adversarial loss: 0.437256\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024688; batch adversarial loss: 0.363560\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038292; batch adversarial loss: 0.387615\n",
      "epoch 176; iter: 0; batch classifier loss: 0.051957; batch adversarial loss: 0.312869\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.454655\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.345233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041317; batch adversarial loss: 0.404515\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049844; batch adversarial loss: 0.425018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.062531; batch adversarial loss: 0.478590\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.389541\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029778; batch adversarial loss: 0.407574\n",
      "epoch 184; iter: 0; batch classifier loss: 0.061396; batch adversarial loss: 0.392831\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054606; batch adversarial loss: 0.490904\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037192; batch adversarial loss: 0.421413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040077; batch adversarial loss: 0.428378\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052321; batch adversarial loss: 0.450055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.055133; batch adversarial loss: 0.464149\n",
      "epoch 190; iter: 0; batch classifier loss: 0.066448; batch adversarial loss: 0.350661\n",
      "epoch 191; iter: 0; batch classifier loss: 0.049268; batch adversarial loss: 0.406505\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042043; batch adversarial loss: 0.433574\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032772; batch adversarial loss: 0.411688\n",
      "epoch 194; iter: 0; batch classifier loss: 0.079478; batch adversarial loss: 0.421872\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020832; batch adversarial loss: 0.441786\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046187; batch adversarial loss: 0.534067\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037163; batch adversarial loss: 0.381807\n",
      "epoch 198; iter: 0; batch classifier loss: 0.065298; batch adversarial loss: 0.408800\n",
      "epoch 199; iter: 0; batch classifier loss: 0.057183; batch adversarial loss: 0.362380\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681309; batch adversarial loss: 0.587381\n",
      "epoch 1; iter: 0; batch classifier loss: 0.378946; batch adversarial loss: 0.603388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.389846; batch adversarial loss: 0.548806\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300465; batch adversarial loss: 0.565140\n",
      "epoch 4; iter: 0; batch classifier loss: 0.275249; batch adversarial loss: 0.535721\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308849; batch adversarial loss: 0.542777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317410; batch adversarial loss: 0.626854\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351127; batch adversarial loss: 0.568373\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304615; batch adversarial loss: 0.566041\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291301; batch adversarial loss: 0.478092\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354225; batch adversarial loss: 0.538085\n",
      "epoch 11; iter: 0; batch classifier loss: 0.249760; batch adversarial loss: 0.542186\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282457; batch adversarial loss: 0.565178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269941; batch adversarial loss: 0.529899\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321932; batch adversarial loss: 0.531158\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261228; batch adversarial loss: 0.421988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.236580; batch adversarial loss: 0.498031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348506; batch adversarial loss: 0.539855\n",
      "epoch 18; iter: 0; batch classifier loss: 0.406228; batch adversarial loss: 0.548900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468706; batch adversarial loss: 0.458983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433088; batch adversarial loss: 0.493572\n",
      "epoch 21; iter: 0; batch classifier loss: 0.301602; batch adversarial loss: 0.457510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.164040; batch adversarial loss: 0.534330\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145919; batch adversarial loss: 0.431019\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169354; batch adversarial loss: 0.437720\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167101; batch adversarial loss: 0.438101\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157172; batch adversarial loss: 0.433897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177081; batch adversarial loss: 0.464000\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167155; batch adversarial loss: 0.473882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137374; batch adversarial loss: 0.370409\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159595; batch adversarial loss: 0.439197\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149296; batch adversarial loss: 0.383278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111541; batch adversarial loss: 0.453238\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131044; batch adversarial loss: 0.375065\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100918; batch adversarial loss: 0.403492\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126812; batch adversarial loss: 0.521157\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111801; batch adversarial loss: 0.437542\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127118; batch adversarial loss: 0.379950\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124277; batch adversarial loss: 0.464458\n",
      "epoch 39; iter: 0; batch classifier loss: 0.071502; batch adversarial loss: 0.478749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148651; batch adversarial loss: 0.452673\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115491; batch adversarial loss: 0.437921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.070337; batch adversarial loss: 0.484976\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105744; batch adversarial loss: 0.356371\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133722; batch adversarial loss: 0.406746\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114237; batch adversarial loss: 0.434825\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108657; batch adversarial loss: 0.487399\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108215; batch adversarial loss: 0.511394\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096574; batch adversarial loss: 0.395276\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085202; batch adversarial loss: 0.438788\n",
      "epoch 50; iter: 0; batch classifier loss: 0.060599; batch adversarial loss: 0.565461\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078274; batch adversarial loss: 0.389304\n",
      "epoch 52; iter: 0; batch classifier loss: 0.057426; batch adversarial loss: 0.430803\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081227; batch adversarial loss: 0.518126\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090033; batch adversarial loss: 0.490387\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068831; batch adversarial loss: 0.488106\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085380; batch adversarial loss: 0.292582\n",
      "epoch 57; iter: 0; batch classifier loss: 0.045081; batch adversarial loss: 0.315554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102165; batch adversarial loss: 0.436939\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087087; batch adversarial loss: 0.439524\n",
      "epoch 60; iter: 0; batch classifier loss: 0.121438; batch adversarial loss: 0.374958\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087500; batch adversarial loss: 0.418326\n",
      "epoch 62; iter: 0; batch classifier loss: 0.039575; batch adversarial loss: 0.490695\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060029; batch adversarial loss: 0.486889\n",
      "epoch 64; iter: 0; batch classifier loss: 0.166337; batch adversarial loss: 0.399307\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084415; batch adversarial loss: 0.535134\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076909; batch adversarial loss: 0.337930\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063384; batch adversarial loss: 0.378338\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116266; batch adversarial loss: 0.437423\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168154; batch adversarial loss: 0.440748\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113516; batch adversarial loss: 0.408535\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081958; batch adversarial loss: 0.420135\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072243; batch adversarial loss: 0.511766\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090075; batch adversarial loss: 0.405075\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066876; batch adversarial loss: 0.447126\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059910; batch adversarial loss: 0.467421\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075367; batch adversarial loss: 0.498282\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074466; batch adversarial loss: 0.478666\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118002; batch adversarial loss: 0.375510\n",
      "epoch 79; iter: 0; batch classifier loss: 0.100171; batch adversarial loss: 0.449326\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078398; batch adversarial loss: 0.445426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064304; batch adversarial loss: 0.412951\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058310; batch adversarial loss: 0.409768\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085255; batch adversarial loss: 0.467509\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050305; batch adversarial loss: 0.374049\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078756; batch adversarial loss: 0.516860\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104257; batch adversarial loss: 0.463827\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058815; batch adversarial loss: 0.525049\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082027; batch adversarial loss: 0.368837\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065591; batch adversarial loss: 0.438910\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061450; batch adversarial loss: 0.409663\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044968; batch adversarial loss: 0.419004\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081895; batch adversarial loss: 0.455472\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045327; batch adversarial loss: 0.556204\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042376; batch adversarial loss: 0.490788\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104229; batch adversarial loss: 0.503218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061073; batch adversarial loss: 0.481998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078869; batch adversarial loss: 0.513555\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047731; batch adversarial loss: 0.546941\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.535293\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066829; batch adversarial loss: 0.437051\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071770; batch adversarial loss: 0.481957\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091194; batch adversarial loss: 0.385090\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038760; batch adversarial loss: 0.405641\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079709; batch adversarial loss: 0.459288\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067393; batch adversarial loss: 0.501098\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052446; batch adversarial loss: 0.496744\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038742; batch adversarial loss: 0.472684\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065119; batch adversarial loss: 0.420542\n",
      "epoch 109; iter: 0; batch classifier loss: 0.120262; batch adversarial loss: 0.492911\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069305; batch adversarial loss: 0.355381\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065225; batch adversarial loss: 0.372640\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025987; batch adversarial loss: 0.388100\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059702; batch adversarial loss: 0.442835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.073163; batch adversarial loss: 0.524089\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031256; batch adversarial loss: 0.373974\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078048; batch adversarial loss: 0.407534\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055542; batch adversarial loss: 0.524041\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073048; batch adversarial loss: 0.315347\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035728; batch adversarial loss: 0.440723\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062638; batch adversarial loss: 0.439361\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036568; batch adversarial loss: 0.358371\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024943; batch adversarial loss: 0.511321\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025704; batch adversarial loss: 0.385200\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050393; batch adversarial loss: 0.429347\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019829; batch adversarial loss: 0.450859\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055207; batch adversarial loss: 0.406118\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042286; batch adversarial loss: 0.433227\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.586145\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021204; batch adversarial loss: 0.510534\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059173; batch adversarial loss: 0.398723\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038597; batch adversarial loss: 0.375602\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030129; batch adversarial loss: 0.396869\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061920; batch adversarial loss: 0.443921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066073; batch adversarial loss: 0.423278\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033085; batch adversarial loss: 0.389997\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012313; batch adversarial loss: 0.402690\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026799; batch adversarial loss: 0.443726\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023027; batch adversarial loss: 0.553863\n",
      "epoch 139; iter: 0; batch classifier loss: 0.081522; batch adversarial loss: 0.427260\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021599; batch adversarial loss: 0.530815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.067555; batch adversarial loss: 0.389633\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014474; batch adversarial loss: 0.535767\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048094; batch adversarial loss: 0.486637\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031698; batch adversarial loss: 0.487365\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014369; batch adversarial loss: 0.399702\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018758; batch adversarial loss: 0.479016\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014464; batch adversarial loss: 0.378923\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057551; batch adversarial loss: 0.482898\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023505; batch adversarial loss: 0.426600\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019539; batch adversarial loss: 0.465501\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032290; batch adversarial loss: 0.484102\n",
      "epoch 152; iter: 0; batch classifier loss: 0.054823; batch adversarial loss: 0.435176\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028784; batch adversarial loss: 0.451652\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055692; batch adversarial loss: 0.422127\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017678; batch adversarial loss: 0.532837\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015401; batch adversarial loss: 0.432020\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037566; batch adversarial loss: 0.397818\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007407; batch adversarial loss: 0.503502\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008261; batch adversarial loss: 0.482921\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027652; batch adversarial loss: 0.412941\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010830; batch adversarial loss: 0.433358\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023137; batch adversarial loss: 0.364676\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023023; batch adversarial loss: 0.463846\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022404; batch adversarial loss: 0.477079\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011836; batch adversarial loss: 0.450176\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023045; batch adversarial loss: 0.333096\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028906; batch adversarial loss: 0.486638\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052854; batch adversarial loss: 0.436150\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007950; batch adversarial loss: 0.484031\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030499; batch adversarial loss: 0.412906\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019066; batch adversarial loss: 0.505273\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018392; batch adversarial loss: 0.340853\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010772; batch adversarial loss: 0.402692\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039731; batch adversarial loss: 0.377655\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.418003\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029744; batch adversarial loss: 0.537726\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017101; batch adversarial loss: 0.439806\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027671; batch adversarial loss: 0.472505\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036483; batch adversarial loss: 0.410997\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021048; batch adversarial loss: 0.444380\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039819; batch adversarial loss: 0.435393\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010987; batch adversarial loss: 0.486052\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046736; batch adversarial loss: 0.446497\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046654; batch adversarial loss: 0.456436\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.417901\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015513; batch adversarial loss: 0.424508\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015234; batch adversarial loss: 0.442065\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041316; batch adversarial loss: 0.374869\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042048; batch adversarial loss: 0.462791\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027318; batch adversarial loss: 0.362490\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019718; batch adversarial loss: 0.497645\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021272; batch adversarial loss: 0.448809\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005062; batch adversarial loss: 0.396381\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012907; batch adversarial loss: 0.424993\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042125; batch adversarial loss: 0.370013\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043093; batch adversarial loss: 0.491077\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017521; batch adversarial loss: 0.446499\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.452396\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041906; batch adversarial loss: 0.451706\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714002; batch adversarial loss: 0.656631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449841; batch adversarial loss: 0.638289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.475722; batch adversarial loss: 0.616228\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417455; batch adversarial loss: 0.606010\n",
      "epoch 4; iter: 0; batch classifier loss: 0.413554; batch adversarial loss: 0.592495\n",
      "epoch 5; iter: 0; batch classifier loss: 0.432540; batch adversarial loss: 0.600300\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536296; batch adversarial loss: 0.592420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595327; batch adversarial loss: 0.523384\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582141; batch adversarial loss: 0.549143\n",
      "epoch 9; iter: 0; batch classifier loss: 0.463607; batch adversarial loss: 0.541315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.414943; batch adversarial loss: 0.530894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370152; batch adversarial loss: 0.549404\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366988; batch adversarial loss: 0.508182\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356568; batch adversarial loss: 0.522984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.425355; batch adversarial loss: 0.445800\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343218; batch adversarial loss: 0.540224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336669; batch adversarial loss: 0.527191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374917; batch adversarial loss: 0.431620\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302995; batch adversarial loss: 0.451810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306952; batch adversarial loss: 0.461996\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279979; batch adversarial loss: 0.456041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263896; batch adversarial loss: 0.486779\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228056; batch adversarial loss: 0.489037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288678; batch adversarial loss: 0.427362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203017; batch adversarial loss: 0.446550\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278380; batch adversarial loss: 0.546815\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191803; batch adversarial loss: 0.462064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262134; batch adversarial loss: 0.467380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227586; batch adversarial loss: 0.428692\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180610; batch adversarial loss: 0.425247\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208679; batch adversarial loss: 0.321397\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186880; batch adversarial loss: 0.471130\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172162; batch adversarial loss: 0.506261\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177350; batch adversarial loss: 0.481128\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205026; batch adversarial loss: 0.475976\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227236; batch adversarial loss: 0.455465\n",
      "epoch 36; iter: 0; batch classifier loss: 0.181815; batch adversarial loss: 0.485890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187983; batch adversarial loss: 0.453740\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221438; batch adversarial loss: 0.389823\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195175; batch adversarial loss: 0.378959\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217251; batch adversarial loss: 0.514459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.152834; batch adversarial loss: 0.506034\n",
      "epoch 42; iter: 0; batch classifier loss: 0.265960; batch adversarial loss: 0.409800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186252; batch adversarial loss: 0.475041\n",
      "epoch 44; iter: 0; batch classifier loss: 0.157473; batch adversarial loss: 0.469250\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194412; batch adversarial loss: 0.457338\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122751; batch adversarial loss: 0.549441\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155902; batch adversarial loss: 0.409731\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122679; batch adversarial loss: 0.505394\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143351; batch adversarial loss: 0.391973\n",
      "epoch 50; iter: 0; batch classifier loss: 0.179712; batch adversarial loss: 0.464394\n",
      "epoch 51; iter: 0; batch classifier loss: 0.163960; batch adversarial loss: 0.458472\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120167; batch adversarial loss: 0.383240\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139935; batch adversarial loss: 0.468033\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100954; batch adversarial loss: 0.500645\n",
      "epoch 55; iter: 0; batch classifier loss: 0.139919; batch adversarial loss: 0.412963\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124448; batch adversarial loss: 0.485528\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140796; batch adversarial loss: 0.428787\n",
      "epoch 58; iter: 0; batch classifier loss: 0.123677; batch adversarial loss: 0.397751\n",
      "epoch 59; iter: 0; batch classifier loss: 0.169940; batch adversarial loss: 0.537349\n",
      "epoch 60; iter: 0; batch classifier loss: 0.193515; batch adversarial loss: 0.413878\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122813; batch adversarial loss: 0.456083\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124132; batch adversarial loss: 0.428177\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089964; batch adversarial loss: 0.461679\n",
      "epoch 64; iter: 0; batch classifier loss: 0.114860; batch adversarial loss: 0.426591\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063204; batch adversarial loss: 0.507524\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115000; batch adversarial loss: 0.433867\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124129; batch adversarial loss: 0.479487\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122835; batch adversarial loss: 0.415724\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099225; batch adversarial loss: 0.422510\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094468; batch adversarial loss: 0.406346\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096913; batch adversarial loss: 0.477108\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071658; batch adversarial loss: 0.396240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097597; batch adversarial loss: 0.512490\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067832; batch adversarial loss: 0.474289\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090277; batch adversarial loss: 0.423311\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057653; batch adversarial loss: 0.443432\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073764; batch adversarial loss: 0.378850\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053424; batch adversarial loss: 0.490072\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119845; batch adversarial loss: 0.446513\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049430; batch adversarial loss: 0.394540\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060894; batch adversarial loss: 0.439359\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071516; batch adversarial loss: 0.399322\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066043; batch adversarial loss: 0.521230\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059770; batch adversarial loss: 0.404605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038167; batch adversarial loss: 0.497354\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040448; batch adversarial loss: 0.442345\n",
      "epoch 87; iter: 0; batch classifier loss: 0.027315; batch adversarial loss: 0.529851\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054259; batch adversarial loss: 0.374116\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062217; batch adversarial loss: 0.455160\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055494; batch adversarial loss: 0.487631\n",
      "epoch 91; iter: 0; batch classifier loss: 0.114482; batch adversarial loss: 0.486725\n",
      "epoch 92; iter: 0; batch classifier loss: 0.115387; batch adversarial loss: 0.389666\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058298; batch adversarial loss: 0.515366\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038603; batch adversarial loss: 0.519332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044964; batch adversarial loss: 0.437522\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042458; batch adversarial loss: 0.409668\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065196; batch adversarial loss: 0.431723\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049760; batch adversarial loss: 0.329354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038854; batch adversarial loss: 0.393487\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054837; batch adversarial loss: 0.521185\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041183; batch adversarial loss: 0.444471\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027708; batch adversarial loss: 0.381342\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032909; batch adversarial loss: 0.388988\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025949; batch adversarial loss: 0.397816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028813; batch adversarial loss: 0.385489\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036943; batch adversarial loss: 0.474518\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039167; batch adversarial loss: 0.441477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.032226; batch adversarial loss: 0.409615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051512; batch adversarial loss: 0.451349\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049761; batch adversarial loss: 0.420234\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028270; batch adversarial loss: 0.389450\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033557; batch adversarial loss: 0.491124\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028519; batch adversarial loss: 0.488858\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045022; batch adversarial loss: 0.399106\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026914; batch adversarial loss: 0.415944\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038656; batch adversarial loss: 0.471699\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028324; batch adversarial loss: 0.526260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044145; batch adversarial loss: 0.438568\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038387; batch adversarial loss: 0.511784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046669; batch adversarial loss: 0.445901\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025544; batch adversarial loss: 0.412229\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032433; batch adversarial loss: 0.458693\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050146; batch adversarial loss: 0.422413\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039307; batch adversarial loss: 0.435583\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056133; batch adversarial loss: 0.359433\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026280; batch adversarial loss: 0.483532\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020035; batch adversarial loss: 0.483345\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029244; batch adversarial loss: 0.491460\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.411237\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034687; batch adversarial loss: 0.437301\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036608; batch adversarial loss: 0.470982\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042652; batch adversarial loss: 0.446650\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033954; batch adversarial loss: 0.463237\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017940; batch adversarial loss: 0.483611\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.452209\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033045; batch adversarial loss: 0.486491\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.405569\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032076; batch adversarial loss: 0.491337\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051596; batch adversarial loss: 0.441671\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016859; batch adversarial loss: 0.503086\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.414993\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042031; batch adversarial loss: 0.387570\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028187; batch adversarial loss: 0.428955\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035245; batch adversarial loss: 0.453501\n",
      "epoch 145; iter: 0; batch classifier loss: 0.078642; batch adversarial loss: 0.402569\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063389; batch adversarial loss: 0.453084\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046628; batch adversarial loss: 0.404315\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020403; batch adversarial loss: 0.416211\n",
      "epoch 149; iter: 0; batch classifier loss: 0.006019; batch adversarial loss: 0.410455\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026823; batch adversarial loss: 0.382119\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018341; batch adversarial loss: 0.446086\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018169; batch adversarial loss: 0.388193\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019525; batch adversarial loss: 0.418364\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014610; batch adversarial loss: 0.447144\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012672; batch adversarial loss: 0.501386\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020401; batch adversarial loss: 0.411505\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024455; batch adversarial loss: 0.533722\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008369; batch adversarial loss: 0.414067\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047715; batch adversarial loss: 0.393850\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014303; batch adversarial loss: 0.431501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007730; batch adversarial loss: 0.405624\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020760; batch adversarial loss: 0.468646\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016296; batch adversarial loss: 0.440906\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017707; batch adversarial loss: 0.382060\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024278; batch adversarial loss: 0.425158\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014859; batch adversarial loss: 0.461116\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025163; batch adversarial loss: 0.455581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020479; batch adversarial loss: 0.504999\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014260; batch adversarial loss: 0.406581\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033589; batch adversarial loss: 0.408127\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005352; batch adversarial loss: 0.489870\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023078; batch adversarial loss: 0.509857\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045582; batch adversarial loss: 0.489966\n",
      "epoch 174; iter: 0; batch classifier loss: 0.002558; batch adversarial loss: 0.441779\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031270; batch adversarial loss: 0.507458\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034690; batch adversarial loss: 0.372597\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044704; batch adversarial loss: 0.462385\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049930; batch adversarial loss: 0.421936\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017902; batch adversarial loss: 0.452881\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008911; batch adversarial loss: 0.455127\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017316; batch adversarial loss: 0.459861\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026524; batch adversarial loss: 0.434482\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010821; batch adversarial loss: 0.435444\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009704; batch adversarial loss: 0.417662\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015475; batch adversarial loss: 0.431491\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015294; batch adversarial loss: 0.436524\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006815; batch adversarial loss: 0.433499\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021035; batch adversarial loss: 0.480889\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023010; batch adversarial loss: 0.454464\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032991; batch adversarial loss: 0.433705\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031864; batch adversarial loss: 0.410149\n",
      "epoch 192; iter: 0; batch classifier loss: 0.027368; batch adversarial loss: 0.376848\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026549; batch adversarial loss: 0.510336\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013833; batch adversarial loss: 0.498953\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014853; batch adversarial loss: 0.406690\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026417; batch adversarial loss: 0.435748\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016252; batch adversarial loss: 0.457574\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013772; batch adversarial loss: 0.537374\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014775; batch adversarial loss: 0.412919\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709980; batch adversarial loss: 0.950043\n",
      "epoch 1; iter: 0; batch classifier loss: 0.577420; batch adversarial loss: 0.891177\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604933; batch adversarial loss: 0.930367\n",
      "epoch 3; iter: 0; batch classifier loss: 0.749085; batch adversarial loss: 0.867447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.921170; batch adversarial loss: 0.793714\n",
      "epoch 5; iter: 0; batch classifier loss: 0.886127; batch adversarial loss: 0.705404\n",
      "epoch 6; iter: 0; batch classifier loss: 0.732278; batch adversarial loss: 0.662366\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563417; batch adversarial loss: 0.588074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339376; batch adversarial loss: 0.568776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301828; batch adversarial loss: 0.588699\n",
      "epoch 10; iter: 0; batch classifier loss: 0.362422; batch adversarial loss: 0.532002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319047; batch adversarial loss: 0.559209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364381; batch adversarial loss: 0.491079\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297161; batch adversarial loss: 0.487717\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254067; batch adversarial loss: 0.477213\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273820; batch adversarial loss: 0.511647\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228116; batch adversarial loss: 0.470234\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186457; batch adversarial loss: 0.456013\n",
      "epoch 18; iter: 0; batch classifier loss: 0.192570; batch adversarial loss: 0.465327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202066; batch adversarial loss: 0.470943\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201973; batch adversarial loss: 0.393225\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138920; batch adversarial loss: 0.454685\n",
      "epoch 22; iter: 0; batch classifier loss: 0.116972; batch adversarial loss: 0.533750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.126594; batch adversarial loss: 0.426192\n",
      "epoch 24; iter: 0; batch classifier loss: 0.144063; batch adversarial loss: 0.437682\n",
      "epoch 25; iter: 0; batch classifier loss: 0.106497; batch adversarial loss: 0.443260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.105128; batch adversarial loss: 0.368115\n",
      "epoch 27; iter: 0; batch classifier loss: 0.111044; batch adversarial loss: 0.456127\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147512; batch adversarial loss: 0.484087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.072855; batch adversarial loss: 0.453603\n",
      "epoch 30; iter: 0; batch classifier loss: 0.103612; batch adversarial loss: 0.435456\n",
      "epoch 31; iter: 0; batch classifier loss: 0.081616; batch adversarial loss: 0.551470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108122; batch adversarial loss: 0.455453\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132766; batch adversarial loss: 0.399807\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120988; batch adversarial loss: 0.476478\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100406; batch adversarial loss: 0.436254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.072098; batch adversarial loss: 0.458554\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074688; batch adversarial loss: 0.411811\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089809; batch adversarial loss: 0.508305\n",
      "epoch 39; iter: 0; batch classifier loss: 0.079527; batch adversarial loss: 0.337103\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121133; batch adversarial loss: 0.484840\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130345; batch adversarial loss: 0.420406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.066507; batch adversarial loss: 0.562972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.080755; batch adversarial loss: 0.464891\n",
      "epoch 44; iter: 0; batch classifier loss: 0.065539; batch adversarial loss: 0.469479\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140922; batch adversarial loss: 0.485497\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082001; batch adversarial loss: 0.416718\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096379; batch adversarial loss: 0.506638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089776; batch adversarial loss: 0.525158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059955; batch adversarial loss: 0.441560\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075704; batch adversarial loss: 0.456343\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090760; batch adversarial loss: 0.540078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.087667; batch adversarial loss: 0.408137\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110012; batch adversarial loss: 0.353091\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071313; batch adversarial loss: 0.458468\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068681; batch adversarial loss: 0.561814\n",
      "epoch 56; iter: 0; batch classifier loss: 0.042171; batch adversarial loss: 0.408378\n",
      "epoch 57; iter: 0; batch classifier loss: 0.037773; batch adversarial loss: 0.414441\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081766; batch adversarial loss: 0.381511\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111310; batch adversarial loss: 0.476969\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086719; batch adversarial loss: 0.395724\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076609; batch adversarial loss: 0.397277\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072220; batch adversarial loss: 0.428883\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121112; batch adversarial loss: 0.461117\n",
      "epoch 64; iter: 0; batch classifier loss: 0.046106; batch adversarial loss: 0.381720\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048028; batch adversarial loss: 0.393154\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060414; batch adversarial loss: 0.408170\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059530; batch adversarial loss: 0.434627\n",
      "epoch 68; iter: 0; batch classifier loss: 0.073477; batch adversarial loss: 0.413029\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052433; batch adversarial loss: 0.384446\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047178; batch adversarial loss: 0.317729\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082162; batch adversarial loss: 0.377026\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066552; batch adversarial loss: 0.421651\n",
      "epoch 73; iter: 0; batch classifier loss: 0.039302; batch adversarial loss: 0.369632\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050771; batch adversarial loss: 0.396880\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068968; batch adversarial loss: 0.568942\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088903; batch adversarial loss: 0.409085\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064824; batch adversarial loss: 0.520167\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063881; batch adversarial loss: 0.507496\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050962; batch adversarial loss: 0.313025\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053743; batch adversarial loss: 0.447740\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076608; batch adversarial loss: 0.442750\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037604; batch adversarial loss: 0.432321\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088104; batch adversarial loss: 0.466595\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087053; batch adversarial loss: 0.319699\n",
      "epoch 85; iter: 0; batch classifier loss: 0.107633; batch adversarial loss: 0.513432\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047927; batch adversarial loss: 0.524138\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070973; batch adversarial loss: 0.449194\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062236; batch adversarial loss: 0.385017\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098851; batch adversarial loss: 0.422555\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052335; batch adversarial loss: 0.451390\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.409141\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035282; batch adversarial loss: 0.371209\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053987; batch adversarial loss: 0.415104\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062334; batch adversarial loss: 0.389795\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054720; batch adversarial loss: 0.502671\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049626; batch adversarial loss: 0.425652\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.400403\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072526; batch adversarial loss: 0.516958\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045980; batch adversarial loss: 0.527497\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030236; batch adversarial loss: 0.420877\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082039; batch adversarial loss: 0.410365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.055314; batch adversarial loss: 0.422907\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059018; batch adversarial loss: 0.374938\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071855; batch adversarial loss: 0.511514\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035966; batch adversarial loss: 0.532755\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071436; batch adversarial loss: 0.450539\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079057; batch adversarial loss: 0.561150\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086124; batch adversarial loss: 0.325053\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061868; batch adversarial loss: 0.471614\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049977; batch adversarial loss: 0.331945\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061792; batch adversarial loss: 0.475578\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044627; batch adversarial loss: 0.334399\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023699; batch adversarial loss: 0.457692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055995; batch adversarial loss: 0.436588\n",
      "epoch 115; iter: 0; batch classifier loss: 0.077732; batch adversarial loss: 0.476373\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041927; batch adversarial loss: 0.458013\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055606; batch adversarial loss: 0.452935\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043822; batch adversarial loss: 0.426779\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060678; batch adversarial loss: 0.430965\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040659; batch adversarial loss: 0.425258\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046301; batch adversarial loss: 0.465249\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048880; batch adversarial loss: 0.525420\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038636; batch adversarial loss: 0.429533\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041502; batch adversarial loss: 0.453508\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057278; batch adversarial loss: 0.455271\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049181; batch adversarial loss: 0.468213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.077112; batch adversarial loss: 0.469678\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041633; batch adversarial loss: 0.410324\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026312; batch adversarial loss: 0.375080\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.452181\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050809; batch adversarial loss: 0.429879\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054643; batch adversarial loss: 0.443773\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066490; batch adversarial loss: 0.435195\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043220; batch adversarial loss: 0.345308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022084; batch adversarial loss: 0.412765\n",
      "epoch 136; iter: 0; batch classifier loss: 0.064707; batch adversarial loss: 0.430821\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039812; batch adversarial loss: 0.493137\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.426750\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049338; batch adversarial loss: 0.411866\n",
      "epoch 140; iter: 0; batch classifier loss: 0.097000; batch adversarial loss: 0.435495\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032362; batch adversarial loss: 0.363108\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031227; batch adversarial loss: 0.464561\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021991; batch adversarial loss: 0.410095\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064508; batch adversarial loss: 0.404603\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042920; batch adversarial loss: 0.479219\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042293; batch adversarial loss: 0.551721\n",
      "epoch 147; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.380949\n",
      "epoch 148; iter: 0; batch classifier loss: 0.082745; batch adversarial loss: 0.424047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.052546; batch adversarial loss: 0.424211\n",
      "epoch 150; iter: 0; batch classifier loss: 0.067121; batch adversarial loss: 0.507095\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046662; batch adversarial loss: 0.426758\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058574; batch adversarial loss: 0.430419\n",
      "epoch 153; iter: 0; batch classifier loss: 0.061536; batch adversarial loss: 0.415665\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046096; batch adversarial loss: 0.377184\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044527; batch adversarial loss: 0.379745\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056071; batch adversarial loss: 0.471659\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054452; batch adversarial loss: 0.523344\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040567; batch adversarial loss: 0.468398\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045846; batch adversarial loss: 0.403922\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064711; batch adversarial loss: 0.436693\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040440; batch adversarial loss: 0.323739\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038267; batch adversarial loss: 0.511714\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057981; batch adversarial loss: 0.371050\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042973; batch adversarial loss: 0.431067\n",
      "epoch 165; iter: 0; batch classifier loss: 0.064512; batch adversarial loss: 0.386532\n",
      "epoch 166; iter: 0; batch classifier loss: 0.097073; batch adversarial loss: 0.510283\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042530; batch adversarial loss: 0.502719\n",
      "epoch 168; iter: 0; batch classifier loss: 0.068121; batch adversarial loss: 0.453617\n",
      "epoch 169; iter: 0; batch classifier loss: 0.066965; batch adversarial loss: 0.463405\n",
      "epoch 170; iter: 0; batch classifier loss: 0.051752; batch adversarial loss: 0.401400\n",
      "epoch 171; iter: 0; batch classifier loss: 0.084718; batch adversarial loss: 0.415081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033590; batch adversarial loss: 0.401159\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031231; batch adversarial loss: 0.381867\n",
      "epoch 174; iter: 0; batch classifier loss: 0.096797; batch adversarial loss: 0.437844\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025758; batch adversarial loss: 0.330009\n",
      "epoch 176; iter: 0; batch classifier loss: 0.054490; batch adversarial loss: 0.416556\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.417232\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045655; batch adversarial loss: 0.360918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033433; batch adversarial loss: 0.425210\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041400; batch adversarial loss: 0.408589\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.490521\n",
      "epoch 182; iter: 0; batch classifier loss: 0.066843; batch adversarial loss: 0.466743\n",
      "epoch 183; iter: 0; batch classifier loss: 0.047170; batch adversarial loss: 0.412790\n",
      "epoch 184; iter: 0; batch classifier loss: 0.054487; batch adversarial loss: 0.352174\n",
      "epoch 185; iter: 0; batch classifier loss: 0.062957; batch adversarial loss: 0.477104\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025162; batch adversarial loss: 0.468934\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047381; batch adversarial loss: 0.501075\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044774; batch adversarial loss: 0.435504\n",
      "epoch 189; iter: 0; batch classifier loss: 0.052847; batch adversarial loss: 0.458118\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037813; batch adversarial loss: 0.414115\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032199; batch adversarial loss: 0.465553\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036947; batch adversarial loss: 0.405064\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041627; batch adversarial loss: 0.534838\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055008; batch adversarial loss: 0.433402\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.363701\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028858; batch adversarial loss: 0.413834\n",
      "epoch 197; iter: 0; batch classifier loss: 0.052529; batch adversarial loss: 0.484539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.040855; batch adversarial loss: 0.529764\n",
      "epoch 199; iter: 0; batch classifier loss: 0.054963; batch adversarial loss: 0.479426\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713498; batch adversarial loss: 0.490967\n",
      "epoch 1; iter: 0; batch classifier loss: 0.402351; batch adversarial loss: 0.583520\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422568; batch adversarial loss: 0.559144\n",
      "epoch 3; iter: 0; batch classifier loss: 0.465486; batch adversarial loss: 0.605361\n",
      "epoch 4; iter: 0; batch classifier loss: 0.432859; batch adversarial loss: 0.634514\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377955; batch adversarial loss: 0.561349\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331703; batch adversarial loss: 0.588512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369978; batch adversarial loss: 0.637238\n",
      "epoch 8; iter: 0; batch classifier loss: 0.398009; batch adversarial loss: 0.660565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341041; batch adversarial loss: 0.505353\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400522; batch adversarial loss: 0.598488\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353949; batch adversarial loss: 0.558347\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385043; batch adversarial loss: 0.516890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507061; batch adversarial loss: 0.566929\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477420; batch adversarial loss: 0.471737\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383453; batch adversarial loss: 0.492168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313669; batch adversarial loss: 0.475729\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240840; batch adversarial loss: 0.418091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.223768; batch adversarial loss: 0.481143\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186889; batch adversarial loss: 0.419910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182985; batch adversarial loss: 0.471753\n",
      "epoch 21; iter: 0; batch classifier loss: 0.193052; batch adversarial loss: 0.547270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193388; batch adversarial loss: 0.508014\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191794; batch adversarial loss: 0.476080\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229879; batch adversarial loss: 0.446236\n",
      "epoch 25; iter: 0; batch classifier loss: 0.117856; batch adversarial loss: 0.492036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.174586; batch adversarial loss: 0.434721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145843; batch adversarial loss: 0.477289\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153701; batch adversarial loss: 0.458323\n",
      "epoch 29; iter: 0; batch classifier loss: 0.115706; batch adversarial loss: 0.497295\n",
      "epoch 30; iter: 0; batch classifier loss: 0.107083; batch adversarial loss: 0.450954\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102411; batch adversarial loss: 0.366997\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101618; batch adversarial loss: 0.511874\n",
      "epoch 33; iter: 0; batch classifier loss: 0.106151; batch adversarial loss: 0.494210\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107188; batch adversarial loss: 0.459956\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099601; batch adversarial loss: 0.467995\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102791; batch adversarial loss: 0.360520\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107772; batch adversarial loss: 0.511051\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110631; batch adversarial loss: 0.518795\n",
      "epoch 39; iter: 0; batch classifier loss: 0.100647; batch adversarial loss: 0.452367\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104338; batch adversarial loss: 0.482368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081697; batch adversarial loss: 0.506891\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091180; batch adversarial loss: 0.444071\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105857; batch adversarial loss: 0.457835\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085539; batch adversarial loss: 0.453715\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083337; batch adversarial loss: 0.453423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074152; batch adversarial loss: 0.438134\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088403; batch adversarial loss: 0.552766\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154822; batch adversarial loss: 0.417153\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076363; batch adversarial loss: 0.500122\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095151; batch adversarial loss: 0.571027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121935; batch adversarial loss: 0.462882\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089251; batch adversarial loss: 0.399490\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123462; batch adversarial loss: 0.412036\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070607; batch adversarial loss: 0.418154\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079085; batch adversarial loss: 0.451543\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077594; batch adversarial loss: 0.408061\n",
      "epoch 57; iter: 0; batch classifier loss: 0.054395; batch adversarial loss: 0.443170\n",
      "epoch 58; iter: 0; batch classifier loss: 0.037544; batch adversarial loss: 0.522099\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077341; batch adversarial loss: 0.537227\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097508; batch adversarial loss: 0.493525\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125102; batch adversarial loss: 0.361279\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120961; batch adversarial loss: 0.471106\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083203; batch adversarial loss: 0.457809\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057960; batch adversarial loss: 0.609313\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125067; batch adversarial loss: 0.409965\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089267; batch adversarial loss: 0.441839\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094212; batch adversarial loss: 0.413947\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082057; batch adversarial loss: 0.433028\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111068; batch adversarial loss: 0.379962\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070730; batch adversarial loss: 0.479831\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.525200\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071592; batch adversarial loss: 0.417300\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074038; batch adversarial loss: 0.499194\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054664; batch adversarial loss: 0.503545\n",
      "epoch 75; iter: 0; batch classifier loss: 0.108546; batch adversarial loss: 0.446509\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076429; batch adversarial loss: 0.389988\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070569; batch adversarial loss: 0.546788\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078263; batch adversarial loss: 0.426750\n",
      "epoch 79; iter: 0; batch classifier loss: 0.073827; batch adversarial loss: 0.378505\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054767; batch adversarial loss: 0.481417\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061973; batch adversarial loss: 0.410695\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077059; batch adversarial loss: 0.469603\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085703; batch adversarial loss: 0.430255\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079624; batch adversarial loss: 0.472943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086878; batch adversarial loss: 0.502220\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057910; batch adversarial loss: 0.515263\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061467; batch adversarial loss: 0.415976\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048391; batch adversarial loss: 0.379621\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062122; batch adversarial loss: 0.485054\n",
      "epoch 90; iter: 0; batch classifier loss: 0.133021; batch adversarial loss: 0.429320\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110287; batch adversarial loss: 0.475910\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059595; batch adversarial loss: 0.420904\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061139; batch adversarial loss: 0.515557\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066527; batch adversarial loss: 0.546130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.066836; batch adversarial loss: 0.474797\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073737; batch adversarial loss: 0.439709\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073045; batch adversarial loss: 0.411659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.515196\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060251; batch adversarial loss: 0.421232\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075404; batch adversarial loss: 0.565172\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052608; batch adversarial loss: 0.458026\n",
      "epoch 102; iter: 0; batch classifier loss: 0.136489; batch adversarial loss: 0.425475\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047805; batch adversarial loss: 0.472473\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075968; batch adversarial loss: 0.481460\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040998; batch adversarial loss: 0.492166\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032840; batch adversarial loss: 0.523309\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051804; batch adversarial loss: 0.431356\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062765; batch adversarial loss: 0.544447\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062307; batch adversarial loss: 0.409009\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039290; batch adversarial loss: 0.432334\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076357; batch adversarial loss: 0.418595\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076721; batch adversarial loss: 0.529989\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.421368\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069948; batch adversarial loss: 0.479184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070775; batch adversarial loss: 0.451382\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.409593\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076543; batch adversarial loss: 0.424021\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025216; batch adversarial loss: 0.417121\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033211; batch adversarial loss: 0.503992\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023442; batch adversarial loss: 0.377749\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035258; batch adversarial loss: 0.388837\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041977; batch adversarial loss: 0.343857\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053927; batch adversarial loss: 0.456446\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.508263\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072980; batch adversarial loss: 0.393270\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052860; batch adversarial loss: 0.548485\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026144; batch adversarial loss: 0.384478\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046595; batch adversarial loss: 0.523441\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060878; batch adversarial loss: 0.398342\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026092; batch adversarial loss: 0.457249\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028405; batch adversarial loss: 0.491538\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029011; batch adversarial loss: 0.438426\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030855; batch adversarial loss: 0.410075\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029614; batch adversarial loss: 0.533221\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039160; batch adversarial loss: 0.610790\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033773; batch adversarial loss: 0.493483\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039132; batch adversarial loss: 0.434864\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042490; batch adversarial loss: 0.401031\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022374; batch adversarial loss: 0.456647\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021126; batch adversarial loss: 0.467336\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019524; batch adversarial loss: 0.546772\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022464; batch adversarial loss: 0.466174\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045697; batch adversarial loss: 0.447238\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026119; batch adversarial loss: 0.547761\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031276; batch adversarial loss: 0.471542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.053825; batch adversarial loss: 0.460736\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.424753\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024837; batch adversarial loss: 0.448609\n",
      "epoch 149; iter: 0; batch classifier loss: 0.060086; batch adversarial loss: 0.357289\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014326; batch adversarial loss: 0.512214\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021930; batch adversarial loss: 0.444039\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023708; batch adversarial loss: 0.450804\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.497712\n",
      "epoch 154; iter: 0; batch classifier loss: 0.060081; batch adversarial loss: 0.488842\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046595; batch adversarial loss: 0.477875\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024878; batch adversarial loss: 0.369214\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022515; batch adversarial loss: 0.456026\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049916; batch adversarial loss: 0.483938\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052133; batch adversarial loss: 0.522849\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015345; batch adversarial loss: 0.472435\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042290; batch adversarial loss: 0.337685\n",
      "epoch 162; iter: 0; batch classifier loss: 0.005674; batch adversarial loss: 0.379282\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012848; batch adversarial loss: 0.426134\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013411; batch adversarial loss: 0.440692\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029123; batch adversarial loss: 0.405263\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015224; batch adversarial loss: 0.398942\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035363; batch adversarial loss: 0.370520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013924; batch adversarial loss: 0.465608\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006339; batch adversarial loss: 0.409837\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012219; batch adversarial loss: 0.420352\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034319; batch adversarial loss: 0.487308\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009795; batch adversarial loss: 0.459009\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032036; batch adversarial loss: 0.361129\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056372; batch adversarial loss: 0.449480\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035798; batch adversarial loss: 0.464898\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028496; batch adversarial loss: 0.531478\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020775; batch adversarial loss: 0.433185\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052429; batch adversarial loss: 0.497419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025918; batch adversarial loss: 0.428284\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016024; batch adversarial loss: 0.488399\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013065; batch adversarial loss: 0.381064\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038408; batch adversarial loss: 0.526211\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010661; batch adversarial loss: 0.479526\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018867; batch adversarial loss: 0.459026\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020870; batch adversarial loss: 0.469672\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029492; batch adversarial loss: 0.432196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.436054\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031305; batch adversarial loss: 0.390111\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022788; batch adversarial loss: 0.447714\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008126; batch adversarial loss: 0.470529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.046382; batch adversarial loss: 0.485762\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036546; batch adversarial loss: 0.343826\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020527; batch adversarial loss: 0.469361\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022038; batch adversarial loss: 0.415005\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013471; batch adversarial loss: 0.500824\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015082; batch adversarial loss: 0.473953\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025221; batch adversarial loss: 0.458980\n",
      "epoch 198; iter: 0; batch classifier loss: 0.042189; batch adversarial loss: 0.370725\n",
      "epoch 199; iter: 0; batch classifier loss: 0.064049; batch adversarial loss: 0.422434\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690961; batch adversarial loss: 0.485706\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447251; batch adversarial loss: 0.566295\n",
      "epoch 2; iter: 0; batch classifier loss: 0.472488; batch adversarial loss: 0.603216\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.569599\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374424; batch adversarial loss: 0.565466\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336906; batch adversarial loss: 0.562955\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373433; batch adversarial loss: 0.574210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416038; batch adversarial loss: 0.582570\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436915; batch adversarial loss: 0.603014\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474199; batch adversarial loss: 0.681228\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512698; batch adversarial loss: 0.591989\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470431; batch adversarial loss: 0.565679\n",
      "epoch 12; iter: 0; batch classifier loss: 0.635570; batch adversarial loss: 0.534564\n",
      "epoch 13; iter: 0; batch classifier loss: 0.807643; batch adversarial loss: 0.551269\n",
      "epoch 14; iter: 0; batch classifier loss: 0.688461; batch adversarial loss: 0.523463\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589567; batch adversarial loss: 0.545280\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413847; batch adversarial loss: 0.534856\n",
      "epoch 17; iter: 0; batch classifier loss: 0.350555; batch adversarial loss: 0.481656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261864; batch adversarial loss: 0.563372\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275892; batch adversarial loss: 0.473963\n",
      "epoch 20; iter: 0; batch classifier loss: 0.236138; batch adversarial loss: 0.502860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170706; batch adversarial loss: 0.426966\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208447; batch adversarial loss: 0.545307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174333; batch adversarial loss: 0.479326\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203973; batch adversarial loss: 0.504879\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203945; batch adversarial loss: 0.476948\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201797; batch adversarial loss: 0.394476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176975; batch adversarial loss: 0.394217\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211092; batch adversarial loss: 0.393774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.230781; batch adversarial loss: 0.462727\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244711; batch adversarial loss: 0.408594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193091; batch adversarial loss: 0.438596\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194936; batch adversarial loss: 0.491765\n",
      "epoch 33; iter: 0; batch classifier loss: 0.210584; batch adversarial loss: 0.363480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202700; batch adversarial loss: 0.318787\n",
      "epoch 35; iter: 0; batch classifier loss: 0.092368; batch adversarial loss: 0.453053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.205345; batch adversarial loss: 0.397893\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186522; batch adversarial loss: 0.450357\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123672; batch adversarial loss: 0.463837\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140540; batch adversarial loss: 0.535579\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212875; batch adversarial loss: 0.492568\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186670; batch adversarial loss: 0.429717\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174138; batch adversarial loss: 0.526209\n",
      "epoch 43; iter: 0; batch classifier loss: 0.167529; batch adversarial loss: 0.407838\n",
      "epoch 44; iter: 0; batch classifier loss: 0.156210; batch adversarial loss: 0.458222\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218994; batch adversarial loss: 0.544433\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196633; batch adversarial loss: 0.377074\n",
      "epoch 47; iter: 0; batch classifier loss: 0.163549; batch adversarial loss: 0.392200\n",
      "epoch 48; iter: 0; batch classifier loss: 0.164857; batch adversarial loss: 0.524170\n",
      "epoch 49; iter: 0; batch classifier loss: 0.274884; batch adversarial loss: 0.410561\n",
      "epoch 50; iter: 0; batch classifier loss: 0.159614; batch adversarial loss: 0.539482\n",
      "epoch 51; iter: 0; batch classifier loss: 0.187376; batch adversarial loss: 0.556203\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175967; batch adversarial loss: 0.487899\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216360; batch adversarial loss: 0.440626\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209119; batch adversarial loss: 0.443687\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199259; batch adversarial loss: 0.461615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.226757; batch adversarial loss: 0.475622\n",
      "epoch 57; iter: 0; batch classifier loss: 0.265002; batch adversarial loss: 0.466539\n",
      "epoch 58; iter: 0; batch classifier loss: 0.249247; batch adversarial loss: 0.484626\n",
      "epoch 59; iter: 0; batch classifier loss: 0.245642; batch adversarial loss: 0.374230\n",
      "epoch 60; iter: 0; batch classifier loss: 0.200923; batch adversarial loss: 0.446117\n",
      "epoch 61; iter: 0; batch classifier loss: 0.181834; batch adversarial loss: 0.423038\n",
      "epoch 62; iter: 0; batch classifier loss: 0.230067; batch adversarial loss: 0.317855\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189296; batch adversarial loss: 0.423838\n",
      "epoch 64; iter: 0; batch classifier loss: 0.195711; batch adversarial loss: 0.424954\n",
      "epoch 65; iter: 0; batch classifier loss: 0.244771; batch adversarial loss: 0.393015\n",
      "epoch 66; iter: 0; batch classifier loss: 0.288396; batch adversarial loss: 0.463616\n",
      "epoch 67; iter: 0; batch classifier loss: 0.282806; batch adversarial loss: 0.520586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.237014; batch adversarial loss: 0.458733\n",
      "epoch 69; iter: 0; batch classifier loss: 0.183229; batch adversarial loss: 0.469980\n",
      "epoch 70; iter: 0; batch classifier loss: 0.237537; batch adversarial loss: 0.458682\n",
      "epoch 71; iter: 0; batch classifier loss: 0.247612; batch adversarial loss: 0.446946\n",
      "epoch 72; iter: 0; batch classifier loss: 0.231043; batch adversarial loss: 0.496706\n",
      "epoch 73; iter: 0; batch classifier loss: 0.232933; batch adversarial loss: 0.446368\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089863; batch adversarial loss: 0.394897\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104629; batch adversarial loss: 0.481338\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093017; batch adversarial loss: 0.473517\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092795; batch adversarial loss: 0.414108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096023; batch adversarial loss: 0.397486\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072244; batch adversarial loss: 0.440944\n",
      "epoch 80; iter: 0; batch classifier loss: 0.112235; batch adversarial loss: 0.364407\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071312; batch adversarial loss: 0.446616\n",
      "epoch 82; iter: 0; batch classifier loss: 0.036691; batch adversarial loss: 0.457682\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041930; batch adversarial loss: 0.407814\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062767; batch adversarial loss: 0.439999\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053270; batch adversarial loss: 0.440040\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113792; batch adversarial loss: 0.375874\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050550; batch adversarial loss: 0.503997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.094751; batch adversarial loss: 0.473448\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033667; batch adversarial loss: 0.405076\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097535; batch adversarial loss: 0.523236\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064271; batch adversarial loss: 0.380520\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071925; batch adversarial loss: 0.528312\n",
      "epoch 93; iter: 0; batch classifier loss: 0.110797; batch adversarial loss: 0.490296\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064086; batch adversarial loss: 0.455426\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057591; batch adversarial loss: 0.429282\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045524; batch adversarial loss: 0.353801\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064595; batch adversarial loss: 0.395392\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056081; batch adversarial loss: 0.321690\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032765; batch adversarial loss: 0.471898\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097620; batch adversarial loss: 0.436834\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048441; batch adversarial loss: 0.384455\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065748; batch adversarial loss: 0.469416\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041103; batch adversarial loss: 0.487544\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034514; batch adversarial loss: 0.380658\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078155; batch adversarial loss: 0.465258\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046643; batch adversarial loss: 0.474969\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076300; batch adversarial loss: 0.418497\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065730; batch adversarial loss: 0.500520\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040717; batch adversarial loss: 0.415686\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073435; batch adversarial loss: 0.477621\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.458156\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053832; batch adversarial loss: 0.431254\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023262; batch adversarial loss: 0.522579\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085606; batch adversarial loss: 0.362406\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080044; batch adversarial loss: 0.356184\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.426514\n",
      "epoch 117; iter: 0; batch classifier loss: 0.091871; batch adversarial loss: 0.384548\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042229; batch adversarial loss: 0.403132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.081306; batch adversarial loss: 0.363503\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059447; batch adversarial loss: 0.537800\n",
      "epoch 121; iter: 0; batch classifier loss: 0.064678; batch adversarial loss: 0.456798\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058631; batch adversarial loss: 0.473531\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064451; batch adversarial loss: 0.422964\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055733; batch adversarial loss: 0.404375\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039287; batch adversarial loss: 0.390605\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035721; batch adversarial loss: 0.440572\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051818; batch adversarial loss: 0.438542\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063470; batch adversarial loss: 0.453796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060237; batch adversarial loss: 0.460863\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052107; batch adversarial loss: 0.410258\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041621; batch adversarial loss: 0.429482\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066668; batch adversarial loss: 0.382326\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057044; batch adversarial loss: 0.403107\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.487348\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053160; batch adversarial loss: 0.437601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050902; batch adversarial loss: 0.449179\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037907; batch adversarial loss: 0.357497\n",
      "epoch 138; iter: 0; batch classifier loss: 0.092350; batch adversarial loss: 0.509752\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044829; batch adversarial loss: 0.363362\n",
      "epoch 140; iter: 0; batch classifier loss: 0.072637; batch adversarial loss: 0.452931\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056810; batch adversarial loss: 0.411753\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040862; batch adversarial loss: 0.437383\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053635; batch adversarial loss: 0.428673\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061655; batch adversarial loss: 0.419282\n",
      "epoch 145; iter: 0; batch classifier loss: 0.078126; batch adversarial loss: 0.344761\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064780; batch adversarial loss: 0.465072\n",
      "epoch 147; iter: 0; batch classifier loss: 0.070618; batch adversarial loss: 0.391040\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054046; batch adversarial loss: 0.493117\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063964; batch adversarial loss: 0.371889\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019650; batch adversarial loss: 0.363689\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040091; batch adversarial loss: 0.430743\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038880; batch adversarial loss: 0.405812\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058742; batch adversarial loss: 0.463248\n",
      "epoch 154; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.425929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043529; batch adversarial loss: 0.417510\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.351180\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056814; batch adversarial loss: 0.397391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029531; batch adversarial loss: 0.400255\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043522; batch adversarial loss: 0.404035\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052726; batch adversarial loss: 0.463352\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051105; batch adversarial loss: 0.385905\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030780; batch adversarial loss: 0.381643\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045224; batch adversarial loss: 0.336370\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036602; batch adversarial loss: 0.435814\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042475; batch adversarial loss: 0.464938\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048022; batch adversarial loss: 0.385304\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058771; batch adversarial loss: 0.323502\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037842; batch adversarial loss: 0.430201\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035660; batch adversarial loss: 0.398213\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028815; batch adversarial loss: 0.452907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.087478; batch adversarial loss: 0.447875\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044221; batch adversarial loss: 0.421540\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.460707\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.427681\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039569; batch adversarial loss: 0.356335\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048992; batch adversarial loss: 0.439356\n",
      "epoch 177; iter: 0; batch classifier loss: 0.061315; batch adversarial loss: 0.392478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051224; batch adversarial loss: 0.404452\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040399; batch adversarial loss: 0.395316\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040174; batch adversarial loss: 0.451629\n",
      "epoch 181; iter: 0; batch classifier loss: 0.057091; batch adversarial loss: 0.421529\n",
      "epoch 182; iter: 0; batch classifier loss: 0.045388; batch adversarial loss: 0.369699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048029; batch adversarial loss: 0.435117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.029235; batch adversarial loss: 0.501284\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037774; batch adversarial loss: 0.402053\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023820; batch adversarial loss: 0.428326\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038770; batch adversarial loss: 0.424828\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044984; batch adversarial loss: 0.449904\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025590; batch adversarial loss: 0.563006\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037524; batch adversarial loss: 0.376063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038203; batch adversarial loss: 0.418988\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030627; batch adversarial loss: 0.542273\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.482595\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029207; batch adversarial loss: 0.339537\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041651; batch adversarial loss: 0.482346\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036957; batch adversarial loss: 0.452244\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028997; batch adversarial loss: 0.493487\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028068; batch adversarial loss: 0.468015\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031675; batch adversarial loss: 0.457675\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707441; batch adversarial loss: 0.620995\n",
      "epoch 1; iter: 0; batch classifier loss: 0.358609; batch adversarial loss: 0.632836\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410037; batch adversarial loss: 0.584430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.312936; batch adversarial loss: 0.589904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327842; batch adversarial loss: 0.553108\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357169; batch adversarial loss: 0.529825\n",
      "epoch 6; iter: 0; batch classifier loss: 0.367093; batch adversarial loss: 0.572468\n",
      "epoch 7; iter: 0; batch classifier loss: 0.246310; batch adversarial loss: 0.511118\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262884; batch adversarial loss: 0.521713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.268572; batch adversarial loss: 0.447674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.188482; batch adversarial loss: 0.487726\n",
      "epoch 11; iter: 0; batch classifier loss: 0.263416; batch adversarial loss: 0.501190\n",
      "epoch 12; iter: 0; batch classifier loss: 0.195505; batch adversarial loss: 0.463307\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215164; batch adversarial loss: 0.522968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.158802; batch adversarial loss: 0.458805\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235245; batch adversarial loss: 0.555167\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250963; batch adversarial loss: 0.573744\n",
      "epoch 17; iter: 0; batch classifier loss: 0.145210; batch adversarial loss: 0.425642\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164146; batch adversarial loss: 0.521988\n",
      "epoch 19; iter: 0; batch classifier loss: 0.153447; batch adversarial loss: 0.433510\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243807; batch adversarial loss: 0.455121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209686; batch adversarial loss: 0.520583\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208396; batch adversarial loss: 0.479716\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201636; batch adversarial loss: 0.581414\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232036; batch adversarial loss: 0.572498\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196128; batch adversarial loss: 0.497195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201069; batch adversarial loss: 0.520653\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269494; batch adversarial loss: 0.522208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.337342; batch adversarial loss: 0.463046\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171224; batch adversarial loss: 0.474180\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125350; batch adversarial loss: 0.580323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145112; batch adversarial loss: 0.434121\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118066; batch adversarial loss: 0.442857\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108429; batch adversarial loss: 0.480804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109340; batch adversarial loss: 0.518017\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108009; batch adversarial loss: 0.444667\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123018; batch adversarial loss: 0.461831\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100350; batch adversarial loss: 0.414585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.075401; batch adversarial loss: 0.439806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.081673; batch adversarial loss: 0.562575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104515; batch adversarial loss: 0.400771\n",
      "epoch 41; iter: 0; batch classifier loss: 0.095732; batch adversarial loss: 0.521299\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075809; batch adversarial loss: 0.492096\n",
      "epoch 43; iter: 0; batch classifier loss: 0.099307; batch adversarial loss: 0.433662\n",
      "epoch 44; iter: 0; batch classifier loss: 0.063839; batch adversarial loss: 0.452984\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079982; batch adversarial loss: 0.485926\n",
      "epoch 46; iter: 0; batch classifier loss: 0.058502; batch adversarial loss: 0.457040\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071963; batch adversarial loss: 0.513925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072232; batch adversarial loss: 0.460991\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106939; batch adversarial loss: 0.433716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069213; batch adversarial loss: 0.463620\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100896; batch adversarial loss: 0.502766\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073403; batch adversarial loss: 0.494709\n",
      "epoch 53; iter: 0; batch classifier loss: 0.052633; batch adversarial loss: 0.455893\n",
      "epoch 54; iter: 0; batch classifier loss: 0.053522; batch adversarial loss: 0.443993\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102551; batch adversarial loss: 0.529889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131306; batch adversarial loss: 0.503660\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083292; batch adversarial loss: 0.456590\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086378; batch adversarial loss: 0.458461\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086226; batch adversarial loss: 0.439204\n",
      "epoch 60; iter: 0; batch classifier loss: 0.049880; batch adversarial loss: 0.593757\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054418; batch adversarial loss: 0.376262\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088735; batch adversarial loss: 0.446870\n",
      "epoch 63; iter: 0; batch classifier loss: 0.069286; batch adversarial loss: 0.464489\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125263; batch adversarial loss: 0.375397\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074020; batch adversarial loss: 0.543688\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078800; batch adversarial loss: 0.443857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057103; batch adversarial loss: 0.434825\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054088; batch adversarial loss: 0.522033\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098259; batch adversarial loss: 0.493700\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048744; batch adversarial loss: 0.464418\n",
      "epoch 71; iter: 0; batch classifier loss: 0.048535; batch adversarial loss: 0.507108\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082008; batch adversarial loss: 0.425287\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050847; batch adversarial loss: 0.482027\n",
      "epoch 74; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.380650\n",
      "epoch 75; iter: 0; batch classifier loss: 0.039203; batch adversarial loss: 0.454473\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066500; batch adversarial loss: 0.537977\n",
      "epoch 77; iter: 0; batch classifier loss: 0.040630; batch adversarial loss: 0.450466\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054145; batch adversarial loss: 0.488853\n",
      "epoch 79; iter: 0; batch classifier loss: 0.033579; batch adversarial loss: 0.564318\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043128; batch adversarial loss: 0.561026\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083131; batch adversarial loss: 0.513140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.108659; batch adversarial loss: 0.511759\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062896; batch adversarial loss: 0.435005\n",
      "epoch 84; iter: 0; batch classifier loss: 0.027756; batch adversarial loss: 0.488674\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035728; batch adversarial loss: 0.400819\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072485; batch adversarial loss: 0.454545\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042687; batch adversarial loss: 0.483695\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037607; batch adversarial loss: 0.383318\n",
      "epoch 89; iter: 0; batch classifier loss: 0.030269; batch adversarial loss: 0.446367\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061876; batch adversarial loss: 0.434763\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.439222\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031939; batch adversarial loss: 0.416920\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038244; batch adversarial loss: 0.390410\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046946; batch adversarial loss: 0.430078\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041331; batch adversarial loss: 0.443326\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062521; batch adversarial loss: 0.437112\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052164; batch adversarial loss: 0.407644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036632; batch adversarial loss: 0.510932\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050372; batch adversarial loss: 0.427114\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050663; batch adversarial loss: 0.404600\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028384; batch adversarial loss: 0.438621\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041255; batch adversarial loss: 0.422619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034383; batch adversarial loss: 0.387505\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027325; batch adversarial loss: 0.530469\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042705; batch adversarial loss: 0.487043\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050065; batch adversarial loss: 0.512926\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037953; batch adversarial loss: 0.546923\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033160; batch adversarial loss: 0.382833\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047437; batch adversarial loss: 0.529514\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027470; batch adversarial loss: 0.453315\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034808; batch adversarial loss: 0.380747\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027022; batch adversarial loss: 0.415631\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069875; batch adversarial loss: 0.428319\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037594; batch adversarial loss: 0.502415\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051219; batch adversarial loss: 0.438749\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031852; batch adversarial loss: 0.527255\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040314; batch adversarial loss: 0.460259\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.443003\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043440; batch adversarial loss: 0.475008\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061027; batch adversarial loss: 0.410799\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039906; batch adversarial loss: 0.364677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029388; batch adversarial loss: 0.382605\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058163; batch adversarial loss: 0.492143\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038383; batch adversarial loss: 0.443434\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024172; batch adversarial loss: 0.381613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059437; batch adversarial loss: 0.512566\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016640; batch adversarial loss: 0.458295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028819; batch adversarial loss: 0.543198\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.432958\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028801; batch adversarial loss: 0.475820\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067169; batch adversarial loss: 0.381089\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024865; batch adversarial loss: 0.443751\n",
      "epoch 133; iter: 0; batch classifier loss: 0.005126; batch adversarial loss: 0.568847\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017442; batch adversarial loss: 0.477152\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061569; batch adversarial loss: 0.376273\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016626; batch adversarial loss: 0.469912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027852; batch adversarial loss: 0.470398\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039086; batch adversarial loss: 0.425966\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031694; batch adversarial loss: 0.426644\n",
      "epoch 140; iter: 0; batch classifier loss: 0.065263; batch adversarial loss: 0.397682\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073102; batch adversarial loss: 0.489057\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.443737\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.435202\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047499; batch adversarial loss: 0.382536\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.526629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.055301; batch adversarial loss: 0.404222\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027890; batch adversarial loss: 0.404172\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031287; batch adversarial loss: 0.493515\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008908; batch adversarial loss: 0.522110\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025929; batch adversarial loss: 0.511724\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025211; batch adversarial loss: 0.406915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032975; batch adversarial loss: 0.464265\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028055; batch adversarial loss: 0.488086\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020110; batch adversarial loss: 0.495769\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021908; batch adversarial loss: 0.520096\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022037; batch adversarial loss: 0.546358\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037239; batch adversarial loss: 0.500586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018949; batch adversarial loss: 0.461834\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050184; batch adversarial loss: 0.462343\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064020; batch adversarial loss: 0.537375\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016438; batch adversarial loss: 0.451086\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.441605\n",
      "epoch 163; iter: 0; batch classifier loss: 0.005150; batch adversarial loss: 0.471721\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011338; batch adversarial loss: 0.465374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017279; batch adversarial loss: 0.441948\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.534016\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022339; batch adversarial loss: 0.476413\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009007; batch adversarial loss: 0.451301\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015157; batch adversarial loss: 0.444422\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044877; batch adversarial loss: 0.410233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007131; batch adversarial loss: 0.485879\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017246; batch adversarial loss: 0.403893\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017235; batch adversarial loss: 0.490699\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007598; batch adversarial loss: 0.504876\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014319; batch adversarial loss: 0.453750\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.415151\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008083; batch adversarial loss: 0.432091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.013399; batch adversarial loss: 0.466395\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007469; batch adversarial loss: 0.490596\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018067; batch adversarial loss: 0.450754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023357; batch adversarial loss: 0.415400\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.469698\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026888; batch adversarial loss: 0.400930\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018708; batch adversarial loss: 0.432329\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015585; batch adversarial loss: 0.466050\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012883; batch adversarial loss: 0.537033\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028162; batch adversarial loss: 0.400820\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016815; batch adversarial loss: 0.470881\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011356; batch adversarial loss: 0.450792\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020463; batch adversarial loss: 0.485402\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009082; batch adversarial loss: 0.441770\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032491; batch adversarial loss: 0.461474\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012629; batch adversarial loss: 0.520198\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015229; batch adversarial loss: 0.389203\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.477385\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028114; batch adversarial loss: 0.548024\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012177; batch adversarial loss: 0.432842\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022370; batch adversarial loss: 0.462519\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012496; batch adversarial loss: 0.501437\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678688; batch adversarial loss: 0.597006\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408312; batch adversarial loss: 0.615444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383902; batch adversarial loss: 0.567456\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347913; batch adversarial loss: 0.546824\n",
      "epoch 4; iter: 0; batch classifier loss: 0.308410; batch adversarial loss: 0.567150\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278570; batch adversarial loss: 0.543014\n",
      "epoch 6; iter: 0; batch classifier loss: 0.306269; batch adversarial loss: 0.530944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385216; batch adversarial loss: 0.503316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262248; batch adversarial loss: 0.508516\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243630; batch adversarial loss: 0.510120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231624; batch adversarial loss: 0.539415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333309; batch adversarial loss: 0.449219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.210455; batch adversarial loss: 0.512811\n",
      "epoch 13; iter: 0; batch classifier loss: 0.233316; batch adversarial loss: 0.457760\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256211; batch adversarial loss: 0.470959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261698; batch adversarial loss: 0.474010\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240165; batch adversarial loss: 0.559923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290871; batch adversarial loss: 0.545316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269390; batch adversarial loss: 0.503548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234372; batch adversarial loss: 0.507975\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306409; batch adversarial loss: 0.487762\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275884; batch adversarial loss: 0.427024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.256070; batch adversarial loss: 0.537261\n",
      "epoch 23; iter: 0; batch classifier loss: 0.312155; batch adversarial loss: 0.446735\n",
      "epoch 24; iter: 0; batch classifier loss: 0.371691; batch adversarial loss: 0.481531\n",
      "epoch 25; iter: 0; batch classifier loss: 0.313332; batch adversarial loss: 0.419175\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213154; batch adversarial loss: 0.470916\n",
      "epoch 27; iter: 0; batch classifier loss: 0.201407; batch adversarial loss: 0.420521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140626; batch adversarial loss: 0.526772\n",
      "epoch 29; iter: 0; batch classifier loss: 0.093448; batch adversarial loss: 0.469703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153296; batch adversarial loss: 0.367234\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226000; batch adversarial loss: 0.483730\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156349; batch adversarial loss: 0.390744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145607; batch adversarial loss: 0.377375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112130; batch adversarial loss: 0.424156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130208; batch adversarial loss: 0.458450\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128237; batch adversarial loss: 0.408723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112333; batch adversarial loss: 0.439462\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130643; batch adversarial loss: 0.533225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107223; batch adversarial loss: 0.489343\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119144; batch adversarial loss: 0.384394\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148409; batch adversarial loss: 0.452764\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128435; batch adversarial loss: 0.422756\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141432; batch adversarial loss: 0.443198\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107217; batch adversarial loss: 0.406297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065406; batch adversarial loss: 0.455268\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131251; batch adversarial loss: 0.425553\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109255; batch adversarial loss: 0.457526\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113295; batch adversarial loss: 0.380628\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113914; batch adversarial loss: 0.407258\n",
      "epoch 50; iter: 0; batch classifier loss: 0.161880; batch adversarial loss: 0.314816\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103470; batch adversarial loss: 0.469639\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111353; batch adversarial loss: 0.503104\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144367; batch adversarial loss: 0.442569\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095605; batch adversarial loss: 0.455170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193267; batch adversarial loss: 0.420696\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080988; batch adversarial loss: 0.476056\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095861; batch adversarial loss: 0.474123\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067087; batch adversarial loss: 0.436736\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111320; batch adversarial loss: 0.421494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106380; batch adversarial loss: 0.354678\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105523; batch adversarial loss: 0.458947\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090298; batch adversarial loss: 0.394239\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078466; batch adversarial loss: 0.439922\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090266; batch adversarial loss: 0.412595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097620; batch adversarial loss: 0.470417\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084543; batch adversarial loss: 0.475650\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101711; batch adversarial loss: 0.397978\n",
      "epoch 68; iter: 0; batch classifier loss: 0.139067; batch adversarial loss: 0.558594\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064072; batch adversarial loss: 0.428509\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065679; batch adversarial loss: 0.500818\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092574; batch adversarial loss: 0.538799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100550; batch adversarial loss: 0.506782\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102785; batch adversarial loss: 0.364163\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141118; batch adversarial loss: 0.390386\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091375; batch adversarial loss: 0.456198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.090420; batch adversarial loss: 0.424799\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064225; batch adversarial loss: 0.459728\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115169; batch adversarial loss: 0.370852\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128873; batch adversarial loss: 0.447767\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088726; batch adversarial loss: 0.472756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069140; batch adversarial loss: 0.507846\n",
      "epoch 82; iter: 0; batch classifier loss: 0.145127; batch adversarial loss: 0.429451\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066916; batch adversarial loss: 0.547310\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067818; batch adversarial loss: 0.394621\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070161; batch adversarial loss: 0.488700\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.447311\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078826; batch adversarial loss: 0.543468\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088961; batch adversarial loss: 0.485585\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037930; batch adversarial loss: 0.576028\n",
      "epoch 90; iter: 0; batch classifier loss: 0.070256; batch adversarial loss: 0.464162\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062192; batch adversarial loss: 0.433076\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059822; batch adversarial loss: 0.459667\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055994; batch adversarial loss: 0.589472\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097712; batch adversarial loss: 0.400068\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059624; batch adversarial loss: 0.418777\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112057; batch adversarial loss: 0.321179\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073316; batch adversarial loss: 0.513387\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046615; batch adversarial loss: 0.399305\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039348; batch adversarial loss: 0.572337\n",
      "epoch 100; iter: 0; batch classifier loss: 0.078942; batch adversarial loss: 0.467116\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070571; batch adversarial loss: 0.533902\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.418718\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061556; batch adversarial loss: 0.396362\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052399; batch adversarial loss: 0.362090\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047706; batch adversarial loss: 0.435739\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074880; batch adversarial loss: 0.353941\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074089; batch adversarial loss: 0.439665\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044273; batch adversarial loss: 0.477457\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048477; batch adversarial loss: 0.418098\n",
      "epoch 110; iter: 0; batch classifier loss: 0.070377; batch adversarial loss: 0.418914\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055211; batch adversarial loss: 0.343209\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052674; batch adversarial loss: 0.466076\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062910; batch adversarial loss: 0.421205\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048304; batch adversarial loss: 0.494830\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072121; batch adversarial loss: 0.444686\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041074; batch adversarial loss: 0.417849\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070224; batch adversarial loss: 0.419640\n",
      "epoch 118; iter: 0; batch classifier loss: 0.017991; batch adversarial loss: 0.370814\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029701; batch adversarial loss: 0.422180\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.473751\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041168; batch adversarial loss: 0.467304\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050117; batch adversarial loss: 0.431888\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037171; batch adversarial loss: 0.404690\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036560; batch adversarial loss: 0.425192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041163; batch adversarial loss: 0.351481\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033370; batch adversarial loss: 0.457440\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017724; batch adversarial loss: 0.528964\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046002; batch adversarial loss: 0.475107\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046426; batch adversarial loss: 0.425976\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032372; batch adversarial loss: 0.432365\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061895; batch adversarial loss: 0.393202\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.411626\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038279; batch adversarial loss: 0.423592\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037540; batch adversarial loss: 0.488285\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056991; batch adversarial loss: 0.443076\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044622; batch adversarial loss: 0.440661\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048664; batch adversarial loss: 0.379338\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038488; batch adversarial loss: 0.404834\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046310; batch adversarial loss: 0.342701\n",
      "epoch 140; iter: 0; batch classifier loss: 0.080124; batch adversarial loss: 0.462982\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039639; batch adversarial loss: 0.473814\n",
      "epoch 142; iter: 0; batch classifier loss: 0.131176; batch adversarial loss: 0.455188\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023827; batch adversarial loss: 0.473803\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025782; batch adversarial loss: 0.456974\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022765; batch adversarial loss: 0.545878\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032206; batch adversarial loss: 0.383224\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031523; batch adversarial loss: 0.466013\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019155; batch adversarial loss: 0.461304\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019519; batch adversarial loss: 0.510640\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030443; batch adversarial loss: 0.488975\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057873; batch adversarial loss: 0.442457\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039419; batch adversarial loss: 0.403098\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017731; batch adversarial loss: 0.469762\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033565; batch adversarial loss: 0.441036\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040965; batch adversarial loss: 0.444284\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017124; batch adversarial loss: 0.481140\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039902; batch adversarial loss: 0.540313\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.414527\n",
      "epoch 159; iter: 0; batch classifier loss: 0.059302; batch adversarial loss: 0.448848\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031542; batch adversarial loss: 0.419412\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039739; batch adversarial loss: 0.551537\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034772; batch adversarial loss: 0.445640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035320; batch adversarial loss: 0.383483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038932; batch adversarial loss: 0.520921\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017449; batch adversarial loss: 0.506719\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021954; batch adversarial loss: 0.373821\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055190; batch adversarial loss: 0.371204\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.533276\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.484915\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024381; batch adversarial loss: 0.514989\n",
      "epoch 171; iter: 0; batch classifier loss: 0.043638; batch adversarial loss: 0.440267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.049649; batch adversarial loss: 0.513621\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011838; batch adversarial loss: 0.515506\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019843; batch adversarial loss: 0.466747\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020198; batch adversarial loss: 0.455909\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039741; batch adversarial loss: 0.449275\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042005; batch adversarial loss: 0.385412\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030422; batch adversarial loss: 0.490510\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.512011\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016872; batch adversarial loss: 0.413554\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017026; batch adversarial loss: 0.488624\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018750; batch adversarial loss: 0.467019\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028873; batch adversarial loss: 0.501113\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013689; batch adversarial loss: 0.545200\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.515868\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011353; batch adversarial loss: 0.453476\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019822; batch adversarial loss: 0.496329\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039922; batch adversarial loss: 0.435820\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037632; batch adversarial loss: 0.496283\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020914; batch adversarial loss: 0.553787\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009425; batch adversarial loss: 0.415911\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005669; batch adversarial loss: 0.417462\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.435759\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006413; batch adversarial loss: 0.383801\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.454379\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027954; batch adversarial loss: 0.459146\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036826; batch adversarial loss: 0.436376\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006693; batch adversarial loss: 0.439498\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015032; batch adversarial loss: 0.411504\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697911; batch adversarial loss: 0.552923\n",
      "epoch 1; iter: 0; batch classifier loss: 0.434919; batch adversarial loss: 0.601201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413734; batch adversarial loss: 0.606743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369152; batch adversarial loss: 0.597319\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324204; batch adversarial loss: 0.543735\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380411; batch adversarial loss: 0.549611\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370840; batch adversarial loss: 0.529444\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319136; batch adversarial loss: 0.605302\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302774; batch adversarial loss: 0.512974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363242; batch adversarial loss: 0.515206\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413647; batch adversarial loss: 0.555484\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416114; batch adversarial loss: 0.577304\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531138; batch adversarial loss: 0.548969\n",
      "epoch 13; iter: 0; batch classifier loss: 0.575456; batch adversarial loss: 0.568189\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551071; batch adversarial loss: 0.484253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384092; batch adversarial loss: 0.488219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346696; batch adversarial loss: 0.499734\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239512; batch adversarial loss: 0.550513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228390; batch adversarial loss: 0.452253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194324; batch adversarial loss: 0.487178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217574; batch adversarial loss: 0.422485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267596; batch adversarial loss: 0.487981\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196824; batch adversarial loss: 0.568386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233599; batch adversarial loss: 0.476866\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172075; batch adversarial loss: 0.510722\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212280; batch adversarial loss: 0.422608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221394; batch adversarial loss: 0.471028\n",
      "epoch 27; iter: 0; batch classifier loss: 0.359746; batch adversarial loss: 0.378937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180714; batch adversarial loss: 0.501379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157932; batch adversarial loss: 0.417259\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191763; batch adversarial loss: 0.474913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163273; batch adversarial loss: 0.579285\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193280; batch adversarial loss: 0.495837\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188641; batch adversarial loss: 0.493382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245007; batch adversarial loss: 0.428353\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202136; batch adversarial loss: 0.562549\n",
      "epoch 36; iter: 0; batch classifier loss: 0.266541; batch adversarial loss: 0.459752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.265539; batch adversarial loss: 0.411001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221290; batch adversarial loss: 0.451717\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231348; batch adversarial loss: 0.539825\n",
      "epoch 40; iter: 0; batch classifier loss: 0.195374; batch adversarial loss: 0.428090\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173262; batch adversarial loss: 0.465897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238438; batch adversarial loss: 0.458932\n",
      "epoch 43; iter: 0; batch classifier loss: 0.197929; batch adversarial loss: 0.408860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.138578; batch adversarial loss: 0.469487\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166553; batch adversarial loss: 0.575425\n",
      "epoch 46; iter: 0; batch classifier loss: 0.182484; batch adversarial loss: 0.505872\n",
      "epoch 47; iter: 0; batch classifier loss: 0.236504; batch adversarial loss: 0.426278\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186671; batch adversarial loss: 0.431010\n",
      "epoch 49; iter: 0; batch classifier loss: 0.152745; batch adversarial loss: 0.519387\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243147; batch adversarial loss: 0.437568\n",
      "epoch 51; iter: 0; batch classifier loss: 0.240841; batch adversarial loss: 0.447285\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183117; batch adversarial loss: 0.403747\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216382; batch adversarial loss: 0.506916\n",
      "epoch 54; iter: 0; batch classifier loss: 0.184249; batch adversarial loss: 0.648510\n",
      "epoch 55; iter: 0; batch classifier loss: 0.219086; batch adversarial loss: 0.459083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.204157; batch adversarial loss: 0.448338\n",
      "epoch 57; iter: 0; batch classifier loss: 0.172564; batch adversarial loss: 0.447473\n",
      "epoch 58; iter: 0; batch classifier loss: 0.146000; batch adversarial loss: 0.495112\n",
      "epoch 59; iter: 0; batch classifier loss: 0.198737; batch adversarial loss: 0.388494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.273728; batch adversarial loss: 0.375899\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233602; batch adversarial loss: 0.447141\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107979; batch adversarial loss: 0.518234\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103857; batch adversarial loss: 0.455904\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083528; batch adversarial loss: 0.456075\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104859; batch adversarial loss: 0.604147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071711; batch adversarial loss: 0.536908\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065673; batch adversarial loss: 0.482828\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169758; batch adversarial loss: 0.480501\n",
      "epoch 69; iter: 0; batch classifier loss: 0.158045; batch adversarial loss: 0.480687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.188193; batch adversarial loss: 0.489066\n",
      "epoch 71; iter: 0; batch classifier loss: 0.236623; batch adversarial loss: 0.507266\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115128; batch adversarial loss: 0.482344\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187383; batch adversarial loss: 0.338179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200770; batch adversarial loss: 0.375866\n",
      "epoch 75; iter: 0; batch classifier loss: 0.202577; batch adversarial loss: 0.457207\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132412; batch adversarial loss: 0.491116\n",
      "epoch 77; iter: 0; batch classifier loss: 0.175840; batch adversarial loss: 0.423293\n",
      "epoch 78; iter: 0; batch classifier loss: 0.148489; batch adversarial loss: 0.459323\n",
      "epoch 79; iter: 0; batch classifier loss: 0.301921; batch adversarial loss: 0.459011\n",
      "epoch 80; iter: 0; batch classifier loss: 0.160233; batch adversarial loss: 0.569314\n",
      "epoch 81; iter: 0; batch classifier loss: 0.145912; batch adversarial loss: 0.469095\n",
      "epoch 82; iter: 0; batch classifier loss: 0.176397; batch adversarial loss: 0.386666\n",
      "epoch 83; iter: 0; batch classifier loss: 0.156547; batch adversarial loss: 0.509526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.176673; batch adversarial loss: 0.446213\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133624; batch adversarial loss: 0.577589\n",
      "epoch 86; iter: 0; batch classifier loss: 0.161921; batch adversarial loss: 0.482345\n",
      "epoch 87; iter: 0; batch classifier loss: 0.174910; batch adversarial loss: 0.469904\n",
      "epoch 88; iter: 0; batch classifier loss: 0.235085; batch adversarial loss: 0.448102\n",
      "epoch 89; iter: 0; batch classifier loss: 0.242966; batch adversarial loss: 0.507309\n",
      "epoch 90; iter: 0; batch classifier loss: 0.189098; batch adversarial loss: 0.423959\n",
      "epoch 91; iter: 0; batch classifier loss: 0.183500; batch adversarial loss: 0.567119\n",
      "epoch 92; iter: 0; batch classifier loss: 0.219468; batch adversarial loss: 0.387766\n",
      "epoch 93; iter: 0; batch classifier loss: 0.120715; batch adversarial loss: 0.530797\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079777; batch adversarial loss: 0.518158\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064684; batch adversarial loss: 0.490349\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050785; batch adversarial loss: 0.481323\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059905; batch adversarial loss: 0.398109\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050501; batch adversarial loss: 0.380418\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050228; batch adversarial loss: 0.567420\n",
      "epoch 100; iter: 0; batch classifier loss: 0.082431; batch adversarial loss: 0.434749\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042748; batch adversarial loss: 0.399192\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053252; batch adversarial loss: 0.446209\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065482; batch adversarial loss: 0.386045\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087212; batch adversarial loss: 0.549669\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031244; batch adversarial loss: 0.400428\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061916; batch adversarial loss: 0.430669\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086567; batch adversarial loss: 0.385476\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055592; batch adversarial loss: 0.367096\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058300; batch adversarial loss: 0.509026\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048936; batch adversarial loss: 0.498016\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047945; batch adversarial loss: 0.357420\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078309; batch adversarial loss: 0.516110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055633; batch adversarial loss: 0.440471\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075205; batch adversarial loss: 0.571069\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035805; batch adversarial loss: 0.448031\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052929; batch adversarial loss: 0.381873\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048472; batch adversarial loss: 0.434234\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038641; batch adversarial loss: 0.411716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045436; batch adversarial loss: 0.516453\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049702; batch adversarial loss: 0.503423\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059555; batch adversarial loss: 0.428133\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056149; batch adversarial loss: 0.518772\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065829; batch adversarial loss: 0.443718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.082015; batch adversarial loss: 0.472513\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038508; batch adversarial loss: 0.444147\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036141; batch adversarial loss: 0.482446\n",
      "epoch 127; iter: 0; batch classifier loss: 0.087554; batch adversarial loss: 0.505147\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.503728\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043621; batch adversarial loss: 0.398582\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058998; batch adversarial loss: 0.401906\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030180; batch adversarial loss: 0.401114\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048206; batch adversarial loss: 0.488496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050735; batch adversarial loss: 0.405254\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048290; batch adversarial loss: 0.433761\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062946; batch adversarial loss: 0.318568\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056380; batch adversarial loss: 0.481854\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048857; batch adversarial loss: 0.455946\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033501; batch adversarial loss: 0.394199\n",
      "epoch 139; iter: 0; batch classifier loss: 0.108863; batch adversarial loss: 0.410378\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029212; batch adversarial loss: 0.407861\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047733; batch adversarial loss: 0.435275\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051944; batch adversarial loss: 0.384476\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035815; batch adversarial loss: 0.462138\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058670; batch adversarial loss: 0.486890\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034721; batch adversarial loss: 0.413119\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061096; batch adversarial loss: 0.491052\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045325; batch adversarial loss: 0.431594\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040353; batch adversarial loss: 0.462826\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041665; batch adversarial loss: 0.402854\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037712; batch adversarial loss: 0.491257\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052056; batch adversarial loss: 0.465035\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044387; batch adversarial loss: 0.371372\n",
      "epoch 153; iter: 0; batch classifier loss: 0.071960; batch adversarial loss: 0.429950\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040070; batch adversarial loss: 0.484812\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065899; batch adversarial loss: 0.384362\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028423; batch adversarial loss: 0.394051\n",
      "epoch 157; iter: 0; batch classifier loss: 0.069060; batch adversarial loss: 0.364622\n",
      "epoch 158; iter: 0; batch classifier loss: 0.060708; batch adversarial loss: 0.410331\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042502; batch adversarial loss: 0.420785\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050619; batch adversarial loss: 0.544203\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051670; batch adversarial loss: 0.593494\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041105; batch adversarial loss: 0.316357\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057901; batch adversarial loss: 0.477271\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047553; batch adversarial loss: 0.379628\n",
      "epoch 165; iter: 0; batch classifier loss: 0.053199; batch adversarial loss: 0.475871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.059199; batch adversarial loss: 0.475781\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054854; batch adversarial loss: 0.482989\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041389; batch adversarial loss: 0.440266\n",
      "epoch 169; iter: 0; batch classifier loss: 0.064103; batch adversarial loss: 0.501047\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054892; batch adversarial loss: 0.468793\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037928; batch adversarial loss: 0.440044\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049016; batch adversarial loss: 0.541872\n",
      "epoch 173; iter: 0; batch classifier loss: 0.067045; batch adversarial loss: 0.468206\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042024; batch adversarial loss: 0.489668\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033409; batch adversarial loss: 0.436490\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037928; batch adversarial loss: 0.447434\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.425768\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043565; batch adversarial loss: 0.447904\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037316; batch adversarial loss: 0.457919\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046121; batch adversarial loss: 0.413397\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052655; batch adversarial loss: 0.412378\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042337; batch adversarial loss: 0.485029\n",
      "epoch 183; iter: 0; batch classifier loss: 0.056180; batch adversarial loss: 0.417567\n",
      "epoch 184; iter: 0; batch classifier loss: 0.048331; batch adversarial loss: 0.384914\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037866; batch adversarial loss: 0.488073\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032551; batch adversarial loss: 0.436730\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033913; batch adversarial loss: 0.423869\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033951; batch adversarial loss: 0.574369\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043243; batch adversarial loss: 0.445034\n",
      "epoch 190; iter: 0; batch classifier loss: 0.053601; batch adversarial loss: 0.483612\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032461; batch adversarial loss: 0.480256\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029719; batch adversarial loss: 0.462360\n",
      "epoch 193; iter: 0; batch classifier loss: 0.061316; batch adversarial loss: 0.414006\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036519; batch adversarial loss: 0.403340\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042261; batch adversarial loss: 0.438228\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032322; batch adversarial loss: 0.434298\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032445; batch adversarial loss: 0.367334\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033170; batch adversarial loss: 0.543875\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021331; batch adversarial loss: 0.502978\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698059; batch adversarial loss: 0.764940\n",
      "epoch 1; iter: 0; batch classifier loss: 0.602016; batch adversarial loss: 0.714722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.451477; batch adversarial loss: 0.604958\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348567; batch adversarial loss: 0.605608\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342427; batch adversarial loss: 0.550639\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345388; batch adversarial loss: 0.578777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257396; batch adversarial loss: 0.563340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354511; batch adversarial loss: 0.570369\n",
      "epoch 8; iter: 0; batch classifier loss: 0.250847; batch adversarial loss: 0.537498\n",
      "epoch 9; iter: 0; batch classifier loss: 0.253519; batch adversarial loss: 0.453516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262903; batch adversarial loss: 0.485796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343701; batch adversarial loss: 0.537451\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254891; batch adversarial loss: 0.478990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262697; batch adversarial loss: 0.462025\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236393; batch adversarial loss: 0.548176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.195972; batch adversarial loss: 0.534495\n",
      "epoch 16; iter: 0; batch classifier loss: 0.214787; batch adversarial loss: 0.499922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.195315; batch adversarial loss: 0.528108\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207358; batch adversarial loss: 0.458792\n",
      "epoch 19; iter: 0; batch classifier loss: 0.146767; batch adversarial loss: 0.501361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179146; batch adversarial loss: 0.493895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.222493; batch adversarial loss: 0.421672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.160027; batch adversarial loss: 0.439671\n",
      "epoch 23; iter: 0; batch classifier loss: 0.129843; batch adversarial loss: 0.516944\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248871; batch adversarial loss: 0.525447\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172851; batch adversarial loss: 0.540317\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149304; batch adversarial loss: 0.490987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162770; batch adversarial loss: 0.473750\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154412; batch adversarial loss: 0.460728\n",
      "epoch 29; iter: 0; batch classifier loss: 0.113657; batch adversarial loss: 0.553437\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167712; batch adversarial loss: 0.434975\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151715; batch adversarial loss: 0.452962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183334; batch adversarial loss: 0.420407\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125859; batch adversarial loss: 0.419742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123183; batch adversarial loss: 0.401255\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117021; batch adversarial loss: 0.464960\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141243; batch adversarial loss: 0.387135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123475; batch adversarial loss: 0.519977\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176927; batch adversarial loss: 0.461851\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125857; batch adversarial loss: 0.444647\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123597; batch adversarial loss: 0.434709\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090399; batch adversarial loss: 0.416270\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114052; batch adversarial loss: 0.474650\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126211; batch adversarial loss: 0.526851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104074; batch adversarial loss: 0.479791\n",
      "epoch 45; iter: 0; batch classifier loss: 0.169211; batch adversarial loss: 0.461431\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106640; batch adversarial loss: 0.448886\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106818; batch adversarial loss: 0.562781\n",
      "epoch 48; iter: 0; batch classifier loss: 0.149926; batch adversarial loss: 0.480525\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149241; batch adversarial loss: 0.463990\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073747; batch adversarial loss: 0.456565\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114814; batch adversarial loss: 0.500368\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142802; batch adversarial loss: 0.426906\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143351; batch adversarial loss: 0.374262\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081060; batch adversarial loss: 0.424910\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134716; batch adversarial loss: 0.407526\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116716; batch adversarial loss: 0.451742\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093562; batch adversarial loss: 0.435640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107002; batch adversarial loss: 0.513046\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087523; batch adversarial loss: 0.455059\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086557; batch adversarial loss: 0.322889\n",
      "epoch 61; iter: 0; batch classifier loss: 0.085129; batch adversarial loss: 0.396255\n",
      "epoch 62; iter: 0; batch classifier loss: 0.118554; batch adversarial loss: 0.504899\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102080; batch adversarial loss: 0.340032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.075119; batch adversarial loss: 0.482382\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084751; batch adversarial loss: 0.431369\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075800; batch adversarial loss: 0.468399\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078327; batch adversarial loss: 0.431902\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069402; batch adversarial loss: 0.438476\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053793; batch adversarial loss: 0.533010\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059832; batch adversarial loss: 0.512285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090697; batch adversarial loss: 0.408108\n",
      "epoch 72; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.478872\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072115; batch adversarial loss: 0.542601\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069077; batch adversarial loss: 0.545169\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074716; batch adversarial loss: 0.526332\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068836; batch adversarial loss: 0.413822\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042590; batch adversarial loss: 0.468714\n",
      "epoch 78; iter: 0; batch classifier loss: 0.116504; batch adversarial loss: 0.488177\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055893; batch adversarial loss: 0.498654\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083518; batch adversarial loss: 0.516834\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057119; batch adversarial loss: 0.433860\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055391; batch adversarial loss: 0.457307\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041160; batch adversarial loss: 0.512717\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082411; batch adversarial loss: 0.506343\n",
      "epoch 85; iter: 0; batch classifier loss: 0.034464; batch adversarial loss: 0.434977\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042148; batch adversarial loss: 0.395370\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053498; batch adversarial loss: 0.400705\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040215; batch adversarial loss: 0.441856\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043919; batch adversarial loss: 0.451893\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046307; batch adversarial loss: 0.478555\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100760; batch adversarial loss: 0.405103\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055100; batch adversarial loss: 0.402218\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042211; batch adversarial loss: 0.404800\n",
      "epoch 94; iter: 0; batch classifier loss: 0.029891; batch adversarial loss: 0.425201\n",
      "epoch 95; iter: 0; batch classifier loss: 0.027552; batch adversarial loss: 0.490206\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065788; batch adversarial loss: 0.482206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043242; batch adversarial loss: 0.481047\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058814; batch adversarial loss: 0.485391\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053469; batch adversarial loss: 0.399799\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050625; batch adversarial loss: 0.519019\n",
      "epoch 101; iter: 0; batch classifier loss: 0.021315; batch adversarial loss: 0.428504\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031520; batch adversarial loss: 0.442535\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046936; batch adversarial loss: 0.438918\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030371; batch adversarial loss: 0.450122\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056612; batch adversarial loss: 0.391177\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037250; batch adversarial loss: 0.469576\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020725; batch adversarial loss: 0.463769\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034868; batch adversarial loss: 0.440050\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029861; batch adversarial loss: 0.510724\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056950; batch adversarial loss: 0.485929\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066229; batch adversarial loss: 0.390016\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036813; batch adversarial loss: 0.445519\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050805; batch adversarial loss: 0.331852\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029595; batch adversarial loss: 0.416366\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036178; batch adversarial loss: 0.518076\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042891; batch adversarial loss: 0.449603\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039005; batch adversarial loss: 0.410194\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028218; batch adversarial loss: 0.438906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032832; batch adversarial loss: 0.501051\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035018; batch adversarial loss: 0.414770\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029513; batch adversarial loss: 0.377713\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048666; batch adversarial loss: 0.419542\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036444; batch adversarial loss: 0.515755\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020068; batch adversarial loss: 0.365413\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.407845\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.487082\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019675; batch adversarial loss: 0.401780\n",
      "epoch 128; iter: 0; batch classifier loss: 0.057217; batch adversarial loss: 0.449223\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035776; batch adversarial loss: 0.446206\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050000; batch adversarial loss: 0.442851\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031375; batch adversarial loss: 0.522129\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043594; batch adversarial loss: 0.709630\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036151; batch adversarial loss: 0.543025\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010918; batch adversarial loss: 0.500231\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039954; batch adversarial loss: 0.477967\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024072; batch adversarial loss: 0.507240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042343; batch adversarial loss: 0.401375\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022809; batch adversarial loss: 0.470741\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034377; batch adversarial loss: 0.402421\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021526; batch adversarial loss: 0.408730\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011807; batch adversarial loss: 0.506210\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051435; batch adversarial loss: 0.478633\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014211; batch adversarial loss: 0.431055\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009712; batch adversarial loss: 0.518047\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033641; batch adversarial loss: 0.501297\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019084; batch adversarial loss: 0.476267\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028233; batch adversarial loss: 0.439018\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019833; batch adversarial loss: 0.407802\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027187; batch adversarial loss: 0.438514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018676; batch adversarial loss: 0.437812\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055928; batch adversarial loss: 0.411088\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021490; batch adversarial loss: 0.495104\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010093; batch adversarial loss: 0.457651\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006111; batch adversarial loss: 0.534975\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034082; batch adversarial loss: 0.434658\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015978; batch adversarial loss: 0.380281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013851; batch adversarial loss: 0.398867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029410; batch adversarial loss: 0.488384\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034402; batch adversarial loss: 0.433550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.008955; batch adversarial loss: 0.415296\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006686; batch adversarial loss: 0.356953\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013953; batch adversarial loss: 0.488853\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013779; batch adversarial loss: 0.402995\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006130; batch adversarial loss: 0.487194\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021020; batch adversarial loss: 0.490774\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052983; batch adversarial loss: 0.517167\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037530; batch adversarial loss: 0.387090\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009754; batch adversarial loss: 0.470146\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029513; batch adversarial loss: 0.547184\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011217; batch adversarial loss: 0.476011\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029579; batch adversarial loss: 0.426234\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033807; batch adversarial loss: 0.541643\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011748; batch adversarial loss: 0.438082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.517625\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017479; batch adversarial loss: 0.427449\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007590; batch adversarial loss: 0.467816\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014094; batch adversarial loss: 0.432426\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015762; batch adversarial loss: 0.429308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021187; batch adversarial loss: 0.392283\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014831; batch adversarial loss: 0.521993\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004792; batch adversarial loss: 0.472262\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021161; batch adversarial loss: 0.467167\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030150; batch adversarial loss: 0.493681\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.385594\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022276; batch adversarial loss: 0.504966\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019159; batch adversarial loss: 0.439057\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022333; batch adversarial loss: 0.505742\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023451; batch adversarial loss: 0.394948\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008610; batch adversarial loss: 0.441473\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004778; batch adversarial loss: 0.457579\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013507; batch adversarial loss: 0.548552\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020332; batch adversarial loss: 0.425282\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020799; batch adversarial loss: 0.429931\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018156; batch adversarial loss: 0.419414\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007857; batch adversarial loss: 0.463377\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007671; batch adversarial loss: 0.422551\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023737; batch adversarial loss: 0.364695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.446390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049816; batch adversarial loss: 0.549630\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670733; batch adversarial loss: 0.645706\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428073; batch adversarial loss: 0.633260\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401913; batch adversarial loss: 0.645569\n",
      "epoch 3; iter: 0; batch classifier loss: 0.370927; batch adversarial loss: 0.629859\n",
      "epoch 4; iter: 0; batch classifier loss: 0.421041; batch adversarial loss: 0.611685\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489485; batch adversarial loss: 0.629554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451340; batch adversarial loss: 0.597085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393800; batch adversarial loss: 0.531563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439240; batch adversarial loss: 0.564353\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530962; batch adversarial loss: 0.570529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419627; batch adversarial loss: 0.549137\n",
      "epoch 11; iter: 0; batch classifier loss: 0.356445; batch adversarial loss: 0.498813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362710; batch adversarial loss: 0.511976\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413339; batch adversarial loss: 0.479108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377301; batch adversarial loss: 0.435561\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326263; batch adversarial loss: 0.496898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281160; batch adversarial loss: 0.501456\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320407; batch adversarial loss: 0.475787\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220925; batch adversarial loss: 0.552233\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280966; batch adversarial loss: 0.454111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.359720; batch adversarial loss: 0.455393\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215182; batch adversarial loss: 0.491531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303393; batch adversarial loss: 0.416829\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206677; batch adversarial loss: 0.499487\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240754; batch adversarial loss: 0.413040\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202649; batch adversarial loss: 0.407418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207486; batch adversarial loss: 0.454323\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245873; batch adversarial loss: 0.490123\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196818; batch adversarial loss: 0.530100\n",
      "epoch 29; iter: 0; batch classifier loss: 0.261757; batch adversarial loss: 0.485666\n",
      "epoch 30; iter: 0; batch classifier loss: 0.310939; batch adversarial loss: 0.448273\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243073; batch adversarial loss: 0.393039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197420; batch adversarial loss: 0.481905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198870; batch adversarial loss: 0.492619\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232820; batch adversarial loss: 0.538720\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277334; batch adversarial loss: 0.420812\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192036; batch adversarial loss: 0.448649\n",
      "epoch 37; iter: 0; batch classifier loss: 0.200465; batch adversarial loss: 0.430760\n",
      "epoch 38; iter: 0; batch classifier loss: 0.184018; batch adversarial loss: 0.405136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.210416; batch adversarial loss: 0.453189\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240445; batch adversarial loss: 0.481945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.194994; batch adversarial loss: 0.423625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202101; batch adversarial loss: 0.468152\n",
      "epoch 43; iter: 0; batch classifier loss: 0.196197; batch adversarial loss: 0.485684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.266936; batch adversarial loss: 0.472522\n",
      "epoch 45; iter: 0; batch classifier loss: 0.237092; batch adversarial loss: 0.539043\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169655; batch adversarial loss: 0.393702\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238401; batch adversarial loss: 0.463155\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232868; batch adversarial loss: 0.438480\n",
      "epoch 49; iter: 0; batch classifier loss: 0.204063; batch adversarial loss: 0.425405\n",
      "epoch 50; iter: 0; batch classifier loss: 0.230644; batch adversarial loss: 0.554398\n",
      "epoch 51; iter: 0; batch classifier loss: 0.263435; batch adversarial loss: 0.435698\n",
      "epoch 52; iter: 0; batch classifier loss: 0.192031; batch adversarial loss: 0.422814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.172764; batch adversarial loss: 0.351871\n",
      "epoch 54; iter: 0; batch classifier loss: 0.166772; batch adversarial loss: 0.422594\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106646; batch adversarial loss: 0.507127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.168126; batch adversarial loss: 0.480731\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188624; batch adversarial loss: 0.384710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.156922; batch adversarial loss: 0.458607\n",
      "epoch 59; iter: 0; batch classifier loss: 0.225439; batch adversarial loss: 0.443439\n",
      "epoch 60; iter: 0; batch classifier loss: 0.280551; batch adversarial loss: 0.472352\n",
      "epoch 61; iter: 0; batch classifier loss: 0.177370; batch adversarial loss: 0.544596\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173107; batch adversarial loss: 0.434121\n",
      "epoch 63; iter: 0; batch classifier loss: 0.172779; batch adversarial loss: 0.422745\n",
      "epoch 64; iter: 0; batch classifier loss: 0.145356; batch adversarial loss: 0.519436\n",
      "epoch 65; iter: 0; batch classifier loss: 0.164362; batch adversarial loss: 0.458628\n",
      "epoch 66; iter: 0; batch classifier loss: 0.187842; batch adversarial loss: 0.435077\n",
      "epoch 67; iter: 0; batch classifier loss: 0.125952; batch adversarial loss: 0.458623\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091000; batch adversarial loss: 0.443528\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087389; batch adversarial loss: 0.394143\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069951; batch adversarial loss: 0.403500\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073745; batch adversarial loss: 0.381404\n",
      "epoch 72; iter: 0; batch classifier loss: 0.201737; batch adversarial loss: 0.494434\n",
      "epoch 73; iter: 0; batch classifier loss: 0.172502; batch adversarial loss: 0.471900\n",
      "epoch 74; iter: 0; batch classifier loss: 0.118113; batch adversarial loss: 0.393087\n",
      "epoch 75; iter: 0; batch classifier loss: 0.144936; batch adversarial loss: 0.387145\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153258; batch adversarial loss: 0.311715\n",
      "epoch 77; iter: 0; batch classifier loss: 0.137489; batch adversarial loss: 0.528276\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096509; batch adversarial loss: 0.533434\n",
      "epoch 79; iter: 0; batch classifier loss: 0.203499; batch adversarial loss: 0.386213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.167268; batch adversarial loss: 0.420692\n",
      "epoch 81; iter: 0; batch classifier loss: 0.178550; batch adversarial loss: 0.434909\n",
      "epoch 82; iter: 0; batch classifier loss: 0.185432; batch adversarial loss: 0.428398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.128302; batch adversarial loss: 0.420624\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109694; batch adversarial loss: 0.413766\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108285; batch adversarial loss: 0.505851\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072620; batch adversarial loss: 0.423482\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087763; batch adversarial loss: 0.494995\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062966; batch adversarial loss: 0.492554\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106517; batch adversarial loss: 0.472483\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089377; batch adversarial loss: 0.408475\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052668; batch adversarial loss: 0.513767\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073485; batch adversarial loss: 0.447466\n",
      "epoch 93; iter: 0; batch classifier loss: 0.151655; batch adversarial loss: 0.431390\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048997; batch adversarial loss: 0.441564\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042310; batch adversarial loss: 0.507713\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064074; batch adversarial loss: 0.518537\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086607; batch adversarial loss: 0.390140\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056698; batch adversarial loss: 0.431632\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040855; batch adversarial loss: 0.518534\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068886; batch adversarial loss: 0.416234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034890; batch adversarial loss: 0.465171\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069000; batch adversarial loss: 0.535077\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080906; batch adversarial loss: 0.397512\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039674; batch adversarial loss: 0.498917\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038300; batch adversarial loss: 0.471268\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064892; batch adversarial loss: 0.402013\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031423; batch adversarial loss: 0.468697\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044454; batch adversarial loss: 0.498935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042841; batch adversarial loss: 0.382857\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035524; batch adversarial loss: 0.485182\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037314; batch adversarial loss: 0.410266\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038245; batch adversarial loss: 0.517902\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021083; batch adversarial loss: 0.601692\n",
      "epoch 114; iter: 0; batch classifier loss: 0.016482; batch adversarial loss: 0.540358\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028979; batch adversarial loss: 0.418066\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021931; batch adversarial loss: 0.438946\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042094; batch adversarial loss: 0.417143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031345; batch adversarial loss: 0.489429\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026861; batch adversarial loss: 0.527126\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036181; batch adversarial loss: 0.351375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051732; batch adversarial loss: 0.473893\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027717; batch adversarial loss: 0.463185\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060306; batch adversarial loss: 0.410438\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061680; batch adversarial loss: 0.491574\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061300; batch adversarial loss: 0.407417\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070199; batch adversarial loss: 0.402839\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037641; batch adversarial loss: 0.511790\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031309; batch adversarial loss: 0.473321\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032612; batch adversarial loss: 0.519392\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043524; batch adversarial loss: 0.555975\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033718; batch adversarial loss: 0.485877\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024986; batch adversarial loss: 0.446342\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014640; batch adversarial loss: 0.478759\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035397; batch adversarial loss: 0.390114\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038203; batch adversarial loss: 0.482435\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021853; batch adversarial loss: 0.520868\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.447032\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052392; batch adversarial loss: 0.466726\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021691; batch adversarial loss: 0.441774\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011007; batch adversarial loss: 0.376068\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040095; batch adversarial loss: 0.380020\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032493; batch adversarial loss: 0.472008\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024290; batch adversarial loss: 0.453516\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027539; batch adversarial loss: 0.384079\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026986; batch adversarial loss: 0.424642\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.434454\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017765; batch adversarial loss: 0.395066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.288117\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015625; batch adversarial loss: 0.418112\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024314; batch adversarial loss: 0.455004\n",
      "epoch 151; iter: 0; batch classifier loss: 0.049219; batch adversarial loss: 0.369239\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008644; batch adversarial loss: 0.455272\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026477; batch adversarial loss: 0.429581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.529137\n",
      "epoch 155; iter: 0; batch classifier loss: 0.060256; batch adversarial loss: 0.415461\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017306; batch adversarial loss: 0.377514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014616; batch adversarial loss: 0.458481\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019923; batch adversarial loss: 0.350510\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038821; batch adversarial loss: 0.450557\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045251; batch adversarial loss: 0.526564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008700; batch adversarial loss: 0.431710\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019558; batch adversarial loss: 0.456022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029920; batch adversarial loss: 0.549223\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032696; batch adversarial loss: 0.541497\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.433144\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014915; batch adversarial loss: 0.409384\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055925; batch adversarial loss: 0.434982\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020190; batch adversarial loss: 0.489099\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016791; batch adversarial loss: 0.436913\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026659; batch adversarial loss: 0.544694\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016703; batch adversarial loss: 0.494809\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027582; batch adversarial loss: 0.451508\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023441; batch adversarial loss: 0.396788\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016058; batch adversarial loss: 0.483469\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008808; batch adversarial loss: 0.483254\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008544; batch adversarial loss: 0.391457\n",
      "epoch 177; iter: 0; batch classifier loss: 0.007655; batch adversarial loss: 0.437533\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046733; batch adversarial loss: 0.472973\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020310; batch adversarial loss: 0.489207\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.468606\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042294; batch adversarial loss: 0.521556\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011754; batch adversarial loss: 0.564487\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014102; batch adversarial loss: 0.486722\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033034; batch adversarial loss: 0.381662\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015444; batch adversarial loss: 0.442594\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036893; batch adversarial loss: 0.374764\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004137; batch adversarial loss: 0.392471\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016354; batch adversarial loss: 0.378331\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020562; batch adversarial loss: 0.420848\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012079; batch adversarial loss: 0.449280\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011740; batch adversarial loss: 0.467675\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004271; batch adversarial loss: 0.441150\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012469; batch adversarial loss: 0.537731\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032329; batch adversarial loss: 0.505080\n",
      "epoch 195; iter: 0; batch classifier loss: 0.057292; batch adversarial loss: 0.449892\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012951; batch adversarial loss: 0.526080\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015122; batch adversarial loss: 0.415201\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020417; batch adversarial loss: 0.524912\n",
      "epoch 199; iter: 0; batch classifier loss: 0.055533; batch adversarial loss: 0.425393\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673075; batch adversarial loss: 0.474173\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430286; batch adversarial loss: 0.611209\n",
      "epoch 2; iter: 0; batch classifier loss: 0.442871; batch adversarial loss: 0.542133\n",
      "epoch 3; iter: 0; batch classifier loss: 0.302950; batch adversarial loss: 0.574110\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378769; batch adversarial loss: 0.570457\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292598; batch adversarial loss: 0.554752\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437809; batch adversarial loss: 0.568799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312819; batch adversarial loss: 0.510609\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403431; batch adversarial loss: 0.567400\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377803; batch adversarial loss: 0.538104\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367429; batch adversarial loss: 0.544959\n",
      "epoch 11; iter: 0; batch classifier loss: 0.418508; batch adversarial loss: 0.516325\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369087; batch adversarial loss: 0.562480\n",
      "epoch 13; iter: 0; batch classifier loss: 0.441199; batch adversarial loss: 0.456336\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548925; batch adversarial loss: 0.567449\n",
      "epoch 15; iter: 0; batch classifier loss: 0.521961; batch adversarial loss: 0.491558\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404735; batch adversarial loss: 0.470360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261943; batch adversarial loss: 0.431260\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268333; batch adversarial loss: 0.444112\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225981; batch adversarial loss: 0.463211\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213929; batch adversarial loss: 0.404350\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258983; batch adversarial loss: 0.502869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264922; batch adversarial loss: 0.508492\n",
      "epoch 23; iter: 0; batch classifier loss: 0.204519; batch adversarial loss: 0.384424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178996; batch adversarial loss: 0.456617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175786; batch adversarial loss: 0.467395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160245; batch adversarial loss: 0.464723\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184504; batch adversarial loss: 0.401762\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172238; batch adversarial loss: 0.452644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146383; batch adversarial loss: 0.479786\n",
      "epoch 30; iter: 0; batch classifier loss: 0.118730; batch adversarial loss: 0.504106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.142438; batch adversarial loss: 0.382898\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115499; batch adversarial loss: 0.478291\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134547; batch adversarial loss: 0.393845\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116388; batch adversarial loss: 0.583860\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122840; batch adversarial loss: 0.522629\n",
      "epoch 36; iter: 0; batch classifier loss: 0.159013; batch adversarial loss: 0.411629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117937; batch adversarial loss: 0.519415\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142797; batch adversarial loss: 0.418612\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163127; batch adversarial loss: 0.480244\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115826; batch adversarial loss: 0.419263\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168862; batch adversarial loss: 0.513719\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111408; batch adversarial loss: 0.502427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134247; batch adversarial loss: 0.425327\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163846; batch adversarial loss: 0.429677\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103342; batch adversarial loss: 0.521255\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104751; batch adversarial loss: 0.544405\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135201; batch adversarial loss: 0.465635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128556; batch adversarial loss: 0.465657\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107788; batch adversarial loss: 0.529892\n",
      "epoch 50; iter: 0; batch classifier loss: 0.078747; batch adversarial loss: 0.481046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.165528; batch adversarial loss: 0.505325\n",
      "epoch 52; iter: 0; batch classifier loss: 0.196476; batch adversarial loss: 0.401737\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149154; batch adversarial loss: 0.432386\n",
      "epoch 54; iter: 0; batch classifier loss: 0.167026; batch adversarial loss: 0.477435\n",
      "epoch 55; iter: 0; batch classifier loss: 0.140831; batch adversarial loss: 0.503557\n",
      "epoch 56; iter: 0; batch classifier loss: 0.137970; batch adversarial loss: 0.399887\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113864; batch adversarial loss: 0.481972\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105099; batch adversarial loss: 0.484198\n",
      "epoch 59; iter: 0; batch classifier loss: 0.073705; batch adversarial loss: 0.446607\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116015; batch adversarial loss: 0.491415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.153512; batch adversarial loss: 0.470287\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111115; batch adversarial loss: 0.549753\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177138; batch adversarial loss: 0.461937\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123107; batch adversarial loss: 0.417733\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144031; batch adversarial loss: 0.511479\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118031; batch adversarial loss: 0.497537\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184343; batch adversarial loss: 0.470169\n",
      "epoch 68; iter: 0; batch classifier loss: 0.150348; batch adversarial loss: 0.419364\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122488; batch adversarial loss: 0.524125\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156975; batch adversarial loss: 0.463247\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128046; batch adversarial loss: 0.376799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.136024; batch adversarial loss: 0.436127\n",
      "epoch 73; iter: 0; batch classifier loss: 0.157926; batch adversarial loss: 0.381665\n",
      "epoch 74; iter: 0; batch classifier loss: 0.150386; batch adversarial loss: 0.461788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.209157; batch adversarial loss: 0.418500\n",
      "epoch 76; iter: 0; batch classifier loss: 0.182562; batch adversarial loss: 0.449019\n",
      "epoch 77; iter: 0; batch classifier loss: 0.167810; batch adversarial loss: 0.475298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.174321; batch adversarial loss: 0.454734\n",
      "epoch 79; iter: 0; batch classifier loss: 0.161259; batch adversarial loss: 0.379611\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103867; batch adversarial loss: 0.488714\n",
      "epoch 81; iter: 0; batch classifier loss: 0.131688; batch adversarial loss: 0.461946\n",
      "epoch 82; iter: 0; batch classifier loss: 0.151584; batch adversarial loss: 0.463632\n",
      "epoch 83; iter: 0; batch classifier loss: 0.145608; batch adversarial loss: 0.428697\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096989; batch adversarial loss: 0.444809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.101143; batch adversarial loss: 0.457586\n",
      "epoch 86; iter: 0; batch classifier loss: 0.188247; batch adversarial loss: 0.543722\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106885; batch adversarial loss: 0.370469\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144076; batch adversarial loss: 0.458901\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099531; batch adversarial loss: 0.545627\n",
      "epoch 90; iter: 0; batch classifier loss: 0.131519; batch adversarial loss: 0.466224\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110851; batch adversarial loss: 0.609320\n",
      "epoch 92; iter: 0; batch classifier loss: 0.163850; batch adversarial loss: 0.572268\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078882; batch adversarial loss: 0.505937\n",
      "epoch 94; iter: 0; batch classifier loss: 0.155486; batch adversarial loss: 0.490416\n",
      "epoch 95; iter: 0; batch classifier loss: 0.115406; batch adversarial loss: 0.592613\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116546; batch adversarial loss: 0.416835\n",
      "epoch 97; iter: 0; batch classifier loss: 0.125393; batch adversarial loss: 0.561086\n",
      "epoch 98; iter: 0; batch classifier loss: 0.162249; batch adversarial loss: 0.433285\n",
      "epoch 99; iter: 0; batch classifier loss: 0.178324; batch adversarial loss: 0.412981\n",
      "epoch 100; iter: 0; batch classifier loss: 0.150042; batch adversarial loss: 0.533879\n",
      "epoch 101; iter: 0; batch classifier loss: 0.170841; batch adversarial loss: 0.555060\n",
      "epoch 102; iter: 0; batch classifier loss: 0.164422; batch adversarial loss: 0.501547\n",
      "epoch 103; iter: 0; batch classifier loss: 0.162492; batch adversarial loss: 0.451249\n",
      "epoch 104; iter: 0; batch classifier loss: 0.178071; batch adversarial loss: 0.474438\n",
      "epoch 105; iter: 0; batch classifier loss: 0.189224; batch adversarial loss: 0.449643\n",
      "epoch 106; iter: 0; batch classifier loss: 0.128718; batch adversarial loss: 0.532455\n",
      "epoch 107; iter: 0; batch classifier loss: 0.170670; batch adversarial loss: 0.466075\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122460; batch adversarial loss: 0.510573\n",
      "epoch 109; iter: 0; batch classifier loss: 0.164120; batch adversarial loss: 0.397749\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086008; batch adversarial loss: 0.536662\n",
      "epoch 111; iter: 0; batch classifier loss: 0.165815; batch adversarial loss: 0.439010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.144928; batch adversarial loss: 0.428450\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073409; batch adversarial loss: 0.493629\n",
      "epoch 114; iter: 0; batch classifier loss: 0.083825; batch adversarial loss: 0.512226\n",
      "epoch 115; iter: 0; batch classifier loss: 0.120149; batch adversarial loss: 0.422821\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072862; batch adversarial loss: 0.515454\n",
      "epoch 117; iter: 0; batch classifier loss: 0.083194; batch adversarial loss: 0.405252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081939; batch adversarial loss: 0.548030\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073677; batch adversarial loss: 0.492663\n",
      "epoch 120; iter: 0; batch classifier loss: 0.092964; batch adversarial loss: 0.494752\n",
      "epoch 121; iter: 0; batch classifier loss: 0.099470; batch adversarial loss: 0.433648\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077287; batch adversarial loss: 0.404587\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054120; batch adversarial loss: 0.589833\n",
      "epoch 124; iter: 0; batch classifier loss: 0.078034; batch adversarial loss: 0.442905\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076674; batch adversarial loss: 0.426622\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042327; batch adversarial loss: 0.537914\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071255; batch adversarial loss: 0.383288\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056036; batch adversarial loss: 0.446263\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061931; batch adversarial loss: 0.432432\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037499; batch adversarial loss: 0.447255\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055466; batch adversarial loss: 0.502290\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062026; batch adversarial loss: 0.475202\n",
      "epoch 133; iter: 0; batch classifier loss: 0.061879; batch adversarial loss: 0.417603\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029558; batch adversarial loss: 0.435709\n",
      "epoch 135; iter: 0; batch classifier loss: 0.081871; batch adversarial loss: 0.394360\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043923; batch adversarial loss: 0.483835\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020662; batch adversarial loss: 0.472019\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027976; batch adversarial loss: 0.473650\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047732; batch adversarial loss: 0.445222\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050780; batch adversarial loss: 0.361522\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020579; batch adversarial loss: 0.394661\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056597; batch adversarial loss: 0.436023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022420; batch adversarial loss: 0.494403\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.598970\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042748; batch adversarial loss: 0.468117\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038813; batch adversarial loss: 0.454585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.084449; batch adversarial loss: 0.449948\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010975; batch adversarial loss: 0.474621\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036115; batch adversarial loss: 0.499755\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032109; batch adversarial loss: 0.510446\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047288; batch adversarial loss: 0.538625\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045258; batch adversarial loss: 0.391881\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021461; batch adversarial loss: 0.423615\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042681; batch adversarial loss: 0.385047\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026722; batch adversarial loss: 0.502244\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.441189\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039938; batch adversarial loss: 0.429061\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076259; batch adversarial loss: 0.363602\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030223; batch adversarial loss: 0.516574\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032603; batch adversarial loss: 0.446725\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017136; batch adversarial loss: 0.403126\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012738; batch adversarial loss: 0.518501\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030838; batch adversarial loss: 0.473183\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019409; batch adversarial loss: 0.415740\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011081; batch adversarial loss: 0.438487\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.442183\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036923; batch adversarial loss: 0.431904\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028555; batch adversarial loss: 0.511558\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029896; batch adversarial loss: 0.438247\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020974; batch adversarial loss: 0.475969\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007277; batch adversarial loss: 0.475386\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031109; batch adversarial loss: 0.440322\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012219; batch adversarial loss: 0.478882\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022200; batch adversarial loss: 0.432260\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028216; batch adversarial loss: 0.504817\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014349; batch adversarial loss: 0.448962\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015529; batch adversarial loss: 0.446100\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023037; batch adversarial loss: 0.487716\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039961; batch adversarial loss: 0.419148\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025928; batch adversarial loss: 0.480113\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053792; batch adversarial loss: 0.419604\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024590; batch adversarial loss: 0.502807\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028746; batch adversarial loss: 0.432133\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017700; batch adversarial loss: 0.574995\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021920; batch adversarial loss: 0.553176\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.464070\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044912; batch adversarial loss: 0.448864\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.502567\n",
      "epoch 189; iter: 0; batch classifier loss: 0.067684; batch adversarial loss: 0.396291\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011428; batch adversarial loss: 0.435230\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008785; batch adversarial loss: 0.463078\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032895; batch adversarial loss: 0.466217\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010468; batch adversarial loss: 0.407163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012690; batch adversarial loss: 0.435467\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018021; batch adversarial loss: 0.491688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017913; batch adversarial loss: 0.382379\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041585; batch adversarial loss: 0.426893\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032386; batch adversarial loss: 0.482266\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011135; batch adversarial loss: 0.378433\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703232; batch adversarial loss: 0.825743\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421522; batch adversarial loss: 0.800209\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395556; batch adversarial loss: 0.794966\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434286; batch adversarial loss: 0.711570\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396771; batch adversarial loss: 0.717008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.325592; batch adversarial loss: 0.682032\n",
      "epoch 6; iter: 0; batch classifier loss: 0.278011; batch adversarial loss: 0.644536\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230021; batch adversarial loss: 0.625988\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262524; batch adversarial loss: 0.604377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312333; batch adversarial loss: 0.564317\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302636; batch adversarial loss: 0.556360\n",
      "epoch 11; iter: 0; batch classifier loss: 0.262932; batch adversarial loss: 0.513116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303754; batch adversarial loss: 0.495812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260924; batch adversarial loss: 0.480205\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269879; batch adversarial loss: 0.473061\n",
      "epoch 15; iter: 0; batch classifier loss: 0.189047; batch adversarial loss: 0.438607\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249702; batch adversarial loss: 0.427640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.212630; batch adversarial loss: 0.483782\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226539; batch adversarial loss: 0.495781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.154339; batch adversarial loss: 0.393528\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182631; batch adversarial loss: 0.426835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.207784; batch adversarial loss: 0.401359\n",
      "epoch 22; iter: 0; batch classifier loss: 0.165533; batch adversarial loss: 0.470580\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152126; batch adversarial loss: 0.424712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208062; batch adversarial loss: 0.373196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184292; batch adversarial loss: 0.414585\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191076; batch adversarial loss: 0.397726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197146; batch adversarial loss: 0.374996\n",
      "epoch 28; iter: 0; batch classifier loss: 0.203550; batch adversarial loss: 0.396261\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158245; batch adversarial loss: 0.364473\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144902; batch adversarial loss: 0.362342\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172921; batch adversarial loss: 0.388917\n",
      "epoch 32; iter: 0; batch classifier loss: 0.142985; batch adversarial loss: 0.407340\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131151; batch adversarial loss: 0.498347\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144260; batch adversarial loss: 0.407037\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136297; batch adversarial loss: 0.338599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107590; batch adversarial loss: 0.518328\n",
      "epoch 37; iter: 0; batch classifier loss: 0.094442; batch adversarial loss: 0.413660\n",
      "epoch 38; iter: 0; batch classifier loss: 0.131340; batch adversarial loss: 0.393651\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136603; batch adversarial loss: 0.392012\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117947; batch adversarial loss: 0.423997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114698; batch adversarial loss: 0.405141\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117565; batch adversarial loss: 0.382604\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106168; batch adversarial loss: 0.353129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.092747; batch adversarial loss: 0.525272\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108446; batch adversarial loss: 0.501172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072651; batch adversarial loss: 0.416861\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089693; batch adversarial loss: 0.415792\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129467; batch adversarial loss: 0.338038\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082363; batch adversarial loss: 0.361826\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077183; batch adversarial loss: 0.463629\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074577; batch adversarial loss: 0.385727\n",
      "epoch 52; iter: 0; batch classifier loss: 0.068516; batch adversarial loss: 0.475700\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105309; batch adversarial loss: 0.372480\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092346; batch adversarial loss: 0.350072\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100108; batch adversarial loss: 0.379764\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089693; batch adversarial loss: 0.431255\n",
      "epoch 57; iter: 0; batch classifier loss: 0.140963; batch adversarial loss: 0.444233\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078224; batch adversarial loss: 0.469076\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092649; batch adversarial loss: 0.460338\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087160; batch adversarial loss: 0.353782\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107410; batch adversarial loss: 0.460959\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072129; batch adversarial loss: 0.440519\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059603; batch adversarial loss: 0.403067\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120281; batch adversarial loss: 0.452430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079693; batch adversarial loss: 0.315770\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085724; batch adversarial loss: 0.422961\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061451; batch adversarial loss: 0.466265\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089672; batch adversarial loss: 0.395061\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074987; batch adversarial loss: 0.261583\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103766; batch adversarial loss: 0.509261\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071908; batch adversarial loss: 0.474897\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045592; batch adversarial loss: 0.454807\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070771; batch adversarial loss: 0.463760\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055972; batch adversarial loss: 0.415243\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038376; batch adversarial loss: 0.449739\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060756; batch adversarial loss: 0.359397\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045580; batch adversarial loss: 0.439959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060875; batch adversarial loss: 0.451790\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049134; batch adversarial loss: 0.463956\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074959; batch adversarial loss: 0.425323\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062656; batch adversarial loss: 0.443021\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042343; batch adversarial loss: 0.521944\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055047; batch adversarial loss: 0.366611\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062477; batch adversarial loss: 0.371638\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065031; batch adversarial loss: 0.486118\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048899; batch adversarial loss: 0.454922\n",
      "epoch 87; iter: 0; batch classifier loss: 0.027886; batch adversarial loss: 0.368280\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050931; batch adversarial loss: 0.491977\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035557; batch adversarial loss: 0.416057\n",
      "epoch 90; iter: 0; batch classifier loss: 0.032121; batch adversarial loss: 0.364586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.029662; batch adversarial loss: 0.442635\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049055; batch adversarial loss: 0.432978\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043885; batch adversarial loss: 0.435061\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061108; batch adversarial loss: 0.394604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051436; batch adversarial loss: 0.506206\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036540; batch adversarial loss: 0.395777\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047958; batch adversarial loss: 0.397853\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061340; batch adversarial loss: 0.511220\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050700; batch adversarial loss: 0.462416\n",
      "epoch 100; iter: 0; batch classifier loss: 0.105499; batch adversarial loss: 0.577978\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050262; batch adversarial loss: 0.418426\n",
      "epoch 102; iter: 0; batch classifier loss: 0.093893; batch adversarial loss: 0.530552\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075538; batch adversarial loss: 0.519924\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098987; batch adversarial loss: 0.516006\n",
      "epoch 105; iter: 0; batch classifier loss: 0.090633; batch adversarial loss: 0.505893\n",
      "epoch 106; iter: 0; batch classifier loss: 0.119415; batch adversarial loss: 0.523631\n",
      "epoch 107; iter: 0; batch classifier loss: 0.170568; batch adversarial loss: 0.631635\n",
      "epoch 108; iter: 0; batch classifier loss: 0.150955; batch adversarial loss: 0.548030\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058075; batch adversarial loss: 0.456752\n",
      "epoch 110; iter: 0; batch classifier loss: 0.099730; batch adversarial loss: 0.633349\n",
      "epoch 111; iter: 0; batch classifier loss: 0.104242; batch adversarial loss: 0.430228\n",
      "epoch 112; iter: 0; batch classifier loss: 0.115199; batch adversarial loss: 0.559737\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065947; batch adversarial loss: 0.395283\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071911; batch adversarial loss: 0.399401\n",
      "epoch 115; iter: 0; batch classifier loss: 0.084327; batch adversarial loss: 0.551865\n",
      "epoch 116; iter: 0; batch classifier loss: 0.246332; batch adversarial loss: 0.683546\n",
      "epoch 117; iter: 0; batch classifier loss: 0.139034; batch adversarial loss: 0.529120\n",
      "epoch 118; iter: 0; batch classifier loss: 0.096978; batch adversarial loss: 0.626574\n",
      "epoch 119; iter: 0; batch classifier loss: 0.101981; batch adversarial loss: 0.540266\n",
      "epoch 120; iter: 0; batch classifier loss: 0.141655; batch adversarial loss: 0.588269\n",
      "epoch 121; iter: 0; batch classifier loss: 0.129382; batch adversarial loss: 0.559465\n",
      "epoch 122; iter: 0; batch classifier loss: 0.116321; batch adversarial loss: 0.493963\n",
      "epoch 123; iter: 0; batch classifier loss: 0.093660; batch adversarial loss: 0.398679\n",
      "epoch 124; iter: 0; batch classifier loss: 0.092200; batch adversarial loss: 0.514164\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089559; batch adversarial loss: 0.458353\n",
      "epoch 126; iter: 0; batch classifier loss: 0.109420; batch adversarial loss: 0.506567\n",
      "epoch 127; iter: 0; batch classifier loss: 0.185640; batch adversarial loss: 0.606953\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087210; batch adversarial loss: 0.454143\n",
      "epoch 129; iter: 0; batch classifier loss: 0.081191; batch adversarial loss: 0.445249\n",
      "epoch 130; iter: 0; batch classifier loss: 0.087585; batch adversarial loss: 0.535025\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078014; batch adversarial loss: 0.495084\n",
      "epoch 132; iter: 0; batch classifier loss: 0.121148; batch adversarial loss: 0.491994\n",
      "epoch 133; iter: 0; batch classifier loss: 0.105180; batch adversarial loss: 0.467430\n",
      "epoch 134; iter: 0; batch classifier loss: 0.102951; batch adversarial loss: 0.523911\n",
      "epoch 135; iter: 0; batch classifier loss: 0.097469; batch adversarial loss: 0.471845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.086334; batch adversarial loss: 0.460987\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064759; batch adversarial loss: 0.427881\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050586; batch adversarial loss: 0.515149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042111; batch adversarial loss: 0.455024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.056372; batch adversarial loss: 0.483007\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.476813\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030785; batch adversarial loss: 0.542246\n",
      "epoch 143; iter: 0; batch classifier loss: 0.094739; batch adversarial loss: 0.495727\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017725; batch adversarial loss: 0.461334\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037838; batch adversarial loss: 0.435844\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044155; batch adversarial loss: 0.483927\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044696; batch adversarial loss: 0.454782\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051462; batch adversarial loss: 0.529529\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035532; batch adversarial loss: 0.465282\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043995; batch adversarial loss: 0.488459\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031129; batch adversarial loss: 0.425407\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041965; batch adversarial loss: 0.427803\n",
      "epoch 153; iter: 0; batch classifier loss: 0.063115; batch adversarial loss: 0.523336\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054657; batch adversarial loss: 0.466618\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062047; batch adversarial loss: 0.450926\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024698; batch adversarial loss: 0.434215\n",
      "epoch 157; iter: 0; batch classifier loss: 0.101017; batch adversarial loss: 0.338144\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054131; batch adversarial loss: 0.408314\n",
      "epoch 159; iter: 0; batch classifier loss: 0.056222; batch adversarial loss: 0.343904\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034837; batch adversarial loss: 0.410863\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037818; batch adversarial loss: 0.397914\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041553; batch adversarial loss: 0.368290\n",
      "epoch 163; iter: 0; batch classifier loss: 0.074292; batch adversarial loss: 0.480456\n",
      "epoch 164; iter: 0; batch classifier loss: 0.058640; batch adversarial loss: 0.427250\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026668; batch adversarial loss: 0.549466\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062820; batch adversarial loss: 0.451049\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034352; batch adversarial loss: 0.541880\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052385; batch adversarial loss: 0.394072\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047641; batch adversarial loss: 0.360395\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023274; batch adversarial loss: 0.591261\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045476; batch adversarial loss: 0.429566\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026647; batch adversarial loss: 0.424261\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040520; batch adversarial loss: 0.472230\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047251; batch adversarial loss: 0.498036\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035777; batch adversarial loss: 0.457401\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044237; batch adversarial loss: 0.439467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032286; batch adversarial loss: 0.380943\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022231; batch adversarial loss: 0.420775\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037057; batch adversarial loss: 0.441702\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017527; batch adversarial loss: 0.454038\n",
      "epoch 181; iter: 0; batch classifier loss: 0.062614; batch adversarial loss: 0.547499\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053489; batch adversarial loss: 0.353433\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038570; batch adversarial loss: 0.475877\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022482; batch adversarial loss: 0.372027\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050672; batch adversarial loss: 0.435556\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030201; batch adversarial loss: 0.488722\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021209; batch adversarial loss: 0.506670\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025838; batch adversarial loss: 0.434081\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045031; batch adversarial loss: 0.424869\n",
      "epoch 190; iter: 0; batch classifier loss: 0.064993; batch adversarial loss: 0.521790\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016033; batch adversarial loss: 0.511013\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022245; batch adversarial loss: 0.465522\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011084; batch adversarial loss: 0.455684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017070; batch adversarial loss: 0.409795\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027221; batch adversarial loss: 0.410374\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022154; batch adversarial loss: 0.543307\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017211; batch adversarial loss: 0.552997\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040762; batch adversarial loss: 0.515359\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012138; batch adversarial loss: 0.449113\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682386; batch adversarial loss: 0.559501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422378; batch adversarial loss: 0.619045\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467540; batch adversarial loss: 0.607467\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464496; batch adversarial loss: 0.684586\n",
      "epoch 4; iter: 0; batch classifier loss: 0.383449; batch adversarial loss: 0.585409\n",
      "epoch 5; iter: 0; batch classifier loss: 0.396817; batch adversarial loss: 0.580551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546080; batch adversarial loss: 0.606643\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615856; batch adversarial loss: 0.556103\n",
      "epoch 8; iter: 0; batch classifier loss: 0.462334; batch adversarial loss: 0.535479\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450162; batch adversarial loss: 0.541859\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465393; batch adversarial loss: 0.510283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372462; batch adversarial loss: 0.482750\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321447; batch adversarial loss: 0.410939\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350375; batch adversarial loss: 0.465402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257702; batch adversarial loss: 0.438955\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289134; batch adversarial loss: 0.530507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307055; batch adversarial loss: 0.474237\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345695; batch adversarial loss: 0.490367\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368201; batch adversarial loss: 0.494979\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303812; batch adversarial loss: 0.466808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290050; batch adversarial loss: 0.487436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288116; batch adversarial loss: 0.477097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241077; batch adversarial loss: 0.492775\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269779; batch adversarial loss: 0.530164\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228155; batch adversarial loss: 0.485242\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193173; batch adversarial loss: 0.454251\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217071; batch adversarial loss: 0.490546\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250442; batch adversarial loss: 0.438399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214109; batch adversarial loss: 0.515814\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212362; batch adversarial loss: 0.476999\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275643; batch adversarial loss: 0.455867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198210; batch adversarial loss: 0.498770\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227034; batch adversarial loss: 0.422612\n",
      "epoch 33; iter: 0; batch classifier loss: 0.228656; batch adversarial loss: 0.458639\n",
      "epoch 34; iter: 0; batch classifier loss: 0.234092; batch adversarial loss: 0.460504\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261005; batch adversarial loss: 0.501775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.182423; batch adversarial loss: 0.460538\n",
      "epoch 37; iter: 0; batch classifier loss: 0.247453; batch adversarial loss: 0.425513\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209586; batch adversarial loss: 0.451020\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222859; batch adversarial loss: 0.493287\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147532; batch adversarial loss: 0.458924\n",
      "epoch 41; iter: 0; batch classifier loss: 0.303025; batch adversarial loss: 0.457754\n",
      "epoch 42; iter: 0; batch classifier loss: 0.229753; batch adversarial loss: 0.501597\n",
      "epoch 43; iter: 0; batch classifier loss: 0.223485; batch adversarial loss: 0.493764\n",
      "epoch 44; iter: 0; batch classifier loss: 0.233118; batch adversarial loss: 0.421025\n",
      "epoch 45; iter: 0; batch classifier loss: 0.287780; batch adversarial loss: 0.370869\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228158; batch adversarial loss: 0.471523\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201616; batch adversarial loss: 0.536138\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193124; batch adversarial loss: 0.491720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.274885; batch adversarial loss: 0.436069\n",
      "epoch 50; iter: 0; batch classifier loss: 0.200472; batch adversarial loss: 0.388224\n",
      "epoch 51; iter: 0; batch classifier loss: 0.267748; batch adversarial loss: 0.423773\n",
      "epoch 52; iter: 0; batch classifier loss: 0.266093; batch adversarial loss: 0.400430\n",
      "epoch 53; iter: 0; batch classifier loss: 0.248828; batch adversarial loss: 0.444541\n",
      "epoch 54; iter: 0; batch classifier loss: 0.249765; batch adversarial loss: 0.543108\n",
      "epoch 55; iter: 0; batch classifier loss: 0.203769; batch adversarial loss: 0.495935\n",
      "epoch 56; iter: 0; batch classifier loss: 0.237956; batch adversarial loss: 0.410796\n",
      "epoch 57; iter: 0; batch classifier loss: 0.291890; batch adversarial loss: 0.446983\n",
      "epoch 58; iter: 0; batch classifier loss: 0.156052; batch adversarial loss: 0.458933\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096390; batch adversarial loss: 0.544472\n",
      "epoch 60; iter: 0; batch classifier loss: 0.257576; batch adversarial loss: 0.374453\n",
      "epoch 61; iter: 0; batch classifier loss: 0.168528; batch adversarial loss: 0.604518\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232978; batch adversarial loss: 0.409740\n",
      "epoch 63; iter: 0; batch classifier loss: 0.262470; batch adversarial loss: 0.496055\n",
      "epoch 64; iter: 0; batch classifier loss: 0.212639; batch adversarial loss: 0.409641\n",
      "epoch 65; iter: 0; batch classifier loss: 0.158613; batch adversarial loss: 0.471657\n",
      "epoch 66; iter: 0; batch classifier loss: 0.129877; batch adversarial loss: 0.582735\n",
      "epoch 67; iter: 0; batch classifier loss: 0.128559; batch adversarial loss: 0.409041\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106745; batch adversarial loss: 0.468425\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147814; batch adversarial loss: 0.431473\n",
      "epoch 70; iter: 0; batch classifier loss: 0.174576; batch adversarial loss: 0.490605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.219714; batch adversarial loss: 0.471381\n",
      "epoch 72; iter: 0; batch classifier loss: 0.199936; batch adversarial loss: 0.445412\n",
      "epoch 73; iter: 0; batch classifier loss: 0.158015; batch adversarial loss: 0.420612\n",
      "epoch 74; iter: 0; batch classifier loss: 0.205298; batch adversarial loss: 0.410212\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195102; batch adversarial loss: 0.545906\n",
      "epoch 76; iter: 0; batch classifier loss: 0.216703; batch adversarial loss: 0.410521\n",
      "epoch 77; iter: 0; batch classifier loss: 0.273840; batch adversarial loss: 0.471675\n",
      "epoch 78; iter: 0; batch classifier loss: 0.223861; batch adversarial loss: 0.458537\n",
      "epoch 79; iter: 0; batch classifier loss: 0.215204; batch adversarial loss: 0.434648\n",
      "epoch 80; iter: 0; batch classifier loss: 0.197005; batch adversarial loss: 0.409962\n",
      "epoch 81; iter: 0; batch classifier loss: 0.205176; batch adversarial loss: 0.520114\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095526; batch adversarial loss: 0.446586\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067207; batch adversarial loss: 0.467185\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067090; batch adversarial loss: 0.557435\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060054; batch adversarial loss: 0.560752\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089626; batch adversarial loss: 0.594275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.209285; batch adversarial loss: 0.441946\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091267; batch adversarial loss: 0.456092\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100835; batch adversarial loss: 0.371889\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146711; batch adversarial loss: 0.537671\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082865; batch adversarial loss: 0.512738\n",
      "epoch 92; iter: 0; batch classifier loss: 0.114959; batch adversarial loss: 0.474326\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096799; batch adversarial loss: 0.453611\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074964; batch adversarial loss: 0.416085\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071967; batch adversarial loss: 0.479156\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064242; batch adversarial loss: 0.501561\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059892; batch adversarial loss: 0.379659\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087021; batch adversarial loss: 0.436001\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081012; batch adversarial loss: 0.421673\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042707; batch adversarial loss: 0.528313\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048693; batch adversarial loss: 0.432692\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067790; batch adversarial loss: 0.444675\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061484; batch adversarial loss: 0.449862\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.478713\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066016; batch adversarial loss: 0.502285\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041133; batch adversarial loss: 0.570607\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050890; batch adversarial loss: 0.472923\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039702; batch adversarial loss: 0.505460\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047997; batch adversarial loss: 0.564500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035482; batch adversarial loss: 0.520513\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041299; batch adversarial loss: 0.406830\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025329; batch adversarial loss: 0.457955\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067164; batch adversarial loss: 0.442020\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037455; batch adversarial loss: 0.459378\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033430; batch adversarial loss: 0.471436\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043804; batch adversarial loss: 0.403651\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031286; batch adversarial loss: 0.493337\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040377; batch adversarial loss: 0.441338\n",
      "epoch 119; iter: 0; batch classifier loss: 0.073969; batch adversarial loss: 0.423313\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031066; batch adversarial loss: 0.415383\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037595; batch adversarial loss: 0.426687\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.448934\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027444; batch adversarial loss: 0.451876\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027951; batch adversarial loss: 0.451172\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020359; batch adversarial loss: 0.520983\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046689; batch adversarial loss: 0.430142\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028209; batch adversarial loss: 0.491537\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031165; batch adversarial loss: 0.441633\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031630; batch adversarial loss: 0.363734\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033915; batch adversarial loss: 0.418768\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028889; batch adversarial loss: 0.447830\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014680; batch adversarial loss: 0.426832\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036533; batch adversarial loss: 0.418672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.052012; batch adversarial loss: 0.407676\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038935; batch adversarial loss: 0.401158\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018523; batch adversarial loss: 0.428861\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014862; batch adversarial loss: 0.500601\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025427; batch adversarial loss: 0.425940\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014113; batch adversarial loss: 0.416386\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017652; batch adversarial loss: 0.424774\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016364; batch adversarial loss: 0.510966\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018832; batch adversarial loss: 0.487828\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.401063\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011588; batch adversarial loss: 0.403478\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021809; batch adversarial loss: 0.427396\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013809; batch adversarial loss: 0.489553\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016607; batch adversarial loss: 0.469746\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016727; batch adversarial loss: 0.458511\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020306; batch adversarial loss: 0.473492\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020622; batch adversarial loss: 0.413343\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008081; batch adversarial loss: 0.468567\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019185; batch adversarial loss: 0.457924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016544; batch adversarial loss: 0.502332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014917; batch adversarial loss: 0.365575\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027173; batch adversarial loss: 0.470024\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014056; batch adversarial loss: 0.604577\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008885; batch adversarial loss: 0.360324\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025397; batch adversarial loss: 0.509327\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011038; batch adversarial loss: 0.417780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015669; batch adversarial loss: 0.381237\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025322; batch adversarial loss: 0.473794\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011227; batch adversarial loss: 0.401237\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009618; batch adversarial loss: 0.434339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021159; batch adversarial loss: 0.420468\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036215; batch adversarial loss: 0.503335\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016303; batch adversarial loss: 0.394660\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015876; batch adversarial loss: 0.539684\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041251; batch adversarial loss: 0.452513\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005495; batch adversarial loss: 0.431328\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032951; batch adversarial loss: 0.474058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013999; batch adversarial loss: 0.425581\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024337; batch adversarial loss: 0.471242\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022148; batch adversarial loss: 0.433610\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009881; batch adversarial loss: 0.460418\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013540; batch adversarial loss: 0.495771\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016857; batch adversarial loss: 0.472630\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010208; batch adversarial loss: 0.462912\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010941; batch adversarial loss: 0.486893\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019310; batch adversarial loss: 0.448812\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009839; batch adversarial loss: 0.465617\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011133; batch adversarial loss: 0.437227\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014833; batch adversarial loss: 0.441738\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003709; batch adversarial loss: 0.436085\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013739; batch adversarial loss: 0.428847\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010125; batch adversarial loss: 0.416897\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030439; batch adversarial loss: 0.580597\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010137; batch adversarial loss: 0.481810\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025861; batch adversarial loss: 0.431729\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009337; batch adversarial loss: 0.407614\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014999; batch adversarial loss: 0.373674\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017587; batch adversarial loss: 0.516410\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035757; batch adversarial loss: 0.406168\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010460; batch adversarial loss: 0.353360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027656; batch adversarial loss: 0.471665\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032608; batch adversarial loss: 0.392884\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008480; batch adversarial loss: 0.343062\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023118; batch adversarial loss: 0.450626\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006875; batch adversarial loss: 0.324344\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010431; batch adversarial loss: 0.443600\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680401; batch adversarial loss: 0.667674\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556428; batch adversarial loss: 0.639095\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422693; batch adversarial loss: 0.572023\n",
      "epoch 3; iter: 0; batch classifier loss: 0.418191; batch adversarial loss: 0.577010\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385571; batch adversarial loss: 0.585684\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443510; batch adversarial loss: 0.581253\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383215; batch adversarial loss: 0.545627\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338977; batch adversarial loss: 0.590255\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325930; batch adversarial loss: 0.521409\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343825; batch adversarial loss: 0.558565\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306326; batch adversarial loss: 0.513707\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315464; batch adversarial loss: 0.500934\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258468; batch adversarial loss: 0.441661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292785; batch adversarial loss: 0.440615\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260193; batch adversarial loss: 0.507659\n",
      "epoch 15; iter: 0; batch classifier loss: 0.269025; batch adversarial loss: 0.466899\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243436; batch adversarial loss: 0.464222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262603; batch adversarial loss: 0.446688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304275; batch adversarial loss: 0.466849\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202210; batch adversarial loss: 0.574173\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221025; batch adversarial loss: 0.462391\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188958; batch adversarial loss: 0.482270\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279420; batch adversarial loss: 0.411954\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162239; batch adversarial loss: 0.497103\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169564; batch adversarial loss: 0.404733\n",
      "epoch 25; iter: 0; batch classifier loss: 0.214170; batch adversarial loss: 0.473466\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167786; batch adversarial loss: 0.387601\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179173; batch adversarial loss: 0.473324\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140632; batch adversarial loss: 0.566536\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151142; batch adversarial loss: 0.437971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.154161; batch adversarial loss: 0.470497\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202426; batch adversarial loss: 0.421102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168405; batch adversarial loss: 0.492693\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216741; batch adversarial loss: 0.348626\n",
      "epoch 34; iter: 0; batch classifier loss: 0.147250; batch adversarial loss: 0.501388\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119489; batch adversarial loss: 0.468154\n",
      "epoch 36; iter: 0; batch classifier loss: 0.216404; batch adversarial loss: 0.427357\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141330; batch adversarial loss: 0.431241\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157264; batch adversarial loss: 0.386866\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235166; batch adversarial loss: 0.441249\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210709; batch adversarial loss: 0.498212\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201398; batch adversarial loss: 0.427352\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107915; batch adversarial loss: 0.424929\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152082; batch adversarial loss: 0.542907\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173471; batch adversarial loss: 0.483895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.185474; batch adversarial loss: 0.461284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.201268; batch adversarial loss: 0.462659\n",
      "epoch 47; iter: 0; batch classifier loss: 0.137442; batch adversarial loss: 0.375168\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154760; batch adversarial loss: 0.558586\n",
      "epoch 49; iter: 0; batch classifier loss: 0.187208; batch adversarial loss: 0.422816\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184468; batch adversarial loss: 0.481701\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144971; batch adversarial loss: 0.484303\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157232; batch adversarial loss: 0.422181\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182747; batch adversarial loss: 0.497432\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174906; batch adversarial loss: 0.467185\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221457; batch adversarial loss: 0.481523\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169510; batch adversarial loss: 0.495308\n",
      "epoch 57; iter: 0; batch classifier loss: 0.155618; batch adversarial loss: 0.612742\n",
      "epoch 58; iter: 0; batch classifier loss: 0.185713; batch adversarial loss: 0.446345\n",
      "epoch 59; iter: 0; batch classifier loss: 0.154549; batch adversarial loss: 0.481588\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124935; batch adversarial loss: 0.458963\n",
      "epoch 61; iter: 0; batch classifier loss: 0.245001; batch adversarial loss: 0.495295\n",
      "epoch 62; iter: 0; batch classifier loss: 0.163451; batch adversarial loss: 0.446643\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195797; batch adversarial loss: 0.434732\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109951; batch adversarial loss: 0.579618\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115089; batch adversarial loss: 0.397632\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106399; batch adversarial loss: 0.515632\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159313; batch adversarial loss: 0.457484\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114157; batch adversarial loss: 0.447360\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106231; batch adversarial loss: 0.606251\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156149; batch adversarial loss: 0.419407\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138673; batch adversarial loss: 0.444852\n",
      "epoch 72; iter: 0; batch classifier loss: 0.127578; batch adversarial loss: 0.514405\n",
      "epoch 73; iter: 0; batch classifier loss: 0.153292; batch adversarial loss: 0.508579\n",
      "epoch 74; iter: 0; batch classifier loss: 0.182144; batch adversarial loss: 0.519952\n",
      "epoch 75; iter: 0; batch classifier loss: 0.143724; batch adversarial loss: 0.443566\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166411; batch adversarial loss: 0.469607\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082352; batch adversarial loss: 0.437419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105696; batch adversarial loss: 0.435056\n",
      "epoch 79; iter: 0; batch classifier loss: 0.125128; batch adversarial loss: 0.437202\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152590; batch adversarial loss: 0.640936\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120827; batch adversarial loss: 0.546749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.115016; batch adversarial loss: 0.457057\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097205; batch adversarial loss: 0.479900\n",
      "epoch 84; iter: 0; batch classifier loss: 0.125820; batch adversarial loss: 0.488221\n",
      "epoch 85; iter: 0; batch classifier loss: 0.126543; batch adversarial loss: 0.510469\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125008; batch adversarial loss: 0.466979\n",
      "epoch 87; iter: 0; batch classifier loss: 0.149805; batch adversarial loss: 0.373262\n",
      "epoch 88; iter: 0; batch classifier loss: 0.129215; batch adversarial loss: 0.515749\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135768; batch adversarial loss: 0.487178\n",
      "epoch 90; iter: 0; batch classifier loss: 0.107490; batch adversarial loss: 0.428564\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078742; batch adversarial loss: 0.529517\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079182; batch adversarial loss: 0.434183\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094417; batch adversarial loss: 0.448479\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068890; batch adversarial loss: 0.460890\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093662; batch adversarial loss: 0.498624\n",
      "epoch 96; iter: 0; batch classifier loss: 0.092575; batch adversarial loss: 0.515451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.115245; batch adversarial loss: 0.343006\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047961; batch adversarial loss: 0.502395\n",
      "epoch 99; iter: 0; batch classifier loss: 0.101582; batch adversarial loss: 0.560918\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056382; batch adversarial loss: 0.546009\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048101; batch adversarial loss: 0.427667\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062344; batch adversarial loss: 0.396918\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059194; batch adversarial loss: 0.490333\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060696; batch adversarial loss: 0.431346\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059872; batch adversarial loss: 0.402431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067406; batch adversarial loss: 0.469454\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037743; batch adversarial loss: 0.364223\n",
      "epoch 108; iter: 0; batch classifier loss: 0.085931; batch adversarial loss: 0.455033\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042806; batch adversarial loss: 0.428350\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033394; batch adversarial loss: 0.461328\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037199; batch adversarial loss: 0.441312\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039331; batch adversarial loss: 0.516677\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053387; batch adversarial loss: 0.416716\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038027; batch adversarial loss: 0.473385\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034751; batch adversarial loss: 0.518283\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075878; batch adversarial loss: 0.550468\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053339; batch adversarial loss: 0.419909\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059695; batch adversarial loss: 0.443159\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066190; batch adversarial loss: 0.435375\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021519; batch adversarial loss: 0.434015\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039187; batch adversarial loss: 0.412080\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042269; batch adversarial loss: 0.528887\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036308; batch adversarial loss: 0.526808\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047433; batch adversarial loss: 0.403761\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038953; batch adversarial loss: 0.494818\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045127; batch adversarial loss: 0.481432\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029520; batch adversarial loss: 0.424875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.037226; batch adversarial loss: 0.458415\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060226; batch adversarial loss: 0.411551\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036711; batch adversarial loss: 0.387038\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045649; batch adversarial loss: 0.464272\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051885; batch adversarial loss: 0.455813\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012057; batch adversarial loss: 0.485279\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049973; batch adversarial loss: 0.386691\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034084; batch adversarial loss: 0.451595\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022109; batch adversarial loss: 0.490311\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037898; batch adversarial loss: 0.500132\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.428249\n",
      "epoch 139; iter: 0; batch classifier loss: 0.070188; batch adversarial loss: 0.444842\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030577; batch adversarial loss: 0.534220\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037379; batch adversarial loss: 0.409385\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033920; batch adversarial loss: 0.503850\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021573; batch adversarial loss: 0.529253\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030733; batch adversarial loss: 0.421707\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014553; batch adversarial loss: 0.444589\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034467; batch adversarial loss: 0.359718\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031244; batch adversarial loss: 0.391672\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031353; batch adversarial loss: 0.493570\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.368773\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022665; batch adversarial loss: 0.579138\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016431; batch adversarial loss: 0.421182\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022327; batch adversarial loss: 0.436020\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014260; batch adversarial loss: 0.481051\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017494; batch adversarial loss: 0.342099\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021010; batch adversarial loss: 0.480728\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022552; batch adversarial loss: 0.442506\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009775; batch adversarial loss: 0.488106\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017626; batch adversarial loss: 0.521905\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014796; batch adversarial loss: 0.434679\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006361; batch adversarial loss: 0.469321\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010342; batch adversarial loss: 0.474516\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020371; batch adversarial loss: 0.615222\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017443; batch adversarial loss: 0.470663\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042453; batch adversarial loss: 0.420895\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036897; batch adversarial loss: 0.549507\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027366; batch adversarial loss: 0.316361\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022369; batch adversarial loss: 0.498305\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018342; batch adversarial loss: 0.321322\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024264; batch adversarial loss: 0.491469\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023638; batch adversarial loss: 0.429283\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004433; batch adversarial loss: 0.462428\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020900; batch adversarial loss: 0.383350\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021002; batch adversarial loss: 0.465679\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004403; batch adversarial loss: 0.451001\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047735; batch adversarial loss: 0.441374\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012721; batch adversarial loss: 0.465728\n",
      "epoch 177; iter: 0; batch classifier loss: 0.012321; batch adversarial loss: 0.426899\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033168; batch adversarial loss: 0.367337\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046969; batch adversarial loss: 0.535306\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028431; batch adversarial loss: 0.505655\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011735; batch adversarial loss: 0.454232\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016745; batch adversarial loss: 0.451751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018982; batch adversarial loss: 0.447202\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.455566\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046416; batch adversarial loss: 0.398677\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012827; batch adversarial loss: 0.415516\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034365; batch adversarial loss: 0.541082\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024308; batch adversarial loss: 0.372206\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023239; batch adversarial loss: 0.478987\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.464597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011328; batch adversarial loss: 0.387844\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012266; batch adversarial loss: 0.430931\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011245; batch adversarial loss: 0.451226\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011103; batch adversarial loss: 0.387244\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017436; batch adversarial loss: 0.492946\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006307; batch adversarial loss: 0.384256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006272; batch adversarial loss: 0.415523\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017164; batch adversarial loss: 0.495808\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017528; batch adversarial loss: 0.390105\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690738; batch adversarial loss: 0.934264\n",
      "epoch 1; iter: 0; batch classifier loss: 0.569082; batch adversarial loss: 1.129745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.545943; batch adversarial loss: 1.270860\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647403; batch adversarial loss: 1.075843\n",
      "epoch 4; iter: 0; batch classifier loss: 0.813912; batch adversarial loss: 1.037929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.733522; batch adversarial loss: 0.939123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.722214; batch adversarial loss: 0.863285\n",
      "epoch 7; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.775736\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294869; batch adversarial loss: 0.676122\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361501; batch adversarial loss: 0.641391\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316881; batch adversarial loss: 0.611198\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267534; batch adversarial loss: 0.592895\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257007; batch adversarial loss: 0.570196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.194469; batch adversarial loss: 0.580641\n",
      "epoch 14; iter: 0; batch classifier loss: 0.216395; batch adversarial loss: 0.572427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.192476; batch adversarial loss: 0.546052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229163; batch adversarial loss: 0.502665\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221539; batch adversarial loss: 0.497132\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214549; batch adversarial loss: 0.474647\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222530; batch adversarial loss: 0.519054\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245811; batch adversarial loss: 0.526333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255116; batch adversarial loss: 0.449532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205345; batch adversarial loss: 0.466705\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151417; batch adversarial loss: 0.455161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.183042; batch adversarial loss: 0.488499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157368; batch adversarial loss: 0.501684\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134310; batch adversarial loss: 0.470920\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154073; batch adversarial loss: 0.525543\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154642; batch adversarial loss: 0.490948\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176310; batch adversarial loss: 0.428701\n",
      "epoch 30; iter: 0; batch classifier loss: 0.161280; batch adversarial loss: 0.424922\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164124; batch adversarial loss: 0.420510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.191003; batch adversarial loss: 0.457516\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193526; batch adversarial loss: 0.431548\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214440; batch adversarial loss: 0.482867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178974; batch adversarial loss: 0.396480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116944; batch adversarial loss: 0.413875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117534; batch adversarial loss: 0.376130\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101707; batch adversarial loss: 0.475852\n",
      "epoch 39; iter: 0; batch classifier loss: 0.076006; batch adversarial loss: 0.480219\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136355; batch adversarial loss: 0.378872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098758; batch adversarial loss: 0.311871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141210; batch adversarial loss: 0.378434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123556; batch adversarial loss: 0.356905\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132528; batch adversarial loss: 0.389047\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104436; batch adversarial loss: 0.339183\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104663; batch adversarial loss: 0.430664\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076924; batch adversarial loss: 0.332187\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105208; batch adversarial loss: 0.492909\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064789; batch adversarial loss: 0.462099\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096502; batch adversarial loss: 0.403696\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075478; batch adversarial loss: 0.373575\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110798; batch adversarial loss: 0.410482\n",
      "epoch 53; iter: 0; batch classifier loss: 0.050395; batch adversarial loss: 0.424581\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077756; batch adversarial loss: 0.408200\n",
      "epoch 55; iter: 0; batch classifier loss: 0.100313; batch adversarial loss: 0.441570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092328; batch adversarial loss: 0.461178\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.413441\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108075; batch adversarial loss: 0.451324\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141052; batch adversarial loss: 0.417504\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097785; batch adversarial loss: 0.465415\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062045; batch adversarial loss: 0.431205\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068287; batch adversarial loss: 0.416789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086746; batch adversarial loss: 0.337756\n",
      "epoch 64; iter: 0; batch classifier loss: 0.079073; batch adversarial loss: 0.440822\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108641; batch adversarial loss: 0.555097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089250; batch adversarial loss: 0.483085\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058728; batch adversarial loss: 0.428124\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077899; batch adversarial loss: 0.436772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069908; batch adversarial loss: 0.400391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053042; batch adversarial loss: 0.425859\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052747; batch adversarial loss: 0.375692\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073708; batch adversarial loss: 0.531290\n",
      "epoch 73; iter: 0; batch classifier loss: 0.046705; batch adversarial loss: 0.447485\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053572; batch adversarial loss: 0.531488\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045204; batch adversarial loss: 0.489458\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043294; batch adversarial loss: 0.400224\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048176; batch adversarial loss: 0.433384\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085036; batch adversarial loss: 0.430028\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066847; batch adversarial loss: 0.379362\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075066; batch adversarial loss: 0.432994\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070589; batch adversarial loss: 0.371500\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050848; batch adversarial loss: 0.400522\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.425713\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079240; batch adversarial loss: 0.467024\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045189; batch adversarial loss: 0.372828\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054622; batch adversarial loss: 0.510225\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068253; batch adversarial loss: 0.401711\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090145; batch adversarial loss: 0.492913\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084253; batch adversarial loss: 0.417577\n",
      "epoch 90; iter: 0; batch classifier loss: 0.033803; batch adversarial loss: 0.450584\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038041; batch adversarial loss: 0.374033\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061211; batch adversarial loss: 0.422697\n",
      "epoch 93; iter: 0; batch classifier loss: 0.024662; batch adversarial loss: 0.354298\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090406; batch adversarial loss: 0.532729\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062881; batch adversarial loss: 0.447031\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076333; batch adversarial loss: 0.368790\n",
      "epoch 97; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.389878\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061375; batch adversarial loss: 0.364533\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041335; batch adversarial loss: 0.538823\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061307; batch adversarial loss: 0.506537\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051727; batch adversarial loss: 0.401484\n",
      "epoch 102; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.402094\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044271; batch adversarial loss: 0.438880\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041303; batch adversarial loss: 0.330991\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046860; batch adversarial loss: 0.417362\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061051; batch adversarial loss: 0.334822\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073067; batch adversarial loss: 0.475045\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040754; batch adversarial loss: 0.406661\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042523; batch adversarial loss: 0.278147\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049724; batch adversarial loss: 0.495146\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046259; batch adversarial loss: 0.470916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051034; batch adversarial loss: 0.504137\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.425221\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056643; batch adversarial loss: 0.457571\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.317560\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.357051\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033497; batch adversarial loss: 0.460191\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068859; batch adversarial loss: 0.433461\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039554; batch adversarial loss: 0.451349\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031900; batch adversarial loss: 0.397634\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060283; batch adversarial loss: 0.415585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.055574; batch adversarial loss: 0.392654\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039043; batch adversarial loss: 0.358992\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055054; batch adversarial loss: 0.396294\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076820; batch adversarial loss: 0.460670\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048797; batch adversarial loss: 0.379197\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044942; batch adversarial loss: 0.477134\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.424388\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038625; batch adversarial loss: 0.349974\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046569; batch adversarial loss: 0.380683\n",
      "epoch 131; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.405145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048858; batch adversarial loss: 0.401494\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036671; batch adversarial loss: 0.356911\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029220; batch adversarial loss: 0.432118\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050379; batch adversarial loss: 0.419756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057248; batch adversarial loss: 0.369286\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031299; batch adversarial loss: 0.447536\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053740; batch adversarial loss: 0.398213\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041157; batch adversarial loss: 0.419370\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046955; batch adversarial loss: 0.436880\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053104; batch adversarial loss: 0.555688\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029503; batch adversarial loss: 0.395316\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047633; batch adversarial loss: 0.414848\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070912; batch adversarial loss: 0.423675\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047755; batch adversarial loss: 0.359657\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025038; batch adversarial loss: 0.443253\n",
      "epoch 147; iter: 0; batch classifier loss: 0.066681; batch adversarial loss: 0.407294\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022964; batch adversarial loss: 0.415972\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039544; batch adversarial loss: 0.379322\n",
      "epoch 150; iter: 0; batch classifier loss: 0.065986; batch adversarial loss: 0.477854\n",
      "epoch 151; iter: 0; batch classifier loss: 0.063543; batch adversarial loss: 0.438945\n",
      "epoch 152; iter: 0; batch classifier loss: 0.060324; batch adversarial loss: 0.360947\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015302; batch adversarial loss: 0.385075\n",
      "epoch 154; iter: 0; batch classifier loss: 0.069421; batch adversarial loss: 0.401804\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050082; batch adversarial loss: 0.503028\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034200; batch adversarial loss: 0.303384\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056641; batch adversarial loss: 0.335194\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046784; batch adversarial loss: 0.413307\n",
      "epoch 159; iter: 0; batch classifier loss: 0.061157; batch adversarial loss: 0.556156\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033751; batch adversarial loss: 0.387941\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052916; batch adversarial loss: 0.451604\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.412170\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037649; batch adversarial loss: 0.521312\n",
      "epoch 164; iter: 0; batch classifier loss: 0.072291; batch adversarial loss: 0.421936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.057057; batch adversarial loss: 0.370533\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031384; batch adversarial loss: 0.431084\n",
      "epoch 167; iter: 0; batch classifier loss: 0.062641; batch adversarial loss: 0.360040\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037753; batch adversarial loss: 0.451850\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033166; batch adversarial loss: 0.394385\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035820; batch adversarial loss: 0.420415\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029925; batch adversarial loss: 0.396401\n",
      "epoch 172; iter: 0; batch classifier loss: 0.069558; batch adversarial loss: 0.476045\n",
      "epoch 173; iter: 0; batch classifier loss: 0.076933; batch adversarial loss: 0.471346\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045677; batch adversarial loss: 0.451242\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040592; batch adversarial loss: 0.380245\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055682; batch adversarial loss: 0.481023\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019647; batch adversarial loss: 0.405388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027826; batch adversarial loss: 0.402697\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057699; batch adversarial loss: 0.494895\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023325; batch adversarial loss: 0.380724\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031306; batch adversarial loss: 0.509812\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049552; batch adversarial loss: 0.422166\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054942; batch adversarial loss: 0.487881\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056972; batch adversarial loss: 0.362117\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027433; batch adversarial loss: 0.458678\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037061; batch adversarial loss: 0.421300\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042672; batch adversarial loss: 0.354327\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024686; batch adversarial loss: 0.464395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045396; batch adversarial loss: 0.383809\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039861; batch adversarial loss: 0.478103\n",
      "epoch 191; iter: 0; batch classifier loss: 0.068442; batch adversarial loss: 0.514845\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050781; batch adversarial loss: 0.455872\n",
      "epoch 193; iter: 0; batch classifier loss: 0.065164; batch adversarial loss: 0.547923\n",
      "epoch 194; iter: 0; batch classifier loss: 0.069755; batch adversarial loss: 0.395973\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044112; batch adversarial loss: 0.347615\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.409135\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029814; batch adversarial loss: 0.406813\n",
      "epoch 198; iter: 0; batch classifier loss: 0.069826; batch adversarial loss: 0.413335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022593; batch adversarial loss: 0.496882\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681856; batch adversarial loss: 0.854805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534186; batch adversarial loss: 0.839825\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658748; batch adversarial loss: 0.847673\n",
      "epoch 3; iter: 0; batch classifier loss: 0.921411; batch adversarial loss: 0.802214\n",
      "epoch 4; iter: 0; batch classifier loss: 0.727678; batch adversarial loss: 0.698055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.704010; batch adversarial loss: 0.662011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584642; batch adversarial loss: 0.570372\n",
      "epoch 7; iter: 0; batch classifier loss: 0.421614; batch adversarial loss: 0.553218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.440286; batch adversarial loss: 0.573294\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334626; batch adversarial loss: 0.554995\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263118; batch adversarial loss: 0.571910\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400336; batch adversarial loss: 0.517850\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316254; batch adversarial loss: 0.544313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282777; batch adversarial loss: 0.514875\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320586; batch adversarial loss: 0.489117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400517; batch adversarial loss: 0.532252\n",
      "epoch 16; iter: 0; batch classifier loss: 0.277708; batch adversarial loss: 0.510130\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301726; batch adversarial loss: 0.517690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328335; batch adversarial loss: 0.487238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.251764; batch adversarial loss: 0.468725\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313786; batch adversarial loss: 0.455879\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254366; batch adversarial loss: 0.460005\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286464; batch adversarial loss: 0.511924\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285333; batch adversarial loss: 0.479945\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240057; batch adversarial loss: 0.563721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.274075; batch adversarial loss: 0.529421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259575; batch adversarial loss: 0.447868\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181051; batch adversarial loss: 0.550237\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187232; batch adversarial loss: 0.516934\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207809; batch adversarial loss: 0.412324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.204568; batch adversarial loss: 0.460567\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191788; batch adversarial loss: 0.563841\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236792; batch adversarial loss: 0.465287\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197090; batch adversarial loss: 0.482920\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171127; batch adversarial loss: 0.468809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.247110; batch adversarial loss: 0.415125\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191281; batch adversarial loss: 0.452037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.213728; batch adversarial loss: 0.418661\n",
      "epoch 38; iter: 0; batch classifier loss: 0.166794; batch adversarial loss: 0.439911\n",
      "epoch 39; iter: 0; batch classifier loss: 0.189645; batch adversarial loss: 0.357148\n",
      "epoch 40; iter: 0; batch classifier loss: 0.201431; batch adversarial loss: 0.404555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131282; batch adversarial loss: 0.562485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169699; batch adversarial loss: 0.478823\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165320; batch adversarial loss: 0.450754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.204398; batch adversarial loss: 0.471046\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202449; batch adversarial loss: 0.406382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.174111; batch adversarial loss: 0.399508\n",
      "epoch 47; iter: 0; batch classifier loss: 0.163544; batch adversarial loss: 0.390729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.136784; batch adversarial loss: 0.477716\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205204; batch adversarial loss: 0.488189\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228786; batch adversarial loss: 0.500690\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154964; batch adversarial loss: 0.428983\n",
      "epoch 52; iter: 0; batch classifier loss: 0.261936; batch adversarial loss: 0.526722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216516; batch adversarial loss: 0.427170\n",
      "epoch 54; iter: 0; batch classifier loss: 0.222997; batch adversarial loss: 0.434713\n",
      "epoch 55; iter: 0; batch classifier loss: 0.169986; batch adversarial loss: 0.352453\n",
      "epoch 56; iter: 0; batch classifier loss: 0.197577; batch adversarial loss: 0.455782\n",
      "epoch 57; iter: 0; batch classifier loss: 0.155347; batch adversarial loss: 0.399059\n",
      "epoch 58; iter: 0; batch classifier loss: 0.147285; batch adversarial loss: 0.497267\n",
      "epoch 59; iter: 0; batch classifier loss: 0.178432; batch adversarial loss: 0.470447\n",
      "epoch 60; iter: 0; batch classifier loss: 0.151394; batch adversarial loss: 0.520572\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167318; batch adversarial loss: 0.434589\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151387; batch adversarial loss: 0.479974\n",
      "epoch 63; iter: 0; batch classifier loss: 0.150129; batch adversarial loss: 0.441249\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127983; batch adversarial loss: 0.471464\n",
      "epoch 65; iter: 0; batch classifier loss: 0.150244; batch adversarial loss: 0.406759\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154631; batch adversarial loss: 0.422047\n",
      "epoch 67; iter: 0; batch classifier loss: 0.204283; batch adversarial loss: 0.429068\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106356; batch adversarial loss: 0.450921\n",
      "epoch 69; iter: 0; batch classifier loss: 0.128607; batch adversarial loss: 0.349601\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165704; batch adversarial loss: 0.513111\n",
      "epoch 71; iter: 0; batch classifier loss: 0.205074; batch adversarial loss: 0.356245\n",
      "epoch 72; iter: 0; batch classifier loss: 0.129725; batch adversarial loss: 0.471318\n",
      "epoch 73; iter: 0; batch classifier loss: 0.203222; batch adversarial loss: 0.446454\n",
      "epoch 74; iter: 0; batch classifier loss: 0.184316; batch adversarial loss: 0.405192\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123787; batch adversarial loss: 0.423664\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101715; batch adversarial loss: 0.497964\n",
      "epoch 77; iter: 0; batch classifier loss: 0.158511; batch adversarial loss: 0.496791\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153059; batch adversarial loss: 0.496128\n",
      "epoch 79; iter: 0; batch classifier loss: 0.180785; batch adversarial loss: 0.493244\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145807; batch adversarial loss: 0.489426\n",
      "epoch 81; iter: 0; batch classifier loss: 0.111078; batch adversarial loss: 0.474077\n",
      "epoch 82; iter: 0; batch classifier loss: 0.209760; batch adversarial loss: 0.430984\n",
      "epoch 83; iter: 0; batch classifier loss: 0.159943; batch adversarial loss: 0.438105\n",
      "epoch 84; iter: 0; batch classifier loss: 0.167248; batch adversarial loss: 0.456265\n",
      "epoch 85; iter: 0; batch classifier loss: 0.124137; batch adversarial loss: 0.566614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.210974; batch adversarial loss: 0.411377\n",
      "epoch 87; iter: 0; batch classifier loss: 0.185028; batch adversarial loss: 0.364928\n",
      "epoch 88; iter: 0; batch classifier loss: 0.157181; batch adversarial loss: 0.436551\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187852; batch adversarial loss: 0.481134\n",
      "epoch 90; iter: 0; batch classifier loss: 0.187230; batch adversarial loss: 0.492911\n",
      "epoch 91; iter: 0; batch classifier loss: 0.213090; batch adversarial loss: 0.481469\n",
      "epoch 92; iter: 0; batch classifier loss: 0.162149; batch adversarial loss: 0.486069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.137528; batch adversarial loss: 0.533512\n",
      "epoch 94; iter: 0; batch classifier loss: 0.252526; batch adversarial loss: 0.349120\n",
      "epoch 95; iter: 0; batch classifier loss: 0.126094; batch adversarial loss: 0.589783\n",
      "epoch 96; iter: 0; batch classifier loss: 0.153223; batch adversarial loss: 0.468694\n",
      "epoch 97; iter: 0; batch classifier loss: 0.222741; batch adversarial loss: 0.443637\n",
      "epoch 98; iter: 0; batch classifier loss: 0.161070; batch adversarial loss: 0.483023\n",
      "epoch 99; iter: 0; batch classifier loss: 0.153816; batch adversarial loss: 0.436829\n",
      "epoch 100; iter: 0; batch classifier loss: 0.126534; batch adversarial loss: 0.430573\n",
      "epoch 101; iter: 0; batch classifier loss: 0.169486; batch adversarial loss: 0.433196\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144295; batch adversarial loss: 0.473066\n",
      "epoch 103; iter: 0; batch classifier loss: 0.163958; batch adversarial loss: 0.508210\n",
      "epoch 104; iter: 0; batch classifier loss: 0.202068; batch adversarial loss: 0.369355\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113062; batch adversarial loss: 0.457137\n",
      "epoch 106; iter: 0; batch classifier loss: 0.192682; batch adversarial loss: 0.432418\n",
      "epoch 107; iter: 0; batch classifier loss: 0.206948; batch adversarial loss: 0.443295\n",
      "epoch 108; iter: 0; batch classifier loss: 0.163221; batch adversarial loss: 0.470094\n",
      "epoch 109; iter: 0; batch classifier loss: 0.198284; batch adversarial loss: 0.388877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.208608; batch adversarial loss: 0.472836\n",
      "epoch 111; iter: 0; batch classifier loss: 0.187665; batch adversarial loss: 0.425396\n",
      "epoch 112; iter: 0; batch classifier loss: 0.273128; batch adversarial loss: 0.396654\n",
      "epoch 113; iter: 0; batch classifier loss: 0.219081; batch adversarial loss: 0.455833\n",
      "epoch 114; iter: 0; batch classifier loss: 0.158850; batch adversarial loss: 0.519243\n",
      "epoch 115; iter: 0; batch classifier loss: 0.163604; batch adversarial loss: 0.531639\n",
      "epoch 116; iter: 0; batch classifier loss: 0.178618; batch adversarial loss: 0.427318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.184385; batch adversarial loss: 0.508344\n",
      "epoch 118; iter: 0; batch classifier loss: 0.123773; batch adversarial loss: 0.470069\n",
      "epoch 119; iter: 0; batch classifier loss: 0.194677; batch adversarial loss: 0.471462\n",
      "epoch 120; iter: 0; batch classifier loss: 0.184036; batch adversarial loss: 0.509203\n",
      "epoch 121; iter: 0; batch classifier loss: 0.245542; batch adversarial loss: 0.445156\n",
      "epoch 122; iter: 0; batch classifier loss: 0.212066; batch adversarial loss: 0.531346\n",
      "epoch 123; iter: 0; batch classifier loss: 0.218550; batch adversarial loss: 0.421170\n",
      "epoch 124; iter: 0; batch classifier loss: 0.238650; batch adversarial loss: 0.457886\n",
      "epoch 125; iter: 0; batch classifier loss: 0.149176; batch adversarial loss: 0.423122\n",
      "epoch 126; iter: 0; batch classifier loss: 0.167190; batch adversarial loss: 0.530990\n",
      "epoch 127; iter: 0; batch classifier loss: 0.178833; batch adversarial loss: 0.470976\n",
      "epoch 128; iter: 0; batch classifier loss: 0.120556; batch adversarial loss: 0.555048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.173293; batch adversarial loss: 0.531179\n",
      "epoch 130; iter: 0; batch classifier loss: 0.167869; batch adversarial loss: 0.411053\n",
      "epoch 131; iter: 0; batch classifier loss: 0.265214; batch adversarial loss: 0.483429\n",
      "epoch 132; iter: 0; batch classifier loss: 0.240740; batch adversarial loss: 0.458925\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066945; batch adversarial loss: 0.409090\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059154; batch adversarial loss: 0.418844\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059227; batch adversarial loss: 0.431784\n",
      "epoch 136; iter: 0; batch classifier loss: 0.063742; batch adversarial loss: 0.470061\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046434; batch adversarial loss: 0.430182\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040561; batch adversarial loss: 0.506766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036343; batch adversarial loss: 0.526615\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053565; batch adversarial loss: 0.414100\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029818; batch adversarial loss: 0.425640\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035556; batch adversarial loss: 0.356588\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076177; batch adversarial loss: 0.499241\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040781; batch adversarial loss: 0.495129\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025248; batch adversarial loss: 0.479285\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024359; batch adversarial loss: 0.420532\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043536; batch adversarial loss: 0.440628\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068392; batch adversarial loss: 0.441865\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038849; batch adversarial loss: 0.441553\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048234; batch adversarial loss: 0.443158\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034383; batch adversarial loss: 0.415798\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.386168\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035439; batch adversarial loss: 0.473157\n",
      "epoch 154; iter: 0; batch classifier loss: 0.048573; batch adversarial loss: 0.529224\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026269; batch adversarial loss: 0.415811\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028532; batch adversarial loss: 0.465528\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020031; batch adversarial loss: 0.425851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021164; batch adversarial loss: 0.503754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031414; batch adversarial loss: 0.493840\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009410; batch adversarial loss: 0.486373\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039401; batch adversarial loss: 0.397148\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031534; batch adversarial loss: 0.439581\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007261; batch adversarial loss: 0.488253\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014298; batch adversarial loss: 0.444299\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018118; batch adversarial loss: 0.465051\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017533; batch adversarial loss: 0.476196\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008165; batch adversarial loss: 0.402797\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.371735\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024876; batch adversarial loss: 0.356590\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022404; batch adversarial loss: 0.476510\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021601; batch adversarial loss: 0.527279\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020312; batch adversarial loss: 0.496637\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017941; batch adversarial loss: 0.408487\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016833; batch adversarial loss: 0.476005\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016489; batch adversarial loss: 0.484130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030560; batch adversarial loss: 0.430415\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016026; batch adversarial loss: 0.493399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022585; batch adversarial loss: 0.533624\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006191; batch adversarial loss: 0.440159\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011189; batch adversarial loss: 0.477758\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012954; batch adversarial loss: 0.404376\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009044; batch adversarial loss: 0.383816\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038508; batch adversarial loss: 0.434983\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004301; batch adversarial loss: 0.383480\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014653; batch adversarial loss: 0.450767\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011882; batch adversarial loss: 0.406738\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009954; batch adversarial loss: 0.505738\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023457; batch adversarial loss: 0.483231\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.431437\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018335; batch adversarial loss: 0.504903\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017793; batch adversarial loss: 0.474967\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018265; batch adversarial loss: 0.385538\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043348; batch adversarial loss: 0.450013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024861; batch adversarial loss: 0.390212\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006652; batch adversarial loss: 0.423427\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004254; batch adversarial loss: 0.449314\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018104; batch adversarial loss: 0.468946\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011769; batch adversarial loss: 0.451570\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008374; batch adversarial loss: 0.413184\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720327; batch adversarial loss: 0.783227\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452915; batch adversarial loss: 0.727010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.453429; batch adversarial loss: 0.684429\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337539; batch adversarial loss: 0.649898\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318717; batch adversarial loss: 0.645886\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298278; batch adversarial loss: 0.625161\n",
      "epoch 6; iter: 0; batch classifier loss: 0.397644; batch adversarial loss: 0.564754\n",
      "epoch 7; iter: 0; batch classifier loss: 0.340466; batch adversarial loss: 0.533960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336944; batch adversarial loss: 0.510186\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280549; batch adversarial loss: 0.498599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326038; batch adversarial loss: 0.514865\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260186; batch adversarial loss: 0.440207\n",
      "epoch 12; iter: 0; batch classifier loss: 0.231861; batch adversarial loss: 0.420421\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242074; batch adversarial loss: 0.459491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.295719; batch adversarial loss: 0.450301\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215890; batch adversarial loss: 0.494724\n",
      "epoch 16; iter: 0; batch classifier loss: 0.201392; batch adversarial loss: 0.425763\n",
      "epoch 17; iter: 0; batch classifier loss: 0.177700; batch adversarial loss: 0.421564\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216804; batch adversarial loss: 0.414902\n",
      "epoch 19; iter: 0; batch classifier loss: 0.183779; batch adversarial loss: 0.387420\n",
      "epoch 20; iter: 0; batch classifier loss: 0.150886; batch adversarial loss: 0.411204\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177432; batch adversarial loss: 0.458899\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213401; batch adversarial loss: 0.441565\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181151; batch adversarial loss: 0.504256\n",
      "epoch 24; iter: 0; batch classifier loss: 0.198495; batch adversarial loss: 0.381449\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129499; batch adversarial loss: 0.414228\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224147; batch adversarial loss: 0.409779\n",
      "epoch 27; iter: 0; batch classifier loss: 0.158574; batch adversarial loss: 0.488777\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146446; batch adversarial loss: 0.460006\n",
      "epoch 29; iter: 0; batch classifier loss: 0.110741; batch adversarial loss: 0.340063\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180675; batch adversarial loss: 0.455348\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134683; batch adversarial loss: 0.438657\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140349; batch adversarial loss: 0.383130\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143966; batch adversarial loss: 0.334064\n",
      "epoch 34; iter: 0; batch classifier loss: 0.199757; batch adversarial loss: 0.415666\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129502; batch adversarial loss: 0.454835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.142497; batch adversarial loss: 0.401906\n",
      "epoch 37; iter: 0; batch classifier loss: 0.201840; batch adversarial loss: 0.463278\n",
      "epoch 38; iter: 0; batch classifier loss: 0.070535; batch adversarial loss: 0.390032\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145943; batch adversarial loss: 0.465783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.120029; batch adversarial loss: 0.399444\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119333; batch adversarial loss: 0.444911\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087996; batch adversarial loss: 0.411155\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118216; batch adversarial loss: 0.452586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137329; batch adversarial loss: 0.475754\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132895; batch adversarial loss: 0.318581\n",
      "epoch 46; iter: 0; batch classifier loss: 0.140625; batch adversarial loss: 0.525383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111206; batch adversarial loss: 0.394916\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085415; batch adversarial loss: 0.387802\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095998; batch adversarial loss: 0.466736\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132333; batch adversarial loss: 0.408199\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123816; batch adversarial loss: 0.434098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100403; batch adversarial loss: 0.387424\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073018; batch adversarial loss: 0.436374\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083388; batch adversarial loss: 0.392206\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098011; batch adversarial loss: 0.404579\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077084; batch adversarial loss: 0.450848\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076278; batch adversarial loss: 0.464716\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098998; batch adversarial loss: 0.425822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.055645; batch adversarial loss: 0.389106\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119987; batch adversarial loss: 0.464000\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097969; batch adversarial loss: 0.437245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061149; batch adversarial loss: 0.402323\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087510; batch adversarial loss: 0.427462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097481; batch adversarial loss: 0.476463\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066957; batch adversarial loss: 0.433089\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084444; batch adversarial loss: 0.492418\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099996; batch adversarial loss: 0.393417\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077900; batch adversarial loss: 0.432056\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071919; batch adversarial loss: 0.428399\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069904; batch adversarial loss: 0.469680\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056570; batch adversarial loss: 0.453629\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108333; batch adversarial loss: 0.456615\n",
      "epoch 73; iter: 0; batch classifier loss: 0.094621; batch adversarial loss: 0.438413\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101113; batch adversarial loss: 0.466251\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061509; batch adversarial loss: 0.387168\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070297; batch adversarial loss: 0.531382\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054512; batch adversarial loss: 0.436288\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066332; batch adversarial loss: 0.408869\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076964; batch adversarial loss: 0.462298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.036112; batch adversarial loss: 0.532217\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049970; batch adversarial loss: 0.439086\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052917; batch adversarial loss: 0.403365\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061993; batch adversarial loss: 0.423311\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061864; batch adversarial loss: 0.625836\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106160; batch adversarial loss: 0.533345\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052030; batch adversarial loss: 0.412752\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048154; batch adversarial loss: 0.460097\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068408; batch adversarial loss: 0.439002\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084145; batch adversarial loss: 0.435649\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.399843\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056940; batch adversarial loss: 0.443007\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041243; batch adversarial loss: 0.349408\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113107; batch adversarial loss: 0.425604\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087672; batch adversarial loss: 0.422362\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043555; batch adversarial loss: 0.497516\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034500; batch adversarial loss: 0.443021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061137; batch adversarial loss: 0.591312\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044881; batch adversarial loss: 0.435561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046412; batch adversarial loss: 0.400213\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062319; batch adversarial loss: 0.505805\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043545; batch adversarial loss: 0.403938\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077673; batch adversarial loss: 0.430247\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046537; batch adversarial loss: 0.471700\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059191; batch adversarial loss: 0.482302\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060194; batch adversarial loss: 0.417581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048850; batch adversarial loss: 0.456300\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074294; batch adversarial loss: 0.392917\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039385; batch adversarial loss: 0.457665\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060050; batch adversarial loss: 0.415849\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061486; batch adversarial loss: 0.424492\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057972; batch adversarial loss: 0.491787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.027220; batch adversarial loss: 0.453822\n",
      "epoch 113; iter: 0; batch classifier loss: 0.106624; batch adversarial loss: 0.503004\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053760; batch adversarial loss: 0.417347\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074667; batch adversarial loss: 0.464544\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040930; batch adversarial loss: 0.425332\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055129; batch adversarial loss: 0.572885\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042020; batch adversarial loss: 0.463698\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030120; batch adversarial loss: 0.532966\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066764; batch adversarial loss: 0.416375\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018979; batch adversarial loss: 0.501432\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029278; batch adversarial loss: 0.493034\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044049; batch adversarial loss: 0.500604\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069861; batch adversarial loss: 0.446683\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024933; batch adversarial loss: 0.425892\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078119; batch adversarial loss: 0.533969\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039089; batch adversarial loss: 0.511984\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049140; batch adversarial loss: 0.485807\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043249; batch adversarial loss: 0.517646\n",
      "epoch 130; iter: 0; batch classifier loss: 0.079951; batch adversarial loss: 0.471404\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061336; batch adversarial loss: 0.485916\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071653; batch adversarial loss: 0.567523\n",
      "epoch 133; iter: 0; batch classifier loss: 0.115626; batch adversarial loss: 0.696217\n",
      "epoch 134; iter: 0; batch classifier loss: 0.086360; batch adversarial loss: 0.593235\n",
      "epoch 135; iter: 0; batch classifier loss: 0.133884; batch adversarial loss: 0.712081\n",
      "epoch 136; iter: 0; batch classifier loss: 0.124223; batch adversarial loss: 0.619779\n",
      "epoch 137; iter: 0; batch classifier loss: 0.089305; batch adversarial loss: 0.543377\n",
      "epoch 138; iter: 0; batch classifier loss: 0.154535; batch adversarial loss: 0.804602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.079677; batch adversarial loss: 0.547386\n",
      "epoch 140; iter: 0; batch classifier loss: 0.138421; batch adversarial loss: 0.534951\n",
      "epoch 141; iter: 0; batch classifier loss: 0.189114; batch adversarial loss: 0.677866\n",
      "epoch 142; iter: 0; batch classifier loss: 0.161050; batch adversarial loss: 0.602488\n",
      "epoch 143; iter: 0; batch classifier loss: 0.165950; batch adversarial loss: 0.775289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.237144; batch adversarial loss: 0.677846\n",
      "epoch 145; iter: 0; batch classifier loss: 0.063168; batch adversarial loss: 0.496736\n",
      "epoch 146; iter: 0; batch classifier loss: 0.119788; batch adversarial loss: 0.441066\n",
      "epoch 147; iter: 0; batch classifier loss: 0.135899; batch adversarial loss: 0.546095\n",
      "epoch 148; iter: 0; batch classifier loss: 0.166084; batch adversarial loss: 0.553644\n",
      "epoch 149; iter: 0; batch classifier loss: 0.159471; batch adversarial loss: 0.625870\n",
      "epoch 150; iter: 0; batch classifier loss: 0.125147; batch adversarial loss: 0.559612\n",
      "epoch 151; iter: 0; batch classifier loss: 0.094091; batch adversarial loss: 0.469279\n",
      "epoch 152; iter: 0; batch classifier loss: 0.151627; batch adversarial loss: 0.580835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.093821; batch adversarial loss: 0.426502\n",
      "epoch 154; iter: 0; batch classifier loss: 0.158682; batch adversarial loss: 0.585744\n",
      "epoch 155; iter: 0; batch classifier loss: 0.127964; batch adversarial loss: 0.551079\n",
      "epoch 156; iter: 0; batch classifier loss: 0.129132; batch adversarial loss: 0.478778\n",
      "epoch 157; iter: 0; batch classifier loss: 0.111652; batch adversarial loss: 0.482225\n",
      "epoch 158; iter: 0; batch classifier loss: 0.096283; batch adversarial loss: 0.419568\n",
      "epoch 159; iter: 0; batch classifier loss: 0.154589; batch adversarial loss: 0.538894\n",
      "epoch 160; iter: 0; batch classifier loss: 0.093817; batch adversarial loss: 0.519221\n",
      "epoch 161; iter: 0; batch classifier loss: 0.166721; batch adversarial loss: 0.574320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.113275; batch adversarial loss: 0.414116\n",
      "epoch 163; iter: 0; batch classifier loss: 0.153195; batch adversarial loss: 0.570459\n",
      "epoch 164; iter: 0; batch classifier loss: 0.096638; batch adversarial loss: 0.376871\n",
      "epoch 165; iter: 0; batch classifier loss: 0.098709; batch adversarial loss: 0.459184\n",
      "epoch 166; iter: 0; batch classifier loss: 0.099019; batch adversarial loss: 0.446801\n",
      "epoch 167; iter: 0; batch classifier loss: 0.093916; batch adversarial loss: 0.433981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.140374; batch adversarial loss: 0.529195\n",
      "epoch 169; iter: 0; batch classifier loss: 0.138492; batch adversarial loss: 0.515706\n",
      "epoch 170; iter: 0; batch classifier loss: 0.101976; batch adversarial loss: 0.555086\n",
      "epoch 171; iter: 0; batch classifier loss: 0.136825; batch adversarial loss: 0.454899\n",
      "epoch 172; iter: 0; batch classifier loss: 0.132930; batch adversarial loss: 0.399734\n",
      "epoch 173; iter: 0; batch classifier loss: 0.096249; batch adversarial loss: 0.477238\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045795; batch adversarial loss: 0.475375\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048780; batch adversarial loss: 0.396715\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039728; batch adversarial loss: 0.461217\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031193; batch adversarial loss: 0.398951\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045700; batch adversarial loss: 0.499736\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.527664\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035781; batch adversarial loss: 0.352644\n",
      "epoch 181; iter: 0; batch classifier loss: 0.056791; batch adversarial loss: 0.354030\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034109; batch adversarial loss: 0.470888\n",
      "epoch 183; iter: 0; batch classifier loss: 0.063390; batch adversarial loss: 0.497201\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035610; batch adversarial loss: 0.413702\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023623; batch adversarial loss: 0.481135\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053980; batch adversarial loss: 0.452274\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017657; batch adversarial loss: 0.478000\n",
      "epoch 188; iter: 0; batch classifier loss: 0.064221; batch adversarial loss: 0.587385\n",
      "epoch 189; iter: 0; batch classifier loss: 0.075339; batch adversarial loss: 0.404514\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040549; batch adversarial loss: 0.357245\n",
      "epoch 191; iter: 0; batch classifier loss: 0.063232; batch adversarial loss: 0.493279\n",
      "epoch 192; iter: 0; batch classifier loss: 0.062192; batch adversarial loss: 0.388779\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022867; batch adversarial loss: 0.465650\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026393; batch adversarial loss: 0.463337\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047833; batch adversarial loss: 0.529378\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035522; batch adversarial loss: 0.432256\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047749; batch adversarial loss: 0.443806\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.491875\n",
      "epoch 199; iter: 0; batch classifier loss: 0.143376; batch adversarial loss: 0.471073\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671176; batch adversarial loss: 0.841351\n",
      "epoch 1; iter: 0; batch classifier loss: 0.541930; batch adversarial loss: 0.854205\n",
      "epoch 2; iter: 0; batch classifier loss: 0.783649; batch adversarial loss: 0.852663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.800253; batch adversarial loss: 0.757660\n",
      "epoch 4; iter: 0; batch classifier loss: 0.789946; batch adversarial loss: 0.705095\n",
      "epoch 5; iter: 0; batch classifier loss: 0.691224; batch adversarial loss: 0.632019\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509899; batch adversarial loss: 0.579881\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362809; batch adversarial loss: 0.575601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.308991; batch adversarial loss: 0.555193\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373268; batch adversarial loss: 0.569833\n",
      "epoch 10; iter: 0; batch classifier loss: 0.351424; batch adversarial loss: 0.539647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317887; batch adversarial loss: 0.544347\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308524; batch adversarial loss: 0.522157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245304; batch adversarial loss: 0.541748\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306483; batch adversarial loss: 0.480794\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260773; batch adversarial loss: 0.481118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285651; batch adversarial loss: 0.493185\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244050; batch adversarial loss: 0.519949\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247052; batch adversarial loss: 0.465241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249821; batch adversarial loss: 0.545998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228605; batch adversarial loss: 0.524101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216286; batch adversarial loss: 0.536481\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277661; batch adversarial loss: 0.490695\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217756; batch adversarial loss: 0.405069\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213892; batch adversarial loss: 0.495981\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141767; batch adversarial loss: 0.549651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.202454; batch adversarial loss: 0.518851\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173082; batch adversarial loss: 0.399185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157814; batch adversarial loss: 0.555537\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147196; batch adversarial loss: 0.517215\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146002; batch adversarial loss: 0.473643\n",
      "epoch 31; iter: 0; batch classifier loss: 0.213427; batch adversarial loss: 0.485640\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154815; batch adversarial loss: 0.385224\n",
      "epoch 33; iter: 0; batch classifier loss: 0.132617; batch adversarial loss: 0.460407\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124806; batch adversarial loss: 0.472581\n",
      "epoch 35; iter: 0; batch classifier loss: 0.168664; batch adversarial loss: 0.537487\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138749; batch adversarial loss: 0.449361\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172601; batch adversarial loss: 0.394330\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151932; batch adversarial loss: 0.365079\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116514; batch adversarial loss: 0.475154\n",
      "epoch 40; iter: 0; batch classifier loss: 0.162782; batch adversarial loss: 0.388945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109111; batch adversarial loss: 0.475987\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155862; batch adversarial loss: 0.428556\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123664; batch adversarial loss: 0.440921\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134717; batch adversarial loss: 0.574972\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104344; batch adversarial loss: 0.463392\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104443; batch adversarial loss: 0.405349\n",
      "epoch 47; iter: 0; batch classifier loss: 0.116339; batch adversarial loss: 0.449113\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088785; batch adversarial loss: 0.396763\n",
      "epoch 49; iter: 0; batch classifier loss: 0.120478; batch adversarial loss: 0.418025\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103722; batch adversarial loss: 0.488689\n",
      "epoch 51; iter: 0; batch classifier loss: 0.066440; batch adversarial loss: 0.459507\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114111; batch adversarial loss: 0.517693\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109316; batch adversarial loss: 0.433841\n",
      "epoch 54; iter: 0; batch classifier loss: 0.066477; batch adversarial loss: 0.418803\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114566; batch adversarial loss: 0.413276\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100323; batch adversarial loss: 0.515106\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098999; batch adversarial loss: 0.474243\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085568; batch adversarial loss: 0.541474\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086521; batch adversarial loss: 0.447720\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075321; batch adversarial loss: 0.516659\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071050; batch adversarial loss: 0.493119\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099833; batch adversarial loss: 0.543040\n",
      "epoch 63; iter: 0; batch classifier loss: 0.103212; batch adversarial loss: 0.421220\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064634; batch adversarial loss: 0.466044\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079837; batch adversarial loss: 0.437181\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060011; batch adversarial loss: 0.494085\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087747; batch adversarial loss: 0.373819\n",
      "epoch 68; iter: 0; batch classifier loss: 0.048362; batch adversarial loss: 0.449362\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066107; batch adversarial loss: 0.540215\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078263; batch adversarial loss: 0.378770\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073126; batch adversarial loss: 0.439823\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079356; batch adversarial loss: 0.468323\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084862; batch adversarial loss: 0.521578\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069284; batch adversarial loss: 0.450506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079255; batch adversarial loss: 0.376787\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054486; batch adversarial loss: 0.482702\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091105; batch adversarial loss: 0.327416\n",
      "epoch 78; iter: 0; batch classifier loss: 0.031927; batch adversarial loss: 0.412768\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070652; batch adversarial loss: 0.566697\n",
      "epoch 80; iter: 0; batch classifier loss: 0.047672; batch adversarial loss: 0.507651\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091371; batch adversarial loss: 0.467157\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.441767\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065853; batch adversarial loss: 0.516035\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063203; batch adversarial loss: 0.507477\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040610; batch adversarial loss: 0.448132\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.442260\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.433577\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050460; batch adversarial loss: 0.352264\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035106; batch adversarial loss: 0.481790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049769; batch adversarial loss: 0.544060\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053583; batch adversarial loss: 0.516371\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037727; batch adversarial loss: 0.365488\n",
      "epoch 93; iter: 0; batch classifier loss: 0.049276; batch adversarial loss: 0.385283\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036719; batch adversarial loss: 0.421883\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045304; batch adversarial loss: 0.425010\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062701; batch adversarial loss: 0.426147\n",
      "epoch 97; iter: 0; batch classifier loss: 0.021214; batch adversarial loss: 0.399193\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049909; batch adversarial loss: 0.564205\n",
      "epoch 99; iter: 0; batch classifier loss: 0.042692; batch adversarial loss: 0.373119\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055446; batch adversarial loss: 0.492911\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061703; batch adversarial loss: 0.529010\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041523; batch adversarial loss: 0.534831\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026905; batch adversarial loss: 0.449787\n",
      "epoch 104; iter: 0; batch classifier loss: 0.026628; batch adversarial loss: 0.450095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031596; batch adversarial loss: 0.437698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.050212; batch adversarial loss: 0.495239\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031000; batch adversarial loss: 0.488985\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024599; batch adversarial loss: 0.504545\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059960; batch adversarial loss: 0.500039\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027351; batch adversarial loss: 0.509563\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026889; batch adversarial loss: 0.499079\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045167; batch adversarial loss: 0.423427\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047207; batch adversarial loss: 0.472526\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058336; batch adversarial loss: 0.413484\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016138; batch adversarial loss: 0.397548\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054220; batch adversarial loss: 0.358256\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043026; batch adversarial loss: 0.508217\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028318; batch adversarial loss: 0.453007\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024101; batch adversarial loss: 0.409521\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022084; batch adversarial loss: 0.417310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021169; batch adversarial loss: 0.486028\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013884; batch adversarial loss: 0.508277\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025987; batch adversarial loss: 0.469663\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019183; batch adversarial loss: 0.493514\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014810; batch adversarial loss: 0.460853\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015465; batch adversarial loss: 0.426935\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034970; batch adversarial loss: 0.414789\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031132; batch adversarial loss: 0.453391\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015803; batch adversarial loss: 0.449321\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025203; batch adversarial loss: 0.485549\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037444; batch adversarial loss: 0.431747\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025545; batch adversarial loss: 0.426853\n",
      "epoch 133; iter: 0; batch classifier loss: 0.048507; batch adversarial loss: 0.420195\n",
      "epoch 134; iter: 0; batch classifier loss: 0.006963; batch adversarial loss: 0.399918\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011253; batch adversarial loss: 0.416664\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016601; batch adversarial loss: 0.434954\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014771; batch adversarial loss: 0.504240\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027713; batch adversarial loss: 0.402863\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041520; batch adversarial loss: 0.408145\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032546; batch adversarial loss: 0.467218\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021302; batch adversarial loss: 0.415068\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026005; batch adversarial loss: 0.489365\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030532; batch adversarial loss: 0.448919\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021597; batch adversarial loss: 0.362642\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.486944\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021144; batch adversarial loss: 0.371422\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026673; batch adversarial loss: 0.409045\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018245; batch adversarial loss: 0.519721\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019507; batch adversarial loss: 0.463532\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008002; batch adversarial loss: 0.440445\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017919; batch adversarial loss: 0.446354\n",
      "epoch 152; iter: 0; batch classifier loss: 0.005893; batch adversarial loss: 0.453889\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013352; batch adversarial loss: 0.524192\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024988; batch adversarial loss: 0.492518\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019864; batch adversarial loss: 0.451229\n",
      "epoch 156; iter: 0; batch classifier loss: 0.005588; batch adversarial loss: 0.562736\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022135; batch adversarial loss: 0.343634\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020263; batch adversarial loss: 0.541190\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035412; batch adversarial loss: 0.545684\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020145; batch adversarial loss: 0.486581\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012964; batch adversarial loss: 0.342245\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028869; batch adversarial loss: 0.422067\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034212; batch adversarial loss: 0.335669\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036093; batch adversarial loss: 0.492922\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023791; batch adversarial loss: 0.431057\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024608; batch adversarial loss: 0.412879\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018343; batch adversarial loss: 0.461244\n",
      "epoch 168; iter: 0; batch classifier loss: 0.003615; batch adversarial loss: 0.454885\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010912; batch adversarial loss: 0.377667\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010147; batch adversarial loss: 0.490100\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009936; batch adversarial loss: 0.382527\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016455; batch adversarial loss: 0.474530\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006948; batch adversarial loss: 0.522333\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014065; batch adversarial loss: 0.411849\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003668; batch adversarial loss: 0.467034\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003868; batch adversarial loss: 0.500754\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028028; batch adversarial loss: 0.434597\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014008; batch adversarial loss: 0.534840\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021475; batch adversarial loss: 0.456005\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019421; batch adversarial loss: 0.348601\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022913; batch adversarial loss: 0.458151\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009406; batch adversarial loss: 0.523641\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009420; batch adversarial loss: 0.460751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.407976\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016287; batch adversarial loss: 0.499848\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022403; batch adversarial loss: 0.419065\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006127; batch adversarial loss: 0.377248\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008930; batch adversarial loss: 0.577974\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029416; batch adversarial loss: 0.403582\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019777; batch adversarial loss: 0.464988\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005025; batch adversarial loss: 0.355327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012040; batch adversarial loss: 0.475179\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004097; batch adversarial loss: 0.458031\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017282; batch adversarial loss: 0.410748\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048539; batch adversarial loss: 0.461306\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010007; batch adversarial loss: 0.410677\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046796; batch adversarial loss: 0.392249\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004557; batch adversarial loss: 0.432132\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014589; batch adversarial loss: 0.479694\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732441; batch adversarial loss: 0.489308\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472249; batch adversarial loss: 0.574181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.308377; batch adversarial loss: 0.598133\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411390; batch adversarial loss: 0.620038\n",
      "epoch 4; iter: 0; batch classifier loss: 0.452622; batch adversarial loss: 0.578455\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337454; batch adversarial loss: 0.595351\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337718; batch adversarial loss: 0.562714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355242; batch adversarial loss: 0.591546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290552; batch adversarial loss: 0.518877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329702; batch adversarial loss: 0.525154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341592; batch adversarial loss: 0.543202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295798; batch adversarial loss: 0.537617\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310419; batch adversarial loss: 0.564381\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309919; batch adversarial loss: 0.523497\n",
      "epoch 14; iter: 0; batch classifier loss: 0.433444; batch adversarial loss: 0.588376\n",
      "epoch 15; iter: 0; batch classifier loss: 0.478441; batch adversarial loss: 0.544400\n",
      "epoch 16; iter: 0; batch classifier loss: 0.545303; batch adversarial loss: 0.554285\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505186; batch adversarial loss: 0.485596\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369319; batch adversarial loss: 0.491548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222216; batch adversarial loss: 0.456091\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237538; batch adversarial loss: 0.489357\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204036; batch adversarial loss: 0.513405\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190061; batch adversarial loss: 0.435049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199138; batch adversarial loss: 0.465157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172771; batch adversarial loss: 0.471941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193452; batch adversarial loss: 0.485203\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162268; batch adversarial loss: 0.485509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196484; batch adversarial loss: 0.582314\n",
      "epoch 28; iter: 0; batch classifier loss: 0.117447; batch adversarial loss: 0.505059\n",
      "epoch 29; iter: 0; batch classifier loss: 0.195700; batch adversarial loss: 0.418207\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145211; batch adversarial loss: 0.355256\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125963; batch adversarial loss: 0.390141\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186646; batch adversarial loss: 0.439826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.077390; batch adversarial loss: 0.574006\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102537; batch adversarial loss: 0.413020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132218; batch adversarial loss: 0.393186\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093086; batch adversarial loss: 0.390217\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122891; batch adversarial loss: 0.434898\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090397; batch adversarial loss: 0.494459\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145190; batch adversarial loss: 0.363561\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103511; batch adversarial loss: 0.498129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106754; batch adversarial loss: 0.435331\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135977; batch adversarial loss: 0.367429\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118119; batch adversarial loss: 0.470941\n",
      "epoch 44; iter: 0; batch classifier loss: 0.062254; batch adversarial loss: 0.435456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129242; batch adversarial loss: 0.421025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113031; batch adversarial loss: 0.528908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102830; batch adversarial loss: 0.407312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101442; batch adversarial loss: 0.489867\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074045; batch adversarial loss: 0.416367\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126736; batch adversarial loss: 0.402271\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098961; batch adversarial loss: 0.446839\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099248; batch adversarial loss: 0.596545\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055983; batch adversarial loss: 0.522821\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108530; batch adversarial loss: 0.444932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089864; batch adversarial loss: 0.332597\n",
      "epoch 56; iter: 0; batch classifier loss: 0.089194; batch adversarial loss: 0.447087\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119144; batch adversarial loss: 0.437382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094799; batch adversarial loss: 0.474856\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085388; batch adversarial loss: 0.370381\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080294; batch adversarial loss: 0.491598\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069049; batch adversarial loss: 0.435568\n",
      "epoch 62; iter: 0; batch classifier loss: 0.051561; batch adversarial loss: 0.327245\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077503; batch adversarial loss: 0.378974\n",
      "epoch 64; iter: 0; batch classifier loss: 0.048253; batch adversarial loss: 0.511542\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081350; batch adversarial loss: 0.483136\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072397; batch adversarial loss: 0.451007\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088024; batch adversarial loss: 0.443818\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052758; batch adversarial loss: 0.531062\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066370; batch adversarial loss: 0.545844\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061369; batch adversarial loss: 0.417140\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053496; batch adversarial loss: 0.481276\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047815; batch adversarial loss: 0.500615\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089170; batch adversarial loss: 0.471141\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066108; batch adversarial loss: 0.613154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066856; batch adversarial loss: 0.479991\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050007; batch adversarial loss: 0.476773\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094530; batch adversarial loss: 0.402445\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061276; batch adversarial loss: 0.411087\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078468; batch adversarial loss: 0.443320\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045970; batch adversarial loss: 0.446925\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064675; batch adversarial loss: 0.421708\n",
      "epoch 82; iter: 0; batch classifier loss: 0.031120; batch adversarial loss: 0.475486\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067595; batch adversarial loss: 0.518098\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060663; batch adversarial loss: 0.496839\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053677; batch adversarial loss: 0.416946\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055366; batch adversarial loss: 0.425356\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060143; batch adversarial loss: 0.354808\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057856; batch adversarial loss: 0.453644\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052126; batch adversarial loss: 0.389419\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045590; batch adversarial loss: 0.448940\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050465; batch adversarial loss: 0.455108\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044225; batch adversarial loss: 0.425545\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096206; batch adversarial loss: 0.405691\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058297; batch adversarial loss: 0.424755\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035282; batch adversarial loss: 0.571246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063224; batch adversarial loss: 0.495830\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084229; batch adversarial loss: 0.513243\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070418; batch adversarial loss: 0.393146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036646; batch adversarial loss: 0.423619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.030042; batch adversarial loss: 0.391002\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042346; batch adversarial loss: 0.404023\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029850; batch adversarial loss: 0.499220\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069355; batch adversarial loss: 0.470586\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041272; batch adversarial loss: 0.425684\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037915; batch adversarial loss: 0.442553\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038961; batch adversarial loss: 0.362844\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027557; batch adversarial loss: 0.393967\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045999; batch adversarial loss: 0.467799\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060708; batch adversarial loss: 0.423778\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066866; batch adversarial loss: 0.479215\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053293; batch adversarial loss: 0.398066\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066391; batch adversarial loss: 0.375334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044016; batch adversarial loss: 0.574322\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040674; batch adversarial loss: 0.401923\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067117; batch adversarial loss: 0.447373\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055138; batch adversarial loss: 0.378075\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028568; batch adversarial loss: 0.410558\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040546; batch adversarial loss: 0.421375\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036662; batch adversarial loss: 0.393246\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045555; batch adversarial loss: 0.439116\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041764; batch adversarial loss: 0.463884\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041599; batch adversarial loss: 0.483307\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038033; batch adversarial loss: 0.426819\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029700; batch adversarial loss: 0.371489\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018521; batch adversarial loss: 0.505763\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.387125\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017274; batch adversarial loss: 0.494786\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042235; batch adversarial loss: 0.389507\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029238; batch adversarial loss: 0.385139\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038384; batch adversarial loss: 0.500854\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017988; batch adversarial loss: 0.409499\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032533; batch adversarial loss: 0.436350\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016125; batch adversarial loss: 0.535565\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044159; batch adversarial loss: 0.471115\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029662; batch adversarial loss: 0.486307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015555; batch adversarial loss: 0.455544\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.413394\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013521; batch adversarial loss: 0.412858\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034684; batch adversarial loss: 0.430382\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033563; batch adversarial loss: 0.442318\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024422; batch adversarial loss: 0.441598\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054466; batch adversarial loss: 0.483349\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026362; batch adversarial loss: 0.479439\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037251; batch adversarial loss: 0.481362\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038871; batch adversarial loss: 0.406767\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023980; batch adversarial loss: 0.442419\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023355; batch adversarial loss: 0.456174\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038854; batch adversarial loss: 0.435647\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019974; batch adversarial loss: 0.391336\n",
      "epoch 150; iter: 0; batch classifier loss: 0.008134; batch adversarial loss: 0.394204\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024812; batch adversarial loss: 0.466251\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031523; batch adversarial loss: 0.527693\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035626; batch adversarial loss: 0.353626\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052022; batch adversarial loss: 0.461806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026304; batch adversarial loss: 0.344213\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011985; batch adversarial loss: 0.516403\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022479; batch adversarial loss: 0.483356\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014433; batch adversarial loss: 0.506772\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024049; batch adversarial loss: 0.406008\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041251; batch adversarial loss: 0.586027\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013633; batch adversarial loss: 0.466280\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026615; batch adversarial loss: 0.545037\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034870; batch adversarial loss: 0.471907\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034006; batch adversarial loss: 0.419373\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.453258\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055800; batch adversarial loss: 0.363600\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.468467\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022475; batch adversarial loss: 0.422964\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010960; batch adversarial loss: 0.474737\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015825; batch adversarial loss: 0.461726\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023800; batch adversarial loss: 0.418593\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027314; batch adversarial loss: 0.404001\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010032; batch adversarial loss: 0.476270\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018288; batch adversarial loss: 0.359074\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017047; batch adversarial loss: 0.431691\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017821; batch adversarial loss: 0.464858\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033241; batch adversarial loss: 0.461310\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015407; batch adversarial loss: 0.463071\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028498; batch adversarial loss: 0.394029\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018314; batch adversarial loss: 0.421728\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034884; batch adversarial loss: 0.407863\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029359; batch adversarial loss: 0.382761\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034229; batch adversarial loss: 0.522348\n",
      "epoch 184; iter: 0; batch classifier loss: 0.055343; batch adversarial loss: 0.437421\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008930; batch adversarial loss: 0.432219\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021496; batch adversarial loss: 0.453929\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012771; batch adversarial loss: 0.508939\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017914; batch adversarial loss: 0.397467\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042668; batch adversarial loss: 0.443684\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.399053\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003337; batch adversarial loss: 0.408916\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008907; batch adversarial loss: 0.409858\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011910; batch adversarial loss: 0.522486\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041806; batch adversarial loss: 0.374876\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012880; batch adversarial loss: 0.448974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.033128; batch adversarial loss: 0.513280\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017737; batch adversarial loss: 0.389785\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.416029\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008862; batch adversarial loss: 0.482905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707792; batch adversarial loss: 0.777524\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476294; batch adversarial loss: 0.736297\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406847; batch adversarial loss: 0.695517\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382274; batch adversarial loss: 0.670448\n",
      "epoch 4; iter: 0; batch classifier loss: 0.391673; batch adversarial loss: 0.629622\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356523; batch adversarial loss: 0.605673\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362973; batch adversarial loss: 0.531888\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342623; batch adversarial loss: 0.527516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317827; batch adversarial loss: 0.510117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293110; batch adversarial loss: 0.531443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.219406; batch adversarial loss: 0.478660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276925; batch adversarial loss: 0.468964\n",
      "epoch 12; iter: 0; batch classifier loss: 0.258466; batch adversarial loss: 0.461593\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263249; batch adversarial loss: 0.405299\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204799; batch adversarial loss: 0.443941\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204740; batch adversarial loss: 0.409923\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253122; batch adversarial loss: 0.447015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254721; batch adversarial loss: 0.344081\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195027; batch adversarial loss: 0.419556\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157744; batch adversarial loss: 0.379440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.166634; batch adversarial loss: 0.364877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173025; batch adversarial loss: 0.370857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200457; batch adversarial loss: 0.416230\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194683; batch adversarial loss: 0.445608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155151; batch adversarial loss: 0.403636\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195508; batch adversarial loss: 0.384130\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137744; batch adversarial loss: 0.409793\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160745; batch adversarial loss: 0.372995\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164298; batch adversarial loss: 0.359690\n",
      "epoch 29; iter: 0; batch classifier loss: 0.186800; batch adversarial loss: 0.408145\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151780; batch adversarial loss: 0.393077\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192773; batch adversarial loss: 0.410843\n",
      "epoch 32; iter: 0; batch classifier loss: 0.153364; batch adversarial loss: 0.339198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129869; batch adversarial loss: 0.409074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.183395; batch adversarial loss: 0.415874\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140646; batch adversarial loss: 0.334257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170327; batch adversarial loss: 0.435403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130860; batch adversarial loss: 0.356520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118923; batch adversarial loss: 0.350030\n",
      "epoch 39; iter: 0; batch classifier loss: 0.083403; batch adversarial loss: 0.317039\n",
      "epoch 40; iter: 0; batch classifier loss: 0.111916; batch adversarial loss: 0.483032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104684; batch adversarial loss: 0.363093\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120095; batch adversarial loss: 0.413284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089200; batch adversarial loss: 0.333967\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122602; batch adversarial loss: 0.474412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098882; batch adversarial loss: 0.370028\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102560; batch adversarial loss: 0.464298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121463; batch adversarial loss: 0.492070\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101358; batch adversarial loss: 0.317937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085797; batch adversarial loss: 0.456062\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126048; batch adversarial loss: 0.392890\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105566; batch adversarial loss: 0.314741\n",
      "epoch 52; iter: 0; batch classifier loss: 0.086743; batch adversarial loss: 0.369367\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090649; batch adversarial loss: 0.373310\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095802; batch adversarial loss: 0.444527\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088901; batch adversarial loss: 0.473727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077816; batch adversarial loss: 0.317666\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091073; batch adversarial loss: 0.414344\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068995; batch adversarial loss: 0.398276\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071353; batch adversarial loss: 0.485810\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077938; batch adversarial loss: 0.349221\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105825; batch adversarial loss: 0.349545\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101251; batch adversarial loss: 0.373960\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090790; batch adversarial loss: 0.455846\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072268; batch adversarial loss: 0.321005\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087106; batch adversarial loss: 0.381674\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066946; batch adversarial loss: 0.384198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.084309; batch adversarial loss: 0.393221\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089995; batch adversarial loss: 0.503465\n",
      "epoch 69; iter: 0; batch classifier loss: 0.088271; batch adversarial loss: 0.427138\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101320; batch adversarial loss: 0.625083\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069015; batch adversarial loss: 0.299903\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086468; batch adversarial loss: 0.369278\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120548; batch adversarial loss: 0.411320\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079156; batch adversarial loss: 0.376491\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081930; batch adversarial loss: 0.326229\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041492; batch adversarial loss: 0.461045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096551; batch adversarial loss: 0.543025\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056553; batch adversarial loss: 0.315224\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075310; batch adversarial loss: 0.338863\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069283; batch adversarial loss: 0.380237\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079450; batch adversarial loss: 0.429280\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063693; batch adversarial loss: 0.410410\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070658; batch adversarial loss: 0.452908\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078240; batch adversarial loss: 0.466180\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075551; batch adversarial loss: 0.479605\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051470; batch adversarial loss: 0.450431\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054160; batch adversarial loss: 0.535572\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085316; batch adversarial loss: 0.409454\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047617; batch adversarial loss: 0.325075\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068548; batch adversarial loss: 0.365294\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085620; batch adversarial loss: 0.392042\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057065; batch adversarial loss: 0.366840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93; iter: 0; batch classifier loss: 0.088747; batch adversarial loss: 0.373738\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058237; batch adversarial loss: 0.357765\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029359; batch adversarial loss: 0.333984\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071107; batch adversarial loss: 0.369808\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063299; batch adversarial loss: 0.481765\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053441; batch adversarial loss: 0.442037\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064976; batch adversarial loss: 0.440762\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049361; batch adversarial loss: 0.376319\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041222; batch adversarial loss: 0.369330\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047643; batch adversarial loss: 0.398312\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041074; batch adversarial loss: 0.360584\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053888; batch adversarial loss: 0.426491\n",
      "epoch 105; iter: 0; batch classifier loss: 0.102911; batch adversarial loss: 0.401588\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033887; batch adversarial loss: 0.336389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069588; batch adversarial loss: 0.396831\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046833; batch adversarial loss: 0.446968\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052200; batch adversarial loss: 0.450775\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060387; batch adversarial loss: 0.390204\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036677; batch adversarial loss: 0.414665\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036889; batch adversarial loss: 0.460459\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038593; batch adversarial loss: 0.535253\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048794; batch adversarial loss: 0.429387\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052005; batch adversarial loss: 0.443875\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041986; batch adversarial loss: 0.393164\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026967; batch adversarial loss: 0.400890\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029980; batch adversarial loss: 0.466300\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034807; batch adversarial loss: 0.427001\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046936; batch adversarial loss: 0.353827\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049464; batch adversarial loss: 0.405459\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058811; batch adversarial loss: 0.364933\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052685; batch adversarial loss: 0.471692\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015940; batch adversarial loss: 0.450285\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033592; batch adversarial loss: 0.450646\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038993; batch adversarial loss: 0.472738\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033859; batch adversarial loss: 0.385159\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019872; batch adversarial loss: 0.477986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.078260; batch adversarial loss: 0.397259\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015615; batch adversarial loss: 0.460289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033787; batch adversarial loss: 0.396447\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017911; batch adversarial loss: 0.436003\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028190; batch adversarial loss: 0.379430\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014438; batch adversarial loss: 0.425368\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045944; batch adversarial loss: 0.413272\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025617; batch adversarial loss: 0.397355\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014859; batch adversarial loss: 0.415949\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018226; batch adversarial loss: 0.401058\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016103; batch adversarial loss: 0.460117\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023913; batch adversarial loss: 0.411265\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014180; batch adversarial loss: 0.438642\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028736; batch adversarial loss: 0.594085\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.379890\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037134; batch adversarial loss: 0.578029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062806; batch adversarial loss: 0.431930\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015045; batch adversarial loss: 0.445571\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068471; batch adversarial loss: 0.554510\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068209; batch adversarial loss: 0.634839\n",
      "epoch 149; iter: 0; batch classifier loss: 0.085774; batch adversarial loss: 0.577424\n",
      "epoch 150; iter: 0; batch classifier loss: 0.096948; batch adversarial loss: 0.606279\n",
      "epoch 151; iter: 0; batch classifier loss: 0.114237; batch adversarial loss: 0.553917\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066801; batch adversarial loss: 0.520750\n",
      "epoch 153; iter: 0; batch classifier loss: 0.067974; batch adversarial loss: 0.516771\n",
      "epoch 154; iter: 0; batch classifier loss: 0.137206; batch adversarial loss: 0.665982\n",
      "epoch 155; iter: 0; batch classifier loss: 0.129902; batch adversarial loss: 0.639835\n",
      "epoch 156; iter: 0; batch classifier loss: 0.232682; batch adversarial loss: 0.834622\n",
      "epoch 157; iter: 0; batch classifier loss: 0.142456; batch adversarial loss: 0.682734\n",
      "epoch 158; iter: 0; batch classifier loss: 0.120154; batch adversarial loss: 0.708494\n",
      "epoch 159; iter: 0; batch classifier loss: 0.173557; batch adversarial loss: 0.607834\n",
      "epoch 160; iter: 0; batch classifier loss: 0.070419; batch adversarial loss: 0.562484\n",
      "epoch 161; iter: 0; batch classifier loss: 0.119481; batch adversarial loss: 0.572088\n",
      "epoch 162; iter: 0; batch classifier loss: 0.106321; batch adversarial loss: 0.560421\n",
      "epoch 163; iter: 0; batch classifier loss: 0.123871; batch adversarial loss: 0.640195\n",
      "epoch 164; iter: 0; batch classifier loss: 0.167039; batch adversarial loss: 0.659105\n",
      "epoch 165; iter: 0; batch classifier loss: 0.152653; batch adversarial loss: 0.570097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.112628; batch adversarial loss: 0.521081\n",
      "epoch 167; iter: 0; batch classifier loss: 0.154061; batch adversarial loss: 0.622415\n",
      "epoch 168; iter: 0; batch classifier loss: 0.092631; batch adversarial loss: 0.507970\n",
      "epoch 169; iter: 0; batch classifier loss: 0.081864; batch adversarial loss: 0.424001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.202779; batch adversarial loss: 0.666307\n",
      "epoch 171; iter: 0; batch classifier loss: 0.083499; batch adversarial loss: 0.518838\n",
      "epoch 172; iter: 0; batch classifier loss: 0.097154; batch adversarial loss: 0.485440\n",
      "epoch 173; iter: 0; batch classifier loss: 0.208706; batch adversarial loss: 0.706738\n",
      "epoch 174; iter: 0; batch classifier loss: 0.131269; batch adversarial loss: 0.577756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147570; batch adversarial loss: 0.542573\n",
      "epoch 176; iter: 0; batch classifier loss: 0.108654; batch adversarial loss: 0.514373\n",
      "epoch 177; iter: 0; batch classifier loss: 0.123873; batch adversarial loss: 0.556548\n",
      "epoch 178; iter: 0; batch classifier loss: 0.183013; batch adversarial loss: 0.736843\n",
      "epoch 179; iter: 0; batch classifier loss: 0.165662; batch adversarial loss: 0.620969\n",
      "epoch 180; iter: 0; batch classifier loss: 0.106851; batch adversarial loss: 0.565517\n",
      "epoch 181; iter: 0; batch classifier loss: 0.102233; batch adversarial loss: 0.555928\n",
      "epoch 182; iter: 0; batch classifier loss: 0.113172; batch adversarial loss: 0.419522\n",
      "epoch 183; iter: 0; batch classifier loss: 0.135531; batch adversarial loss: 0.467483\n",
      "epoch 184; iter: 0; batch classifier loss: 0.080487; batch adversarial loss: 0.488887\n",
      "epoch 185; iter: 0; batch classifier loss: 0.110396; batch adversarial loss: 0.548862\n",
      "epoch 186; iter: 0; batch classifier loss: 0.178173; batch adversarial loss: 0.584574\n",
      "epoch 187; iter: 0; batch classifier loss: 0.103164; batch adversarial loss: 0.457462\n",
      "epoch 188; iter: 0; batch classifier loss: 0.128331; batch adversarial loss: 0.432004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 189; iter: 0; batch classifier loss: 0.093241; batch adversarial loss: 0.476165\n",
      "epoch 190; iter: 0; batch classifier loss: 0.141844; batch adversarial loss: 0.534354\n",
      "epoch 191; iter: 0; batch classifier loss: 0.051393; batch adversarial loss: 0.383472\n",
      "epoch 192; iter: 0; batch classifier loss: 0.129602; batch adversarial loss: 0.531271\n",
      "epoch 193; iter: 0; batch classifier loss: 0.132562; batch adversarial loss: 0.502744\n",
      "epoch 194; iter: 0; batch classifier loss: 0.085439; batch adversarial loss: 0.516633\n",
      "epoch 195; iter: 0; batch classifier loss: 0.110291; batch adversarial loss: 0.577641\n",
      "epoch 196; iter: 0; batch classifier loss: 0.127507; batch adversarial loss: 0.453863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.115802; batch adversarial loss: 0.470262\n",
      "epoch 198; iter: 0; batch classifier loss: 0.135237; batch adversarial loss: 0.436302\n",
      "epoch 199; iter: 0; batch classifier loss: 0.077807; batch adversarial loss: 0.448511\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682409; batch adversarial loss: 0.698211\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480089; batch adversarial loss: 0.630827\n",
      "epoch 2; iter: 0; batch classifier loss: 0.279107; batch adversarial loss: 0.622433\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388738; batch adversarial loss: 0.597052\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331267; batch adversarial loss: 0.578059\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378750; batch adversarial loss: 0.532745\n",
      "epoch 6; iter: 0; batch classifier loss: 0.269172; batch adversarial loss: 0.542217\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342720; batch adversarial loss: 0.493219\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308466; batch adversarial loss: 0.528501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.223144; batch adversarial loss: 0.466401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255824; batch adversarial loss: 0.435744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236242; batch adversarial loss: 0.451357\n",
      "epoch 12; iter: 0; batch classifier loss: 0.188386; batch adversarial loss: 0.470762\n",
      "epoch 13; iter: 0; batch classifier loss: 0.214243; batch adversarial loss: 0.521271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.199324; batch adversarial loss: 0.488778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.207122; batch adversarial loss: 0.493485\n",
      "epoch 16; iter: 0; batch classifier loss: 0.165778; batch adversarial loss: 0.555040\n",
      "epoch 17; iter: 0; batch classifier loss: 0.134680; batch adversarial loss: 0.431898\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187971; batch adversarial loss: 0.460758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223394; batch adversarial loss: 0.541586\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159503; batch adversarial loss: 0.575214\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185699; batch adversarial loss: 0.490201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257519; batch adversarial loss: 0.585162\n",
      "epoch 23; iter: 0; batch classifier loss: 0.170417; batch adversarial loss: 0.509636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165002; batch adversarial loss: 0.406499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212158; batch adversarial loss: 0.549425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169420; batch adversarial loss: 0.634603\n",
      "epoch 27; iter: 0; batch classifier loss: 0.195978; batch adversarial loss: 0.477184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.254377; batch adversarial loss: 0.433341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.336338; batch adversarial loss: 0.561941\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218023; batch adversarial loss: 0.403729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.220071; batch adversarial loss: 0.426846\n",
      "epoch 32; iter: 0; batch classifier loss: 0.344817; batch adversarial loss: 0.515631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348601; batch adversarial loss: 0.484253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128228; batch adversarial loss: 0.460703\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094102; batch adversarial loss: 0.509171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133740; batch adversarial loss: 0.502765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.080159; batch adversarial loss: 0.473047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141510; batch adversarial loss: 0.587732\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102766; batch adversarial loss: 0.472838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100844; batch adversarial loss: 0.483526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112635; batch adversarial loss: 0.519037\n",
      "epoch 42; iter: 0; batch classifier loss: 0.069234; batch adversarial loss: 0.384500\n",
      "epoch 43; iter: 0; batch classifier loss: 0.076650; batch adversarial loss: 0.388543\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086230; batch adversarial loss: 0.394481\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070065; batch adversarial loss: 0.353369\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113473; batch adversarial loss: 0.486397\n",
      "epoch 47; iter: 0; batch classifier loss: 0.057031; batch adversarial loss: 0.402846\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092216; batch adversarial loss: 0.488284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084122; batch adversarial loss: 0.504769\n",
      "epoch 50; iter: 0; batch classifier loss: 0.120777; batch adversarial loss: 0.465827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083284; batch adversarial loss: 0.421189\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113543; batch adversarial loss: 0.447210\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097705; batch adversarial loss: 0.448818\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086739; batch adversarial loss: 0.485453\n",
      "epoch 55; iter: 0; batch classifier loss: 0.039544; batch adversarial loss: 0.536052\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109342; batch adversarial loss: 0.400215\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107697; batch adversarial loss: 0.533911\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081943; batch adversarial loss: 0.512900\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067481; batch adversarial loss: 0.483054\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088249; batch adversarial loss: 0.521059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068442; batch adversarial loss: 0.451171\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078609; batch adversarial loss: 0.512910\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156002; batch adversarial loss: 0.422802\n",
      "epoch 64; iter: 0; batch classifier loss: 0.053811; batch adversarial loss: 0.439347\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083434; batch adversarial loss: 0.484878\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079480; batch adversarial loss: 0.491422\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087648; batch adversarial loss: 0.465322\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103161; batch adversarial loss: 0.453178\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091962; batch adversarial loss: 0.504157\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121817; batch adversarial loss: 0.513619\n",
      "epoch 71; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.496988\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097510; batch adversarial loss: 0.429486\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097115; batch adversarial loss: 0.513710\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080498; batch adversarial loss: 0.448716\n",
      "epoch 75; iter: 0; batch classifier loss: 0.121368; batch adversarial loss: 0.485685\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081457; batch adversarial loss: 0.470743\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097386; batch adversarial loss: 0.485039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122886; batch adversarial loss: 0.505824\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092289; batch adversarial loss: 0.461111\n",
      "epoch 80; iter: 0; batch classifier loss: 0.104140; batch adversarial loss: 0.462641\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038956; batch adversarial loss: 0.524654\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089849; batch adversarial loss: 0.472069\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085455; batch adversarial loss: 0.389017\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064995; batch adversarial loss: 0.558927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090987; batch adversarial loss: 0.452760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.064680; batch adversarial loss: 0.488991\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099577; batch adversarial loss: 0.474551\n",
      "epoch 88; iter: 0; batch classifier loss: 0.083991; batch adversarial loss: 0.491019\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074601; batch adversarial loss: 0.404353\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077591; batch adversarial loss: 0.562447\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101156; batch adversarial loss: 0.457304\n",
      "epoch 92; iter: 0; batch classifier loss: 0.093882; batch adversarial loss: 0.439101\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076649; batch adversarial loss: 0.504380\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073872; batch adversarial loss: 0.462175\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049877; batch adversarial loss: 0.428964\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045215; batch adversarial loss: 0.515205\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088617; batch adversarial loss: 0.424859\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096049; batch adversarial loss: 0.492748\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055667; batch adversarial loss: 0.425837\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097112; batch adversarial loss: 0.442054\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083900; batch adversarial loss: 0.503207\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081291; batch adversarial loss: 0.438179\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076272; batch adversarial loss: 0.434867\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057578; batch adversarial loss: 0.444801\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046493; batch adversarial loss: 0.426833\n",
      "epoch 106; iter: 0; batch classifier loss: 0.113703; batch adversarial loss: 0.428452\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068043; batch adversarial loss: 0.494359\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060037; batch adversarial loss: 0.483622\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062383; batch adversarial loss: 0.432414\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049856; batch adversarial loss: 0.458859\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064223; batch adversarial loss: 0.381395\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052861; batch adversarial loss: 0.514009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035688; batch adversarial loss: 0.438069\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070401; batch adversarial loss: 0.505512\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070855; batch adversarial loss: 0.347739\n",
      "epoch 116; iter: 0; batch classifier loss: 0.095085; batch adversarial loss: 0.430480\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065053; batch adversarial loss: 0.419992\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.396497\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051073; batch adversarial loss: 0.482951\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023486; batch adversarial loss: 0.367587\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059355; batch adversarial loss: 0.509004\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053678; batch adversarial loss: 0.344922\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047434; batch adversarial loss: 0.401553\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025296; batch adversarial loss: 0.425472\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072015; batch adversarial loss: 0.475971\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051839; batch adversarial loss: 0.439302\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044460; batch adversarial loss: 0.490510\n",
      "epoch 128; iter: 0; batch classifier loss: 0.073584; batch adversarial loss: 0.468974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.075081; batch adversarial loss: 0.496195\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042876; batch adversarial loss: 0.482885\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.457043\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024249; batch adversarial loss: 0.500914\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010866; batch adversarial loss: 0.460312\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016240; batch adversarial loss: 0.491746\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059864; batch adversarial loss: 0.413734\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032499; batch adversarial loss: 0.426831\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041739; batch adversarial loss: 0.488873\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026304; batch adversarial loss: 0.515786\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030368; batch adversarial loss: 0.419725\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018418; batch adversarial loss: 0.445862\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048863; batch adversarial loss: 0.448821\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020259; batch adversarial loss: 0.463485\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.516426\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025253; batch adversarial loss: 0.465808\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.467924\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019708; batch adversarial loss: 0.449839\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011290; batch adversarial loss: 0.471108\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030341; batch adversarial loss: 0.525085\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048846; batch adversarial loss: 0.348091\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.394641\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051872; batch adversarial loss: 0.476527\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014547; batch adversarial loss: 0.438469\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024739; batch adversarial loss: 0.344805\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012207; batch adversarial loss: 0.389211\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033132; batch adversarial loss: 0.544277\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042379; batch adversarial loss: 0.402568\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016270; batch adversarial loss: 0.424546\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028187; batch adversarial loss: 0.426504\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042579; batch adversarial loss: 0.548510\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053407; batch adversarial loss: 0.508803\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025351; batch adversarial loss: 0.415653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015301; batch adversarial loss: 0.488498\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040680; batch adversarial loss: 0.495357\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017659; batch adversarial loss: 0.493465\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026343; batch adversarial loss: 0.433161\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044721; batch adversarial loss: 0.509187\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016061; batch adversarial loss: 0.496510\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046654; batch adversarial loss: 0.428422\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028662; batch adversarial loss: 0.498501\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049599; batch adversarial loss: 0.526992\n",
      "epoch 171; iter: 0; batch classifier loss: 0.056968; batch adversarial loss: 0.397597\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009028; batch adversarial loss: 0.400166\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029885; batch adversarial loss: 0.480836\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049978; batch adversarial loss: 0.476937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031658; batch adversarial loss: 0.530130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013672; batch adversarial loss: 0.443104\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049008; batch adversarial loss: 0.382460\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044881; batch adversarial loss: 0.393241\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027558; batch adversarial loss: 0.425206\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021735; batch adversarial loss: 0.312821\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036032; batch adversarial loss: 0.493944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.040734; batch adversarial loss: 0.422320\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028387; batch adversarial loss: 0.446410\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020094; batch adversarial loss: 0.442191\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028069; batch adversarial loss: 0.469093\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016460; batch adversarial loss: 0.529252\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012401; batch adversarial loss: 0.519877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023155; batch adversarial loss: 0.401032\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014661; batch adversarial loss: 0.545811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027576; batch adversarial loss: 0.334343\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041993; batch adversarial loss: 0.382382\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022129; batch adversarial loss: 0.435972\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004320; batch adversarial loss: 0.445629\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019398; batch adversarial loss: 0.459797\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020526; batch adversarial loss: 0.468612\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015383; batch adversarial loss: 0.441581\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020688; batch adversarial loss: 0.439815\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020613; batch adversarial loss: 0.409571\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019418; batch adversarial loss: 0.478763\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682830; batch adversarial loss: 0.765563\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445332; batch adversarial loss: 0.745563\n",
      "epoch 2; iter: 0; batch classifier loss: 0.329719; batch adversarial loss: 0.701994\n",
      "epoch 3; iter: 0; batch classifier loss: 0.297213; batch adversarial loss: 0.657816\n",
      "epoch 4; iter: 0; batch classifier loss: 0.295552; batch adversarial loss: 0.638739\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328275; batch adversarial loss: 0.609622\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320888; batch adversarial loss: 0.581549\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326151; batch adversarial loss: 0.538214\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330411; batch adversarial loss: 0.545715\n",
      "epoch 9; iter: 0; batch classifier loss: 0.256371; batch adversarial loss: 0.501468\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263299; batch adversarial loss: 0.485766\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283717; batch adversarial loss: 0.428217\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277799; batch adversarial loss: 0.494912\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215641; batch adversarial loss: 0.448697\n",
      "epoch 14; iter: 0; batch classifier loss: 0.211240; batch adversarial loss: 0.458818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.258750; batch adversarial loss: 0.366765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270092; batch adversarial loss: 0.474422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.179771; batch adversarial loss: 0.434123\n",
      "epoch 18; iter: 0; batch classifier loss: 0.168339; batch adversarial loss: 0.480750\n",
      "epoch 19; iter: 0; batch classifier loss: 0.216645; batch adversarial loss: 0.418159\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185008; batch adversarial loss: 0.432211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218006; batch adversarial loss: 0.449974\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191679; batch adversarial loss: 0.414261\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180052; batch adversarial loss: 0.466998\n",
      "epoch 24; iter: 0; batch classifier loss: 0.179157; batch adversarial loss: 0.360239\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171346; batch adversarial loss: 0.407675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.147314; batch adversarial loss: 0.443304\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191435; batch adversarial loss: 0.391424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167281; batch adversarial loss: 0.366152\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146391; batch adversarial loss: 0.373571\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144449; batch adversarial loss: 0.407483\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149199; batch adversarial loss: 0.376789\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121136; batch adversarial loss: 0.444210\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131494; batch adversarial loss: 0.357791\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148700; batch adversarial loss: 0.463663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106419; batch adversarial loss: 0.410022\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163998; batch adversarial loss: 0.381897\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112873; batch adversarial loss: 0.377963\n",
      "epoch 38; iter: 0; batch classifier loss: 0.141422; batch adversarial loss: 0.366795\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147493; batch adversarial loss: 0.461761\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091645; batch adversarial loss: 0.381456\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131791; batch adversarial loss: 0.345169\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118356; batch adversarial loss: 0.277812\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093609; batch adversarial loss: 0.429179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.142162; batch adversarial loss: 0.529645\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104065; batch adversarial loss: 0.358382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093366; batch adversarial loss: 0.343589\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063003; batch adversarial loss: 0.367116\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099367; batch adversarial loss: 0.423284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129949; batch adversarial loss: 0.312701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110351; batch adversarial loss: 0.478827\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071364; batch adversarial loss: 0.343128\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102187; batch adversarial loss: 0.417925\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071068; batch adversarial loss: 0.436031\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091610; batch adversarial loss: 0.463059\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072502; batch adversarial loss: 0.441259\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094897; batch adversarial loss: 0.383120\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068331; batch adversarial loss: 0.473817\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109091; batch adversarial loss: 0.354227\n",
      "epoch 59; iter: 0; batch classifier loss: 0.048614; batch adversarial loss: 0.396604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.109604; batch adversarial loss: 0.420832\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078190; batch adversarial loss: 0.334069\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084538; batch adversarial loss: 0.458582\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115525; batch adversarial loss: 0.409967\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091016; batch adversarial loss: 0.430590\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083239; batch adversarial loss: 0.443164\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090144; batch adversarial loss: 0.439555\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061818; batch adversarial loss: 0.390245\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066020; batch adversarial loss: 0.352350\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096909; batch adversarial loss: 0.411264\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124892; batch adversarial loss: 0.433611\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075470; batch adversarial loss: 0.423976\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076490; batch adversarial loss: 0.432656\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066376; batch adversarial loss: 0.399261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.121189; batch adversarial loss: 0.540699\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047433; batch adversarial loss: 0.331763\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062552; batch adversarial loss: 0.414547\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047591; batch adversarial loss: 0.387431\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057743; batch adversarial loss: 0.370011\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.383982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.080581; batch adversarial loss: 0.439467\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060248; batch adversarial loss: 0.358989\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066368; batch adversarial loss: 0.534207\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081133; batch adversarial loss: 0.431664\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074681; batch adversarial loss: 0.486435\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048090; batch adversarial loss: 0.474798\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060994; batch adversarial loss: 0.403752\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046905; batch adversarial loss: 0.387976\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058268; batch adversarial loss: 0.429042\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052745; batch adversarial loss: 0.333433\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060621; batch adversarial loss: 0.453112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108284; batch adversarial loss: 0.386993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079349; batch adversarial loss: 0.297916\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050216; batch adversarial loss: 0.463171\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080085; batch adversarial loss: 0.388348\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082777; batch adversarial loss: 0.447427\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065091; batch adversarial loss: 0.433125\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073093; batch adversarial loss: 0.341155\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075960; batch adversarial loss: 0.498007\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096305; batch adversarial loss: 0.360164\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087073; batch adversarial loss: 0.420220\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088070; batch adversarial loss: 0.455373\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037130; batch adversarial loss: 0.425593\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070167; batch adversarial loss: 0.328960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048509; batch adversarial loss: 0.440479\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071252; batch adversarial loss: 0.442861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067811; batch adversarial loss: 0.461631\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058581; batch adversarial loss: 0.480161\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051995; batch adversarial loss: 0.468181\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046805; batch adversarial loss: 0.422172\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042126; batch adversarial loss: 0.427253\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061927; batch adversarial loss: 0.439139\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078475; batch adversarial loss: 0.369170\n",
      "epoch 113; iter: 0; batch classifier loss: 0.090113; batch adversarial loss: 0.377626\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059736; batch adversarial loss: 0.455652\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060495; batch adversarial loss: 0.348956\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036538; batch adversarial loss: 0.467302\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028694; batch adversarial loss: 0.455246\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066414; batch adversarial loss: 0.395515\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069173; batch adversarial loss: 0.458871\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.512123\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052356; batch adversarial loss: 0.407271\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.386683\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066407; batch adversarial loss: 0.439456\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057530; batch adversarial loss: 0.331035\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037302; batch adversarial loss: 0.498251\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072277; batch adversarial loss: 0.451242\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045306; batch adversarial loss: 0.425104\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053519; batch adversarial loss: 0.376761\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065325; batch adversarial loss: 0.465798\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031068; batch adversarial loss: 0.442988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034290; batch adversarial loss: 0.359181\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047095; batch adversarial loss: 0.440453\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033810; batch adversarial loss: 0.406076\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030120; batch adversarial loss: 0.459227\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029523; batch adversarial loss: 0.487890\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039738; batch adversarial loss: 0.471203\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026506; batch adversarial loss: 0.478941\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039105; batch adversarial loss: 0.473572\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048021; batch adversarial loss: 0.369448\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040272; batch adversarial loss: 0.463172\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046391; batch adversarial loss: 0.508489\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045229; batch adversarial loss: 0.509695\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047832; batch adversarial loss: 0.399747\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044340; batch adversarial loss: 0.385240\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037194; batch adversarial loss: 0.427548\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027847; batch adversarial loss: 0.444669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030838; batch adversarial loss: 0.438214\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046704; batch adversarial loss: 0.418205\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056503; batch adversarial loss: 0.363691\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024903; batch adversarial loss: 0.443751\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016779; batch adversarial loss: 0.431269\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019471; batch adversarial loss: 0.386630\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030248; batch adversarial loss: 0.470339\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037678; batch adversarial loss: 0.370693\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046882; batch adversarial loss: 0.459037\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037271; batch adversarial loss: 0.454339\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014198; batch adversarial loss: 0.368399\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009521; batch adversarial loss: 0.508575\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019159; batch adversarial loss: 0.531508\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039972; batch adversarial loss: 0.433266\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038396; batch adversarial loss: 0.501594\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018901; batch adversarial loss: 0.465213\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038939; batch adversarial loss: 0.473783\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047391; batch adversarial loss: 0.472830\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025868; batch adversarial loss: 0.449229\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019812; batch adversarial loss: 0.509163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034847; batch adversarial loss: 0.438333\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.420327\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052223; batch adversarial loss: 0.395444\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025051; batch adversarial loss: 0.465356\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030934; batch adversarial loss: 0.408965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039984; batch adversarial loss: 0.512429\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036586; batch adversarial loss: 0.501246\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027488; batch adversarial loss: 0.482085\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020442; batch adversarial loss: 0.491487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.015132; batch adversarial loss: 0.378600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.054907; batch adversarial loss: 0.530579\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049417; batch adversarial loss: 0.433540\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026030; batch adversarial loss: 0.452201\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031533; batch adversarial loss: 0.461332\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026511; batch adversarial loss: 0.446997\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027740; batch adversarial loss: 0.368465\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021017; batch adversarial loss: 0.534301\n",
      "epoch 184; iter: 0; batch classifier loss: 0.053363; batch adversarial loss: 0.452909\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017469; batch adversarial loss: 0.512297\n",
      "epoch 186; iter: 0; batch classifier loss: 0.053495; batch adversarial loss: 0.551112\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021445; batch adversarial loss: 0.453461\n",
      "epoch 188; iter: 0; batch classifier loss: 0.069501; batch adversarial loss: 0.481164\n",
      "epoch 189; iter: 0; batch classifier loss: 0.064824; batch adversarial loss: 0.548468\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019663; batch adversarial loss: 0.397475\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035443; batch adversarial loss: 0.595635\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051621; batch adversarial loss: 0.644063\n",
      "epoch 193; iter: 0; batch classifier loss: 0.083746; batch adversarial loss: 0.599816\n",
      "epoch 194; iter: 0; batch classifier loss: 0.111128; batch adversarial loss: 0.714705\n",
      "epoch 195; iter: 0; batch classifier loss: 0.204343; batch adversarial loss: 0.851873\n",
      "epoch 196; iter: 0; batch classifier loss: 0.073551; batch adversarial loss: 0.430927\n",
      "epoch 197; iter: 0; batch classifier loss: 0.153664; batch adversarial loss: 0.877044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.075495; batch adversarial loss: 0.599277\n",
      "epoch 199; iter: 0; batch classifier loss: 0.127400; batch adversarial loss: 0.557831\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704553; batch adversarial loss: 0.640436\n",
      "epoch 1; iter: 0; batch classifier loss: 0.402793; batch adversarial loss: 0.618350\n",
      "epoch 2; iter: 0; batch classifier loss: 0.483483; batch adversarial loss: 0.605031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369185; batch adversarial loss: 0.587130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.392486; batch adversarial loss: 0.590187\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379861; batch adversarial loss: 0.609842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579703; batch adversarial loss: 0.559544\n",
      "epoch 7; iter: 0; batch classifier loss: 0.643272; batch adversarial loss: 0.592097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530975; batch adversarial loss: 0.549199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563412; batch adversarial loss: 0.578902\n",
      "epoch 10; iter: 0; batch classifier loss: 0.429973; batch adversarial loss: 0.528551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381723; batch adversarial loss: 0.504090\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364681; batch adversarial loss: 0.562624\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463268; batch adversarial loss: 0.469942\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370553; batch adversarial loss: 0.519777\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.501496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.295689; batch adversarial loss: 0.524315\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287547; batch adversarial loss: 0.510592\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314888; batch adversarial loss: 0.492701\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321139; batch adversarial loss: 0.465864\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269231; batch adversarial loss: 0.477389\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364449; batch adversarial loss: 0.458654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330072; batch adversarial loss: 0.474663\n",
      "epoch 23; iter: 0; batch classifier loss: 0.312016; batch adversarial loss: 0.490394\n",
      "epoch 24; iter: 0; batch classifier loss: 0.220444; batch adversarial loss: 0.508035\n",
      "epoch 25; iter: 0; batch classifier loss: 0.283293; batch adversarial loss: 0.461953\n",
      "epoch 26; iter: 0; batch classifier loss: 0.265807; batch adversarial loss: 0.490709\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312772; batch adversarial loss: 0.469308\n",
      "epoch 28; iter: 0; batch classifier loss: 0.293755; batch adversarial loss: 0.363286\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215036; batch adversarial loss: 0.451194\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264204; batch adversarial loss: 0.541896\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234751; batch adversarial loss: 0.436000\n",
      "epoch 32; iter: 0; batch classifier loss: 0.277069; batch adversarial loss: 0.410412\n",
      "epoch 33; iter: 0; batch classifier loss: 0.335317; batch adversarial loss: 0.444783\n",
      "epoch 34; iter: 0; batch classifier loss: 0.242736; batch adversarial loss: 0.405695\n",
      "epoch 35; iter: 0; batch classifier loss: 0.216257; batch adversarial loss: 0.462549\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250906; batch adversarial loss: 0.474542\n",
      "epoch 37; iter: 0; batch classifier loss: 0.279748; batch adversarial loss: 0.427846\n",
      "epoch 38; iter: 0; batch classifier loss: 0.256691; batch adversarial loss: 0.435609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320845; batch adversarial loss: 0.436630\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270224; batch adversarial loss: 0.437391\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358213; batch adversarial loss: 0.437652\n",
      "epoch 42; iter: 0; batch classifier loss: 0.187130; batch adversarial loss: 0.447913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.182888; batch adversarial loss: 0.543042\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267183; batch adversarial loss: 0.517768\n",
      "epoch 45; iter: 0; batch classifier loss: 0.141696; batch adversarial loss: 0.543248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.177599; batch adversarial loss: 0.473068\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185862; batch adversarial loss: 0.544825\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138445; batch adversarial loss: 0.374692\n",
      "epoch 49; iter: 0; batch classifier loss: 0.274354; batch adversarial loss: 0.411201\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132877; batch adversarial loss: 0.495014\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199840; batch adversarial loss: 0.482545\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157143; batch adversarial loss: 0.495574\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129072; batch adversarial loss: 0.434848\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114860; batch adversarial loss: 0.395977\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131462; batch adversarial loss: 0.557313\n",
      "epoch 56; iter: 0; batch classifier loss: 0.248994; batch adversarial loss: 0.596303\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134842; batch adversarial loss: 0.434514\n",
      "epoch 58; iter: 0; batch classifier loss: 0.120591; batch adversarial loss: 0.336576\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144272; batch adversarial loss: 0.447494\n",
      "epoch 60; iter: 0; batch classifier loss: 0.167392; batch adversarial loss: 0.485220\n",
      "epoch 61; iter: 0; batch classifier loss: 0.229698; batch adversarial loss: 0.361176\n",
      "epoch 62; iter: 0; batch classifier loss: 0.153187; batch adversarial loss: 0.397443\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095446; batch adversarial loss: 0.408425\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074422; batch adversarial loss: 0.445408\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069382; batch adversarial loss: 0.317195\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060876; batch adversarial loss: 0.478949\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050789; batch adversarial loss: 0.419313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078543; batch adversarial loss: 0.422605\n",
      "epoch 69; iter: 0; batch classifier loss: 0.047684; batch adversarial loss: 0.497835\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066280; batch adversarial loss: 0.323740\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067711; batch adversarial loss: 0.515244\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085867; batch adversarial loss: 0.440824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73; iter: 0; batch classifier loss: 0.096513; batch adversarial loss: 0.320645\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109897; batch adversarial loss: 0.433112\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086850; batch adversarial loss: 0.457775\n",
      "epoch 76; iter: 0; batch classifier loss: 0.105488; batch adversarial loss: 0.405766\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118400; batch adversarial loss: 0.504342\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075914; batch adversarial loss: 0.481173\n",
      "epoch 79; iter: 0; batch classifier loss: 0.083649; batch adversarial loss: 0.436590\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079300; batch adversarial loss: 0.459994\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078381; batch adversarial loss: 0.369695\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078930; batch adversarial loss: 0.450320\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053106; batch adversarial loss: 0.364872\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069892; batch adversarial loss: 0.470547\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067077; batch adversarial loss: 0.491790\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076197; batch adversarial loss: 0.511253\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051251; batch adversarial loss: 0.444759\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070404; batch adversarial loss: 0.333936\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036557; batch adversarial loss: 0.395577\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075835; batch adversarial loss: 0.444349\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046391; batch adversarial loss: 0.453182\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060098; batch adversarial loss: 0.430425\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085439; batch adversarial loss: 0.385822\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047551; batch adversarial loss: 0.456220\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054067; batch adversarial loss: 0.461279\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043633; batch adversarial loss: 0.443646\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047208; batch adversarial loss: 0.504103\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033049; batch adversarial loss: 0.430097\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054760; batch adversarial loss: 0.575433\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048464; batch adversarial loss: 0.506561\n",
      "epoch 101; iter: 0; batch classifier loss: 0.029639; batch adversarial loss: 0.550858\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068914; batch adversarial loss: 0.438628\n",
      "epoch 103; iter: 0; batch classifier loss: 0.019397; batch adversarial loss: 0.447222\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027245; batch adversarial loss: 0.583923\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054525; batch adversarial loss: 0.405285\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067067; batch adversarial loss: 0.409778\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061310; batch adversarial loss: 0.442381\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057046; batch adversarial loss: 0.476697\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039193; batch adversarial loss: 0.452697\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041488; batch adversarial loss: 0.503791\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022314; batch adversarial loss: 0.393986\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039304; batch adversarial loss: 0.499492\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025078; batch adversarial loss: 0.503497\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048478; batch adversarial loss: 0.465903\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040971; batch adversarial loss: 0.476393\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036306; batch adversarial loss: 0.473742\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056305; batch adversarial loss: 0.504200\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057811; batch adversarial loss: 0.468564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043534; batch adversarial loss: 0.496915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051647; batch adversarial loss: 0.471438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034065; batch adversarial loss: 0.475276\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037878; batch adversarial loss: 0.500697\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057489; batch adversarial loss: 0.439071\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040224; batch adversarial loss: 0.427324\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029864; batch adversarial loss: 0.394445\n",
      "epoch 126; iter: 0; batch classifier loss: 0.010947; batch adversarial loss: 0.450168\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032822; batch adversarial loss: 0.504191\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027734; batch adversarial loss: 0.457623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033901; batch adversarial loss: 0.451204\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048223; batch adversarial loss: 0.429067\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054084; batch adversarial loss: 0.389736\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031459; batch adversarial loss: 0.448581\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052008; batch adversarial loss: 0.416612\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037655; batch adversarial loss: 0.390298\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026663; batch adversarial loss: 0.417143\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029156; batch adversarial loss: 0.445424\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055171; batch adversarial loss: 0.472320\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.411378\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023656; batch adversarial loss: 0.413712\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018605; batch adversarial loss: 0.379059\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021224; batch adversarial loss: 0.437081\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.554822\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011493; batch adversarial loss: 0.373685\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022961; batch adversarial loss: 0.354119\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016777; batch adversarial loss: 0.421799\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031812; batch adversarial loss: 0.428596\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040940; batch adversarial loss: 0.458212\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041053; batch adversarial loss: 0.391905\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016424; batch adversarial loss: 0.444938\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046887; batch adversarial loss: 0.468606\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013001; batch adversarial loss: 0.468383\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.371171\n",
      "epoch 153; iter: 0; batch classifier loss: 0.004772; batch adversarial loss: 0.524221\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034380; batch adversarial loss: 0.393557\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023996; batch adversarial loss: 0.468615\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020183; batch adversarial loss: 0.433677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.412656\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019076; batch adversarial loss: 0.391946\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010612; batch adversarial loss: 0.464428\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009049; batch adversarial loss: 0.373699\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019215; batch adversarial loss: 0.458703\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026974; batch adversarial loss: 0.522105\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008126; batch adversarial loss: 0.489456\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009346; batch adversarial loss: 0.498313\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016456; batch adversarial loss: 0.404866\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010067; batch adversarial loss: 0.477128\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010080; batch adversarial loss: 0.418845\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026502; batch adversarial loss: 0.467727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 169; iter: 0; batch classifier loss: 0.007335; batch adversarial loss: 0.455217\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015079; batch adversarial loss: 0.475849\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021534; batch adversarial loss: 0.468257\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016034; batch adversarial loss: 0.506646\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006943; batch adversarial loss: 0.371927\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022587; batch adversarial loss: 0.526248\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017058; batch adversarial loss: 0.481126\n",
      "epoch 176; iter: 0; batch classifier loss: 0.006967; batch adversarial loss: 0.322265\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009501; batch adversarial loss: 0.429603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.402670\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007986; batch adversarial loss: 0.464029\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023895; batch adversarial loss: 0.441226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008838; batch adversarial loss: 0.349943\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011481; batch adversarial loss: 0.464811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030733; batch adversarial loss: 0.527643\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015593; batch adversarial loss: 0.495152\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028259; batch adversarial loss: 0.394076\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.491374\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006355; batch adversarial loss: 0.422579\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026145; batch adversarial loss: 0.434395\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016463; batch adversarial loss: 0.459734\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008305; batch adversarial loss: 0.479256\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010218; batch adversarial loss: 0.449774\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008458; batch adversarial loss: 0.605241\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010478; batch adversarial loss: 0.421104\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003681; batch adversarial loss: 0.398800\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008238; batch adversarial loss: 0.411059\n",
      "epoch 196; iter: 0; batch classifier loss: 0.001963; batch adversarial loss: 0.405378\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008000; batch adversarial loss: 0.426684\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014280; batch adversarial loss: 0.423144\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004465; batch adversarial loss: 0.472377\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687272; batch adversarial loss: 0.974170\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718226; batch adversarial loss: 1.107869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.928747; batch adversarial loss: 1.131726\n",
      "epoch 3; iter: 0; batch classifier loss: 1.033387; batch adversarial loss: 1.034829\n",
      "epoch 4; iter: 0; batch classifier loss: 1.141502; batch adversarial loss: 0.952486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.969490; batch adversarial loss: 0.820356\n",
      "epoch 6; iter: 0; batch classifier loss: 1.075412; batch adversarial loss: 0.785702\n",
      "epoch 7; iter: 0; batch classifier loss: 0.921276; batch adversarial loss: 0.689087\n",
      "epoch 8; iter: 0; batch classifier loss: 0.728818; batch adversarial loss: 0.663832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.714849; batch adversarial loss: 0.598940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488647; batch adversarial loss: 0.594355\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409335; batch adversarial loss: 0.535168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331342; batch adversarial loss: 0.519770\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326871; batch adversarial loss: 0.469048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263934; batch adversarial loss: 0.502711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304916; batch adversarial loss: 0.455555\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249064; batch adversarial loss: 0.518726\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313030; batch adversarial loss: 0.498563\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239659; batch adversarial loss: 0.458346\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222168; batch adversarial loss: 0.444537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198762; batch adversarial loss: 0.516205\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221123; batch adversarial loss: 0.466936\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240976; batch adversarial loss: 0.480004\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239051; batch adversarial loss: 0.516088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.212273; batch adversarial loss: 0.485382\n",
      "epoch 25; iter: 0; batch classifier loss: 0.227631; batch adversarial loss: 0.503643\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148264; batch adversarial loss: 0.510670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166010; batch adversarial loss: 0.606250\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160868; batch adversarial loss: 0.532632\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216063; batch adversarial loss: 0.482485\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157133; batch adversarial loss: 0.503900\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265788; batch adversarial loss: 0.450143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216782; batch adversarial loss: 0.418530\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193340; batch adversarial loss: 0.463392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148156; batch adversarial loss: 0.525238\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135482; batch adversarial loss: 0.498791\n",
      "epoch 36; iter: 0; batch classifier loss: 0.206926; batch adversarial loss: 0.406980\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148745; batch adversarial loss: 0.401481\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165457; batch adversarial loss: 0.390742\n",
      "epoch 39; iter: 0; batch classifier loss: 0.178977; batch adversarial loss: 0.382752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165432; batch adversarial loss: 0.503618\n",
      "epoch 41; iter: 0; batch classifier loss: 0.169487; batch adversarial loss: 0.466222\n",
      "epoch 42; iter: 0; batch classifier loss: 0.218935; batch adversarial loss: 0.536798\n",
      "epoch 43; iter: 0; batch classifier loss: 0.165233; batch adversarial loss: 0.507477\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163080; batch adversarial loss: 0.485551\n",
      "epoch 45; iter: 0; batch classifier loss: 0.238990; batch adversarial loss: 0.418759\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207096; batch adversarial loss: 0.443243\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215078; batch adversarial loss: 0.435005\n",
      "epoch 48; iter: 0; batch classifier loss: 0.139526; batch adversarial loss: 0.426043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212162; batch adversarial loss: 0.421496\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142837; batch adversarial loss: 0.559166\n",
      "epoch 51; iter: 0; batch classifier loss: 0.140656; batch adversarial loss: 0.441372\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116168; batch adversarial loss: 0.457429\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189905; batch adversarial loss: 0.420482\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147269; batch adversarial loss: 0.464676\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146792; batch adversarial loss: 0.512677\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100638; batch adversarial loss: 0.484480\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133077; batch adversarial loss: 0.477323\n",
      "epoch 58; iter: 0; batch classifier loss: 0.140046; batch adversarial loss: 0.472289\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104171; batch adversarial loss: 0.490657\n",
      "epoch 60; iter: 0; batch classifier loss: 0.246231; batch adversarial loss: 0.432507\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113308; batch adversarial loss: 0.528934\n",
      "epoch 62; iter: 0; batch classifier loss: 0.207790; batch adversarial loss: 0.349435\n",
      "epoch 63; iter: 0; batch classifier loss: 0.161428; batch adversarial loss: 0.413480\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154881; batch adversarial loss: 0.453151\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122893; batch adversarial loss: 0.393973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.155549; batch adversarial loss: 0.431922\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133754; batch adversarial loss: 0.486811\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071378; batch adversarial loss: 0.462226\n",
      "epoch 69; iter: 0; batch classifier loss: 0.119228; batch adversarial loss: 0.436984\n",
      "epoch 70; iter: 0; batch classifier loss: 0.177891; batch adversarial loss: 0.408806\n",
      "epoch 71; iter: 0; batch classifier loss: 0.159381; batch adversarial loss: 0.429471\n",
      "epoch 72; iter: 0; batch classifier loss: 0.163568; batch adversarial loss: 0.391301\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099398; batch adversarial loss: 0.398858\n",
      "epoch 74; iter: 0; batch classifier loss: 0.120849; batch adversarial loss: 0.302574\n",
      "epoch 75; iter: 0; batch classifier loss: 0.167886; batch adversarial loss: 0.433935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.144403; batch adversarial loss: 0.412769\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156182; batch adversarial loss: 0.418521\n",
      "epoch 78; iter: 0; batch classifier loss: 0.139465; batch adversarial loss: 0.445459\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114348; batch adversarial loss: 0.476595\n",
      "epoch 80; iter: 0; batch classifier loss: 0.127067; batch adversarial loss: 0.452655\n",
      "epoch 81; iter: 0; batch classifier loss: 0.141867; batch adversarial loss: 0.413002\n",
      "epoch 82; iter: 0; batch classifier loss: 0.180757; batch adversarial loss: 0.384555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.147879; batch adversarial loss: 0.455911\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153039; batch adversarial loss: 0.343865\n",
      "epoch 85; iter: 0; batch classifier loss: 0.139198; batch adversarial loss: 0.425312\n",
      "epoch 86; iter: 0; batch classifier loss: 0.143196; batch adversarial loss: 0.461873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154862; batch adversarial loss: 0.494449\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103649; batch adversarial loss: 0.531668\n",
      "epoch 89; iter: 0; batch classifier loss: 0.148489; batch adversarial loss: 0.488553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147477; batch adversarial loss: 0.383870\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139049; batch adversarial loss: 0.486786\n",
      "epoch 92; iter: 0; batch classifier loss: 0.181858; batch adversarial loss: 0.470279\n",
      "epoch 93; iter: 0; batch classifier loss: 0.162676; batch adversarial loss: 0.433168\n",
      "epoch 94; iter: 0; batch classifier loss: 0.195890; batch adversarial loss: 0.480328\n",
      "epoch 95; iter: 0; batch classifier loss: 0.151285; batch adversarial loss: 0.456654\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083943; batch adversarial loss: 0.474580\n",
      "epoch 97; iter: 0; batch classifier loss: 0.130695; batch adversarial loss: 0.418807\n",
      "epoch 98; iter: 0; batch classifier loss: 0.175956; batch adversarial loss: 0.330561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.161215; batch adversarial loss: 0.403655\n",
      "epoch 100; iter: 0; batch classifier loss: 0.171040; batch adversarial loss: 0.480981\n",
      "epoch 101; iter: 0; batch classifier loss: 0.140806; batch adversarial loss: 0.454502\n",
      "epoch 102; iter: 0; batch classifier loss: 0.153453; batch adversarial loss: 0.420908\n",
      "epoch 103; iter: 0; batch classifier loss: 0.165098; batch adversarial loss: 0.406865\n",
      "epoch 104; iter: 0; batch classifier loss: 0.183981; batch adversarial loss: 0.385976\n",
      "epoch 105; iter: 0; batch classifier loss: 0.141655; batch adversarial loss: 0.383637\n",
      "epoch 106; iter: 0; batch classifier loss: 0.178724; batch adversarial loss: 0.443042\n",
      "epoch 107; iter: 0; batch classifier loss: 0.111368; batch adversarial loss: 0.510260\n",
      "epoch 108; iter: 0; batch classifier loss: 0.203263; batch adversarial loss: 0.369101\n",
      "epoch 109; iter: 0; batch classifier loss: 0.160713; batch adversarial loss: 0.457903\n",
      "epoch 110; iter: 0; batch classifier loss: 0.145597; batch adversarial loss: 0.393390\n",
      "epoch 111; iter: 0; batch classifier loss: 0.204299; batch adversarial loss: 0.498794\n",
      "epoch 112; iter: 0; batch classifier loss: 0.165777; batch adversarial loss: 0.470268\n",
      "epoch 113; iter: 0; batch classifier loss: 0.174626; batch adversarial loss: 0.437026\n",
      "epoch 114; iter: 0; batch classifier loss: 0.155097; batch adversarial loss: 0.396767\n",
      "epoch 115; iter: 0; batch classifier loss: 0.106967; batch adversarial loss: 0.537301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.145642; batch adversarial loss: 0.443968\n",
      "epoch 117; iter: 0; batch classifier loss: 0.145494; batch adversarial loss: 0.393861\n",
      "epoch 118; iter: 0; batch classifier loss: 0.195457; batch adversarial loss: 0.484905\n",
      "epoch 119; iter: 0; batch classifier loss: 0.152979; batch adversarial loss: 0.497670\n",
      "epoch 120; iter: 0; batch classifier loss: 0.203553; batch adversarial loss: 0.487378\n",
      "epoch 121; iter: 0; batch classifier loss: 0.163880; batch adversarial loss: 0.435079\n",
      "epoch 122; iter: 0; batch classifier loss: 0.150848; batch adversarial loss: 0.396163\n",
      "epoch 123; iter: 0; batch classifier loss: 0.164705; batch adversarial loss: 0.435012\n",
      "epoch 124; iter: 0; batch classifier loss: 0.148098; batch adversarial loss: 0.394331\n",
      "epoch 125; iter: 0; batch classifier loss: 0.157912; batch adversarial loss: 0.469075\n",
      "epoch 126; iter: 0; batch classifier loss: 0.190886; batch adversarial loss: 0.523483\n",
      "epoch 127; iter: 0; batch classifier loss: 0.168913; batch adversarial loss: 0.495284\n",
      "epoch 128; iter: 0; batch classifier loss: 0.165670; batch adversarial loss: 0.459611\n",
      "epoch 129; iter: 0; batch classifier loss: 0.196353; batch adversarial loss: 0.447117\n",
      "epoch 130; iter: 0; batch classifier loss: 0.170767; batch adversarial loss: 0.359976\n",
      "epoch 131; iter: 0; batch classifier loss: 0.230171; batch adversarial loss: 0.371137\n",
      "epoch 132; iter: 0; batch classifier loss: 0.170946; batch adversarial loss: 0.345713\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210181; batch adversarial loss: 0.545188\n",
      "epoch 134; iter: 0; batch classifier loss: 0.157820; batch adversarial loss: 0.435158\n",
      "epoch 135; iter: 0; batch classifier loss: 0.166218; batch adversarial loss: 0.359849\n",
      "epoch 136; iter: 0; batch classifier loss: 0.172934; batch adversarial loss: 0.445420\n",
      "epoch 137; iter: 0; batch classifier loss: 0.259980; batch adversarial loss: 0.460363\n",
      "epoch 138; iter: 0; batch classifier loss: 0.195533; batch adversarial loss: 0.457847\n",
      "epoch 139; iter: 0; batch classifier loss: 0.152972; batch adversarial loss: 0.522881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.149533; batch adversarial loss: 0.484451\n",
      "epoch 141; iter: 0; batch classifier loss: 0.200566; batch adversarial loss: 0.408644\n",
      "epoch 142; iter: 0; batch classifier loss: 0.156743; batch adversarial loss: 0.383867\n",
      "epoch 143; iter: 0; batch classifier loss: 0.090260; batch adversarial loss: 0.433982\n",
      "epoch 144; iter: 0; batch classifier loss: 0.162526; batch adversarial loss: 0.396151\n",
      "epoch 145; iter: 0; batch classifier loss: 0.132623; batch adversarial loss: 0.522277\n",
      "epoch 146; iter: 0; batch classifier loss: 0.171835; batch adversarial loss: 0.422441\n",
      "epoch 147; iter: 0; batch classifier loss: 0.145026; batch adversarial loss: 0.496999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.142246; batch adversarial loss: 0.571701\n",
      "epoch 149; iter: 0; batch classifier loss: 0.233828; batch adversarial loss: 0.345575\n",
      "epoch 150; iter: 0; batch classifier loss: 0.103389; batch adversarial loss: 0.496491\n",
      "epoch 151; iter: 0; batch classifier loss: 0.065731; batch adversarial loss: 0.432209\n",
      "epoch 152; iter: 0; batch classifier loss: 0.059073; batch adversarial loss: 0.532800\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045283; batch adversarial loss: 0.496873\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043387; batch adversarial loss: 0.407514\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052078; batch adversarial loss: 0.459457\n",
      "epoch 156; iter: 0; batch classifier loss: 0.069113; batch adversarial loss: 0.484366\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050289; batch adversarial loss: 0.408300\n",
      "epoch 158; iter: 0; batch classifier loss: 0.098197; batch adversarial loss: 0.423744\n",
      "epoch 159; iter: 0; batch classifier loss: 0.062678; batch adversarial loss: 0.526614\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054766; batch adversarial loss: 0.413538\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053571; batch adversarial loss: 0.390781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.057673; batch adversarial loss: 0.450904\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059838; batch adversarial loss: 0.531352\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029704; batch adversarial loss: 0.439637\n",
      "epoch 165; iter: 0; batch classifier loss: 0.097290; batch adversarial loss: 0.423855\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.408131\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037450; batch adversarial loss: 0.430637\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040037; batch adversarial loss: 0.458012\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048373; batch adversarial loss: 0.391718\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058759; batch adversarial loss: 0.451463\n",
      "epoch 171; iter: 0; batch classifier loss: 0.066263; batch adversarial loss: 0.360213\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033144; batch adversarial loss: 0.390081\n",
      "epoch 173; iter: 0; batch classifier loss: 0.060573; batch adversarial loss: 0.402818\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049747; batch adversarial loss: 0.472779\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040385; batch adversarial loss: 0.468952\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044297; batch adversarial loss: 0.440705\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023082; batch adversarial loss: 0.455531\n",
      "epoch 178; iter: 0; batch classifier loss: 0.061944; batch adversarial loss: 0.447322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028912; batch adversarial loss: 0.323839\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041475; batch adversarial loss: 0.418779\n",
      "epoch 181; iter: 0; batch classifier loss: 0.050081; batch adversarial loss: 0.517948\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016060; batch adversarial loss: 0.471835\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016760; batch adversarial loss: 0.370456\n",
      "epoch 184; iter: 0; batch classifier loss: 0.065525; batch adversarial loss: 0.421834\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022588; batch adversarial loss: 0.515208\n",
      "epoch 186; iter: 0; batch classifier loss: 0.058029; batch adversarial loss: 0.451584\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.510183\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031824; batch adversarial loss: 0.500838\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023183; batch adversarial loss: 0.436971\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040056; batch adversarial loss: 0.461211\n",
      "epoch 191; iter: 0; batch classifier loss: 0.059129; batch adversarial loss: 0.473721\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031384; batch adversarial loss: 0.431913\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022203; batch adversarial loss: 0.450323\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012222; batch adversarial loss: 0.498222\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010095; batch adversarial loss: 0.457343\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026760; batch adversarial loss: 0.496275\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028462; batch adversarial loss: 0.425658\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022932; batch adversarial loss: 0.422551\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022142; batch adversarial loss: 0.567554\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698594; batch adversarial loss: 0.596799\n",
      "epoch 1; iter: 0; batch classifier loss: 0.363386; batch adversarial loss: 0.612312\n",
      "epoch 2; iter: 0; batch classifier loss: 0.309621; batch adversarial loss: 0.600274\n",
      "epoch 3; iter: 0; batch classifier loss: 0.262070; batch adversarial loss: 0.602553\n",
      "epoch 4; iter: 0; batch classifier loss: 0.307528; batch adversarial loss: 0.571099\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336494; batch adversarial loss: 0.511065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.372367; batch adversarial loss: 0.561971\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334359; batch adversarial loss: 0.466412\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271209; batch adversarial loss: 0.560963\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271061; batch adversarial loss: 0.530890\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258141; batch adversarial loss: 0.573944\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228458; batch adversarial loss: 0.532317\n",
      "epoch 12; iter: 0; batch classifier loss: 0.177730; batch adversarial loss: 0.578249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.192094; batch adversarial loss: 0.472924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.211025; batch adversarial loss: 0.569445\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229630; batch adversarial loss: 0.514292\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223225; batch adversarial loss: 0.505699\n",
      "epoch 17; iter: 0; batch classifier loss: 0.157420; batch adversarial loss: 0.498265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287948; batch adversarial loss: 0.626251\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224642; batch adversarial loss: 0.616182\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187966; batch adversarial loss: 0.603408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248702; batch adversarial loss: 0.564738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268002; batch adversarial loss: 0.474746\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282495; batch adversarial loss: 0.577638\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291460; batch adversarial loss: 0.597575\n",
      "epoch 25; iter: 0; batch classifier loss: 0.264845; batch adversarial loss: 0.499177\n",
      "epoch 26; iter: 0; batch classifier loss: 0.270024; batch adversarial loss: 0.495179\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243212; batch adversarial loss: 0.439272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.253178; batch adversarial loss: 0.554926\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441173; batch adversarial loss: 0.560070\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246242; batch adversarial loss: 0.455263\n",
      "epoch 31; iter: 0; batch classifier loss: 0.196232; batch adversarial loss: 0.507232\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134975; batch adversarial loss: 0.601638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130940; batch adversarial loss: 0.497946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.109733; batch adversarial loss: 0.496401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.149758; batch adversarial loss: 0.427850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095579; batch adversarial loss: 0.493923\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113381; batch adversarial loss: 0.433579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.080432; batch adversarial loss: 0.407072\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107519; batch adversarial loss: 0.508812\n",
      "epoch 40; iter: 0; batch classifier loss: 0.055833; batch adversarial loss: 0.452724\n",
      "epoch 41; iter: 0; batch classifier loss: 0.090230; batch adversarial loss: 0.484063\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090142; batch adversarial loss: 0.452201\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090007; batch adversarial loss: 0.460950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074852; batch adversarial loss: 0.397561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107872; batch adversarial loss: 0.456786\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110988; batch adversarial loss: 0.446760\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075584; batch adversarial loss: 0.532971\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100612; batch adversarial loss: 0.451238\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085357; batch adversarial loss: 0.416802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.063300; batch adversarial loss: 0.436355\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076923; batch adversarial loss: 0.530210\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091859; batch adversarial loss: 0.460735\n",
      "epoch 53; iter: 0; batch classifier loss: 0.156292; batch adversarial loss: 0.470309\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069240; batch adversarial loss: 0.365287\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072069; batch adversarial loss: 0.452369\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067421; batch adversarial loss: 0.520527\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109596; batch adversarial loss: 0.487690\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072069; batch adversarial loss: 0.475823\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102750; batch adversarial loss: 0.466140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.103212; batch adversarial loss: 0.382715\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090359; batch adversarial loss: 0.500391\n",
      "epoch 62; iter: 0; batch classifier loss: 0.059521; batch adversarial loss: 0.515719\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054553; batch adversarial loss: 0.472806\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063872; batch adversarial loss: 0.536489\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055297; batch adversarial loss: 0.471669\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045674; batch adversarial loss: 0.485591\n",
      "epoch 67; iter: 0; batch classifier loss: 0.048501; batch adversarial loss: 0.493451\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071026; batch adversarial loss: 0.478009\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050746; batch adversarial loss: 0.510091\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085306; batch adversarial loss: 0.412244\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065903; batch adversarial loss: 0.446528\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062033; batch adversarial loss: 0.494751\n",
      "epoch 73; iter: 0; batch classifier loss: 0.031110; batch adversarial loss: 0.557916\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080296; batch adversarial loss: 0.501740\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083982; batch adversarial loss: 0.537817\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071793; batch adversarial loss: 0.368048\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048246; batch adversarial loss: 0.523964\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082797; batch adversarial loss: 0.522381\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047331; batch adversarial loss: 0.407194\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078473; batch adversarial loss: 0.437107\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069019; batch adversarial loss: 0.512428\n",
      "epoch 82; iter: 0; batch classifier loss: 0.100585; batch adversarial loss: 0.416091\n",
      "epoch 83; iter: 0; batch classifier loss: 0.047159; batch adversarial loss: 0.574299\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072269; batch adversarial loss: 0.454976\n",
      "epoch 85; iter: 0; batch classifier loss: 0.031714; batch adversarial loss: 0.458524\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065710; batch adversarial loss: 0.433888\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041789; batch adversarial loss: 0.509659\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062280; batch adversarial loss: 0.495068\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089082; batch adversarial loss: 0.434172\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047053; batch adversarial loss: 0.473954\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059077; batch adversarial loss: 0.527967\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070728; batch adversarial loss: 0.457997\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055598; batch adversarial loss: 0.388993\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051947; batch adversarial loss: 0.428263\n",
      "epoch 95; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.497839\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045924; batch adversarial loss: 0.483641\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027582; batch adversarial loss: 0.432642\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055456; batch adversarial loss: 0.389989\n",
      "epoch 99; iter: 0; batch classifier loss: 0.019017; batch adversarial loss: 0.477074\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075372; batch adversarial loss: 0.476880\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063320; batch adversarial loss: 0.445265\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032130; batch adversarial loss: 0.446573\n",
      "epoch 103; iter: 0; batch classifier loss: 0.047973; batch adversarial loss: 0.369051\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059513; batch adversarial loss: 0.537977\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061394; batch adversarial loss: 0.471636\n",
      "epoch 106; iter: 0; batch classifier loss: 0.109091; batch adversarial loss: 0.536076\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045162; batch adversarial loss: 0.409862\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034961; batch adversarial loss: 0.478717\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068954; batch adversarial loss: 0.468398\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077761; batch adversarial loss: 0.436974\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041287; batch adversarial loss: 0.461016\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033232; batch adversarial loss: 0.521301\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029741; batch adversarial loss: 0.451597\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069858; batch adversarial loss: 0.448169\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032301; batch adversarial loss: 0.488931\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018785; batch adversarial loss: 0.470967\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050485; batch adversarial loss: 0.458055\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030489; batch adversarial loss: 0.448511\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052089; batch adversarial loss: 0.505138\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051431; batch adversarial loss: 0.427319\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056039; batch adversarial loss: 0.377960\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055845; batch adversarial loss: 0.395779\n",
      "epoch 123; iter: 0; batch classifier loss: 0.022045; batch adversarial loss: 0.472822\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030669; batch adversarial loss: 0.482251\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023711; batch adversarial loss: 0.390708\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.464751\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044435; batch adversarial loss: 0.544908\n",
      "epoch 128; iter: 0; batch classifier loss: 0.084225; batch adversarial loss: 0.500191\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020310; batch adversarial loss: 0.400852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066266; batch adversarial loss: 0.476449\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023889; batch adversarial loss: 0.473723\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057414; batch adversarial loss: 0.397141\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021686; batch adversarial loss: 0.441784\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018286; batch adversarial loss: 0.474522\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048363; batch adversarial loss: 0.458453\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043177; batch adversarial loss: 0.503323\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037558; batch adversarial loss: 0.405887\n",
      "epoch 138; iter: 0; batch classifier loss: 0.058636; batch adversarial loss: 0.317527\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026485; batch adversarial loss: 0.497001\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021673; batch adversarial loss: 0.422763\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037306; batch adversarial loss: 0.366335\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032390; batch adversarial loss: 0.574998\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040251; batch adversarial loss: 0.493817\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018128; batch adversarial loss: 0.606732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048256; batch adversarial loss: 0.440485\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061964; batch adversarial loss: 0.432539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030600; batch adversarial loss: 0.431077\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052124; batch adversarial loss: 0.346710\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044404; batch adversarial loss: 0.384420\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056068; batch adversarial loss: 0.511430\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032500; batch adversarial loss: 0.476434\n",
      "epoch 152; iter: 0; batch classifier loss: 0.109569; batch adversarial loss: 0.409408\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055730; batch adversarial loss: 0.470775\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019924; batch adversarial loss: 0.430594\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042178; batch adversarial loss: 0.450672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.061149; batch adversarial loss: 0.423404\n",
      "epoch 157; iter: 0; batch classifier loss: 0.054890; batch adversarial loss: 0.443347\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032010; batch adversarial loss: 0.473395\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.508304\n",
      "epoch 160; iter: 0; batch classifier loss: 0.059949; batch adversarial loss: 0.506157\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027209; batch adversarial loss: 0.437735\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034535; batch adversarial loss: 0.360265\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051446; batch adversarial loss: 0.483561\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023073; batch adversarial loss: 0.546356\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.458256\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014237; batch adversarial loss: 0.432766\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033735; batch adversarial loss: 0.544113\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025847; batch adversarial loss: 0.479391\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015431; batch adversarial loss: 0.396722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.438734\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048276; batch adversarial loss: 0.504809\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012779; batch adversarial loss: 0.496738\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019192; batch adversarial loss: 0.433673\n",
      "epoch 174; iter: 0; batch classifier loss: 0.057223; batch adversarial loss: 0.410187\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035985; batch adversarial loss: 0.480397\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019096; batch adversarial loss: 0.551488\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020260; batch adversarial loss: 0.493689\n",
      "epoch 178; iter: 0; batch classifier loss: 0.064746; batch adversarial loss: 0.432052\n",
      "epoch 179; iter: 0; batch classifier loss: 0.042247; batch adversarial loss: 0.478208\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006685; batch adversarial loss: 0.388048\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034049; batch adversarial loss: 0.394676\n",
      "epoch 182; iter: 0; batch classifier loss: 0.083984; batch adversarial loss: 0.448196\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046592; batch adversarial loss: 0.460237\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032929; batch adversarial loss: 0.503276\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016596; batch adversarial loss: 0.482756\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024965; batch adversarial loss: 0.460008\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014806; batch adversarial loss: 0.487763\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.463414\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015494; batch adversarial loss: 0.478425\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011719; batch adversarial loss: 0.356448\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078070; batch adversarial loss: 0.340415\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028265; batch adversarial loss: 0.469741\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007010; batch adversarial loss: 0.430615\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025201; batch adversarial loss: 0.439571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045343; batch adversarial loss: 0.512665\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012383; batch adversarial loss: 0.498699\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028286; batch adversarial loss: 0.532461\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006497; batch adversarial loss: 0.470641\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032280; batch adversarial loss: 0.484645\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685294; batch adversarial loss: 0.598174\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498686; batch adversarial loss: 0.605346\n",
      "epoch 2; iter: 0; batch classifier loss: 0.403272; batch adversarial loss: 0.571766\n",
      "epoch 3; iter: 0; batch classifier loss: 0.512544; batch adversarial loss: 0.619937\n",
      "epoch 4; iter: 0; batch classifier loss: 0.373464; batch adversarial loss: 0.578350\n",
      "epoch 5; iter: 0; batch classifier loss: 0.475176; batch adversarial loss: 0.585123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501648; batch adversarial loss: 0.620540\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586813; batch adversarial loss: 0.594882\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645015; batch adversarial loss: 0.560100\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514586; batch adversarial loss: 0.580275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372431; batch adversarial loss: 0.570504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291610; batch adversarial loss: 0.543368\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361993; batch adversarial loss: 0.510713\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382492; batch adversarial loss: 0.512135\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312721; batch adversarial loss: 0.484069\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327052; batch adversarial loss: 0.515861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222311; batch adversarial loss: 0.537759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255344; batch adversarial loss: 0.460920\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246126; batch adversarial loss: 0.451029\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266553; batch adversarial loss: 0.430380\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212967; batch adversarial loss: 0.507946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223238; batch adversarial loss: 0.447757\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162190; batch adversarial loss: 0.487756\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182884; batch adversarial loss: 0.511179\n",
      "epoch 24; iter: 0; batch classifier loss: 0.237224; batch adversarial loss: 0.474963\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155393; batch adversarial loss: 0.440273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223556; batch adversarial loss: 0.509787\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194095; batch adversarial loss: 0.442534\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160959; batch adversarial loss: 0.413908\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160756; batch adversarial loss: 0.445781\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138577; batch adversarial loss: 0.496124\n",
      "epoch 31; iter: 0; batch classifier loss: 0.198604; batch adversarial loss: 0.486380\n",
      "epoch 32; iter: 0; batch classifier loss: 0.229285; batch adversarial loss: 0.420711\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148397; batch adversarial loss: 0.397039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122814; batch adversarial loss: 0.410747\n",
      "epoch 35; iter: 0; batch classifier loss: 0.204301; batch adversarial loss: 0.423191\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112931; batch adversarial loss: 0.551687\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139143; batch adversarial loss: 0.424478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129028; batch adversarial loss: 0.416039\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135658; batch adversarial loss: 0.435391\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158549; batch adversarial loss: 0.405995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.204019; batch adversarial loss: 0.415595\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110770; batch adversarial loss: 0.400935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.148545; batch adversarial loss: 0.536941\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127279; batch adversarial loss: 0.416303\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099322; batch adversarial loss: 0.429280\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164086; batch adversarial loss: 0.482212\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106399; batch adversarial loss: 0.496843\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154768; batch adversarial loss: 0.578353\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106423; batch adversarial loss: 0.415047\n",
      "epoch 50; iter: 0; batch classifier loss: 0.137815; batch adversarial loss: 0.427060\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099244; batch adversarial loss: 0.497267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.130428; batch adversarial loss: 0.521380\n",
      "epoch 53; iter: 0; batch classifier loss: 0.177390; batch adversarial loss: 0.436683\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159097; batch adversarial loss: 0.470362\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117667; batch adversarial loss: 0.430749\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124729; batch adversarial loss: 0.448220\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102211; batch adversarial loss: 0.437777\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104617; batch adversarial loss: 0.492681\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133343; batch adversarial loss: 0.425721\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122854; batch adversarial loss: 0.444561\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078086; batch adversarial loss: 0.533601\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127946; batch adversarial loss: 0.412737\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100137; batch adversarial loss: 0.311088\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127671; batch adversarial loss: 0.463953\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153350; batch adversarial loss: 0.408839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118998; batch adversarial loss: 0.572601\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073817; batch adversarial loss: 0.491145\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087147; batch adversarial loss: 0.361164\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146681; batch adversarial loss: 0.489492\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060782; batch adversarial loss: 0.521004\n",
      "epoch 71; iter: 0; batch classifier loss: 0.128165; batch adversarial loss: 0.421008\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082971; batch adversarial loss: 0.429303\n",
      "epoch 73; iter: 0; batch classifier loss: 0.165670; batch adversarial loss: 0.425155\n",
      "epoch 74; iter: 0; batch classifier loss: 0.135243; batch adversarial loss: 0.394167\n",
      "epoch 75; iter: 0; batch classifier loss: 0.120154; batch adversarial loss: 0.468283\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077163; batch adversarial loss: 0.494687\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106857; batch adversarial loss: 0.368456\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128923; batch adversarial loss: 0.411775\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108440; batch adversarial loss: 0.543255\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066457; batch adversarial loss: 0.459780\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073930; batch adversarial loss: 0.399771\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073382; batch adversarial loss: 0.395841\n",
      "epoch 83; iter: 0; batch classifier loss: 0.095418; batch adversarial loss: 0.454275\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055105; batch adversarial loss: 0.465053\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082480; batch adversarial loss: 0.423944\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105740; batch adversarial loss: 0.469381\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073049; batch adversarial loss: 0.491056\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041552; batch adversarial loss: 0.473468\n",
      "epoch 89; iter: 0; batch classifier loss: 0.103719; batch adversarial loss: 0.438998\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051602; batch adversarial loss: 0.496546\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049188; batch adversarial loss: 0.471476\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055073; batch adversarial loss: 0.388992\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080749; batch adversarial loss: 0.444594\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047006; batch adversarial loss: 0.506673\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042597; batch adversarial loss: 0.464933\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048575; batch adversarial loss: 0.463023\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068629; batch adversarial loss: 0.435990\n",
      "epoch 98; iter: 0; batch classifier loss: 0.103389; batch adversarial loss: 0.473740\n",
      "epoch 99; iter: 0; batch classifier loss: 0.089481; batch adversarial loss: 0.406531\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073634; batch adversarial loss: 0.420705\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031974; batch adversarial loss: 0.362735\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062040; batch adversarial loss: 0.484557\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073485; batch adversarial loss: 0.574984\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087071; batch adversarial loss: 0.412985\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024531; batch adversarial loss: 0.414976\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075798; batch adversarial loss: 0.511579\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047455; batch adversarial loss: 0.404363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051594; batch adversarial loss: 0.465389\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037126; batch adversarial loss: 0.405527\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054812; batch adversarial loss: 0.374540\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063212; batch adversarial loss: 0.457821\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045760; batch adversarial loss: 0.417181\n",
      "epoch 113; iter: 0; batch classifier loss: 0.083444; batch adversarial loss: 0.477791\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057875; batch adversarial loss: 0.391772\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064592; batch adversarial loss: 0.393517\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034159; batch adversarial loss: 0.472161\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049434; batch adversarial loss: 0.565874\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040911; batch adversarial loss: 0.438858\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049116; batch adversarial loss: 0.429491\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043307; batch adversarial loss: 0.483162\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021041; batch adversarial loss: 0.436286\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075898; batch adversarial loss: 0.390499\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027565; batch adversarial loss: 0.451606\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057665; batch adversarial loss: 0.419506\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047684; batch adversarial loss: 0.391196\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046897; batch adversarial loss: 0.350621\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019203; batch adversarial loss: 0.440353\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031014; batch adversarial loss: 0.506652\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043070; batch adversarial loss: 0.433759\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021269; batch adversarial loss: 0.451736\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017669; batch adversarial loss: 0.408053\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024012; batch adversarial loss: 0.379943\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029929; batch adversarial loss: 0.394285\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019613; batch adversarial loss: 0.466500\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021633; batch adversarial loss: 0.459830\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051445; batch adversarial loss: 0.553448\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064906; batch adversarial loss: 0.326406\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019190; batch adversarial loss: 0.402546\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040761; batch adversarial loss: 0.440189\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011655; batch adversarial loss: 0.491324\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019962; batch adversarial loss: 0.449035\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037989; batch adversarial loss: 0.494800\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014050; batch adversarial loss: 0.397837\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020065; batch adversarial loss: 0.494434\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029181; batch adversarial loss: 0.415205\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019051; batch adversarial loss: 0.423817\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038435; batch adversarial loss: 0.334466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.018775; batch adversarial loss: 0.468348\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023216; batch adversarial loss: 0.471302\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049939; batch adversarial loss: 0.446811\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029591; batch adversarial loss: 0.513253\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.421805\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044042; batch adversarial loss: 0.432560\n",
      "epoch 154; iter: 0; batch classifier loss: 0.007967; batch adversarial loss: 0.514776\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017501; batch adversarial loss: 0.441916\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034234; batch adversarial loss: 0.465147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030724; batch adversarial loss: 0.422239\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.457128\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018264; batch adversarial loss: 0.459018\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017465; batch adversarial loss: 0.411465\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023300; batch adversarial loss: 0.446925\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034743; batch adversarial loss: 0.502907\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043672; batch adversarial loss: 0.408357\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022506; batch adversarial loss: 0.395223\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043699; batch adversarial loss: 0.437566\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019665; batch adversarial loss: 0.393415\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030569; batch adversarial loss: 0.516318\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018176; batch adversarial loss: 0.419953\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027302; batch adversarial loss: 0.441378\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016382; batch adversarial loss: 0.494999\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030105; batch adversarial loss: 0.432702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041348; batch adversarial loss: 0.484711\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025261; batch adversarial loss: 0.458602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026608; batch adversarial loss: 0.431619\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006213; batch adversarial loss: 0.437530\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032567; batch adversarial loss: 0.532841\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029169; batch adversarial loss: 0.470754\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032988; batch adversarial loss: 0.405107\n",
      "epoch 179; iter: 0; batch classifier loss: 0.058516; batch adversarial loss: 0.444794\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045141; batch adversarial loss: 0.432794\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007543; batch adversarial loss: 0.491783\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009706; batch adversarial loss: 0.488858\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007683; batch adversarial loss: 0.402115\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013680; batch adversarial loss: 0.489302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013368; batch adversarial loss: 0.427031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025035; batch adversarial loss: 0.446940\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007132; batch adversarial loss: 0.447537\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022945; batch adversarial loss: 0.447629\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041528; batch adversarial loss: 0.465935\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027674; batch adversarial loss: 0.389313\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014808; batch adversarial loss: 0.425619\n",
      "epoch 192; iter: 0; batch classifier loss: 0.058477; batch adversarial loss: 0.439557\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004079; batch adversarial loss: 0.431380\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016896; batch adversarial loss: 0.438497\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026931; batch adversarial loss: 0.497398\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031838; batch adversarial loss: 0.447381\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014991; batch adversarial loss: 0.421508\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025429; batch adversarial loss: 0.428429\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008734; batch adversarial loss: 0.546754\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697185; batch adversarial loss: 0.510021\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429042; batch adversarial loss: 0.558385\n",
      "epoch 2; iter: 0; batch classifier loss: 0.365129; batch adversarial loss: 0.610998\n",
      "epoch 3; iter: 0; batch classifier loss: 0.480101; batch adversarial loss: 0.572875\n",
      "epoch 4; iter: 0; batch classifier loss: 0.346678; batch adversarial loss: 0.610901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355207; batch adversarial loss: 0.652691\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429081; batch adversarial loss: 0.662107\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351567; batch adversarial loss: 0.559689\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418740; batch adversarial loss: 0.580663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265675; batch adversarial loss: 0.624390\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374126; batch adversarial loss: 0.547816\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514267; batch adversarial loss: 0.654641\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522073; batch adversarial loss: 0.470278\n",
      "epoch 13; iter: 0; batch classifier loss: 0.596265; batch adversarial loss: 0.580333\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544262; batch adversarial loss: 0.485401\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371584; batch adversarial loss: 0.533069\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391268; batch adversarial loss: 0.446112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225444; batch adversarial loss: 0.415066\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256047; batch adversarial loss: 0.468119\n",
      "epoch 19; iter: 0; batch classifier loss: 0.245146; batch adversarial loss: 0.430476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188407; batch adversarial loss: 0.503221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.157377; batch adversarial loss: 0.458447\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178627; batch adversarial loss: 0.523899\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177773; batch adversarial loss: 0.409990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197461; batch adversarial loss: 0.480402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162888; batch adversarial loss: 0.428798\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157027; batch adversarial loss: 0.380443\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178814; batch adversarial loss: 0.346106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.120778; batch adversarial loss: 0.475049\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182011; batch adversarial loss: 0.458130\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113233; batch adversarial loss: 0.488400\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131552; batch adversarial loss: 0.472689\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145144; batch adversarial loss: 0.383338\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177868; batch adversarial loss: 0.349918\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186354; batch adversarial loss: 0.363341\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198496; batch adversarial loss: 0.459930\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123500; batch adversarial loss: 0.354421\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166223; batch adversarial loss: 0.425149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.114545; batch adversarial loss: 0.456411\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124815; batch adversarial loss: 0.422703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116150; batch adversarial loss: 0.474893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098261; batch adversarial loss: 0.547610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149917; batch adversarial loss: 0.400937\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108439; batch adversarial loss: 0.350711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.132083; batch adversarial loss: 0.465876\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146053; batch adversarial loss: 0.415621\n",
      "epoch 46; iter: 0; batch classifier loss: 0.115710; batch adversarial loss: 0.422152\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147532; batch adversarial loss: 0.350785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097831; batch adversarial loss: 0.474126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.130215; batch adversarial loss: 0.381064\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118668; batch adversarial loss: 0.458678\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076236; batch adversarial loss: 0.483163\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109102; batch adversarial loss: 0.495464\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106246; batch adversarial loss: 0.381162\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091285; batch adversarial loss: 0.592618\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120676; batch adversarial loss: 0.399940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098606; batch adversarial loss: 0.500571\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135979; batch adversarial loss: 0.538550\n",
      "epoch 58; iter: 0; batch classifier loss: 0.176465; batch adversarial loss: 0.437544\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188191; batch adversarial loss: 0.418640\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092702; batch adversarial loss: 0.610707\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148563; batch adversarial loss: 0.336105\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114897; batch adversarial loss: 0.465779\n",
      "epoch 63; iter: 0; batch classifier loss: 0.113120; batch adversarial loss: 0.437164\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133731; batch adversarial loss: 0.488884\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087102; batch adversarial loss: 0.530156\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097784; batch adversarial loss: 0.367222\n",
      "epoch 67; iter: 0; batch classifier loss: 0.128104; batch adversarial loss: 0.434668\n",
      "epoch 68; iter: 0; batch classifier loss: 0.114698; batch adversarial loss: 0.520287\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114767; batch adversarial loss: 0.440040\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157968; batch adversarial loss: 0.447508\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089982; batch adversarial loss: 0.476110\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109784; batch adversarial loss: 0.438184\n",
      "epoch 73; iter: 0; batch classifier loss: 0.132698; batch adversarial loss: 0.434696\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143045; batch adversarial loss: 0.522740\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111491; batch adversarial loss: 0.434935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114129; batch adversarial loss: 0.540547\n",
      "epoch 77; iter: 0; batch classifier loss: 0.092786; batch adversarial loss: 0.407432\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085266; batch adversarial loss: 0.441485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.398511\n",
      "epoch 80; iter: 0; batch classifier loss: 0.120488; batch adversarial loss: 0.495027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096488; batch adversarial loss: 0.401354\n",
      "epoch 82; iter: 0; batch classifier loss: 0.126661; batch adversarial loss: 0.483867\n",
      "epoch 83; iter: 0; batch classifier loss: 0.098895; batch adversarial loss: 0.367468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103144; batch adversarial loss: 0.398688\n",
      "epoch 85; iter: 0; batch classifier loss: 0.121083; batch adversarial loss: 0.419962\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064992; batch adversarial loss: 0.480003\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051848; batch adversarial loss: 0.451129\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140000; batch adversarial loss: 0.462714\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100514; batch adversarial loss: 0.555604\n",
      "epoch 90; iter: 0; batch classifier loss: 0.084276; batch adversarial loss: 0.468975\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070619; batch adversarial loss: 0.428161\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072296; batch adversarial loss: 0.482731\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084552; batch adversarial loss: 0.418635\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098217; batch adversarial loss: 0.437067\n",
      "epoch 95; iter: 0; batch classifier loss: 0.086167; batch adversarial loss: 0.490764\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112549; batch adversarial loss: 0.466091\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060135; batch adversarial loss: 0.498337\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.509692\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072277; batch adversarial loss: 0.357777\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116333; batch adversarial loss: 0.370721\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046291; batch adversarial loss: 0.432102\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042085; batch adversarial loss: 0.502419\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056915; batch adversarial loss: 0.405418\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052475; batch adversarial loss: 0.363677\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034156; batch adversarial loss: 0.473853\n",
      "epoch 106; iter: 0; batch classifier loss: 0.131106; batch adversarial loss: 0.438857\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054390; batch adversarial loss: 0.427360\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075187; batch adversarial loss: 0.397234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040435; batch adversarial loss: 0.482459\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050448; batch adversarial loss: 0.521061\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049118; batch adversarial loss: 0.579957\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.458247\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054716; batch adversarial loss: 0.399177\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044442; batch adversarial loss: 0.485605\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057974; batch adversarial loss: 0.513188\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068869; batch adversarial loss: 0.449774\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029409; batch adversarial loss: 0.379740\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039781; batch adversarial loss: 0.471835\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.490291\n",
      "epoch 120; iter: 0; batch classifier loss: 0.093049; batch adversarial loss: 0.413784\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071061; batch adversarial loss: 0.496222\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036148; batch adversarial loss: 0.462623\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040320; batch adversarial loss: 0.431430\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.414483\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022054; batch adversarial loss: 0.429417\n",
      "epoch 126; iter: 0; batch classifier loss: 0.010214; batch adversarial loss: 0.423917\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035248; batch adversarial loss: 0.458225\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034538; batch adversarial loss: 0.488290\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066981; batch adversarial loss: 0.547904\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018039; batch adversarial loss: 0.470594\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068387; batch adversarial loss: 0.458612\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048814; batch adversarial loss: 0.482166\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031948; batch adversarial loss: 0.467398\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.543016\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046928; batch adversarial loss: 0.375044\n",
      "epoch 136; iter: 0; batch classifier loss: 0.078583; batch adversarial loss: 0.437584\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015048; batch adversarial loss: 0.401749\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034599; batch adversarial loss: 0.408335\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027676; batch adversarial loss: 0.437547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.024660; batch adversarial loss: 0.370148\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027887; batch adversarial loss: 0.440457\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021428; batch adversarial loss: 0.392539\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019771; batch adversarial loss: 0.473805\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070827; batch adversarial loss: 0.502731\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033108; batch adversarial loss: 0.456949\n",
      "epoch 146; iter: 0; batch classifier loss: 0.066289; batch adversarial loss: 0.446199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040375; batch adversarial loss: 0.469866\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029194; batch adversarial loss: 0.475147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011474; batch adversarial loss: 0.474134\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022481; batch adversarial loss: 0.522103\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027919; batch adversarial loss: 0.433690\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011343; batch adversarial loss: 0.380667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037409; batch adversarial loss: 0.454639\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025642; batch adversarial loss: 0.448867\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035667; batch adversarial loss: 0.449443\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032711; batch adversarial loss: 0.525888\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009668; batch adversarial loss: 0.498135\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015030; batch adversarial loss: 0.464862\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071340; batch adversarial loss: 0.463236\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052984; batch adversarial loss: 0.439566\n",
      "epoch 161; iter: 0; batch classifier loss: 0.083841; batch adversarial loss: 0.448433\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031333; batch adversarial loss: 0.524352\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014687; batch adversarial loss: 0.385563\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040844; batch adversarial loss: 0.383897\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014102; batch adversarial loss: 0.500008\n",
      "epoch 166; iter: 0; batch classifier loss: 0.076017; batch adversarial loss: 0.460731\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028048; batch adversarial loss: 0.467221\n",
      "epoch 168; iter: 0; batch classifier loss: 0.047690; batch adversarial loss: 0.450292\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029983; batch adversarial loss: 0.486001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038110; batch adversarial loss: 0.468591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018523; batch adversarial loss: 0.392854\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017258; batch adversarial loss: 0.428362\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021941; batch adversarial loss: 0.564605\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.451781\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006911; batch adversarial loss: 0.381956\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045552; batch adversarial loss: 0.375725\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016033; batch adversarial loss: 0.437115\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023265; batch adversarial loss: 0.442857\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016449; batch adversarial loss: 0.445605\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014603; batch adversarial loss: 0.464640\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035054; batch adversarial loss: 0.516362\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018639; batch adversarial loss: 0.431558\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022552; batch adversarial loss: 0.368894\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019708; batch adversarial loss: 0.486956\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028302; batch adversarial loss: 0.409970\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022961; batch adversarial loss: 0.471837\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010174; batch adversarial loss: 0.448600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028494; batch adversarial loss: 0.464643\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.429819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050656; batch adversarial loss: 0.531780\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024428; batch adversarial loss: 0.513734\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012957; batch adversarial loss: 0.423638\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036917; batch adversarial loss: 0.406057\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020428; batch adversarial loss: 0.419835\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014403; batch adversarial loss: 0.499269\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.490849\n",
      "epoch 197; iter: 0; batch classifier loss: 0.032445; batch adversarial loss: 0.526190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044581; batch adversarial loss: 0.416092\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010279; batch adversarial loss: 0.391191\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704645; batch adversarial loss: 0.610575\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534445; batch adversarial loss: 0.639172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.532116; batch adversarial loss: 0.615293\n",
      "epoch 3; iter: 0; batch classifier loss: 0.494680; batch adversarial loss: 0.595237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457511; batch adversarial loss: 0.615616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536546; batch adversarial loss: 0.615630\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607030; batch adversarial loss: 0.600258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571305; batch adversarial loss: 0.561818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.408251; batch adversarial loss: 0.575170\n",
      "epoch 9; iter: 0; batch classifier loss: 0.405872; batch adversarial loss: 0.538195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321064; batch adversarial loss: 0.551212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342990; batch adversarial loss: 0.544647\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350284; batch adversarial loss: 0.510763\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396962; batch adversarial loss: 0.496960\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348638; batch adversarial loss: 0.481137\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343507; batch adversarial loss: 0.494392\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410248; batch adversarial loss: 0.446356\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287263; batch adversarial loss: 0.473686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.291136; batch adversarial loss: 0.472906\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270045; batch adversarial loss: 0.467703\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264950; batch adversarial loss: 0.437064\n",
      "epoch 21; iter: 0; batch classifier loss: 0.318945; batch adversarial loss: 0.486202\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258826; batch adversarial loss: 0.472159\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269434; batch adversarial loss: 0.492808\n",
      "epoch 24; iter: 0; batch classifier loss: 0.285261; batch adversarial loss: 0.496317\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252902; batch adversarial loss: 0.411149\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250640; batch adversarial loss: 0.416170\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262630; batch adversarial loss: 0.516947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.317844; batch adversarial loss: 0.458927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219979; batch adversarial loss: 0.493389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202321; batch adversarial loss: 0.422800\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238661; batch adversarial loss: 0.481549\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267048; batch adversarial loss: 0.528359\n",
      "epoch 33; iter: 0; batch classifier loss: 0.280307; batch adversarial loss: 0.392522\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231068; batch adversarial loss: 0.444323\n",
      "epoch 35; iter: 0; batch classifier loss: 0.243312; batch adversarial loss: 0.465581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.267069; batch adversarial loss: 0.495904\n",
      "epoch 37; iter: 0; batch classifier loss: 0.244457; batch adversarial loss: 0.391410\n",
      "epoch 38; iter: 0; batch classifier loss: 0.303894; batch adversarial loss: 0.409976\n",
      "epoch 39; iter: 0; batch classifier loss: 0.196947; batch adversarial loss: 0.441393\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219228; batch adversarial loss: 0.450374\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265980; batch adversarial loss: 0.479365\n",
      "epoch 42; iter: 0; batch classifier loss: 0.282242; batch adversarial loss: 0.423007\n",
      "epoch 43; iter: 0; batch classifier loss: 0.223002; batch adversarial loss: 0.469956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.219050; batch adversarial loss: 0.449610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205318; batch adversarial loss: 0.458784\n",
      "epoch 46; iter: 0; batch classifier loss: 0.240957; batch adversarial loss: 0.436104\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234228; batch adversarial loss: 0.363809\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105446; batch adversarial loss: 0.504859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106245; batch adversarial loss: 0.428260\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080626; batch adversarial loss: 0.435415\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097162; batch adversarial loss: 0.509891\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082463; batch adversarial loss: 0.416601\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127340; batch adversarial loss: 0.410430\n",
      "epoch 54; iter: 0; batch classifier loss: 0.107590; batch adversarial loss: 0.408821\n",
      "epoch 55; iter: 0; batch classifier loss: 0.101786; batch adversarial loss: 0.431398\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109450; batch adversarial loss: 0.474497\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108842; batch adversarial loss: 0.391601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106681; batch adversarial loss: 0.553194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117599; batch adversarial loss: 0.328462\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093014; batch adversarial loss: 0.456429\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107631; batch adversarial loss: 0.474110\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100217; batch adversarial loss: 0.429472\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078034; batch adversarial loss: 0.444130\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073773; batch adversarial loss: 0.344455\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065866; batch adversarial loss: 0.514155\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097126; batch adversarial loss: 0.499070\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106703; batch adversarial loss: 0.460550\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045603; batch adversarial loss: 0.415027\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083751; batch adversarial loss: 0.383508\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083944; batch adversarial loss: 0.461173\n",
      "epoch 71; iter: 0; batch classifier loss: 0.123611; batch adversarial loss: 0.514799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.141179; batch adversarial loss: 0.497759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085064; batch adversarial loss: 0.455076\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081889; batch adversarial loss: 0.471271\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076702; batch adversarial loss: 0.436805\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081905; batch adversarial loss: 0.437258\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084124; batch adversarial loss: 0.439334\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066308; batch adversarial loss: 0.483883\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053924; batch adversarial loss: 0.503140\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072920; batch adversarial loss: 0.407310\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038150; batch adversarial loss: 0.448795\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079635; batch adversarial loss: 0.482451\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045737; batch adversarial loss: 0.392159\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070372; batch adversarial loss: 0.406762\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079364; batch adversarial loss: 0.462580\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074322; batch adversarial loss: 0.389020\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045732; batch adversarial loss: 0.419222\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041779; batch adversarial loss: 0.411893\n",
      "epoch 89; iter: 0; batch classifier loss: 0.089828; batch adversarial loss: 0.473983\n",
      "epoch 90; iter: 0; batch classifier loss: 0.029226; batch adversarial loss: 0.406787\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043821; batch adversarial loss: 0.523786\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068768; batch adversarial loss: 0.399532\n",
      "epoch 93; iter: 0; batch classifier loss: 0.088868; batch adversarial loss: 0.475001\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067102; batch adversarial loss: 0.497360\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071858; batch adversarial loss: 0.390700\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083092; batch adversarial loss: 0.475744\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062123; batch adversarial loss: 0.328441\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070213; batch adversarial loss: 0.393420\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062883; batch adversarial loss: 0.420932\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088443; batch adversarial loss: 0.499497\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088753; batch adversarial loss: 0.309968\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057562; batch adversarial loss: 0.354190\n",
      "epoch 103; iter: 0; batch classifier loss: 0.104620; batch adversarial loss: 0.394375\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048611; batch adversarial loss: 0.331884\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049430; batch adversarial loss: 0.349350\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047833; batch adversarial loss: 0.349696\n",
      "epoch 107; iter: 0; batch classifier loss: 0.090574; batch adversarial loss: 0.398287\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041015; batch adversarial loss: 0.424229\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079309; batch adversarial loss: 0.387313\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035008; batch adversarial loss: 0.455484\n",
      "epoch 111; iter: 0; batch classifier loss: 0.106648; batch adversarial loss: 0.313389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.097674; batch adversarial loss: 0.397278\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048897; batch adversarial loss: 0.334028\n",
      "epoch 114; iter: 0; batch classifier loss: 0.090135; batch adversarial loss: 0.319907\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050076; batch adversarial loss: 0.409538\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053788; batch adversarial loss: 0.503364\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032575; batch adversarial loss: 0.397394\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051326; batch adversarial loss: 0.383421\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042753; batch adversarial loss: 0.474552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062940; batch adversarial loss: 0.403493\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033090; batch adversarial loss: 0.411993\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081272; batch adversarial loss: 0.450750\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045397; batch adversarial loss: 0.370550\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072115; batch adversarial loss: 0.382369\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068290; batch adversarial loss: 0.461296\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034070; batch adversarial loss: 0.371321\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052667; batch adversarial loss: 0.281966\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067515; batch adversarial loss: 0.432897\n",
      "epoch 129; iter: 0; batch classifier loss: 0.070347; batch adversarial loss: 0.383280\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041082; batch adversarial loss: 0.457116\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051759; batch adversarial loss: 0.430294\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043330; batch adversarial loss: 0.423686\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023667; batch adversarial loss: 0.333512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.049065; batch adversarial loss: 0.414772\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044872; batch adversarial loss: 0.398736\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068495; batch adversarial loss: 0.448844\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046477; batch adversarial loss: 0.444770\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042527; batch adversarial loss: 0.395217\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048392; batch adversarial loss: 0.357798\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032635; batch adversarial loss: 0.424758\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041223; batch adversarial loss: 0.414392\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.419778\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041176; batch adversarial loss: 0.433980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029946; batch adversarial loss: 0.460381\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019269; batch adversarial loss: 0.403233\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031440; batch adversarial loss: 0.357375\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024924; batch adversarial loss: 0.439441\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022383; batch adversarial loss: 0.411637\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047425; batch adversarial loss: 0.403988\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032255; batch adversarial loss: 0.504267\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027555; batch adversarial loss: 0.393124\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017617; batch adversarial loss: 0.450717\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021153; batch adversarial loss: 0.389097\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020323; batch adversarial loss: 0.405128\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023811; batch adversarial loss: 0.371101\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022289; batch adversarial loss: 0.443591\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025586; batch adversarial loss: 0.457750\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022134; batch adversarial loss: 0.359014\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016850; batch adversarial loss: 0.434224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019994; batch adversarial loss: 0.439650\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.432186\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024523; batch adversarial loss: 0.475599\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011117; batch adversarial loss: 0.481768\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016654; batch adversarial loss: 0.457427\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006634; batch adversarial loss: 0.509560\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026965; batch adversarial loss: 0.445548\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017699; batch adversarial loss: 0.543389\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028854; batch adversarial loss: 0.431916\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017525; batch adversarial loss: 0.490135\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015348; batch adversarial loss: 0.419966\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015103; batch adversarial loss: 0.445200\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025269; batch adversarial loss: 0.442515\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015918; batch adversarial loss: 0.522582\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007993; batch adversarial loss: 0.487915\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024361; batch adversarial loss: 0.388737\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.513417\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016316; batch adversarial loss: 0.404415\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.559250\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011923; batch adversarial loss: 0.478641\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009512; batch adversarial loss: 0.447271\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033092; batch adversarial loss: 0.404807\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030093; batch adversarial loss: 0.369778\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015942; batch adversarial loss: 0.451884\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011631; batch adversarial loss: 0.446774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030945; batch adversarial loss: 0.444983\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006770; batch adversarial loss: 0.433277\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020607; batch adversarial loss: 0.468551\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017644; batch adversarial loss: 0.448512\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005804; batch adversarial loss: 0.379841\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023507; batch adversarial loss: 0.480461\n",
      "epoch 191; iter: 0; batch classifier loss: 0.050266; batch adversarial loss: 0.498927\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031686; batch adversarial loss: 0.513803\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038761; batch adversarial loss: 0.403598\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042872; batch adversarial loss: 0.468275\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015271; batch adversarial loss: 0.536479\n",
      "epoch 196; iter: 0; batch classifier loss: 0.075578; batch adversarial loss: 0.650473\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018302; batch adversarial loss: 0.425646\n",
      "epoch 198; iter: 0; batch classifier loss: 0.082811; batch adversarial loss: 0.673722\n",
      "epoch 199; iter: 0; batch classifier loss: 0.054616; batch adversarial loss: 0.553380\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692638; batch adversarial loss: 0.634310\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447622; batch adversarial loss: 0.624799\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419948; batch adversarial loss: 0.605814\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379081; batch adversarial loss: 0.537600\n",
      "epoch 4; iter: 0; batch classifier loss: 0.323775; batch adversarial loss: 0.542710\n",
      "epoch 5; iter: 0; batch classifier loss: 0.267999; batch adversarial loss: 0.507440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.297305; batch adversarial loss: 0.513283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277605; batch adversarial loss: 0.487666\n",
      "epoch 8; iter: 0; batch classifier loss: 0.350810; batch adversarial loss: 0.483550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.181363; batch adversarial loss: 0.506380\n",
      "epoch 10; iter: 0; batch classifier loss: 0.230165; batch adversarial loss: 0.498891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219031; batch adversarial loss: 0.422592\n",
      "epoch 12; iter: 0; batch classifier loss: 0.200164; batch adversarial loss: 0.433888\n",
      "epoch 13; iter: 0; batch classifier loss: 0.180365; batch adversarial loss: 0.511715\n",
      "epoch 14; iter: 0; batch classifier loss: 0.183413; batch adversarial loss: 0.474904\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248320; batch adversarial loss: 0.495812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.148675; batch adversarial loss: 0.494674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268956; batch adversarial loss: 0.480801\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216247; batch adversarial loss: 0.492171\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175162; batch adversarial loss: 0.435211\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247675; batch adversarial loss: 0.488518\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174267; batch adversarial loss: 0.542142\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213615; batch adversarial loss: 0.559763\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178530; batch adversarial loss: 0.444825\n",
      "epoch 24; iter: 0; batch classifier loss: 0.180486; batch adversarial loss: 0.489205\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191033; batch adversarial loss: 0.423438\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223760; batch adversarial loss: 0.521028\n",
      "epoch 27; iter: 0; batch classifier loss: 0.223786; batch adversarial loss: 0.460579\n",
      "epoch 28; iter: 0; batch classifier loss: 0.219325; batch adversarial loss: 0.452213\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303293; batch adversarial loss: 0.396364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.302052; batch adversarial loss: 0.425635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193628; batch adversarial loss: 0.372004\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115979; batch adversarial loss: 0.417876\n",
      "epoch 33; iter: 0; batch classifier loss: 0.124953; batch adversarial loss: 0.412240\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142573; batch adversarial loss: 0.406741\n",
      "epoch 35; iter: 0; batch classifier loss: 0.131894; batch adversarial loss: 0.541348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109181; batch adversarial loss: 0.489878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145141; batch adversarial loss: 0.451250\n",
      "epoch 38; iter: 0; batch classifier loss: 0.102392; batch adversarial loss: 0.456846\n",
      "epoch 39; iter: 0; batch classifier loss: 0.065840; batch adversarial loss: 0.443028\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147794; batch adversarial loss: 0.449950\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080804; batch adversarial loss: 0.366290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111152; batch adversarial loss: 0.336536\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116401; batch adversarial loss: 0.396172\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097119; batch adversarial loss: 0.381195\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090710; batch adversarial loss: 0.444292\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112693; batch adversarial loss: 0.438053\n",
      "epoch 47; iter: 0; batch classifier loss: 0.049236; batch adversarial loss: 0.494906\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097314; batch adversarial loss: 0.433282\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070631; batch adversarial loss: 0.388055\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076344; batch adversarial loss: 0.424516\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100062; batch adversarial loss: 0.490279\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091066; batch adversarial loss: 0.406210\n",
      "epoch 53; iter: 0; batch classifier loss: 0.038534; batch adversarial loss: 0.392997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156031; batch adversarial loss: 0.382689\n",
      "epoch 55; iter: 0; batch classifier loss: 0.050838; batch adversarial loss: 0.440788\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071010; batch adversarial loss: 0.459869\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118585; batch adversarial loss: 0.342206\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065769; batch adversarial loss: 0.421272\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109446; batch adversarial loss: 0.381716\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111559; batch adversarial loss: 0.489850\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086723; batch adversarial loss: 0.394202\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096059; batch adversarial loss: 0.443106\n",
      "epoch 63; iter: 0; batch classifier loss: 0.130765; batch adversarial loss: 0.384395\n",
      "epoch 64; iter: 0; batch classifier loss: 0.128894; batch adversarial loss: 0.328077\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095440; batch adversarial loss: 0.415817\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060659; batch adversarial loss: 0.384705\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094987; batch adversarial loss: 0.456108\n",
      "epoch 68; iter: 0; batch classifier loss: 0.033725; batch adversarial loss: 0.423748\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087195; batch adversarial loss: 0.416978\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135159; batch adversarial loss: 0.426283\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069724; batch adversarial loss: 0.346465\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069610; batch adversarial loss: 0.438593\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057691; batch adversarial loss: 0.477244\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050868; batch adversarial loss: 0.427477\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051363; batch adversarial loss: 0.536362\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043681; batch adversarial loss: 0.428938\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114570; batch adversarial loss: 0.371234\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071807; batch adversarial loss: 0.348237\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099979; batch adversarial loss: 0.439989\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060137; batch adversarial loss: 0.506248\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067295; batch adversarial loss: 0.442420\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090270; batch adversarial loss: 0.378164\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061384; batch adversarial loss: 0.343840\n",
      "epoch 84; iter: 0; batch classifier loss: 0.057063; batch adversarial loss: 0.393105\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063195; batch adversarial loss: 0.447227\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035124; batch adversarial loss: 0.446909\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062935; batch adversarial loss: 0.338264\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063838; batch adversarial loss: 0.442511\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065836; batch adversarial loss: 0.392362\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090936; batch adversarial loss: 0.402356\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.472788\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051210; batch adversarial loss: 0.523508\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055650; batch adversarial loss: 0.371163\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094172; batch adversarial loss: 0.416776\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042582; batch adversarial loss: 0.479200\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044188; batch adversarial loss: 0.318277\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057058; batch adversarial loss: 0.432890\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061442; batch adversarial loss: 0.353224\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071834; batch adversarial loss: 0.393129\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022250; batch adversarial loss: 0.429567\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038187; batch adversarial loss: 0.466912\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032830; batch adversarial loss: 0.397497\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048424; batch adversarial loss: 0.453224\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061661; batch adversarial loss: 0.424471\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052971; batch adversarial loss: 0.414693\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024915; batch adversarial loss: 0.490365\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038066; batch adversarial loss: 0.474204\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029802; batch adversarial loss: 0.411896\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047790; batch adversarial loss: 0.407124\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.500759\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052057; batch adversarial loss: 0.391394\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026483; batch adversarial loss: 0.504097\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037097; batch adversarial loss: 0.426890\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039783; batch adversarial loss: 0.458970\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070126; batch adversarial loss: 0.394543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040655; batch adversarial loss: 0.422658\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034467; batch adversarial loss: 0.481462\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069240; batch adversarial loss: 0.464479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034237; batch adversarial loss: 0.386855\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054408; batch adversarial loss: 0.471793\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012071; batch adversarial loss: 0.382181\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024877; batch adversarial loss: 0.358998\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020195; batch adversarial loss: 0.450371\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041374; batch adversarial loss: 0.454524\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014101; batch adversarial loss: 0.394342\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025985; batch adversarial loss: 0.462208\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043928; batch adversarial loss: 0.474208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.043951; batch adversarial loss: 0.372985\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051772; batch adversarial loss: 0.426481\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021416; batch adversarial loss: 0.364245\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042281; batch adversarial loss: 0.461688\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.436873\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036493; batch adversarial loss: 0.463622\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023396; batch adversarial loss: 0.445249\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.465364\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020408; batch adversarial loss: 0.485335\n",
      "epoch 137; iter: 0; batch classifier loss: 0.069966; batch adversarial loss: 0.439708\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057966; batch adversarial loss: 0.389964\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021258; batch adversarial loss: 0.397772\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017513; batch adversarial loss: 0.492677\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015003; batch adversarial loss: 0.450181\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036478; batch adversarial loss: 0.466805\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027534; batch adversarial loss: 0.425623\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027401; batch adversarial loss: 0.426272\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061306; batch adversarial loss: 0.421088\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016624; batch adversarial loss: 0.484136\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011565; batch adversarial loss: 0.494782\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014734; batch adversarial loss: 0.560340\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012314; batch adversarial loss: 0.519133\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026082; batch adversarial loss: 0.497477\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028166; batch adversarial loss: 0.446341\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010029; batch adversarial loss: 0.399762\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015999; batch adversarial loss: 0.525528\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041791; batch adversarial loss: 0.478317\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027271; batch adversarial loss: 0.454389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008996; batch adversarial loss: 0.446755\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.380041\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049748; batch adversarial loss: 0.442820\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017070; batch adversarial loss: 0.392955\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060925; batch adversarial loss: 0.566001\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026911; batch adversarial loss: 0.509700\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033246; batch adversarial loss: 0.518194\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010664; batch adversarial loss: 0.542536\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015128; batch adversarial loss: 0.448623\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038005; batch adversarial loss: 0.394130\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028219; batch adversarial loss: 0.379399\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018755; batch adversarial loss: 0.493461\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022610; batch adversarial loss: 0.505334\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028333; batch adversarial loss: 0.447551\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034540; batch adversarial loss: 0.390117\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030192; batch adversarial loss: 0.405292\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045242; batch adversarial loss: 0.478833\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025143; batch adversarial loss: 0.439612\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066413; batch adversarial loss: 0.400048\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009540; batch adversarial loss: 0.456065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007746; batch adversarial loss: 0.383532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040473; batch adversarial loss: 0.511488\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019326; batch adversarial loss: 0.429975\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011350; batch adversarial loss: 0.436001\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006367; batch adversarial loss: 0.460301\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008811; batch adversarial loss: 0.524682\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019725; batch adversarial loss: 0.367475\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015343; batch adversarial loss: 0.468945\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016488; batch adversarial loss: 0.512522\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019967; batch adversarial loss: 0.365845\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007121; batch adversarial loss: 0.512442\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040608; batch adversarial loss: 0.447904\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012857; batch adversarial loss: 0.392710\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027038; batch adversarial loss: 0.532024\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.411538\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023610; batch adversarial loss: 0.458702\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025075; batch adversarial loss: 0.451341\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031296; batch adversarial loss: 0.369873\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038543; batch adversarial loss: 0.373454\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013134; batch adversarial loss: 0.499440\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014656; batch adversarial loss: 0.451859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016415; batch adversarial loss: 0.502224\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022783; batch adversarial loss: 0.431042\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015198; batch adversarial loss: 0.451705\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675084; batch adversarial loss: 0.665034\n",
      "epoch 1; iter: 0; batch classifier loss: 0.538660; batch adversarial loss: 0.638636\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433145; batch adversarial loss: 0.616953\n",
      "epoch 3; iter: 0; batch classifier loss: 0.476061; batch adversarial loss: 0.609889\n",
      "epoch 4; iter: 0; batch classifier loss: 0.497466; batch adversarial loss: 0.602177\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532519; batch adversarial loss: 0.558387\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403873; batch adversarial loss: 0.609504\n",
      "epoch 7; iter: 0; batch classifier loss: 0.448771; batch adversarial loss: 0.554199\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431108; batch adversarial loss: 0.545999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461318; batch adversarial loss: 0.543686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401937; batch adversarial loss: 0.500224\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359518; batch adversarial loss: 0.556877\n",
      "epoch 12; iter: 0; batch classifier loss: 0.380479; batch adversarial loss: 0.490550\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355652; batch adversarial loss: 0.558913\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282838; batch adversarial loss: 0.528463\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386682; batch adversarial loss: 0.507614\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348585; batch adversarial loss: 0.451896\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283781; batch adversarial loss: 0.510802\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295519; batch adversarial loss: 0.454485\n",
      "epoch 19; iter: 0; batch classifier loss: 0.288142; batch adversarial loss: 0.489082\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251902; batch adversarial loss: 0.440400\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269011; batch adversarial loss: 0.431555\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269242; batch adversarial loss: 0.497163\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248136; batch adversarial loss: 0.551931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.236069; batch adversarial loss: 0.447167\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253650; batch adversarial loss: 0.437239\n",
      "epoch 26; iter: 0; batch classifier loss: 0.254894; batch adversarial loss: 0.420062\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221673; batch adversarial loss: 0.506876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285589; batch adversarial loss: 0.447009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.229229; batch adversarial loss: 0.534819\n",
      "epoch 30; iter: 0; batch classifier loss: 0.273893; batch adversarial loss: 0.366992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.248021; batch adversarial loss: 0.457037\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237445; batch adversarial loss: 0.479668\n",
      "epoch 33; iter: 0; batch classifier loss: 0.341440; batch adversarial loss: 0.484888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.243979; batch adversarial loss: 0.424203\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231690; batch adversarial loss: 0.455968\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194634; batch adversarial loss: 0.507677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.268818; batch adversarial loss: 0.452696\n",
      "epoch 38; iter: 0; batch classifier loss: 0.299082; batch adversarial loss: 0.464544\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157047; batch adversarial loss: 0.523547\n",
      "epoch 40; iter: 0; batch classifier loss: 0.197426; batch adversarial loss: 0.421369\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129990; batch adversarial loss: 0.532455\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172503; batch adversarial loss: 0.407467\n",
      "epoch 43; iter: 0; batch classifier loss: 0.216229; batch adversarial loss: 0.462116\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245056; batch adversarial loss: 0.384427\n",
      "epoch 45; iter: 0; batch classifier loss: 0.193351; batch adversarial loss: 0.457948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.225535; batch adversarial loss: 0.389307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240252; batch adversarial loss: 0.467332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214320; batch adversarial loss: 0.477617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.304945; batch adversarial loss: 0.376368\n",
      "epoch 50; iter: 0; batch classifier loss: 0.217044; batch adversarial loss: 0.410631\n",
      "epoch 51; iter: 0; batch classifier loss: 0.222145; batch adversarial loss: 0.497203\n",
      "epoch 52; iter: 0; batch classifier loss: 0.204032; batch adversarial loss: 0.484012\n",
      "epoch 53; iter: 0; batch classifier loss: 0.183546; batch adversarial loss: 0.528861\n",
      "epoch 54; iter: 0; batch classifier loss: 0.263730; batch adversarial loss: 0.411271\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199138; batch adversarial loss: 0.480133\n",
      "epoch 56; iter: 0; batch classifier loss: 0.162609; batch adversarial loss: 0.508173\n",
      "epoch 57; iter: 0; batch classifier loss: 0.248489; batch adversarial loss: 0.447612\n",
      "epoch 58; iter: 0; batch classifier loss: 0.207781; batch adversarial loss: 0.483078\n",
      "epoch 59; iter: 0; batch classifier loss: 0.229370; batch adversarial loss: 0.445551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.198743; batch adversarial loss: 0.568665\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102058; batch adversarial loss: 0.506756\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081506; batch adversarial loss: 0.407152\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075459; batch adversarial loss: 0.451268\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105043; batch adversarial loss: 0.507539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080627; batch adversarial loss: 0.428428\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056469; batch adversarial loss: 0.521122\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087668; batch adversarial loss: 0.432756\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144124; batch adversarial loss: 0.468888\n",
      "epoch 69; iter: 0; batch classifier loss: 0.150249; batch adversarial loss: 0.503426\n",
      "epoch 70; iter: 0; batch classifier loss: 0.119571; batch adversarial loss: 0.497566\n",
      "epoch 71; iter: 0; batch classifier loss: 0.153867; batch adversarial loss: 0.405524\n",
      "epoch 72; iter: 0; batch classifier loss: 0.132417; batch adversarial loss: 0.473792\n",
      "epoch 73; iter: 0; batch classifier loss: 0.112210; batch adversarial loss: 0.450168\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085479; batch adversarial loss: 0.437693\n",
      "epoch 75; iter: 0; batch classifier loss: 0.102343; batch adversarial loss: 0.433918\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133302; batch adversarial loss: 0.489006\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126483; batch adversarial loss: 0.432526\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055748; batch adversarial loss: 0.375121\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067014; batch adversarial loss: 0.519684\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084180; batch adversarial loss: 0.447460\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099667; batch adversarial loss: 0.409607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067408; batch adversarial loss: 0.492516\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078479; batch adversarial loss: 0.425927\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059308; batch adversarial loss: 0.443690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055305; batch adversarial loss: 0.483757\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043816; batch adversarial loss: 0.371301\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053302; batch adversarial loss: 0.438373\n",
      "epoch 88; iter: 0; batch classifier loss: 0.083158; batch adversarial loss: 0.377333\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057090; batch adversarial loss: 0.476564\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052727; batch adversarial loss: 0.454585\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066927; batch adversarial loss: 0.454255\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074776; batch adversarial loss: 0.507655\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044737; batch adversarial loss: 0.473385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047707; batch adversarial loss: 0.461775\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080936; batch adversarial loss: 0.420643\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038841; batch adversarial loss: 0.513772\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046839; batch adversarial loss: 0.469223\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055070; batch adversarial loss: 0.478348\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035307; batch adversarial loss: 0.538828\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047823; batch adversarial loss: 0.430202\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048091; batch adversarial loss: 0.418975\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026660; batch adversarial loss: 0.494082\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027856; batch adversarial loss: 0.434523\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050190; batch adversarial loss: 0.386579\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029557; batch adversarial loss: 0.533498\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028735; batch adversarial loss: 0.398111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060352; batch adversarial loss: 0.370683\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018063; batch adversarial loss: 0.455160\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036561; batch adversarial loss: 0.434521\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063733; batch adversarial loss: 0.348070\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035947; batch adversarial loss: 0.545475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063563; batch adversarial loss: 0.446670\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049108; batch adversarial loss: 0.460957\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.481789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036017; batch adversarial loss: 0.449220\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023642; batch adversarial loss: 0.364530\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032888; batch adversarial loss: 0.400453\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022692; batch adversarial loss: 0.431906\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034300; batch adversarial loss: 0.493883\n",
      "epoch 120; iter: 0; batch classifier loss: 0.016010; batch adversarial loss: 0.465728\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026110; batch adversarial loss: 0.454797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.015069; batch adversarial loss: 0.427994\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037292; batch adversarial loss: 0.446467\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.532801\n",
      "epoch 125; iter: 0; batch classifier loss: 0.013516; batch adversarial loss: 0.458952\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029857; batch adversarial loss: 0.468091\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.400354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044088; batch adversarial loss: 0.392429\n",
      "epoch 129; iter: 0; batch classifier loss: 0.007436; batch adversarial loss: 0.465142\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016227; batch adversarial loss: 0.491022\n",
      "epoch 131; iter: 0; batch classifier loss: 0.010418; batch adversarial loss: 0.487044\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042690; batch adversarial loss: 0.367705\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034240; batch adversarial loss: 0.447133\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012685; batch adversarial loss: 0.408069\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025347; batch adversarial loss: 0.391157\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025627; batch adversarial loss: 0.363811\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028001; batch adversarial loss: 0.483303\n",
      "epoch 138; iter: 0; batch classifier loss: 0.008680; batch adversarial loss: 0.532711\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019323; batch adversarial loss: 0.510057\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019520; batch adversarial loss: 0.361476\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011550; batch adversarial loss: 0.505588\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012602; batch adversarial loss: 0.402724\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018620; batch adversarial loss: 0.482578\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019001; batch adversarial loss: 0.502397\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014190; batch adversarial loss: 0.421224\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014109; batch adversarial loss: 0.438018\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011599; batch adversarial loss: 0.437922\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021956; batch adversarial loss: 0.507618\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028866; batch adversarial loss: 0.389856\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025994; batch adversarial loss: 0.493655\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025825; batch adversarial loss: 0.510945\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036589; batch adversarial loss: 0.396173\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.450654\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034788; batch adversarial loss: 0.440075\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011020; batch adversarial loss: 0.402768\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015635; batch adversarial loss: 0.459858\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036270; batch adversarial loss: 0.499403\n",
      "epoch 158; iter: 0; batch classifier loss: 0.004273; batch adversarial loss: 0.413225\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011972; batch adversarial loss: 0.420042\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010116; batch adversarial loss: 0.534725\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010975; batch adversarial loss: 0.460105\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019727; batch adversarial loss: 0.445578\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011292; batch adversarial loss: 0.406740\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019333; batch adversarial loss: 0.394276\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012811; batch adversarial loss: 0.507556\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016844; batch adversarial loss: 0.358720\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023853; batch adversarial loss: 0.525023\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032898; batch adversarial loss: 0.412284\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028032; batch adversarial loss: 0.480406\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010478; batch adversarial loss: 0.538599\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012817; batch adversarial loss: 0.343584\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016940; batch adversarial loss: 0.442240\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006633; batch adversarial loss: 0.433113\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042364; batch adversarial loss: 0.394228\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016795; batch adversarial loss: 0.424895\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010104; batch adversarial loss: 0.396367\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015996; batch adversarial loss: 0.548411\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020212; batch adversarial loss: 0.447221\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004836; batch adversarial loss: 0.498816\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028722; batch adversarial loss: 0.565320\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019477; batch adversarial loss: 0.450479\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012450; batch adversarial loss: 0.393306\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014734; batch adversarial loss: 0.493699\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015713; batch adversarial loss: 0.419532\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022928; batch adversarial loss: 0.450235\n",
      "epoch 186; iter: 0; batch classifier loss: 0.048567; batch adversarial loss: 0.545158\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019871; batch adversarial loss: 0.370227\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011806; batch adversarial loss: 0.450356\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015493; batch adversarial loss: 0.522518\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016396; batch adversarial loss: 0.516582\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023190; batch adversarial loss: 0.412777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004236; batch adversarial loss: 0.393580\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005876; batch adversarial loss: 0.389105\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008068; batch adversarial loss: 0.432796\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010093; batch adversarial loss: 0.421040\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008171; batch adversarial loss: 0.387270\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007648; batch adversarial loss: 0.489592\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019708; batch adversarial loss: 0.410658\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009227; batch adversarial loss: 0.450190\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711660; batch adversarial loss: 0.612243\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422583; batch adversarial loss: 0.612316\n",
      "epoch 2; iter: 0; batch classifier loss: 0.322303; batch adversarial loss: 0.598079\n",
      "epoch 3; iter: 0; batch classifier loss: 0.478428; batch adversarial loss: 0.595470\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347689; batch adversarial loss: 0.606996\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337351; batch adversarial loss: 0.614842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.426742; batch adversarial loss: 0.513427\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507719; batch adversarial loss: 0.585097\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625003; batch adversarial loss: 0.568001\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634568; batch adversarial loss: 0.579226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517359; batch adversarial loss: 0.547284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366874; batch adversarial loss: 0.585942\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476377; batch adversarial loss: 0.473812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.305283; batch adversarial loss: 0.497447\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307805; batch adversarial loss: 0.462989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294419; batch adversarial loss: 0.489671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282242; batch adversarial loss: 0.482237\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302256; batch adversarial loss: 0.538611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.292265; batch adversarial loss: 0.490603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205689; batch adversarial loss: 0.495030\n",
      "epoch 20; iter: 0; batch classifier loss: 0.246513; batch adversarial loss: 0.476169\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225647; batch adversarial loss: 0.409978\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243511; batch adversarial loss: 0.433608\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218551; batch adversarial loss: 0.449731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223915; batch adversarial loss: 0.584140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.203684; batch adversarial loss: 0.497865\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256754; batch adversarial loss: 0.475152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224571; batch adversarial loss: 0.490584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225911; batch adversarial loss: 0.459080\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176681; batch adversarial loss: 0.431724\n",
      "epoch 30; iter: 0; batch classifier loss: 0.267658; batch adversarial loss: 0.544272\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193379; batch adversarial loss: 0.481324\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187565; batch adversarial loss: 0.419316\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187701; batch adversarial loss: 0.502129\n",
      "epoch 34; iter: 0; batch classifier loss: 0.181864; batch adversarial loss: 0.465095\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173232; batch adversarial loss: 0.428725\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220845; batch adversarial loss: 0.430420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147920; batch adversarial loss: 0.504763\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165272; batch adversarial loss: 0.499600\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172637; batch adversarial loss: 0.432541\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133586; batch adversarial loss: 0.520027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225041; batch adversarial loss: 0.362780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.263487; batch adversarial loss: 0.478949\n",
      "epoch 43; iter: 0; batch classifier loss: 0.256139; batch adversarial loss: 0.404549\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247347; batch adversarial loss: 0.482741\n",
      "epoch 45; iter: 0; batch classifier loss: 0.127597; batch adversarial loss: 0.534560\n",
      "epoch 46; iter: 0; batch classifier loss: 0.236570; batch adversarial loss: 0.437915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206374; batch adversarial loss: 0.492298\n",
      "epoch 48; iter: 0; batch classifier loss: 0.197567; batch adversarial loss: 0.473817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.213056; batch adversarial loss: 0.505056\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177450; batch adversarial loss: 0.494246\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218104; batch adversarial loss: 0.506632\n",
      "epoch 52; iter: 0; batch classifier loss: 0.215118; batch adversarial loss: 0.485421\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176120; batch adversarial loss: 0.460383\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205963; batch adversarial loss: 0.448929\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189558; batch adversarial loss: 0.614949\n",
      "epoch 56; iter: 0; batch classifier loss: 0.223877; batch adversarial loss: 0.413002\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193038; batch adversarial loss: 0.517492\n",
      "epoch 58; iter: 0; batch classifier loss: 0.298654; batch adversarial loss: 0.435565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200016; batch adversarial loss: 0.471691\n",
      "epoch 60; iter: 0; batch classifier loss: 0.260667; batch adversarial loss: 0.349902\n",
      "epoch 61; iter: 0; batch classifier loss: 0.291373; batch adversarial loss: 0.579492\n",
      "epoch 62; iter: 0; batch classifier loss: 0.116579; batch adversarial loss: 0.470463\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059809; batch adversarial loss: 0.489868\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101037; batch adversarial loss: 0.356367\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064787; batch adversarial loss: 0.473106\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111279; batch adversarial loss: 0.486298\n",
      "epoch 67; iter: 0; batch classifier loss: 0.139268; batch adversarial loss: 0.382989\n",
      "epoch 68; iter: 0; batch classifier loss: 0.171601; batch adversarial loss: 0.477711\n",
      "epoch 69; iter: 0; batch classifier loss: 0.155749; batch adversarial loss: 0.432028\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151682; batch adversarial loss: 0.528445\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178903; batch adversarial loss: 0.469000\n",
      "epoch 72; iter: 0; batch classifier loss: 0.130050; batch adversarial loss: 0.504454\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155463; batch adversarial loss: 0.403247\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171205; batch adversarial loss: 0.470685\n",
      "epoch 75; iter: 0; batch classifier loss: 0.186473; batch adversarial loss: 0.444970\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103774; batch adversarial loss: 0.475453\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136026; batch adversarial loss: 0.391317\n",
      "epoch 78; iter: 0; batch classifier loss: 0.169926; batch adversarial loss: 0.462073\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094522; batch adversarial loss: 0.434322\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138919; batch adversarial loss: 0.464887\n",
      "epoch 81; iter: 0; batch classifier loss: 0.124179; batch adversarial loss: 0.475700\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102605; batch adversarial loss: 0.521847\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081356; batch adversarial loss: 0.466812\n",
      "epoch 84; iter: 0; batch classifier loss: 0.101801; batch adversarial loss: 0.323639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.123258; batch adversarial loss: 0.455457\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083074; batch adversarial loss: 0.526609\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075794; batch adversarial loss: 0.575138\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102670; batch adversarial loss: 0.501901\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135785; batch adversarial loss: 0.468788\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066070; batch adversarial loss: 0.390318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051253; batch adversarial loss: 0.447810\n",
      "epoch 92; iter: 0; batch classifier loss: 0.108446; batch adversarial loss: 0.504087\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104677; batch adversarial loss: 0.428147\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050405; batch adversarial loss: 0.501965\n",
      "epoch 95; iter: 0; batch classifier loss: 0.089865; batch adversarial loss: 0.339511\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066307; batch adversarial loss: 0.390207\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079599; batch adversarial loss: 0.534938\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079401; batch adversarial loss: 0.407417\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064988; batch adversarial loss: 0.431392\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073882; batch adversarial loss: 0.472710\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051359; batch adversarial loss: 0.515349\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054436; batch adversarial loss: 0.440113\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032734; batch adversarial loss: 0.442488\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067250; batch adversarial loss: 0.524102\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061806; batch adversarial loss: 0.445558\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036951; batch adversarial loss: 0.481687\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029519; batch adversarial loss: 0.382223\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034470; batch adversarial loss: 0.489859\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066062; batch adversarial loss: 0.481252\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046477; batch adversarial loss: 0.488503\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064487; batch adversarial loss: 0.499355\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059740; batch adversarial loss: 0.532241\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054391; batch adversarial loss: 0.424693\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026463; batch adversarial loss: 0.453129\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029423; batch adversarial loss: 0.424257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.052514; batch adversarial loss: 0.393406\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060247; batch adversarial loss: 0.530641\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068480; batch adversarial loss: 0.471094\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098357; batch adversarial loss: 0.508865\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023504; batch adversarial loss: 0.378600\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054350; batch adversarial loss: 0.489244\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071562; batch adversarial loss: 0.463001\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024617; batch adversarial loss: 0.511574\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055548; batch adversarial loss: 0.398797\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047809; batch adversarial loss: 0.345214\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032437; batch adversarial loss: 0.492143\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.433407\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021865; batch adversarial loss: 0.449364\n",
      "epoch 129; iter: 0; batch classifier loss: 0.009008; batch adversarial loss: 0.447557\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034446; batch adversarial loss: 0.429566\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069699; batch adversarial loss: 0.429260\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031312; batch adversarial loss: 0.429652\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032411; batch adversarial loss: 0.375308\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026234; batch adversarial loss: 0.415251\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028074; batch adversarial loss: 0.364460\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026612; batch adversarial loss: 0.392601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027497; batch adversarial loss: 0.453997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020727; batch adversarial loss: 0.540228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020981; batch adversarial loss: 0.456134\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037164; batch adversarial loss: 0.414903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050184; batch adversarial loss: 0.423660\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031847; batch adversarial loss: 0.438489\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021123; batch adversarial loss: 0.435437\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040862; batch adversarial loss: 0.506100\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011856; batch adversarial loss: 0.448043\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035851; batch adversarial loss: 0.453459\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014878; batch adversarial loss: 0.495422\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038194; batch adversarial loss: 0.414560\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.340540\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046951; batch adversarial loss: 0.397479\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009364; batch adversarial loss: 0.427815\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033846; batch adversarial loss: 0.414126\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020013; batch adversarial loss: 0.527001\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011919; batch adversarial loss: 0.473611\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027664; batch adversarial loss: 0.334125\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023568; batch adversarial loss: 0.529818\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011405; batch adversarial loss: 0.467486\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033118; batch adversarial loss: 0.501782\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019690; batch adversarial loss: 0.398190\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010645; batch adversarial loss: 0.484634\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025765; batch adversarial loss: 0.509041\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012699; batch adversarial loss: 0.434695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026829; batch adversarial loss: 0.435567\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010975; batch adversarial loss: 0.390444\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014154; batch adversarial loss: 0.536393\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021715; batch adversarial loss: 0.390990\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024754; batch adversarial loss: 0.463906\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019769; batch adversarial loss: 0.496571\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017488; batch adversarial loss: 0.413198\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014999; batch adversarial loss: 0.453784\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010934; batch adversarial loss: 0.505245\n",
      "epoch 172; iter: 0; batch classifier loss: 0.063942; batch adversarial loss: 0.386833\n",
      "epoch 173; iter: 0; batch classifier loss: 0.063734; batch adversarial loss: 0.527613\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018147; batch adversarial loss: 0.463457\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009762; batch adversarial loss: 0.456520\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022285; batch adversarial loss: 0.447154\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052285; batch adversarial loss: 0.509409\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011930; batch adversarial loss: 0.466512\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048730; batch adversarial loss: 0.481621\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014755; batch adversarial loss: 0.501620\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017139; batch adversarial loss: 0.448523\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008251; batch adversarial loss: 0.443517\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.460395\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027591; batch adversarial loss: 0.367936\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015327; batch adversarial loss: 0.360285\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017081; batch adversarial loss: 0.471252\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022720; batch adversarial loss: 0.428398\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017482; batch adversarial loss: 0.440312\n",
      "epoch 189; iter: 0; batch classifier loss: 0.004544; batch adversarial loss: 0.471322\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007717; batch adversarial loss: 0.594454\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005259; batch adversarial loss: 0.417843\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011344; batch adversarial loss: 0.522920\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046064; batch adversarial loss: 0.467334\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024831; batch adversarial loss: 0.462604\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024556; batch adversarial loss: 0.417335\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005908; batch adversarial loss: 0.594253\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008465; batch adversarial loss: 0.566517\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014137; batch adversarial loss: 0.494534\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013716; batch adversarial loss: 0.416441\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697454; batch adversarial loss: 0.797643\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428730; batch adversarial loss: 0.798753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395304; batch adversarial loss: 0.756391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365462; batch adversarial loss: 0.688232\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336851; batch adversarial loss: 0.670927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379697; batch adversarial loss: 0.634603\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358031; batch adversarial loss: 0.625716\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353414; batch adversarial loss: 0.586659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.239462; batch adversarial loss: 0.565254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343023; batch adversarial loss: 0.536041\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373969; batch adversarial loss: 0.507856\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292036; batch adversarial loss: 0.447652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.276982; batch adversarial loss: 0.454628\n",
      "epoch 13; iter: 0; batch classifier loss: 0.207072; batch adversarial loss: 0.495313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280529; batch adversarial loss: 0.467215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.202732; batch adversarial loss: 0.444279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.214053; batch adversarial loss: 0.472283\n",
      "epoch 17; iter: 0; batch classifier loss: 0.168978; batch adversarial loss: 0.417731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.178581; batch adversarial loss: 0.415874\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172948; batch adversarial loss: 0.348702\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208605; batch adversarial loss: 0.410082\n",
      "epoch 21; iter: 0; batch classifier loss: 0.156746; batch adversarial loss: 0.378901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.149044; batch adversarial loss: 0.400806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188492; batch adversarial loss: 0.405028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168750; batch adversarial loss: 0.447902\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179941; batch adversarial loss: 0.351010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194051; batch adversarial loss: 0.359980\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146852; batch adversarial loss: 0.419868\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212018; batch adversarial loss: 0.431903\n",
      "epoch 29; iter: 0; batch classifier loss: 0.097251; batch adversarial loss: 0.374727\n",
      "epoch 30; iter: 0; batch classifier loss: 0.117774; batch adversarial loss: 0.365874\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133341; batch adversarial loss: 0.418358\n",
      "epoch 32; iter: 0; batch classifier loss: 0.137088; batch adversarial loss: 0.428423\n",
      "epoch 33; iter: 0; batch classifier loss: 0.156932; batch adversarial loss: 0.375551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.172282; batch adversarial loss: 0.340874\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099681; batch adversarial loss: 0.451922\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113648; batch adversarial loss: 0.373045\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159509; batch adversarial loss: 0.325430\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159039; batch adversarial loss: 0.430953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132600; batch adversarial loss: 0.389160\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154798; batch adversarial loss: 0.407419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104844; batch adversarial loss: 0.394626\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105700; batch adversarial loss: 0.383217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.108666; batch adversarial loss: 0.487369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106376; batch adversarial loss: 0.560454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080717; batch adversarial loss: 0.327105\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117413; batch adversarial loss: 0.442324\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076560; batch adversarial loss: 0.431606\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129538; batch adversarial loss: 0.441012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119431; batch adversarial loss: 0.402873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111221; batch adversarial loss: 0.396230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092021; batch adversarial loss: 0.349589\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107282; batch adversarial loss: 0.363136\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098444; batch adversarial loss: 0.470306\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080280; batch adversarial loss: 0.441040\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073128; batch adversarial loss: 0.430361\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096937; batch adversarial loss: 0.408691\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095689; batch adversarial loss: 0.432922\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086005; batch adversarial loss: 0.336693\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109898; batch adversarial loss: 0.440966\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081699; batch adversarial loss: 0.411882\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100616; batch adversarial loss: 0.370294\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073235; batch adversarial loss: 0.403983\n",
      "epoch 63; iter: 0; batch classifier loss: 0.069665; batch adversarial loss: 0.479987\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097241; batch adversarial loss: 0.398213\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073295; batch adversarial loss: 0.457379\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081495; batch adversarial loss: 0.371752\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085953; batch adversarial loss: 0.379566\n",
      "epoch 68; iter: 0; batch classifier loss: 0.049415; batch adversarial loss: 0.385010\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073837; batch adversarial loss: 0.324365\n",
      "epoch 70; iter: 0; batch classifier loss: 0.044826; batch adversarial loss: 0.337380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074985; batch adversarial loss: 0.412103\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060055; batch adversarial loss: 0.371241\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102496; batch adversarial loss: 0.411090\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075524; batch adversarial loss: 0.420228\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086462; batch adversarial loss: 0.438653\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058927; batch adversarial loss: 0.456579\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094503; batch adversarial loss: 0.558784\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080141; batch adversarial loss: 0.447313\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091419; batch adversarial loss: 0.432332\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061382; batch adversarial loss: 0.431637\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065370; batch adversarial loss: 0.416997\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058591; batch adversarial loss: 0.423874\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078078; batch adversarial loss: 0.449524\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048245; batch adversarial loss: 0.377923\n",
      "epoch 85; iter: 0; batch classifier loss: 0.047872; batch adversarial loss: 0.417941\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072273; batch adversarial loss: 0.404303\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054973; batch adversarial loss: 0.399671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092755; batch adversarial loss: 0.396514\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083714; batch adversarial loss: 0.440768\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077002; batch adversarial loss: 0.446529\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059168; batch adversarial loss: 0.361041\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047322; batch adversarial loss: 0.595480\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043812; batch adversarial loss: 0.399883\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083471; batch adversarial loss: 0.372860\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045511; batch adversarial loss: 0.338907\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044118; batch adversarial loss: 0.455451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037727; batch adversarial loss: 0.418571\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034135; batch adversarial loss: 0.473440\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065684; batch adversarial loss: 0.419606\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052102; batch adversarial loss: 0.394019\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057261; batch adversarial loss: 0.373392\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065061; batch adversarial loss: 0.419584\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.455183\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051019; batch adversarial loss: 0.478503\n",
      "epoch 105; iter: 0; batch classifier loss: 0.080032; batch adversarial loss: 0.505617\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041030; batch adversarial loss: 0.407545\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027956; batch adversarial loss: 0.474048\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020603; batch adversarial loss: 0.456966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031403; batch adversarial loss: 0.451592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.370047\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045653; batch adversarial loss: 0.513785\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047872; batch adversarial loss: 0.387577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019377; batch adversarial loss: 0.347650\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036599; batch adversarial loss: 0.394099\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044907; batch adversarial loss: 0.549896\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028231; batch adversarial loss: 0.456313\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031224; batch adversarial loss: 0.460812\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022578; batch adversarial loss: 0.403990\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029047; batch adversarial loss: 0.445017\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015189; batch adversarial loss: 0.432316\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034274; batch adversarial loss: 0.417132\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063755; batch adversarial loss: 0.543925\n",
      "epoch 123; iter: 0; batch classifier loss: 0.018282; batch adversarial loss: 0.449629\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026116; batch adversarial loss: 0.451990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012158; batch adversarial loss: 0.436120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.097262; batch adversarial loss: 0.454148\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030064; batch adversarial loss: 0.365149\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045976; batch adversarial loss: 0.482497\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058709; batch adversarial loss: 0.553882\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063715; batch adversarial loss: 0.456194\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036101; batch adversarial loss: 0.591804\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052190; batch adversarial loss: 0.512987\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058402; batch adversarial loss: 0.597114\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069099; batch adversarial loss: 0.484044\n",
      "epoch 135; iter: 0; batch classifier loss: 0.154056; batch adversarial loss: 0.681283\n",
      "epoch 136; iter: 0; batch classifier loss: 0.145709; batch adversarial loss: 0.627460\n",
      "epoch 137; iter: 0; batch classifier loss: 0.144071; batch adversarial loss: 0.611787\n",
      "epoch 138; iter: 0; batch classifier loss: 0.188958; batch adversarial loss: 0.703384\n",
      "epoch 139; iter: 0; batch classifier loss: 0.170979; batch adversarial loss: 0.658263\n",
      "epoch 140; iter: 0; batch classifier loss: 0.141894; batch adversarial loss: 0.670520\n",
      "epoch 141; iter: 0; batch classifier loss: 0.122113; batch adversarial loss: 0.552430\n",
      "epoch 142; iter: 0; batch classifier loss: 0.182300; batch adversarial loss: 0.643879\n",
      "epoch 143; iter: 0; batch classifier loss: 0.149708; batch adversarial loss: 0.561121\n",
      "epoch 144; iter: 0; batch classifier loss: 0.155992; batch adversarial loss: 0.680106\n",
      "epoch 145; iter: 0; batch classifier loss: 0.144951; batch adversarial loss: 0.536301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.218688; batch adversarial loss: 0.723366\n",
      "epoch 147; iter: 0; batch classifier loss: 0.200942; batch adversarial loss: 0.624644\n",
      "epoch 148; iter: 0; batch classifier loss: 0.145571; batch adversarial loss: 0.653194\n",
      "epoch 149; iter: 0; batch classifier loss: 0.142322; batch adversarial loss: 0.572976\n",
      "epoch 150; iter: 0; batch classifier loss: 0.186242; batch adversarial loss: 0.686739\n",
      "epoch 151; iter: 0; batch classifier loss: 0.144870; batch adversarial loss: 0.589604\n",
      "epoch 152; iter: 0; batch classifier loss: 0.122019; batch adversarial loss: 0.584858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.119065; batch adversarial loss: 0.512574\n",
      "epoch 154; iter: 0; batch classifier loss: 0.163773; batch adversarial loss: 0.535554\n",
      "epoch 155; iter: 0; batch classifier loss: 0.143483; batch adversarial loss: 0.448367\n",
      "epoch 156; iter: 0; batch classifier loss: 0.156365; batch adversarial loss: 0.481092\n",
      "epoch 157; iter: 0; batch classifier loss: 0.163335; batch adversarial loss: 0.590383\n",
      "epoch 158; iter: 0; batch classifier loss: 0.210737; batch adversarial loss: 0.658234\n",
      "epoch 159; iter: 0; batch classifier loss: 0.082590; batch adversarial loss: 0.462001\n",
      "epoch 160; iter: 0; batch classifier loss: 0.175681; batch adversarial loss: 0.581840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.160413; batch adversarial loss: 0.567759\n",
      "epoch 162; iter: 0; batch classifier loss: 0.193560; batch adversarial loss: 0.612953\n",
      "epoch 163; iter: 0; batch classifier loss: 0.169862; batch adversarial loss: 0.543125\n",
      "epoch 164; iter: 0; batch classifier loss: 0.099013; batch adversarial loss: 0.500587\n",
      "epoch 165; iter: 0; batch classifier loss: 0.144850; batch adversarial loss: 0.536523\n",
      "epoch 166; iter: 0; batch classifier loss: 0.066665; batch adversarial loss: 0.437162\n",
      "epoch 167; iter: 0; batch classifier loss: 0.117739; batch adversarial loss: 0.451843\n",
      "epoch 168; iter: 0; batch classifier loss: 0.207849; batch adversarial loss: 0.588786\n",
      "epoch 169; iter: 0; batch classifier loss: 0.133901; batch adversarial loss: 0.424148\n",
      "epoch 170; iter: 0; batch classifier loss: 0.093888; batch adversarial loss: 0.462458\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072488; batch adversarial loss: 0.415823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.122264; batch adversarial loss: 0.480832\n",
      "epoch 173; iter: 0; batch classifier loss: 0.144016; batch adversarial loss: 0.500031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.146919; batch adversarial loss: 0.485811\n",
      "epoch 175; iter: 0; batch classifier loss: 0.113104; batch adversarial loss: 0.409409\n",
      "epoch 176; iter: 0; batch classifier loss: 0.082890; batch adversarial loss: 0.378885\n",
      "epoch 177; iter: 0; batch classifier loss: 0.074939; batch adversarial loss: 0.477436\n",
      "epoch 178; iter: 0; batch classifier loss: 0.155912; batch adversarial loss: 0.471372\n",
      "epoch 179; iter: 0; batch classifier loss: 0.164139; batch adversarial loss: 0.518834\n",
      "epoch 180; iter: 0; batch classifier loss: 0.156301; batch adversarial loss: 0.508026\n",
      "epoch 181; iter: 0; batch classifier loss: 0.088618; batch adversarial loss: 0.428961\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028222; batch adversarial loss: 0.414610\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036036; batch adversarial loss: 0.491608\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038250; batch adversarial loss: 0.507361\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024057; batch adversarial loss: 0.454507\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043189; batch adversarial loss: 0.419239\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031670; batch adversarial loss: 0.432629\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035189; batch adversarial loss: 0.485019\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050131; batch adversarial loss: 0.337974\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027662; batch adversarial loss: 0.318444\n",
      "epoch 191; iter: 0; batch classifier loss: 0.049318; batch adversarial loss: 0.438387\n",
      "epoch 192; iter: 0; batch classifier loss: 0.057659; batch adversarial loss: 0.468702\n",
      "epoch 193; iter: 0; batch classifier loss: 0.070389; batch adversarial loss: 0.330368\n",
      "epoch 194; iter: 0; batch classifier loss: 0.066391; batch adversarial loss: 0.564801\n",
      "epoch 195; iter: 0; batch classifier loss: 0.096823; batch adversarial loss: 0.441622\n",
      "epoch 196; iter: 0; batch classifier loss: 0.057344; batch adversarial loss: 0.546321\n",
      "epoch 197; iter: 0; batch classifier loss: 0.075870; batch adversarial loss: 0.461807\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056509; batch adversarial loss: 0.381679\n",
      "epoch 199; iter: 0; batch classifier loss: 0.075466; batch adversarial loss: 0.488840\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682186; batch adversarial loss: 0.548557\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423013; batch adversarial loss: 0.579431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.462274; batch adversarial loss: 0.545895\n",
      "epoch 3; iter: 0; batch classifier loss: 0.447989; batch adversarial loss: 0.608389\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408172; batch adversarial loss: 0.584966\n",
      "epoch 5; iter: 0; batch classifier loss: 0.381080; batch adversarial loss: 0.642227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.400096; batch adversarial loss: 0.589579\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501647; batch adversarial loss: 0.587871\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574530; batch adversarial loss: 0.562733\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604149; batch adversarial loss: 0.602450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588741; batch adversarial loss: 0.554356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591801; batch adversarial loss: 0.489832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478161; batch adversarial loss: 0.498645\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390211; batch adversarial loss: 0.531267\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404209; batch adversarial loss: 0.502547\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402627; batch adversarial loss: 0.425897\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243694; batch adversarial loss: 0.435325\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233858; batch adversarial loss: 0.460690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258887; batch adversarial loss: 0.435748\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231253; batch adversarial loss: 0.467753\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251268; batch adversarial loss: 0.413021\n",
      "epoch 21; iter: 0; batch classifier loss: 0.244857; batch adversarial loss: 0.507239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.176917; batch adversarial loss: 0.494175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197343; batch adversarial loss: 0.477574\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210050; batch adversarial loss: 0.456501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271225; batch adversarial loss: 0.472411\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199674; batch adversarial loss: 0.502531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.189946; batch adversarial loss: 0.484759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214668; batch adversarial loss: 0.475543\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179714; batch adversarial loss: 0.362332\n",
      "epoch 30; iter: 0; batch classifier loss: 0.241969; batch adversarial loss: 0.412500\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132613; batch adversarial loss: 0.455022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.213979; batch adversarial loss: 0.393179\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291029; batch adversarial loss: 0.359632\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168765; batch adversarial loss: 0.435273\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112043; batch adversarial loss: 0.434796\n",
      "epoch 36; iter: 0; batch classifier loss: 0.136695; batch adversarial loss: 0.395447\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136641; batch adversarial loss: 0.395094\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133913; batch adversarial loss: 0.419464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135041; batch adversarial loss: 0.565370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.205488; batch adversarial loss: 0.368111\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157308; batch adversarial loss: 0.414690\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147503; batch adversarial loss: 0.502754\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157910; batch adversarial loss: 0.390242\n",
      "epoch 44; iter: 0; batch classifier loss: 0.168909; batch adversarial loss: 0.421595\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188344; batch adversarial loss: 0.456905\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165379; batch adversarial loss: 0.405836\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153805; batch adversarial loss: 0.325423\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142351; batch adversarial loss: 0.424174\n",
      "epoch 49; iter: 0; batch classifier loss: 0.164284; batch adversarial loss: 0.483164\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220983; batch adversarial loss: 0.359812\n",
      "epoch 51; iter: 0; batch classifier loss: 0.202868; batch adversarial loss: 0.479192\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148330; batch adversarial loss: 0.431420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151046; batch adversarial loss: 0.441874\n",
      "epoch 54; iter: 0; batch classifier loss: 0.162925; batch adversarial loss: 0.447144\n",
      "epoch 55; iter: 0; batch classifier loss: 0.214215; batch adversarial loss: 0.421904\n",
      "epoch 56; iter: 0; batch classifier loss: 0.190001; batch adversarial loss: 0.368155\n",
      "epoch 57; iter: 0; batch classifier loss: 0.290206; batch adversarial loss: 0.467222\n",
      "epoch 58; iter: 0; batch classifier loss: 0.131505; batch adversarial loss: 0.347774\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159807; batch adversarial loss: 0.536969\n",
      "epoch 60; iter: 0; batch classifier loss: 0.159073; batch adversarial loss: 0.409424\n",
      "epoch 61; iter: 0; batch classifier loss: 0.137575; batch adversarial loss: 0.484192\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186311; batch adversarial loss: 0.483789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.244321; batch adversarial loss: 0.485033\n",
      "epoch 64; iter: 0; batch classifier loss: 0.206678; batch adversarial loss: 0.359793\n",
      "epoch 65; iter: 0; batch classifier loss: 0.202186; batch adversarial loss: 0.380678\n",
      "epoch 66; iter: 0; batch classifier loss: 0.186954; batch adversarial loss: 0.459127\n",
      "epoch 67; iter: 0; batch classifier loss: 0.228016; batch adversarial loss: 0.380676\n",
      "epoch 68; iter: 0; batch classifier loss: 0.165385; batch adversarial loss: 0.384891\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211302; batch adversarial loss: 0.435151\n",
      "epoch 70; iter: 0; batch classifier loss: 0.171510; batch adversarial loss: 0.369944\n",
      "epoch 71; iter: 0; batch classifier loss: 0.165061; batch adversarial loss: 0.396560\n",
      "epoch 72; iter: 0; batch classifier loss: 0.217082; batch adversarial loss: 0.457793\n",
      "epoch 73; iter: 0; batch classifier loss: 0.251204; batch adversarial loss: 0.382520\n",
      "epoch 74; iter: 0; batch classifier loss: 0.256589; batch adversarial loss: 0.433351\n",
      "epoch 75; iter: 0; batch classifier loss: 0.204909; batch adversarial loss: 0.460179\n",
      "epoch 76; iter: 0; batch classifier loss: 0.178431; batch adversarial loss: 0.332196\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165502; batch adversarial loss: 0.472012\n",
      "epoch 78; iter: 0; batch classifier loss: 0.176514; batch adversarial loss: 0.446832\n",
      "epoch 79; iter: 0; batch classifier loss: 0.171555; batch adversarial loss: 0.408356\n",
      "epoch 80; iter: 0; batch classifier loss: 0.181695; batch adversarial loss: 0.421050\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115663; batch adversarial loss: 0.446092\n",
      "epoch 82; iter: 0; batch classifier loss: 0.208124; batch adversarial loss: 0.473705\n",
      "epoch 83; iter: 0; batch classifier loss: 0.216524; batch adversarial loss: 0.421307\n",
      "epoch 84; iter: 0; batch classifier loss: 0.230742; batch adversarial loss: 0.471205\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194224; batch adversarial loss: 0.523724\n",
      "epoch 86; iter: 0; batch classifier loss: 0.184617; batch adversarial loss: 0.433718\n",
      "epoch 87; iter: 0; batch classifier loss: 0.152817; batch adversarial loss: 0.407410\n",
      "epoch 88; iter: 0; batch classifier loss: 0.226249; batch adversarial loss: 0.523272\n",
      "epoch 89; iter: 0; batch classifier loss: 0.226909; batch adversarial loss: 0.434286\n",
      "epoch 90; iter: 0; batch classifier loss: 0.245295; batch adversarial loss: 0.471591\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082667; batch adversarial loss: 0.471140\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052844; batch adversarial loss: 0.339945\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065142; batch adversarial loss: 0.351059\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065831; batch adversarial loss: 0.374332\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045300; batch adversarial loss: 0.424604\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052342; batch adversarial loss: 0.432314\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041938; batch adversarial loss: 0.467617\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055951; batch adversarial loss: 0.398727\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044312; batch adversarial loss: 0.443998\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049702; batch adversarial loss: 0.431878\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076822; batch adversarial loss: 0.572393\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047001; batch adversarial loss: 0.415686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.035673; batch adversarial loss: 0.452684\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053886; batch adversarial loss: 0.413709\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049464; batch adversarial loss: 0.520147\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063229; batch adversarial loss: 0.426395\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097725; batch adversarial loss: 0.448359\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053970; batch adversarial loss: 0.476152\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075836; batch adversarial loss: 0.469359\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079804; batch adversarial loss: 0.414421\n",
      "epoch 111; iter: 0; batch classifier loss: 0.082764; batch adversarial loss: 0.433138\n",
      "epoch 112; iter: 0; batch classifier loss: 0.086539; batch adversarial loss: 0.478603\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044965; batch adversarial loss: 0.391763\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072592; batch adversarial loss: 0.440281\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070378; batch adversarial loss: 0.523851\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072684; batch adversarial loss: 0.473864\n",
      "epoch 117; iter: 0; batch classifier loss: 0.090589; batch adversarial loss: 0.441080\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067713; batch adversarial loss: 0.451732\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033218; batch adversarial loss: 0.449553\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.463421\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038101; batch adversarial loss: 0.445903\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061695; batch adversarial loss: 0.339599\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075600; batch adversarial loss: 0.368850\n",
      "epoch 124; iter: 0; batch classifier loss: 0.098037; batch adversarial loss: 0.392825\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023688; batch adversarial loss: 0.383741\n",
      "epoch 126; iter: 0; batch classifier loss: 0.119519; batch adversarial loss: 0.399733\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060977; batch adversarial loss: 0.347939\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062005; batch adversarial loss: 0.317331\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048690; batch adversarial loss: 0.440328\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026993; batch adversarial loss: 0.441425\n",
      "epoch 131; iter: 0; batch classifier loss: 0.083501; batch adversarial loss: 0.371228\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034444; batch adversarial loss: 0.441710\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083847; batch adversarial loss: 0.410265\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049654; batch adversarial loss: 0.529367\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.501425\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051785; batch adversarial loss: 0.435633\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053438; batch adversarial loss: 0.410177\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044856; batch adversarial loss: 0.423440\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056711; batch adversarial loss: 0.414340\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055340; batch adversarial loss: 0.357498\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042728; batch adversarial loss: 0.481254\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044424; batch adversarial loss: 0.399955\n",
      "epoch 143; iter: 0; batch classifier loss: 0.060403; batch adversarial loss: 0.461812\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050222; batch adversarial loss: 0.443545\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048988; batch adversarial loss: 0.394836\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052323; batch adversarial loss: 0.489245\n",
      "epoch 147; iter: 0; batch classifier loss: 0.053394; batch adversarial loss: 0.410371\n",
      "epoch 148; iter: 0; batch classifier loss: 0.084077; batch adversarial loss: 0.348016\n",
      "epoch 149; iter: 0; batch classifier loss: 0.066150; batch adversarial loss: 0.409896\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055814; batch adversarial loss: 0.410633\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048299; batch adversarial loss: 0.493053\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034841; batch adversarial loss: 0.460830\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058211; batch adversarial loss: 0.329541\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041398; batch adversarial loss: 0.437452\n",
      "epoch 155; iter: 0; batch classifier loss: 0.086197; batch adversarial loss: 0.389176\n",
      "epoch 156; iter: 0; batch classifier loss: 0.065361; batch adversarial loss: 0.449647\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022847; batch adversarial loss: 0.386350\n",
      "epoch 158; iter: 0; batch classifier loss: 0.059945; batch adversarial loss: 0.339814\n",
      "epoch 159; iter: 0; batch classifier loss: 0.088481; batch adversarial loss: 0.436794\n",
      "epoch 160; iter: 0; batch classifier loss: 0.071080; batch adversarial loss: 0.481829\n",
      "epoch 161; iter: 0; batch classifier loss: 0.063852; batch adversarial loss: 0.430489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.072296; batch adversarial loss: 0.417602\n",
      "epoch 163; iter: 0; batch classifier loss: 0.071857; batch adversarial loss: 0.468919\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043072; batch adversarial loss: 0.406408\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042508; batch adversarial loss: 0.333457\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044870; batch adversarial loss: 0.307982\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044888; batch adversarial loss: 0.499493\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036654; batch adversarial loss: 0.375031\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053148; batch adversarial loss: 0.449711\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045973; batch adversarial loss: 0.417985\n",
      "epoch 171; iter: 0; batch classifier loss: 0.062146; batch adversarial loss: 0.426202\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037238; batch adversarial loss: 0.370319\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044235; batch adversarial loss: 0.399434\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036892; batch adversarial loss: 0.356058\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028690; batch adversarial loss: 0.408281\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053577; batch adversarial loss: 0.307933\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049803; batch adversarial loss: 0.380231\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048075; batch adversarial loss: 0.384834\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036178; batch adversarial loss: 0.393223\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019606; batch adversarial loss: 0.348149\n",
      "epoch 181; iter: 0; batch classifier loss: 0.073650; batch adversarial loss: 0.456026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.063464; batch adversarial loss: 0.441858\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046324; batch adversarial loss: 0.419469\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027392; batch adversarial loss: 0.411493\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034046; batch adversarial loss: 0.385655\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039214; batch adversarial loss: 0.450402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033174; batch adversarial loss: 0.450944\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047112; batch adversarial loss: 0.445378\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026807; batch adversarial loss: 0.362467\n",
      "epoch 190; iter: 0; batch classifier loss: 0.055570; batch adversarial loss: 0.383761\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.327960\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033038; batch adversarial loss: 0.461436\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033748; batch adversarial loss: 0.483577\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030428; batch adversarial loss: 0.417064\n",
      "epoch 195; iter: 0; batch classifier loss: 0.071718; batch adversarial loss: 0.395280\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.484448\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046502; batch adversarial loss: 0.431750\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.469250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.060730; batch adversarial loss: 0.356398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700414; batch adversarial loss: 0.928772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.527717; batch adversarial loss: 0.882461\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595777; batch adversarial loss: 0.911555\n",
      "epoch 3; iter: 0; batch classifier loss: 0.799896; batch adversarial loss: 0.842437\n",
      "epoch 4; iter: 0; batch classifier loss: 0.818323; batch adversarial loss: 0.761732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.831243; batch adversarial loss: 0.689371\n",
      "epoch 6; iter: 0; batch classifier loss: 0.623081; batch adversarial loss: 0.622723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.423412; batch adversarial loss: 0.593455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300021; batch adversarial loss: 0.557478\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341501; batch adversarial loss: 0.561102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324097; batch adversarial loss: 0.517537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352163; batch adversarial loss: 0.484114\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241520; batch adversarial loss: 0.499860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198019; batch adversarial loss: 0.505646\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223951; batch adversarial loss: 0.481611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.243119; batch adversarial loss: 0.498301\n",
      "epoch 16; iter: 0; batch classifier loss: 0.221949; batch adversarial loss: 0.516587\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186187; batch adversarial loss: 0.484696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170020; batch adversarial loss: 0.451457\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157133; batch adversarial loss: 0.443619\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178989; batch adversarial loss: 0.464642\n",
      "epoch 21; iter: 0; batch classifier loss: 0.155419; batch adversarial loss: 0.464853\n",
      "epoch 22; iter: 0; batch classifier loss: 0.186123; batch adversarial loss: 0.392095\n",
      "epoch 23; iter: 0; batch classifier loss: 0.137073; batch adversarial loss: 0.398088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130265; batch adversarial loss: 0.484822\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165394; batch adversarial loss: 0.355991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154494; batch adversarial loss: 0.461428\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120418; batch adversarial loss: 0.438680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.093026; batch adversarial loss: 0.374883\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119017; batch adversarial loss: 0.481016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141452; batch adversarial loss: 0.415652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.118768; batch adversarial loss: 0.427198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115569; batch adversarial loss: 0.398335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119841; batch adversarial loss: 0.427712\n",
      "epoch 34; iter: 0; batch classifier loss: 0.074251; batch adversarial loss: 0.437679\n",
      "epoch 35; iter: 0; batch classifier loss: 0.114687; batch adversarial loss: 0.497069\n",
      "epoch 36; iter: 0; batch classifier loss: 0.086095; batch adversarial loss: 0.491353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.086459; batch adversarial loss: 0.389203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122584; batch adversarial loss: 0.547334\n",
      "epoch 39; iter: 0; batch classifier loss: 0.091458; batch adversarial loss: 0.506293\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096788; batch adversarial loss: 0.523541\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161301; batch adversarial loss: 0.423045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108751; batch adversarial loss: 0.429153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081369; batch adversarial loss: 0.399290\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074252; batch adversarial loss: 0.450251\n",
      "epoch 45; iter: 0; batch classifier loss: 0.070955; batch adversarial loss: 0.453867\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095981; batch adversarial loss: 0.423862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.047957; batch adversarial loss: 0.449903\n",
      "epoch 48; iter: 0; batch classifier loss: 0.055388; batch adversarial loss: 0.374436\n",
      "epoch 49; iter: 0; batch classifier loss: 0.108654; batch adversarial loss: 0.442757\n",
      "epoch 50; iter: 0; batch classifier loss: 0.064496; batch adversarial loss: 0.482399\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101647; batch adversarial loss: 0.436356\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105121; batch adversarial loss: 0.464954\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068998; batch adversarial loss: 0.440942\n",
      "epoch 54; iter: 0; batch classifier loss: 0.045768; batch adversarial loss: 0.496335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.058935; batch adversarial loss: 0.436409\n",
      "epoch 56; iter: 0; batch classifier loss: 0.054161; batch adversarial loss: 0.345632\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077480; batch adversarial loss: 0.466805\n",
      "epoch 58; iter: 0; batch classifier loss: 0.057736; batch adversarial loss: 0.451800\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072372; batch adversarial loss: 0.410269\n",
      "epoch 60; iter: 0; batch classifier loss: 0.103557; batch adversarial loss: 0.408401\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071971; batch adversarial loss: 0.367200\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124591; batch adversarial loss: 0.525305\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071253; batch adversarial loss: 0.399728\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080166; batch adversarial loss: 0.397341\n",
      "epoch 65; iter: 0; batch classifier loss: 0.041608; batch adversarial loss: 0.420068\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077703; batch adversarial loss: 0.415905\n",
      "epoch 67; iter: 0; batch classifier loss: 0.058007; batch adversarial loss: 0.474870\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086561; batch adversarial loss: 0.419338\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079096; batch adversarial loss: 0.515336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048983; batch adversarial loss: 0.489549\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079812; batch adversarial loss: 0.420675\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053094; batch adversarial loss: 0.345314\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055626; batch adversarial loss: 0.419246\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070572; batch adversarial loss: 0.453656\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051114; batch adversarial loss: 0.462990\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058275; batch adversarial loss: 0.523819\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069565; batch adversarial loss: 0.397615\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054982; batch adversarial loss: 0.472297\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085827; batch adversarial loss: 0.385534\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075229; batch adversarial loss: 0.607334\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087917; batch adversarial loss: 0.335048\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067358; batch adversarial loss: 0.439949\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073269; batch adversarial loss: 0.428766\n",
      "epoch 84; iter: 0; batch classifier loss: 0.052211; batch adversarial loss: 0.466251\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052591; batch adversarial loss: 0.359001\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120971; batch adversarial loss: 0.411980\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046645; batch adversarial loss: 0.499693\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082916; batch adversarial loss: 0.427081\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053863; batch adversarial loss: 0.470440\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046145; batch adversarial loss: 0.430457\n",
      "epoch 91; iter: 0; batch classifier loss: 0.026262; batch adversarial loss: 0.405878\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068107; batch adversarial loss: 0.447466\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052325; batch adversarial loss: 0.353736\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044872; batch adversarial loss: 0.398702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068763; batch adversarial loss: 0.274279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.100475; batch adversarial loss: 0.401747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082519; batch adversarial loss: 0.385597\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052411; batch adversarial loss: 0.346198\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065988; batch adversarial loss: 0.391478\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050113; batch adversarial loss: 0.401024\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056566; batch adversarial loss: 0.380723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051682; batch adversarial loss: 0.470996\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099308; batch adversarial loss: 0.492713\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039469; batch adversarial loss: 0.388315\n",
      "epoch 105; iter: 0; batch classifier loss: 0.015494; batch adversarial loss: 0.440071\n",
      "epoch 106; iter: 0; batch classifier loss: 0.111446; batch adversarial loss: 0.442268\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072948; batch adversarial loss: 0.423983\n",
      "epoch 108; iter: 0; batch classifier loss: 0.113468; batch adversarial loss: 0.470200\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042253; batch adversarial loss: 0.428165\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031295; batch adversarial loss: 0.317182\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074406; batch adversarial loss: 0.546167\n",
      "epoch 112; iter: 0; batch classifier loss: 0.081256; batch adversarial loss: 0.433646\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033623; batch adversarial loss: 0.376773\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050380; batch adversarial loss: 0.495324\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048478; batch adversarial loss: 0.458668\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023139; batch adversarial loss: 0.422229\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058383; batch adversarial loss: 0.453090\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063022; batch adversarial loss: 0.440501\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026263; batch adversarial loss: 0.321279\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042240; batch adversarial loss: 0.493869\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044648; batch adversarial loss: 0.408860\n",
      "epoch 122; iter: 0; batch classifier loss: 0.075321; batch adversarial loss: 0.568584\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053096; batch adversarial loss: 0.475078\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061182; batch adversarial loss: 0.448940\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066230; batch adversarial loss: 0.374587\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061268; batch adversarial loss: 0.581543\n",
      "epoch 127; iter: 0; batch classifier loss: 0.075876; batch adversarial loss: 0.437488\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051491; batch adversarial loss: 0.338853\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067364; batch adversarial loss: 0.444035\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051515; batch adversarial loss: 0.412220\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041111; batch adversarial loss: 0.440268\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047318; batch adversarial loss: 0.431162\n",
      "epoch 133; iter: 0; batch classifier loss: 0.077802; batch adversarial loss: 0.434317\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056540; batch adversarial loss: 0.409869\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039023; batch adversarial loss: 0.479607\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028926; batch adversarial loss: 0.440161\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033665; batch adversarial loss: 0.468356\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046627; batch adversarial loss: 0.375098\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032379; batch adversarial loss: 0.451792\n",
      "epoch 140; iter: 0; batch classifier loss: 0.077313; batch adversarial loss: 0.449728\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032728; batch adversarial loss: 0.460633\n",
      "epoch 142; iter: 0; batch classifier loss: 0.109220; batch adversarial loss: 0.427303\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026479; batch adversarial loss: 0.448369\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033353; batch adversarial loss: 0.377784\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036642; batch adversarial loss: 0.449559\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050185; batch adversarial loss: 0.430615\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036882; batch adversarial loss: 0.453412\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.428070\n",
      "epoch 149; iter: 0; batch classifier loss: 0.058195; batch adversarial loss: 0.412304\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047662; batch adversarial loss: 0.419373\n",
      "epoch 151; iter: 0; batch classifier loss: 0.082171; batch adversarial loss: 0.405545\n",
      "epoch 152; iter: 0; batch classifier loss: 0.074267; batch adversarial loss: 0.434377\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.394177\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033279; batch adversarial loss: 0.345825\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047671; batch adversarial loss: 0.429728\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043853; batch adversarial loss: 0.434853\n",
      "epoch 157; iter: 0; batch classifier loss: 0.080438; batch adversarial loss: 0.423603\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049138; batch adversarial loss: 0.502679\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063494; batch adversarial loss: 0.403472\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039273; batch adversarial loss: 0.370842\n",
      "epoch 161; iter: 0; batch classifier loss: 0.046135; batch adversarial loss: 0.439399\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043274; batch adversarial loss: 0.483939\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050641; batch adversarial loss: 0.381127\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052707; batch adversarial loss: 0.364968\n",
      "epoch 165; iter: 0; batch classifier loss: 0.074712; batch adversarial loss: 0.470686\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068546; batch adversarial loss: 0.434132\n",
      "epoch 167; iter: 0; batch classifier loss: 0.063860; batch adversarial loss: 0.491846\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042419; batch adversarial loss: 0.397778\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052782; batch adversarial loss: 0.401070\n",
      "epoch 170; iter: 0; batch classifier loss: 0.057079; batch adversarial loss: 0.425233\n",
      "epoch 171; iter: 0; batch classifier loss: 0.064415; batch adversarial loss: 0.492637\n",
      "epoch 172; iter: 0; batch classifier loss: 0.071044; batch adversarial loss: 0.387721\n",
      "epoch 173; iter: 0; batch classifier loss: 0.054157; batch adversarial loss: 0.422034\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050022; batch adversarial loss: 0.370478\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028928; batch adversarial loss: 0.436554\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034567; batch adversarial loss: 0.326535\n",
      "epoch 177; iter: 0; batch classifier loss: 0.074265; batch adversarial loss: 0.420457\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048913; batch adversarial loss: 0.434422\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040321; batch adversarial loss: 0.438381\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043601; batch adversarial loss: 0.482260\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051627; batch adversarial loss: 0.383992\n",
      "epoch 182; iter: 0; batch classifier loss: 0.049655; batch adversarial loss: 0.369660\n",
      "epoch 183; iter: 0; batch classifier loss: 0.048109; batch adversarial loss: 0.441311\n",
      "epoch 184; iter: 0; batch classifier loss: 0.063765; batch adversarial loss: 0.424957\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053216; batch adversarial loss: 0.439458\n",
      "epoch 186; iter: 0; batch classifier loss: 0.067674; batch adversarial loss: 0.429397\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043809; batch adversarial loss: 0.448664\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047598; batch adversarial loss: 0.477060\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045422; batch adversarial loss: 0.358023\n",
      "epoch 190; iter: 0; batch classifier loss: 0.090515; batch adversarial loss: 0.451948\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040318; batch adversarial loss: 0.459343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.040288; batch adversarial loss: 0.428475\n",
      "epoch 193; iter: 0; batch classifier loss: 0.051688; batch adversarial loss: 0.447732\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042916; batch adversarial loss: 0.484813\n",
      "epoch 195; iter: 0; batch classifier loss: 0.077398; batch adversarial loss: 0.435805\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033251; batch adversarial loss: 0.483812\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026035; batch adversarial loss: 0.379633\n",
      "epoch 198; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.269853\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051681; batch adversarial loss: 0.392488\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681789; batch adversarial loss: 0.610108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496122; batch adversarial loss: 0.613647\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424150; batch adversarial loss: 0.610229\n",
      "epoch 3; iter: 0; batch classifier loss: 0.448264; batch adversarial loss: 0.605617\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439348; batch adversarial loss: 0.567877\n",
      "epoch 5; iter: 0; batch classifier loss: 0.401888; batch adversarial loss: 0.542486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.424921; batch adversarial loss: 0.610631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.655739; batch adversarial loss: 0.593014\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642206; batch adversarial loss: 0.589852\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601287; batch adversarial loss: 0.534515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489279; batch adversarial loss: 0.526270\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432856; batch adversarial loss: 0.464173\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327585; batch adversarial loss: 0.484321\n",
      "epoch 13; iter: 0; batch classifier loss: 0.296075; batch adversarial loss: 0.494886\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277339; batch adversarial loss: 0.514391\n",
      "epoch 15; iter: 0; batch classifier loss: 0.328794; batch adversarial loss: 0.519022\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358245; batch adversarial loss: 0.453794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250911; batch adversarial loss: 0.480379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211188; batch adversarial loss: 0.537474\n",
      "epoch 19; iter: 0; batch classifier loss: 0.208797; batch adversarial loss: 0.523403\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251456; batch adversarial loss: 0.454201\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241429; batch adversarial loss: 0.521792\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259637; batch adversarial loss: 0.437387\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203900; batch adversarial loss: 0.489037\n",
      "epoch 24; iter: 0; batch classifier loss: 0.183953; batch adversarial loss: 0.558061\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188946; batch adversarial loss: 0.377298\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173531; batch adversarial loss: 0.485475\n",
      "epoch 27; iter: 0; batch classifier loss: 0.233044; batch adversarial loss: 0.452405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182928; batch adversarial loss: 0.401457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.149488; batch adversarial loss: 0.502963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157730; batch adversarial loss: 0.473328\n",
      "epoch 31; iter: 0; batch classifier loss: 0.141041; batch adversarial loss: 0.514738\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133609; batch adversarial loss: 0.430213\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234161; batch adversarial loss: 0.444144\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212303; batch adversarial loss: 0.446712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139966; batch adversarial loss: 0.487337\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170651; batch adversarial loss: 0.450696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113843; batch adversarial loss: 0.501529\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116291; batch adversarial loss: 0.406385\n",
      "epoch 39; iter: 0; batch classifier loss: 0.165084; batch adversarial loss: 0.426694\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178349; batch adversarial loss: 0.436384\n",
      "epoch 41; iter: 0; batch classifier loss: 0.169988; batch adversarial loss: 0.544072\n",
      "epoch 42; iter: 0; batch classifier loss: 0.190773; batch adversarial loss: 0.538843\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180873; batch adversarial loss: 0.474132\n",
      "epoch 44; iter: 0; batch classifier loss: 0.239418; batch adversarial loss: 0.490904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.139629; batch adversarial loss: 0.543718\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150806; batch adversarial loss: 0.425225\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162756; batch adversarial loss: 0.470365\n",
      "epoch 48; iter: 0; batch classifier loss: 0.147089; batch adversarial loss: 0.553186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099768; batch adversarial loss: 0.545233\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126956; batch adversarial loss: 0.432041\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167986; batch adversarial loss: 0.436449\n",
      "epoch 52; iter: 0; batch classifier loss: 0.151309; batch adversarial loss: 0.500242\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123934; batch adversarial loss: 0.453456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.221531; batch adversarial loss: 0.386373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.159404; batch adversarial loss: 0.502667\n",
      "epoch 56; iter: 0; batch classifier loss: 0.147062; batch adversarial loss: 0.503304\n",
      "epoch 57; iter: 0; batch classifier loss: 0.146748; batch adversarial loss: 0.488180\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127267; batch adversarial loss: 0.422978\n",
      "epoch 59; iter: 0; batch classifier loss: 0.129367; batch adversarial loss: 0.534097\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187916; batch adversarial loss: 0.455494\n",
      "epoch 61; iter: 0; batch classifier loss: 0.165879; batch adversarial loss: 0.505982\n",
      "epoch 62; iter: 0; batch classifier loss: 0.180825; batch adversarial loss: 0.432818\n",
      "epoch 63; iter: 0; batch classifier loss: 0.131798; batch adversarial loss: 0.336384\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107612; batch adversarial loss: 0.455676\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196993; batch adversarial loss: 0.445455\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121333; batch adversarial loss: 0.538139\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132683; batch adversarial loss: 0.459461\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215678; batch adversarial loss: 0.431906\n",
      "epoch 69; iter: 0; batch classifier loss: 0.194714; batch adversarial loss: 0.497428\n",
      "epoch 70; iter: 0; batch classifier loss: 0.163479; batch adversarial loss: 0.450253\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148184; batch adversarial loss: 0.418188\n",
      "epoch 72; iter: 0; batch classifier loss: 0.175490; batch adversarial loss: 0.454560\n",
      "epoch 73; iter: 0; batch classifier loss: 0.183011; batch adversarial loss: 0.461383\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160603; batch adversarial loss: 0.421883\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105646; batch adversarial loss: 0.533382\n",
      "epoch 76; iter: 0; batch classifier loss: 0.177649; batch adversarial loss: 0.470499\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154407; batch adversarial loss: 0.482325\n",
      "epoch 78; iter: 0; batch classifier loss: 0.141848; batch adversarial loss: 0.458508\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132448; batch adversarial loss: 0.472110\n",
      "epoch 80; iter: 0; batch classifier loss: 0.193417; batch adversarial loss: 0.465385\n",
      "epoch 81; iter: 0; batch classifier loss: 0.201056; batch adversarial loss: 0.408212\n",
      "epoch 82; iter: 0; batch classifier loss: 0.142276; batch adversarial loss: 0.429640\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099096; batch adversarial loss: 0.456283\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184123; batch adversarial loss: 0.497257\n",
      "epoch 85; iter: 0; batch classifier loss: 0.105755; batch adversarial loss: 0.480483\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106801; batch adversarial loss: 0.357406\n",
      "epoch 87; iter: 0; batch classifier loss: 0.132723; batch adversarial loss: 0.434419\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086922; batch adversarial loss: 0.534223\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071491; batch adversarial loss: 0.422907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.161653; batch adversarial loss: 0.428367\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056415; batch adversarial loss: 0.485459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.132662; batch adversarial loss: 0.496211\n",
      "epoch 93; iter: 0; batch classifier loss: 0.098837; batch adversarial loss: 0.385568\n",
      "epoch 94; iter: 0; batch classifier loss: 0.121487; batch adversarial loss: 0.479213\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062899; batch adversarial loss: 0.517257\n",
      "epoch 96; iter: 0; batch classifier loss: 0.130569; batch adversarial loss: 0.380071\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076063; batch adversarial loss: 0.446947\n",
      "epoch 98; iter: 0; batch classifier loss: 0.093968; batch adversarial loss: 0.423401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057114; batch adversarial loss: 0.435091\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073151; batch adversarial loss: 0.498884\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105402; batch adversarial loss: 0.456182\n",
      "epoch 102; iter: 0; batch classifier loss: 0.107715; batch adversarial loss: 0.369436\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058501; batch adversarial loss: 0.433350\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047602; batch adversarial loss: 0.534571\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049849; batch adversarial loss: 0.435795\n",
      "epoch 106; iter: 0; batch classifier loss: 0.097733; batch adversarial loss: 0.392630\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075295; batch adversarial loss: 0.431377\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.410960\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026260; batch adversarial loss: 0.469731\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054730; batch adversarial loss: 0.520388\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039575; batch adversarial loss: 0.451018\n",
      "epoch 112; iter: 0; batch classifier loss: 0.016402; batch adversarial loss: 0.529281\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049373; batch adversarial loss: 0.491635\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029093; batch adversarial loss: 0.419004\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058435; batch adversarial loss: 0.422338\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056489; batch adversarial loss: 0.444022\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051425; batch adversarial loss: 0.462754\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039339; batch adversarial loss: 0.500124\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039163; batch adversarial loss: 0.493269\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045195; batch adversarial loss: 0.521915\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026409; batch adversarial loss: 0.410597\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044501; batch adversarial loss: 0.448235\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031422; batch adversarial loss: 0.431797\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039540; batch adversarial loss: 0.483349\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018333; batch adversarial loss: 0.432512\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017029; batch adversarial loss: 0.430588\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029262; batch adversarial loss: 0.524493\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031745; batch adversarial loss: 0.431266\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.429070\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021188; batch adversarial loss: 0.463423\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030193; batch adversarial loss: 0.466960\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030798; batch adversarial loss: 0.476319\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019251; batch adversarial loss: 0.473186\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032354; batch adversarial loss: 0.394122\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017421; batch adversarial loss: 0.401176\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013588; batch adversarial loss: 0.312220\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019526; batch adversarial loss: 0.514904\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050937; batch adversarial loss: 0.416805\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022072; batch adversarial loss: 0.463358\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030467; batch adversarial loss: 0.526746\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011054; batch adversarial loss: 0.397210\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031441; batch adversarial loss: 0.431899\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028256; batch adversarial loss: 0.459741\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041434; batch adversarial loss: 0.451988\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019880; batch adversarial loss: 0.521967\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009365; batch adversarial loss: 0.468657\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024310; batch adversarial loss: 0.495975\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027477; batch adversarial loss: 0.460377\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027553; batch adversarial loss: 0.433655\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014464; batch adversarial loss: 0.481157\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017859; batch adversarial loss: 0.350087\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.485919\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030811; batch adversarial loss: 0.468699\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021633; batch adversarial loss: 0.405181\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028035; batch adversarial loss: 0.461719\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018632; batch adversarial loss: 0.362041\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018129; batch adversarial loss: 0.484255\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015003; batch adversarial loss: 0.513683\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009607; batch adversarial loss: 0.422763\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012187; batch adversarial loss: 0.384303\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007741; batch adversarial loss: 0.381552\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.487237\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007742; batch adversarial loss: 0.436746\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028618; batch adversarial loss: 0.374607\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040839; batch adversarial loss: 0.387510\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007996; batch adversarial loss: 0.378438\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006273; batch adversarial loss: 0.512275\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010543; batch adversarial loss: 0.492988\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011168; batch adversarial loss: 0.452745\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013800; batch adversarial loss: 0.579097\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010470; batch adversarial loss: 0.436049\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015105; batch adversarial loss: 0.557969\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013317; batch adversarial loss: 0.483302\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008702; batch adversarial loss: 0.421117\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010002; batch adversarial loss: 0.457733\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012839; batch adversarial loss: 0.490136\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015224; batch adversarial loss: 0.496298\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.404662\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007212; batch adversarial loss: 0.557701\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007420; batch adversarial loss: 0.464861\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006598; batch adversarial loss: 0.399178\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035193; batch adversarial loss: 0.383657\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005684; batch adversarial loss: 0.447929\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004326; batch adversarial loss: 0.426835\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027478; batch adversarial loss: 0.465125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.025516; batch adversarial loss: 0.392868\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023488; batch adversarial loss: 0.471151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021830; batch adversarial loss: 0.449492\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014407; batch adversarial loss: 0.404554\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012259; batch adversarial loss: 0.389533\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034938; batch adversarial loss: 0.491057\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008231; batch adversarial loss: 0.576557\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013989; batch adversarial loss: 0.434535\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015961; batch adversarial loss: 0.417120\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010778; batch adversarial loss: 0.436442\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014198; batch adversarial loss: 0.392605\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015891; batch adversarial loss: 0.464122\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031078; batch adversarial loss: 0.505929\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012113; batch adversarial loss: 0.461014\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706730; batch adversarial loss: 0.692217\n",
      "epoch 1; iter: 0; batch classifier loss: 0.574174; batch adversarial loss: 0.659728\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432754; batch adversarial loss: 0.626967\n",
      "epoch 3; iter: 0; batch classifier loss: 0.366148; batch adversarial loss: 0.615347\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419837; batch adversarial loss: 0.597105\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532198; batch adversarial loss: 0.569870\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437799; batch adversarial loss: 0.570633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435814; batch adversarial loss: 0.556273\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487947; batch adversarial loss: 0.526729\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453522; batch adversarial loss: 0.550501\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434712; batch adversarial loss: 0.511658\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391889; batch adversarial loss: 0.537301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398397; batch adversarial loss: 0.502331\n",
      "epoch 13; iter: 0; batch classifier loss: 0.422430; batch adversarial loss: 0.494301\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384103; batch adversarial loss: 0.497832\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253558; batch adversarial loss: 0.512813\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362603; batch adversarial loss: 0.528656\n",
      "epoch 17; iter: 0; batch classifier loss: 0.308093; batch adversarial loss: 0.474932\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308412; batch adversarial loss: 0.449394\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414637; batch adversarial loss: 0.424840\n",
      "epoch 20; iter: 0; batch classifier loss: 0.277780; batch adversarial loss: 0.510973\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347484; batch adversarial loss: 0.456518\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307999; batch adversarial loss: 0.421925\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273317; batch adversarial loss: 0.505754\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314995; batch adversarial loss: 0.512057\n",
      "epoch 25; iter: 0; batch classifier loss: 0.315792; batch adversarial loss: 0.458753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209397; batch adversarial loss: 0.486060\n",
      "epoch 27; iter: 0; batch classifier loss: 0.259729; batch adversarial loss: 0.509614\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274612; batch adversarial loss: 0.467555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.284109; batch adversarial loss: 0.509018\n",
      "epoch 30; iter: 0; batch classifier loss: 0.306376; batch adversarial loss: 0.465227\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307545; batch adversarial loss: 0.394946\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286364; batch adversarial loss: 0.406366\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264556; batch adversarial loss: 0.437897\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276095; batch adversarial loss: 0.486087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.323286; batch adversarial loss: 0.452755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248745; batch adversarial loss: 0.471334\n",
      "epoch 37; iter: 0; batch classifier loss: 0.259359; batch adversarial loss: 0.438142\n",
      "epoch 38; iter: 0; batch classifier loss: 0.312247; batch adversarial loss: 0.459601\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248418; batch adversarial loss: 0.391649\n",
      "epoch 40; iter: 0; batch classifier loss: 0.255519; batch adversarial loss: 0.379284\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252753; batch adversarial loss: 0.389761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.275977; batch adversarial loss: 0.484236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.214155; batch adversarial loss: 0.461994\n",
      "epoch 44; iter: 0; batch classifier loss: 0.257490; batch adversarial loss: 0.459085\n",
      "epoch 45; iter: 0; batch classifier loss: 0.190748; batch adversarial loss: 0.471065\n",
      "epoch 46; iter: 0; batch classifier loss: 0.157860; batch adversarial loss: 0.471014\n",
      "epoch 47; iter: 0; batch classifier loss: 0.198111; batch adversarial loss: 0.482702\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130819; batch adversarial loss: 0.408946\n",
      "epoch 49; iter: 0; batch classifier loss: 0.203615; batch adversarial loss: 0.433591\n",
      "epoch 50; iter: 0; batch classifier loss: 0.134797; batch adversarial loss: 0.458609\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129935; batch adversarial loss: 0.450165\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154814; batch adversarial loss: 0.437553\n",
      "epoch 53; iter: 0; batch classifier loss: 0.209689; batch adversarial loss: 0.386736\n",
      "epoch 54; iter: 0; batch classifier loss: 0.196656; batch adversarial loss: 0.461510\n",
      "epoch 55; iter: 0; batch classifier loss: 0.204813; batch adversarial loss: 0.447523\n",
      "epoch 56; iter: 0; batch classifier loss: 0.178924; batch adversarial loss: 0.497598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.174870; batch adversarial loss: 0.384521\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247834; batch adversarial loss: 0.433826\n",
      "epoch 59; iter: 0; batch classifier loss: 0.246098; batch adversarial loss: 0.409608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089066; batch adversarial loss: 0.471060\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080551; batch adversarial loss: 0.416767\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079985; batch adversarial loss: 0.482166\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062689; batch adversarial loss: 0.461989\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118608; batch adversarial loss: 0.438042\n",
      "epoch 65; iter: 0; batch classifier loss: 0.045162; batch adversarial loss: 0.408190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086490; batch adversarial loss: 0.434525\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133309; batch adversarial loss: 0.492141\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096326; batch adversarial loss: 0.416861\n",
      "epoch 69; iter: 0; batch classifier loss: 0.051050; batch adversarial loss: 0.411518\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109261; batch adversarial loss: 0.390901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086272; batch adversarial loss: 0.482101\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082666; batch adversarial loss: 0.464140\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047065; batch adversarial loss: 0.414408\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101220; batch adversarial loss: 0.435478\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093013; batch adversarial loss: 0.490614\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076687; batch adversarial loss: 0.462229\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071080; batch adversarial loss: 0.516700\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052313; batch adversarial loss: 0.446303\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063845; batch adversarial loss: 0.415034\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063931; batch adversarial loss: 0.409919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055751; batch adversarial loss: 0.432735\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063072; batch adversarial loss: 0.461659\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056895; batch adversarial loss: 0.392636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.056384; batch adversarial loss: 0.387662\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048488; batch adversarial loss: 0.359826\n",
      "epoch 86; iter: 0; batch classifier loss: 0.106333; batch adversarial loss: 0.460987\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041816; batch adversarial loss: 0.401203\n",
      "epoch 88; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.413326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064924; batch adversarial loss: 0.443933\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060971; batch adversarial loss: 0.397925\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052585; batch adversarial loss: 0.505982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069594; batch adversarial loss: 0.408952\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071710; batch adversarial loss: 0.430997\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042486; batch adversarial loss: 0.381585\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068998; batch adversarial loss: 0.340300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.122248; batch adversarial loss: 0.362953\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063243; batch adversarial loss: 0.471302\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.426049\n",
      "epoch 99; iter: 0; batch classifier loss: 0.068858; batch adversarial loss: 0.390009\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054771; batch adversarial loss: 0.400562\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031330; batch adversarial loss: 0.405308\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038349; batch adversarial loss: 0.416794\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033962; batch adversarial loss: 0.429587\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095819; batch adversarial loss: 0.333790\n",
      "epoch 105; iter: 0; batch classifier loss: 0.058522; batch adversarial loss: 0.439680\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051401; batch adversarial loss: 0.489400\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.389333\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057111; batch adversarial loss: 0.440157\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040699; batch adversarial loss: 0.445772\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045455; batch adversarial loss: 0.470126\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031573; batch adversarial loss: 0.438590\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049121; batch adversarial loss: 0.440926\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072458; batch adversarial loss: 0.503703\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054452; batch adversarial loss: 0.397958\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076564; batch adversarial loss: 0.465708\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056703; batch adversarial loss: 0.464824\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069739; batch adversarial loss: 0.452528\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068665; batch adversarial loss: 0.363647\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051664; batch adversarial loss: 0.364528\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064730; batch adversarial loss: 0.344765\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055220; batch adversarial loss: 0.484128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053115; batch adversarial loss: 0.338234\n",
      "epoch 123; iter: 0; batch classifier loss: 0.073151; batch adversarial loss: 0.416251\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052134; batch adversarial loss: 0.378091\n",
      "epoch 125; iter: 0; batch classifier loss: 0.074593; batch adversarial loss: 0.488167\n",
      "epoch 126; iter: 0; batch classifier loss: 0.074335; batch adversarial loss: 0.399303\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045942; batch adversarial loss: 0.364360\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045863; batch adversarial loss: 0.371691\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060552; batch adversarial loss: 0.366978\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047271; batch adversarial loss: 0.432027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037460; batch adversarial loss: 0.362067\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030180; batch adversarial loss: 0.415899\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060907; batch adversarial loss: 0.373912\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042431; batch adversarial loss: 0.485701\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058466; batch adversarial loss: 0.366363\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033156; batch adversarial loss: 0.537562\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048161; batch adversarial loss: 0.418887\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040637; batch adversarial loss: 0.385399\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.441476\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055524; batch adversarial loss: 0.491169\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051898; batch adversarial loss: 0.469675\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039997; batch adversarial loss: 0.376854\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041452; batch adversarial loss: 0.427549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041719; batch adversarial loss: 0.428861\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027901; batch adversarial loss: 0.423276\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024950; batch adversarial loss: 0.417235\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035764; batch adversarial loss: 0.433308\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032186; batch adversarial loss: 0.370556\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041969; batch adversarial loss: 0.524777\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023042; batch adversarial loss: 0.404296\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035250; batch adversarial loss: 0.371910\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.401452\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052210; batch adversarial loss: 0.411915\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027662; batch adversarial loss: 0.382044\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013679; batch adversarial loss: 0.436158\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.449513\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034678; batch adversarial loss: 0.434377\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028838; batch adversarial loss: 0.473459\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017867; batch adversarial loss: 0.402270\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023093; batch adversarial loss: 0.399083\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028085; batch adversarial loss: 0.426622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017116; batch adversarial loss: 0.474701\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015653; batch adversarial loss: 0.397315\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021151; batch adversarial loss: 0.433133\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024415; batch adversarial loss: 0.406733\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024290; batch adversarial loss: 0.439459\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029517; batch adversarial loss: 0.492259\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022362; batch adversarial loss: 0.456607\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019774; batch adversarial loss: 0.434585\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016523; batch adversarial loss: 0.453418\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031335; batch adversarial loss: 0.362501\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015369; batch adversarial loss: 0.500536\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041529; batch adversarial loss: 0.463452\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029053; batch adversarial loss: 0.331258\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.388040\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026461; batch adversarial loss: 0.465554\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022179; batch adversarial loss: 0.352257\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.425347\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022631; batch adversarial loss: 0.461535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.485037\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022964; batch adversarial loss: 0.537023\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037530; batch adversarial loss: 0.494764\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021168; batch adversarial loss: 0.416328\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012157; batch adversarial loss: 0.335275\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014597; batch adversarial loss: 0.367526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013245; batch adversarial loss: 0.442741\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044798; batch adversarial loss: 0.393801\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007974; batch adversarial loss: 0.344176\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016980; batch adversarial loss: 0.496821\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017299; batch adversarial loss: 0.430480\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033374; batch adversarial loss: 0.459288\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021291; batch adversarial loss: 0.469880\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009132; batch adversarial loss: 0.483597\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016215; batch adversarial loss: 0.435675\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012960; batch adversarial loss: 0.428660\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036837; batch adversarial loss: 0.400166\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013810; batch adversarial loss: 0.410956\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020315; batch adversarial loss: 0.420993\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035490; batch adversarial loss: 0.426512\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697546; batch adversarial loss: 0.577819\n",
      "epoch 1; iter: 0; batch classifier loss: 0.520765; batch adversarial loss: 0.614606\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388440; batch adversarial loss: 0.576057\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403039; batch adversarial loss: 0.587772\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351167; batch adversarial loss: 0.570225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422090; batch adversarial loss: 0.594753\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432101; batch adversarial loss: 0.594751\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544580; batch adversarial loss: 0.636680\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562851; batch adversarial loss: 0.608364\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604702; batch adversarial loss: 0.549970\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525092; batch adversarial loss: 0.546623\n",
      "epoch 11; iter: 0; batch classifier loss: 0.602722; batch adversarial loss: 0.515406\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467900; batch adversarial loss: 0.578722\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323611; batch adversarial loss: 0.530033\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303721; batch adversarial loss: 0.494339\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319427; batch adversarial loss: 0.499820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270762; batch adversarial loss: 0.495474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.271870; batch adversarial loss: 0.481522\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274002; batch adversarial loss: 0.479517\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295641; batch adversarial loss: 0.513526\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260273; batch adversarial loss: 0.575625\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225921; batch adversarial loss: 0.480199\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224614; batch adversarial loss: 0.556841\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254082; batch adversarial loss: 0.416885\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223853; batch adversarial loss: 0.507414\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215440; batch adversarial loss: 0.407676\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215220; batch adversarial loss: 0.463695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.259565; batch adversarial loss: 0.503594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194529; batch adversarial loss: 0.468049\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178408; batch adversarial loss: 0.364568\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217846; batch adversarial loss: 0.436554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.136515; batch adversarial loss: 0.413165\n",
      "epoch 32; iter: 0; batch classifier loss: 0.200067; batch adversarial loss: 0.494527\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203376; batch adversarial loss: 0.463460\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197345; batch adversarial loss: 0.465628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184179; batch adversarial loss: 0.533770\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150203; batch adversarial loss: 0.384454\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193055; batch adversarial loss: 0.357052\n",
      "epoch 38; iter: 0; batch classifier loss: 0.242341; batch adversarial loss: 0.453948\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268591; batch adversarial loss: 0.487430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.201263; batch adversarial loss: 0.432175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181826; batch adversarial loss: 0.524649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.183213; batch adversarial loss: 0.474650\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131467; batch adversarial loss: 0.448067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190735; batch adversarial loss: 0.476862\n",
      "epoch 45; iter: 0; batch classifier loss: 0.154945; batch adversarial loss: 0.532890\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187627; batch adversarial loss: 0.493157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.179614; batch adversarial loss: 0.506287\n",
      "epoch 48; iter: 0; batch classifier loss: 0.199322; batch adversarial loss: 0.457464\n",
      "epoch 49; iter: 0; batch classifier loss: 0.173058; batch adversarial loss: 0.549564\n",
      "epoch 50; iter: 0; batch classifier loss: 0.231909; batch adversarial loss: 0.462641\n",
      "epoch 51; iter: 0; batch classifier loss: 0.162451; batch adversarial loss: 0.412183\n",
      "epoch 52; iter: 0; batch classifier loss: 0.160978; batch adversarial loss: 0.421695\n",
      "epoch 53; iter: 0; batch classifier loss: 0.249816; batch adversarial loss: 0.444496\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214593; batch adversarial loss: 0.419827\n",
      "epoch 55; iter: 0; batch classifier loss: 0.179809; batch adversarial loss: 0.354281\n",
      "epoch 56; iter: 0; batch classifier loss: 0.288275; batch adversarial loss: 0.398116\n",
      "epoch 57; iter: 0; batch classifier loss: 0.227355; batch adversarial loss: 0.508364\n",
      "epoch 58; iter: 0; batch classifier loss: 0.223208; batch adversarial loss: 0.435193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.252691; batch adversarial loss: 0.413174\n",
      "epoch 60; iter: 0; batch classifier loss: 0.228291; batch adversarial loss: 0.515231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163540; batch adversarial loss: 0.482140\n",
      "epoch 62; iter: 0; batch classifier loss: 0.232819; batch adversarial loss: 0.455581\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204745; batch adversarial loss: 0.370207\n",
      "epoch 64; iter: 0; batch classifier loss: 0.209928; batch adversarial loss: 0.405604\n",
      "epoch 65; iter: 0; batch classifier loss: 0.174470; batch adversarial loss: 0.509538\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272142; batch adversarial loss: 0.459957\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185803; batch adversarial loss: 0.447537\n",
      "epoch 68; iter: 0; batch classifier loss: 0.197424; batch adversarial loss: 0.444679\n",
      "epoch 69; iter: 0; batch classifier loss: 0.224558; batch adversarial loss: 0.431114\n",
      "epoch 70; iter: 0; batch classifier loss: 0.231210; batch adversarial loss: 0.483986\n",
      "epoch 71; iter: 0; batch classifier loss: 0.189760; batch adversarial loss: 0.526256\n",
      "epoch 72; iter: 0; batch classifier loss: 0.216425; batch adversarial loss: 0.389499\n",
      "epoch 73; iter: 0; batch classifier loss: 0.230443; batch adversarial loss: 0.472605\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209940; batch adversarial loss: 0.571623\n",
      "epoch 75; iter: 0; batch classifier loss: 0.128769; batch adversarial loss: 0.473157\n",
      "epoch 76; iter: 0; batch classifier loss: 0.229311; batch adversarial loss: 0.479907\n",
      "epoch 77; iter: 0; batch classifier loss: 0.226803; batch adversarial loss: 0.396930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.183488; batch adversarial loss: 0.459213\n",
      "epoch 79; iter: 0; batch classifier loss: 0.260844; batch adversarial loss: 0.448153\n",
      "epoch 80; iter: 0; batch classifier loss: 0.223824; batch adversarial loss: 0.533175\n",
      "epoch 81; iter: 0; batch classifier loss: 0.153325; batch adversarial loss: 0.521078\n",
      "epoch 82; iter: 0; batch classifier loss: 0.235495; batch adversarial loss: 0.435638\n",
      "epoch 83; iter: 0; batch classifier loss: 0.187513; batch adversarial loss: 0.409228\n",
      "epoch 84; iter: 0; batch classifier loss: 0.263559; batch adversarial loss: 0.460917\n",
      "epoch 85; iter: 0; batch classifier loss: 0.218401; batch adversarial loss: 0.521494\n",
      "epoch 86; iter: 0; batch classifier loss: 0.273927; batch adversarial loss: 0.545379\n",
      "epoch 87; iter: 0; batch classifier loss: 0.260372; batch adversarial loss: 0.447063\n",
      "epoch 88; iter: 0; batch classifier loss: 0.230190; batch adversarial loss: 0.458314\n",
      "epoch 89; iter: 0; batch classifier loss: 0.259509; batch adversarial loss: 0.371275\n",
      "epoch 90; iter: 0; batch classifier loss: 0.282673; batch adversarial loss: 0.496114\n",
      "epoch 91; iter: 0; batch classifier loss: 0.181829; batch adversarial loss: 0.459066\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214532; batch adversarial loss: 0.483674\n",
      "epoch 93; iter: 0; batch classifier loss: 0.248335; batch adversarial loss: 0.420904\n",
      "epoch 94; iter: 0; batch classifier loss: 0.202842; batch adversarial loss: 0.497603\n",
      "epoch 95; iter: 0; batch classifier loss: 0.257161; batch adversarial loss: 0.472419\n",
      "epoch 96; iter: 0; batch classifier loss: 0.218161; batch adversarial loss: 0.408733\n",
      "epoch 97; iter: 0; batch classifier loss: 0.269633; batch adversarial loss: 0.409330\n",
      "epoch 98; iter: 0; batch classifier loss: 0.251970; batch adversarial loss: 0.471319\n",
      "epoch 99; iter: 0; batch classifier loss: 0.282222; batch adversarial loss: 0.346447\n",
      "epoch 100; iter: 0; batch classifier loss: 0.246514; batch adversarial loss: 0.509168\n",
      "epoch 101; iter: 0; batch classifier loss: 0.136444; batch adversarial loss: 0.483381\n",
      "epoch 102; iter: 0; batch classifier loss: 0.162688; batch adversarial loss: 0.407119\n",
      "epoch 103; iter: 0; batch classifier loss: 0.151987; batch adversarial loss: 0.480432\n",
      "epoch 104; iter: 0; batch classifier loss: 0.203159; batch adversarial loss: 0.420636\n",
      "epoch 105; iter: 0; batch classifier loss: 0.265062; batch adversarial loss: 0.470440\n",
      "epoch 106; iter: 0; batch classifier loss: 0.245256; batch adversarial loss: 0.483122\n",
      "epoch 107; iter: 0; batch classifier loss: 0.201979; batch adversarial loss: 0.447885\n",
      "epoch 108; iter: 0; batch classifier loss: 0.256238; batch adversarial loss: 0.459301\n",
      "epoch 109; iter: 0; batch classifier loss: 0.275458; batch adversarial loss: 0.483072\n",
      "epoch 110; iter: 0; batch classifier loss: 0.168903; batch adversarial loss: 0.395016\n",
      "epoch 111; iter: 0; batch classifier loss: 0.247551; batch adversarial loss: 0.433854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.254379; batch adversarial loss: 0.446416\n",
      "epoch 113; iter: 0; batch classifier loss: 0.209943; batch adversarial loss: 0.459562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.289490; batch adversarial loss: 0.433882\n",
      "epoch 115; iter: 0; batch classifier loss: 0.234620; batch adversarial loss: 0.471046\n",
      "epoch 116; iter: 0; batch classifier loss: 0.175325; batch adversarial loss: 0.507931\n",
      "epoch 117; iter: 0; batch classifier loss: 0.236902; batch adversarial loss: 0.395688\n",
      "epoch 118; iter: 0; batch classifier loss: 0.215010; batch adversarial loss: 0.347563\n",
      "epoch 119; iter: 0; batch classifier loss: 0.149440; batch adversarial loss: 0.473117\n",
      "epoch 120; iter: 0; batch classifier loss: 0.227339; batch adversarial loss: 0.471500\n",
      "epoch 121; iter: 0; batch classifier loss: 0.339236; batch adversarial loss: 0.422983\n",
      "epoch 122; iter: 0; batch classifier loss: 0.196496; batch adversarial loss: 0.445584\n",
      "epoch 123; iter: 0; batch classifier loss: 0.248609; batch adversarial loss: 0.383289\n",
      "epoch 124; iter: 0; batch classifier loss: 0.239857; batch adversarial loss: 0.419927\n",
      "epoch 125; iter: 0; batch classifier loss: 0.272809; batch adversarial loss: 0.396010\n",
      "epoch 126; iter: 0; batch classifier loss: 0.165661; batch adversarial loss: 0.535507\n",
      "epoch 127; iter: 0; batch classifier loss: 0.200699; batch adversarial loss: 0.495010\n",
      "epoch 128; iter: 0; batch classifier loss: 0.231516; batch adversarial loss: 0.396463\n",
      "epoch 129; iter: 0; batch classifier loss: 0.212047; batch adversarial loss: 0.420550\n",
      "epoch 130; iter: 0; batch classifier loss: 0.202298; batch adversarial loss: 0.459088\n",
      "epoch 131; iter: 0; batch classifier loss: 0.132313; batch adversarial loss: 0.446441\n",
      "epoch 132; iter: 0; batch classifier loss: 0.197760; batch adversarial loss: 0.473890\n",
      "epoch 133; iter: 0; batch classifier loss: 0.183800; batch adversarial loss: 0.431259\n",
      "epoch 134; iter: 0; batch classifier loss: 0.177865; batch adversarial loss: 0.496046\n",
      "epoch 135; iter: 0; batch classifier loss: 0.175978; batch adversarial loss: 0.358884\n",
      "epoch 136; iter: 0; batch classifier loss: 0.159934; batch adversarial loss: 0.459119\n",
      "epoch 137; iter: 0; batch classifier loss: 0.181508; batch adversarial loss: 0.483869\n",
      "epoch 138; iter: 0; batch classifier loss: 0.148875; batch adversarial loss: 0.395891\n",
      "epoch 139; iter: 0; batch classifier loss: 0.148846; batch adversarial loss: 0.607513\n",
      "epoch 140; iter: 0; batch classifier loss: 0.131264; batch adversarial loss: 0.302445\n",
      "epoch 141; iter: 0; batch classifier loss: 0.107748; batch adversarial loss: 0.395588\n",
      "epoch 142; iter: 0; batch classifier loss: 0.086306; batch adversarial loss: 0.509900\n",
      "epoch 143; iter: 0; batch classifier loss: 0.077889; batch adversarial loss: 0.501123\n",
      "epoch 144; iter: 0; batch classifier loss: 0.065340; batch adversarial loss: 0.352313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.049553; batch adversarial loss: 0.402936\n",
      "epoch 146; iter: 0; batch classifier loss: 0.057535; batch adversarial loss: 0.443729\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036246; batch adversarial loss: 0.498699\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057591; batch adversarial loss: 0.530934\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034223; batch adversarial loss: 0.495545\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019160; batch adversarial loss: 0.515179\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054873; batch adversarial loss: 0.370178\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039542; batch adversarial loss: 0.482913\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035726; batch adversarial loss: 0.365635\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020717; batch adversarial loss: 0.438965\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031515; batch adversarial loss: 0.491590\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033335; batch adversarial loss: 0.400483\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047068; batch adversarial loss: 0.453783\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036870; batch adversarial loss: 0.459828\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033346; batch adversarial loss: 0.406991\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034756; batch adversarial loss: 0.380616\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038679; batch adversarial loss: 0.453896\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.366347\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022226; batch adversarial loss: 0.446714\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025023; batch adversarial loss: 0.499714\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035523; batch adversarial loss: 0.374020\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011817; batch adversarial loss: 0.501760\n",
      "epoch 167; iter: 0; batch classifier loss: 0.065320; batch adversarial loss: 0.358142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048963; batch adversarial loss: 0.391961\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019894; batch adversarial loss: 0.429103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026321; batch adversarial loss: 0.468168\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028486; batch adversarial loss: 0.479422\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022010; batch adversarial loss: 0.478335\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017125; batch adversarial loss: 0.527218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.007546; batch adversarial loss: 0.374697\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.499316\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033097; batch adversarial loss: 0.387879\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026937; batch adversarial loss: 0.425283\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013804; batch adversarial loss: 0.438688\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013335; batch adversarial loss: 0.436089\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048381; batch adversarial loss: 0.412176\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017500; batch adversarial loss: 0.409680\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022815; batch adversarial loss: 0.377017\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025333; batch adversarial loss: 0.398152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026109; batch adversarial loss: 0.353112\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021472; batch adversarial loss: 0.483769\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008473; batch adversarial loss: 0.444495\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034566; batch adversarial loss: 0.499788\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031927; batch adversarial loss: 0.443505\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039980; batch adversarial loss: 0.543114\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029915; batch adversarial loss: 0.487811\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027792; batch adversarial loss: 0.504140\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024455; batch adversarial loss: 0.383758\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010021; batch adversarial loss: 0.428244\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026493; batch adversarial loss: 0.491169\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011726; batch adversarial loss: 0.436455\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017580; batch adversarial loss: 0.435090\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009590; batch adversarial loss: 0.430162\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036953; batch adversarial loss: 0.409529\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048126; batch adversarial loss: 0.447798\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686049; batch adversarial loss: 0.934578\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586095; batch adversarial loss: 0.986094\n",
      "epoch 2; iter: 0; batch classifier loss: 0.777569; batch adversarial loss: 1.032766\n",
      "epoch 3; iter: 0; batch classifier loss: 0.928517; batch adversarial loss: 0.952773\n",
      "epoch 4; iter: 0; batch classifier loss: 1.065990; batch adversarial loss: 0.861391\n",
      "epoch 5; iter: 0; batch classifier loss: 1.003633; batch adversarial loss: 0.774300\n",
      "epoch 6; iter: 0; batch classifier loss: 1.085139; batch adversarial loss: 0.705904\n",
      "epoch 7; iter: 0; batch classifier loss: 0.942017; batch adversarial loss: 0.641086\n",
      "epoch 8; iter: 0; batch classifier loss: 1.015283; batch adversarial loss: 0.580302\n",
      "epoch 9; iter: 0; batch classifier loss: 0.652558; batch adversarial loss: 0.520057\n",
      "epoch 10; iter: 0; batch classifier loss: 0.360807; batch adversarial loss: 0.535299\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310889; batch adversarial loss: 0.545239\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372342; batch adversarial loss: 0.515874\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307053; batch adversarial loss: 0.499167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333538; batch adversarial loss: 0.532991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348780; batch adversarial loss: 0.456394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313827; batch adversarial loss: 0.502690\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357474; batch adversarial loss: 0.487582\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336861; batch adversarial loss: 0.506716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276680; batch adversarial loss: 0.478368\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316328; batch adversarial loss: 0.485168\n",
      "epoch 21; iter: 0; batch classifier loss: 0.316755; batch adversarial loss: 0.458654\n",
      "epoch 22; iter: 0; batch classifier loss: 0.337483; batch adversarial loss: 0.468406\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379015; batch adversarial loss: 0.479199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.247431; batch adversarial loss: 0.464090\n",
      "epoch 25; iter: 0; batch classifier loss: 0.353814; batch adversarial loss: 0.528204\n",
      "epoch 26; iter: 0; batch classifier loss: 0.344149; batch adversarial loss: 0.456403\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315881; batch adversarial loss: 0.491412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315323; batch adversarial loss: 0.513314\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338865; batch adversarial loss: 0.454389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.325044; batch adversarial loss: 0.499478\n",
      "epoch 31; iter: 0; batch classifier loss: 0.318760; batch adversarial loss: 0.429284\n",
      "epoch 32; iter: 0; batch classifier loss: 0.345651; batch adversarial loss: 0.508531\n",
      "epoch 33; iter: 0; batch classifier loss: 0.340148; batch adversarial loss: 0.433087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230952; batch adversarial loss: 0.492316\n",
      "epoch 35; iter: 0; batch classifier loss: 0.250148; batch adversarial loss: 0.497364\n",
      "epoch 36; iter: 0; batch classifier loss: 0.285420; batch adversarial loss: 0.442799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.330668; batch adversarial loss: 0.461900\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340288; batch adversarial loss: 0.453082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.280201; batch adversarial loss: 0.451587\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328467; batch adversarial loss: 0.395536\n",
      "epoch 41; iter: 0; batch classifier loss: 0.323881; batch adversarial loss: 0.468488\n",
      "epoch 42; iter: 0; batch classifier loss: 0.296963; batch adversarial loss: 0.473192\n",
      "epoch 43; iter: 0; batch classifier loss: 0.218519; batch adversarial loss: 0.484148\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247646; batch adversarial loss: 0.520458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.233091; batch adversarial loss: 0.507984\n",
      "epoch 46; iter: 0; batch classifier loss: 0.233107; batch adversarial loss: 0.496207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.245378; batch adversarial loss: 0.568356\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186905; batch adversarial loss: 0.444382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.252185; batch adversarial loss: 0.411022\n",
      "epoch 50; iter: 0; batch classifier loss: 0.189063; batch adversarial loss: 0.444580\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231344; batch adversarial loss: 0.494442\n",
      "epoch 52; iter: 0; batch classifier loss: 0.200911; batch adversarial loss: 0.584178\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224721; batch adversarial loss: 0.494939\n",
      "epoch 54; iter: 0; batch classifier loss: 0.278758; batch adversarial loss: 0.423611\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215312; batch adversarial loss: 0.483890\n",
      "epoch 56; iter: 0; batch classifier loss: 0.258114; batch adversarial loss: 0.480584\n",
      "epoch 57; iter: 0; batch classifier loss: 0.235159; batch adversarial loss: 0.494406\n",
      "epoch 58; iter: 0; batch classifier loss: 0.249579; batch adversarial loss: 0.446187\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151299; batch adversarial loss: 0.481391\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204808; batch adversarial loss: 0.457900\n",
      "epoch 61; iter: 0; batch classifier loss: 0.231640; batch adversarial loss: 0.458144\n",
      "epoch 62; iter: 0; batch classifier loss: 0.196039; batch adversarial loss: 0.507239\n",
      "epoch 63; iter: 0; batch classifier loss: 0.285890; batch adversarial loss: 0.446725\n",
      "epoch 64; iter: 0; batch classifier loss: 0.159670; batch adversarial loss: 0.471239\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144523; batch adversarial loss: 0.572429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.213126; batch adversarial loss: 0.412636\n",
      "epoch 67; iter: 0; batch classifier loss: 0.208990; batch adversarial loss: 0.523688\n",
      "epoch 68; iter: 0; batch classifier loss: 0.174720; batch adversarial loss: 0.470243\n",
      "epoch 69; iter: 0; batch classifier loss: 0.261896; batch adversarial loss: 0.458200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.168306; batch adversarial loss: 0.571023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.213376; batch adversarial loss: 0.372139\n",
      "epoch 72; iter: 0; batch classifier loss: 0.215774; batch adversarial loss: 0.435094\n",
      "epoch 73; iter: 0; batch classifier loss: 0.266301; batch adversarial loss: 0.457815\n",
      "epoch 74; iter: 0; batch classifier loss: 0.203416; batch adversarial loss: 0.359100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.296409; batch adversarial loss: 0.383105\n",
      "epoch 76; iter: 0; batch classifier loss: 0.268552; batch adversarial loss: 0.421411\n",
      "epoch 77; iter: 0; batch classifier loss: 0.218276; batch adversarial loss: 0.421240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.214579; batch adversarial loss: 0.333786\n",
      "epoch 79; iter: 0; batch classifier loss: 0.143456; batch adversarial loss: 0.446612\n",
      "epoch 80; iter: 0; batch classifier loss: 0.180965; batch adversarial loss: 0.496368\n",
      "epoch 81; iter: 0; batch classifier loss: 0.087430; batch adversarial loss: 0.521477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.165607; batch adversarial loss: 0.446824\n",
      "epoch 83; iter: 0; batch classifier loss: 0.149030; batch adversarial loss: 0.474138\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107674; batch adversarial loss: 0.394937\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182171; batch adversarial loss: 0.599386\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206130; batch adversarial loss: 0.373724\n",
      "epoch 87; iter: 0; batch classifier loss: 0.278438; batch adversarial loss: 0.410492\n",
      "epoch 88; iter: 0; batch classifier loss: 0.215610; batch adversarial loss: 0.483024\n",
      "epoch 89; iter: 0; batch classifier loss: 0.172232; batch adversarial loss: 0.398137\n",
      "epoch 90; iter: 0; batch classifier loss: 0.149566; batch adversarial loss: 0.520218\n",
      "epoch 91; iter: 0; batch classifier loss: 0.252996; batch adversarial loss: 0.396186\n",
      "epoch 92; iter: 0; batch classifier loss: 0.206998; batch adversarial loss: 0.409767\n",
      "epoch 93; iter: 0; batch classifier loss: 0.155104; batch adversarial loss: 0.585006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.192273; batch adversarial loss: 0.396300\n",
      "epoch 95; iter: 0; batch classifier loss: 0.270515; batch adversarial loss: 0.447307\n",
      "epoch 96; iter: 0; batch classifier loss: 0.205121; batch adversarial loss: 0.496597\n",
      "epoch 97; iter: 0; batch classifier loss: 0.231374; batch adversarial loss: 0.433607\n",
      "epoch 98; iter: 0; batch classifier loss: 0.133691; batch adversarial loss: 0.421337\n",
      "epoch 99; iter: 0; batch classifier loss: 0.123739; batch adversarial loss: 0.571496\n",
      "epoch 100; iter: 0; batch classifier loss: 0.306501; batch adversarial loss: 0.409426\n",
      "epoch 101; iter: 0; batch classifier loss: 0.212922; batch adversarial loss: 0.484706\n",
      "epoch 102; iter: 0; batch classifier loss: 0.227180; batch adversarial loss: 0.446645\n",
      "epoch 103; iter: 0; batch classifier loss: 0.262738; batch adversarial loss: 0.408567\n",
      "epoch 104; iter: 0; batch classifier loss: 0.341346; batch adversarial loss: 0.396252\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071982; batch adversarial loss: 0.407708\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056178; batch adversarial loss: 0.365618\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036373; batch adversarial loss: 0.467902\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039855; batch adversarial loss: 0.444698\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037670; batch adversarial loss: 0.418947\n",
      "epoch 110; iter: 0; batch classifier loss: 0.038663; batch adversarial loss: 0.427446\n",
      "epoch 111; iter: 0; batch classifier loss: 0.088734; batch adversarial loss: 0.471843\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071204; batch adversarial loss: 0.387687\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071013; batch adversarial loss: 0.561235\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055036; batch adversarial loss: 0.348956\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057374; batch adversarial loss: 0.454262\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038072; batch adversarial loss: 0.356683\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036410; batch adversarial loss: 0.330672\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046297; batch adversarial loss: 0.398050\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024955; batch adversarial loss: 0.403914\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059658; batch adversarial loss: 0.474097\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040196; batch adversarial loss: 0.403548\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021901; batch adversarial loss: 0.426254\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050322; batch adversarial loss: 0.439130\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.397466\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021559; batch adversarial loss: 0.460369\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047316; batch adversarial loss: 0.386805\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022374; batch adversarial loss: 0.442941\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034151; batch adversarial loss: 0.465683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066882; batch adversarial loss: 0.491484\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018191; batch adversarial loss: 0.451326\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037098; batch adversarial loss: 0.407962\n",
      "epoch 132; iter: 0; batch classifier loss: 0.069658; batch adversarial loss: 0.391688\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062856; batch adversarial loss: 0.341324\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034222; batch adversarial loss: 0.467648\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019440; batch adversarial loss: 0.299133\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021316; batch adversarial loss: 0.481344\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030067; batch adversarial loss: 0.466915\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.514328\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017340; batch adversarial loss: 0.389719\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032897; batch adversarial loss: 0.351408\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021749; batch adversarial loss: 0.492446\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027174; batch adversarial loss: 0.450305\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.527154\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018336; batch adversarial loss: 0.371860\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020985; batch adversarial loss: 0.459467\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028943; batch adversarial loss: 0.468455\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017586; batch adversarial loss: 0.419752\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023455; batch adversarial loss: 0.345148\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036763; batch adversarial loss: 0.407003\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030510; batch adversarial loss: 0.495526\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030473; batch adversarial loss: 0.522581\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012407; batch adversarial loss: 0.463933\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.396686\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016961; batch adversarial loss: 0.469093\n",
      "epoch 155; iter: 0; batch classifier loss: 0.007557; batch adversarial loss: 0.489736\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025150; batch adversarial loss: 0.511938\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021522; batch adversarial loss: 0.408219\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025159; batch adversarial loss: 0.364261\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.442634\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011906; batch adversarial loss: 0.396371\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041028; batch adversarial loss: 0.384533\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010264; batch adversarial loss: 0.520190\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012318; batch adversarial loss: 0.472017\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006673; batch adversarial loss: 0.494794\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014921; batch adversarial loss: 0.520349\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020941; batch adversarial loss: 0.503999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.006034; batch adversarial loss: 0.441600\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013711; batch adversarial loss: 0.459187\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044007; batch adversarial loss: 0.586756\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006838; batch adversarial loss: 0.390302\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020634; batch adversarial loss: 0.488330\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007364; batch adversarial loss: 0.404783\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009168; batch adversarial loss: 0.418167\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011570; batch adversarial loss: 0.484798\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028840; batch adversarial loss: 0.480487\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034153; batch adversarial loss: 0.540462\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017284; batch adversarial loss: 0.475009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035318; batch adversarial loss: 0.433676\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006156; batch adversarial loss: 0.420816\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013148; batch adversarial loss: 0.417720\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037505; batch adversarial loss: 0.403355\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007540; batch adversarial loss: 0.418624\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021668; batch adversarial loss: 0.389904\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041393; batch adversarial loss: 0.421339\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003691; batch adversarial loss: 0.339319\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013151; batch adversarial loss: 0.436196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027379; batch adversarial loss: 0.436983\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006647; batch adversarial loss: 0.377892\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008556; batch adversarial loss: 0.421953\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008997; batch adversarial loss: 0.355828\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002474; batch adversarial loss: 0.464871\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012021; batch adversarial loss: 0.452924\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004995; batch adversarial loss: 0.414881\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003276; batch adversarial loss: 0.499954\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012206; batch adversarial loss: 0.439037\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002901; batch adversarial loss: 0.440462\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015537; batch adversarial loss: 0.447585\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004740; batch adversarial loss: 0.452142\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014006; batch adversarial loss: 0.572197\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697038; batch adversarial loss: 0.731639\n",
      "epoch 1; iter: 0; batch classifier loss: 0.486258; batch adversarial loss: 0.684389\n",
      "epoch 2; iter: 0; batch classifier loss: 0.359353; batch adversarial loss: 0.656227\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401916; batch adversarial loss: 0.614076\n",
      "epoch 4; iter: 0; batch classifier loss: 0.322292; batch adversarial loss: 0.562873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342909; batch adversarial loss: 0.543802\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311332; batch adversarial loss: 0.522809\n",
      "epoch 7; iter: 0; batch classifier loss: 0.255868; batch adversarial loss: 0.527259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.247213; batch adversarial loss: 0.474509\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282359; batch adversarial loss: 0.485940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254724; batch adversarial loss: 0.585055\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235694; batch adversarial loss: 0.450301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234057; batch adversarial loss: 0.438943\n",
      "epoch 13; iter: 0; batch classifier loss: 0.212796; batch adversarial loss: 0.477489\n",
      "epoch 14; iter: 0; batch classifier loss: 0.174206; batch adversarial loss: 0.460118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190039; batch adversarial loss: 0.386675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.201511; batch adversarial loss: 0.447397\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196936; batch adversarial loss: 0.412404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.159131; batch adversarial loss: 0.446108\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236693; batch adversarial loss: 0.377029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.141713; batch adversarial loss: 0.473394\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197248; batch adversarial loss: 0.431353\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168440; batch adversarial loss: 0.368399\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159930; batch adversarial loss: 0.391410\n",
      "epoch 24; iter: 0; batch classifier loss: 0.156613; batch adversarial loss: 0.471403\n",
      "epoch 25; iter: 0; batch classifier loss: 0.167780; batch adversarial loss: 0.462889\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173630; batch adversarial loss: 0.403891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.133945; batch adversarial loss: 0.447425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147930; batch adversarial loss: 0.382087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.107552; batch adversarial loss: 0.360918\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131356; batch adversarial loss: 0.421552\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137371; batch adversarial loss: 0.397730\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129538; batch adversarial loss: 0.484906\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144530; batch adversarial loss: 0.476773\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176050; batch adversarial loss: 0.404890\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121381; batch adversarial loss: 0.408468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149482; batch adversarial loss: 0.404410\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105993; batch adversarial loss: 0.400299\n",
      "epoch 38; iter: 0; batch classifier loss: 0.145648; batch adversarial loss: 0.382580\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104904; batch adversarial loss: 0.355453\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109491; batch adversarial loss: 0.464617\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131722; batch adversarial loss: 0.468380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144450; batch adversarial loss: 0.413643\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121265; batch adversarial loss: 0.437243\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102019; batch adversarial loss: 0.361929\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065719; batch adversarial loss: 0.393532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077412; batch adversarial loss: 0.388199\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095769; batch adversarial loss: 0.476180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.091663; batch adversarial loss: 0.403349\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077974; batch adversarial loss: 0.379879\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103733; batch adversarial loss: 0.409190\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081761; batch adversarial loss: 0.295455\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083623; batch adversarial loss: 0.425534\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062343; batch adversarial loss: 0.388431\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112982; batch adversarial loss: 0.432199\n",
      "epoch 55; iter: 0; batch classifier loss: 0.060508; batch adversarial loss: 0.373216\n",
      "epoch 56; iter: 0; batch classifier loss: 0.041062; batch adversarial loss: 0.324882\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071541; batch adversarial loss: 0.431670\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059595; batch adversarial loss: 0.353900\n",
      "epoch 59; iter: 0; batch classifier loss: 0.047238; batch adversarial loss: 0.459812\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047378; batch adversarial loss: 0.431312\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081716; batch adversarial loss: 0.451244\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093507; batch adversarial loss: 0.374084\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073110; batch adversarial loss: 0.507721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.123880; batch adversarial loss: 0.469430\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116755; batch adversarial loss: 0.476900\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062452; batch adversarial loss: 0.345267\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090223; batch adversarial loss: 0.444386\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075721; batch adversarial loss: 0.419479\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068629; batch adversarial loss: 0.429596\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086284; batch adversarial loss: 0.393623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.035144; batch adversarial loss: 0.424407\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073883; batch adversarial loss: 0.460810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079891; batch adversarial loss: 0.449220\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072243; batch adversarial loss: 0.427179\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057068; batch adversarial loss: 0.512197\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061223; batch adversarial loss: 0.395442\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101585; batch adversarial loss: 0.400755\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066586; batch adversarial loss: 0.389464\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062029; batch adversarial loss: 0.346498\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078534; batch adversarial loss: 0.420179\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058210; batch adversarial loss: 0.362670\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074782; batch adversarial loss: 0.410901\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069614; batch adversarial loss: 0.421100\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053002; batch adversarial loss: 0.450627\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061597; batch adversarial loss: 0.353803\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063822; batch adversarial loss: 0.435937\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047568; batch adversarial loss: 0.374104\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051525; batch adversarial loss: 0.381211\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069585; batch adversarial loss: 0.396622\n",
      "epoch 90; iter: 0; batch classifier loss: 0.071111; batch adversarial loss: 0.375262\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062170; batch adversarial loss: 0.433883\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067428; batch adversarial loss: 0.444507\n",
      "epoch 93; iter: 0; batch classifier loss: 0.085016; batch adversarial loss: 0.411134\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086283; batch adversarial loss: 0.416689\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051585; batch adversarial loss: 0.415030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035566; batch adversarial loss: 0.417097\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052746; batch adversarial loss: 0.434806\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080981; batch adversarial loss: 0.502001\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050522; batch adversarial loss: 0.446369\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063116; batch adversarial loss: 0.419234\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073857; batch adversarial loss: 0.475746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079098; batch adversarial loss: 0.459954\n",
      "epoch 103; iter: 0; batch classifier loss: 0.020726; batch adversarial loss: 0.437202\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059998; batch adversarial loss: 0.418663\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026023; batch adversarial loss: 0.420353\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071743; batch adversarial loss: 0.409489\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032216; batch adversarial loss: 0.395792\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055778; batch adversarial loss: 0.439348\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066955; batch adversarial loss: 0.456270\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039041; batch adversarial loss: 0.465332\n",
      "epoch 111; iter: 0; batch classifier loss: 0.079468; batch adversarial loss: 0.416301\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.401005\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031991; batch adversarial loss: 0.428354\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035183; batch adversarial loss: 0.407501\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024647; batch adversarial loss: 0.454288\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023450; batch adversarial loss: 0.490724\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043897; batch adversarial loss: 0.446160\n",
      "epoch 118; iter: 0; batch classifier loss: 0.094936; batch adversarial loss: 0.305847\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033126; batch adversarial loss: 0.469495\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038246; batch adversarial loss: 0.346424\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031741; batch adversarial loss: 0.425902\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039556; batch adversarial loss: 0.415356\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028225; batch adversarial loss: 0.455102\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048558; batch adversarial loss: 0.486790\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029815; batch adversarial loss: 0.488486\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042416; batch adversarial loss: 0.420728\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028745; batch adversarial loss: 0.444059\n",
      "epoch 128; iter: 0; batch classifier loss: 0.046143; batch adversarial loss: 0.407970\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046108; batch adversarial loss: 0.434646\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058827; batch adversarial loss: 0.459942\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018197; batch adversarial loss: 0.527940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039861; batch adversarial loss: 0.392173\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043638; batch adversarial loss: 0.494175\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027486; batch adversarial loss: 0.488474\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036087; batch adversarial loss: 0.426181\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029667; batch adversarial loss: 0.420693\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049431; batch adversarial loss: 0.466054\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044789; batch adversarial loss: 0.584496\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054759; batch adversarial loss: 0.482121\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063795; batch adversarial loss: 0.587781\n",
      "epoch 141; iter: 0; batch classifier loss: 0.074882; batch adversarial loss: 0.484446\n",
      "epoch 142; iter: 0; batch classifier loss: 0.083958; batch adversarial loss: 0.508495\n",
      "epoch 143; iter: 0; batch classifier loss: 0.094057; batch adversarial loss: 0.733422\n",
      "epoch 144; iter: 0; batch classifier loss: 0.127969; batch adversarial loss: 0.647468\n",
      "epoch 145; iter: 0; batch classifier loss: 0.128872; batch adversarial loss: 0.595140\n",
      "epoch 146; iter: 0; batch classifier loss: 0.121069; batch adversarial loss: 0.632199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.142403; batch adversarial loss: 0.510501\n",
      "epoch 148; iter: 0; batch classifier loss: 0.164883; batch adversarial loss: 0.624378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.162480; batch adversarial loss: 0.689327\n",
      "epoch 150; iter: 0; batch classifier loss: 0.091232; batch adversarial loss: 0.399755\n",
      "epoch 151; iter: 0; batch classifier loss: 0.134113; batch adversarial loss: 0.646767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.148147; batch adversarial loss: 0.633580\n",
      "epoch 153; iter: 0; batch classifier loss: 0.224002; batch adversarial loss: 0.761005\n",
      "epoch 154; iter: 0; batch classifier loss: 0.223627; batch adversarial loss: 0.657647\n",
      "epoch 155; iter: 0; batch classifier loss: 0.149052; batch adversarial loss: 0.546368\n",
      "epoch 156; iter: 0; batch classifier loss: 0.162711; batch adversarial loss: 0.634314\n",
      "epoch 157; iter: 0; batch classifier loss: 0.156759; batch adversarial loss: 0.611248\n",
      "epoch 158; iter: 0; batch classifier loss: 0.121906; batch adversarial loss: 0.650895\n",
      "epoch 159; iter: 0; batch classifier loss: 0.170628; batch adversarial loss: 0.545347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.211552; batch adversarial loss: 0.637453\n",
      "epoch 161; iter: 0; batch classifier loss: 0.086964; batch adversarial loss: 0.480439\n",
      "epoch 162; iter: 0; batch classifier loss: 0.160754; batch adversarial loss: 0.564640\n",
      "epoch 163; iter: 0; batch classifier loss: 0.161457; batch adversarial loss: 0.539556\n",
      "epoch 164; iter: 0; batch classifier loss: 0.126634; batch adversarial loss: 0.497345\n",
      "epoch 165; iter: 0; batch classifier loss: 0.100145; batch adversarial loss: 0.567607\n",
      "epoch 166; iter: 0; batch classifier loss: 0.164845; batch adversarial loss: 0.576208\n",
      "epoch 167; iter: 0; batch classifier loss: 0.143695; batch adversarial loss: 0.501067\n",
      "epoch 168; iter: 0; batch classifier loss: 0.219617; batch adversarial loss: 0.665374\n",
      "epoch 169; iter: 0; batch classifier loss: 0.129000; batch adversarial loss: 0.489877\n",
      "epoch 170; iter: 0; batch classifier loss: 0.129194; batch adversarial loss: 0.480924\n",
      "epoch 171; iter: 0; batch classifier loss: 0.139078; batch adversarial loss: 0.522924\n",
      "epoch 172; iter: 0; batch classifier loss: 0.082923; batch adversarial loss: 0.357546\n",
      "epoch 173; iter: 0; batch classifier loss: 0.147150; batch adversarial loss: 0.443651\n",
      "epoch 174; iter: 0; batch classifier loss: 0.118179; batch adversarial loss: 0.553225\n",
      "epoch 175; iter: 0; batch classifier loss: 0.081051; batch adversarial loss: 0.435764\n",
      "epoch 176; iter: 0; batch classifier loss: 0.085886; batch adversarial loss: 0.439755\n",
      "epoch 177; iter: 0; batch classifier loss: 0.147575; batch adversarial loss: 0.535563\n",
      "epoch 178; iter: 0; batch classifier loss: 0.126398; batch adversarial loss: 0.483053\n",
      "epoch 179; iter: 0; batch classifier loss: 0.071234; batch adversarial loss: 0.404283\n",
      "epoch 180; iter: 0; batch classifier loss: 0.077007; batch adversarial loss: 0.398853\n",
      "epoch 181; iter: 0; batch classifier loss: 0.081804; batch adversarial loss: 0.321940\n",
      "epoch 182; iter: 0; batch classifier loss: 0.088823; batch adversarial loss: 0.461611\n",
      "epoch 183; iter: 0; batch classifier loss: 0.061514; batch adversarial loss: 0.626628\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026370; batch adversarial loss: 0.545790\n",
      "epoch 185; iter: 0; batch classifier loss: 0.086474; batch adversarial loss: 0.425144\n",
      "epoch 186; iter: 0; batch classifier loss: 0.073990; batch adversarial loss: 0.547946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040741; batch adversarial loss: 0.434638\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018998; batch adversarial loss: 0.488140\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008911; batch adversarial loss: 0.413640\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025623; batch adversarial loss: 0.462825\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053249; batch adversarial loss: 0.524736\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017741; batch adversarial loss: 0.483029\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048955; batch adversarial loss: 0.483278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028939; batch adversarial loss: 0.463422\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032633; batch adversarial loss: 0.408097\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037176; batch adversarial loss: 0.439071\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038720; batch adversarial loss: 0.442694\n",
      "epoch 198; iter: 0; batch classifier loss: 0.073710; batch adversarial loss: 0.443551\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025987; batch adversarial loss: 0.431063\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682121; batch adversarial loss: 0.708704\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489569; batch adversarial loss: 0.673285\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445148; batch adversarial loss: 0.639061\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321382; batch adversarial loss: 0.591693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458452; batch adversarial loss: 0.561825\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293112; batch adversarial loss: 0.528818\n",
      "epoch 6; iter: 0; batch classifier loss: 0.380382; batch adversarial loss: 0.510330\n",
      "epoch 7; iter: 0; batch classifier loss: 0.347849; batch adversarial loss: 0.499505\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270453; batch adversarial loss: 0.523357\n",
      "epoch 9; iter: 0; batch classifier loss: 0.272136; batch adversarial loss: 0.495769\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280464; batch adversarial loss: 0.436657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.197939; batch adversarial loss: 0.478487\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241095; batch adversarial loss: 0.386149\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236077; batch adversarial loss: 0.472053\n",
      "epoch 14; iter: 0; batch classifier loss: 0.197515; batch adversarial loss: 0.449666\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191895; batch adversarial loss: 0.462873\n",
      "epoch 16; iter: 0; batch classifier loss: 0.131737; batch adversarial loss: 0.462257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.174098; batch adversarial loss: 0.348980\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220021; batch adversarial loss: 0.387548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.107486; batch adversarial loss: 0.496508\n",
      "epoch 20; iter: 0; batch classifier loss: 0.141064; batch adversarial loss: 0.404383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175249; batch adversarial loss: 0.424919\n",
      "epoch 22; iter: 0; batch classifier loss: 0.098630; batch adversarial loss: 0.507735\n",
      "epoch 23; iter: 0; batch classifier loss: 0.149081; batch adversarial loss: 0.495675\n",
      "epoch 24; iter: 0; batch classifier loss: 0.134201; batch adversarial loss: 0.515519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132976; batch adversarial loss: 0.508762\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165531; batch adversarial loss: 0.418782\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211896; batch adversarial loss: 0.430004\n",
      "epoch 28; iter: 0; batch classifier loss: 0.133198; batch adversarial loss: 0.469168\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176671; batch adversarial loss: 0.494739\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184208; batch adversarial loss: 0.478432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140112; batch adversarial loss: 0.438692\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187195; batch adversarial loss: 0.420095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.186183; batch adversarial loss: 0.422759\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158608; batch adversarial loss: 0.511939\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159078; batch adversarial loss: 0.451469\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240369; batch adversarial loss: 0.438696\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154504; batch adversarial loss: 0.369711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.088886; batch adversarial loss: 0.569684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120181; batch adversarial loss: 0.428832\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088783; batch adversarial loss: 0.407536\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086275; batch adversarial loss: 0.433625\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109180; batch adversarial loss: 0.387721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083297; batch adversarial loss: 0.415712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098448; batch adversarial loss: 0.382731\n",
      "epoch 45; iter: 0; batch classifier loss: 0.054500; batch adversarial loss: 0.439523\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095313; batch adversarial loss: 0.458052\n",
      "epoch 47; iter: 0; batch classifier loss: 0.069598; batch adversarial loss: 0.370995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.051952; batch adversarial loss: 0.449814\n",
      "epoch 49; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.443431\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098001; batch adversarial loss: 0.446331\n",
      "epoch 51; iter: 0; batch classifier loss: 0.051801; batch adversarial loss: 0.465155\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108854; batch adversarial loss: 0.425004\n",
      "epoch 53; iter: 0; batch classifier loss: 0.057945; batch adversarial loss: 0.426625\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074618; batch adversarial loss: 0.471220\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072683; batch adversarial loss: 0.449656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057622; batch adversarial loss: 0.593597\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086782; batch adversarial loss: 0.415797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.072938; batch adversarial loss: 0.485599\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079209; batch adversarial loss: 0.502382\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114607; batch adversarial loss: 0.526242\n",
      "epoch 61; iter: 0; batch classifier loss: 0.047899; batch adversarial loss: 0.365883\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113886; batch adversarial loss: 0.455614\n",
      "epoch 63; iter: 0; batch classifier loss: 0.068477; batch adversarial loss: 0.462215\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055503; batch adversarial loss: 0.399962\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071132; batch adversarial loss: 0.400323\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086524; batch adversarial loss: 0.328522\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114345; batch adversarial loss: 0.416656\n",
      "epoch 68; iter: 0; batch classifier loss: 0.042854; batch adversarial loss: 0.340963\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084636; batch adversarial loss: 0.443139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.043747; batch adversarial loss: 0.429738\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061359; batch adversarial loss: 0.411522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085331; batch adversarial loss: 0.512177\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075297; batch adversarial loss: 0.415496\n",
      "epoch 74; iter: 0; batch classifier loss: 0.040316; batch adversarial loss: 0.404384\n",
      "epoch 75; iter: 0; batch classifier loss: 0.053384; batch adversarial loss: 0.429761\n",
      "epoch 76; iter: 0; batch classifier loss: 0.033644; batch adversarial loss: 0.448896\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055727; batch adversarial loss: 0.425789\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091330; batch adversarial loss: 0.377496\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051037; batch adversarial loss: 0.457994\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067049; batch adversarial loss: 0.442098\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054374; batch adversarial loss: 0.328679\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054076; batch adversarial loss: 0.453423\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060597; batch adversarial loss: 0.346551\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095600; batch adversarial loss: 0.484787\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050945; batch adversarial loss: 0.574529\n",
      "epoch 86; iter: 0; batch classifier loss: 0.031481; batch adversarial loss: 0.556645\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090799; batch adversarial loss: 0.442904\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049686; batch adversarial loss: 0.465385\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073658; batch adversarial loss: 0.409141\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062613; batch adversarial loss: 0.512767\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055067; batch adversarial loss: 0.434943\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098196; batch adversarial loss: 0.437096\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038417; batch adversarial loss: 0.462358\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049922; batch adversarial loss: 0.493348\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041242; batch adversarial loss: 0.422879\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056751; batch adversarial loss: 0.387182\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067765; batch adversarial loss: 0.386782\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078378; batch adversarial loss: 0.451971\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051436; batch adversarial loss: 0.425527\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038090; batch adversarial loss: 0.525906\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043925; batch adversarial loss: 0.380768\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056759; batch adversarial loss: 0.490709\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062185; batch adversarial loss: 0.389193\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098696; batch adversarial loss: 0.406172\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060175; batch adversarial loss: 0.428506\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022112; batch adversarial loss: 0.431518\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045768; batch adversarial loss: 0.464374\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048535; batch adversarial loss: 0.439555\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037525; batch adversarial loss: 0.357233\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065668; batch adversarial loss: 0.394129\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029913; batch adversarial loss: 0.430935\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045028; batch adversarial loss: 0.526002\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035543; batch adversarial loss: 0.364205\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068490; batch adversarial loss: 0.502784\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064791; batch adversarial loss: 0.460889\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023485; batch adversarial loss: 0.453773\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.420599\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024291; batch adversarial loss: 0.434839\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035634; batch adversarial loss: 0.457060\n",
      "epoch 120; iter: 0; batch classifier loss: 0.029759; batch adversarial loss: 0.515648\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043142; batch adversarial loss: 0.404219\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061513; batch adversarial loss: 0.464516\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046143; batch adversarial loss: 0.366793\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040060; batch adversarial loss: 0.494161\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036464; batch adversarial loss: 0.400872\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036879; batch adversarial loss: 0.482344\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025816; batch adversarial loss: 0.417102\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031379; batch adversarial loss: 0.477315\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039502; batch adversarial loss: 0.443474\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023409; batch adversarial loss: 0.421831\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052523; batch adversarial loss: 0.364134\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015226; batch adversarial loss: 0.443334\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011066; batch adversarial loss: 0.457359\n",
      "epoch 134; iter: 0; batch classifier loss: 0.022780; batch adversarial loss: 0.455791\n",
      "epoch 135; iter: 0; batch classifier loss: 0.005345; batch adversarial loss: 0.445700\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040309; batch adversarial loss: 0.405364\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011962; batch adversarial loss: 0.376875\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.430149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022930; batch adversarial loss: 0.455692\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054035; batch adversarial loss: 0.429907\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022647; batch adversarial loss: 0.494529\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023655; batch adversarial loss: 0.361022\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027161; batch adversarial loss: 0.461795\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032353; batch adversarial loss: 0.446106\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018938; batch adversarial loss: 0.459916\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013190; batch adversarial loss: 0.570718\n",
      "epoch 147; iter: 0; batch classifier loss: 0.069717; batch adversarial loss: 0.390885\n",
      "epoch 148; iter: 0; batch classifier loss: 0.009449; batch adversarial loss: 0.558331\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019493; batch adversarial loss: 0.405837\n",
      "epoch 150; iter: 0; batch classifier loss: 0.092217; batch adversarial loss: 0.365139\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045584; batch adversarial loss: 0.388878\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040915; batch adversarial loss: 0.438813\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032866; batch adversarial loss: 0.414886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.018515; batch adversarial loss: 0.446655\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018104; batch adversarial loss: 0.543413\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027826; batch adversarial loss: 0.463952\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045126; batch adversarial loss: 0.421515\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042479; batch adversarial loss: 0.460033\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032751; batch adversarial loss: 0.403568\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027180; batch adversarial loss: 0.470176\n",
      "epoch 161; iter: 0; batch classifier loss: 0.065723; batch adversarial loss: 0.453323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041890; batch adversarial loss: 0.337954\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016439; batch adversarial loss: 0.437597\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015341; batch adversarial loss: 0.452206\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011785; batch adversarial loss: 0.388865\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024139; batch adversarial loss: 0.434573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033701; batch adversarial loss: 0.332948\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008451; batch adversarial loss: 0.408973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015474; batch adversarial loss: 0.432139\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027220; batch adversarial loss: 0.437167\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018940; batch adversarial loss: 0.428506\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051592; batch adversarial loss: 0.443392\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021246; batch adversarial loss: 0.425387\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035171; batch adversarial loss: 0.401910\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041795; batch adversarial loss: 0.368982\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011432; batch adversarial loss: 0.433499\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019189; batch adversarial loss: 0.372796\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025583; batch adversarial loss: 0.477810\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006160; batch adversarial loss: 0.458324\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.439479\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026198; batch adversarial loss: 0.414405\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013653; batch adversarial loss: 0.354153\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021492; batch adversarial loss: 0.474167\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024621; batch adversarial loss: 0.487924\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005953; batch adversarial loss: 0.403289\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040800; batch adversarial loss: 0.354528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.050638; batch adversarial loss: 0.482735\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.467651\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008152; batch adversarial loss: 0.495004\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024349; batch adversarial loss: 0.391803\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017728; batch adversarial loss: 0.427387\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020886; batch adversarial loss: 0.375958\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018518; batch adversarial loss: 0.418185\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025196; batch adversarial loss: 0.377578\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034853; batch adversarial loss: 0.497371\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007272; batch adversarial loss: 0.510678\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.454740\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029727; batch adversarial loss: 0.547394\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.400096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.663508; batch adversarial loss: 0.836682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400106; batch adversarial loss: 0.911900\n",
      "epoch 2; iter: 0; batch classifier loss: 0.371199; batch adversarial loss: 0.817639\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399423; batch adversarial loss: 0.744712\n",
      "epoch 4; iter: 0; batch classifier loss: 0.301693; batch adversarial loss: 0.755025\n",
      "epoch 5; iter: 0; batch classifier loss: 0.273654; batch adversarial loss: 0.672930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324614; batch adversarial loss: 0.661036\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280293; batch adversarial loss: 0.650507\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286473; batch adversarial loss: 0.607102\n",
      "epoch 9; iter: 0; batch classifier loss: 0.301173; batch adversarial loss: 0.591784\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253548; batch adversarial loss: 0.573902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255812; batch adversarial loss: 0.522053\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245051; batch adversarial loss: 0.517740\n",
      "epoch 13; iter: 0; batch classifier loss: 0.254372; batch adversarial loss: 0.521674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.224310; batch adversarial loss: 0.511264\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233335; batch adversarial loss: 0.485172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253868; batch adversarial loss: 0.432934\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237475; batch adversarial loss: 0.442584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196933; batch adversarial loss: 0.425800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236406; batch adversarial loss: 0.406297\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191006; batch adversarial loss: 0.382549\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201650; batch adversarial loss: 0.472053\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167567; batch adversarial loss: 0.434856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174968; batch adversarial loss: 0.427153\n",
      "epoch 24; iter: 0; batch classifier loss: 0.131490; batch adversarial loss: 0.385778\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195050; batch adversarial loss: 0.364233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146991; batch adversarial loss: 0.380196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.174452; batch adversarial loss: 0.336126\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184356; batch adversarial loss: 0.402743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177126; batch adversarial loss: 0.409200\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151473; batch adversarial loss: 0.442887\n",
      "epoch 31; iter: 0; batch classifier loss: 0.071731; batch adversarial loss: 0.475129\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159962; batch adversarial loss: 0.357211\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167706; batch adversarial loss: 0.381647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.113596; batch adversarial loss: 0.310632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115115; batch adversarial loss: 0.400520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140851; batch adversarial loss: 0.428967\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143224; batch adversarial loss: 0.476946\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103496; batch adversarial loss: 0.376809\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108653; batch adversarial loss: 0.477291\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112901; batch adversarial loss: 0.396434\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111089; batch adversarial loss: 0.367339\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125438; batch adversarial loss: 0.395288\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102782; batch adversarial loss: 0.492478\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103623; batch adversarial loss: 0.322483\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096631; batch adversarial loss: 0.469845\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081364; batch adversarial loss: 0.342807\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097135; batch adversarial loss: 0.393651\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112958; batch adversarial loss: 0.410579\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102116; batch adversarial loss: 0.377128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.094162; batch adversarial loss: 0.451242\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126710; batch adversarial loss: 0.377739\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100139; batch adversarial loss: 0.345402\n",
      "epoch 53; iter: 0; batch classifier loss: 0.058564; batch adversarial loss: 0.460731\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128451; batch adversarial loss: 0.464119\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111222; batch adversarial loss: 0.314214\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132425; batch adversarial loss: 0.397772\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066366; batch adversarial loss: 0.356517\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111285; batch adversarial loss: 0.405372\n",
      "epoch 59; iter: 0; batch classifier loss: 0.131132; batch adversarial loss: 0.336760\n",
      "epoch 60; iter: 0; batch classifier loss: 0.057805; batch adversarial loss: 0.464734\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067853; batch adversarial loss: 0.344073\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093811; batch adversarial loss: 0.387745\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070446; batch adversarial loss: 0.438786\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069015; batch adversarial loss: 0.431340\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086144; batch adversarial loss: 0.384701\n",
      "epoch 66; iter: 0; batch classifier loss: 0.042869; batch adversarial loss: 0.396158\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079368; batch adversarial loss: 0.427537\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082445; batch adversarial loss: 0.396206\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086794; batch adversarial loss: 0.329262\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077255; batch adversarial loss: 0.417565\n",
      "epoch 71; iter: 0; batch classifier loss: 0.045390; batch adversarial loss: 0.443233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049283; batch adversarial loss: 0.452337\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040211; batch adversarial loss: 0.314445\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066361; batch adversarial loss: 0.471250\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062418; batch adversarial loss: 0.420710\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075191; batch adversarial loss: 0.339314\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066378; batch adversarial loss: 0.445379\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042555; batch adversarial loss: 0.398367\n",
      "epoch 79; iter: 0; batch classifier loss: 0.032162; batch adversarial loss: 0.408053\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070246; batch adversarial loss: 0.441509\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071950; batch adversarial loss: 0.408774\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046486; batch adversarial loss: 0.385573\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049567; batch adversarial loss: 0.481870\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050930; batch adversarial loss: 0.493590\n",
      "epoch 85; iter: 0; batch classifier loss: 0.037329; batch adversarial loss: 0.417528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036060; batch adversarial loss: 0.342228\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069992; batch adversarial loss: 0.336609\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044355; batch adversarial loss: 0.372009\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065570; batch adversarial loss: 0.317751\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058516; batch adversarial loss: 0.453935\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058360; batch adversarial loss: 0.495675\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069593; batch adversarial loss: 0.343580\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040490; batch adversarial loss: 0.366218\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055867; batch adversarial loss: 0.359173\n",
      "epoch 95; iter: 0; batch classifier loss: 0.016777; batch adversarial loss: 0.401278\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048855; batch adversarial loss: 0.412220\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042528; batch adversarial loss: 0.496123\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047620; batch adversarial loss: 0.436757\n",
      "epoch 99; iter: 0; batch classifier loss: 0.026744; batch adversarial loss: 0.409763\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033121; batch adversarial loss: 0.547521\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068537; batch adversarial loss: 0.366824\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024705; batch adversarial loss: 0.443026\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054886; batch adversarial loss: 0.374668\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058759; batch adversarial loss: 0.478107\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022526; batch adversarial loss: 0.478626\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028585; batch adversarial loss: 0.415027\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068728; batch adversarial loss: 0.427079\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031668; batch adversarial loss: 0.404330\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036839; batch adversarial loss: 0.486877\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026851; batch adversarial loss: 0.380224\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032364; batch adversarial loss: 0.352452\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031618; batch adversarial loss: 0.434233\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053467; batch adversarial loss: 0.424701\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030086; batch adversarial loss: 0.499147\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021625; batch adversarial loss: 0.450964\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025983; batch adversarial loss: 0.444150\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032821; batch adversarial loss: 0.354348\n",
      "epoch 118; iter: 0; batch classifier loss: 0.010269; batch adversarial loss: 0.563691\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026686; batch adversarial loss: 0.493643\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032014; batch adversarial loss: 0.504923\n",
      "epoch 121; iter: 0; batch classifier loss: 0.063562; batch adversarial loss: 0.438434\n",
      "epoch 122; iter: 0; batch classifier loss: 0.016372; batch adversarial loss: 0.453020\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040940; batch adversarial loss: 0.343396\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027751; batch adversarial loss: 0.432883\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.405174\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034524; batch adversarial loss: 0.355984\n",
      "epoch 127; iter: 0; batch classifier loss: 0.012813; batch adversarial loss: 0.406471\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.490951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013506; batch adversarial loss: 0.407382\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023693; batch adversarial loss: 0.468800\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045435; batch adversarial loss: 0.433645\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020402; batch adversarial loss: 0.498620\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.366359\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013476; batch adversarial loss: 0.343302\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061047; batch adversarial loss: 0.379240\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.507533\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019204; batch adversarial loss: 0.444248\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031101; batch adversarial loss: 0.367256\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049507; batch adversarial loss: 0.435392\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017670; batch adversarial loss: 0.534630\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011195; batch adversarial loss: 0.413790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029277; batch adversarial loss: 0.400964\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022220; batch adversarial loss: 0.575497\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021964; batch adversarial loss: 0.465259\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016861; batch adversarial loss: 0.483382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.020991; batch adversarial loss: 0.384474\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036900; batch adversarial loss: 0.406552\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023165; batch adversarial loss: 0.406287\n",
      "epoch 149; iter: 0; batch classifier loss: 0.085430; batch adversarial loss: 0.372922\n",
      "epoch 150; iter: 0; batch classifier loss: 0.069953; batch adversarial loss: 0.520734\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035612; batch adversarial loss: 0.441941\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037521; batch adversarial loss: 0.592791\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050941; batch adversarial loss: 0.464666\n",
      "epoch 154; iter: 0; batch classifier loss: 0.078556; batch adversarial loss: 0.610003\n",
      "epoch 155; iter: 0; batch classifier loss: 0.117642; batch adversarial loss: 0.676726\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049867; batch adversarial loss: 0.430386\n",
      "epoch 157; iter: 0; batch classifier loss: 0.071659; batch adversarial loss: 0.571063\n",
      "epoch 158; iter: 0; batch classifier loss: 0.132367; batch adversarial loss: 0.664351\n",
      "epoch 159; iter: 0; batch classifier loss: 0.074960; batch adversarial loss: 0.555768\n",
      "epoch 160; iter: 0; batch classifier loss: 0.170275; batch adversarial loss: 0.680571\n",
      "epoch 161; iter: 0; batch classifier loss: 0.126428; batch adversarial loss: 0.642899\n",
      "epoch 162; iter: 0; batch classifier loss: 0.107705; batch adversarial loss: 0.582129\n",
      "epoch 163; iter: 0; batch classifier loss: 0.055977; batch adversarial loss: 0.444627\n",
      "epoch 164; iter: 0; batch classifier loss: 0.122542; batch adversarial loss: 0.546604\n",
      "epoch 165; iter: 0; batch classifier loss: 0.093914; batch adversarial loss: 0.463481\n",
      "epoch 166; iter: 0; batch classifier loss: 0.133869; batch adversarial loss: 0.632086\n",
      "epoch 167; iter: 0; batch classifier loss: 0.174535; batch adversarial loss: 0.717699\n",
      "epoch 168; iter: 0; batch classifier loss: 0.117783; batch adversarial loss: 0.602063\n",
      "epoch 169; iter: 0; batch classifier loss: 0.090820; batch adversarial loss: 0.580095\n",
      "epoch 170; iter: 0; batch classifier loss: 0.117612; batch adversarial loss: 0.595976\n",
      "epoch 171; iter: 0; batch classifier loss: 0.121782; batch adversarial loss: 0.543931\n",
      "epoch 172; iter: 0; batch classifier loss: 0.154916; batch adversarial loss: 0.560224\n",
      "epoch 173; iter: 0; batch classifier loss: 0.136616; batch adversarial loss: 0.601154\n",
      "epoch 174; iter: 0; batch classifier loss: 0.165317; batch adversarial loss: 0.687659\n",
      "epoch 175; iter: 0; batch classifier loss: 0.169279; batch adversarial loss: 0.579062\n",
      "epoch 176; iter: 0; batch classifier loss: 0.129235; batch adversarial loss: 0.616182\n",
      "epoch 177; iter: 0; batch classifier loss: 0.143403; batch adversarial loss: 0.555613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.187236; batch adversarial loss: 0.539129\n",
      "epoch 179; iter: 0; batch classifier loss: 0.170683; batch adversarial loss: 0.668630\n",
      "epoch 180; iter: 0; batch classifier loss: 0.093211; batch adversarial loss: 0.430869\n",
      "epoch 181; iter: 0; batch classifier loss: 0.154774; batch adversarial loss: 0.572666\n",
      "epoch 182; iter: 0; batch classifier loss: 0.149559; batch adversarial loss: 0.564870\n",
      "epoch 183; iter: 0; batch classifier loss: 0.176344; batch adversarial loss: 0.555591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.175065; batch adversarial loss: 0.648654\n",
      "epoch 185; iter: 0; batch classifier loss: 0.173800; batch adversarial loss: 0.518778\n",
      "epoch 186; iter: 0; batch classifier loss: 0.146799; batch adversarial loss: 0.595402\n",
      "epoch 187; iter: 0; batch classifier loss: 0.167220; batch adversarial loss: 0.670699\n",
      "epoch 188; iter: 0; batch classifier loss: 0.216115; batch adversarial loss: 0.648123\n",
      "epoch 189; iter: 0; batch classifier loss: 0.097829; batch adversarial loss: 0.479772\n",
      "epoch 190; iter: 0; batch classifier loss: 0.134010; batch adversarial loss: 0.507968\n",
      "epoch 191; iter: 0; batch classifier loss: 0.226477; batch adversarial loss: 0.623879\n",
      "epoch 192; iter: 0; batch classifier loss: 0.180562; batch adversarial loss: 0.545528\n",
      "epoch 193; iter: 0; batch classifier loss: 0.108676; batch adversarial loss: 0.487502\n",
      "epoch 194; iter: 0; batch classifier loss: 0.142746; batch adversarial loss: 0.503549\n",
      "epoch 195; iter: 0; batch classifier loss: 0.167476; batch adversarial loss: 0.603306\n",
      "epoch 196; iter: 0; batch classifier loss: 0.093442; batch adversarial loss: 0.454447\n",
      "epoch 197; iter: 0; batch classifier loss: 0.126543; batch adversarial loss: 0.457228\n",
      "epoch 198; iter: 0; batch classifier loss: 0.074832; batch adversarial loss: 0.383222\n",
      "epoch 199; iter: 0; batch classifier loss: 0.102731; batch adversarial loss: 0.426091\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698909; batch adversarial loss: 0.632349\n",
      "epoch 1; iter: 0; batch classifier loss: 0.548189; batch adversarial loss: 0.642384\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417196; batch adversarial loss: 0.606399\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346968; batch adversarial loss: 0.629077\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504917; batch adversarial loss: 0.610257\n",
      "epoch 5; iter: 0; batch classifier loss: 0.427878; batch adversarial loss: 0.577688\n",
      "epoch 6; iter: 0; batch classifier loss: 0.352028; batch adversarial loss: 0.619272\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411502; batch adversarial loss: 0.586534\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375800; batch adversarial loss: 0.509209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314458; batch adversarial loss: 0.566764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388683; batch adversarial loss: 0.505781\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369255; batch adversarial loss: 0.575082\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344914; batch adversarial loss: 0.512017\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312924; batch adversarial loss: 0.496662\n",
      "epoch 14; iter: 0; batch classifier loss: 0.380797; batch adversarial loss: 0.491353\n",
      "epoch 15; iter: 0; batch classifier loss: 0.317242; batch adversarial loss: 0.477815\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399142; batch adversarial loss: 0.407577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377057; batch adversarial loss: 0.435565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263738; batch adversarial loss: 0.484810\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302303; batch adversarial loss: 0.467685\n",
      "epoch 20; iter: 0; batch classifier loss: 0.301159; batch adversarial loss: 0.422103\n",
      "epoch 21; iter: 0; batch classifier loss: 0.346816; batch adversarial loss: 0.468190\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336649; batch adversarial loss: 0.392140\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266702; batch adversarial loss: 0.493290\n",
      "epoch 24; iter: 0; batch classifier loss: 0.235410; batch adversarial loss: 0.509846\n",
      "epoch 25; iter: 0; batch classifier loss: 0.289048; batch adversarial loss: 0.490111\n",
      "epoch 26; iter: 0; batch classifier loss: 0.293705; batch adversarial loss: 0.530880\n",
      "epoch 27; iter: 0; batch classifier loss: 0.340052; batch adversarial loss: 0.358548\n",
      "epoch 28; iter: 0; batch classifier loss: 0.310254; batch adversarial loss: 0.509185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221613; batch adversarial loss: 0.458782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.222852; batch adversarial loss: 0.567589\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279027; batch adversarial loss: 0.526753\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241552; batch adversarial loss: 0.543693\n",
      "epoch 33; iter: 0; batch classifier loss: 0.308201; batch adversarial loss: 0.421395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.295943; batch adversarial loss: 0.418653\n",
      "epoch 35; iter: 0; batch classifier loss: 0.318399; batch adversarial loss: 0.413556\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275299; batch adversarial loss: 0.388983\n",
      "epoch 37; iter: 0; batch classifier loss: 0.249580; batch adversarial loss: 0.409157\n",
      "epoch 38; iter: 0; batch classifier loss: 0.295994; batch adversarial loss: 0.557873\n",
      "epoch 39; iter: 0; batch classifier loss: 0.281363; batch adversarial loss: 0.450790\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269962; batch adversarial loss: 0.470170\n",
      "epoch 41; iter: 0; batch classifier loss: 0.328920; batch adversarial loss: 0.379139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.206047; batch adversarial loss: 0.459772\n",
      "epoch 43; iter: 0; batch classifier loss: 0.279500; batch adversarial loss: 0.494566\n",
      "epoch 44; iter: 0; batch classifier loss: 0.159900; batch adversarial loss: 0.423299\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117176; batch adversarial loss: 0.386082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125219; batch adversarial loss: 0.387209\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132296; batch adversarial loss: 0.409111\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098334; batch adversarial loss: 0.523316\n",
      "epoch 49; iter: 0; batch classifier loss: 0.146792; batch adversarial loss: 0.474569\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083453; batch adversarial loss: 0.474022\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100219; batch adversarial loss: 0.463342\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161212; batch adversarial loss: 0.358824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.158660; batch adversarial loss: 0.554595\n",
      "epoch 54; iter: 0; batch classifier loss: 0.197033; batch adversarial loss: 0.403992\n",
      "epoch 55; iter: 0; batch classifier loss: 0.147271; batch adversarial loss: 0.414305\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143708; batch adversarial loss: 0.466019\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158690; batch adversarial loss: 0.518866\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135650; batch adversarial loss: 0.436286\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212878; batch adversarial loss: 0.472947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204361; batch adversarial loss: 0.537764\n",
      "epoch 61; iter: 0; batch classifier loss: 0.214192; batch adversarial loss: 0.447463\n",
      "epoch 62; iter: 0; batch classifier loss: 0.150033; batch adversarial loss: 0.448364\n",
      "epoch 63; iter: 0; batch classifier loss: 0.191779; batch adversarial loss: 0.482063\n",
      "epoch 64; iter: 0; batch classifier loss: 0.238993; batch adversarial loss: 0.408827\n",
      "epoch 65; iter: 0; batch classifier loss: 0.203055; batch adversarial loss: 0.496426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.226875; batch adversarial loss: 0.409345\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173782; batch adversarial loss: 0.493866\n",
      "epoch 68; iter: 0; batch classifier loss: 0.233332; batch adversarial loss: 0.471203\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204269; batch adversarial loss: 0.483061\n",
      "epoch 70; iter: 0; batch classifier loss: 0.185529; batch adversarial loss: 0.496646\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133060; batch adversarial loss: 0.560027\n",
      "epoch 72; iter: 0; batch classifier loss: 0.327700; batch adversarial loss: 0.421286\n",
      "epoch 73; iter: 0; batch classifier loss: 0.172154; batch adversarial loss: 0.458477\n",
      "epoch 74; iter: 0; batch classifier loss: 0.190141; batch adversarial loss: 0.409761\n",
      "epoch 75; iter: 0; batch classifier loss: 0.232909; batch adversarial loss: 0.508359\n",
      "epoch 76; iter: 0; batch classifier loss: 0.231484; batch adversarial loss: 0.421823\n",
      "epoch 77; iter: 0; batch classifier loss: 0.195805; batch adversarial loss: 0.458915\n",
      "epoch 78; iter: 0; batch classifier loss: 0.130575; batch adversarial loss: 0.459495\n",
      "epoch 79; iter: 0; batch classifier loss: 0.216077; batch adversarial loss: 0.520863\n",
      "epoch 80; iter: 0; batch classifier loss: 0.134627; batch adversarial loss: 0.408967\n",
      "epoch 81; iter: 0; batch classifier loss: 0.235233; batch adversarial loss: 0.433302\n",
      "epoch 82; iter: 0; batch classifier loss: 0.269261; batch adversarial loss: 0.396508\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111999; batch adversarial loss: 0.520477\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059864; batch adversarial loss: 0.494320\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063799; batch adversarial loss: 0.445699\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054712; batch adversarial loss: 0.418266\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043800; batch adversarial loss: 0.488639\n",
      "epoch 88; iter: 0; batch classifier loss: 0.098645; batch adversarial loss: 0.369747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066404; batch adversarial loss: 0.475032\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105449; batch adversarial loss: 0.445929\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081864; batch adversarial loss: 0.405718\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062096; batch adversarial loss: 0.396959\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066545; batch adversarial loss: 0.399316\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070095; batch adversarial loss: 0.548837\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077371; batch adversarial loss: 0.418224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.118027; batch adversarial loss: 0.385440\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063912; batch adversarial loss: 0.478087\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050563; batch adversarial loss: 0.417622\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072176; batch adversarial loss: 0.428933\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053959; batch adversarial loss: 0.329702\n",
      "epoch 101; iter: 0; batch classifier loss: 0.069845; batch adversarial loss: 0.454808\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057668; batch adversarial loss: 0.418604\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045014; batch adversarial loss: 0.478329\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034963; batch adversarial loss: 0.338216\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076684; batch adversarial loss: 0.388600\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067491; batch adversarial loss: 0.508553\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042483; batch adversarial loss: 0.481362\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048692; batch adversarial loss: 0.375483\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064395; batch adversarial loss: 0.461130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040035; batch adversarial loss: 0.452525\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083543; batch adversarial loss: 0.417142\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046551; batch adversarial loss: 0.362534\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035923; batch adversarial loss: 0.557763\n",
      "epoch 114; iter: 0; batch classifier loss: 0.096626; batch adversarial loss: 0.369247\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080511; batch adversarial loss: 0.460654\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057020; batch adversarial loss: 0.476525\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.403625\n",
      "epoch 118; iter: 0; batch classifier loss: 0.010999; batch adversarial loss: 0.431694\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022656; batch adversarial loss: 0.427888\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028201; batch adversarial loss: 0.351488\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045388; batch adversarial loss: 0.449423\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051144; batch adversarial loss: 0.440207\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044043; batch adversarial loss: 0.519396\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018107; batch adversarial loss: 0.508450\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033462; batch adversarial loss: 0.482048\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059610; batch adversarial loss: 0.381496\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022505; batch adversarial loss: 0.444810\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044934; batch adversarial loss: 0.392581\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062092; batch adversarial loss: 0.432526\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063102; batch adversarial loss: 0.435172\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022936; batch adversarial loss: 0.406032\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022765; batch adversarial loss: 0.473544\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049893; batch adversarial loss: 0.424045\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069701; batch adversarial loss: 0.466383\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016974; batch adversarial loss: 0.378840\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.454513\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028603; batch adversarial loss: 0.521506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.027906; batch adversarial loss: 0.443512\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.500223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032091; batch adversarial loss: 0.519155\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026692; batch adversarial loss: 0.379561\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013211; batch adversarial loss: 0.482710\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016440; batch adversarial loss: 0.448525\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014775; batch adversarial loss: 0.417522\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014780; batch adversarial loss: 0.376830\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032946; batch adversarial loss: 0.492917\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028391; batch adversarial loss: 0.460683\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019161; batch adversarial loss: 0.425221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018476; batch adversarial loss: 0.465999\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027091; batch adversarial loss: 0.317274\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020021; batch adversarial loss: 0.495183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018215; batch adversarial loss: 0.472419\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024585; batch adversarial loss: 0.397411\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018929; batch adversarial loss: 0.472342\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049865; batch adversarial loss: 0.357247\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029435; batch adversarial loss: 0.483499\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009760; batch adversarial loss: 0.444456\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021270; batch adversarial loss: 0.391964\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031773; batch adversarial loss: 0.412969\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024927; batch adversarial loss: 0.457528\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016178; batch adversarial loss: 0.482650\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014878; batch adversarial loss: 0.401736\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037905; batch adversarial loss: 0.464062\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011006; batch adversarial loss: 0.410143\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019907; batch adversarial loss: 0.370411\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009674; batch adversarial loss: 0.507648\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019374; batch adversarial loss: 0.465913\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018003; batch adversarial loss: 0.502913\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026499; batch adversarial loss: 0.418469\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021510; batch adversarial loss: 0.452943\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048411; batch adversarial loss: 0.438456\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004791; batch adversarial loss: 0.514046\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020374; batch adversarial loss: 0.386132\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.512353\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009923; batch adversarial loss: 0.460844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041617; batch adversarial loss: 0.456022\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006818; batch adversarial loss: 0.554123\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017152; batch adversarial loss: 0.424786\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020574; batch adversarial loss: 0.504761\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008102; batch adversarial loss: 0.376701\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035364; batch adversarial loss: 0.404627\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018728; batch adversarial loss: 0.442730\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019135; batch adversarial loss: 0.500391\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019531; batch adversarial loss: 0.425525\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043047; batch adversarial loss: 0.334968\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019430; batch adversarial loss: 0.400446\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020141; batch adversarial loss: 0.386594\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005756; batch adversarial loss: 0.397442\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006660; batch adversarial loss: 0.432653\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027599; batch adversarial loss: 0.431814\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014751; batch adversarial loss: 0.400346\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012909; batch adversarial loss: 0.452128\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005144; batch adversarial loss: 0.417937\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014096; batch adversarial loss: 0.385187\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015061; batch adversarial loss: 0.506583\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014604; batch adversarial loss: 0.487640\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015057; batch adversarial loss: 0.385782\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028946; batch adversarial loss: 0.456963\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033706; batch adversarial loss: 0.495828\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686002; batch adversarial loss: 1.123733\n",
      "epoch 1; iter: 0; batch classifier loss: 0.644015; batch adversarial loss: 1.302118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.873873; batch adversarial loss: 1.320567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.926256; batch adversarial loss: 1.296439\n",
      "epoch 4; iter: 0; batch classifier loss: 1.007771; batch adversarial loss: 1.158546\n",
      "epoch 5; iter: 0; batch classifier loss: 0.990219; batch adversarial loss: 1.070992\n",
      "epoch 6; iter: 0; batch classifier loss: 0.986547; batch adversarial loss: 0.969676\n",
      "epoch 7; iter: 0; batch classifier loss: 0.894929; batch adversarial loss: 0.885942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.683516; batch adversarial loss: 0.853593\n",
      "epoch 9; iter: 0; batch classifier loss: 0.672244; batch adversarial loss: 0.734625\n",
      "epoch 10; iter: 0; batch classifier loss: 0.457384; batch adversarial loss: 0.694970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.293801; batch adversarial loss: 0.599214\n",
      "epoch 12; iter: 0; batch classifier loss: 0.294383; batch adversarial loss: 0.612499\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243575; batch adversarial loss: 0.570436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179478; batch adversarial loss: 0.542301\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240543; batch adversarial loss: 0.521981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193707; batch adversarial loss: 0.533060\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313669; batch adversarial loss: 0.531004\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211433; batch adversarial loss: 0.490760\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247343; batch adversarial loss: 0.479047\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182417; batch adversarial loss: 0.520743\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263834; batch adversarial loss: 0.518046\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231493; batch adversarial loss: 0.434656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231518; batch adversarial loss: 0.528153\n",
      "epoch 24; iter: 0; batch classifier loss: 0.236605; batch adversarial loss: 0.489299\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270889; batch adversarial loss: 0.510278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.367463; batch adversarial loss: 0.492466\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221672; batch adversarial loss: 0.508050\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217502; batch adversarial loss: 0.519219\n",
      "epoch 29; iter: 0; batch classifier loss: 0.302051; batch adversarial loss: 0.495012\n",
      "epoch 30; iter: 0; batch classifier loss: 0.313412; batch adversarial loss: 0.369555\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277639; batch adversarial loss: 0.488088\n",
      "epoch 32; iter: 0; batch classifier loss: 0.295364; batch adversarial loss: 0.391051\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318442; batch adversarial loss: 0.438187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 0; batch classifier loss: 0.355252; batch adversarial loss: 0.427428\n",
      "epoch 35; iter: 0; batch classifier loss: 0.253730; batch adversarial loss: 0.424405\n",
      "epoch 36; iter: 0; batch classifier loss: 0.196698; batch adversarial loss: 0.493714\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145617; batch adversarial loss: 0.411014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169994; batch adversarial loss: 0.418698\n",
      "epoch 39; iter: 0; batch classifier loss: 0.157633; batch adversarial loss: 0.449379\n",
      "epoch 40; iter: 0; batch classifier loss: 0.132803; batch adversarial loss: 0.495274\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082790; batch adversarial loss: 0.516616\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097476; batch adversarial loss: 0.472222\n",
      "epoch 43; iter: 0; batch classifier loss: 0.144823; batch adversarial loss: 0.426576\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118208; batch adversarial loss: 0.400413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.066442; batch adversarial loss: 0.459281\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082255; batch adversarial loss: 0.525921\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096466; batch adversarial loss: 0.384073\n",
      "epoch 48; iter: 0; batch classifier loss: 0.068997; batch adversarial loss: 0.372240\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083094; batch adversarial loss: 0.446197\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080260; batch adversarial loss: 0.419948\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089689; batch adversarial loss: 0.504874\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104231; batch adversarial loss: 0.504870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096380; batch adversarial loss: 0.540754\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080529; batch adversarial loss: 0.392131\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081919; batch adversarial loss: 0.427743\n",
      "epoch 56; iter: 0; batch classifier loss: 0.057188; batch adversarial loss: 0.456719\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063673; batch adversarial loss: 0.516237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067520; batch adversarial loss: 0.557478\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074976; batch adversarial loss: 0.478280\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107700; batch adversarial loss: 0.468866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.044383; batch adversarial loss: 0.521058\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080672; batch adversarial loss: 0.497782\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093226; batch adversarial loss: 0.486562\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068128; batch adversarial loss: 0.441802\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099929; batch adversarial loss: 0.328384\n",
      "epoch 66; iter: 0; batch classifier loss: 0.080196; batch adversarial loss: 0.438649\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056525; batch adversarial loss: 0.441748\n",
      "epoch 68; iter: 0; batch classifier loss: 0.120851; batch adversarial loss: 0.400582\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077986; batch adversarial loss: 0.433494\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048858; batch adversarial loss: 0.477841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065433; batch adversarial loss: 0.441229\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058581; batch adversarial loss: 0.423595\n",
      "epoch 73; iter: 0; batch classifier loss: 0.036732; batch adversarial loss: 0.451508\n",
      "epoch 74; iter: 0; batch classifier loss: 0.069531; batch adversarial loss: 0.473953\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057582; batch adversarial loss: 0.447115\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073387; batch adversarial loss: 0.468627\n",
      "epoch 77; iter: 0; batch classifier loss: 0.035943; batch adversarial loss: 0.468386\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058682; batch adversarial loss: 0.446026\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071423; batch adversarial loss: 0.330316\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043380; batch adversarial loss: 0.406973\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079631; batch adversarial loss: 0.438272\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062364; batch adversarial loss: 0.520065\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043286; batch adversarial loss: 0.492468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042490; batch adversarial loss: 0.469092\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054060; batch adversarial loss: 0.448525\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063110; batch adversarial loss: 0.450491\n",
      "epoch 87; iter: 0; batch classifier loss: 0.020757; batch adversarial loss: 0.505286\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054972; batch adversarial loss: 0.448900\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045200; batch adversarial loss: 0.489646\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060905; batch adversarial loss: 0.442178\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049427; batch adversarial loss: 0.496682\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041510; batch adversarial loss: 0.400998\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044737; batch adversarial loss: 0.422832\n",
      "epoch 94; iter: 0; batch classifier loss: 0.099951; batch adversarial loss: 0.397187\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047378; batch adversarial loss: 0.507448\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062532; batch adversarial loss: 0.434242\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057891; batch adversarial loss: 0.405141\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080622; batch adversarial loss: 0.551744\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074654; batch adversarial loss: 0.587653\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.437067\n",
      "epoch 101; iter: 0; batch classifier loss: 0.043128; batch adversarial loss: 0.417168\n",
      "epoch 102; iter: 0; batch classifier loss: 0.022109; batch adversarial loss: 0.477797\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065565; batch adversarial loss: 0.494405\n",
      "epoch 104; iter: 0; batch classifier loss: 0.117397; batch adversarial loss: 0.348450\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029053; batch adversarial loss: 0.464626\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036736; batch adversarial loss: 0.364307\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057722; batch adversarial loss: 0.433244\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046827; batch adversarial loss: 0.469886\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058130; batch adversarial loss: 0.457925\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032634; batch adversarial loss: 0.559013\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025793; batch adversarial loss: 0.354823\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026925; batch adversarial loss: 0.441905\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029427; batch adversarial loss: 0.429008\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052427; batch adversarial loss: 0.450032\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041529; batch adversarial loss: 0.411071\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062355; batch adversarial loss: 0.428304\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042898; batch adversarial loss: 0.453047\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048174; batch adversarial loss: 0.336057\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017236; batch adversarial loss: 0.448068\n",
      "epoch 120; iter: 0; batch classifier loss: 0.081893; batch adversarial loss: 0.441435\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028020; batch adversarial loss: 0.541089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036599; batch adversarial loss: 0.435094\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.570268\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052639; batch adversarial loss: 0.416921\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069496; batch adversarial loss: 0.414466\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058720; batch adversarial loss: 0.435485\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046271; batch adversarial loss: 0.388902\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.518299\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039640; batch adversarial loss: 0.403310\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019282; batch adversarial loss: 0.437744\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024889; batch adversarial loss: 0.485862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 132; iter: 0; batch classifier loss: 0.023263; batch adversarial loss: 0.510594\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051994; batch adversarial loss: 0.517420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058495; batch adversarial loss: 0.366623\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021183; batch adversarial loss: 0.474357\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.391388\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064887; batch adversarial loss: 0.462301\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013723; batch adversarial loss: 0.483764\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.443092\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017252; batch adversarial loss: 0.482518\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041899; batch adversarial loss: 0.440797\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020305; batch adversarial loss: 0.378208\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038905; batch adversarial loss: 0.386700\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021582; batch adversarial loss: 0.433087\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029213; batch adversarial loss: 0.581532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026284; batch adversarial loss: 0.521427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007678; batch adversarial loss: 0.498872\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025772; batch adversarial loss: 0.398576\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013981; batch adversarial loss: 0.403923\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045856; batch adversarial loss: 0.465236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017768; batch adversarial loss: 0.516963\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.445792\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.357299\n",
      "epoch 154; iter: 0; batch classifier loss: 0.069107; batch adversarial loss: 0.475035\n",
      "epoch 155; iter: 0; batch classifier loss: 0.074903; batch adversarial loss: 0.411575\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007989; batch adversarial loss: 0.497022\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025648; batch adversarial loss: 0.378534\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055112; batch adversarial loss: 0.455396\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026126; batch adversarial loss: 0.472599\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043362; batch adversarial loss: 0.425459\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024092; batch adversarial loss: 0.434246\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018774; batch adversarial loss: 0.501763\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032359; batch adversarial loss: 0.464466\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025720; batch adversarial loss: 0.477760\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038245; batch adversarial loss: 0.532370\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043498; batch adversarial loss: 0.465760\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011889; batch adversarial loss: 0.458023\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030064; batch adversarial loss: 0.430643\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015188; batch adversarial loss: 0.376884\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028998; batch adversarial loss: 0.490983\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019162; batch adversarial loss: 0.392717\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020947; batch adversarial loss: 0.386204\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022366; batch adversarial loss: 0.451480\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010819; batch adversarial loss: 0.473602\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010640; batch adversarial loss: 0.498477\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018649; batch adversarial loss: 0.401662\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023484; batch adversarial loss: 0.382193\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009722; batch adversarial loss: 0.430913\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032018; batch adversarial loss: 0.493757\n",
      "epoch 180; iter: 0; batch classifier loss: 0.055278; batch adversarial loss: 0.452476\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024732; batch adversarial loss: 0.468524\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023292; batch adversarial loss: 0.377235\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011016; batch adversarial loss: 0.465913\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020241; batch adversarial loss: 0.511794\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035136; batch adversarial loss: 0.482621\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029341; batch adversarial loss: 0.457915\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035621; batch adversarial loss: 0.449373\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009879; batch adversarial loss: 0.389010\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011052; batch adversarial loss: 0.543716\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036376; batch adversarial loss: 0.439818\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012678; batch adversarial loss: 0.427485\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022675; batch adversarial loss: 0.401266\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025750; batch adversarial loss: 0.508697\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031514; batch adversarial loss: 0.546135\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029117; batch adversarial loss: 0.463866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025974; batch adversarial loss: 0.446713\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044613; batch adversarial loss: 0.519748\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023359; batch adversarial loss: 0.409185\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015223; batch adversarial loss: 0.462513\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709862; batch adversarial loss: 0.903507\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619179; batch adversarial loss: 0.934112\n",
      "epoch 2; iter: 0; batch classifier loss: 0.998674; batch adversarial loss: 0.991791\n",
      "epoch 3; iter: 0; batch classifier loss: 0.923063; batch adversarial loss: 0.849887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.934426; batch adversarial loss: 0.776861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.942480; batch adversarial loss: 0.715453\n",
      "epoch 6; iter: 0; batch classifier loss: 0.740694; batch adversarial loss: 0.646059\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574693; batch adversarial loss: 0.604030\n",
      "epoch 8; iter: 0; batch classifier loss: 0.462101; batch adversarial loss: 0.574980\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354880; batch adversarial loss: 0.606097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304899; batch adversarial loss: 0.555947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292226; batch adversarial loss: 0.522773\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319748; batch adversarial loss: 0.542452\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312702; batch adversarial loss: 0.533297\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298595; batch adversarial loss: 0.525309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263862; batch adversarial loss: 0.506303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222213; batch adversarial loss: 0.453795\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296703; batch adversarial loss: 0.485015\n",
      "epoch 18; iter: 0; batch classifier loss: 0.199411; batch adversarial loss: 0.489444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.227711; batch adversarial loss: 0.518858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222765; batch adversarial loss: 0.473931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234851; batch adversarial loss: 0.422340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189963; batch adversarial loss: 0.518136\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190451; batch adversarial loss: 0.484544\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257973; batch adversarial loss: 0.473828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247147; batch adversarial loss: 0.453219\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240487; batch adversarial loss: 0.500282\n",
      "epoch 27; iter: 0; batch classifier loss: 0.296278; batch adversarial loss: 0.486871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.176738; batch adversarial loss: 0.468504\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202401; batch adversarial loss: 0.493270\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208457; batch adversarial loss: 0.437275\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121684; batch adversarial loss: 0.505329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159973; batch adversarial loss: 0.446932\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163481; batch adversarial loss: 0.468617\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187183; batch adversarial loss: 0.465882\n",
      "epoch 35; iter: 0; batch classifier loss: 0.219041; batch adversarial loss: 0.481033\n",
      "epoch 36; iter: 0; batch classifier loss: 0.156607; batch adversarial loss: 0.578980\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153928; batch adversarial loss: 0.509510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172075; batch adversarial loss: 0.532339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126037; batch adversarial loss: 0.473575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119816; batch adversarial loss: 0.476066\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156053; batch adversarial loss: 0.507844\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152088; batch adversarial loss: 0.464196\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186192; batch adversarial loss: 0.466956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211199; batch adversarial loss: 0.444331\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166251; batch adversarial loss: 0.530968\n",
      "epoch 46; iter: 0; batch classifier loss: 0.199546; batch adversarial loss: 0.483381\n",
      "epoch 47; iter: 0; batch classifier loss: 0.191306; batch adversarial loss: 0.410691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196497; batch adversarial loss: 0.459361\n",
      "epoch 49; iter: 0; batch classifier loss: 0.144537; batch adversarial loss: 0.511495\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160191; batch adversarial loss: 0.473489\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156339; batch adversarial loss: 0.397529\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122491; batch adversarial loss: 0.480898\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119498; batch adversarial loss: 0.430394\n",
      "epoch 54; iter: 0; batch classifier loss: 0.153157; batch adversarial loss: 0.360561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.127546; batch adversarial loss: 0.443078\n",
      "epoch 56; iter: 0; batch classifier loss: 0.150515; batch adversarial loss: 0.543439\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096213; batch adversarial loss: 0.464819\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080621; batch adversarial loss: 0.448554\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094459; batch adversarial loss: 0.443586\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105484; batch adversarial loss: 0.405652\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088944; batch adversarial loss: 0.499014\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203947; batch adversarial loss: 0.426074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138501; batch adversarial loss: 0.423572\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082506; batch adversarial loss: 0.366406\n",
      "epoch 65; iter: 0; batch classifier loss: 0.177940; batch adversarial loss: 0.415206\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112190; batch adversarial loss: 0.434190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106988; batch adversarial loss: 0.479536\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117757; batch adversarial loss: 0.463301\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057185; batch adversarial loss: 0.569793\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090198; batch adversarial loss: 0.449548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107138; batch adversarial loss: 0.430001\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099569; batch adversarial loss: 0.434075\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097112; batch adversarial loss: 0.482411\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093886; batch adversarial loss: 0.471643\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087567; batch adversarial loss: 0.515105\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083940; batch adversarial loss: 0.513055\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100069; batch adversarial loss: 0.395366\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076634; batch adversarial loss: 0.499414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047842; batch adversarial loss: 0.445345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078065; batch adversarial loss: 0.393061\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078519; batch adversarial loss: 0.462639\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078501; batch adversarial loss: 0.485666\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064448; batch adversarial loss: 0.547426\n",
      "epoch 84; iter: 0; batch classifier loss: 0.088790; batch adversarial loss: 0.405911\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077199; batch adversarial loss: 0.516261\n",
      "epoch 86; iter: 0; batch classifier loss: 0.039078; batch adversarial loss: 0.512064\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055908; batch adversarial loss: 0.478887\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069461; batch adversarial loss: 0.420724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051846; batch adversarial loss: 0.490380\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063151; batch adversarial loss: 0.382961\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041532; batch adversarial loss: 0.315263\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056900; batch adversarial loss: 0.425029\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065648; batch adversarial loss: 0.476681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038652; batch adversarial loss: 0.444130\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084729; batch adversarial loss: 0.346691\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047743; batch adversarial loss: 0.378944\n",
      "epoch 97; iter: 0; batch classifier loss: 0.034232; batch adversarial loss: 0.457276\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050185; batch adversarial loss: 0.571649\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041212; batch adversarial loss: 0.292063\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037380; batch adversarial loss: 0.371187\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065558; batch adversarial loss: 0.419172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038092; batch adversarial loss: 0.469919\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043874; batch adversarial loss: 0.457524\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030671; batch adversarial loss: 0.398066\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028184; batch adversarial loss: 0.532337\n",
      "epoch 106; iter: 0; batch classifier loss: 0.015115; batch adversarial loss: 0.445014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045119; batch adversarial loss: 0.427929\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029614; batch adversarial loss: 0.450165\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044690; batch adversarial loss: 0.557119\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048719; batch adversarial loss: 0.447336\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039703; batch adversarial loss: 0.413471\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017515; batch adversarial loss: 0.411331\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041941; batch adversarial loss: 0.451804\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029054; batch adversarial loss: 0.364131\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024437; batch adversarial loss: 0.459258\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038042; batch adversarial loss: 0.433580\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.406314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036306; batch adversarial loss: 0.543957\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030259; batch adversarial loss: 0.387619\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014250; batch adversarial loss: 0.498036\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017971; batch adversarial loss: 0.485510\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020528; batch adversarial loss: 0.492513\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031745; batch adversarial loss: 0.438021\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030774; batch adversarial loss: 0.466064\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057112; batch adversarial loss: 0.403866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.022849; batch adversarial loss: 0.455821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021944; batch adversarial loss: 0.450734\n",
      "epoch 128; iter: 0; batch classifier loss: 0.009797; batch adversarial loss: 0.534750\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031536; batch adversarial loss: 0.487847\n",
      "epoch 130; iter: 0; batch classifier loss: 0.012085; batch adversarial loss: 0.486922\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031183; batch adversarial loss: 0.450014\n",
      "epoch 132; iter: 0; batch classifier loss: 0.008810; batch adversarial loss: 0.545365\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018226; batch adversarial loss: 0.410066\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014046; batch adversarial loss: 0.547460\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013612; batch adversarial loss: 0.403669\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021643; batch adversarial loss: 0.467949\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016644; batch adversarial loss: 0.475352\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014629; batch adversarial loss: 0.434723\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018292; batch adversarial loss: 0.518036\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024575; batch adversarial loss: 0.387084\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033303; batch adversarial loss: 0.402461\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019249; batch adversarial loss: 0.447478\n",
      "epoch 143; iter: 0; batch classifier loss: 0.006365; batch adversarial loss: 0.475773\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014618; batch adversarial loss: 0.415747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036287; batch adversarial loss: 0.452728\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038850; batch adversarial loss: 0.558723\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012812; batch adversarial loss: 0.458334\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019664; batch adversarial loss: 0.468196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042197; batch adversarial loss: 0.459876\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024018; batch adversarial loss: 0.406573\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022760; batch adversarial loss: 0.453985\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027231; batch adversarial loss: 0.361531\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019022; batch adversarial loss: 0.397889\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.540121\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029247; batch adversarial loss: 0.436080\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007431; batch adversarial loss: 0.441969\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006910; batch adversarial loss: 0.392736\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011241; batch adversarial loss: 0.409400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039927; batch adversarial loss: 0.463542\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026803; batch adversarial loss: 0.392854\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011942; batch adversarial loss: 0.430503\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020708; batch adversarial loss: 0.463555\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026643; batch adversarial loss: 0.422430\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020502; batch adversarial loss: 0.447465\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012151; batch adversarial loss: 0.547413\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011645; batch adversarial loss: 0.469235\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017107; batch adversarial loss: 0.507616\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009593; batch adversarial loss: 0.381040\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016595; batch adversarial loss: 0.550248\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016781; batch adversarial loss: 0.450792\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007297; batch adversarial loss: 0.476336\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013944; batch adversarial loss: 0.570186\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021050; batch adversarial loss: 0.414484\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019919; batch adversarial loss: 0.577307\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.437469\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034759; batch adversarial loss: 0.500585\n",
      "epoch 177; iter: 0; batch classifier loss: 0.001768; batch adversarial loss: 0.450409\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017852; batch adversarial loss: 0.412918\n",
      "epoch 179; iter: 0; batch classifier loss: 0.002678; batch adversarial loss: 0.513283\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009874; batch adversarial loss: 0.460969\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008587; batch adversarial loss: 0.453327\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006294; batch adversarial loss: 0.463210\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033050; batch adversarial loss: 0.435226\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015839; batch adversarial loss: 0.489403\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004509; batch adversarial loss: 0.589690\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013291; batch adversarial loss: 0.495200\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022633; batch adversarial loss: 0.498410\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.500343\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012892; batch adversarial loss: 0.438334\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010096; batch adversarial loss: 0.463635\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004525; batch adversarial loss: 0.374157\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011323; batch adversarial loss: 0.440408\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019246; batch adversarial loss: 0.372019\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036904; batch adversarial loss: 0.468478\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008607; batch adversarial loss: 0.465517\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007162; batch adversarial loss: 0.477499\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037133; batch adversarial loss: 0.487344\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.497253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013299; batch adversarial loss: 0.396153\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681891; batch adversarial loss: 0.604350\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469838; batch adversarial loss: 0.610165\n",
      "epoch 2; iter: 0; batch classifier loss: 0.339891; batch adversarial loss: 0.636865\n",
      "epoch 3; iter: 0; batch classifier loss: 0.533691; batch adversarial loss: 0.655569\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548652; batch adversarial loss: 0.635399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576024; batch adversarial loss: 0.645765\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552707; batch adversarial loss: 0.593241\n",
      "epoch 7; iter: 0; batch classifier loss: 0.446596; batch adversarial loss: 0.567635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446295; batch adversarial loss: 0.571561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417835; batch adversarial loss: 0.515616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455250; batch adversarial loss: 0.501641\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369932; batch adversarial loss: 0.512077\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383678; batch adversarial loss: 0.532040\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373429; batch adversarial loss: 0.478531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373072; batch adversarial loss: 0.451717\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.470321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337080; batch adversarial loss: 0.554987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331951; batch adversarial loss: 0.438700\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316045; batch adversarial loss: 0.444272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273849; batch adversarial loss: 0.466004\n",
      "epoch 20; iter: 0; batch classifier loss: 0.284075; batch adversarial loss: 0.535333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338642; batch adversarial loss: 0.430663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.266070; batch adversarial loss: 0.504396\n",
      "epoch 23; iter: 0; batch classifier loss: 0.300564; batch adversarial loss: 0.500034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265991; batch adversarial loss: 0.416385\n",
      "epoch 25; iter: 0; batch classifier loss: 0.214386; batch adversarial loss: 0.573169\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200786; batch adversarial loss: 0.427070\n",
      "epoch 27; iter: 0; batch classifier loss: 0.266926; batch adversarial loss: 0.544409\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228398; batch adversarial loss: 0.437102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249083; batch adversarial loss: 0.486489\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265411; batch adversarial loss: 0.363916\n",
      "epoch 31; iter: 0; batch classifier loss: 0.251382; batch adversarial loss: 0.480887\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248411; batch adversarial loss: 0.576675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202104; batch adversarial loss: 0.495076\n",
      "epoch 34; iter: 0; batch classifier loss: 0.321533; batch adversarial loss: 0.544842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206402; batch adversarial loss: 0.454979\n",
      "epoch 36; iter: 0; batch classifier loss: 0.222783; batch adversarial loss: 0.475665\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207233; batch adversarial loss: 0.542532\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213456; batch adversarial loss: 0.546884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.275247; batch adversarial loss: 0.384424\n",
      "epoch 40; iter: 0; batch classifier loss: 0.199586; batch adversarial loss: 0.539680\n",
      "epoch 41; iter: 0; batch classifier loss: 0.232870; batch adversarial loss: 0.449452\n",
      "epoch 42; iter: 0; batch classifier loss: 0.191706; batch adversarial loss: 0.505592\n",
      "epoch 43; iter: 0; batch classifier loss: 0.252945; batch adversarial loss: 0.382072\n",
      "epoch 44; iter: 0; batch classifier loss: 0.256658; batch adversarial loss: 0.539098\n",
      "epoch 45; iter: 0; batch classifier loss: 0.247936; batch adversarial loss: 0.470478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168355; batch adversarial loss: 0.494404\n",
      "epoch 47; iter: 0; batch classifier loss: 0.136432; batch adversarial loss: 0.423581\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154412; batch adversarial loss: 0.459058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107486; batch adversarial loss: 0.485001\n",
      "epoch 50; iter: 0; batch classifier loss: 0.171442; batch adversarial loss: 0.576016\n",
      "epoch 51; iter: 0; batch classifier loss: 0.212962; batch adversarial loss: 0.504128\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163304; batch adversarial loss: 0.409985\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137723; batch adversarial loss: 0.514580\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122239; batch adversarial loss: 0.496307\n",
      "epoch 55; iter: 0; batch classifier loss: 0.225576; batch adversarial loss: 0.540824\n",
      "epoch 56; iter: 0; batch classifier loss: 0.193752; batch adversarial loss: 0.578487\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170438; batch adversarial loss: 0.457701\n",
      "epoch 58; iter: 0; batch classifier loss: 0.212119; batch adversarial loss: 0.399472\n",
      "epoch 59; iter: 0; batch classifier loss: 0.240398; batch adversarial loss: 0.424200\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245245; batch adversarial loss: 0.388800\n",
      "epoch 61; iter: 0; batch classifier loss: 0.169196; batch adversarial loss: 0.471765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.157765; batch adversarial loss: 0.531287\n",
      "epoch 63; iter: 0; batch classifier loss: 0.197948; batch adversarial loss: 0.446846\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108579; batch adversarial loss: 0.517914\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105566; batch adversarial loss: 0.531800\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109413; batch adversarial loss: 0.501613\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162431; batch adversarial loss: 0.468906\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234339; batch adversarial loss: 0.434399\n",
      "epoch 69; iter: 0; batch classifier loss: 0.142369; batch adversarial loss: 0.519212\n",
      "epoch 70; iter: 0; batch classifier loss: 0.151272; batch adversarial loss: 0.530521\n",
      "epoch 71; iter: 0; batch classifier loss: 0.185036; batch adversarial loss: 0.418966\n",
      "epoch 72; iter: 0; batch classifier loss: 0.170486; batch adversarial loss: 0.492817\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191255; batch adversarial loss: 0.364685\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136191; batch adversarial loss: 0.505634\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154362; batch adversarial loss: 0.517271\n",
      "epoch 76; iter: 0; batch classifier loss: 0.216926; batch adversarial loss: 0.421008\n",
      "epoch 77; iter: 0; batch classifier loss: 0.162104; batch adversarial loss: 0.481796\n",
      "epoch 78; iter: 0; batch classifier loss: 0.249027; batch adversarial loss: 0.482174\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135477; batch adversarial loss: 0.458921\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153200; batch adversarial loss: 0.494579\n",
      "epoch 81; iter: 0; batch classifier loss: 0.176230; batch adversarial loss: 0.457001\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189079; batch adversarial loss: 0.410572\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126229; batch adversarial loss: 0.521261\n",
      "epoch 84; iter: 0; batch classifier loss: 0.117994; batch adversarial loss: 0.450032\n",
      "epoch 85; iter: 0; batch classifier loss: 0.160787; batch adversarial loss: 0.505659\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100635; batch adversarial loss: 0.520243\n",
      "epoch 87; iter: 0; batch classifier loss: 0.146640; batch adversarial loss: 0.457889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125277; batch adversarial loss: 0.495407\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099398; batch adversarial loss: 0.495878\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117044; batch adversarial loss: 0.430630\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087335; batch adversarial loss: 0.431112\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106018; batch adversarial loss: 0.449949\n",
      "epoch 93; iter: 0; batch classifier loss: 0.097271; batch adversarial loss: 0.445664\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076699; batch adversarial loss: 0.495614\n",
      "epoch 95; iter: 0; batch classifier loss: 0.098541; batch adversarial loss: 0.432834\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087735; batch adversarial loss: 0.449774\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085531; batch adversarial loss: 0.425461\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075501; batch adversarial loss: 0.488797\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079109; batch adversarial loss: 0.539466\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086551; batch adversarial loss: 0.538665\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042837; batch adversarial loss: 0.418424\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065723; batch adversarial loss: 0.519177\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031984; batch adversarial loss: 0.468743\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034977; batch adversarial loss: 0.435960\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055518; batch adversarial loss: 0.480209\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068720; batch adversarial loss: 0.436461\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048344; batch adversarial loss: 0.496472\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018762; batch adversarial loss: 0.423948\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066596; batch adversarial loss: 0.509167\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040724; batch adversarial loss: 0.430494\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044035; batch adversarial loss: 0.598345\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044060; batch adversarial loss: 0.441180\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067433; batch adversarial loss: 0.362626\n",
      "epoch 114; iter: 0; batch classifier loss: 0.130395; batch adversarial loss: 0.373353\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043275; batch adversarial loss: 0.431667\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030002; batch adversarial loss: 0.490042\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012214; batch adversarial loss: 0.557286\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043708; batch adversarial loss: 0.408832\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037880; batch adversarial loss: 0.552385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.046413; batch adversarial loss: 0.481901\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021556; batch adversarial loss: 0.422707\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.395978\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046019; batch adversarial loss: 0.445946\n",
      "epoch 124; iter: 0; batch classifier loss: 0.009408; batch adversarial loss: 0.520116\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024850; batch adversarial loss: 0.408291\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036873; batch adversarial loss: 0.394352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020988; batch adversarial loss: 0.464663\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038790; batch adversarial loss: 0.488968\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021125; batch adversarial loss: 0.433512\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048798; batch adversarial loss: 0.515814\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040680; batch adversarial loss: 0.489224\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.459904\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043781; batch adversarial loss: 0.520411\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042877; batch adversarial loss: 0.468682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016005; batch adversarial loss: 0.447425\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.485656\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025405; batch adversarial loss: 0.514275\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015357; batch adversarial loss: 0.394478\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.481683\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016135; batch adversarial loss: 0.412029\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020256; batch adversarial loss: 0.400430\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035230; batch adversarial loss: 0.447918\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040820; batch adversarial loss: 0.477856\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024328; batch adversarial loss: 0.431528\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009634; batch adversarial loss: 0.444462\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011421; batch adversarial loss: 0.436785\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021829; batch adversarial loss: 0.405096\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021282; batch adversarial loss: 0.523591\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020837; batch adversarial loss: 0.393360\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011717; batch adversarial loss: 0.440322\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016621; batch adversarial loss: 0.458321\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027937; batch adversarial loss: 0.471975\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031567; batch adversarial loss: 0.385150\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006190; batch adversarial loss: 0.471634\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022442; batch adversarial loss: 0.439379\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021424; batch adversarial loss: 0.507010\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009852; batch adversarial loss: 0.579580\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016430; batch adversarial loss: 0.441247\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029832; batch adversarial loss: 0.433781\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025228; batch adversarial loss: 0.431285\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008685; batch adversarial loss: 0.507725\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022382; batch adversarial loss: 0.427811\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045813; batch adversarial loss: 0.471924\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016480; batch adversarial loss: 0.406115\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023806; batch adversarial loss: 0.449915\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022582; batch adversarial loss: 0.414969\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024130; batch adversarial loss: 0.430784\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026104; batch adversarial loss: 0.448239\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012732; batch adversarial loss: 0.412602\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029314; batch adversarial loss: 0.443164\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007578; batch adversarial loss: 0.442045\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049885; batch adversarial loss: 0.421125\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027477; batch adversarial loss: 0.509842\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019501; batch adversarial loss: 0.466316\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006158; batch adversarial loss: 0.402071\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007990; batch adversarial loss: 0.587187\n",
      "epoch 177; iter: 0; batch classifier loss: 0.068628; batch adversarial loss: 0.409782\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012848; batch adversarial loss: 0.469236\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012847; batch adversarial loss: 0.463103\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044213; batch adversarial loss: 0.489311\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015332; batch adversarial loss: 0.424684\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013239; batch adversarial loss: 0.499075\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026977; batch adversarial loss: 0.531844\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009641; batch adversarial loss: 0.489490\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025828; batch adversarial loss: 0.430340\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007351; batch adversarial loss: 0.393184\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014739; batch adversarial loss: 0.432931\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010999; batch adversarial loss: 0.352058\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027949; batch adversarial loss: 0.505495\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.480537\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012967; batch adversarial loss: 0.469931\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031642; batch adversarial loss: 0.474778\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.484023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018290; batch adversarial loss: 0.436898\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029805; batch adversarial loss: 0.492126\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023947; batch adversarial loss: 0.407016\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028737; batch adversarial loss: 0.471276\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006124; batch adversarial loss: 0.397310\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014883; batch adversarial loss: 0.410366\n",
      "epoch 0; iter: 0; batch classifier loss: 0.739126; batch adversarial loss: 0.713068\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435136; batch adversarial loss: 0.683812\n",
      "epoch 2; iter: 0; batch classifier loss: 0.454981; batch adversarial loss: 0.655221\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362111; batch adversarial loss: 0.629337\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382571; batch adversarial loss: 0.563735\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355392; batch adversarial loss: 0.529401\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254618; batch adversarial loss: 0.542698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284211; batch adversarial loss: 0.500463\n",
      "epoch 8; iter: 0; batch classifier loss: 0.268931; batch adversarial loss: 0.525998\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323677; batch adversarial loss: 0.482878\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291118; batch adversarial loss: 0.520076\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255431; batch adversarial loss: 0.497335\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218779; batch adversarial loss: 0.455856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195509; batch adversarial loss: 0.442179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191261; batch adversarial loss: 0.442561\n",
      "epoch 15; iter: 0; batch classifier loss: 0.269306; batch adversarial loss: 0.529097\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228690; batch adversarial loss: 0.446974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.205540; batch adversarial loss: 0.472688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.128743; batch adversarial loss: 0.427376\n",
      "epoch 19; iter: 0; batch classifier loss: 0.158362; batch adversarial loss: 0.391219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133879; batch adversarial loss: 0.486891\n",
      "epoch 21; iter: 0; batch classifier loss: 0.128285; batch adversarial loss: 0.381574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.125242; batch adversarial loss: 0.350239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158580; batch adversarial loss: 0.434002\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182491; batch adversarial loss: 0.371948\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164638; batch adversarial loss: 0.357377\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188436; batch adversarial loss: 0.445362\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138115; batch adversarial loss: 0.402689\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166229; batch adversarial loss: 0.390619\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173564; batch adversarial loss: 0.521508\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186538; batch adversarial loss: 0.399867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168559; batch adversarial loss: 0.446964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093764; batch adversarial loss: 0.460780\n",
      "epoch 33; iter: 0; batch classifier loss: 0.110678; batch adversarial loss: 0.421248\n",
      "epoch 34; iter: 0; batch classifier loss: 0.124174; batch adversarial loss: 0.370866\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167012; batch adversarial loss: 0.325704\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141187; batch adversarial loss: 0.381883\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121962; batch adversarial loss: 0.393272\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133931; batch adversarial loss: 0.424157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112054; batch adversarial loss: 0.409779\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158082; batch adversarial loss: 0.407398\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084823; batch adversarial loss: 0.404700\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128532; batch adversarial loss: 0.391195\n",
      "epoch 43; iter: 0; batch classifier loss: 0.133864; batch adversarial loss: 0.395386\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097914; batch adversarial loss: 0.429661\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121917; batch adversarial loss: 0.387017\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121077; batch adversarial loss: 0.356034\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075417; batch adversarial loss: 0.382702\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100941; batch adversarial loss: 0.438752\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122286; batch adversarial loss: 0.426630\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087237; batch adversarial loss: 0.379928\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102785; batch adversarial loss: 0.337406\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111402; batch adversarial loss: 0.466711\n",
      "epoch 53; iter: 0; batch classifier loss: 0.136074; batch adversarial loss: 0.425209\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105021; batch adversarial loss: 0.404651\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111653; batch adversarial loss: 0.405123\n",
      "epoch 56; iter: 0; batch classifier loss: 0.062675; batch adversarial loss: 0.422195\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108146; batch adversarial loss: 0.452534\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096215; batch adversarial loss: 0.397990\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105576; batch adversarial loss: 0.375118\n",
      "epoch 60; iter: 0; batch classifier loss: 0.144164; batch adversarial loss: 0.495113\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112315; batch adversarial loss: 0.479609\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061392; batch adversarial loss: 0.407584\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093944; batch adversarial loss: 0.329197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093710; batch adversarial loss: 0.337592\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081512; batch adversarial loss: 0.468986\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096808; batch adversarial loss: 0.546419\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068965; batch adversarial loss: 0.540776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.100432; batch adversarial loss: 0.416693\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072133; batch adversarial loss: 0.512150\n",
      "epoch 70; iter: 0; batch classifier loss: 0.102117; batch adversarial loss: 0.401660\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104530; batch adversarial loss: 0.402999\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093862; batch adversarial loss: 0.460859\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069798; batch adversarial loss: 0.524197\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066705; batch adversarial loss: 0.307784\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097164; batch adversarial loss: 0.453180\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084394; batch adversarial loss: 0.363632\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076317; batch adversarial loss: 0.445294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082230; batch adversarial loss: 0.419372\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062185; batch adversarial loss: 0.401351\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043085; batch adversarial loss: 0.427977\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064777; batch adversarial loss: 0.372645\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104254; batch adversarial loss: 0.344912\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066096; batch adversarial loss: 0.393945\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074929; batch adversarial loss: 0.399690\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083101; batch adversarial loss: 0.465649\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070277; batch adversarial loss: 0.512540\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034147; batch adversarial loss: 0.466190\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034915; batch adversarial loss: 0.388724\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066005; batch adversarial loss: 0.398387\n",
      "epoch 90; iter: 0; batch classifier loss: 0.116271; batch adversarial loss: 0.354892\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043571; batch adversarial loss: 0.406459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051961; batch adversarial loss: 0.381015\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034423; batch adversarial loss: 0.443930\n",
      "epoch 94; iter: 0; batch classifier loss: 0.097888; batch adversarial loss: 0.423522\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050896; batch adversarial loss: 0.405201\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051476; batch adversarial loss: 0.481541\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055292; batch adversarial loss: 0.410180\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059108; batch adversarial loss: 0.357090\n",
      "epoch 99; iter: 0; batch classifier loss: 0.026323; batch adversarial loss: 0.453003\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024944; batch adversarial loss: 0.407761\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056416; batch adversarial loss: 0.467640\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053377; batch adversarial loss: 0.363255\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053652; batch adversarial loss: 0.406888\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041767; batch adversarial loss: 0.337489\n",
      "epoch 105; iter: 0; batch classifier loss: 0.073233; batch adversarial loss: 0.413061\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051605; batch adversarial loss: 0.396434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066914; batch adversarial loss: 0.359759\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038635; batch adversarial loss: 0.461307\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048708; batch adversarial loss: 0.340071\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049545; batch adversarial loss: 0.392472\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048638; batch adversarial loss: 0.436507\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041193; batch adversarial loss: 0.458141\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048430; batch adversarial loss: 0.405111\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040579; batch adversarial loss: 0.339582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.044820; batch adversarial loss: 0.375292\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029858; batch adversarial loss: 0.420136\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044028; batch adversarial loss: 0.436897\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028598; batch adversarial loss: 0.488221\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044992; batch adversarial loss: 0.373953\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018875; batch adversarial loss: 0.441477\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041223; batch adversarial loss: 0.420940\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030956; batch adversarial loss: 0.550644\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039405; batch adversarial loss: 0.486364\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.455921\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028186; batch adversarial loss: 0.434276\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033137; batch adversarial loss: 0.459397\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021751; batch adversarial loss: 0.447285\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037010; batch adversarial loss: 0.385556\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032960; batch adversarial loss: 0.489613\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056402; batch adversarial loss: 0.401967\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041229; batch adversarial loss: 0.410335\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033320; batch adversarial loss: 0.482501\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009793; batch adversarial loss: 0.368043\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021381; batch adversarial loss: 0.493591\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029089; batch adversarial loss: 0.516841\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033255; batch adversarial loss: 0.446383\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030550; batch adversarial loss: 0.479762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049660; batch adversarial loss: 0.553607\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055432; batch adversarial loss: 0.447594\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046763; batch adversarial loss: 0.536919\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053257; batch adversarial loss: 0.576750\n",
      "epoch 142; iter: 0; batch classifier loss: 0.185107; batch adversarial loss: 0.923808\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024138; batch adversarial loss: 0.576514\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043796; batch adversarial loss: 0.517904\n",
      "epoch 145; iter: 0; batch classifier loss: 0.155040; batch adversarial loss: 0.719452\n",
      "epoch 146; iter: 0; batch classifier loss: 0.087601; batch adversarial loss: 0.639296\n",
      "epoch 147; iter: 0; batch classifier loss: 0.127530; batch adversarial loss: 0.569399\n",
      "epoch 148; iter: 0; batch classifier loss: 0.139827; batch adversarial loss: 0.807268\n",
      "epoch 149; iter: 0; batch classifier loss: 0.134343; batch adversarial loss: 0.613425\n",
      "epoch 150; iter: 0; batch classifier loss: 0.097183; batch adversarial loss: 0.620244\n",
      "epoch 151; iter: 0; batch classifier loss: 0.126512; batch adversarial loss: 0.599547\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044457; batch adversarial loss: 0.416296\n",
      "epoch 153; iter: 0; batch classifier loss: 0.105110; batch adversarial loss: 0.634837\n",
      "epoch 154; iter: 0; batch classifier loss: 0.097725; batch adversarial loss: 0.632392\n",
      "epoch 155; iter: 0; batch classifier loss: 0.154317; batch adversarial loss: 0.653924\n",
      "epoch 156; iter: 0; batch classifier loss: 0.100748; batch adversarial loss: 0.561814\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057349; batch adversarial loss: 0.450555\n",
      "epoch 158; iter: 0; batch classifier loss: 0.150893; batch adversarial loss: 0.684222\n",
      "epoch 159; iter: 0; batch classifier loss: 0.110159; batch adversarial loss: 0.637848\n",
      "epoch 160; iter: 0; batch classifier loss: 0.201090; batch adversarial loss: 0.640034\n",
      "epoch 161; iter: 0; batch classifier loss: 0.124895; batch adversarial loss: 0.655918\n",
      "epoch 162; iter: 0; batch classifier loss: 0.165962; batch adversarial loss: 0.696572\n",
      "epoch 163; iter: 0; batch classifier loss: 0.104232; batch adversarial loss: 0.575654\n",
      "epoch 164; iter: 0; batch classifier loss: 0.188200; batch adversarial loss: 0.714370\n",
      "epoch 165; iter: 0; batch classifier loss: 0.180310; batch adversarial loss: 0.690176\n",
      "epoch 166; iter: 0; batch classifier loss: 0.084363; batch adversarial loss: 0.477374\n",
      "epoch 167; iter: 0; batch classifier loss: 0.091392; batch adversarial loss: 0.492265\n",
      "epoch 168; iter: 0; batch classifier loss: 0.092658; batch adversarial loss: 0.514386\n",
      "epoch 169; iter: 0; batch classifier loss: 0.175471; batch adversarial loss: 0.663318\n",
      "epoch 170; iter: 0; batch classifier loss: 0.187109; batch adversarial loss: 0.724254\n",
      "epoch 171; iter: 0; batch classifier loss: 0.135065; batch adversarial loss: 0.589340\n",
      "epoch 172; iter: 0; batch classifier loss: 0.147884; batch adversarial loss: 0.597366\n",
      "epoch 173; iter: 0; batch classifier loss: 0.107460; batch adversarial loss: 0.529602\n",
      "epoch 174; iter: 0; batch classifier loss: 0.149798; batch adversarial loss: 0.573381\n",
      "epoch 175; iter: 0; batch classifier loss: 0.127769; batch adversarial loss: 0.493753\n",
      "epoch 176; iter: 0; batch classifier loss: 0.149281; batch adversarial loss: 0.657060\n",
      "epoch 177; iter: 0; batch classifier loss: 0.179180; batch adversarial loss: 0.571708\n",
      "epoch 178; iter: 0; batch classifier loss: 0.086950; batch adversarial loss: 0.400366\n",
      "epoch 179; iter: 0; batch classifier loss: 0.131980; batch adversarial loss: 0.510548\n",
      "epoch 180; iter: 0; batch classifier loss: 0.134547; batch adversarial loss: 0.538418\n",
      "epoch 181; iter: 0; batch classifier loss: 0.166531; batch adversarial loss: 0.563879\n",
      "epoch 182; iter: 0; batch classifier loss: 0.096043; batch adversarial loss: 0.558721\n",
      "epoch 183; iter: 0; batch classifier loss: 0.085975; batch adversarial loss: 0.444428\n",
      "epoch 184; iter: 0; batch classifier loss: 0.129873; batch adversarial loss: 0.443203\n",
      "epoch 185; iter: 0; batch classifier loss: 0.073821; batch adversarial loss: 0.418314\n",
      "epoch 186; iter: 0; batch classifier loss: 0.117570; batch adversarial loss: 0.489547\n",
      "epoch 187; iter: 0; batch classifier loss: 0.137628; batch adversarial loss: 0.504450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.139417; batch adversarial loss: 0.515554\n",
      "epoch 189; iter: 0; batch classifier loss: 0.109179; batch adversarial loss: 0.465489\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074328; batch adversarial loss: 0.378937\n",
      "epoch 191; iter: 0; batch classifier loss: 0.066506; batch adversarial loss: 0.362027\n",
      "epoch 192; iter: 0; batch classifier loss: 0.163094; batch adversarial loss: 0.539567\n",
      "epoch 193; iter: 0; batch classifier loss: 0.138713; batch adversarial loss: 0.482827\n",
      "epoch 194; iter: 0; batch classifier loss: 0.113911; batch adversarial loss: 0.501924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.085749; batch adversarial loss: 0.458325\n",
      "epoch 196; iter: 0; batch classifier loss: 0.065526; batch adversarial loss: 0.366002\n",
      "epoch 197; iter: 0; batch classifier loss: 0.083964; batch adversarial loss: 0.490005\n",
      "epoch 198; iter: 0; batch classifier loss: 0.099297; batch adversarial loss: 0.451804\n",
      "epoch 199; iter: 0; batch classifier loss: 0.116505; batch adversarial loss: 0.510946\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702622; batch adversarial loss: 0.596383\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466049; batch adversarial loss: 0.609485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.441677; batch adversarial loss: 0.638581\n",
      "epoch 3; iter: 0; batch classifier loss: 0.304291; batch adversarial loss: 0.586919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.420620; batch adversarial loss: 0.576197\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351016; batch adversarial loss: 0.532189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364013; batch adversarial loss: 0.591137\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366388; batch adversarial loss: 0.593343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.329508; batch adversarial loss: 0.601440\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341864; batch adversarial loss: 0.585333\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.575566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.624960; batch adversarial loss: 0.597818\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597398; batch adversarial loss: 0.589862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.434629; batch adversarial loss: 0.495387\n",
      "epoch 14; iter: 0; batch classifier loss: 0.329526; batch adversarial loss: 0.493572\n",
      "epoch 15; iter: 0; batch classifier loss: 0.237085; batch adversarial loss: 0.465530\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261884; batch adversarial loss: 0.512804\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275741; batch adversarial loss: 0.518396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264941; batch adversarial loss: 0.467646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192619; batch adversarial loss: 0.478289\n",
      "epoch 20; iter: 0; batch classifier loss: 0.144270; batch adversarial loss: 0.413158\n",
      "epoch 21; iter: 0; batch classifier loss: 0.188172; batch adversarial loss: 0.434221\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188884; batch adversarial loss: 0.510198\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211394; batch adversarial loss: 0.486697\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229453; batch adversarial loss: 0.520078\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189805; batch adversarial loss: 0.481862\n",
      "epoch 26; iter: 0; batch classifier loss: 0.189410; batch adversarial loss: 0.556525\n",
      "epoch 27; iter: 0; batch classifier loss: 0.194642; batch adversarial loss: 0.460371\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210090; batch adversarial loss: 0.420412\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150159; batch adversarial loss: 0.484151\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137388; batch adversarial loss: 0.456230\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137953; batch adversarial loss: 0.426185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152509; batch adversarial loss: 0.474853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107157; batch adversarial loss: 0.524031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141907; batch adversarial loss: 0.468815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100363; batch adversarial loss: 0.470082\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137573; batch adversarial loss: 0.541270\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093628; batch adversarial loss: 0.522782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160833; batch adversarial loss: 0.430046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.188076; batch adversarial loss: 0.479456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.162285; batch adversarial loss: 0.337046\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146415; batch adversarial loss: 0.425145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119068; batch adversarial loss: 0.499223\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145318; batch adversarial loss: 0.468868\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124733; batch adversarial loss: 0.502680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151169; batch adversarial loss: 0.532444\n",
      "epoch 46; iter: 0; batch classifier loss: 0.171111; batch adversarial loss: 0.475238\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171646; batch adversarial loss: 0.448324\n",
      "epoch 48; iter: 0; batch classifier loss: 0.113672; batch adversarial loss: 0.486990\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101766; batch adversarial loss: 0.452118\n",
      "epoch 50; iter: 0; batch classifier loss: 0.174539; batch adversarial loss: 0.444620\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160906; batch adversarial loss: 0.532893\n",
      "epoch 52; iter: 0; batch classifier loss: 0.173917; batch adversarial loss: 0.469081\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163048; batch adversarial loss: 0.478188\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119493; batch adversarial loss: 0.433006\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097691; batch adversarial loss: 0.444414\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145676; batch adversarial loss: 0.439057\n",
      "epoch 57; iter: 0; batch classifier loss: 0.138230; batch adversarial loss: 0.522133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.164551; batch adversarial loss: 0.395159\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130659; batch adversarial loss: 0.525236\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115682; batch adversarial loss: 0.531675\n",
      "epoch 61; iter: 0; batch classifier loss: 0.212991; batch adversarial loss: 0.506282\n",
      "epoch 62; iter: 0; batch classifier loss: 0.171044; batch adversarial loss: 0.506126\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156123; batch adversarial loss: 0.419145\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101292; batch adversarial loss: 0.372119\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115879; batch adversarial loss: 0.460250\n",
      "epoch 66; iter: 0; batch classifier loss: 0.108836; batch adversarial loss: 0.477543\n",
      "epoch 67; iter: 0; batch classifier loss: 0.194117; batch adversarial loss: 0.436634\n",
      "epoch 68; iter: 0; batch classifier loss: 0.149248; batch adversarial loss: 0.412717\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098793; batch adversarial loss: 0.466585\n",
      "epoch 70; iter: 0; batch classifier loss: 0.129625; batch adversarial loss: 0.469583\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174787; batch adversarial loss: 0.513784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.133948; batch adversarial loss: 0.491176\n",
      "epoch 73; iter: 0; batch classifier loss: 0.174353; batch adversarial loss: 0.478403\n",
      "epoch 74; iter: 0; batch classifier loss: 0.141665; batch adversarial loss: 0.458874\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163707; batch adversarial loss: 0.470199\n",
      "epoch 76; iter: 0; batch classifier loss: 0.144687; batch adversarial loss: 0.481250\n",
      "epoch 77; iter: 0; batch classifier loss: 0.173531; batch adversarial loss: 0.411298\n",
      "epoch 78; iter: 0; batch classifier loss: 0.150476; batch adversarial loss: 0.469721\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138068; batch adversarial loss: 0.479866\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199161; batch adversarial loss: 0.471668\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123894; batch adversarial loss: 0.411356\n",
      "epoch 82; iter: 0; batch classifier loss: 0.167191; batch adversarial loss: 0.429865\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153315; batch adversarial loss: 0.421020\n",
      "epoch 84; iter: 0; batch classifier loss: 0.162723; batch adversarial loss: 0.453941\n",
      "epoch 85; iter: 0; batch classifier loss: 0.153354; batch adversarial loss: 0.435881\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102021; batch adversarial loss: 0.489518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.147620; batch adversarial loss: 0.450865\n",
      "epoch 88; iter: 0; batch classifier loss: 0.149647; batch adversarial loss: 0.496743\n",
      "epoch 89; iter: 0; batch classifier loss: 0.136586; batch adversarial loss: 0.467282\n",
      "epoch 90; iter: 0; batch classifier loss: 0.205047; batch adversarial loss: 0.432516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.125906; batch adversarial loss: 0.506549\n",
      "epoch 92; iter: 0; batch classifier loss: 0.149765; batch adversarial loss: 0.471870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.179891; batch adversarial loss: 0.421349\n",
      "epoch 94; iter: 0; batch classifier loss: 0.128154; batch adversarial loss: 0.481686\n",
      "epoch 95; iter: 0; batch classifier loss: 0.126333; batch adversarial loss: 0.459714\n",
      "epoch 96; iter: 0; batch classifier loss: 0.146704; batch adversarial loss: 0.443613\n",
      "epoch 97; iter: 0; batch classifier loss: 0.178596; batch adversarial loss: 0.432097\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172605; batch adversarial loss: 0.471510\n",
      "epoch 99; iter: 0; batch classifier loss: 0.181058; batch adversarial loss: 0.472296\n",
      "epoch 100; iter: 0; batch classifier loss: 0.129654; batch adversarial loss: 0.389013\n",
      "epoch 101; iter: 0; batch classifier loss: 0.146747; batch adversarial loss: 0.454928\n",
      "epoch 102; iter: 0; batch classifier loss: 0.123132; batch adversarial loss: 0.533073\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099379; batch adversarial loss: 0.416485\n",
      "epoch 104; iter: 0; batch classifier loss: 0.124627; batch adversarial loss: 0.579208\n",
      "epoch 105; iter: 0; batch classifier loss: 0.138122; batch adversarial loss: 0.482000\n",
      "epoch 106; iter: 0; batch classifier loss: 0.146538; batch adversarial loss: 0.432740\n",
      "epoch 107; iter: 0; batch classifier loss: 0.148462; batch adversarial loss: 0.415773\n",
      "epoch 108; iter: 0; batch classifier loss: 0.121527; batch adversarial loss: 0.407231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.100539; batch adversarial loss: 0.436904\n",
      "epoch 110; iter: 0; batch classifier loss: 0.160124; batch adversarial loss: 0.440707\n",
      "epoch 111; iter: 0; batch classifier loss: 0.107355; batch adversarial loss: 0.431064\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073069; batch adversarial loss: 0.528943\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056735; batch adversarial loss: 0.446193\n",
      "epoch 114; iter: 0; batch classifier loss: 0.125503; batch adversarial loss: 0.504268\n",
      "epoch 115; iter: 0; batch classifier loss: 0.111877; batch adversarial loss: 0.519771\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066637; batch adversarial loss: 0.568756\n",
      "epoch 117; iter: 0; batch classifier loss: 0.121176; batch adversarial loss: 0.479792\n",
      "epoch 118; iter: 0; batch classifier loss: 0.089205; batch adversarial loss: 0.470207\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064784; batch adversarial loss: 0.482205\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070092; batch adversarial loss: 0.540833\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034334; batch adversarial loss: 0.478549\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044519; batch adversarial loss: 0.511065\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088307; batch adversarial loss: 0.480752\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034808; batch adversarial loss: 0.559045\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050065; batch adversarial loss: 0.351715\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064889; batch adversarial loss: 0.577862\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041923; batch adversarial loss: 0.434055\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047831; batch adversarial loss: 0.435993\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055014; batch adversarial loss: 0.489114\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046366; batch adversarial loss: 0.461739\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039601; batch adversarial loss: 0.430699\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043310; batch adversarial loss: 0.464664\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052916; batch adversarial loss: 0.438132\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052501; batch adversarial loss: 0.404376\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024834; batch adversarial loss: 0.559135\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024036; batch adversarial loss: 0.407838\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031663; batch adversarial loss: 0.499956\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046314; batch adversarial loss: 0.434576\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029984; batch adversarial loss: 0.439358\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058439; batch adversarial loss: 0.483278\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026603; batch adversarial loss: 0.369224\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037453; batch adversarial loss: 0.422123\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026342; batch adversarial loss: 0.469751\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025846; batch adversarial loss: 0.428246\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025231; batch adversarial loss: 0.443257\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032250; batch adversarial loss: 0.366910\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025744; batch adversarial loss: 0.389920\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.494964\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.525371\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017791; batch adversarial loss: 0.389199\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031917; batch adversarial loss: 0.486051\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019848; batch adversarial loss: 0.442573\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017896; batch adversarial loss: 0.409368\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022522; batch adversarial loss: 0.421529\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028276; batch adversarial loss: 0.441513\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014941; batch adversarial loss: 0.385095\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010211; batch adversarial loss: 0.532504\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027704; batch adversarial loss: 0.484768\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023853; batch adversarial loss: 0.387497\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026179; batch adversarial loss: 0.432480\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022370; batch adversarial loss: 0.421121\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022994; batch adversarial loss: 0.454304\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035597; batch adversarial loss: 0.476992\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054265; batch adversarial loss: 0.443144\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023502; batch adversarial loss: 0.566813\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046932; batch adversarial loss: 0.503803\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032741; batch adversarial loss: 0.548276\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.461601\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.364284\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015792; batch adversarial loss: 0.461383\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032174; batch adversarial loss: 0.456885\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020431; batch adversarial loss: 0.462263\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022801; batch adversarial loss: 0.341113\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024605; batch adversarial loss: 0.468252\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009756; batch adversarial loss: 0.467035\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012857; batch adversarial loss: 0.342740\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024675; batch adversarial loss: 0.446478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014301; batch adversarial loss: 0.480113\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006710; batch adversarial loss: 0.410387\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024485; batch adversarial loss: 0.379961\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013746; batch adversarial loss: 0.427395\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010681; batch adversarial loss: 0.497333\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009902; batch adversarial loss: 0.446389\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016334; batch adversarial loss: 0.390073\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010007; batch adversarial loss: 0.463461\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.444708\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033948; batch adversarial loss: 0.477436\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014880; batch adversarial loss: 0.389485\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036851; batch adversarial loss: 0.411434\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022162; batch adversarial loss: 0.471188\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024684; batch adversarial loss: 0.458266\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009566; batch adversarial loss: 0.394862\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009130; batch adversarial loss: 0.488772\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011661; batch adversarial loss: 0.378461\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017003; batch adversarial loss: 0.481493\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009492; batch adversarial loss: 0.379486\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030048; batch adversarial loss: 0.385244\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008025; batch adversarial loss: 0.466487\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028710; batch adversarial loss: 0.501055\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675896; batch adversarial loss: 0.564982\n",
      "epoch 1; iter: 0; batch classifier loss: 0.436182; batch adversarial loss: 0.517270\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367449; batch adversarial loss: 0.605270\n",
      "epoch 3; iter: 0; batch classifier loss: 0.357925; batch adversarial loss: 0.541941\n",
      "epoch 4; iter: 0; batch classifier loss: 0.303593; batch adversarial loss: 0.576948\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366613; batch adversarial loss: 0.630920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.332495; batch adversarial loss: 0.530137\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356887; batch adversarial loss: 0.467283\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293395; batch adversarial loss: 0.595955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361508; batch adversarial loss: 0.570721\n",
      "epoch 10; iter: 0; batch classifier loss: 0.403251; batch adversarial loss: 0.511001\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400658; batch adversarial loss: 0.501220\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382524; batch adversarial loss: 0.512045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342545; batch adversarial loss: 0.522505\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279958; batch adversarial loss: 0.532018\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236908; batch adversarial loss: 0.538990\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236993; batch adversarial loss: 0.516564\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251449; batch adversarial loss: 0.470914\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227506; batch adversarial loss: 0.511451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228219; batch adversarial loss: 0.467986\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204135; batch adversarial loss: 0.543219\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247905; batch adversarial loss: 0.495426\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184093; batch adversarial loss: 0.500838\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169692; batch adversarial loss: 0.521412\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177203; batch adversarial loss: 0.417045\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151038; batch adversarial loss: 0.425215\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248670; batch adversarial loss: 0.492348\n",
      "epoch 27; iter: 0; batch classifier loss: 0.179963; batch adversarial loss: 0.531250\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188415; batch adversarial loss: 0.532056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156434; batch adversarial loss: 0.485721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124718; batch adversarial loss: 0.369713\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188826; batch adversarial loss: 0.467517\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136528; batch adversarial loss: 0.447952\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162284; batch adversarial loss: 0.500969\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143536; batch adversarial loss: 0.568675\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122258; batch adversarial loss: 0.439752\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150052; batch adversarial loss: 0.536120\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137951; batch adversarial loss: 0.455845\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121650; batch adversarial loss: 0.516977\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158526; batch adversarial loss: 0.535335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144758; batch adversarial loss: 0.449476\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181230; batch adversarial loss: 0.419884\n",
      "epoch 42; iter: 0; batch classifier loss: 0.144067; batch adversarial loss: 0.499197\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147087; batch adversarial loss: 0.489330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.208148; batch adversarial loss: 0.363235\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200147; batch adversarial loss: 0.430222\n",
      "epoch 46; iter: 0; batch classifier loss: 0.208242; batch adversarial loss: 0.473810\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122374; batch adversarial loss: 0.431391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.184189; batch adversarial loss: 0.350410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132819; batch adversarial loss: 0.478981\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181000; batch adversarial loss: 0.469798\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124176; batch adversarial loss: 0.512044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.185641; batch adversarial loss: 0.451666\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109779; batch adversarial loss: 0.406215\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199822; batch adversarial loss: 0.429675\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142650; batch adversarial loss: 0.472704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161339; batch adversarial loss: 0.443401\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188809; batch adversarial loss: 0.489621\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152572; batch adversarial loss: 0.490258\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172799; batch adversarial loss: 0.415821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.168118; batch adversarial loss: 0.427329\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143713; batch adversarial loss: 0.501613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121113; batch adversarial loss: 0.443155\n",
      "epoch 63; iter: 0; batch classifier loss: 0.178207; batch adversarial loss: 0.505299\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140258; batch adversarial loss: 0.432633\n",
      "epoch 65; iter: 0; batch classifier loss: 0.184616; batch adversarial loss: 0.473058\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137383; batch adversarial loss: 0.395542\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138147; batch adversarial loss: 0.527600\n",
      "epoch 68; iter: 0; batch classifier loss: 0.190481; batch adversarial loss: 0.438465\n",
      "epoch 69; iter: 0; batch classifier loss: 0.183551; batch adversarial loss: 0.424592\n",
      "epoch 70; iter: 0; batch classifier loss: 0.189930; batch adversarial loss: 0.445918\n",
      "epoch 71; iter: 0; batch classifier loss: 0.237913; batch adversarial loss: 0.420784\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151529; batch adversarial loss: 0.411089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128637; batch adversarial loss: 0.477804\n",
      "epoch 74; iter: 0; batch classifier loss: 0.152155; batch adversarial loss: 0.518241\n",
      "epoch 75; iter: 0; batch classifier loss: 0.190161; batch adversarial loss: 0.555445\n",
      "epoch 76; iter: 0; batch classifier loss: 0.127482; batch adversarial loss: 0.483013\n",
      "epoch 77; iter: 0; batch classifier loss: 0.187265; batch adversarial loss: 0.454269\n",
      "epoch 78; iter: 0; batch classifier loss: 0.122905; batch adversarial loss: 0.510996\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151423; batch adversarial loss: 0.597396\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137840; batch adversarial loss: 0.471994\n",
      "epoch 81; iter: 0; batch classifier loss: 0.146602; batch adversarial loss: 0.482611\n",
      "epoch 82; iter: 0; batch classifier loss: 0.219534; batch adversarial loss: 0.458490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.212792; batch adversarial loss: 0.419984\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166021; batch adversarial loss: 0.406255\n",
      "epoch 85; iter: 0; batch classifier loss: 0.144526; batch adversarial loss: 0.602210\n",
      "epoch 86; iter: 0; batch classifier loss: 0.188081; batch adversarial loss: 0.470484\n",
      "epoch 87; iter: 0; batch classifier loss: 0.197639; batch adversarial loss: 0.423359\n",
      "epoch 88; iter: 0; batch classifier loss: 0.191190; batch adversarial loss: 0.485871\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120858; batch adversarial loss: 0.483052\n",
      "epoch 90; iter: 0; batch classifier loss: 0.183433; batch adversarial loss: 0.456220\n",
      "epoch 91; iter: 0; batch classifier loss: 0.129216; batch adversarial loss: 0.422694\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111994; batch adversarial loss: 0.515252\n",
      "epoch 93; iter: 0; batch classifier loss: 0.237927; batch adversarial loss: 0.408428\n",
      "epoch 94; iter: 0; batch classifier loss: 0.177175; batch adversarial loss: 0.445012\n",
      "epoch 95; iter: 0; batch classifier loss: 0.155734; batch adversarial loss: 0.466528\n",
      "epoch 96; iter: 0; batch classifier loss: 0.148666; batch adversarial loss: 0.427854\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214691; batch adversarial loss: 0.493811\n",
      "epoch 98; iter: 0; batch classifier loss: 0.177213; batch adversarial loss: 0.418561\n",
      "epoch 99; iter: 0; batch classifier loss: 0.185377; batch adversarial loss: 0.481317\n",
      "epoch 100; iter: 0; batch classifier loss: 0.086507; batch adversarial loss: 0.516011\n",
      "epoch 101; iter: 0; batch classifier loss: 0.118897; batch adversarial loss: 0.480541\n",
      "epoch 102; iter: 0; batch classifier loss: 0.175416; batch adversarial loss: 0.431022\n",
      "epoch 103; iter: 0; batch classifier loss: 0.161211; batch adversarial loss: 0.516464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.146191; batch adversarial loss: 0.415519\n",
      "epoch 105; iter: 0; batch classifier loss: 0.124103; batch adversarial loss: 0.447601\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093345; batch adversarial loss: 0.397721\n",
      "epoch 107; iter: 0; batch classifier loss: 0.156979; batch adversarial loss: 0.423902\n",
      "epoch 108; iter: 0; batch classifier loss: 0.184672; batch adversarial loss: 0.486498\n",
      "epoch 109; iter: 0; batch classifier loss: 0.171999; batch adversarial loss: 0.480576\n",
      "epoch 110; iter: 0; batch classifier loss: 0.118736; batch adversarial loss: 0.453682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101805; batch adversarial loss: 0.404792\n",
      "epoch 112; iter: 0; batch classifier loss: 0.122027; batch adversarial loss: 0.499489\n",
      "epoch 113; iter: 0; batch classifier loss: 0.078709; batch adversarial loss: 0.508937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079377; batch adversarial loss: 0.453793\n",
      "epoch 115; iter: 0; batch classifier loss: 0.107528; batch adversarial loss: 0.446324\n",
      "epoch 116; iter: 0; batch classifier loss: 0.147627; batch adversarial loss: 0.439961\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065417; batch adversarial loss: 0.412161\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046237; batch adversarial loss: 0.588089\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060845; batch adversarial loss: 0.363900\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049207; batch adversarial loss: 0.497991\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059677; batch adversarial loss: 0.463534\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.359204\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064398; batch adversarial loss: 0.348689\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040054; batch adversarial loss: 0.394269\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037188; batch adversarial loss: 0.505511\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050290; batch adversarial loss: 0.385058\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048995; batch adversarial loss: 0.442106\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061790; batch adversarial loss: 0.388585\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041465; batch adversarial loss: 0.481463\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048954; batch adversarial loss: 0.480169\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.511078\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027144; batch adversarial loss: 0.492474\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030300; batch adversarial loss: 0.406492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032885; batch adversarial loss: 0.470158\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031324; batch adversarial loss: 0.421266\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.389934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.068458; batch adversarial loss: 0.411382\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033810; batch adversarial loss: 0.426833\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024705; batch adversarial loss: 0.424662\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034343; batch adversarial loss: 0.539013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038686; batch adversarial loss: 0.456484\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026945; batch adversarial loss: 0.412733\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043820; batch adversarial loss: 0.481922\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021654; batch adversarial loss: 0.419640\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023021; batch adversarial loss: 0.525424\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050206; batch adversarial loss: 0.427898\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026461; batch adversarial loss: 0.375143\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.363671\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048414; batch adversarial loss: 0.428027\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027328; batch adversarial loss: 0.453808\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016074; batch adversarial loss: 0.421672\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.506646\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044815; batch adversarial loss: 0.407156\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030407; batch adversarial loss: 0.459301\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044436; batch adversarial loss: 0.415057\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015057; batch adversarial loss: 0.408854\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023179; batch adversarial loss: 0.464872\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033938; batch adversarial loss: 0.397319\n",
      "epoch 159; iter: 0; batch classifier loss: 0.069274; batch adversarial loss: 0.460737\n",
      "epoch 160; iter: 0; batch classifier loss: 0.060930; batch adversarial loss: 0.523527\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018633; batch adversarial loss: 0.500288\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012850; batch adversarial loss: 0.522044\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043140; batch adversarial loss: 0.427496\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029523; batch adversarial loss: 0.478823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019476; batch adversarial loss: 0.500766\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037401; batch adversarial loss: 0.415946\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015816; batch adversarial loss: 0.452801\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.450126\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042973; batch adversarial loss: 0.380889\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018155; batch adversarial loss: 0.410009\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036593; batch adversarial loss: 0.538969\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009384; batch adversarial loss: 0.475047\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017008; batch adversarial loss: 0.383325\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050258; batch adversarial loss: 0.462263\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012462; batch adversarial loss: 0.573938\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023987; batch adversarial loss: 0.424621\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020157; batch adversarial loss: 0.491392\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006432; batch adversarial loss: 0.420325\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020863; batch adversarial loss: 0.427897\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015045; batch adversarial loss: 0.417942\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034170; batch adversarial loss: 0.491512\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025148; batch adversarial loss: 0.516943\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023110; batch adversarial loss: 0.401140\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049949; batch adversarial loss: 0.568007\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026689; batch adversarial loss: 0.445281\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030594; batch adversarial loss: 0.499189\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033444; batch adversarial loss: 0.394479\n",
      "epoch 188; iter: 0; batch classifier loss: 0.056889; batch adversarial loss: 0.481461\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012284; batch adversarial loss: 0.450483\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018934; batch adversarial loss: 0.473325\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024634; batch adversarial loss: 0.571104\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009938; batch adversarial loss: 0.393649\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016007; batch adversarial loss: 0.419299\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035188; batch adversarial loss: 0.451124\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.438879\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018656; batch adversarial loss: 0.423552\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010765; batch adversarial loss: 0.537568\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007851; batch adversarial loss: 0.507481\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022319; batch adversarial loss: 0.482786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.690730; batch adversarial loss: 0.754152\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470934; batch adversarial loss: 0.702384\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360170; batch adversarial loss: 0.677191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.366766; batch adversarial loss: 0.651304\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361016; batch adversarial loss: 0.612048\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378965; batch adversarial loss: 0.577475\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331352; batch adversarial loss: 0.552877\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351466; batch adversarial loss: 0.499605\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252089; batch adversarial loss: 0.476451\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254078; batch adversarial loss: 0.462825\n",
      "epoch 10; iter: 0; batch classifier loss: 0.196331; batch adversarial loss: 0.528292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335497; batch adversarial loss: 0.475065\n",
      "epoch 12; iter: 0; batch classifier loss: 0.218992; batch adversarial loss: 0.431829\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299830; batch adversarial loss: 0.515494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232726; batch adversarial loss: 0.383313\n",
      "epoch 15; iter: 0; batch classifier loss: 0.169978; batch adversarial loss: 0.496261\n",
      "epoch 16; iter: 0; batch classifier loss: 0.167630; batch adversarial loss: 0.474632\n",
      "epoch 17; iter: 0; batch classifier loss: 0.171712; batch adversarial loss: 0.449895\n",
      "epoch 18; iter: 0; batch classifier loss: 0.176090; batch adversarial loss: 0.443670\n",
      "epoch 19; iter: 0; batch classifier loss: 0.171663; batch adversarial loss: 0.397326\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202402; batch adversarial loss: 0.483606\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200041; batch adversarial loss: 0.391570\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200055; batch adversarial loss: 0.448724\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172255; batch adversarial loss: 0.388848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.158660; batch adversarial loss: 0.421137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.180050; batch adversarial loss: 0.427161\n",
      "epoch 26; iter: 0; batch classifier loss: 0.116341; batch adversarial loss: 0.427039\n",
      "epoch 27; iter: 0; batch classifier loss: 0.126715; batch adversarial loss: 0.444322\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147906; batch adversarial loss: 0.391282\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168528; batch adversarial loss: 0.381155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.115357; batch adversarial loss: 0.384182\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176624; batch adversarial loss: 0.469183\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136645; batch adversarial loss: 0.409325\n",
      "epoch 33; iter: 0; batch classifier loss: 0.174910; batch adversarial loss: 0.410722\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116945; batch adversarial loss: 0.404938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185145; batch adversarial loss: 0.425315\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128303; batch adversarial loss: 0.454622\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119080; batch adversarial loss: 0.396599\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139460; batch adversarial loss: 0.420002\n",
      "epoch 39; iter: 0; batch classifier loss: 0.097455; batch adversarial loss: 0.442647\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104198; batch adversarial loss: 0.477234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157479; batch adversarial loss: 0.483638\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122875; batch adversarial loss: 0.402812\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117507; batch adversarial loss: 0.408379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140914; batch adversarial loss: 0.488200\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088291; batch adversarial loss: 0.349289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096222; batch adversarial loss: 0.427606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.065639; batch adversarial loss: 0.436040\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089215; batch adversarial loss: 0.431237\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082454; batch adversarial loss: 0.455081\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094883; batch adversarial loss: 0.482451\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115128; batch adversarial loss: 0.456045\n",
      "epoch 52; iter: 0; batch classifier loss: 0.143528; batch adversarial loss: 0.510997\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088254; batch adversarial loss: 0.428280\n",
      "epoch 54; iter: 0; batch classifier loss: 0.115767; batch adversarial loss: 0.467348\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076127; batch adversarial loss: 0.388913\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112154; batch adversarial loss: 0.379847\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086710; batch adversarial loss: 0.443151\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100412; batch adversarial loss: 0.386087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.051814; batch adversarial loss: 0.506792\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088985; batch adversarial loss: 0.381260\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098792; batch adversarial loss: 0.381792\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124331; batch adversarial loss: 0.494406\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096804; batch adversarial loss: 0.467461\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073581; batch adversarial loss: 0.336680\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077900; batch adversarial loss: 0.411037\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095229; batch adversarial loss: 0.466490\n",
      "epoch 67; iter: 0; batch classifier loss: 0.093394; batch adversarial loss: 0.368621\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108452; batch adversarial loss: 0.412745\n",
      "epoch 69; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.435877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090601; batch adversarial loss: 0.393339\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078820; batch adversarial loss: 0.403806\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097368; batch adversarial loss: 0.431462\n",
      "epoch 73; iter: 0; batch classifier loss: 0.054354; batch adversarial loss: 0.388536\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088579; batch adversarial loss: 0.397566\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078488; batch adversarial loss: 0.402482\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060764; batch adversarial loss: 0.484230\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050293; batch adversarial loss: 0.444627\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076743; batch adversarial loss: 0.388972\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081461; batch adversarial loss: 0.327155\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076042; batch adversarial loss: 0.421941\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083278; batch adversarial loss: 0.416793\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087139; batch adversarial loss: 0.442011\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088402; batch adversarial loss: 0.407146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099987; batch adversarial loss: 0.339771\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069380; batch adversarial loss: 0.458697\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094932; batch adversarial loss: 0.410873\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050510; batch adversarial loss: 0.521770\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092020; batch adversarial loss: 0.374638\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036669; batch adversarial loss: 0.406706\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075906; batch adversarial loss: 0.409340\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055891; batch adversarial loss: 0.391064\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065752; batch adversarial loss: 0.485610\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069374; batch adversarial loss: 0.563746\n",
      "epoch 94; iter: 0; batch classifier loss: 0.055647; batch adversarial loss: 0.433994\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058331; batch adversarial loss: 0.429048\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045550; batch adversarial loss: 0.398784\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054674; batch adversarial loss: 0.402013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.062835; batch adversarial loss: 0.470108\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054774; batch adversarial loss: 0.516154\n",
      "epoch 100; iter: 0; batch classifier loss: 0.071439; batch adversarial loss: 0.361064\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063505; batch adversarial loss: 0.451572\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033522; batch adversarial loss: 0.457713\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031611; batch adversarial loss: 0.392935\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036898; batch adversarial loss: 0.568392\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078613; batch adversarial loss: 0.421926\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052313; batch adversarial loss: 0.460756\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.384295\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053028; batch adversarial loss: 0.422770\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029069; batch adversarial loss: 0.457532\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057407; batch adversarial loss: 0.492994\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020596; batch adversarial loss: 0.441364\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064847; batch adversarial loss: 0.466369\n",
      "epoch 113; iter: 0; batch classifier loss: 0.067415; batch adversarial loss: 0.339841\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054346; batch adversarial loss: 0.436373\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022186; batch adversarial loss: 0.463029\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022329; batch adversarial loss: 0.472956\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020682; batch adversarial loss: 0.498195\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028278; batch adversarial loss: 0.486929\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043368; batch adversarial loss: 0.460312\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.437416\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012053; batch adversarial loss: 0.434760\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057930; batch adversarial loss: 0.407539\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028765; batch adversarial loss: 0.460710\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032689; batch adversarial loss: 0.430681\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021667; batch adversarial loss: 0.467016\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047118; batch adversarial loss: 0.482404\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037418; batch adversarial loss: 0.524776\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039705; batch adversarial loss: 0.435092\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013397; batch adversarial loss: 0.468843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033073; batch adversarial loss: 0.434799\n",
      "epoch 131; iter: 0; batch classifier loss: 0.081609; batch adversarial loss: 0.628664\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047167; batch adversarial loss: 0.508604\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056212; batch adversarial loss: 0.555135\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025319; batch adversarial loss: 0.417704\n",
      "epoch 135; iter: 0; batch classifier loss: 0.070401; batch adversarial loss: 0.583592\n",
      "epoch 136; iter: 0; batch classifier loss: 0.066725; batch adversarial loss: 0.596077\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042626; batch adversarial loss: 0.528935\n",
      "epoch 138; iter: 0; batch classifier loss: 0.114955; batch adversarial loss: 0.699287\n",
      "epoch 139; iter: 0; batch classifier loss: 0.086524; batch adversarial loss: 0.686467\n",
      "epoch 140; iter: 0; batch classifier loss: 0.131945; batch adversarial loss: 0.609765\n",
      "epoch 141; iter: 0; batch classifier loss: 0.138019; batch adversarial loss: 0.678445\n",
      "epoch 142; iter: 0; batch classifier loss: 0.128739; batch adversarial loss: 0.536590\n",
      "epoch 143; iter: 0; batch classifier loss: 0.123348; batch adversarial loss: 0.494506\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163502; batch adversarial loss: 0.604566\n",
      "epoch 145; iter: 0; batch classifier loss: 0.108191; batch adversarial loss: 0.579676\n",
      "epoch 146; iter: 0; batch classifier loss: 0.127544; batch adversarial loss: 0.558646\n",
      "epoch 147; iter: 0; batch classifier loss: 0.148937; batch adversarial loss: 0.650984\n",
      "epoch 148; iter: 0; batch classifier loss: 0.143561; batch adversarial loss: 0.547453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.109043; batch adversarial loss: 0.506456\n",
      "epoch 150; iter: 0; batch classifier loss: 0.170111; batch adversarial loss: 0.710673\n",
      "epoch 151; iter: 0; batch classifier loss: 0.156814; batch adversarial loss: 0.618228\n",
      "epoch 152; iter: 0; batch classifier loss: 0.178413; batch adversarial loss: 0.578254\n",
      "epoch 153; iter: 0; batch classifier loss: 0.139263; batch adversarial loss: 0.607619\n",
      "epoch 154; iter: 0; batch classifier loss: 0.125567; batch adversarial loss: 0.498790\n",
      "epoch 155; iter: 0; batch classifier loss: 0.114923; batch adversarial loss: 0.593832\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091916; batch adversarial loss: 0.504772\n",
      "epoch 157; iter: 0; batch classifier loss: 0.171817; batch adversarial loss: 0.629189\n",
      "epoch 158; iter: 0; batch classifier loss: 0.106595; batch adversarial loss: 0.452898\n",
      "epoch 159; iter: 0; batch classifier loss: 0.140369; batch adversarial loss: 0.561540\n",
      "epoch 160; iter: 0; batch classifier loss: 0.135405; batch adversarial loss: 0.558102\n",
      "epoch 161; iter: 0; batch classifier loss: 0.167234; batch adversarial loss: 0.600255\n",
      "epoch 162; iter: 0; batch classifier loss: 0.195896; batch adversarial loss: 0.692707\n",
      "epoch 163; iter: 0; batch classifier loss: 0.125348; batch adversarial loss: 0.456781\n",
      "epoch 164; iter: 0; batch classifier loss: 0.155680; batch adversarial loss: 0.630458\n",
      "epoch 165; iter: 0; batch classifier loss: 0.117029; batch adversarial loss: 0.530602\n",
      "epoch 166; iter: 0; batch classifier loss: 0.161609; batch adversarial loss: 0.541043\n",
      "epoch 167; iter: 0; batch classifier loss: 0.171093; batch adversarial loss: 0.609706\n",
      "epoch 168; iter: 0; batch classifier loss: 0.202823; batch adversarial loss: 0.569394\n",
      "epoch 169; iter: 0; batch classifier loss: 0.125008; batch adversarial loss: 0.485744\n",
      "epoch 170; iter: 0; batch classifier loss: 0.138060; batch adversarial loss: 0.576028\n",
      "epoch 171; iter: 0; batch classifier loss: 0.124081; batch adversarial loss: 0.423729\n",
      "epoch 172; iter: 0; batch classifier loss: 0.149220; batch adversarial loss: 0.531657\n",
      "epoch 173; iter: 0; batch classifier loss: 0.128350; batch adversarial loss: 0.497293\n",
      "epoch 174; iter: 0; batch classifier loss: 0.130051; batch adversarial loss: 0.505788\n",
      "epoch 175; iter: 0; batch classifier loss: 0.069084; batch adversarial loss: 0.420974\n",
      "epoch 176; iter: 0; batch classifier loss: 0.127498; batch adversarial loss: 0.445154\n",
      "epoch 177; iter: 0; batch classifier loss: 0.153766; batch adversarial loss: 0.604274\n",
      "epoch 178; iter: 0; batch classifier loss: 0.119364; batch adversarial loss: 0.540360\n",
      "epoch 179; iter: 0; batch classifier loss: 0.089186; batch adversarial loss: 0.454371\n",
      "epoch 180; iter: 0; batch classifier loss: 0.111075; batch adversarial loss: 0.449340\n",
      "epoch 181; iter: 0; batch classifier loss: 0.152417; batch adversarial loss: 0.422344\n",
      "epoch 182; iter: 0; batch classifier loss: 0.075535; batch adversarial loss: 0.348078\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024715; batch adversarial loss: 0.449817\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.488815\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050579; batch adversarial loss: 0.453008\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033995; batch adversarial loss: 0.515645\n",
      "epoch 187; iter: 0; batch classifier loss: 0.054525; batch adversarial loss: 0.456376\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036886; batch adversarial loss: 0.434076\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027384; batch adversarial loss: 0.555597\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030576; batch adversarial loss: 0.453651\n",
      "epoch 191; iter: 0; batch classifier loss: 0.066965; batch adversarial loss: 0.344389\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042886; batch adversarial loss: 0.532637\n",
      "epoch 193; iter: 0; batch classifier loss: 0.069091; batch adversarial loss: 0.329193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.053377; batch adversarial loss: 0.455378\n",
      "epoch 195; iter: 0; batch classifier loss: 0.065343; batch adversarial loss: 0.443032\n",
      "epoch 196; iter: 0; batch classifier loss: 0.052048; batch adversarial loss: 0.458305\n",
      "epoch 197; iter: 0; batch classifier loss: 0.067305; batch adversarial loss: 0.512159\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036467; batch adversarial loss: 0.410472\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062304; batch adversarial loss: 0.448191\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692299; batch adversarial loss: 0.604722\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489263; batch adversarial loss: 0.597239\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423078; batch adversarial loss: 0.600005\n",
      "epoch 3; iter: 0; batch classifier loss: 0.486966; batch adversarial loss: 0.597545\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368798; batch adversarial loss: 0.655929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368392; batch adversarial loss: 0.607783\n",
      "epoch 6; iter: 0; batch classifier loss: 0.354876; batch adversarial loss: 0.544253\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362509; batch adversarial loss: 0.563358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.333904; batch adversarial loss: 0.587578\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308908; batch adversarial loss: 0.590121\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317203; batch adversarial loss: 0.506096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359052; batch adversarial loss: 0.509068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277965; batch adversarial loss: 0.498339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302644; batch adversarial loss: 0.462188\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267836; batch adversarial loss: 0.477862\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209678; batch adversarial loss: 0.507300\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229422; batch adversarial loss: 0.425910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.194478; batch adversarial loss: 0.528918\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251616; batch adversarial loss: 0.505333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.146944; batch adversarial loss: 0.488671\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198090; batch adversarial loss: 0.437223\n",
      "epoch 21; iter: 0; batch classifier loss: 0.158149; batch adversarial loss: 0.469364\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191561; batch adversarial loss: 0.477456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222306; batch adversarial loss: 0.460924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218709; batch adversarial loss: 0.482901\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202469; batch adversarial loss: 0.461386\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180927; batch adversarial loss: 0.479255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171250; batch adversarial loss: 0.456904\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220650; batch adversarial loss: 0.569608\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161843; batch adversarial loss: 0.379317\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144628; batch adversarial loss: 0.524518\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162888; batch adversarial loss: 0.504995\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216740; batch adversarial loss: 0.392562\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224625; batch adversarial loss: 0.529466\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205915; batch adversarial loss: 0.476581\n",
      "epoch 35; iter: 0; batch classifier loss: 0.247328; batch adversarial loss: 0.468702\n",
      "epoch 36; iter: 0; batch classifier loss: 0.239183; batch adversarial loss: 0.490484\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232731; batch adversarial loss: 0.435351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.193250; batch adversarial loss: 0.474541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.190987; batch adversarial loss: 0.506597\n",
      "epoch 40; iter: 0; batch classifier loss: 0.231124; batch adversarial loss: 0.456960\n",
      "epoch 41; iter: 0; batch classifier loss: 0.268815; batch adversarial loss: 0.524198\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214933; batch adversarial loss: 0.417020\n",
      "epoch 43; iter: 0; batch classifier loss: 0.206368; batch adversarial loss: 0.346187\n",
      "epoch 44; iter: 0; batch classifier loss: 0.246337; batch adversarial loss: 0.404399\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215102; batch adversarial loss: 0.412826\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223738; batch adversarial loss: 0.478584\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180952; batch adversarial loss: 0.460130\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180440; batch adversarial loss: 0.342946\n",
      "epoch 49; iter: 0; batch classifier loss: 0.212076; batch adversarial loss: 0.457847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.220817; batch adversarial loss: 0.385351\n",
      "epoch 51; iter: 0; batch classifier loss: 0.321899; batch adversarial loss: 0.445794\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180767; batch adversarial loss: 0.517490\n",
      "epoch 53; iter: 0; batch classifier loss: 0.198987; batch adversarial loss: 0.446912\n",
      "epoch 54; iter: 0; batch classifier loss: 0.310409; batch adversarial loss: 0.362852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119393; batch adversarial loss: 0.495039\n",
      "epoch 56; iter: 0; batch classifier loss: 0.106706; batch adversarial loss: 0.480540\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092336; batch adversarial loss: 0.513685\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091617; batch adversarial loss: 0.487657\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076407; batch adversarial loss: 0.527457\n",
      "epoch 60; iter: 0; batch classifier loss: 0.152367; batch adversarial loss: 0.390756\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103178; batch adversarial loss: 0.399954\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072209; batch adversarial loss: 0.524367\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094758; batch adversarial loss: 0.427511\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076405; batch adversarial loss: 0.523168\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083480; batch adversarial loss: 0.477450\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072231; batch adversarial loss: 0.398607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071531; batch adversarial loss: 0.390650\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083777; batch adversarial loss: 0.354058\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081240; batch adversarial loss: 0.398339\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069380; batch adversarial loss: 0.405102\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099611; batch adversarial loss: 0.449970\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068440; batch adversarial loss: 0.417794\n",
      "epoch 73; iter: 0; batch classifier loss: 0.113173; batch adversarial loss: 0.546531\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066238; batch adversarial loss: 0.414282\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074121; batch adversarial loss: 0.406236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057190; batch adversarial loss: 0.345863\n",
      "epoch 77; iter: 0; batch classifier loss: 0.113165; batch adversarial loss: 0.504293\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077091; batch adversarial loss: 0.451795\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059817; batch adversarial loss: 0.462381\n",
      "epoch 80; iter: 0; batch classifier loss: 0.131651; batch adversarial loss: 0.513052\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070998; batch adversarial loss: 0.452462\n",
      "epoch 82; iter: 0; batch classifier loss: 0.081727; batch adversarial loss: 0.473855\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071513; batch adversarial loss: 0.437052\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073495; batch adversarial loss: 0.467801\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085473; batch adversarial loss: 0.459945\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073753; batch adversarial loss: 0.357776\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062018; batch adversarial loss: 0.510963\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066930; batch adversarial loss: 0.443478\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080017; batch adversarial loss: 0.359599\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077966; batch adversarial loss: 0.341679\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072361; batch adversarial loss: 0.377966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.076019; batch adversarial loss: 0.312410\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079342; batch adversarial loss: 0.380120\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079703; batch adversarial loss: 0.463950\n",
      "epoch 95; iter: 0; batch classifier loss: 0.120677; batch adversarial loss: 0.416456\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051844; batch adversarial loss: 0.463232\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077533; batch adversarial loss: 0.481778\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071479; batch adversarial loss: 0.449769\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069899; batch adversarial loss: 0.424448\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068393; batch adversarial loss: 0.400800\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091727; batch adversarial loss: 0.357381\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078934; batch adversarial loss: 0.392607\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069660; batch adversarial loss: 0.458467\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054764; batch adversarial loss: 0.483158\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069620; batch adversarial loss: 0.435891\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087377; batch adversarial loss: 0.359677\n",
      "epoch 107; iter: 0; batch classifier loss: 0.049549; batch adversarial loss: 0.426342\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047914; batch adversarial loss: 0.396691\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074733; batch adversarial loss: 0.317624\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050761; batch adversarial loss: 0.392911\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081000; batch adversarial loss: 0.489787\n",
      "epoch 112; iter: 0; batch classifier loss: 0.113364; batch adversarial loss: 0.510216\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074419; batch adversarial loss: 0.479225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069921; batch adversarial loss: 0.457236\n",
      "epoch 115; iter: 0; batch classifier loss: 0.095640; batch adversarial loss: 0.383800\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074200; batch adversarial loss: 0.441421\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056871; batch adversarial loss: 0.443203\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063257; batch adversarial loss: 0.383668\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069045; batch adversarial loss: 0.417279\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077545; batch adversarial loss: 0.431470\n",
      "epoch 121; iter: 0; batch classifier loss: 0.086687; batch adversarial loss: 0.492917\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036321; batch adversarial loss: 0.501236\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046925; batch adversarial loss: 0.432245\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041632; batch adversarial loss: 0.402761\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057786; batch adversarial loss: 0.400632\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052608; batch adversarial loss: 0.501424\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053429; batch adversarial loss: 0.404663\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049472; batch adversarial loss: 0.402497\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043393; batch adversarial loss: 0.407571\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059370; batch adversarial loss: 0.427999\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054578; batch adversarial loss: 0.336547\n",
      "epoch 132; iter: 0; batch classifier loss: 0.051030; batch adversarial loss: 0.431447\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041016; batch adversarial loss: 0.405255\n",
      "epoch 134; iter: 0; batch classifier loss: 0.065384; batch adversarial loss: 0.458679\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048515; batch adversarial loss: 0.341805\n",
      "epoch 136; iter: 0; batch classifier loss: 0.068140; batch adversarial loss: 0.491914\n",
      "epoch 137; iter: 0; batch classifier loss: 0.065037; batch adversarial loss: 0.463614\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035494; batch adversarial loss: 0.344679\n",
      "epoch 139; iter: 0; batch classifier loss: 0.064866; batch adversarial loss: 0.353168\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042544; batch adversarial loss: 0.433413\n",
      "epoch 141; iter: 0; batch classifier loss: 0.066322; batch adversarial loss: 0.334200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045272; batch adversarial loss: 0.431042\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040610; batch adversarial loss: 0.403612\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061058; batch adversarial loss: 0.471330\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043789; batch adversarial loss: 0.477732\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026531; batch adversarial loss: 0.385512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026231; batch adversarial loss: 0.555501\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056433; batch adversarial loss: 0.457781\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033112; batch adversarial loss: 0.485220\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041551; batch adversarial loss: 0.473468\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028423; batch adversarial loss: 0.307207\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040771; batch adversarial loss: 0.440767\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032670; batch adversarial loss: 0.469085\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030202; batch adversarial loss: 0.400167\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025086; batch adversarial loss: 0.511215\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036701; batch adversarial loss: 0.396884\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033417; batch adversarial loss: 0.370252\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038483; batch adversarial loss: 0.339349\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034389; batch adversarial loss: 0.477163\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026731; batch adversarial loss: 0.392430\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020304; batch adversarial loss: 0.509651\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021285; batch adversarial loss: 0.471993\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043775; batch adversarial loss: 0.400461\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040041; batch adversarial loss: 0.416726\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025515; batch adversarial loss: 0.423782\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019097; batch adversarial loss: 0.466794\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042162; batch adversarial loss: 0.383477\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023934; batch adversarial loss: 0.471801\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021480; batch adversarial loss: 0.475395\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026001; batch adversarial loss: 0.361664\n",
      "epoch 171; iter: 0; batch classifier loss: 0.057149; batch adversarial loss: 0.358229\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018150; batch adversarial loss: 0.465412\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008524; batch adversarial loss: 0.436162\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027501; batch adversarial loss: 0.403523\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027563; batch adversarial loss: 0.463344\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023367; batch adversarial loss: 0.482782\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023057; batch adversarial loss: 0.429410\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020107; batch adversarial loss: 0.385339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019400; batch adversarial loss: 0.467177\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017537; batch adversarial loss: 0.404579\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.390016\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042968; batch adversarial loss: 0.391830\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034173; batch adversarial loss: 0.471930\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022601; batch adversarial loss: 0.480423\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017519; batch adversarial loss: 0.414275\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019624; batch adversarial loss: 0.482332\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020821; batch adversarial loss: 0.373270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.015031; batch adversarial loss: 0.455674\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041680; batch adversarial loss: 0.393238\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022796; batch adversarial loss: 0.520114\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008919; batch adversarial loss: 0.371790\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005438; batch adversarial loss: 0.404519\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015811; batch adversarial loss: 0.492333\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012003; batch adversarial loss: 0.386886\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018501; batch adversarial loss: 0.515011\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026204; batch adversarial loss: 0.445774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007228; batch adversarial loss: 0.450960\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016012; batch adversarial loss: 0.465364\n",
      "epoch 199; iter: 0; batch classifier loss: 0.039782; batch adversarial loss: 0.511164\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691952; batch adversarial loss: 0.563719\n",
      "epoch 1; iter: 0; batch classifier loss: 0.407191; batch adversarial loss: 0.590329\n",
      "epoch 2; iter: 0; batch classifier loss: 0.308206; batch adversarial loss: 0.551141\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400822; batch adversarial loss: 0.558875\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412845; batch adversarial loss: 0.540436\n",
      "epoch 5; iter: 0; batch classifier loss: 0.289096; batch adversarial loss: 0.551555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.551080\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290109; batch adversarial loss: 0.525057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303226; batch adversarial loss: 0.516849\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392186; batch adversarial loss: 0.578051\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363623; batch adversarial loss: 0.495544\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551112; batch adversarial loss: 0.574749\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470391; batch adversarial loss: 0.553990\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585231; batch adversarial loss: 0.609790\n",
      "epoch 14; iter: 0; batch classifier loss: 0.630521; batch adversarial loss: 0.536623\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398516; batch adversarial loss: 0.578657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364374; batch adversarial loss: 0.486208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.237810; batch adversarial loss: 0.465467\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261117; batch adversarial loss: 0.455720\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297215; batch adversarial loss: 0.439167\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243667; batch adversarial loss: 0.412115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.180525; batch adversarial loss: 0.504706\n",
      "epoch 22; iter: 0; batch classifier loss: 0.185292; batch adversarial loss: 0.442086\n",
      "epoch 23; iter: 0; batch classifier loss: 0.144217; batch adversarial loss: 0.501413\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190769; batch adversarial loss: 0.502455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171421; batch adversarial loss: 0.449748\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157535; batch adversarial loss: 0.561840\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184570; batch adversarial loss: 0.478647\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158565; batch adversarial loss: 0.445138\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178478; batch adversarial loss: 0.473945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.204309; batch adversarial loss: 0.443724\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111582; batch adversarial loss: 0.453875\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199478; batch adversarial loss: 0.447130\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163708; batch adversarial loss: 0.448613\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128667; batch adversarial loss: 0.460192\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121132; batch adversarial loss: 0.520875\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120784; batch adversarial loss: 0.457120\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117532; batch adversarial loss: 0.419210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127618; batch adversarial loss: 0.398664\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106509; batch adversarial loss: 0.459236\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158884; batch adversarial loss: 0.538444\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116657; batch adversarial loss: 0.402347\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135239; batch adversarial loss: 0.452872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126182; batch adversarial loss: 0.430545\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092962; batch adversarial loss: 0.496474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128771; batch adversarial loss: 0.421567\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097351; batch adversarial loss: 0.484913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122466; batch adversarial loss: 0.396265\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114611; batch adversarial loss: 0.472190\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095785; batch adversarial loss: 0.379473\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160271; batch adversarial loss: 0.457662\n",
      "epoch 51; iter: 0; batch classifier loss: 0.144150; batch adversarial loss: 0.441472\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156301; batch adversarial loss: 0.497311\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160172; batch adversarial loss: 0.460449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112420; batch adversarial loss: 0.471092\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103567; batch adversarial loss: 0.429648\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128997; batch adversarial loss: 0.429440\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085994; batch adversarial loss: 0.425657\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106785; batch adversarial loss: 0.510730\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098442; batch adversarial loss: 0.525665\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165892; batch adversarial loss: 0.469795\n",
      "epoch 61; iter: 0; batch classifier loss: 0.148454; batch adversarial loss: 0.426971\n",
      "epoch 62; iter: 0; batch classifier loss: 0.095789; batch adversarial loss: 0.443483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102501; batch adversarial loss: 0.572336\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110930; batch adversarial loss: 0.474664\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122529; batch adversarial loss: 0.451119\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125074; batch adversarial loss: 0.520513\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132959; batch adversarial loss: 0.449323\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113193; batch adversarial loss: 0.446264\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108656; batch adversarial loss: 0.542761\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103872; batch adversarial loss: 0.354755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.124485; batch adversarial loss: 0.424535\n",
      "epoch 72; iter: 0; batch classifier loss: 0.141309; batch adversarial loss: 0.531164\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083068; batch adversarial loss: 0.524491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139127; batch adversarial loss: 0.337123\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198117; batch adversarial loss: 0.471448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.187134; batch adversarial loss: 0.433959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111564; batch adversarial loss: 0.510307\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136277; batch adversarial loss: 0.440741\n",
      "epoch 79; iter: 0; batch classifier loss: 0.103373; batch adversarial loss: 0.467152\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110877; batch adversarial loss: 0.454242\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072954; batch adversarial loss: 0.451299\n",
      "epoch 82; iter: 0; batch classifier loss: 0.121127; batch adversarial loss: 0.474432\n",
      "epoch 83; iter: 0; batch classifier loss: 0.158183; batch adversarial loss: 0.440898\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102475; batch adversarial loss: 0.377298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.082938; batch adversarial loss: 0.468579\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108835; batch adversarial loss: 0.600093\n",
      "epoch 87; iter: 0; batch classifier loss: 0.107162; batch adversarial loss: 0.433010\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085305; batch adversarial loss: 0.512603\n",
      "epoch 89; iter: 0; batch classifier loss: 0.131422; batch adversarial loss: 0.456333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091558; batch adversarial loss: 0.345583\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102609; batch adversarial loss: 0.623904\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113734; batch adversarial loss: 0.488780\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089827; batch adversarial loss: 0.535361\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083759; batch adversarial loss: 0.594303\n",
      "epoch 95; iter: 0; batch classifier loss: 0.106033; batch adversarial loss: 0.462127\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075318; batch adversarial loss: 0.489742\n",
      "epoch 97; iter: 0; batch classifier loss: 0.135354; batch adversarial loss: 0.429980\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051966; batch adversarial loss: 0.423310\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107031; batch adversarial loss: 0.407571\n",
      "epoch 100; iter: 0; batch classifier loss: 0.096796; batch adversarial loss: 0.480728\n",
      "epoch 101; iter: 0; batch classifier loss: 0.111086; batch adversarial loss: 0.496075\n",
      "epoch 102; iter: 0; batch classifier loss: 0.105773; batch adversarial loss: 0.424538\n",
      "epoch 103; iter: 0; batch classifier loss: 0.095703; batch adversarial loss: 0.474807\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070099; batch adversarial loss: 0.437384\n",
      "epoch 105; iter: 0; batch classifier loss: 0.113954; batch adversarial loss: 0.510981\n",
      "epoch 106; iter: 0; batch classifier loss: 0.101230; batch adversarial loss: 0.469025\n",
      "epoch 107; iter: 0; batch classifier loss: 0.124717; batch adversarial loss: 0.447577\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043794; batch adversarial loss: 0.539930\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056931; batch adversarial loss: 0.551229\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075177; batch adversarial loss: 0.347329\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061920; batch adversarial loss: 0.434981\n",
      "epoch 112; iter: 0; batch classifier loss: 0.152338; batch adversarial loss: 0.416934\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020227; batch adversarial loss: 0.584915\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068159; batch adversarial loss: 0.499099\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033982; batch adversarial loss: 0.468211\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036963; batch adversarial loss: 0.410197\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070674; batch adversarial loss: 0.498809\n",
      "epoch 118; iter: 0; batch classifier loss: 0.102134; batch adversarial loss: 0.388434\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053594; batch adversarial loss: 0.449985\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059781; batch adversarial loss: 0.491685\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044670; batch adversarial loss: 0.417732\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063467; batch adversarial loss: 0.425326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082665; batch adversarial loss: 0.564573\n",
      "epoch 124; iter: 0; batch classifier loss: 0.076368; batch adversarial loss: 0.472488\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042805; batch adversarial loss: 0.489984\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071725; batch adversarial loss: 0.361529\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036970; batch adversarial loss: 0.398114\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027910; batch adversarial loss: 0.517798\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061214; batch adversarial loss: 0.420792\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062477; batch adversarial loss: 0.455874\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039911; batch adversarial loss: 0.543738\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042404; batch adversarial loss: 0.512614\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019656; batch adversarial loss: 0.524603\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028195; batch adversarial loss: 0.457573\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024225; batch adversarial loss: 0.524741\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023796; batch adversarial loss: 0.463824\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015275; batch adversarial loss: 0.469654\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012350; batch adversarial loss: 0.406196\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024451; batch adversarial loss: 0.470585\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049630; batch adversarial loss: 0.434422\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049895; batch adversarial loss: 0.419494\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037763; batch adversarial loss: 0.453230\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052180; batch adversarial loss: 0.401321\n",
      "epoch 144; iter: 0; batch classifier loss: 0.075489; batch adversarial loss: 0.461001\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.480176\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050723; batch adversarial loss: 0.451512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029908; batch adversarial loss: 0.445945\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017219; batch adversarial loss: 0.534829\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028605; batch adversarial loss: 0.436817\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022917; batch adversarial loss: 0.478958\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014406; batch adversarial loss: 0.476380\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028260; batch adversarial loss: 0.466418\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043830; batch adversarial loss: 0.454826\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034369; batch adversarial loss: 0.418670\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036168; batch adversarial loss: 0.561746\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022247; batch adversarial loss: 0.455646\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015193; batch adversarial loss: 0.490077\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026992; batch adversarial loss: 0.482022\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.527627\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012585; batch adversarial loss: 0.539489\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012899; batch adversarial loss: 0.396622\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007020; batch adversarial loss: 0.312776\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038746; batch adversarial loss: 0.431363\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013935; batch adversarial loss: 0.439570\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017232; batch adversarial loss: 0.436991\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021072; batch adversarial loss: 0.471041\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024007; batch adversarial loss: 0.479715\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045745; batch adversarial loss: 0.426740\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016814; batch adversarial loss: 0.441122\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026813; batch adversarial loss: 0.428317\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028840; batch adversarial loss: 0.412397\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019271; batch adversarial loss: 0.468876\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019206; batch adversarial loss: 0.452992\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010815; batch adversarial loss: 0.483570\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015664; batch adversarial loss: 0.361361\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013595; batch adversarial loss: 0.484374\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030974; batch adversarial loss: 0.433408\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022131; batch adversarial loss: 0.442594\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012796; batch adversarial loss: 0.491556\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031485; batch adversarial loss: 0.526950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.015035; batch adversarial loss: 0.471908\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017176; batch adversarial loss: 0.530601\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.498987\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024656; batch adversarial loss: 0.421244\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015209; batch adversarial loss: 0.348725\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024552; batch adversarial loss: 0.408972\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035007; batch adversarial loss: 0.512462\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025882; batch adversarial loss: 0.526206\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007168; batch adversarial loss: 0.347097\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008977; batch adversarial loss: 0.441422\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038247; batch adversarial loss: 0.412707\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013508; batch adversarial loss: 0.495026\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026470; batch adversarial loss: 0.437355\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036526; batch adversarial loss: 0.402202\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011521; batch adversarial loss: 0.631410\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007256; batch adversarial loss: 0.418877\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021554; batch adversarial loss: 0.419357\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.373318\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005505; batch adversarial loss: 0.408739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692544; batch adversarial loss: 0.565350\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492382; batch adversarial loss: 0.629467\n",
      "epoch 2; iter: 0; batch classifier loss: 0.453958; batch adversarial loss: 0.591430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392694; batch adversarial loss: 0.609807\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409659; batch adversarial loss: 0.662952\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555940; batch adversarial loss: 0.603008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626741; batch adversarial loss: 0.601360\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477556; batch adversarial loss: 0.600279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506530; batch adversarial loss: 0.563829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454282; batch adversarial loss: 0.568770\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422982; batch adversarial loss: 0.559645\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351550; batch adversarial loss: 0.522787\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334139; batch adversarial loss: 0.475707\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312842; batch adversarial loss: 0.528721\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348042; batch adversarial loss: 0.527612\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296029; batch adversarial loss: 0.468842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265375; batch adversarial loss: 0.462036\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270463; batch adversarial loss: 0.599804\n",
      "epoch 18; iter: 0; batch classifier loss: 0.289796; batch adversarial loss: 0.536563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324498; batch adversarial loss: 0.482235\n",
      "epoch 20; iter: 0; batch classifier loss: 0.208112; batch adversarial loss: 0.456723\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328838; batch adversarial loss: 0.484208\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264794; batch adversarial loss: 0.506783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239369; batch adversarial loss: 0.468910\n",
      "epoch 24; iter: 0; batch classifier loss: 0.272551; batch adversarial loss: 0.471140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291490; batch adversarial loss: 0.469826\n",
      "epoch 26; iter: 0; batch classifier loss: 0.243214; batch adversarial loss: 0.506989\n",
      "epoch 27; iter: 0; batch classifier loss: 0.263555; batch adversarial loss: 0.447785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.245581; batch adversarial loss: 0.422488\n",
      "epoch 29; iter: 0; batch classifier loss: 0.253721; batch adversarial loss: 0.410387\n",
      "epoch 30; iter: 0; batch classifier loss: 0.299190; batch adversarial loss: 0.458503\n",
      "epoch 31; iter: 0; batch classifier loss: 0.237339; batch adversarial loss: 0.349142\n",
      "epoch 32; iter: 0; batch classifier loss: 0.169540; batch adversarial loss: 0.421221\n",
      "epoch 33; iter: 0; batch classifier loss: 0.169545; batch adversarial loss: 0.474904\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186960; batch adversarial loss: 0.505066\n",
      "epoch 35; iter: 0; batch classifier loss: 0.188496; batch adversarial loss: 0.407380\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280522; batch adversarial loss: 0.527196\n",
      "epoch 37; iter: 0; batch classifier loss: 0.199757; batch adversarial loss: 0.498542\n",
      "epoch 38; iter: 0; batch classifier loss: 0.233561; batch adversarial loss: 0.438962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174548; batch adversarial loss: 0.426632\n",
      "epoch 40; iter: 0; batch classifier loss: 0.190624; batch adversarial loss: 0.483837\n",
      "epoch 41; iter: 0; batch classifier loss: 0.211035; batch adversarial loss: 0.371721\n",
      "epoch 42; iter: 0; batch classifier loss: 0.186641; batch adversarial loss: 0.434993\n",
      "epoch 43; iter: 0; batch classifier loss: 0.275859; batch adversarial loss: 0.379466\n",
      "epoch 44; iter: 0; batch classifier loss: 0.232919; batch adversarial loss: 0.506019\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215109; batch adversarial loss: 0.482838\n",
      "epoch 46; iter: 0; batch classifier loss: 0.202632; batch adversarial loss: 0.494702\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108689; batch adversarial loss: 0.410263\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148645; batch adversarial loss: 0.435427\n",
      "epoch 49; iter: 0; batch classifier loss: 0.139272; batch adversarial loss: 0.445947\n",
      "epoch 50; iter: 0; batch classifier loss: 0.176280; batch adversarial loss: 0.447556\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280866; batch adversarial loss: 0.484802\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148397; batch adversarial loss: 0.385883\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110432; batch adversarial loss: 0.446194\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190152; batch adversarial loss: 0.496086\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134009; batch adversarial loss: 0.496473\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158956; batch adversarial loss: 0.384170\n",
      "epoch 57; iter: 0; batch classifier loss: 0.209438; batch adversarial loss: 0.496028\n",
      "epoch 58; iter: 0; batch classifier loss: 0.121238; batch adversarial loss: 0.606804\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174081; batch adversarial loss: 0.471801\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161020; batch adversarial loss: 0.458866\n",
      "epoch 61; iter: 0; batch classifier loss: 0.257826; batch adversarial loss: 0.446686\n",
      "epoch 62; iter: 0; batch classifier loss: 0.157298; batch adversarial loss: 0.470673\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115255; batch adversarial loss: 0.642027\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084074; batch adversarial loss: 0.456114\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125155; batch adversarial loss: 0.497971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.156733; batch adversarial loss: 0.483272\n",
      "epoch 67; iter: 0; batch classifier loss: 0.157387; batch adversarial loss: 0.459106\n",
      "epoch 68; iter: 0; batch classifier loss: 0.137301; batch adversarial loss: 0.482874\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217447; batch adversarial loss: 0.384081\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219304; batch adversarial loss: 0.409799\n",
      "epoch 71; iter: 0; batch classifier loss: 0.171303; batch adversarial loss: 0.422000\n",
      "epoch 72; iter: 0; batch classifier loss: 0.178106; batch adversarial loss: 0.483426\n",
      "epoch 73; iter: 0; batch classifier loss: 0.167705; batch adversarial loss: 0.532633\n",
      "epoch 74; iter: 0; batch classifier loss: 0.073118; batch adversarial loss: 0.471485\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069314; batch adversarial loss: 0.546098\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132321; batch adversarial loss: 0.421423\n",
      "epoch 77; iter: 0; batch classifier loss: 0.222502; batch adversarial loss: 0.457790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.136932; batch adversarial loss: 0.447342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.207831; batch adversarial loss: 0.384280\n",
      "epoch 80; iter: 0; batch classifier loss: 0.165783; batch adversarial loss: 0.483664\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102317; batch adversarial loss: 0.520972\n",
      "epoch 82; iter: 0; batch classifier loss: 0.198777; batch adversarial loss: 0.495825\n",
      "epoch 83; iter: 0; batch classifier loss: 0.272096; batch adversarial loss: 0.385003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.118808; batch adversarial loss: 0.544589\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055989; batch adversarial loss: 0.259541\n",
      "epoch 86; iter: 0; batch classifier loss: 0.068686; batch adversarial loss: 0.585518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.109752; batch adversarial loss: 0.493437\n",
      "epoch 88; iter: 0; batch classifier loss: 0.123203; batch adversarial loss: 0.454595\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100329; batch adversarial loss: 0.385201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.148703; batch adversarial loss: 0.397796\n",
      "epoch 91; iter: 0; batch classifier loss: 0.169041; batch adversarial loss: 0.498891\n",
      "epoch 92; iter: 0; batch classifier loss: 0.183298; batch adversarial loss: 0.521628\n",
      "epoch 93; iter: 0; batch classifier loss: 0.194001; batch adversarial loss: 0.444715\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173406; batch adversarial loss: 0.447152\n",
      "epoch 95; iter: 0; batch classifier loss: 0.205607; batch adversarial loss: 0.399657\n",
      "epoch 96; iter: 0; batch classifier loss: 0.159089; batch adversarial loss: 0.485088\n",
      "epoch 97; iter: 0; batch classifier loss: 0.174758; batch adversarial loss: 0.407902\n",
      "epoch 98; iter: 0; batch classifier loss: 0.210359; batch adversarial loss: 0.495297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.165353; batch adversarial loss: 0.447353\n",
      "epoch 100; iter: 0; batch classifier loss: 0.166269; batch adversarial loss: 0.458772\n",
      "epoch 101; iter: 0; batch classifier loss: 0.193163; batch adversarial loss: 0.445864\n",
      "epoch 102; iter: 0; batch classifier loss: 0.171939; batch adversarial loss: 0.446608\n",
      "epoch 103; iter: 0; batch classifier loss: 0.212573; batch adversarial loss: 0.447006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.137820; batch adversarial loss: 0.397296\n",
      "epoch 105; iter: 0; batch classifier loss: 0.109522; batch adversarial loss: 0.532912\n",
      "epoch 106; iter: 0; batch classifier loss: 0.143238; batch adversarial loss: 0.471415\n",
      "epoch 107; iter: 0; batch classifier loss: 0.129967; batch adversarial loss: 0.483892\n",
      "epoch 108; iter: 0; batch classifier loss: 0.116737; batch adversarial loss: 0.495636\n",
      "epoch 109; iter: 0; batch classifier loss: 0.170851; batch adversarial loss: 0.520055\n",
      "epoch 110; iter: 0; batch classifier loss: 0.155356; batch adversarial loss: 0.484021\n",
      "epoch 111; iter: 0; batch classifier loss: 0.175867; batch adversarial loss: 0.459011\n",
      "epoch 112; iter: 0; batch classifier loss: 0.171068; batch adversarial loss: 0.620713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.160141; batch adversarial loss: 0.446757\n",
      "epoch 114; iter: 0; batch classifier loss: 0.156802; batch adversarial loss: 0.459485\n",
      "epoch 115; iter: 0; batch classifier loss: 0.177210; batch adversarial loss: 0.433693\n",
      "epoch 116; iter: 0; batch classifier loss: 0.199606; batch adversarial loss: 0.495763\n",
      "epoch 117; iter: 0; batch classifier loss: 0.185857; batch adversarial loss: 0.371959\n",
      "epoch 118; iter: 0; batch classifier loss: 0.141104; batch adversarial loss: 0.421259\n",
      "epoch 119; iter: 0; batch classifier loss: 0.145156; batch adversarial loss: 0.409209\n",
      "epoch 120; iter: 0; batch classifier loss: 0.169522; batch adversarial loss: 0.507566\n",
      "epoch 121; iter: 0; batch classifier loss: 0.189715; batch adversarial loss: 0.458866\n",
      "epoch 122; iter: 0; batch classifier loss: 0.152526; batch adversarial loss: 0.421927\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080812; batch adversarial loss: 0.395958\n",
      "epoch 124; iter: 0; batch classifier loss: 0.095262; batch adversarial loss: 0.472114\n",
      "epoch 125; iter: 0; batch classifier loss: 0.124763; batch adversarial loss: 0.443644\n",
      "epoch 126; iter: 0; batch classifier loss: 0.073317; batch adversarial loss: 0.464366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068898; batch adversarial loss: 0.499836\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047986; batch adversarial loss: 0.502561\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077929; batch adversarial loss: 0.518452\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.476179\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044456; batch adversarial loss: 0.387278\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042380; batch adversarial loss: 0.473012\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052458; batch adversarial loss: 0.430523\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030863; batch adversarial loss: 0.581308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032289; batch adversarial loss: 0.364346\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061252; batch adversarial loss: 0.474302\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024350; batch adversarial loss: 0.489640\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051423; batch adversarial loss: 0.374395\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025368; batch adversarial loss: 0.489076\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.501288\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030852; batch adversarial loss: 0.400920\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045367; batch adversarial loss: 0.436131\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029641; batch adversarial loss: 0.500887\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028438; batch adversarial loss: 0.465549\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034013; batch adversarial loss: 0.325757\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051738; batch adversarial loss: 0.472163\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039805; batch adversarial loss: 0.473131\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034412; batch adversarial loss: 0.465218\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016179; batch adversarial loss: 0.529129\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021850; batch adversarial loss: 0.324148\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017228; batch adversarial loss: 0.550986\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038088; batch adversarial loss: 0.408876\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023703; batch adversarial loss: 0.533610\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017536; batch adversarial loss: 0.486455\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015363; batch adversarial loss: 0.463819\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012348; batch adversarial loss: 0.443351\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014459; batch adversarial loss: 0.619599\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012474; batch adversarial loss: 0.515223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038235; batch adversarial loss: 0.450432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035954; batch adversarial loss: 0.437250\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008397; batch adversarial loss: 0.462519\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015388; batch adversarial loss: 0.401275\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023306; batch adversarial loss: 0.391796\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022786; batch adversarial loss: 0.410133\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046697; batch adversarial loss: 0.469120\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.475128\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021237; batch adversarial loss: 0.429840\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021175; batch adversarial loss: 0.493197\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034550; batch adversarial loss: 0.499702\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018942; batch adversarial loss: 0.492193\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021612; batch adversarial loss: 0.501619\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029778; batch adversarial loss: 0.440706\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027198; batch adversarial loss: 0.428912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.033491; batch adversarial loss: 0.489497\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010771; batch adversarial loss: 0.327318\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018193; batch adversarial loss: 0.511101\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020993; batch adversarial loss: 0.385982\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023470; batch adversarial loss: 0.441695\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031653; batch adversarial loss: 0.371276\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014943; batch adversarial loss: 0.445248\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016409; batch adversarial loss: 0.302974\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017223; batch adversarial loss: 0.449089\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017398; batch adversarial loss: 0.493429\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017123; batch adversarial loss: 0.371555\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014461; batch adversarial loss: 0.581116\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022777; batch adversarial loss: 0.415636\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020356; batch adversarial loss: 0.385652\n",
      "epoch 188; iter: 0; batch classifier loss: 0.004362; batch adversarial loss: 0.463173\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010833; batch adversarial loss: 0.483767\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015035; batch adversarial loss: 0.408557\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030458; batch adversarial loss: 0.614385\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017646; batch adversarial loss: 0.373181\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018090; batch adversarial loss: 0.503936\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004508; batch adversarial loss: 0.506864\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010259; batch adversarial loss: 0.433206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009278; batch adversarial loss: 0.413999\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005810; batch adversarial loss: 0.443166\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013320; batch adversarial loss: 0.455847\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007379; batch adversarial loss: 0.453269\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707573; batch adversarial loss: 0.644104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.349300; batch adversarial loss: 0.628774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419465; batch adversarial loss: 0.575554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330723; batch adversarial loss: 0.611276\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319069; batch adversarial loss: 0.559672\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302153; batch adversarial loss: 0.512577\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308141; batch adversarial loss: 0.551322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302599; batch adversarial loss: 0.546413\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256858; batch adversarial loss: 0.536204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238274; batch adversarial loss: 0.529306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.179208; batch adversarial loss: 0.523330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260364; batch adversarial loss: 0.450229\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233032; batch adversarial loss: 0.523179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220065; batch adversarial loss: 0.421909\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307103; batch adversarial loss: 0.466069\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216225; batch adversarial loss: 0.469199\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194506; batch adversarial loss: 0.497953\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268772; batch adversarial loss: 0.483817\n",
      "epoch 18; iter: 0; batch classifier loss: 0.275974; batch adversarial loss: 0.455907\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235323; batch adversarial loss: 0.500955\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281697; batch adversarial loss: 0.661981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196539; batch adversarial loss: 0.475714\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203331; batch adversarial loss: 0.531862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182873; batch adversarial loss: 0.481170\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228859; batch adversarial loss: 0.489407\n",
      "epoch 25; iter: 0; batch classifier loss: 0.318701; batch adversarial loss: 0.551062\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212205; batch adversarial loss: 0.446340\n",
      "epoch 27; iter: 0; batch classifier loss: 0.295037; batch adversarial loss: 0.579857\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225448; batch adversarial loss: 0.524524\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269296; batch adversarial loss: 0.418008\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279515; batch adversarial loss: 0.500862\n",
      "epoch 31; iter: 0; batch classifier loss: 0.119425; batch adversarial loss: 0.390784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110908; batch adversarial loss: 0.432180\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125888; batch adversarial loss: 0.442781\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151253; batch adversarial loss: 0.432982\n",
      "epoch 35; iter: 0; batch classifier loss: 0.145237; batch adversarial loss: 0.442808\n",
      "epoch 36; iter: 0; batch classifier loss: 0.075739; batch adversarial loss: 0.483256\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107316; batch adversarial loss: 0.515910\n",
      "epoch 38; iter: 0; batch classifier loss: 0.102518; batch adversarial loss: 0.410425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135902; batch adversarial loss: 0.548094\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113902; batch adversarial loss: 0.459570\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092271; batch adversarial loss: 0.460061\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168624; batch adversarial loss: 0.358767\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109242; batch adversarial loss: 0.422940\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073961; batch adversarial loss: 0.534829\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129444; batch adversarial loss: 0.533755\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077834; batch adversarial loss: 0.431645\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110651; batch adversarial loss: 0.501952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.064489; batch adversarial loss: 0.497617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109140; batch adversarial loss: 0.434600\n",
      "epoch 50; iter: 0; batch classifier loss: 0.111352; batch adversarial loss: 0.397421\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109429; batch adversarial loss: 0.501331\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117523; batch adversarial loss: 0.455655\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130741; batch adversarial loss: 0.534765\n",
      "epoch 54; iter: 0; batch classifier loss: 0.128318; batch adversarial loss: 0.450551\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117423; batch adversarial loss: 0.456122\n",
      "epoch 56; iter: 0; batch classifier loss: 0.135988; batch adversarial loss: 0.466186\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136369; batch adversarial loss: 0.527504\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080778; batch adversarial loss: 0.483115\n",
      "epoch 59; iter: 0; batch classifier loss: 0.144280; batch adversarial loss: 0.514685\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142947; batch adversarial loss: 0.421556\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145412; batch adversarial loss: 0.387541\n",
      "epoch 62; iter: 0; batch classifier loss: 0.175272; batch adversarial loss: 0.454477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.146018; batch adversarial loss: 0.420184\n",
      "epoch 64; iter: 0; batch classifier loss: 0.145576; batch adversarial loss: 0.389418\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125623; batch adversarial loss: 0.458687\n",
      "epoch 66; iter: 0; batch classifier loss: 0.145501; batch adversarial loss: 0.477390\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127805; batch adversarial loss: 0.507956\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126212; batch adversarial loss: 0.515684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.133211; batch adversarial loss: 0.389417\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110776; batch adversarial loss: 0.395265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.190106; batch adversarial loss: 0.417129\n",
      "epoch 72; iter: 0; batch classifier loss: 0.196301; batch adversarial loss: 0.453271\n",
      "epoch 73; iter: 0; batch classifier loss: 0.195098; batch adversarial loss: 0.429709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.186886; batch adversarial loss: 0.476824\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134309; batch adversarial loss: 0.500030\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161701; batch adversarial loss: 0.435484\n",
      "epoch 77; iter: 0; batch classifier loss: 0.175824; batch adversarial loss: 0.442389\n",
      "epoch 78; iter: 0; batch classifier loss: 0.219964; batch adversarial loss: 0.455753\n",
      "epoch 79; iter: 0; batch classifier loss: 0.185174; batch adversarial loss: 0.437434\n",
      "epoch 80; iter: 0; batch classifier loss: 0.121462; batch adversarial loss: 0.504782\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106171; batch adversarial loss: 0.496581\n",
      "epoch 82; iter: 0; batch classifier loss: 0.236163; batch adversarial loss: 0.430578\n",
      "epoch 83; iter: 0; batch classifier loss: 0.172332; batch adversarial loss: 0.480752\n",
      "epoch 84; iter: 0; batch classifier loss: 0.156292; batch adversarial loss: 0.463635\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133686; batch adversarial loss: 0.518614\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150764; batch adversarial loss: 0.454591\n",
      "epoch 87; iter: 0; batch classifier loss: 0.130736; batch adversarial loss: 0.516799\n",
      "epoch 88; iter: 0; batch classifier loss: 0.155286; batch adversarial loss: 0.454997\n",
      "epoch 89; iter: 0; batch classifier loss: 0.151716; batch adversarial loss: 0.458458\n",
      "epoch 90; iter: 0; batch classifier loss: 0.207247; batch adversarial loss: 0.489332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.196240; batch adversarial loss: 0.428024\n",
      "epoch 92; iter: 0; batch classifier loss: 0.162173; batch adversarial loss: 0.511267\n",
      "epoch 93; iter: 0; batch classifier loss: 0.216286; batch adversarial loss: 0.430965\n",
      "epoch 94; iter: 0; batch classifier loss: 0.193934; batch adversarial loss: 0.436868\n",
      "epoch 95; iter: 0; batch classifier loss: 0.165457; batch adversarial loss: 0.508063\n",
      "epoch 96; iter: 0; batch classifier loss: 0.188802; batch adversarial loss: 0.384959\n",
      "epoch 97; iter: 0; batch classifier loss: 0.214020; batch adversarial loss: 0.517847\n",
      "epoch 98; iter: 0; batch classifier loss: 0.260296; batch adversarial loss: 0.476288\n",
      "epoch 99; iter: 0; batch classifier loss: 0.272308; batch adversarial loss: 0.414145\n",
      "epoch 100; iter: 0; batch classifier loss: 0.202997; batch adversarial loss: 0.503109\n",
      "epoch 101; iter: 0; batch classifier loss: 0.135926; batch adversarial loss: 0.565428\n",
      "epoch 102; iter: 0; batch classifier loss: 0.270451; batch adversarial loss: 0.437519\n",
      "epoch 103; iter: 0; batch classifier loss: 0.231293; batch adversarial loss: 0.484774\n",
      "epoch 104; iter: 0; batch classifier loss: 0.221313; batch adversarial loss: 0.422034\n",
      "epoch 105; iter: 0; batch classifier loss: 0.223135; batch adversarial loss: 0.358603\n",
      "epoch 106; iter: 0; batch classifier loss: 0.216016; batch adversarial loss: 0.470290\n",
      "epoch 107; iter: 0; batch classifier loss: 0.239915; batch adversarial loss: 0.420756\n",
      "epoch 108; iter: 0; batch classifier loss: 0.248322; batch adversarial loss: 0.532934\n",
      "epoch 109; iter: 0; batch classifier loss: 0.177192; batch adversarial loss: 0.447751\n",
      "epoch 110; iter: 0; batch classifier loss: 0.191271; batch adversarial loss: 0.470563\n",
      "epoch 111; iter: 0; batch classifier loss: 0.152338; batch adversarial loss: 0.520064\n",
      "epoch 112; iter: 0; batch classifier loss: 0.231336; batch adversarial loss: 0.507979\n",
      "epoch 113; iter: 0; batch classifier loss: 0.218259; batch adversarial loss: 0.446907\n",
      "epoch 114; iter: 0; batch classifier loss: 0.259977; batch adversarial loss: 0.446843\n",
      "epoch 115; iter: 0; batch classifier loss: 0.248104; batch adversarial loss: 0.483085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.201339; batch adversarial loss: 0.495435\n",
      "epoch 117; iter: 0; batch classifier loss: 0.195016; batch adversarial loss: 0.507490\n",
      "epoch 118; iter: 0; batch classifier loss: 0.224161; batch adversarial loss: 0.446614\n",
      "epoch 119; iter: 0; batch classifier loss: 0.252216; batch adversarial loss: 0.410074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.115869; batch adversarial loss: 0.507306\n",
      "epoch 121; iter: 0; batch classifier loss: 0.108336; batch adversarial loss: 0.483691\n",
      "epoch 122; iter: 0; batch classifier loss: 0.215695; batch adversarial loss: 0.557241\n",
      "epoch 123; iter: 0; batch classifier loss: 0.226239; batch adversarial loss: 0.481899\n",
      "epoch 124; iter: 0; batch classifier loss: 0.231073; batch adversarial loss: 0.484579\n",
      "epoch 125; iter: 0; batch classifier loss: 0.198944; batch adversarial loss: 0.434329\n",
      "epoch 126; iter: 0; batch classifier loss: 0.211682; batch adversarial loss: 0.509469\n",
      "epoch 127; iter: 0; batch classifier loss: 0.189850; batch adversarial loss: 0.458908\n",
      "epoch 128; iter: 0; batch classifier loss: 0.181038; batch adversarial loss: 0.532715\n",
      "epoch 129; iter: 0; batch classifier loss: 0.221351; batch adversarial loss: 0.409371\n",
      "epoch 130; iter: 0; batch classifier loss: 0.266616; batch adversarial loss: 0.410597\n",
      "epoch 131; iter: 0; batch classifier loss: 0.152919; batch adversarial loss: 0.520693\n",
      "epoch 132; iter: 0; batch classifier loss: 0.146705; batch adversarial loss: 0.483535\n",
      "epoch 133; iter: 0; batch classifier loss: 0.209531; batch adversarial loss: 0.470167\n",
      "epoch 134; iter: 0; batch classifier loss: 0.212556; batch adversarial loss: 0.531390\n",
      "epoch 135; iter: 0; batch classifier loss: 0.191335; batch adversarial loss: 0.458353\n",
      "epoch 136; iter: 0; batch classifier loss: 0.243425; batch adversarial loss: 0.580789\n",
      "epoch 137; iter: 0; batch classifier loss: 0.216922; batch adversarial loss: 0.520080\n",
      "epoch 138; iter: 0; batch classifier loss: 0.158459; batch adversarial loss: 0.494792\n",
      "epoch 139; iter: 0; batch classifier loss: 0.218667; batch adversarial loss: 0.497283\n",
      "epoch 140; iter: 0; batch classifier loss: 0.173019; batch adversarial loss: 0.482806\n",
      "epoch 141; iter: 0; batch classifier loss: 0.237881; batch adversarial loss: 0.447562\n",
      "epoch 142; iter: 0; batch classifier loss: 0.220826; batch adversarial loss: 0.409158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.258558; batch adversarial loss: 0.422865\n",
      "epoch 144; iter: 0; batch classifier loss: 0.142286; batch adversarial loss: 0.532319\n",
      "epoch 145; iter: 0; batch classifier loss: 0.309209; batch adversarial loss: 0.397553\n",
      "epoch 146; iter: 0; batch classifier loss: 0.125789; batch adversarial loss: 0.483041\n",
      "epoch 147; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.420928\n",
      "epoch 148; iter: 0; batch classifier loss: 0.073611; batch adversarial loss: 0.359378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048226; batch adversarial loss: 0.453424\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038210; batch adversarial loss: 0.475235\n",
      "epoch 151; iter: 0; batch classifier loss: 0.081876; batch adversarial loss: 0.397393\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062902; batch adversarial loss: 0.439751\n",
      "epoch 153; iter: 0; batch classifier loss: 0.057666; batch adversarial loss: 0.477630\n",
      "epoch 154; iter: 0; batch classifier loss: 0.099220; batch adversarial loss: 0.436366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.080011; batch adversarial loss: 0.408463\n",
      "epoch 156; iter: 0; batch classifier loss: 0.057486; batch adversarial loss: 0.366259\n",
      "epoch 157; iter: 0; batch classifier loss: 0.063296; batch adversarial loss: 0.476002\n",
      "epoch 158; iter: 0; batch classifier loss: 0.088037; batch adversarial loss: 0.385569\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045592; batch adversarial loss: 0.462193\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053004; batch adversarial loss: 0.488106\n",
      "epoch 161; iter: 0; batch classifier loss: 0.070684; batch adversarial loss: 0.395345\n",
      "epoch 162; iter: 0; batch classifier loss: 0.103454; batch adversarial loss: 0.442178\n",
      "epoch 163; iter: 0; batch classifier loss: 0.098980; batch adversarial loss: 0.433208\n",
      "epoch 164; iter: 0; batch classifier loss: 0.094546; batch adversarial loss: 0.541674\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060540; batch adversarial loss: 0.515646\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036414; batch adversarial loss: 0.327005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.088628; batch adversarial loss: 0.435812\n",
      "epoch 168; iter: 0; batch classifier loss: 0.064969; batch adversarial loss: 0.457830\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044625; batch adversarial loss: 0.523698\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029134; batch adversarial loss: 0.466636\n",
      "epoch 171; iter: 0; batch classifier loss: 0.072699; batch adversarial loss: 0.425875\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052697; batch adversarial loss: 0.439320\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044035; batch adversarial loss: 0.474545\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058835; batch adversarial loss: 0.525843\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042877; batch adversarial loss: 0.537714\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040195; batch adversarial loss: 0.370358\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050551; batch adversarial loss: 0.393246\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042393; batch adversarial loss: 0.431847\n",
      "epoch 179; iter: 0; batch classifier loss: 0.074027; batch adversarial loss: 0.398783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.064849; batch adversarial loss: 0.498446\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031593; batch adversarial loss: 0.442015\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053360; batch adversarial loss: 0.458231\n",
      "epoch 183; iter: 0; batch classifier loss: 0.065433; batch adversarial loss: 0.501955\n",
      "epoch 184; iter: 0; batch classifier loss: 0.078150; batch adversarial loss: 0.407660\n",
      "epoch 185; iter: 0; batch classifier loss: 0.074461; batch adversarial loss: 0.320610\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050162; batch adversarial loss: 0.427468\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049276; batch adversarial loss: 0.392352\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043649; batch adversarial loss: 0.453433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057572; batch adversarial loss: 0.423981\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040915; batch adversarial loss: 0.437440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.056294; batch adversarial loss: 0.448324\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040517; batch adversarial loss: 0.363550\n",
      "epoch 193; iter: 0; batch classifier loss: 0.082137; batch adversarial loss: 0.388434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.084631; batch adversarial loss: 0.416854\n",
      "epoch 195; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.487635\n",
      "epoch 196; iter: 0; batch classifier loss: 0.049230; batch adversarial loss: 0.444339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053266; batch adversarial loss: 0.501946\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050058; batch adversarial loss: 0.532213\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036554; batch adversarial loss: 0.444240\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705193; batch adversarial loss: 1.004143\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622610; batch adversarial loss: 1.067850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.909670; batch adversarial loss: 1.157396\n",
      "epoch 3; iter: 0; batch classifier loss: 1.006561; batch adversarial loss: 1.054677\n",
      "epoch 4; iter: 0; batch classifier loss: 1.238985; batch adversarial loss: 0.997448\n",
      "epoch 5; iter: 0; batch classifier loss: 1.058407; batch adversarial loss: 0.869653\n",
      "epoch 6; iter: 0; batch classifier loss: 1.135098; batch adversarial loss: 0.820354\n",
      "epoch 7; iter: 0; batch classifier loss: 1.040153; batch adversarial loss: 0.725745\n",
      "epoch 8; iter: 0; batch classifier loss: 0.874395; batch adversarial loss: 0.653441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.755324; batch adversarial loss: 0.633610\n",
      "epoch 10; iter: 0; batch classifier loss: 0.623992; batch adversarial loss: 0.580439\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548948; batch adversarial loss: 0.587029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365898; batch adversarial loss: 0.521564\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338442; batch adversarial loss: 0.584406\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296486; batch adversarial loss: 0.543374\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273535; batch adversarial loss: 0.544502\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296158; batch adversarial loss: 0.467929\n",
      "epoch 17; iter: 0; batch classifier loss: 0.250436; batch adversarial loss: 0.507441\n",
      "epoch 18; iter: 0; batch classifier loss: 0.297749; batch adversarial loss: 0.470641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231888; batch adversarial loss: 0.504656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257436; batch adversarial loss: 0.483514\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256611; batch adversarial loss: 0.474638\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206752; batch adversarial loss: 0.492372\n",
      "epoch 23; iter: 0; batch classifier loss: 0.230535; batch adversarial loss: 0.476580\n",
      "epoch 24; iter: 0; batch classifier loss: 0.245417; batch adversarial loss: 0.481402\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199406; batch adversarial loss: 0.592277\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206793; batch adversarial loss: 0.474335\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243354; batch adversarial loss: 0.457649\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188808; batch adversarial loss: 0.490319\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202449; batch adversarial loss: 0.536103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154958; batch adversarial loss: 0.469782\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164157; batch adversarial loss: 0.463548\n",
      "epoch 32; iter: 0; batch classifier loss: 0.207351; batch adversarial loss: 0.423710\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202928; batch adversarial loss: 0.456385\n",
      "epoch 34; iter: 0; batch classifier loss: 0.180908; batch adversarial loss: 0.466030\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160097; batch adversarial loss: 0.504687\n",
      "epoch 36; iter: 0; batch classifier loss: 0.160247; batch adversarial loss: 0.531392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.156805; batch adversarial loss: 0.514903\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262829; batch adversarial loss: 0.411056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185315; batch adversarial loss: 0.477500\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191959; batch adversarial loss: 0.386061\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128235; batch adversarial loss: 0.416306\n",
      "epoch 42; iter: 0; batch classifier loss: 0.210065; batch adversarial loss: 0.525447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.194616; batch adversarial loss: 0.478637\n",
      "epoch 44; iter: 0; batch classifier loss: 0.191226; batch adversarial loss: 0.490314\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159030; batch adversarial loss: 0.474216\n",
      "epoch 46; iter: 0; batch classifier loss: 0.218283; batch adversarial loss: 0.497163\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130752; batch adversarial loss: 0.355359\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106044; batch adversarial loss: 0.451742\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116406; batch adversarial loss: 0.533503\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157380; batch adversarial loss: 0.449067\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175445; batch adversarial loss: 0.501252\n",
      "epoch 52; iter: 0; batch classifier loss: 0.177763; batch adversarial loss: 0.469719\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151317; batch adversarial loss: 0.411660\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110976; batch adversarial loss: 0.600242\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120030; batch adversarial loss: 0.527192\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177199; batch adversarial loss: 0.380957\n",
      "epoch 57; iter: 0; batch classifier loss: 0.171942; batch adversarial loss: 0.340659\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130273; batch adversarial loss: 0.465619\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106983; batch adversarial loss: 0.551188\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105380; batch adversarial loss: 0.434232\n",
      "epoch 61; iter: 0; batch classifier loss: 0.157554; batch adversarial loss: 0.491613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149903; batch adversarial loss: 0.460761\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128516; batch adversarial loss: 0.506535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.137586; batch adversarial loss: 0.481077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.117455; batch adversarial loss: 0.499478\n",
      "epoch 66; iter: 0; batch classifier loss: 0.159290; batch adversarial loss: 0.434834\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148333; batch adversarial loss: 0.442419\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094875; batch adversarial loss: 0.517845\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145350; batch adversarial loss: 0.413812\n",
      "epoch 70; iter: 0; batch classifier loss: 0.152401; batch adversarial loss: 0.425966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138154; batch adversarial loss: 0.441506\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140141; batch adversarial loss: 0.420866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074719; batch adversarial loss: 0.471845\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122984; batch adversarial loss: 0.368883\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122577; batch adversarial loss: 0.576459\n",
      "epoch 76; iter: 0; batch classifier loss: 0.145181; batch adversarial loss: 0.579138\n",
      "epoch 77; iter: 0; batch classifier loss: 0.137274; batch adversarial loss: 0.472171\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108909; batch adversarial loss: 0.557273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151322; batch adversarial loss: 0.442730\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118063; batch adversarial loss: 0.455156\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095180; batch adversarial loss: 0.552150\n",
      "epoch 82; iter: 0; batch classifier loss: 0.108308; batch adversarial loss: 0.446505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089705; batch adversarial loss: 0.512429\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114445; batch adversarial loss: 0.504833\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122127; batch adversarial loss: 0.432847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092793; batch adversarial loss: 0.458202\n",
      "epoch 87; iter: 0; batch classifier loss: 0.162956; batch adversarial loss: 0.521277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.133253; batch adversarial loss: 0.431655\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081423; batch adversarial loss: 0.404957\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106808; batch adversarial loss: 0.540517\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100217; batch adversarial loss: 0.438198\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109890; batch adversarial loss: 0.414316\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093438; batch adversarial loss: 0.475445\n",
      "epoch 94; iter: 0; batch classifier loss: 0.095436; batch adversarial loss: 0.475410\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107666; batch adversarial loss: 0.469108\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061294; batch adversarial loss: 0.466203\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074889; batch adversarial loss: 0.500623\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077355; batch adversarial loss: 0.452252\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078130; batch adversarial loss: 0.461676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075044; batch adversarial loss: 0.536119\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068262; batch adversarial loss: 0.456784\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081826; batch adversarial loss: 0.469763\n",
      "epoch 103; iter: 0; batch classifier loss: 0.139046; batch adversarial loss: 0.418411\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059840; batch adversarial loss: 0.472700\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028172; batch adversarial loss: 0.406105\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082910; batch adversarial loss: 0.547408\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069364; batch adversarial loss: 0.377895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092063; batch adversarial loss: 0.425165\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057978; batch adversarial loss: 0.481950\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069302; batch adversarial loss: 0.345121\n",
      "epoch 111; iter: 0; batch classifier loss: 0.108793; batch adversarial loss: 0.456012\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089802; batch adversarial loss: 0.608543\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048602; batch adversarial loss: 0.408627\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082070; batch adversarial loss: 0.426719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066750; batch adversarial loss: 0.455461\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078379; batch adversarial loss: 0.383071\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058346; batch adversarial loss: 0.482156\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064242; batch adversarial loss: 0.426994\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064427; batch adversarial loss: 0.528555\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036075; batch adversarial loss: 0.500047\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043383; batch adversarial loss: 0.417708\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064621; batch adversarial loss: 0.463010\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033365; batch adversarial loss: 0.466076\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053935; batch adversarial loss: 0.488906\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069423; batch adversarial loss: 0.479157\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063599; batch adversarial loss: 0.416331\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.452926\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053153; batch adversarial loss: 0.444837\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.422950\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041203; batch adversarial loss: 0.450160\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016867; batch adversarial loss: 0.473550\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038939; batch adversarial loss: 0.384751\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030555; batch adversarial loss: 0.502004\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027429; batch adversarial loss: 0.441110\n",
      "epoch 135; iter: 0; batch classifier loss: 0.063566; batch adversarial loss: 0.463428\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044989; batch adversarial loss: 0.421369\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058197; batch adversarial loss: 0.384230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040199; batch adversarial loss: 0.493097\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045693; batch adversarial loss: 0.424757\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047396; batch adversarial loss: 0.357991\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033699; batch adversarial loss: 0.395730\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026395; batch adversarial loss: 0.473281\n",
      "epoch 143; iter: 0; batch classifier loss: 0.041009; batch adversarial loss: 0.524047\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049378; batch adversarial loss: 0.482677\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043061; batch adversarial loss: 0.461625\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027350; batch adversarial loss: 0.462984\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021213; batch adversarial loss: 0.473223\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068169; batch adversarial loss: 0.444077\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018660; batch adversarial loss: 0.505611\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034376; batch adversarial loss: 0.473505\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019516; batch adversarial loss: 0.461346\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038105; batch adversarial loss: 0.509236\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026636; batch adversarial loss: 0.465789\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016342; batch adversarial loss: 0.361399\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009219; batch adversarial loss: 0.530618\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015053; batch adversarial loss: 0.428699\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018867; batch adversarial loss: 0.508262\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034666; batch adversarial loss: 0.485489\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032351; batch adversarial loss: 0.515868\n",
      "epoch 160; iter: 0; batch classifier loss: 0.002729; batch adversarial loss: 0.394660\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037486; batch adversarial loss: 0.402126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.018228; batch adversarial loss: 0.399949\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017476; batch adversarial loss: 0.532367\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011968; batch adversarial loss: 0.437392\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012506; batch adversarial loss: 0.459861\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014269; batch adversarial loss: 0.449265\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013592; batch adversarial loss: 0.544957\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010541; batch adversarial loss: 0.430473\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027882; batch adversarial loss: 0.461591\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012106; batch adversarial loss: 0.461553\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016819; batch adversarial loss: 0.505581\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009476; batch adversarial loss: 0.510521\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017193; batch adversarial loss: 0.391059\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023350; batch adversarial loss: 0.465716\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018064; batch adversarial loss: 0.480260\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.510615\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022045; batch adversarial loss: 0.413165\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009372; batch adversarial loss: 0.410746\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014045; batch adversarial loss: 0.562585\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013520; batch adversarial loss: 0.435489\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040818; batch adversarial loss: 0.565127\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006348; batch adversarial loss: 0.394107\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009552; batch adversarial loss: 0.471969\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008939; batch adversarial loss: 0.518581\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027795; batch adversarial loss: 0.445659\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008952; batch adversarial loss: 0.485302\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023662; batch adversarial loss: 0.389552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017198; batch adversarial loss: 0.441530\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014805; batch adversarial loss: 0.432545\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016999; batch adversarial loss: 0.489220\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028803; batch adversarial loss: 0.438401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019938; batch adversarial loss: 0.452177\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015214; batch adversarial loss: 0.406677\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010979; batch adversarial loss: 0.512379\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018331; batch adversarial loss: 0.406227\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019926; batch adversarial loss: 0.442525\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008485; batch adversarial loss: 0.447302\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010197; batch adversarial loss: 0.469254\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005535; batch adversarial loss: 0.518367\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672351; batch adversarial loss: 0.820035\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457046; batch adversarial loss: 0.811977\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420758; batch adversarial loss: 0.713961\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344804; batch adversarial loss: 0.727616\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298095; batch adversarial loss: 0.701349\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379543; batch adversarial loss: 0.651574\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335185; batch adversarial loss: 0.630105\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369028; batch adversarial loss: 0.605328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.269769; batch adversarial loss: 0.554114\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335403; batch adversarial loss: 0.569060\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292690; batch adversarial loss: 0.489343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.298678; batch adversarial loss: 0.537633\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245343; batch adversarial loss: 0.495533\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239916; batch adversarial loss: 0.440349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258089; batch adversarial loss: 0.466078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298522; batch adversarial loss: 0.425211\n",
      "epoch 16; iter: 0; batch classifier loss: 0.232052; batch adversarial loss: 0.413208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.190792; batch adversarial loss: 0.412843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255098; batch adversarial loss: 0.456070\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264533; batch adversarial loss: 0.381264\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278617; batch adversarial loss: 0.351533\n",
      "epoch 21; iter: 0; batch classifier loss: 0.296012; batch adversarial loss: 0.407702\n",
      "epoch 22; iter: 0; batch classifier loss: 0.234743; batch adversarial loss: 0.432778\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171486; batch adversarial loss: 0.423081\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185079; batch adversarial loss: 0.416084\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237147; batch adversarial loss: 0.381032\n",
      "epoch 26; iter: 0; batch classifier loss: 0.130967; batch adversarial loss: 0.386762\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180176; batch adversarial loss: 0.336093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184629; batch adversarial loss: 0.449210\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167397; batch adversarial loss: 0.335775\n",
      "epoch 30; iter: 0; batch classifier loss: 0.143051; batch adversarial loss: 0.380737\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148518; batch adversarial loss: 0.348643\n",
      "epoch 32; iter: 0; batch classifier loss: 0.125459; batch adversarial loss: 0.468761\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137103; batch adversarial loss: 0.464979\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154788; batch adversarial loss: 0.458680\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179451; batch adversarial loss: 0.424205\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126834; batch adversarial loss: 0.409221\n",
      "epoch 37; iter: 0; batch classifier loss: 0.115196; batch adversarial loss: 0.402505\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140851; batch adversarial loss: 0.343792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146947; batch adversarial loss: 0.368179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161989; batch adversarial loss: 0.479053\n",
      "epoch 41; iter: 0; batch classifier loss: 0.160937; batch adversarial loss: 0.368338\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116090; batch adversarial loss: 0.372691\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091769; batch adversarial loss: 0.427832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132159; batch adversarial loss: 0.399861\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171513; batch adversarial loss: 0.458710\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112394; batch adversarial loss: 0.338847\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101419; batch adversarial loss: 0.333515\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075625; batch adversarial loss: 0.393696\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101111; batch adversarial loss: 0.481086\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077927; batch adversarial loss: 0.424706\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095818; batch adversarial loss: 0.462652\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088435; batch adversarial loss: 0.398597\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094853; batch adversarial loss: 0.419679\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100384; batch adversarial loss: 0.428948\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088576; batch adversarial loss: 0.343780\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085164; batch adversarial loss: 0.355266\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099815; batch adversarial loss: 0.464436\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088086; batch adversarial loss: 0.390026\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124575; batch adversarial loss: 0.357313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.075358; batch adversarial loss: 0.453458\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102517; batch adversarial loss: 0.371378\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084782; batch adversarial loss: 0.453944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090119; batch adversarial loss: 0.388992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073678; batch adversarial loss: 0.472353\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066773; batch adversarial loss: 0.410094\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059409; batch adversarial loss: 0.448099\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098615; batch adversarial loss: 0.421485\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071981; batch adversarial loss: 0.382416\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057168; batch adversarial loss: 0.436312\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090355; batch adversarial loss: 0.388572\n",
      "epoch 71; iter: 0; batch classifier loss: 0.115818; batch adversarial loss: 0.429269\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068160; batch adversarial loss: 0.380893\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074830; batch adversarial loss: 0.426414\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078422; batch adversarial loss: 0.464513\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070339; batch adversarial loss: 0.362072\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065056; batch adversarial loss: 0.354179\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066387; batch adversarial loss: 0.396899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085462; batch adversarial loss: 0.406614\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057641; batch adversarial loss: 0.404223\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083724; batch adversarial loss: 0.449538\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071295; batch adversarial loss: 0.424307\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088476; batch adversarial loss: 0.388900\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070714; batch adversarial loss: 0.509114\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066375; batch adversarial loss: 0.320662\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052840; batch adversarial loss: 0.458350\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052400; batch adversarial loss: 0.420527\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058234; batch adversarial loss: 0.415018\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049573; batch adversarial loss: 0.508615\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056427; batch adversarial loss: 0.460120\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066323; batch adversarial loss: 0.377393\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064751; batch adversarial loss: 0.292477\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068268; batch adversarial loss: 0.462303\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043073; batch adversarial loss: 0.403523\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.509029\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038510; batch adversarial loss: 0.423220\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047909; batch adversarial loss: 0.388026\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042840; batch adversarial loss: 0.419551\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047512; batch adversarial loss: 0.436166\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033594; batch adversarial loss: 0.382901\n",
      "epoch 100; iter: 0; batch classifier loss: 0.020922; batch adversarial loss: 0.438831\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035084; batch adversarial loss: 0.364361\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054366; batch adversarial loss: 0.400903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048025; batch adversarial loss: 0.419569\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057274; batch adversarial loss: 0.456976\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049583; batch adversarial loss: 0.434459\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022274; batch adversarial loss: 0.481435\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039894; batch adversarial loss: 0.442738\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026147; batch adversarial loss: 0.446972\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023994; batch adversarial loss: 0.448656\n",
      "epoch 110; iter: 0; batch classifier loss: 0.012483; batch adversarial loss: 0.413769\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039004; batch adversarial loss: 0.455518\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027012; batch adversarial loss: 0.487271\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019742; batch adversarial loss: 0.530790\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034291; batch adversarial loss: 0.459141\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.394799\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022168; batch adversarial loss: 0.399440\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039538; batch adversarial loss: 0.366574\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063502; batch adversarial loss: 0.409366\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030417; batch adversarial loss: 0.480559\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046025; batch adversarial loss: 0.513363\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.392196\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032012; batch adversarial loss: 0.499608\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028633; batch adversarial loss: 0.322441\n",
      "epoch 124; iter: 0; batch classifier loss: 0.132393; batch adversarial loss: 0.642577\n",
      "epoch 125; iter: 0; batch classifier loss: 0.191510; batch adversarial loss: 0.680567\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062706; batch adversarial loss: 0.561308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.121511; batch adversarial loss: 0.598047\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056305; batch adversarial loss: 0.465188\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071247; batch adversarial loss: 0.608158\n",
      "epoch 130; iter: 0; batch classifier loss: 0.126135; batch adversarial loss: 0.660046\n",
      "epoch 131; iter: 0; batch classifier loss: 0.118079; batch adversarial loss: 0.539505\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061539; batch adversarial loss: 0.506377\n",
      "epoch 133; iter: 0; batch classifier loss: 0.130082; batch adversarial loss: 0.613210\n",
      "epoch 134; iter: 0; batch classifier loss: 0.149523; batch adversarial loss: 0.695795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.154088; batch adversarial loss: 0.652350\n",
      "epoch 136; iter: 0; batch classifier loss: 0.134849; batch adversarial loss: 0.577383\n",
      "epoch 137; iter: 0; batch classifier loss: 0.127339; batch adversarial loss: 0.505912\n",
      "epoch 138; iter: 0; batch classifier loss: 0.117579; batch adversarial loss: 0.529690\n",
      "epoch 139; iter: 0; batch classifier loss: 0.115902; batch adversarial loss: 0.527933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.147665; batch adversarial loss: 0.578040\n",
      "epoch 141; iter: 0; batch classifier loss: 0.137807; batch adversarial loss: 0.591929\n",
      "epoch 142; iter: 0; batch classifier loss: 0.128852; batch adversarial loss: 0.596982\n",
      "epoch 143; iter: 0; batch classifier loss: 0.167681; batch adversarial loss: 0.683816\n",
      "epoch 144; iter: 0; batch classifier loss: 0.054115; batch adversarial loss: 0.511732\n",
      "epoch 145; iter: 0; batch classifier loss: 0.183193; batch adversarial loss: 0.649061\n",
      "epoch 146; iter: 0; batch classifier loss: 0.148328; batch adversarial loss: 0.615390\n",
      "epoch 147; iter: 0; batch classifier loss: 0.166999; batch adversarial loss: 0.501428\n",
      "epoch 148; iter: 0; batch classifier loss: 0.159299; batch adversarial loss: 0.580467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.104709; batch adversarial loss: 0.541346\n",
      "epoch 150; iter: 0; batch classifier loss: 0.127682; batch adversarial loss: 0.551753\n",
      "epoch 151; iter: 0; batch classifier loss: 0.063807; batch adversarial loss: 0.451312\n",
      "epoch 152; iter: 0; batch classifier loss: 0.103889; batch adversarial loss: 0.509326\n",
      "epoch 153; iter: 0; batch classifier loss: 0.107725; batch adversarial loss: 0.481082\n",
      "epoch 154; iter: 0; batch classifier loss: 0.184706; batch adversarial loss: 0.573752\n",
      "epoch 155; iter: 0; batch classifier loss: 0.099424; batch adversarial loss: 0.444631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.116140; batch adversarial loss: 0.505322\n",
      "epoch 157; iter: 0; batch classifier loss: 0.161584; batch adversarial loss: 0.431771\n",
      "epoch 158; iter: 0; batch classifier loss: 0.191619; batch adversarial loss: 0.652489\n",
      "epoch 159; iter: 0; batch classifier loss: 0.147776; batch adversarial loss: 0.496145\n",
      "epoch 160; iter: 0; batch classifier loss: 0.077967; batch adversarial loss: 0.493325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.108431; batch adversarial loss: 0.469804\n",
      "epoch 162; iter: 0; batch classifier loss: 0.095130; batch adversarial loss: 0.451465\n",
      "epoch 163; iter: 0; batch classifier loss: 0.122390; batch adversarial loss: 0.503073\n",
      "epoch 164; iter: 0; batch classifier loss: 0.104731; batch adversarial loss: 0.535743\n",
      "epoch 165; iter: 0; batch classifier loss: 0.112391; batch adversarial loss: 0.511061\n",
      "epoch 166; iter: 0; batch classifier loss: 0.091191; batch adversarial loss: 0.441923\n",
      "epoch 167; iter: 0; batch classifier loss: 0.130972; batch adversarial loss: 0.549209\n",
      "epoch 168; iter: 0; batch classifier loss: 0.067271; batch adversarial loss: 0.425847\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054175; batch adversarial loss: 0.424635\n",
      "epoch 170; iter: 0; batch classifier loss: 0.142829; batch adversarial loss: 0.483507\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037589; batch adversarial loss: 0.469734\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032485; batch adversarial loss: 0.467500\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021745; batch adversarial loss: 0.430633\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028591; batch adversarial loss: 0.453875\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021672; batch adversarial loss: 0.480736\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055328; batch adversarial loss: 0.431366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026645; batch adversarial loss: 0.402058\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016603; batch adversarial loss: 0.449371\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030676; batch adversarial loss: 0.482677\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025536; batch adversarial loss: 0.598675\n",
      "epoch 181; iter: 0; batch classifier loss: 0.057208; batch adversarial loss: 0.402526\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.412307\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051203; batch adversarial loss: 0.463952\n",
      "epoch 184; iter: 0; batch classifier loss: 0.076648; batch adversarial loss: 0.462443\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036244; batch adversarial loss: 0.521583\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052801; batch adversarial loss: 0.449225\n",
      "epoch 187; iter: 0; batch classifier loss: 0.107977; batch adversarial loss: 0.401824\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041571; batch adversarial loss: 0.468075\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047536; batch adversarial loss: 0.483103\n",
      "epoch 190; iter: 0; batch classifier loss: 0.048847; batch adversarial loss: 0.410895\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022106; batch adversarial loss: 0.536711\n",
      "epoch 192; iter: 0; batch classifier loss: 0.074882; batch adversarial loss: 0.587232\n",
      "epoch 193; iter: 0; batch classifier loss: 0.092091; batch adversarial loss: 0.393294\n",
      "epoch 194; iter: 0; batch classifier loss: 0.057514; batch adversarial loss: 0.368928\n",
      "epoch 195; iter: 0; batch classifier loss: 0.064322; batch adversarial loss: 0.392530\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028155; batch adversarial loss: 0.441190\n",
      "epoch 197; iter: 0; batch classifier loss: 0.077446; batch adversarial loss: 0.403554\n",
      "epoch 198; iter: 0; batch classifier loss: 0.070846; batch adversarial loss: 0.492832\n",
      "epoch 199; iter: 0; batch classifier loss: 0.074522; batch adversarial loss: 0.452323\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683390; batch adversarial loss: 0.643995\n",
      "epoch 1; iter: 0; batch classifier loss: 0.358887; batch adversarial loss: 0.646384\n",
      "epoch 2; iter: 0; batch classifier loss: 0.472899; batch adversarial loss: 0.575511\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411379; batch adversarial loss: 0.562599\n",
      "epoch 4; iter: 0; batch classifier loss: 0.287578; batch adversarial loss: 0.563876\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324697; batch adversarial loss: 0.524730\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281220; batch adversarial loss: 0.522305\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306399; batch adversarial loss: 0.518802\n",
      "epoch 8; iter: 0; batch classifier loss: 0.293611; batch adversarial loss: 0.512485\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252344; batch adversarial loss: 0.540547\n",
      "epoch 10; iter: 0; batch classifier loss: 0.199681; batch adversarial loss: 0.479457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.232891; batch adversarial loss: 0.440078\n",
      "epoch 12; iter: 0; batch classifier loss: 0.210485; batch adversarial loss: 0.440542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218485; batch adversarial loss: 0.478646\n",
      "epoch 14; iter: 0; batch classifier loss: 0.207536; batch adversarial loss: 0.485298\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224877; batch adversarial loss: 0.528723\n",
      "epoch 16; iter: 0; batch classifier loss: 0.189023; batch adversarial loss: 0.479707\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256658; batch adversarial loss: 0.562532\n",
      "epoch 18; iter: 0; batch classifier loss: 0.149364; batch adversarial loss: 0.456000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206859; batch adversarial loss: 0.463141\n",
      "epoch 20; iter: 0; batch classifier loss: 0.231467; batch adversarial loss: 0.550742\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167164; batch adversarial loss: 0.544875\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197024; batch adversarial loss: 0.428217\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259430; batch adversarial loss: 0.506752\n",
      "epoch 24; iter: 0; batch classifier loss: 0.278657; batch adversarial loss: 0.477316\n",
      "epoch 25; iter: 0; batch classifier loss: 0.221553; batch adversarial loss: 0.413483\n",
      "epoch 26; iter: 0; batch classifier loss: 0.274785; batch adversarial loss: 0.456768\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392074; batch adversarial loss: 0.473714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.338701; batch adversarial loss: 0.464406\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167298; batch adversarial loss: 0.524602\n",
      "epoch 30; iter: 0; batch classifier loss: 0.117812; batch adversarial loss: 0.529635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.081696; batch adversarial loss: 0.472097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.090602; batch adversarial loss: 0.510941\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145547; batch adversarial loss: 0.558486\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114389; batch adversarial loss: 0.428071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102663; batch adversarial loss: 0.466942\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120379; batch adversarial loss: 0.453366\n",
      "epoch 37; iter: 0; batch classifier loss: 0.128066; batch adversarial loss: 0.452598\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135656; batch adversarial loss: 0.446711\n",
      "epoch 39; iter: 0; batch classifier loss: 0.099581; batch adversarial loss: 0.408313\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126455; batch adversarial loss: 0.418150\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108530; batch adversarial loss: 0.381397\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102912; batch adversarial loss: 0.441747\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120525; batch adversarial loss: 0.448812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099292; batch adversarial loss: 0.474719\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088446; batch adversarial loss: 0.462006\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156270; batch adversarial loss: 0.346564\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125830; batch adversarial loss: 0.472372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106032; batch adversarial loss: 0.490488\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078744; batch adversarial loss: 0.477391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.163427; batch adversarial loss: 0.434552\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139034; batch adversarial loss: 0.434304\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093163; batch adversarial loss: 0.497254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53; iter: 0; batch classifier loss: 0.117748; batch adversarial loss: 0.455535\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096633; batch adversarial loss: 0.591181\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083049; batch adversarial loss: 0.476561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157229; batch adversarial loss: 0.466010\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159614; batch adversarial loss: 0.472159\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096731; batch adversarial loss: 0.451192\n",
      "epoch 59; iter: 0; batch classifier loss: 0.151660; batch adversarial loss: 0.451435\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134718; batch adversarial loss: 0.544237\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198321; batch adversarial loss: 0.447433\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158997; batch adversarial loss: 0.452557\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070577; batch adversarial loss: 0.483091\n",
      "epoch 64; iter: 0; batch classifier loss: 0.144582; batch adversarial loss: 0.434869\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125274; batch adversarial loss: 0.531490\n",
      "epoch 66; iter: 0; batch classifier loss: 0.196463; batch adversarial loss: 0.435857\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116412; batch adversarial loss: 0.455123\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121393; batch adversarial loss: 0.543433\n",
      "epoch 69; iter: 0; batch classifier loss: 0.213405; batch adversarial loss: 0.506362\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150046; batch adversarial loss: 0.532188\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078389; batch adversarial loss: 0.441535\n",
      "epoch 72; iter: 0; batch classifier loss: 0.123227; batch adversarial loss: 0.453947\n",
      "epoch 73; iter: 0; batch classifier loss: 0.151759; batch adversarial loss: 0.464262\n",
      "epoch 74; iter: 0; batch classifier loss: 0.139584; batch adversarial loss: 0.391601\n",
      "epoch 75; iter: 0; batch classifier loss: 0.152427; batch adversarial loss: 0.373849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217410; batch adversarial loss: 0.453713\n",
      "epoch 77; iter: 0; batch classifier loss: 0.189393; batch adversarial loss: 0.369533\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167166; batch adversarial loss: 0.446780\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112027; batch adversarial loss: 0.520507\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138850; batch adversarial loss: 0.385353\n",
      "epoch 81; iter: 0; batch classifier loss: 0.153407; batch adversarial loss: 0.518739\n",
      "epoch 82; iter: 0; batch classifier loss: 0.178192; batch adversarial loss: 0.446124\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122074; batch adversarial loss: 0.514063\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119302; batch adversarial loss: 0.509682\n",
      "epoch 85; iter: 0; batch classifier loss: 0.170822; batch adversarial loss: 0.420101\n",
      "epoch 86; iter: 0; batch classifier loss: 0.131255; batch adversarial loss: 0.488521\n",
      "epoch 87; iter: 0; batch classifier loss: 0.204473; batch adversarial loss: 0.457801\n",
      "epoch 88; iter: 0; batch classifier loss: 0.207778; batch adversarial loss: 0.386171\n",
      "epoch 89; iter: 0; batch classifier loss: 0.158739; batch adversarial loss: 0.554000\n",
      "epoch 90; iter: 0; batch classifier loss: 0.140026; batch adversarial loss: 0.376802\n",
      "epoch 91; iter: 0; batch classifier loss: 0.128817; batch adversarial loss: 0.485372\n",
      "epoch 92; iter: 0; batch classifier loss: 0.187315; batch adversarial loss: 0.428769\n",
      "epoch 93; iter: 0; batch classifier loss: 0.147919; batch adversarial loss: 0.518406\n",
      "epoch 94; iter: 0; batch classifier loss: 0.184928; batch adversarial loss: 0.400870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.175909; batch adversarial loss: 0.546444\n",
      "epoch 96; iter: 0; batch classifier loss: 0.137993; batch adversarial loss: 0.381527\n",
      "epoch 97; iter: 0; batch classifier loss: 0.144728; batch adversarial loss: 0.397319\n",
      "epoch 98; iter: 0; batch classifier loss: 0.147097; batch adversarial loss: 0.462654\n",
      "epoch 99; iter: 0; batch classifier loss: 0.207526; batch adversarial loss: 0.480666\n",
      "epoch 100; iter: 0; batch classifier loss: 0.126059; batch adversarial loss: 0.445880\n",
      "epoch 101; iter: 0; batch classifier loss: 0.158103; batch adversarial loss: 0.421535\n",
      "epoch 102; iter: 0; batch classifier loss: 0.135973; batch adversarial loss: 0.409761\n",
      "epoch 103; iter: 0; batch classifier loss: 0.182210; batch adversarial loss: 0.487070\n",
      "epoch 104; iter: 0; batch classifier loss: 0.130395; batch adversarial loss: 0.456276\n",
      "epoch 105; iter: 0; batch classifier loss: 0.104590; batch adversarial loss: 0.443024\n",
      "epoch 106; iter: 0; batch classifier loss: 0.224160; batch adversarial loss: 0.441770\n",
      "epoch 107; iter: 0; batch classifier loss: 0.139609; batch adversarial loss: 0.437909\n",
      "epoch 108; iter: 0; batch classifier loss: 0.163144; batch adversarial loss: 0.447718\n",
      "epoch 109; iter: 0; batch classifier loss: 0.111973; batch adversarial loss: 0.535743\n",
      "epoch 110; iter: 0; batch classifier loss: 0.181065; batch adversarial loss: 0.456933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.169098; batch adversarial loss: 0.412995\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101969; batch adversarial loss: 0.569285\n",
      "epoch 113; iter: 0; batch classifier loss: 0.161162; batch adversarial loss: 0.548193\n",
      "epoch 114; iter: 0; batch classifier loss: 0.114122; batch adversarial loss: 0.429078\n",
      "epoch 115; iter: 0; batch classifier loss: 0.115217; batch adversarial loss: 0.456253\n",
      "epoch 116; iter: 0; batch classifier loss: 0.157299; batch adversarial loss: 0.487189\n",
      "epoch 117; iter: 0; batch classifier loss: 0.129612; batch adversarial loss: 0.459991\n",
      "epoch 118; iter: 0; batch classifier loss: 0.117571; batch adversarial loss: 0.456942\n",
      "epoch 119; iter: 0; batch classifier loss: 0.204161; batch adversarial loss: 0.474319\n",
      "epoch 120; iter: 0; batch classifier loss: 0.132013; batch adversarial loss: 0.393660\n",
      "epoch 121; iter: 0; batch classifier loss: 0.147564; batch adversarial loss: 0.419616\n",
      "epoch 122; iter: 0; batch classifier loss: 0.154646; batch adversarial loss: 0.432594\n",
      "epoch 123; iter: 0; batch classifier loss: 0.170554; batch adversarial loss: 0.404660\n",
      "epoch 124; iter: 0; batch classifier loss: 0.157178; batch adversarial loss: 0.379201\n",
      "epoch 125; iter: 0; batch classifier loss: 0.094013; batch adversarial loss: 0.490414\n",
      "epoch 126; iter: 0; batch classifier loss: 0.122509; batch adversarial loss: 0.513607\n",
      "epoch 127; iter: 0; batch classifier loss: 0.132730; batch adversarial loss: 0.462295\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087671; batch adversarial loss: 0.502839\n",
      "epoch 129; iter: 0; batch classifier loss: 0.064165; batch adversarial loss: 0.445050\n",
      "epoch 130; iter: 0; batch classifier loss: 0.080736; batch adversarial loss: 0.431437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.114130; batch adversarial loss: 0.396349\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070125; batch adversarial loss: 0.416757\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062534; batch adversarial loss: 0.430336\n",
      "epoch 134; iter: 0; batch classifier loss: 0.084567; batch adversarial loss: 0.364247\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069101; batch adversarial loss: 0.384378\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036607; batch adversarial loss: 0.528177\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053223; batch adversarial loss: 0.407607\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034042; batch adversarial loss: 0.431387\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032082; batch adversarial loss: 0.443568\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036795; batch adversarial loss: 0.495760\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061156; batch adversarial loss: 0.424523\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051183; batch adversarial loss: 0.477915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039702; batch adversarial loss: 0.419663\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037901; batch adversarial loss: 0.450696\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035739; batch adversarial loss: 0.427760\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042041; batch adversarial loss: 0.465582\n",
      "epoch 147; iter: 0; batch classifier loss: 0.063918; batch adversarial loss: 0.464571\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.432017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 149; iter: 0; batch classifier loss: 0.017629; batch adversarial loss: 0.475064\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038283; batch adversarial loss: 0.352671\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028488; batch adversarial loss: 0.404400\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031900; batch adversarial loss: 0.487017\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047475; batch adversarial loss: 0.462656\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044138; batch adversarial loss: 0.429130\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034088; batch adversarial loss: 0.438861\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043929; batch adversarial loss: 0.437532\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044884; batch adversarial loss: 0.400222\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021066; batch adversarial loss: 0.389172\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048087; batch adversarial loss: 0.479418\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025414; batch adversarial loss: 0.566683\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034379; batch adversarial loss: 0.374052\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057174; batch adversarial loss: 0.496725\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.470715\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031057; batch adversarial loss: 0.384413\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022753; batch adversarial loss: 0.465322\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049103; batch adversarial loss: 0.381827\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021147; batch adversarial loss: 0.409705\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020721; batch adversarial loss: 0.453461\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029289; batch adversarial loss: 0.442197\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024163; batch adversarial loss: 0.507398\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023413; batch adversarial loss: 0.406139\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034063; batch adversarial loss: 0.449322\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065794; batch adversarial loss: 0.507122\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058131; batch adversarial loss: 0.478041\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025578; batch adversarial loss: 0.429007\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026883; batch adversarial loss: 0.387366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021737; batch adversarial loss: 0.403809\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043895; batch adversarial loss: 0.465831\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024152; batch adversarial loss: 0.422329\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033446; batch adversarial loss: 0.463663\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020802; batch adversarial loss: 0.441073\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011542; batch adversarial loss: 0.429439\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015942; batch adversarial loss: 0.525056\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023895; batch adversarial loss: 0.504553\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049489; batch adversarial loss: 0.495471\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011971; batch adversarial loss: 0.422610\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019916; batch adversarial loss: 0.429624\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020360; batch adversarial loss: 0.415141\n",
      "epoch 189; iter: 0; batch classifier loss: 0.056743; batch adversarial loss: 0.542499\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017647; batch adversarial loss: 0.454442\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013780; batch adversarial loss: 0.468193\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019548; batch adversarial loss: 0.483649\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019119; batch adversarial loss: 0.465836\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.549220\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.350926\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016435; batch adversarial loss: 0.423843\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027874; batch adversarial loss: 0.469396\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012046; batch adversarial loss: 0.470894\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008430; batch adversarial loss: 0.448806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713318; batch adversarial loss: 0.715386\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452585; batch adversarial loss: 0.673491\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391796; batch adversarial loss: 0.639553\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339405; batch adversarial loss: 0.604975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340985; batch adversarial loss: 0.575483\n",
      "epoch 5; iter: 0; batch classifier loss: 0.295725; batch adversarial loss: 0.567403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.279518; batch adversarial loss: 0.536128\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277237; batch adversarial loss: 0.526501\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238010; batch adversarial loss: 0.527917\n",
      "epoch 9; iter: 0; batch classifier loss: 0.214270; batch adversarial loss: 0.502586\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258857; batch adversarial loss: 0.551709\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219656; batch adversarial loss: 0.532431\n",
      "epoch 12; iter: 0; batch classifier loss: 0.267083; batch adversarial loss: 0.500805\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377807; batch adversarial loss: 0.548374\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245522; batch adversarial loss: 0.475236\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309359; batch adversarial loss: 0.551793\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314548; batch adversarial loss: 0.428047\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523837; batch adversarial loss: 0.519825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.576385; batch adversarial loss: 0.518052\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417595; batch adversarial loss: 0.585872\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272467; batch adversarial loss: 0.498470\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310611; batch adversarial loss: 0.450162\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220330; batch adversarial loss: 0.537473\n",
      "epoch 23; iter: 0; batch classifier loss: 0.198649; batch adversarial loss: 0.407067\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214381; batch adversarial loss: 0.440862\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234109; batch adversarial loss: 0.453880\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137780; batch adversarial loss: 0.494728\n",
      "epoch 27; iter: 0; batch classifier loss: 0.177841; batch adversarial loss: 0.458163\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143204; batch adversarial loss: 0.514518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.190721; batch adversarial loss: 0.442974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119564; batch adversarial loss: 0.468526\n",
      "epoch 31; iter: 0; batch classifier loss: 0.127937; batch adversarial loss: 0.396700\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129053; batch adversarial loss: 0.466499\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152849; batch adversarial loss: 0.530028\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157419; batch adversarial loss: 0.473632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.083828; batch adversarial loss: 0.500323\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123959; batch adversarial loss: 0.529172\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138783; batch adversarial loss: 0.455167\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164268; batch adversarial loss: 0.449840\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113330; batch adversarial loss: 0.422556\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164017; batch adversarial loss: 0.432100\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130857; batch adversarial loss: 0.428997\n",
      "epoch 42; iter: 0; batch classifier loss: 0.158247; batch adversarial loss: 0.493279\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071810; batch adversarial loss: 0.531592\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124344; batch adversarial loss: 0.395321\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113135; batch adversarial loss: 0.495411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 0; batch classifier loss: 0.138541; batch adversarial loss: 0.483375\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147083; batch adversarial loss: 0.477505\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120117; batch adversarial loss: 0.446487\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088703; batch adversarial loss: 0.479267\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091951; batch adversarial loss: 0.517165\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122671; batch adversarial loss: 0.436660\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114316; batch adversarial loss: 0.439761\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154760; batch adversarial loss: 0.530516\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144512; batch adversarial loss: 0.378825\n",
      "epoch 55; iter: 0; batch classifier loss: 0.148846; batch adversarial loss: 0.496061\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087057; batch adversarial loss: 0.406700\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093923; batch adversarial loss: 0.584686\n",
      "epoch 58; iter: 0; batch classifier loss: 0.136972; batch adversarial loss: 0.469880\n",
      "epoch 59; iter: 0; batch classifier loss: 0.155013; batch adversarial loss: 0.386844\n",
      "epoch 60; iter: 0; batch classifier loss: 0.136447; batch adversarial loss: 0.461430\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130479; batch adversarial loss: 0.400837\n",
      "epoch 62; iter: 0; batch classifier loss: 0.189073; batch adversarial loss: 0.495675\n",
      "epoch 63; iter: 0; batch classifier loss: 0.145052; batch adversarial loss: 0.476760\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112694; batch adversarial loss: 0.521983\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068935; batch adversarial loss: 0.653814\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151685; batch adversarial loss: 0.485712\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107851; batch adversarial loss: 0.547823\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103647; batch adversarial loss: 0.449798\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078085; batch adversarial loss: 0.440283\n",
      "epoch 70; iter: 0; batch classifier loss: 0.129966; batch adversarial loss: 0.387124\n",
      "epoch 71; iter: 0; batch classifier loss: 0.107554; batch adversarial loss: 0.519804\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097543; batch adversarial loss: 0.539205\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111213; batch adversarial loss: 0.529251\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100349; batch adversarial loss: 0.440519\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070240; batch adversarial loss: 0.469236\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073431; batch adversarial loss: 0.408331\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073044; batch adversarial loss: 0.436262\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095682; batch adversarial loss: 0.418503\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150809; batch adversarial loss: 0.527231\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110147; batch adversarial loss: 0.414836\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083366; batch adversarial loss: 0.467654\n",
      "epoch 82; iter: 0; batch classifier loss: 0.114152; batch adversarial loss: 0.426492\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183956; batch adversarial loss: 0.380263\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136181; batch adversarial loss: 0.414608\n",
      "epoch 85; iter: 0; batch classifier loss: 0.112387; batch adversarial loss: 0.504046\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090901; batch adversarial loss: 0.409421\n",
      "epoch 87; iter: 0; batch classifier loss: 0.079502; batch adversarial loss: 0.472704\n",
      "epoch 88; iter: 0; batch classifier loss: 0.111510; batch adversarial loss: 0.362825\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066754; batch adversarial loss: 0.505815\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059645; batch adversarial loss: 0.459189\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083447; batch adversarial loss: 0.488756\n",
      "epoch 92; iter: 0; batch classifier loss: 0.111264; batch adversarial loss: 0.426957\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058995; batch adversarial loss: 0.538581\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077048; batch adversarial loss: 0.376407\n",
      "epoch 95; iter: 0; batch classifier loss: 0.104490; batch adversarial loss: 0.415689\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040038; batch adversarial loss: 0.431093\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094375; batch adversarial loss: 0.396375\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067434; batch adversarial loss: 0.424789\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038396; batch adversarial loss: 0.519061\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055906; batch adversarial loss: 0.441359\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072272; batch adversarial loss: 0.460430\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085440; batch adversarial loss: 0.431226\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050253; batch adversarial loss: 0.469876\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064311; batch adversarial loss: 0.379767\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045875; batch adversarial loss: 0.572724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062827; batch adversarial loss: 0.541668\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059089; batch adversarial loss: 0.531247\n",
      "epoch 108; iter: 0; batch classifier loss: 0.119883; batch adversarial loss: 0.507415\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078189; batch adversarial loss: 0.422918\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.448554\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027771; batch adversarial loss: 0.498554\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031231; batch adversarial loss: 0.364669\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076861; batch adversarial loss: 0.454455\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053827; batch adversarial loss: 0.531184\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063063; batch adversarial loss: 0.503038\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035373; batch adversarial loss: 0.471350\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039316; batch adversarial loss: 0.507541\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031308; batch adversarial loss: 0.415466\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013592; batch adversarial loss: 0.381538\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045639; batch adversarial loss: 0.408539\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017809; batch adversarial loss: 0.412445\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049567; batch adversarial loss: 0.392417\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048455; batch adversarial loss: 0.446288\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032455; batch adversarial loss: 0.470957\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024095; batch adversarial loss: 0.436397\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038488; batch adversarial loss: 0.439200\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051241; batch adversarial loss: 0.409829\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023194; batch adversarial loss: 0.486980\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038382; batch adversarial loss: 0.462148\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031993; batch adversarial loss: 0.387085\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037446; batch adversarial loss: 0.496163\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046745; batch adversarial loss: 0.392446\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031029; batch adversarial loss: 0.490469\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029154; batch adversarial loss: 0.414648\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056989; batch adversarial loss: 0.383445\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040844; batch adversarial loss: 0.503056\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016880; batch adversarial loss: 0.429842\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039964; batch adversarial loss: 0.439724\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030486; batch adversarial loss: 0.356753\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067956; batch adversarial loss: 0.501106\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037606; batch adversarial loss: 0.406324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 142; iter: 0; batch classifier loss: 0.018572; batch adversarial loss: 0.453028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033106; batch adversarial loss: 0.391039\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017266; batch adversarial loss: 0.397099\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027000; batch adversarial loss: 0.412260\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022322; batch adversarial loss: 0.429843\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023724; batch adversarial loss: 0.544071\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032730; batch adversarial loss: 0.484805\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017664; batch adversarial loss: 0.316699\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030966; batch adversarial loss: 0.403073\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018130; batch adversarial loss: 0.415744\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039505; batch adversarial loss: 0.532615\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047333; batch adversarial loss: 0.380638\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032568; batch adversarial loss: 0.370949\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028023; batch adversarial loss: 0.419320\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038913; batch adversarial loss: 0.465725\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031181; batch adversarial loss: 0.487462\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035090; batch adversarial loss: 0.444555\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023916; batch adversarial loss: 0.469506\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046073; batch adversarial loss: 0.473136\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005660; batch adversarial loss: 0.408508\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046038; batch adversarial loss: 0.570698\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025178; batch adversarial loss: 0.459762\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003349; batch adversarial loss: 0.456234\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031065; batch adversarial loss: 0.460876\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019956; batch adversarial loss: 0.430443\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033271; batch adversarial loss: 0.473119\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022979; batch adversarial loss: 0.424087\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052363; batch adversarial loss: 0.368289\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008918; batch adversarial loss: 0.468089\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036348; batch adversarial loss: 0.475759\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012534; batch adversarial loss: 0.479634\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025519; batch adversarial loss: 0.373830\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045098; batch adversarial loss: 0.430305\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016027; batch adversarial loss: 0.437896\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045616; batch adversarial loss: 0.380002\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025674; batch adversarial loss: 0.437652\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015516; batch adversarial loss: 0.353452\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037813; batch adversarial loss: 0.366168\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032400; batch adversarial loss: 0.400980\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022412; batch adversarial loss: 0.371857\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008027; batch adversarial loss: 0.400220\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008477; batch adversarial loss: 0.450063\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009956; batch adversarial loss: 0.407424\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012964; batch adversarial loss: 0.491536\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016193; batch adversarial loss: 0.493345\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010833; batch adversarial loss: 0.432402\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014465; batch adversarial loss: 0.476992\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015489; batch adversarial loss: 0.488420\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019852; batch adversarial loss: 0.423273\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038345; batch adversarial loss: 0.480442\n",
      "epoch 192; iter: 0; batch classifier loss: 0.039203; batch adversarial loss: 0.495268\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020838; batch adversarial loss: 0.460236\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007712; batch adversarial loss: 0.502701\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019636; batch adversarial loss: 0.474312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030399; batch adversarial loss: 0.493437\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021796; batch adversarial loss: 0.458585\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010767; batch adversarial loss: 0.406184\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006876; batch adversarial loss: 0.545632\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706206; batch adversarial loss: 0.537113\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493644; batch adversarial loss: 0.590604\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431804; batch adversarial loss: 0.573172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423327; batch adversarial loss: 0.631424\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402063; batch adversarial loss: 0.578234\n",
      "epoch 5; iter: 0; batch classifier loss: 0.394176; batch adversarial loss: 0.566028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.452554; batch adversarial loss: 0.588519\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539524; batch adversarial loss: 0.597956\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581766; batch adversarial loss: 0.746640\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589636; batch adversarial loss: 0.663435\n",
      "epoch 10; iter: 0; batch classifier loss: 0.757134; batch adversarial loss: 0.546985\n",
      "epoch 11; iter: 0; batch classifier loss: 0.641611; batch adversarial loss: 0.539742\n",
      "epoch 12; iter: 0; batch classifier loss: 0.516791; batch adversarial loss: 0.487200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394832; batch adversarial loss: 0.587454\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316557; batch adversarial loss: 0.436346\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311784; batch adversarial loss: 0.494324\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264568; batch adversarial loss: 0.449638\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259144; batch adversarial loss: 0.433885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314642; batch adversarial loss: 0.440214\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274152; batch adversarial loss: 0.411746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304046; batch adversarial loss: 0.547573\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252561; batch adversarial loss: 0.469501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253755; batch adversarial loss: 0.478675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194857; batch adversarial loss: 0.523989\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181500; batch adversarial loss: 0.460521\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170039; batch adversarial loss: 0.485574\n",
      "epoch 26; iter: 0; batch classifier loss: 0.265857; batch adversarial loss: 0.414694\n",
      "epoch 27; iter: 0; batch classifier loss: 0.242013; batch adversarial loss: 0.406069\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231016; batch adversarial loss: 0.386693\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222253; batch adversarial loss: 0.430655\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209500; batch adversarial loss: 0.467879\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233855; batch adversarial loss: 0.398678\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218721; batch adversarial loss: 0.498164\n",
      "epoch 33; iter: 0; batch classifier loss: 0.214407; batch adversarial loss: 0.463579\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240144; batch adversarial loss: 0.453248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198032; batch adversarial loss: 0.462244\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238963; batch adversarial loss: 0.531644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.229567; batch adversarial loss: 0.439449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.199327; batch adversarial loss: 0.462920\n",
      "epoch 39; iter: 0; batch classifier loss: 0.188618; batch adversarial loss: 0.555270\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206528; batch adversarial loss: 0.445893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201573; batch adversarial loss: 0.485675\n",
      "epoch 42; iter: 0; batch classifier loss: 0.223444; batch adversarial loss: 0.492621\n",
      "epoch 43; iter: 0; batch classifier loss: 0.284361; batch adversarial loss: 0.511207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.242326; batch adversarial loss: 0.510471\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200954; batch adversarial loss: 0.477879\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264161; batch adversarial loss: 0.510564\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215776; batch adversarial loss: 0.432414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231158; batch adversarial loss: 0.448198\n",
      "epoch 49; iter: 0; batch classifier loss: 0.326430; batch adversarial loss: 0.506867\n",
      "epoch 50; iter: 0; batch classifier loss: 0.237114; batch adversarial loss: 0.440535\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230199; batch adversarial loss: 0.434782\n",
      "epoch 52; iter: 0; batch classifier loss: 0.337168; batch adversarial loss: 0.387233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176723; batch adversarial loss: 0.555048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.307785; batch adversarial loss: 0.376560\n",
      "epoch 55; iter: 0; batch classifier loss: 0.250637; batch adversarial loss: 0.470491\n",
      "epoch 56; iter: 0; batch classifier loss: 0.349214; batch adversarial loss: 0.411103\n",
      "epoch 57; iter: 0; batch classifier loss: 0.180094; batch adversarial loss: 0.433759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.160391; batch adversarial loss: 0.395767\n",
      "epoch 59; iter: 0; batch classifier loss: 0.234517; batch adversarial loss: 0.408947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186431; batch adversarial loss: 0.471249\n",
      "epoch 61; iter: 0; batch classifier loss: 0.169319; batch adversarial loss: 0.410843\n",
      "epoch 62; iter: 0; batch classifier loss: 0.275392; batch adversarial loss: 0.470365\n",
      "epoch 63; iter: 0; batch classifier loss: 0.277307; batch adversarial loss: 0.423129\n",
      "epoch 64; iter: 0; batch classifier loss: 0.244873; batch adversarial loss: 0.459116\n",
      "epoch 65; iter: 0; batch classifier loss: 0.219580; batch adversarial loss: 0.519328\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135974; batch adversarial loss: 0.457296\n",
      "epoch 67; iter: 0; batch classifier loss: 0.189381; batch adversarial loss: 0.470474\n",
      "epoch 68; iter: 0; batch classifier loss: 0.347331; batch adversarial loss: 0.459184\n",
      "epoch 69; iter: 0; batch classifier loss: 0.131045; batch adversarial loss: 0.520451\n",
      "epoch 70; iter: 0; batch classifier loss: 0.254983; batch adversarial loss: 0.458157\n",
      "epoch 71; iter: 0; batch classifier loss: 0.249029; batch adversarial loss: 0.495790\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179670; batch adversarial loss: 0.349701\n",
      "epoch 73; iter: 0; batch classifier loss: 0.281101; batch adversarial loss: 0.313340\n",
      "epoch 74; iter: 0; batch classifier loss: 0.232353; batch adversarial loss: 0.579516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.125593; batch adversarial loss: 0.434106\n",
      "epoch 76; iter: 0; batch classifier loss: 0.155152; batch adversarial loss: 0.384873\n",
      "epoch 77; iter: 0; batch classifier loss: 0.168132; batch adversarial loss: 0.421244\n",
      "epoch 78; iter: 0; batch classifier loss: 0.221626; batch adversarial loss: 0.421821\n",
      "epoch 79; iter: 0; batch classifier loss: 0.231148; batch adversarial loss: 0.434613\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152598; batch adversarial loss: 0.446273\n",
      "epoch 81; iter: 0; batch classifier loss: 0.275539; batch adversarial loss: 0.447895\n",
      "epoch 82; iter: 0; batch classifier loss: 0.112134; batch adversarial loss: 0.397400\n",
      "epoch 83; iter: 0; batch classifier loss: 0.179711; batch adversarial loss: 0.422174\n",
      "epoch 84; iter: 0; batch classifier loss: 0.149013; batch adversarial loss: 0.458459\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194356; batch adversarial loss: 0.459952\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181080; batch adversarial loss: 0.519154\n",
      "epoch 87; iter: 0; batch classifier loss: 0.174145; batch adversarial loss: 0.434362\n",
      "epoch 88; iter: 0; batch classifier loss: 0.247823; batch adversarial loss: 0.531800\n",
      "epoch 89; iter: 0; batch classifier loss: 0.193943; batch adversarial loss: 0.434468\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.421021\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062701; batch adversarial loss: 0.543663\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048807; batch adversarial loss: 0.526784\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086725; batch adversarial loss: 0.523870\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063727; batch adversarial loss: 0.391962\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058052; batch adversarial loss: 0.433659\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058977; batch adversarial loss: 0.644138\n",
      "epoch 97; iter: 0; batch classifier loss: 0.126443; batch adversarial loss: 0.434689\n",
      "epoch 98; iter: 0; batch classifier loss: 0.113485; batch adversarial loss: 0.536049\n",
      "epoch 99; iter: 0; batch classifier loss: 0.131569; batch adversarial loss: 0.396788\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093427; batch adversarial loss: 0.423829\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083603; batch adversarial loss: 0.421700\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056031; batch adversarial loss: 0.438904\n",
      "epoch 103; iter: 0; batch classifier loss: 0.130007; batch adversarial loss: 0.449737\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056995; batch adversarial loss: 0.536822\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042643; batch adversarial loss: 0.491463\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052515; batch adversarial loss: 0.491090\n",
      "epoch 107; iter: 0; batch classifier loss: 0.088115; batch adversarial loss: 0.494362\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055889; batch adversarial loss: 0.431909\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.526874\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045981; batch adversarial loss: 0.434403\n",
      "epoch 111; iter: 0; batch classifier loss: 0.072392; batch adversarial loss: 0.461414\n",
      "epoch 112; iter: 0; batch classifier loss: 0.119242; batch adversarial loss: 0.480449\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040028; batch adversarial loss: 0.416523\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054970; batch adversarial loss: 0.447124\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062689; batch adversarial loss: 0.458442\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079774; batch adversarial loss: 0.494003\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052350; batch adversarial loss: 0.376443\n",
      "epoch 118; iter: 0; batch classifier loss: 0.084439; batch adversarial loss: 0.484514\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055365; batch adversarial loss: 0.458169\n",
      "epoch 120; iter: 0; batch classifier loss: 0.089849; batch adversarial loss: 0.507731\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045819; batch adversarial loss: 0.454658\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076487; batch adversarial loss: 0.425395\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048751; batch adversarial loss: 0.517375\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039628; batch adversarial loss: 0.501336\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034128; batch adversarial loss: 0.422244\n",
      "epoch 126; iter: 0; batch classifier loss: 0.086192; batch adversarial loss: 0.505559\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054103; batch adversarial loss: 0.560649\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014787; batch adversarial loss: 0.435291\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040968; batch adversarial loss: 0.545381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061533; batch adversarial loss: 0.522446\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029066; batch adversarial loss: 0.321378\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033159; batch adversarial loss: 0.459193\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.502025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.027731; batch adversarial loss: 0.524697\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040484; batch adversarial loss: 0.446187\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026993; batch adversarial loss: 0.515876\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033359; batch adversarial loss: 0.434953\n",
      "epoch 138; iter: 0; batch classifier loss: 0.074760; batch adversarial loss: 0.385462\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067046; batch adversarial loss: 0.519146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056541; batch adversarial loss: 0.384995\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039977; batch adversarial loss: 0.385259\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036911; batch adversarial loss: 0.328115\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027289; batch adversarial loss: 0.550880\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.459012\n",
      "epoch 145; iter: 0; batch classifier loss: 0.065237; batch adversarial loss: 0.498821\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013365; batch adversarial loss: 0.466075\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033221; batch adversarial loss: 0.473158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007058; batch adversarial loss: 0.467152\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028920; batch adversarial loss: 0.429270\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041428; batch adversarial loss: 0.347764\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034134; batch adversarial loss: 0.409058\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019114; batch adversarial loss: 0.437639\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029624; batch adversarial loss: 0.508673\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015384; batch adversarial loss: 0.338629\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037396; batch adversarial loss: 0.397346\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039145; batch adversarial loss: 0.586079\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018244; batch adversarial loss: 0.531388\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032218; batch adversarial loss: 0.433842\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014628; batch adversarial loss: 0.449136\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013258; batch adversarial loss: 0.472593\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024293; batch adversarial loss: 0.363153\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019146; batch adversarial loss: 0.514736\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012071; batch adversarial loss: 0.426993\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043197; batch adversarial loss: 0.412880\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.474421\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018708; batch adversarial loss: 0.476041\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016110; batch adversarial loss: 0.381391\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022026; batch adversarial loss: 0.489863\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.397491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023272; batch adversarial loss: 0.437496\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044984; batch adversarial loss: 0.458342\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004508; batch adversarial loss: 0.513033\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010683; batch adversarial loss: 0.459673\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.378690\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010721; batch adversarial loss: 0.521865\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035264; batch adversarial loss: 0.467264\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008977; batch adversarial loss: 0.505385\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010160; batch adversarial loss: 0.489502\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008299; batch adversarial loss: 0.487471\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030881; batch adversarial loss: 0.542888\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034263; batch adversarial loss: 0.443984\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035641; batch adversarial loss: 0.387709\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032857; batch adversarial loss: 0.512946\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014063; batch adversarial loss: 0.397792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017891; batch adversarial loss: 0.490944\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027058; batch adversarial loss: 0.418960\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029799; batch adversarial loss: 0.419601\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013007; batch adversarial loss: 0.418372\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008575; batch adversarial loss: 0.476700\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038024; batch adversarial loss: 0.432427\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010628; batch adversarial loss: 0.419648\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004853; batch adversarial loss: 0.450070\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012175; batch adversarial loss: 0.384028\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008666; batch adversarial loss: 0.486108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003207; batch adversarial loss: 0.491976\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010919; batch adversarial loss: 0.486651\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018722; batch adversarial loss: 0.402996\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012393; batch adversarial loss: 0.392362\n",
      "epoch 199; iter: 0; batch classifier loss: 0.038158; batch adversarial loss: 0.428217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.737269; batch adversarial loss: 0.976789\n",
      "epoch 1; iter: 0; batch classifier loss: 0.669942; batch adversarial loss: 1.000873\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900487; batch adversarial loss: 1.055067\n",
      "epoch 3; iter: 0; batch classifier loss: 0.821673; batch adversarial loss: 0.932709\n",
      "epoch 4; iter: 0; batch classifier loss: 0.996328; batch adversarial loss: 0.849435\n",
      "epoch 5; iter: 0; batch classifier loss: 0.907357; batch adversarial loss: 0.780545\n",
      "epoch 6; iter: 0; batch classifier loss: 1.010986; batch adversarial loss: 0.685371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.857673; batch adversarial loss: 0.659902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.846790; batch adversarial loss: 0.592217\n",
      "epoch 9; iter: 0; batch classifier loss: 0.644203; batch adversarial loss: 0.553205\n",
      "epoch 10; iter: 0; batch classifier loss: 0.329443; batch adversarial loss: 0.569286\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308480; batch adversarial loss: 0.521029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356024; batch adversarial loss: 0.538445\n",
      "epoch 13; iter: 0; batch classifier loss: 0.359527; batch adversarial loss: 0.492536\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281721; batch adversarial loss: 0.534231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315152; batch adversarial loss: 0.535715\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333975; batch adversarial loss: 0.487089\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333356; batch adversarial loss: 0.493565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332397; batch adversarial loss: 0.530310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392271; batch adversarial loss: 0.494998\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381671; batch adversarial loss: 0.436980\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306527; batch adversarial loss: 0.495036\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329687; batch adversarial loss: 0.450385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319313; batch adversarial loss: 0.474950\n",
      "epoch 24; iter: 0; batch classifier loss: 0.304522; batch adversarial loss: 0.533502\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316301; batch adversarial loss: 0.474407\n",
      "epoch 26; iter: 0; batch classifier loss: 0.396093; batch adversarial loss: 0.515195\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313952; batch adversarial loss: 0.504966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.271398; batch adversarial loss: 0.523689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332535; batch adversarial loss: 0.495398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.351280; batch adversarial loss: 0.473559\n",
      "epoch 31; iter: 0; batch classifier loss: 0.301878; batch adversarial loss: 0.504430\n",
      "epoch 32; iter: 0; batch classifier loss: 0.254537; batch adversarial loss: 0.478231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.304076; batch adversarial loss: 0.535871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.307994; batch adversarial loss: 0.401528\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314467; batch adversarial loss: 0.400828\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249371; batch adversarial loss: 0.443273\n",
      "epoch 37; iter: 0; batch classifier loss: 0.330370; batch adversarial loss: 0.455462\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223475; batch adversarial loss: 0.404834\n",
      "epoch 39; iter: 0; batch classifier loss: 0.233983; batch adversarial loss: 0.426737\n",
      "epoch 40; iter: 0; batch classifier loss: 0.281971; batch adversarial loss: 0.485174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.289279; batch adversarial loss: 0.435081\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235187; batch adversarial loss: 0.377181\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227666; batch adversarial loss: 0.508023\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267596; batch adversarial loss: 0.465796\n",
      "epoch 45; iter: 0; batch classifier loss: 0.218935; batch adversarial loss: 0.462183\n",
      "epoch 46; iter: 0; batch classifier loss: 0.243814; batch adversarial loss: 0.355766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.264316; batch adversarial loss: 0.473461\n",
      "epoch 48; iter: 0; batch classifier loss: 0.241585; batch adversarial loss: 0.424813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.243188; batch adversarial loss: 0.483226\n",
      "epoch 50; iter: 0; batch classifier loss: 0.200189; batch adversarial loss: 0.412007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.208328; batch adversarial loss: 0.447448\n",
      "epoch 52; iter: 0; batch classifier loss: 0.220225; batch adversarial loss: 0.434502\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247904; batch adversarial loss: 0.411894\n",
      "epoch 54; iter: 0; batch classifier loss: 0.148476; batch adversarial loss: 0.573129\n",
      "epoch 55; iter: 0; batch classifier loss: 0.258909; batch adversarial loss: 0.372413\n",
      "epoch 56; iter: 0; batch classifier loss: 0.280082; batch adversarial loss: 0.461360\n",
      "epoch 57; iter: 0; batch classifier loss: 0.285568; batch adversarial loss: 0.408943\n",
      "epoch 58; iter: 0; batch classifier loss: 0.283888; batch adversarial loss: 0.483852\n",
      "epoch 59; iter: 0; batch classifier loss: 0.228168; batch adversarial loss: 0.407144\n",
      "epoch 60; iter: 0; batch classifier loss: 0.218627; batch adversarial loss: 0.423420\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175385; batch adversarial loss: 0.419989\n",
      "epoch 62; iter: 0; batch classifier loss: 0.230884; batch adversarial loss: 0.470558\n",
      "epoch 63; iter: 0; batch classifier loss: 0.233932; batch adversarial loss: 0.421164\n",
      "epoch 64; iter: 0; batch classifier loss: 0.202275; batch adversarial loss: 0.409017\n",
      "epoch 65; iter: 0; batch classifier loss: 0.180770; batch adversarial loss: 0.447798\n",
      "epoch 66; iter: 0; batch classifier loss: 0.185361; batch adversarial loss: 0.497065\n",
      "epoch 67; iter: 0; batch classifier loss: 0.266623; batch adversarial loss: 0.433710\n",
      "epoch 68; iter: 0; batch classifier loss: 0.246705; batch adversarial loss: 0.497380\n",
      "epoch 69; iter: 0; batch classifier loss: 0.239045; batch adversarial loss: 0.432974\n",
      "epoch 70; iter: 0; batch classifier loss: 0.223311; batch adversarial loss: 0.395775\n",
      "epoch 71; iter: 0; batch classifier loss: 0.144984; batch adversarial loss: 0.331909\n",
      "epoch 72; iter: 0; batch classifier loss: 0.295666; batch adversarial loss: 0.433484\n",
      "epoch 73; iter: 0; batch classifier loss: 0.161843; batch adversarial loss: 0.471730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316137; batch adversarial loss: 0.510069\n",
      "epoch 75; iter: 0; batch classifier loss: 0.138370; batch adversarial loss: 0.420042\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170512; batch adversarial loss: 0.459216\n",
      "epoch 77; iter: 0; batch classifier loss: 0.232485; batch adversarial loss: 0.432356\n",
      "epoch 78; iter: 0; batch classifier loss: 0.153854; batch adversarial loss: 0.498587\n",
      "epoch 79; iter: 0; batch classifier loss: 0.177193; batch adversarial loss: 0.446277\n",
      "epoch 80; iter: 0; batch classifier loss: 0.212816; batch adversarial loss: 0.382811\n",
      "epoch 81; iter: 0; batch classifier loss: 0.194492; batch adversarial loss: 0.433610\n",
      "epoch 82; iter: 0; batch classifier loss: 0.235034; batch adversarial loss: 0.510715\n",
      "epoch 83; iter: 0; batch classifier loss: 0.190485; batch adversarial loss: 0.459096\n",
      "epoch 84; iter: 0; batch classifier loss: 0.145741; batch adversarial loss: 0.343961\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089052; batch adversarial loss: 0.432263\n",
      "epoch 86; iter: 0; batch classifier loss: 0.130888; batch adversarial loss: 0.418461\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122247; batch adversarial loss: 0.538424\n",
      "epoch 88; iter: 0; batch classifier loss: 0.152123; batch adversarial loss: 0.499291\n",
      "epoch 89; iter: 0; batch classifier loss: 0.201442; batch adversarial loss: 0.458636\n",
      "epoch 90; iter: 0; batch classifier loss: 0.238458; batch adversarial loss: 0.445439\n",
      "epoch 91; iter: 0; batch classifier loss: 0.235498; batch adversarial loss: 0.460310\n",
      "epoch 92; iter: 0; batch classifier loss: 0.152768; batch adversarial loss: 0.484396\n",
      "epoch 93; iter: 0; batch classifier loss: 0.188455; batch adversarial loss: 0.424375\n",
      "epoch 94; iter: 0; batch classifier loss: 0.210049; batch adversarial loss: 0.408575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.224347; batch adversarial loss: 0.524511\n",
      "epoch 96; iter: 0; batch classifier loss: 0.225733; batch adversarial loss: 0.446303\n",
      "epoch 97; iter: 0; batch classifier loss: 0.171822; batch adversarial loss: 0.548409\n",
      "epoch 98; iter: 0; batch classifier loss: 0.193359; batch adversarial loss: 0.330643\n",
      "epoch 99; iter: 0; batch classifier loss: 0.220442; batch adversarial loss: 0.421196\n",
      "epoch 100; iter: 0; batch classifier loss: 0.203648; batch adversarial loss: 0.407544\n",
      "epoch 101; iter: 0; batch classifier loss: 0.235951; batch adversarial loss: 0.432960\n",
      "epoch 102; iter: 0; batch classifier loss: 0.222022; batch adversarial loss: 0.356904\n",
      "epoch 103; iter: 0; batch classifier loss: 0.150587; batch adversarial loss: 0.523091\n",
      "epoch 104; iter: 0; batch classifier loss: 0.132484; batch adversarial loss: 0.573794\n",
      "epoch 105; iter: 0; batch classifier loss: 0.183240; batch adversarial loss: 0.471985\n",
      "epoch 106; iter: 0; batch classifier loss: 0.222274; batch adversarial loss: 0.318703\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153652; batch adversarial loss: 0.433561\n",
      "epoch 108; iter: 0; batch classifier loss: 0.074372; batch adversarial loss: 0.420383\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071541; batch adversarial loss: 0.328144\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075822; batch adversarial loss: 0.404243\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062085; batch adversarial loss: 0.392432\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049500; batch adversarial loss: 0.390590\n",
      "epoch 113; iter: 0; batch classifier loss: 0.088840; batch adversarial loss: 0.440994\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068874; batch adversarial loss: 0.471232\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065474; batch adversarial loss: 0.355814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.093857; batch adversarial loss: 0.503114\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053347; batch adversarial loss: 0.480180\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073924; batch adversarial loss: 0.399514\n",
      "epoch 119; iter: 0; batch classifier loss: 0.080025; batch adversarial loss: 0.282529\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069771; batch adversarial loss: 0.395977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.097826; batch adversarial loss: 0.392409\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033442; batch adversarial loss: 0.512851\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079112; batch adversarial loss: 0.441041\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064658; batch adversarial loss: 0.429155\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075287; batch adversarial loss: 0.373698\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035568; batch adversarial loss: 0.546478\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.428378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.066326; batch adversarial loss: 0.427764\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028059; batch adversarial loss: 0.469349\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026193; batch adversarial loss: 0.504774\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.457206\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034586; batch adversarial loss: 0.303330\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016646; batch adversarial loss: 0.406244\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055962; batch adversarial loss: 0.476928\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067556; batch adversarial loss: 0.383994\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055183; batch adversarial loss: 0.481240\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025268; batch adversarial loss: 0.385929\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056042; batch adversarial loss: 0.436176\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034897; batch adversarial loss: 0.383021\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034882; batch adversarial loss: 0.414261\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047515; batch adversarial loss: 0.448979\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030053; batch adversarial loss: 0.508939\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031568; batch adversarial loss: 0.381218\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027591; batch adversarial loss: 0.394713\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038033; batch adversarial loss: 0.499214\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047553; batch adversarial loss: 0.364442\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016835; batch adversarial loss: 0.442322\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023115; batch adversarial loss: 0.418490\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009637; batch adversarial loss: 0.421613\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.473236\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033787; batch adversarial loss: 0.502666\n",
      "epoch 152; iter: 0; batch classifier loss: 0.048397; batch adversarial loss: 0.497381\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014815; batch adversarial loss: 0.419649\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046910; batch adversarial loss: 0.514859\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009266; batch adversarial loss: 0.451950\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046187; batch adversarial loss: 0.457726\n",
      "epoch 157; iter: 0; batch classifier loss: 0.063540; batch adversarial loss: 0.388851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011890; batch adversarial loss: 0.345822\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026274; batch adversarial loss: 0.400707\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015328; batch adversarial loss: 0.376170\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008783; batch adversarial loss: 0.447067\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027004; batch adversarial loss: 0.492295\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026605; batch adversarial loss: 0.503258\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031354; batch adversarial loss: 0.546331\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005299; batch adversarial loss: 0.361975\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019026; batch adversarial loss: 0.398564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.035836; batch adversarial loss: 0.422874\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025477; batch adversarial loss: 0.462025\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006224; batch adversarial loss: 0.455933\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028723; batch adversarial loss: 0.441887\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025604; batch adversarial loss: 0.430409\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018432; batch adversarial loss: 0.482964\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006540; batch adversarial loss: 0.420876\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017846; batch adversarial loss: 0.410657\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007857; batch adversarial loss: 0.407509\n",
      "epoch 176; iter: 0; batch classifier loss: 0.049201; batch adversarial loss: 0.469973\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031715; batch adversarial loss: 0.530982\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008118; batch adversarial loss: 0.424024\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007297; batch adversarial loss: 0.492383\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019552; batch adversarial loss: 0.393516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034372; batch adversarial loss: 0.550026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003705; batch adversarial loss: 0.439774\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.383190\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007155; batch adversarial loss: 0.466927\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007134; batch adversarial loss: 0.471280\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008184; batch adversarial loss: 0.452399\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024818; batch adversarial loss: 0.355943\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005434; batch adversarial loss: 0.455518\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009861; batch adversarial loss: 0.422388\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021649; batch adversarial loss: 0.386500\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015333; batch adversarial loss: 0.436424\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026633; batch adversarial loss: 0.465349\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008585; batch adversarial loss: 0.361635\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020435; batch adversarial loss: 0.431501\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011107; batch adversarial loss: 0.406732\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026773; batch adversarial loss: 0.466988\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002455; batch adversarial loss: 0.475982\n",
      "epoch 198; iter: 0; batch classifier loss: 0.051192; batch adversarial loss: 0.404370\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023747; batch adversarial loss: 0.410076\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694985; batch adversarial loss: 1.013927\n",
      "epoch 1; iter: 0; batch classifier loss: 0.673361; batch adversarial loss: 1.157154\n",
      "epoch 2; iter: 0; batch classifier loss: 0.844938; batch adversarial loss: 1.193223\n",
      "epoch 3; iter: 0; batch classifier loss: 1.043939; batch adversarial loss: 1.156130\n",
      "epoch 4; iter: 0; batch classifier loss: 1.059968; batch adversarial loss: 1.033713\n",
      "epoch 5; iter: 0; batch classifier loss: 0.875487; batch adversarial loss: 0.926853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.931545; batch adversarial loss: 0.849267\n",
      "epoch 7; iter: 0; batch classifier loss: 1.018518; batch adversarial loss: 0.769653\n",
      "epoch 8; iter: 0; batch classifier loss: 1.096463; batch adversarial loss: 0.705802\n",
      "epoch 9; iter: 0; batch classifier loss: 1.068065; batch adversarial loss: 0.647157\n",
      "epoch 10; iter: 0; batch classifier loss: 1.021401; batch adversarial loss: 0.607855\n",
      "epoch 11; iter: 0; batch classifier loss: 1.031303; batch adversarial loss: 0.568706\n",
      "epoch 12; iter: 0; batch classifier loss: 0.716803; batch adversarial loss: 0.505703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370407; batch adversarial loss: 0.500109\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280949; batch adversarial loss: 0.529961\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284407; batch adversarial loss: 0.530636\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293266; batch adversarial loss: 0.513364\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349062; batch adversarial loss: 0.464919\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252768; batch adversarial loss: 0.497814\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285380; batch adversarial loss: 0.487179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259484; batch adversarial loss: 0.474430\n",
      "epoch 21; iter: 0; batch classifier loss: 0.309560; batch adversarial loss: 0.578371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174031; batch adversarial loss: 0.529529\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245515; batch adversarial loss: 0.523117\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175226; batch adversarial loss: 0.506079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.267832; batch adversarial loss: 0.469073\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307225; batch adversarial loss: 0.423055\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235257; batch adversarial loss: 0.496474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.270740; batch adversarial loss: 0.443311\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289193; batch adversarial loss: 0.522436\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226747; batch adversarial loss: 0.419362\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260681; batch adversarial loss: 0.492988\n",
      "epoch 32; iter: 0; batch classifier loss: 0.245533; batch adversarial loss: 0.525699\n",
      "epoch 33; iter: 0; batch classifier loss: 0.196643; batch adversarial loss: 0.510446\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214898; batch adversarial loss: 0.503719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.212074; batch adversarial loss: 0.412945\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235095; batch adversarial loss: 0.478096\n",
      "epoch 37; iter: 0; batch classifier loss: 0.254161; batch adversarial loss: 0.443903\n",
      "epoch 38; iter: 0; batch classifier loss: 0.202237; batch adversarial loss: 0.453152\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221976; batch adversarial loss: 0.393804\n",
      "epoch 40; iter: 0; batch classifier loss: 0.216966; batch adversarial loss: 0.476858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275448; batch adversarial loss: 0.373293\n",
      "epoch 42; iter: 0; batch classifier loss: 0.230335; batch adversarial loss: 0.585351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227387; batch adversarial loss: 0.570680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.192452; batch adversarial loss: 0.375409\n",
      "epoch 45; iter: 0; batch classifier loss: 0.211315; batch adversarial loss: 0.466098\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175974; batch adversarial loss: 0.426476\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215885; batch adversarial loss: 0.499181\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275217; batch adversarial loss: 0.402639\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214964; batch adversarial loss: 0.375891\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152146; batch adversarial loss: 0.452274\n",
      "epoch 51; iter: 0; batch classifier loss: 0.219232; batch adversarial loss: 0.472126\n",
      "epoch 52; iter: 0; batch classifier loss: 0.170415; batch adversarial loss: 0.413648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204048; batch adversarial loss: 0.503050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.160641; batch adversarial loss: 0.464974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160570; batch adversarial loss: 0.458523\n",
      "epoch 56; iter: 0; batch classifier loss: 0.195807; batch adversarial loss: 0.458733\n",
      "epoch 57; iter: 0; batch classifier loss: 0.222112; batch adversarial loss: 0.408511\n",
      "epoch 58; iter: 0; batch classifier loss: 0.199939; batch adversarial loss: 0.452313\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134654; batch adversarial loss: 0.518312\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158942; batch adversarial loss: 0.469808\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134317; batch adversarial loss: 0.461316\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177008; batch adversarial loss: 0.385831\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149194; batch adversarial loss: 0.449721\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178243; batch adversarial loss: 0.541632\n",
      "epoch 65; iter: 0; batch classifier loss: 0.170121; batch adversarial loss: 0.507874\n",
      "epoch 66; iter: 0; batch classifier loss: 0.145919; batch adversarial loss: 0.512242\n",
      "epoch 67; iter: 0; batch classifier loss: 0.172178; batch adversarial loss: 0.447832\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144186; batch adversarial loss: 0.481081\n",
      "epoch 69; iter: 0; batch classifier loss: 0.213924; batch adversarial loss: 0.456446\n",
      "epoch 70; iter: 0; batch classifier loss: 0.172950; batch adversarial loss: 0.419796\n",
      "epoch 71; iter: 0; batch classifier loss: 0.140111; batch adversarial loss: 0.407173\n",
      "epoch 72; iter: 0; batch classifier loss: 0.137792; batch adversarial loss: 0.473190\n",
      "epoch 73; iter: 0; batch classifier loss: 0.136945; batch adversarial loss: 0.515957\n",
      "epoch 74; iter: 0; batch classifier loss: 0.180103; batch adversarial loss: 0.393210\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171891; batch adversarial loss: 0.502738\n",
      "epoch 76; iter: 0; batch classifier loss: 0.179620; batch adversarial loss: 0.510403\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193121; batch adversarial loss: 0.408205\n",
      "epoch 78; iter: 0; batch classifier loss: 0.171958; batch adversarial loss: 0.376218\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072624; batch adversarial loss: 0.527930\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153247; batch adversarial loss: 0.452086\n",
      "epoch 81; iter: 0; batch classifier loss: 0.181523; batch adversarial loss: 0.453777\n",
      "epoch 82; iter: 0; batch classifier loss: 0.171451; batch adversarial loss: 0.472206\n",
      "epoch 83; iter: 0; batch classifier loss: 0.195642; batch adversarial loss: 0.468792\n",
      "epoch 84; iter: 0; batch classifier loss: 0.142019; batch adversarial loss: 0.457515\n",
      "epoch 85; iter: 0; batch classifier loss: 0.181947; batch adversarial loss: 0.348753\n",
      "epoch 86; iter: 0; batch classifier loss: 0.135466; batch adversarial loss: 0.509512\n",
      "epoch 87; iter: 0; batch classifier loss: 0.175799; batch adversarial loss: 0.422937\n",
      "epoch 88; iter: 0; batch classifier loss: 0.190008; batch adversarial loss: 0.443657\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110833; batch adversarial loss: 0.545750\n",
      "epoch 90; iter: 0; batch classifier loss: 0.130576; batch adversarial loss: 0.446367\n",
      "epoch 91; iter: 0; batch classifier loss: 0.144278; batch adversarial loss: 0.456191\n",
      "epoch 92; iter: 0; batch classifier loss: 0.159864; batch adversarial loss: 0.458127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.125983; batch adversarial loss: 0.541304\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092920; batch adversarial loss: 0.519160\n",
      "epoch 95; iter: 0; batch classifier loss: 0.127499; batch adversarial loss: 0.425720\n",
      "epoch 96; iter: 0; batch classifier loss: 0.100100; batch adversarial loss: 0.422064\n",
      "epoch 97; iter: 0; batch classifier loss: 0.120011; batch adversarial loss: 0.409486\n",
      "epoch 98; iter: 0; batch classifier loss: 0.169366; batch adversarial loss: 0.459365\n",
      "epoch 99; iter: 0; batch classifier loss: 0.128495; batch adversarial loss: 0.422699\n",
      "epoch 100; iter: 0; batch classifier loss: 0.161117; batch adversarial loss: 0.382670\n",
      "epoch 101; iter: 0; batch classifier loss: 0.148777; batch adversarial loss: 0.471913\n",
      "epoch 102; iter: 0; batch classifier loss: 0.128331; batch adversarial loss: 0.521310\n",
      "epoch 103; iter: 0; batch classifier loss: 0.150304; batch adversarial loss: 0.554969\n",
      "epoch 104; iter: 0; batch classifier loss: 0.174906; batch adversarial loss: 0.394010\n",
      "epoch 105; iter: 0; batch classifier loss: 0.157679; batch adversarial loss: 0.447522\n",
      "epoch 106; iter: 0; batch classifier loss: 0.163470; batch adversarial loss: 0.541266\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153060; batch adversarial loss: 0.413889\n",
      "epoch 108; iter: 0; batch classifier loss: 0.124851; batch adversarial loss: 0.468747\n",
      "epoch 109; iter: 0; batch classifier loss: 0.101876; batch adversarial loss: 0.475618\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089845; batch adversarial loss: 0.516859\n",
      "epoch 111; iter: 0; batch classifier loss: 0.153205; batch adversarial loss: 0.394986\n",
      "epoch 112; iter: 0; batch classifier loss: 0.136019; batch adversarial loss: 0.456318\n",
      "epoch 113; iter: 0; batch classifier loss: 0.154481; batch adversarial loss: 0.513330\n",
      "epoch 114; iter: 0; batch classifier loss: 0.152669; batch adversarial loss: 0.468650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.106597; batch adversarial loss: 0.397755\n",
      "epoch 116; iter: 0; batch classifier loss: 0.073436; batch adversarial loss: 0.404993\n",
      "epoch 117; iter: 0; batch classifier loss: 0.139097; batch adversarial loss: 0.404373\n",
      "epoch 118; iter: 0; batch classifier loss: 0.090055; batch adversarial loss: 0.455149\n",
      "epoch 119; iter: 0; batch classifier loss: 0.109887; batch adversarial loss: 0.565222\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074472; batch adversarial loss: 0.444977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.104007; batch adversarial loss: 0.429279\n",
      "epoch 122; iter: 0; batch classifier loss: 0.094785; batch adversarial loss: 0.388407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.081510; batch adversarial loss: 0.428540\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058800; batch adversarial loss: 0.398200\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062738; batch adversarial loss: 0.519112\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060302; batch adversarial loss: 0.386852\n",
      "epoch 127; iter: 0; batch classifier loss: 0.097370; batch adversarial loss: 0.415266\n",
      "epoch 128; iter: 0; batch classifier loss: 0.076010; batch adversarial loss: 0.431794\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055512; batch adversarial loss: 0.527399\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061109; batch adversarial loss: 0.478594\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033185; batch adversarial loss: 0.474734\n",
      "epoch 132; iter: 0; batch classifier loss: 0.050824; batch adversarial loss: 0.488526\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.489413\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046131; batch adversarial loss: 0.483008\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.556368\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026661; batch adversarial loss: 0.446115\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050188; batch adversarial loss: 0.551696\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041076; batch adversarial loss: 0.397354\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040378; batch adversarial loss: 0.463547\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031030; batch adversarial loss: 0.547798\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039761; batch adversarial loss: 0.497399\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032249; batch adversarial loss: 0.473333\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031283; batch adversarial loss: 0.499281\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016354; batch adversarial loss: 0.419333\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040979; batch adversarial loss: 0.482544\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037090; batch adversarial loss: 0.475790\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.533141\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025552; batch adversarial loss: 0.433890\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019934; batch adversarial loss: 0.486997\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028559; batch adversarial loss: 0.491560\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040343; batch adversarial loss: 0.418687\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016428; batch adversarial loss: 0.458470\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031614; batch adversarial loss: 0.556634\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044830; batch adversarial loss: 0.342258\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023351; batch adversarial loss: 0.474989\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037386; batch adversarial loss: 0.478096\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032290; batch adversarial loss: 0.374586\n",
      "epoch 158; iter: 0; batch classifier loss: 0.020670; batch adversarial loss: 0.478686\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038503; batch adversarial loss: 0.448551\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027871; batch adversarial loss: 0.403757\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029367; batch adversarial loss: 0.366596\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021859; batch adversarial loss: 0.544814\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020639; batch adversarial loss: 0.365551\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016865; batch adversarial loss: 0.468329\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034492; batch adversarial loss: 0.420360\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010819; batch adversarial loss: 0.404241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022134; batch adversarial loss: 0.423166\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008987; batch adversarial loss: 0.524727\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016988; batch adversarial loss: 0.451075\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016537; batch adversarial loss: 0.473929\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025722; batch adversarial loss: 0.384679\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013802; batch adversarial loss: 0.448318\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007948; batch adversarial loss: 0.382956\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008668; batch adversarial loss: 0.467332\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.466769\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022338; batch adversarial loss: 0.555971\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009583; batch adversarial loss: 0.441009\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021350; batch adversarial loss: 0.417963\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019435; batch adversarial loss: 0.493255\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007641; batch adversarial loss: 0.520412\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052970; batch adversarial loss: 0.539979\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017039; batch adversarial loss: 0.374140\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030024; batch adversarial loss: 0.404516\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026539; batch adversarial loss: 0.518033\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009165; batch adversarial loss: 0.488182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013405; batch adversarial loss: 0.529395\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012082; batch adversarial loss: 0.491507\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035004; batch adversarial loss: 0.483126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019972; batch adversarial loss: 0.443590\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008069; batch adversarial loss: 0.516956\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030359; batch adversarial loss: 0.416066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026000; batch adversarial loss: 0.425524\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011307; batch adversarial loss: 0.459593\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024472; batch adversarial loss: 0.386827\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021293; batch adversarial loss: 0.508567\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023426; batch adversarial loss: 0.363888\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004426; batch adversarial loss: 0.431483\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016773; batch adversarial loss: 0.447524\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042570; batch adversarial loss: 0.391098\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708094; batch adversarial loss: 0.973122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.633115; batch adversarial loss: 1.098464\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900713; batch adversarial loss: 1.137997\n",
      "epoch 3; iter: 0; batch classifier loss: 0.763982; batch adversarial loss: 1.027741\n",
      "epoch 4; iter: 0; batch classifier loss: 1.097070; batch adversarial loss: 0.956469\n",
      "epoch 5; iter: 0; batch classifier loss: 1.058107; batch adversarial loss: 0.860471\n",
      "epoch 6; iter: 0; batch classifier loss: 1.246726; batch adversarial loss: 0.793984\n",
      "epoch 7; iter: 0; batch classifier loss: 1.115212; batch adversarial loss: 0.710656\n",
      "epoch 8; iter: 0; batch classifier loss: 1.041461; batch adversarial loss: 0.663348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.945197; batch adversarial loss: 0.600915\n",
      "epoch 10; iter: 0; batch classifier loss: 0.969375; batch adversarial loss: 0.568872\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546864; batch adversarial loss: 0.513081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436981; batch adversarial loss: 0.525757\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406398; batch adversarial loss: 0.472623\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395293; batch adversarial loss: 0.485295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306491; batch adversarial loss: 0.500154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276639; batch adversarial loss: 0.544285\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292839; batch adversarial loss: 0.490670\n",
      "epoch 18; iter: 0; batch classifier loss: 0.311802; batch adversarial loss: 0.501793\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343349; batch adversarial loss: 0.457700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.359598; batch adversarial loss: 0.475325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298780; batch adversarial loss: 0.526664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259058; batch adversarial loss: 0.478212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263442; batch adversarial loss: 0.435434\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271796; batch adversarial loss: 0.466861\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341710; batch adversarial loss: 0.454331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.310320; batch adversarial loss: 0.517951\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.411694\n",
      "epoch 28; iter: 0; batch classifier loss: 0.329035; batch adversarial loss: 0.423817\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313872; batch adversarial loss: 0.516689\n",
      "epoch 30; iter: 0; batch classifier loss: 0.317028; batch adversarial loss: 0.422136\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314105; batch adversarial loss: 0.510173\n",
      "epoch 32; iter: 0; batch classifier loss: 0.294558; batch adversarial loss: 0.404904\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330999; batch adversarial loss: 0.435381\n",
      "epoch 34; iter: 0; batch classifier loss: 0.259980; batch adversarial loss: 0.464041\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277165; batch adversarial loss: 0.455771\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293684; batch adversarial loss: 0.501011\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233186; batch adversarial loss: 0.417733\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296238; batch adversarial loss: 0.494024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.281515; batch adversarial loss: 0.556720\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260368; batch adversarial loss: 0.450445\n",
      "epoch 41; iter: 0; batch classifier loss: 0.272923; batch adversarial loss: 0.382545\n",
      "epoch 42; iter: 0; batch classifier loss: 0.265471; batch adversarial loss: 0.372014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.248020; batch adversarial loss: 0.403164\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206579; batch adversarial loss: 0.530214\n",
      "epoch 45; iter: 0; batch classifier loss: 0.210790; batch adversarial loss: 0.458471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.213880; batch adversarial loss: 0.472236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.237197; batch adversarial loss: 0.508815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244504; batch adversarial loss: 0.406353\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197020; batch adversarial loss: 0.486498\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181146; batch adversarial loss: 0.439183\n",
      "epoch 51; iter: 0; batch classifier loss: 0.197386; batch adversarial loss: 0.445202\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161237; batch adversarial loss: 0.496161\n",
      "epoch 53; iter: 0; batch classifier loss: 0.154810; batch adversarial loss: 0.607089\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147468; batch adversarial loss: 0.549955\n",
      "epoch 55; iter: 0; batch classifier loss: 0.193584; batch adversarial loss: 0.395334\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169804; batch adversarial loss: 0.531588\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143688; batch adversarial loss: 0.514509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.121671; batch adversarial loss: 0.388706\n",
      "epoch 59; iter: 0; batch classifier loss: 0.166109; batch adversarial loss: 0.442515\n",
      "epoch 60; iter: 0; batch classifier loss: 0.160815; batch adversarial loss: 0.425512\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124404; batch adversarial loss: 0.471801\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160564; batch adversarial loss: 0.357725\n",
      "epoch 63; iter: 0; batch classifier loss: 0.179892; batch adversarial loss: 0.393935\n",
      "epoch 64; iter: 0; batch classifier loss: 0.158110; batch adversarial loss: 0.423190\n",
      "epoch 65; iter: 0; batch classifier loss: 0.140516; batch adversarial loss: 0.478230\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146058; batch adversarial loss: 0.465870\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118325; batch adversarial loss: 0.484081\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144006; batch adversarial loss: 0.426367\n",
      "epoch 69; iter: 0; batch classifier loss: 0.120319; batch adversarial loss: 0.492967\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089770; batch adversarial loss: 0.473006\n",
      "epoch 71; iter: 0; batch classifier loss: 0.153471; batch adversarial loss: 0.476346\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140926; batch adversarial loss: 0.460379\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089040; batch adversarial loss: 0.369289\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076392; batch adversarial loss: 0.404720\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095871; batch adversarial loss: 0.397109\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070355; batch adversarial loss: 0.426588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156034; batch adversarial loss: 0.419539\n",
      "epoch 78; iter: 0; batch classifier loss: 0.164968; batch adversarial loss: 0.483675\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104139; batch adversarial loss: 0.390264\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128366; batch adversarial loss: 0.424688\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064455; batch adversarial loss: 0.407116\n",
      "epoch 82; iter: 0; batch classifier loss: 0.089327; batch adversarial loss: 0.480733\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074082; batch adversarial loss: 0.405432\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062503; batch adversarial loss: 0.426481\n",
      "epoch 85; iter: 0; batch classifier loss: 0.101275; batch adversarial loss: 0.429521\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084478; batch adversarial loss: 0.455140\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100042; batch adversarial loss: 0.437739\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088019; batch adversarial loss: 0.495026\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121196; batch adversarial loss: 0.577681\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078338; batch adversarial loss: 0.419179\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070763; batch adversarial loss: 0.578674\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.373181\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091765; batch adversarial loss: 0.449520\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072603; batch adversarial loss: 0.403562\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047780; batch adversarial loss: 0.455087\n",
      "epoch 96; iter: 0; batch classifier loss: 0.114465; batch adversarial loss: 0.459698\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069542; batch adversarial loss: 0.501747\n",
      "epoch 98; iter: 0; batch classifier loss: 0.119991; batch adversarial loss: 0.447079\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034146; batch adversarial loss: 0.539816\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059219; batch adversarial loss: 0.537081\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056051; batch adversarial loss: 0.496793\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035782; batch adversarial loss: 0.379118\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046825; batch adversarial loss: 0.491110\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064132; batch adversarial loss: 0.398590\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038010; batch adversarial loss: 0.410281\n",
      "epoch 106; iter: 0; batch classifier loss: 0.093615; batch adversarial loss: 0.388795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.018427; batch adversarial loss: 0.478248\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040782; batch adversarial loss: 0.452371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040205; batch adversarial loss: 0.390845\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046833; batch adversarial loss: 0.492081\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048907; batch adversarial loss: 0.498699\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046523; batch adversarial loss: 0.439026\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048543; batch adversarial loss: 0.514292\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059724; batch adversarial loss: 0.484069\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078080; batch adversarial loss: 0.521627\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039614; batch adversarial loss: 0.398535\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012144; batch adversarial loss: 0.448854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.066583; batch adversarial loss: 0.349492\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057433; batch adversarial loss: 0.398764\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034225; batch adversarial loss: 0.448105\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029918; batch adversarial loss: 0.425549\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049629; batch adversarial loss: 0.517811\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039739; batch adversarial loss: 0.426062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029008; batch adversarial loss: 0.510274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046835; batch adversarial loss: 0.500298\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033566; batch adversarial loss: 0.467224\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.531008\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017417; batch adversarial loss: 0.354073\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039163; batch adversarial loss: 0.501753\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044145; batch adversarial loss: 0.466150\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019582; batch adversarial loss: 0.472363\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011051; batch adversarial loss: 0.412115\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013548; batch adversarial loss: 0.495101\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017941; batch adversarial loss: 0.515762\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026703; batch adversarial loss: 0.508759\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025466; batch adversarial loss: 0.460185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016024; batch adversarial loss: 0.471474\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032731; batch adversarial loss: 0.489579\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041236; batch adversarial loss: 0.501463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012134; batch adversarial loss: 0.456365\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043442; batch adversarial loss: 0.438222\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.404887\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018736; batch adversarial loss: 0.454582\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014387; batch adversarial loss: 0.494152\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026016; batch adversarial loss: 0.448999\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044367; batch adversarial loss: 0.421514\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044901; batch adversarial loss: 0.567371\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016212; batch adversarial loss: 0.548690\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028853; batch adversarial loss: 0.429548\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025207; batch adversarial loss: 0.438911\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050171; batch adversarial loss: 0.379017\n",
      "epoch 152; iter: 0; batch classifier loss: 0.007054; batch adversarial loss: 0.487463\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012186; batch adversarial loss: 0.483104\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052916; batch adversarial loss: 0.513279\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012935; batch adversarial loss: 0.486760\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013632; batch adversarial loss: 0.464376\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030575; batch adversarial loss: 0.534461\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018919; batch adversarial loss: 0.468809\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025001; batch adversarial loss: 0.471045\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016823; batch adversarial loss: 0.413784\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018981; batch adversarial loss: 0.533341\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015438; batch adversarial loss: 0.481138\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030208; batch adversarial loss: 0.395483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025069; batch adversarial loss: 0.313634\n",
      "epoch 165; iter: 0; batch classifier loss: 0.005317; batch adversarial loss: 0.439201\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005929; batch adversarial loss: 0.392406\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020319; batch adversarial loss: 0.452384\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020243; batch adversarial loss: 0.391351\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008614; batch adversarial loss: 0.515153\n",
      "epoch 170; iter: 0; batch classifier loss: 0.001951; batch adversarial loss: 0.399925\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015624; batch adversarial loss: 0.556413\n",
      "epoch 172; iter: 0; batch classifier loss: 0.002965; batch adversarial loss: 0.430910\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023217; batch adversarial loss: 0.370370\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032726; batch adversarial loss: 0.354304\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029657; batch adversarial loss: 0.481179\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023483; batch adversarial loss: 0.491919\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034067; batch adversarial loss: 0.485389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043603; batch adversarial loss: 0.294316\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004196; batch adversarial loss: 0.454583\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016317; batch adversarial loss: 0.457041\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012004; batch adversarial loss: 0.495520\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014567; batch adversarial loss: 0.443948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032166; batch adversarial loss: 0.455950\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.422867\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.416639\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008151; batch adversarial loss: 0.375280\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013028; batch adversarial loss: 0.438398\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027867; batch adversarial loss: 0.495860\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021774; batch adversarial loss: 0.480912\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020689; batch adversarial loss: 0.370308\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018233; batch adversarial loss: 0.428592\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042374; batch adversarial loss: 0.360038\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014194; batch adversarial loss: 0.524969\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010117; batch adversarial loss: 0.370569\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014703; batch adversarial loss: 0.445637\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016556; batch adversarial loss: 0.390887\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012299; batch adversarial loss: 0.510527\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019821; batch adversarial loss: 0.496545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014331; batch adversarial loss: 0.461831\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702186; batch adversarial loss: 0.838625\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498402; batch adversarial loss: 0.794386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.807934; batch adversarial loss: 0.818477\n",
      "epoch 3; iter: 0; batch classifier loss: 0.789598; batch adversarial loss: 0.727952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.755164; batch adversarial loss: 0.660108\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555998; batch adversarial loss: 0.605662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389593; batch adversarial loss: 0.585877\n",
      "epoch 7; iter: 0; batch classifier loss: 0.348316; batch adversarial loss: 0.548154\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360143; batch adversarial loss: 0.546132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289948; batch adversarial loss: 0.517660\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338452; batch adversarial loss: 0.498122\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319875; batch adversarial loss: 0.545745\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338609; batch adversarial loss: 0.503013\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272621; batch adversarial loss: 0.513458\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274348; batch adversarial loss: 0.478168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.258649; batch adversarial loss: 0.552264\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260887; batch adversarial loss: 0.468759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290556; batch adversarial loss: 0.496103\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319380; batch adversarial loss: 0.438493\n",
      "epoch 19; iter: 0; batch classifier loss: 0.252407; batch adversarial loss: 0.481099\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204270; batch adversarial loss: 0.478735\n",
      "epoch 21; iter: 0; batch classifier loss: 0.181027; batch adversarial loss: 0.476316\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250553; batch adversarial loss: 0.424397\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190040; batch adversarial loss: 0.518568\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261656; batch adversarial loss: 0.387238\n",
      "epoch 25; iter: 0; batch classifier loss: 0.281291; batch adversarial loss: 0.415984\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146452; batch adversarial loss: 0.503702\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151782; batch adversarial loss: 0.431195\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153889; batch adversarial loss: 0.435114\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166788; batch adversarial loss: 0.495679\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186793; batch adversarial loss: 0.509763\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212495; batch adversarial loss: 0.471948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123840; batch adversarial loss: 0.446675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160976; batch adversarial loss: 0.481531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.138305; batch adversarial loss: 0.441867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152122; batch adversarial loss: 0.488526\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133515; batch adversarial loss: 0.473737\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159189; batch adversarial loss: 0.506024\n",
      "epoch 38; iter: 0; batch classifier loss: 0.194211; batch adversarial loss: 0.459569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173064; batch adversarial loss: 0.448503\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097589; batch adversarial loss: 0.557515\n",
      "epoch 41; iter: 0; batch classifier loss: 0.180320; batch adversarial loss: 0.469655\n",
      "epoch 42; iter: 0; batch classifier loss: 0.132133; batch adversarial loss: 0.428487\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093783; batch adversarial loss: 0.360056\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134517; batch adversarial loss: 0.412683\n",
      "epoch 45; iter: 0; batch classifier loss: 0.078809; batch adversarial loss: 0.534398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.135407; batch adversarial loss: 0.396060\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103163; batch adversarial loss: 0.487787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111954; batch adversarial loss: 0.406624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.133276; batch adversarial loss: 0.449823\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133289; batch adversarial loss: 0.530779\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133749; batch adversarial loss: 0.389962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082447; batch adversarial loss: 0.555592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109290; batch adversarial loss: 0.500819\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130071; batch adversarial loss: 0.491812\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113693; batch adversarial loss: 0.426790\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138621; batch adversarial loss: 0.492096\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098892; batch adversarial loss: 0.398149\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080761; batch adversarial loss: 0.420985\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150654; batch adversarial loss: 0.482345\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100960; batch adversarial loss: 0.461691\n",
      "epoch 61; iter: 0; batch classifier loss: 0.052968; batch adversarial loss: 0.492046\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090166; batch adversarial loss: 0.424915\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082424; batch adversarial loss: 0.414016\n",
      "epoch 64; iter: 0; batch classifier loss: 0.100002; batch adversarial loss: 0.411774\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126332; batch adversarial loss: 0.404079\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083049; batch adversarial loss: 0.443819\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101158; batch adversarial loss: 0.464923\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082239; batch adversarial loss: 0.574776\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102227; batch adversarial loss: 0.507592\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051650; batch adversarial loss: 0.442593\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073902; batch adversarial loss: 0.405937\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059865; batch adversarial loss: 0.565839\n",
      "epoch 73; iter: 0; batch classifier loss: 0.059762; batch adversarial loss: 0.453871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059429; batch adversarial loss: 0.415171\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111400; batch adversarial loss: 0.479167\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060204; batch adversarial loss: 0.530724\n",
      "epoch 77; iter: 0; batch classifier loss: 0.024971; batch adversarial loss: 0.478949\n",
      "epoch 78; iter: 0; batch classifier loss: 0.045436; batch adversarial loss: 0.459821\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050058; batch adversarial loss: 0.463059\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073997; batch adversarial loss: 0.489211\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062238; batch adversarial loss: 0.440588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.057791; batch adversarial loss: 0.477971\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080046; batch adversarial loss: 0.456863\n",
      "epoch 84; iter: 0; batch classifier loss: 0.038827; batch adversarial loss: 0.500964\n",
      "epoch 85; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.506111\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055699; batch adversarial loss: 0.492900\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040720; batch adversarial loss: 0.432568\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045930; batch adversarial loss: 0.516429\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052130; batch adversarial loss: 0.568860\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067523; batch adversarial loss: 0.432634\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066552; batch adversarial loss: 0.434642\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071565; batch adversarial loss: 0.543446\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055165; batch adversarial loss: 0.418957\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065584; batch adversarial loss: 0.537182\n",
      "epoch 95; iter: 0; batch classifier loss: 0.031632; batch adversarial loss: 0.462120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058836; batch adversarial loss: 0.375047\n",
      "epoch 97; iter: 0; batch classifier loss: 0.028992; batch adversarial loss: 0.535658\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.458764\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041969; batch adversarial loss: 0.432414\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031931; batch adversarial loss: 0.457922\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041947; batch adversarial loss: 0.430164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064653; batch adversarial loss: 0.430887\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050769; batch adversarial loss: 0.506937\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058995; batch adversarial loss: 0.473147\n",
      "epoch 105; iter: 0; batch classifier loss: 0.019685; batch adversarial loss: 0.450030\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059501; batch adversarial loss: 0.394153\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039409; batch adversarial loss: 0.419914\n",
      "epoch 108; iter: 0; batch classifier loss: 0.018967; batch adversarial loss: 0.579136\n",
      "epoch 109; iter: 0; batch classifier loss: 0.023782; batch adversarial loss: 0.505296\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049945; batch adversarial loss: 0.464458\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024460; batch adversarial loss: 0.527060\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022149; batch adversarial loss: 0.585030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.033595; batch adversarial loss: 0.457974\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042107; batch adversarial loss: 0.407814\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080953; batch adversarial loss: 0.471938\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021006; batch adversarial loss: 0.474277\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031193; batch adversarial loss: 0.373951\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022115; batch adversarial loss: 0.545491\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013200; batch adversarial loss: 0.453050\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055971; batch adversarial loss: 0.374205\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036366; batch adversarial loss: 0.552554\n",
      "epoch 122; iter: 0; batch classifier loss: 0.020967; batch adversarial loss: 0.386751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041559; batch adversarial loss: 0.325223\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024229; batch adversarial loss: 0.497214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041085; batch adversarial loss: 0.490142\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017071; batch adversarial loss: 0.540380\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028950; batch adversarial loss: 0.542260\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.442036\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026972; batch adversarial loss: 0.473910\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038876; batch adversarial loss: 0.436020\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019615; batch adversarial loss: 0.482286\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028745; batch adversarial loss: 0.410923\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025699; batch adversarial loss: 0.432567\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042325; batch adversarial loss: 0.382839\n",
      "epoch 135; iter: 0; batch classifier loss: 0.007743; batch adversarial loss: 0.478016\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017090; batch adversarial loss: 0.399798\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011331; batch adversarial loss: 0.399469\n",
      "epoch 138; iter: 0; batch classifier loss: 0.006924; batch adversarial loss: 0.393631\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053054; batch adversarial loss: 0.430695\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009717; batch adversarial loss: 0.426399\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012455; batch adversarial loss: 0.345974\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020080; batch adversarial loss: 0.410242\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049932; batch adversarial loss: 0.465249\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026075; batch adversarial loss: 0.406467\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012414; batch adversarial loss: 0.389048\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011194; batch adversarial loss: 0.478568\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020868; batch adversarial loss: 0.423498\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035712; batch adversarial loss: 0.409343\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024631; batch adversarial loss: 0.582526\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029384; batch adversarial loss: 0.489405\n",
      "epoch 151; iter: 0; batch classifier loss: 0.005870; batch adversarial loss: 0.476262\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027144; batch adversarial loss: 0.463239\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008486; batch adversarial loss: 0.447301\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012302; batch adversarial loss: 0.347628\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027003; batch adversarial loss: 0.475723\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025780; batch adversarial loss: 0.552707\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.548938\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011404; batch adversarial loss: 0.506956\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014092; batch adversarial loss: 0.482227\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006524; batch adversarial loss: 0.536830\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032162; batch adversarial loss: 0.439320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.003457; batch adversarial loss: 0.364732\n",
      "epoch 163; iter: 0; batch classifier loss: 0.002614; batch adversarial loss: 0.543053\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018329; batch adversarial loss: 0.410221\n",
      "epoch 165; iter: 0; batch classifier loss: 0.003164; batch adversarial loss: 0.510999\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007313; batch adversarial loss: 0.477729\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007455; batch adversarial loss: 0.325414\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013946; batch adversarial loss: 0.492267\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024497; batch adversarial loss: 0.493176\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009494; batch adversarial loss: 0.442261\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018123; batch adversarial loss: 0.381923\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012519; batch adversarial loss: 0.501817\n",
      "epoch 173; iter: 0; batch classifier loss: 0.001855; batch adversarial loss: 0.576291\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006642; batch adversarial loss: 0.412179\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004812; batch adversarial loss: 0.409001\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008876; batch adversarial loss: 0.497553\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006597; batch adversarial loss: 0.522526\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007666; batch adversarial loss: 0.449333\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022382; batch adversarial loss: 0.422578\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021437; batch adversarial loss: 0.500494\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007648; batch adversarial loss: 0.368714\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009543; batch adversarial loss: 0.365532\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013895; batch adversarial loss: 0.501412\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011081; batch adversarial loss: 0.524635\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008223; batch adversarial loss: 0.417369\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004164; batch adversarial loss: 0.439599\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013243; batch adversarial loss: 0.497650\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008939; batch adversarial loss: 0.431631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021735; batch adversarial loss: 0.493609\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008263; batch adversarial loss: 0.470495\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002581; batch adversarial loss: 0.444153\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008861; batch adversarial loss: 0.557453\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004611; batch adversarial loss: 0.467923\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010356; batch adversarial loss: 0.413424\n",
      "epoch 195; iter: 0; batch classifier loss: 0.002219; batch adversarial loss: 0.528929\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.427738\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013867; batch adversarial loss: 0.388373\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018650; batch adversarial loss: 0.479959\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010170; batch adversarial loss: 0.530290\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713084; batch adversarial loss: 0.693428\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461990; batch adversarial loss: 0.653069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.498042; batch adversarial loss: 0.610004\n",
      "epoch 3; iter: 0; batch classifier loss: 0.433232; batch adversarial loss: 0.603114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496517; batch adversarial loss: 0.571258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489141; batch adversarial loss: 0.554800\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375980; batch adversarial loss: 0.538483\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409116; batch adversarial loss: 0.535760\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451372; batch adversarial loss: 0.578705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.458577; batch adversarial loss: 0.526344\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405765; batch adversarial loss: 0.496755\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.524725\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351464; batch adversarial loss: 0.508510\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383515; batch adversarial loss: 0.484097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389801; batch adversarial loss: 0.469060\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363493; batch adversarial loss: 0.461024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377568; batch adversarial loss: 0.544172\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334609; batch adversarial loss: 0.478335\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281920; batch adversarial loss: 0.521098\n",
      "epoch 19; iter: 0; batch classifier loss: 0.314943; batch adversarial loss: 0.530308\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299666; batch adversarial loss: 0.489544\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373713; batch adversarial loss: 0.419039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297257; batch adversarial loss: 0.449116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.330972; batch adversarial loss: 0.522907\n",
      "epoch 24; iter: 0; batch classifier loss: 0.287889; batch adversarial loss: 0.438094\n",
      "epoch 25; iter: 0; batch classifier loss: 0.299284; batch adversarial loss: 0.480151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.269638; batch adversarial loss: 0.446850\n",
      "epoch 27; iter: 0; batch classifier loss: 0.286327; batch adversarial loss: 0.415355\n",
      "epoch 28; iter: 0; batch classifier loss: 0.305150; batch adversarial loss: 0.496759\n",
      "epoch 29; iter: 0; batch classifier loss: 0.260797; batch adversarial loss: 0.455089\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296453; batch adversarial loss: 0.481216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317339; batch adversarial loss: 0.542734\n",
      "epoch 32; iter: 0; batch classifier loss: 0.332199; batch adversarial loss: 0.392314\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260294; batch adversarial loss: 0.420001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.269879; batch adversarial loss: 0.473975\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231379; batch adversarial loss: 0.500876\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242837; batch adversarial loss: 0.518874\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273648; batch adversarial loss: 0.532497\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182612; batch adversarial loss: 0.473557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.240016; batch adversarial loss: 0.514800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.268884; batch adversarial loss: 0.411083\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248163; batch adversarial loss: 0.426485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.262725; batch adversarial loss: 0.457326\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227247; batch adversarial loss: 0.426523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193507; batch adversarial loss: 0.389741\n",
      "epoch 45; iter: 0; batch classifier loss: 0.159244; batch adversarial loss: 0.518006\n",
      "epoch 46; iter: 0; batch classifier loss: 0.249120; batch adversarial loss: 0.329032\n",
      "epoch 47; iter: 0; batch classifier loss: 0.104948; batch adversarial loss: 0.447307\n",
      "epoch 48; iter: 0; batch classifier loss: 0.251891; batch adversarial loss: 0.482989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168334; batch adversarial loss: 0.435273\n",
      "epoch 50; iter: 0; batch classifier loss: 0.238149; batch adversarial loss: 0.410479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135649; batch adversarial loss: 0.519109\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136255; batch adversarial loss: 0.407708\n",
      "epoch 53; iter: 0; batch classifier loss: 0.116490; batch adversarial loss: 0.457815\n",
      "epoch 54; iter: 0; batch classifier loss: 0.229750; batch adversarial loss: 0.412374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160058; batch adversarial loss: 0.446992\n",
      "epoch 56; iter: 0; batch classifier loss: 0.162526; batch adversarial loss: 0.457496\n",
      "epoch 57; iter: 0; batch classifier loss: 0.103104; batch adversarial loss: 0.459318\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163477; batch adversarial loss: 0.447709\n",
      "epoch 59; iter: 0; batch classifier loss: 0.265255; batch adversarial loss: 0.397559\n",
      "epoch 60; iter: 0; batch classifier loss: 0.211086; batch adversarial loss: 0.423351\n",
      "epoch 61; iter: 0; batch classifier loss: 0.159471; batch adversarial loss: 0.444972\n",
      "epoch 62; iter: 0; batch classifier loss: 0.123611; batch adversarial loss: 0.409132\n",
      "epoch 63; iter: 0; batch classifier loss: 0.210274; batch adversarial loss: 0.423778\n",
      "epoch 64; iter: 0; batch classifier loss: 0.162926; batch adversarial loss: 0.436135\n",
      "epoch 65; iter: 0; batch classifier loss: 0.159118; batch adversarial loss: 0.409354\n",
      "epoch 66; iter: 0; batch classifier loss: 0.183785; batch adversarial loss: 0.421215\n",
      "epoch 67; iter: 0; batch classifier loss: 0.242358; batch adversarial loss: 0.432000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.135786; batch adversarial loss: 0.447278\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146551; batch adversarial loss: 0.343483\n",
      "epoch 70; iter: 0; batch classifier loss: 0.161894; batch adversarial loss: 0.344839\n",
      "epoch 71; iter: 0; batch classifier loss: 0.187299; batch adversarial loss: 0.547969\n",
      "epoch 72; iter: 0; batch classifier loss: 0.231041; batch adversarial loss: 0.382648\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086257; batch adversarial loss: 0.458597\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102296; batch adversarial loss: 0.394044\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141764; batch adversarial loss: 0.356874\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132911; batch adversarial loss: 0.451091\n",
      "epoch 77; iter: 0; batch classifier loss: 0.177423; batch adversarial loss: 0.368888\n",
      "epoch 78; iter: 0; batch classifier loss: 0.210562; batch adversarial loss: 0.459859\n",
      "epoch 79; iter: 0; batch classifier loss: 0.167603; batch adversarial loss: 0.456844\n",
      "epoch 80; iter: 0; batch classifier loss: 0.177485; batch adversarial loss: 0.411349\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090556; batch adversarial loss: 0.472917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076821; batch adversarial loss: 0.445300\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085888; batch adversarial loss: 0.352576\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068836; batch adversarial loss: 0.410428\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059158; batch adversarial loss: 0.421867\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062720; batch adversarial loss: 0.446388\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067894; batch adversarial loss: 0.464551\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079621; batch adversarial loss: 0.467335\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054525; batch adversarial loss: 0.489763\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075357; batch adversarial loss: 0.427039\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046106; batch adversarial loss: 0.445999\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062783; batch adversarial loss: 0.427452\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051407; batch adversarial loss: 0.513807\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050097; batch adversarial loss: 0.514078\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090228; batch adversarial loss: 0.474830\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037775; batch adversarial loss: 0.353136\n",
      "epoch 97; iter: 0; batch classifier loss: 0.031210; batch adversarial loss: 0.453180\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.421692\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046428; batch adversarial loss: 0.458824\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036088; batch adversarial loss: 0.433120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.019004; batch adversarial loss: 0.410169\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041493; batch adversarial loss: 0.462482\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063593; batch adversarial loss: 0.394413\n",
      "epoch 104; iter: 0; batch classifier loss: 0.010945; batch adversarial loss: 0.484894\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028063; batch adversarial loss: 0.420855\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037166; batch adversarial loss: 0.443359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.045037; batch adversarial loss: 0.357084\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055356; batch adversarial loss: 0.441477\n",
      "epoch 109; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.431917\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015245; batch adversarial loss: 0.470431\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034510; batch adversarial loss: 0.467439\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063616; batch adversarial loss: 0.450634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019163; batch adversarial loss: 0.456023\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046390; batch adversarial loss: 0.491906\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053307; batch adversarial loss: 0.390741\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038408; batch adversarial loss: 0.318086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038371; batch adversarial loss: 0.469312\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025559; batch adversarial loss: 0.481560\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018555; batch adversarial loss: 0.484745\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031183; batch adversarial loss: 0.453729\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027009; batch adversarial loss: 0.420771\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037283; batch adversarial loss: 0.404488\n",
      "epoch 123; iter: 0; batch classifier loss: 0.013140; batch adversarial loss: 0.448550\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014373; batch adversarial loss: 0.442059\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023123; batch adversarial loss: 0.424866\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025712; batch adversarial loss: 0.488497\n",
      "epoch 127; iter: 0; batch classifier loss: 0.008580; batch adversarial loss: 0.458683\n",
      "epoch 128; iter: 0; batch classifier loss: 0.012700; batch adversarial loss: 0.363362\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032447; batch adversarial loss: 0.454740\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016827; batch adversarial loss: 0.494189\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030858; batch adversarial loss: 0.472003\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.475613\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019373; batch adversarial loss: 0.382139\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035572; batch adversarial loss: 0.462329\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018634; batch adversarial loss: 0.412130\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016011; batch adversarial loss: 0.492507\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026402; batch adversarial loss: 0.408165\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.475683\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028560; batch adversarial loss: 0.435888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020733; batch adversarial loss: 0.445171\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026567; batch adversarial loss: 0.450455\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039063; batch adversarial loss: 0.487380\n",
      "epoch 143; iter: 0; batch classifier loss: 0.008428; batch adversarial loss: 0.509393\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034065; batch adversarial loss: 0.523643\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010697; batch adversarial loss: 0.488801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026099; batch adversarial loss: 0.413826\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031769; batch adversarial loss: 0.469659\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012337; batch adversarial loss: 0.509188\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013739; batch adversarial loss: 0.417228\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023089; batch adversarial loss: 0.432516\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006746; batch adversarial loss: 0.414513\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032964; batch adversarial loss: 0.500349\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028958; batch adversarial loss: 0.429005\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012506; batch adversarial loss: 0.416273\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013410; batch adversarial loss: 0.535470\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011166; batch adversarial loss: 0.439479\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.436132\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021906; batch adversarial loss: 0.392566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018894; batch adversarial loss: 0.477619\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025961; batch adversarial loss: 0.464881\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006641; batch adversarial loss: 0.414562\n",
      "epoch 162; iter: 0; batch classifier loss: 0.005879; batch adversarial loss: 0.434937\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017202; batch adversarial loss: 0.452173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027500; batch adversarial loss: 0.581986\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032912; batch adversarial loss: 0.484544\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005456; batch adversarial loss: 0.427669\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009996; batch adversarial loss: 0.487837\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008939; batch adversarial loss: 0.447356\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004677; batch adversarial loss: 0.405804\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016625; batch adversarial loss: 0.361238\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008306; batch adversarial loss: 0.443903\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012227; batch adversarial loss: 0.484639\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023194; batch adversarial loss: 0.577434\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013823; batch adversarial loss: 0.551701\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012068; batch adversarial loss: 0.478960\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013253; batch adversarial loss: 0.428923\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023298; batch adversarial loss: 0.386879\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015979; batch adversarial loss: 0.486377\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024060; batch adversarial loss: 0.367595\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016896; batch adversarial loss: 0.454292\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008268; batch adversarial loss: 0.527490\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046609; batch adversarial loss: 0.311779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004148; batch adversarial loss: 0.398164\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010181; batch adversarial loss: 0.402261\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023555; batch adversarial loss: 0.473945\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025457; batch adversarial loss: 0.442603\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043750; batch adversarial loss: 0.502778\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012657; batch adversarial loss: 0.428126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009879; batch adversarial loss: 0.522796\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012352; batch adversarial loss: 0.493964\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003850; batch adversarial loss: 0.473162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021284; batch adversarial loss: 0.428868\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014348; batch adversarial loss: 0.386324\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013618; batch adversarial loss: 0.403737\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003328; batch adversarial loss: 0.296400\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021574; batch adversarial loss: 0.437810\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005751; batch adversarial loss: 0.446202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005971; batch adversarial loss: 0.474392\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012604; batch adversarial loss: 0.431131\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720256; batch adversarial loss: 0.779197\n",
      "epoch 1; iter: 0; batch classifier loss: 0.600886; batch adversarial loss: 0.764582\n",
      "epoch 2; iter: 0; batch classifier loss: 0.721140; batch adversarial loss: 0.731778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.610463; batch adversarial loss: 0.653188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498229; batch adversarial loss: 0.602874\n",
      "epoch 5; iter: 0; batch classifier loss: 0.425749; batch adversarial loss: 0.597709\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395321; batch adversarial loss: 0.567431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433537; batch adversarial loss: 0.550921\n",
      "epoch 8; iter: 0; batch classifier loss: 0.290241; batch adversarial loss: 0.538232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329892; batch adversarial loss: 0.518989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.323072; batch adversarial loss: 0.482569\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274430; batch adversarial loss: 0.512202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.392781; batch adversarial loss: 0.459360\n",
      "epoch 13; iter: 0; batch classifier loss: 0.365948; batch adversarial loss: 0.490184\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345105; batch adversarial loss: 0.490493\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264775; batch adversarial loss: 0.513322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244656; batch adversarial loss: 0.441842\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189702; batch adversarial loss: 0.574374\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236131; batch adversarial loss: 0.434639\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247107; batch adversarial loss: 0.487833\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253200; batch adversarial loss: 0.493007\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291655; batch adversarial loss: 0.505912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229254; batch adversarial loss: 0.427285\n",
      "epoch 23; iter: 0; batch classifier loss: 0.267652; batch adversarial loss: 0.511435\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214424; batch adversarial loss: 0.425710\n",
      "epoch 25; iter: 0; batch classifier loss: 0.238193; batch adversarial loss: 0.410914\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262564; batch adversarial loss: 0.476973\n",
      "epoch 27; iter: 0; batch classifier loss: 0.197483; batch adversarial loss: 0.466086\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194369; batch adversarial loss: 0.450340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212385; batch adversarial loss: 0.494920\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159148; batch adversarial loss: 0.430295\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195713; batch adversarial loss: 0.545994\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265233; batch adversarial loss: 0.520279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235593; batch adversarial loss: 0.448433\n",
      "epoch 34; iter: 0; batch classifier loss: 0.207248; batch adversarial loss: 0.454527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.292013; batch adversarial loss: 0.517929\n",
      "epoch 36; iter: 0; batch classifier loss: 0.208202; batch adversarial loss: 0.404667\n",
      "epoch 37; iter: 0; batch classifier loss: 0.212075; batch adversarial loss: 0.458868\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186159; batch adversarial loss: 0.466850\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227877; batch adversarial loss: 0.419435\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158552; batch adversarial loss: 0.559001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.186253; batch adversarial loss: 0.484765\n",
      "epoch 42; iter: 0; batch classifier loss: 0.171925; batch adversarial loss: 0.410413\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227452; batch adversarial loss: 0.426704\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202216; batch adversarial loss: 0.510616\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213471; batch adversarial loss: 0.468435\n",
      "epoch 46; iter: 0; batch classifier loss: 0.165954; batch adversarial loss: 0.455595\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185433; batch adversarial loss: 0.489986\n",
      "epoch 48; iter: 0; batch classifier loss: 0.282638; batch adversarial loss: 0.371352\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246464; batch adversarial loss: 0.455795\n",
      "epoch 50; iter: 0; batch classifier loss: 0.198470; batch adversarial loss: 0.473564\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231949; batch adversarial loss: 0.431684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.179485; batch adversarial loss: 0.474312\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232537; batch adversarial loss: 0.374350\n",
      "epoch 54; iter: 0; batch classifier loss: 0.233788; batch adversarial loss: 0.373363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.171696; batch adversarial loss: 0.540712\n",
      "epoch 56; iter: 0; batch classifier loss: 0.154185; batch adversarial loss: 0.459840\n",
      "epoch 57; iter: 0; batch classifier loss: 0.205404; batch adversarial loss: 0.468613\n",
      "epoch 58; iter: 0; batch classifier loss: 0.255899; batch adversarial loss: 0.506708\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160764; batch adversarial loss: 0.520281\n",
      "epoch 60; iter: 0; batch classifier loss: 0.230942; batch adversarial loss: 0.464610\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175408; batch adversarial loss: 0.509765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.188090; batch adversarial loss: 0.433781\n",
      "epoch 63; iter: 0; batch classifier loss: 0.164791; batch adversarial loss: 0.510105\n",
      "epoch 64; iter: 0; batch classifier loss: 0.203377; batch adversarial loss: 0.468573\n",
      "epoch 65; iter: 0; batch classifier loss: 0.216945; batch adversarial loss: 0.411214\n",
      "epoch 66; iter: 0; batch classifier loss: 0.175500; batch adversarial loss: 0.522469\n",
      "epoch 67; iter: 0; batch classifier loss: 0.185274; batch adversarial loss: 0.510061\n",
      "epoch 68; iter: 0; batch classifier loss: 0.209720; batch adversarial loss: 0.322481\n",
      "epoch 69; iter: 0; batch classifier loss: 0.230104; batch adversarial loss: 0.470434\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210344; batch adversarial loss: 0.532539\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222369; batch adversarial loss: 0.385252\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171789; batch adversarial loss: 0.421172\n",
      "epoch 73; iter: 0; batch classifier loss: 0.208504; batch adversarial loss: 0.559545\n",
      "epoch 74; iter: 0; batch classifier loss: 0.230785; batch adversarial loss: 0.396256\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195029; batch adversarial loss: 0.372273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.212837; batch adversarial loss: 0.421438\n",
      "epoch 77; iter: 0; batch classifier loss: 0.201715; batch adversarial loss: 0.310711\n",
      "epoch 78; iter: 0; batch classifier loss: 0.291880; batch adversarial loss: 0.422315\n",
      "epoch 79; iter: 0; batch classifier loss: 0.245508; batch adversarial loss: 0.409714\n",
      "epoch 80; iter: 0; batch classifier loss: 0.189574; batch adversarial loss: 0.384347\n",
      "epoch 81; iter: 0; batch classifier loss: 0.131543; batch adversarial loss: 0.520752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.248555; batch adversarial loss: 0.396852\n",
      "epoch 83; iter: 0; batch classifier loss: 0.191053; batch adversarial loss: 0.458365\n",
      "epoch 84; iter: 0; batch classifier loss: 0.208569; batch adversarial loss: 0.471159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.192820; batch adversarial loss: 0.532501\n",
      "epoch 86; iter: 0; batch classifier loss: 0.252571; batch adversarial loss: 0.372395\n",
      "epoch 87; iter: 0; batch classifier loss: 0.229022; batch adversarial loss: 0.409867\n",
      "epoch 88; iter: 0; batch classifier loss: 0.202775; batch adversarial loss: 0.421758\n",
      "epoch 89; iter: 0; batch classifier loss: 0.194362; batch adversarial loss: 0.458897\n",
      "epoch 90; iter: 0; batch classifier loss: 0.202812; batch adversarial loss: 0.396432\n",
      "epoch 91; iter: 0; batch classifier loss: 0.199821; batch adversarial loss: 0.471626\n",
      "epoch 92; iter: 0; batch classifier loss: 0.201511; batch adversarial loss: 0.396395\n",
      "epoch 93; iter: 0; batch classifier loss: 0.190127; batch adversarial loss: 0.556680\n",
      "epoch 94; iter: 0; batch classifier loss: 0.178633; batch adversarial loss: 0.559051\n",
      "epoch 95; iter: 0; batch classifier loss: 0.167316; batch adversarial loss: 0.434387\n",
      "epoch 96; iter: 0; batch classifier loss: 0.118013; batch adversarial loss: 0.393783\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097385; batch adversarial loss: 0.517536\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088177; batch adversarial loss: 0.409928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092427; batch adversarial loss: 0.456493\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075107; batch adversarial loss: 0.402461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.087530; batch adversarial loss: 0.328207\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089073; batch adversarial loss: 0.452522\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091838; batch adversarial loss: 0.495670\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068518; batch adversarial loss: 0.390281\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076956; batch adversarial loss: 0.478390\n",
      "epoch 106; iter: 0; batch classifier loss: 0.125481; batch adversarial loss: 0.405199\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073128; batch adversarial loss: 0.536463\n",
      "epoch 108; iter: 0; batch classifier loss: 0.133028; batch adversarial loss: 0.487946\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055962; batch adversarial loss: 0.366335\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079200; batch adversarial loss: 0.496036\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052623; batch adversarial loss: 0.411267\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057446; batch adversarial loss: 0.379060\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081285; batch adversarial loss: 0.411139\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056798; batch adversarial loss: 0.550395\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038734; batch adversarial loss: 0.465449\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049168; batch adversarial loss: 0.502110\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066323; batch adversarial loss: 0.383980\n",
      "epoch 118; iter: 0; batch classifier loss: 0.083642; batch adversarial loss: 0.426479\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071336; batch adversarial loss: 0.432138\n",
      "epoch 120; iter: 0; batch classifier loss: 0.107153; batch adversarial loss: 0.372373\n",
      "epoch 121; iter: 0; batch classifier loss: 0.130964; batch adversarial loss: 0.374669\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062093; batch adversarial loss: 0.448733\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061693; batch adversarial loss: 0.375575\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046133; batch adversarial loss: 0.460506\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069466; batch adversarial loss: 0.416747\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059458; batch adversarial loss: 0.459825\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056366; batch adversarial loss: 0.472148\n",
      "epoch 128; iter: 0; batch classifier loss: 0.078218; batch adversarial loss: 0.420694\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040966; batch adversarial loss: 0.436513\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067111; batch adversarial loss: 0.464732\n",
      "epoch 131; iter: 0; batch classifier loss: 0.074072; batch adversarial loss: 0.463161\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061132; batch adversarial loss: 0.472349\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.522968\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046167; batch adversarial loss: 0.411441\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048841; batch adversarial loss: 0.497517\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038224; batch adversarial loss: 0.476149\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036889; batch adversarial loss: 0.456741\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056908; batch adversarial loss: 0.362895\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068976; batch adversarial loss: 0.436276\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039088; batch adversarial loss: 0.453528\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052432; batch adversarial loss: 0.341546\n",
      "epoch 142; iter: 0; batch classifier loss: 0.061508; batch adversarial loss: 0.444131\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025845; batch adversarial loss: 0.436441\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060652; batch adversarial loss: 0.483622\n",
      "epoch 145; iter: 0; batch classifier loss: 0.070242; batch adversarial loss: 0.453540\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052189; batch adversarial loss: 0.471786\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054698; batch adversarial loss: 0.494172\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059550; batch adversarial loss: 0.422098\n",
      "epoch 149; iter: 0; batch classifier loss: 0.073809; batch adversarial loss: 0.419615\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061689; batch adversarial loss: 0.426154\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059906; batch adversarial loss: 0.401643\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058296; batch adversarial loss: 0.475182\n",
      "epoch 153; iter: 0; batch classifier loss: 0.065998; batch adversarial loss: 0.448226\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036093; batch adversarial loss: 0.386726\n",
      "epoch 155; iter: 0; batch classifier loss: 0.076782; batch adversarial loss: 0.503993\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045019; batch adversarial loss: 0.459612\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053926; batch adversarial loss: 0.386585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037732; batch adversarial loss: 0.474763\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039599; batch adversarial loss: 0.464992\n",
      "epoch 160; iter: 0; batch classifier loss: 0.064687; batch adversarial loss: 0.484959\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053436; batch adversarial loss: 0.328114\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029060; batch adversarial loss: 0.486327\n",
      "epoch 163; iter: 0; batch classifier loss: 0.048526; batch adversarial loss: 0.453326\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.467862\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044931; batch adversarial loss: 0.398767\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034292; batch adversarial loss: 0.392861\n",
      "epoch 167; iter: 0; batch classifier loss: 0.060391; batch adversarial loss: 0.442535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.065470; batch adversarial loss: 0.436409\n",
      "epoch 169; iter: 0; batch classifier loss: 0.074394; batch adversarial loss: 0.393298\n",
      "epoch 170; iter: 0; batch classifier loss: 0.075386; batch adversarial loss: 0.462117\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039073; batch adversarial loss: 0.400219\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025643; batch adversarial loss: 0.384164\n",
      "epoch 173; iter: 0; batch classifier loss: 0.074222; batch adversarial loss: 0.394204\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039364; batch adversarial loss: 0.495564\n",
      "epoch 175; iter: 0; batch classifier loss: 0.054380; batch adversarial loss: 0.377647\n",
      "epoch 176; iter: 0; batch classifier loss: 0.056217; batch adversarial loss: 0.478530\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050273; batch adversarial loss: 0.464858\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034855; batch adversarial loss: 0.453867\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040038; batch adversarial loss: 0.391588\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044403; batch adversarial loss: 0.406049\n",
      "epoch 181; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.319506\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042067; batch adversarial loss: 0.476534\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.444499\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045531; batch adversarial loss: 0.369058\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037438; batch adversarial loss: 0.399663\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050323; batch adversarial loss: 0.419472\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.440143\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036747; batch adversarial loss: 0.341736\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023710; batch adversarial loss: 0.611311\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025377; batch adversarial loss: 0.525560\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036244; batch adversarial loss: 0.498765\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031215; batch adversarial loss: 0.384968\n",
      "epoch 193; iter: 0; batch classifier loss: 0.054553; batch adversarial loss: 0.433858\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040491; batch adversarial loss: 0.529459\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037680; batch adversarial loss: 0.356959\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033726; batch adversarial loss: 0.458730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.397200\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041853; batch adversarial loss: 0.362049\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034295; batch adversarial loss: 0.390913\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697157; batch adversarial loss: 0.527074\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395711; batch adversarial loss: 0.577110\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361251; batch adversarial loss: 0.532393\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340738; batch adversarial loss: 0.578028\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378516; batch adversarial loss: 0.556773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365274; batch adversarial loss: 0.534060\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357269; batch adversarial loss: 0.521053\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294477; batch adversarial loss: 0.604907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394815; batch adversarial loss: 0.568201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402896; batch adversarial loss: 0.642851\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466008; batch adversarial loss: 0.581008\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471308; batch adversarial loss: 0.560316\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512970; batch adversarial loss: 0.519259\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453470; batch adversarial loss: 0.539502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356459; batch adversarial loss: 0.514716\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321339; batch adversarial loss: 0.442394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249229; batch adversarial loss: 0.430922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.245784; batch adversarial loss: 0.540997\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246640; batch adversarial loss: 0.506104\n",
      "epoch 19; iter: 0; batch classifier loss: 0.158782; batch adversarial loss: 0.441749\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172005; batch adversarial loss: 0.486728\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163725; batch adversarial loss: 0.407848\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183299; batch adversarial loss: 0.405495\n",
      "epoch 23; iter: 0; batch classifier loss: 0.199519; batch adversarial loss: 0.474108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213842; batch adversarial loss: 0.478060\n",
      "epoch 25; iter: 0; batch classifier loss: 0.170119; batch adversarial loss: 0.434011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.127144; batch adversarial loss: 0.344897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131743; batch adversarial loss: 0.355506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167988; batch adversarial loss: 0.370779\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135075; batch adversarial loss: 0.477599\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111358; batch adversarial loss: 0.398186\n",
      "epoch 31; iter: 0; batch classifier loss: 0.117713; batch adversarial loss: 0.388308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166484; batch adversarial loss: 0.390494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172900; batch adversarial loss: 0.429439\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157333; batch adversarial loss: 0.482456\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125018; batch adversarial loss: 0.472434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163629; batch adversarial loss: 0.369715\n",
      "epoch 37; iter: 0; batch classifier loss: 0.161311; batch adversarial loss: 0.393833\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159098; batch adversarial loss: 0.435409\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143932; batch adversarial loss: 0.416035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145454; batch adversarial loss: 0.497363\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144936; batch adversarial loss: 0.479010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131000; batch adversarial loss: 0.429352\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145151; batch adversarial loss: 0.439866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140334; batch adversarial loss: 0.446653\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166207; batch adversarial loss: 0.463271\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132075; batch adversarial loss: 0.389865\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152257; batch adversarial loss: 0.389555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117434; batch adversarial loss: 0.424138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119512; batch adversarial loss: 0.446255\n",
      "epoch 50; iter: 0; batch classifier loss: 0.121060; batch adversarial loss: 0.394731\n",
      "epoch 51; iter: 0; batch classifier loss: 0.154380; batch adversarial loss: 0.473548\n",
      "epoch 52; iter: 0; batch classifier loss: 0.217695; batch adversarial loss: 0.367654\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104833; batch adversarial loss: 0.442317\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136042; batch adversarial loss: 0.478421\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110092; batch adversarial loss: 0.478537\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167140; batch adversarial loss: 0.369014\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090768; batch adversarial loss: 0.452629\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082384; batch adversarial loss: 0.468901\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118021; batch adversarial loss: 0.478271\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082763; batch adversarial loss: 0.504380\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127820; batch adversarial loss: 0.420622\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067013; batch adversarial loss: 0.380026\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120970; batch adversarial loss: 0.494196\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089417; batch adversarial loss: 0.422238\n",
      "epoch 65; iter: 0; batch classifier loss: 0.148602; batch adversarial loss: 0.434248\n",
      "epoch 66; iter: 0; batch classifier loss: 0.111747; batch adversarial loss: 0.508295\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079839; batch adversarial loss: 0.524574\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088580; batch adversarial loss: 0.433665\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129464; batch adversarial loss: 0.464901\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133932; batch adversarial loss: 0.506916\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111616; batch adversarial loss: 0.542363\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159719; batch adversarial loss: 0.438416\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148095; batch adversarial loss: 0.418555\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130271; batch adversarial loss: 0.431783\n",
      "epoch 75; iter: 0; batch classifier loss: 0.242838; batch adversarial loss: 0.495002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.155232; batch adversarial loss: 0.407594\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111440; batch adversarial loss: 0.480045\n",
      "epoch 78; iter: 0; batch classifier loss: 0.142806; batch adversarial loss: 0.479487\n",
      "epoch 79; iter: 0; batch classifier loss: 0.117786; batch adversarial loss: 0.510205\n",
      "epoch 80; iter: 0; batch classifier loss: 0.152754; batch adversarial loss: 0.486878\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096922; batch adversarial loss: 0.460331\n",
      "epoch 82; iter: 0; batch classifier loss: 0.166381; batch adversarial loss: 0.518386\n",
      "epoch 83; iter: 0; batch classifier loss: 0.096148; batch adversarial loss: 0.404423\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172139; batch adversarial loss: 0.406707\n",
      "epoch 85; iter: 0; batch classifier loss: 0.151271; batch adversarial loss: 0.462212\n",
      "epoch 86; iter: 0; batch classifier loss: 0.149938; batch adversarial loss: 0.418387\n",
      "epoch 87; iter: 0; batch classifier loss: 0.130666; batch adversarial loss: 0.457986\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125786; batch adversarial loss: 0.405676\n",
      "epoch 89; iter: 0; batch classifier loss: 0.104047; batch adversarial loss: 0.487064\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078045; batch adversarial loss: 0.388045\n",
      "epoch 91; iter: 0; batch classifier loss: 0.149845; batch adversarial loss: 0.420511\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091115; batch adversarial loss: 0.385933\n",
      "epoch 93; iter: 0; batch classifier loss: 0.142751; batch adversarial loss: 0.413770\n",
      "epoch 94; iter: 0; batch classifier loss: 0.101074; batch adversarial loss: 0.484909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.094257; batch adversarial loss: 0.342153\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083779; batch adversarial loss: 0.455160\n",
      "epoch 97; iter: 0; batch classifier loss: 0.109567; batch adversarial loss: 0.513464\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090557; batch adversarial loss: 0.480949\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107858; batch adversarial loss: 0.431067\n",
      "epoch 100; iter: 0; batch classifier loss: 0.117683; batch adversarial loss: 0.470899\n",
      "epoch 101; iter: 0; batch classifier loss: 0.088388; batch adversarial loss: 0.373531\n",
      "epoch 102; iter: 0; batch classifier loss: 0.095817; batch adversarial loss: 0.482797\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085795; batch adversarial loss: 0.417006\n",
      "epoch 104; iter: 0; batch classifier loss: 0.113031; batch adversarial loss: 0.592251\n",
      "epoch 105; iter: 0; batch classifier loss: 0.103479; batch adversarial loss: 0.417330\n",
      "epoch 106; iter: 0; batch classifier loss: 0.085291; batch adversarial loss: 0.451176\n",
      "epoch 107; iter: 0; batch classifier loss: 0.096503; batch adversarial loss: 0.420916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039045; batch adversarial loss: 0.466844\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026456; batch adversarial loss: 0.514218\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067571; batch adversarial loss: 0.439105\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073389; batch adversarial loss: 0.525901\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059954; batch adversarial loss: 0.479046\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056749; batch adversarial loss: 0.489559\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076083; batch adversarial loss: 0.479945\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070347; batch adversarial loss: 0.443945\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056966; batch adversarial loss: 0.521666\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054608; batch adversarial loss: 0.411919\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069601; batch adversarial loss: 0.442961\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043768; batch adversarial loss: 0.485101\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035466; batch adversarial loss: 0.374088\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033431; batch adversarial loss: 0.435128\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035968; batch adversarial loss: 0.418391\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036257; batch adversarial loss: 0.446388\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046251; batch adversarial loss: 0.461503\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061752; batch adversarial loss: 0.481913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045763; batch adversarial loss: 0.508244\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029239; batch adversarial loss: 0.497435\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028476; batch adversarial loss: 0.490581\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022651; batch adversarial loss: 0.390556\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025590; batch adversarial loss: 0.445799\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032634; batch adversarial loss: 0.405050\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020906; batch adversarial loss: 0.390366\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022372; batch adversarial loss: 0.372648\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042688; batch adversarial loss: 0.420580\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.406741\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028243; batch adversarial loss: 0.444468\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033395; batch adversarial loss: 0.366215\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023017; batch adversarial loss: 0.457697\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046301; batch adversarial loss: 0.380575\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057264; batch adversarial loss: 0.477870\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028242; batch adversarial loss: 0.471590\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044081; batch adversarial loss: 0.449724\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032993; batch adversarial loss: 0.460203\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017835; batch adversarial loss: 0.343523\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044820; batch adversarial loss: 0.471246\n",
      "epoch 146; iter: 0; batch classifier loss: 0.070748; batch adversarial loss: 0.537302\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030941; batch adversarial loss: 0.379399\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072349; batch adversarial loss: 0.434351\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022031; batch adversarial loss: 0.334371\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050760; batch adversarial loss: 0.446912\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.410679\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031677; batch adversarial loss: 0.420174\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036799; batch adversarial loss: 0.470041\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011056; batch adversarial loss: 0.492819\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018661; batch adversarial loss: 0.461466\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046532; batch adversarial loss: 0.442892\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010045; batch adversarial loss: 0.378500\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014928; batch adversarial loss: 0.425135\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017343; batch adversarial loss: 0.404913\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018310; batch adversarial loss: 0.461650\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028178; batch adversarial loss: 0.374418\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031677; batch adversarial loss: 0.493911\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015187; batch adversarial loss: 0.451169\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046149; batch adversarial loss: 0.451853\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030564; batch adversarial loss: 0.442590\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015199; batch adversarial loss: 0.497132\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.561523\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012398; batch adversarial loss: 0.460168\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022580; batch adversarial loss: 0.496334\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039041; batch adversarial loss: 0.441403\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035318; batch adversarial loss: 0.412971\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013365; batch adversarial loss: 0.566171\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022462; batch adversarial loss: 0.450307\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046314; batch adversarial loss: 0.405968\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009414; batch adversarial loss: 0.412934\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016140; batch adversarial loss: 0.492243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.063652; batch adversarial loss: 0.376232\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012356; batch adversarial loss: 0.452039\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.501808\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010997; batch adversarial loss: 0.457419\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027719; batch adversarial loss: 0.473178\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010777; batch adversarial loss: 0.469339\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008971; batch adversarial loss: 0.497280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031515; batch adversarial loss: 0.472673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011859; batch adversarial loss: 0.465937\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006014; batch adversarial loss: 0.455840\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006790; batch adversarial loss: 0.424452\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022030; batch adversarial loss: 0.396143\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014009; batch adversarial loss: 0.436670\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029667; batch adversarial loss: 0.423398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.010555; batch adversarial loss: 0.474446\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011307; batch adversarial loss: 0.424704\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007963; batch adversarial loss: 0.449072\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039840; batch adversarial loss: 0.348100\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024890; batch adversarial loss: 0.401294\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012894; batch adversarial loss: 0.495659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019271; batch adversarial loss: 0.472692\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.401457\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024381; batch adversarial loss: 0.484749\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673349; batch adversarial loss: 1.025735\n",
      "epoch 1; iter: 0; batch classifier loss: 0.609133; batch adversarial loss: 1.235218\n",
      "epoch 2; iter: 0; batch classifier loss: 0.840615; batch adversarial loss: 1.292246\n",
      "epoch 3; iter: 0; batch classifier loss: 1.003122; batch adversarial loss: 1.210405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.959000; batch adversarial loss: 1.095604\n",
      "epoch 5; iter: 0; batch classifier loss: 1.133548; batch adversarial loss: 0.999092\n",
      "epoch 6; iter: 0; batch classifier loss: 1.197058; batch adversarial loss: 0.905360\n",
      "epoch 7; iter: 0; batch classifier loss: 1.021396; batch adversarial loss: 0.835144\n",
      "epoch 8; iter: 0; batch classifier loss: 0.915209; batch adversarial loss: 0.774821\n",
      "epoch 9; iter: 0; batch classifier loss: 1.015626; batch adversarial loss: 0.706179\n",
      "epoch 10; iter: 0; batch classifier loss: 0.930509; batch adversarial loss: 0.640751\n",
      "epoch 11; iter: 0; batch classifier loss: 0.886485; batch adversarial loss: 0.606292\n",
      "epoch 12; iter: 0; batch classifier loss: 0.923759; batch adversarial loss: 0.548653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.718450; batch adversarial loss: 0.574827\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402152; batch adversarial loss: 0.538954\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365138; batch adversarial loss: 0.481356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265127; batch adversarial loss: 0.522073\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334155; batch adversarial loss: 0.443509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220142; batch adversarial loss: 0.474566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.215010; batch adversarial loss: 0.541735\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163899; batch adversarial loss: 0.470912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162462; batch adversarial loss: 0.537733\n",
      "epoch 22; iter: 0; batch classifier loss: 0.111411; batch adversarial loss: 0.455234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.181173; batch adversarial loss: 0.385753\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273822; batch adversarial loss: 0.402015\n",
      "epoch 25; iter: 0; batch classifier loss: 0.115347; batch adversarial loss: 0.499623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117950; batch adversarial loss: 0.498092\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147936; batch adversarial loss: 0.478687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170098; batch adversarial loss: 0.459292\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126168; batch adversarial loss: 0.478580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.102440; batch adversarial loss: 0.449489\n",
      "epoch 31; iter: 0; batch classifier loss: 0.077534; batch adversarial loss: 0.496579\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149569; batch adversarial loss: 0.391651\n",
      "epoch 33; iter: 0; batch classifier loss: 0.068423; batch adversarial loss: 0.473883\n",
      "epoch 34; iter: 0; batch classifier loss: 0.076194; batch adversarial loss: 0.536000\n",
      "epoch 35; iter: 0; batch classifier loss: 0.090446; batch adversarial loss: 0.438544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.089109; batch adversarial loss: 0.444991\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119810; batch adversarial loss: 0.449780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129906; batch adversarial loss: 0.510557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111427; batch adversarial loss: 0.496337\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104761; batch adversarial loss: 0.544226\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076847; batch adversarial loss: 0.469000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133936; batch adversarial loss: 0.428554\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136239; batch adversarial loss: 0.451941\n",
      "epoch 44; iter: 0; batch classifier loss: 0.155987; batch adversarial loss: 0.404708\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118090; batch adversarial loss: 0.355255\n",
      "epoch 46; iter: 0; batch classifier loss: 0.208364; batch adversarial loss: 0.472990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.152480; batch adversarial loss: 0.402555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138187; batch adversarial loss: 0.437569\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091880; batch adversarial loss: 0.458185\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080678; batch adversarial loss: 0.452923\n",
      "epoch 51; iter: 0; batch classifier loss: 0.171564; batch adversarial loss: 0.393065\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119434; batch adversarial loss: 0.442105\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089664; batch adversarial loss: 0.365758\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080514; batch adversarial loss: 0.476869\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092200; batch adversarial loss: 0.506896\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095067; batch adversarial loss: 0.449653\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090353; batch adversarial loss: 0.448440\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097361; batch adversarial loss: 0.400244\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076271; batch adversarial loss: 0.553585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087560; batch adversarial loss: 0.494057\n",
      "epoch 61; iter: 0; batch classifier loss: 0.107989; batch adversarial loss: 0.417019\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085662; batch adversarial loss: 0.479676\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059795; batch adversarial loss: 0.450315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057516; batch adversarial loss: 0.366804\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084419; batch adversarial loss: 0.528057\n",
      "epoch 66; iter: 0; batch classifier loss: 0.059013; batch adversarial loss: 0.419351\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095478; batch adversarial loss: 0.464918\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057455; batch adversarial loss: 0.468757\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076710; batch adversarial loss: 0.337904\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095766; batch adversarial loss: 0.337740\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052780; batch adversarial loss: 0.398791\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065920; batch adversarial loss: 0.422873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.054748; batch adversarial loss: 0.373565\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047761; batch adversarial loss: 0.519734\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072828; batch adversarial loss: 0.486569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058166; batch adversarial loss: 0.414039\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051349; batch adversarial loss: 0.499644\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067844; batch adversarial loss: 0.492077\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089553; batch adversarial loss: 0.569532\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054859; batch adversarial loss: 0.447441\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055189; batch adversarial loss: 0.461255\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066429; batch adversarial loss: 0.389438\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061236; batch adversarial loss: 0.488561\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119976; batch adversarial loss: 0.559993\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046943; batch adversarial loss: 0.450626\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082152; batch adversarial loss: 0.534445\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066095; batch adversarial loss: 0.379679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.051887; batch adversarial loss: 0.437916\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058829; batch adversarial loss: 0.423244\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076770; batch adversarial loss: 0.455620\n",
      "epoch 91; iter: 0; batch classifier loss: 0.037189; batch adversarial loss: 0.441730\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047086; batch adversarial loss: 0.542474\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042975; batch adversarial loss: 0.401442\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056247; batch adversarial loss: 0.484722\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080686; batch adversarial loss: 0.476413\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039166; batch adversarial loss: 0.489676\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089078; batch adversarial loss: 0.375606\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050774; batch adversarial loss: 0.453434\n",
      "epoch 99; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.401176\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088556; batch adversarial loss: 0.377496\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044594; batch adversarial loss: 0.439443\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043942; batch adversarial loss: 0.493340\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040072; batch adversarial loss: 0.406174\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047427; batch adversarial loss: 0.412828\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044084; batch adversarial loss: 0.510449\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035686; batch adversarial loss: 0.516575\n",
      "epoch 107; iter: 0; batch classifier loss: 0.101606; batch adversarial loss: 0.483716\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067612; batch adversarial loss: 0.462750\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066534; batch adversarial loss: 0.471416\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051422; batch adversarial loss: 0.418684\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055623; batch adversarial loss: 0.401968\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034280; batch adversarial loss: 0.528205\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047222; batch adversarial loss: 0.481781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046408; batch adversarial loss: 0.400798\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074251; batch adversarial loss: 0.489606\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072753; batch adversarial loss: 0.408933\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061829; batch adversarial loss: 0.405873\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045157; batch adversarial loss: 0.514411\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059227; batch adversarial loss: 0.508353\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050527; batch adversarial loss: 0.410928\n",
      "epoch 121; iter: 0; batch classifier loss: 0.064327; batch adversarial loss: 0.452808\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030674; batch adversarial loss: 0.461921\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068964; batch adversarial loss: 0.501719\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064819; batch adversarial loss: 0.473922\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032742; batch adversarial loss: 0.543676\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027710; batch adversarial loss: 0.513464\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030255; batch adversarial loss: 0.477717\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040600; batch adversarial loss: 0.455547\n",
      "epoch 129; iter: 0; batch classifier loss: 0.069510; batch adversarial loss: 0.438272\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032059; batch adversarial loss: 0.434308\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041677; batch adversarial loss: 0.495964\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029332; batch adversarial loss: 0.374856\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041695; batch adversarial loss: 0.440765\n",
      "epoch 134; iter: 0; batch classifier loss: 0.075614; batch adversarial loss: 0.394136\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031626; batch adversarial loss: 0.411941\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026532; batch adversarial loss: 0.455441\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024755; batch adversarial loss: 0.454453\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022176; batch adversarial loss: 0.442672\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016649; batch adversarial loss: 0.418038\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014515; batch adversarial loss: 0.424738\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041244; batch adversarial loss: 0.419083\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056949; batch adversarial loss: 0.462383\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019462; batch adversarial loss: 0.497620\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029907; batch adversarial loss: 0.500810\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047785; batch adversarial loss: 0.502337\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020249; batch adversarial loss: 0.539103\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015706; batch adversarial loss: 0.377620\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046148; batch adversarial loss: 0.406824\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009960; batch adversarial loss: 0.435594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017534; batch adversarial loss: 0.421158\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047577; batch adversarial loss: 0.386047\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020181; batch adversarial loss: 0.568725\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023588; batch adversarial loss: 0.511935\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028687; batch adversarial loss: 0.477462\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022344; batch adversarial loss: 0.441147\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039745; batch adversarial loss: 0.304101\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028232; batch adversarial loss: 0.388673\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017938; batch adversarial loss: 0.459151\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020838; batch adversarial loss: 0.456238\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041777; batch adversarial loss: 0.407540\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019129; batch adversarial loss: 0.436235\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020004; batch adversarial loss: 0.369925\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016584; batch adversarial loss: 0.466090\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013671; batch adversarial loss: 0.410947\n",
      "epoch 165; iter: 0; batch classifier loss: 0.006879; batch adversarial loss: 0.392561\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008599; batch adversarial loss: 0.481400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012716; batch adversarial loss: 0.461492\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033471; batch adversarial loss: 0.444320\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013070; batch adversarial loss: 0.492026\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035877; batch adversarial loss: 0.398578\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.443504\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020230; batch adversarial loss: 0.329990\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029907; batch adversarial loss: 0.485622\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014717; batch adversarial loss: 0.396648\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028520; batch adversarial loss: 0.419523\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055390; batch adversarial loss: 0.544448\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014177; batch adversarial loss: 0.554400\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010265; batch adversarial loss: 0.435609\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027665; batch adversarial loss: 0.491634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027672; batch adversarial loss: 0.425361\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045281; batch adversarial loss: 0.390082\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010243; batch adversarial loss: 0.405197\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012879; batch adversarial loss: 0.394932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.016584; batch adversarial loss: 0.475723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024367; batch adversarial loss: 0.453981\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017309; batch adversarial loss: 0.550445\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013684; batch adversarial loss: 0.439101\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028030; batch adversarial loss: 0.424314\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019489; batch adversarial loss: 0.500878\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029483; batch adversarial loss: 0.571479\n",
      "epoch 191; iter: 0; batch classifier loss: 0.058530; batch adversarial loss: 0.445885\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013667; batch adversarial loss: 0.420045\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030424; batch adversarial loss: 0.392426\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012339; batch adversarial loss: 0.508792\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012240; batch adversarial loss: 0.532010\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029459; batch adversarial loss: 0.407287\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005126; batch adversarial loss: 0.436178\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023445; batch adversarial loss: 0.442340\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009023; batch adversarial loss: 0.400979\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694692; batch adversarial loss: 0.832922\n",
      "epoch 1; iter: 0; batch classifier loss: 0.728787; batch adversarial loss: 0.926978\n",
      "epoch 2; iter: 0; batch classifier loss: 0.807940; batch adversarial loss: 0.883494\n",
      "epoch 3; iter: 0; batch classifier loss: 0.915182; batch adversarial loss: 0.815682\n",
      "epoch 4; iter: 0; batch classifier loss: 0.816441; batch adversarial loss: 0.734321\n",
      "epoch 5; iter: 0; batch classifier loss: 0.759282; batch adversarial loss: 0.672741\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611085; batch adversarial loss: 0.617575\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494473; batch adversarial loss: 0.571534\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403623; batch adversarial loss: 0.534772\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397844; batch adversarial loss: 0.549269\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343981; batch adversarial loss: 0.543732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286031; batch adversarial loss: 0.485581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301016; batch adversarial loss: 0.493414\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337939; batch adversarial loss: 0.487502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250883; batch adversarial loss: 0.555847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298093; batch adversarial loss: 0.518487\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343771; batch adversarial loss: 0.432660\n",
      "epoch 17; iter: 0; batch classifier loss: 0.266744; batch adversarial loss: 0.411417\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259553; batch adversarial loss: 0.479696\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203621; batch adversarial loss: 0.478536\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272983; batch adversarial loss: 0.421014\n",
      "epoch 21; iter: 0; batch classifier loss: 0.189058; batch adversarial loss: 0.428769\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226100; batch adversarial loss: 0.469853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227774; batch adversarial loss: 0.405835\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164691; batch adversarial loss: 0.524967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.230932; batch adversarial loss: 0.465337\n",
      "epoch 26; iter: 0; batch classifier loss: 0.236919; batch adversarial loss: 0.459021\n",
      "epoch 27; iter: 0; batch classifier loss: 0.275659; batch adversarial loss: 0.411569\n",
      "epoch 28; iter: 0; batch classifier loss: 0.257441; batch adversarial loss: 0.406074\n",
      "epoch 29; iter: 0; batch classifier loss: 0.317701; batch adversarial loss: 0.410634\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254697; batch adversarial loss: 0.416432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208797; batch adversarial loss: 0.467435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222751; batch adversarial loss: 0.518971\n",
      "epoch 33; iter: 0; batch classifier loss: 0.189332; batch adversarial loss: 0.426419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202668; batch adversarial loss: 0.448188\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220397; batch adversarial loss: 0.416081\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209829; batch adversarial loss: 0.482242\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193556; batch adversarial loss: 0.399398\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218923; batch adversarial loss: 0.390166\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127584; batch adversarial loss: 0.365121\n",
      "epoch 40; iter: 0; batch classifier loss: 0.206620; batch adversarial loss: 0.570742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148982; batch adversarial loss: 0.524749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137499; batch adversarial loss: 0.488750\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229519; batch adversarial loss: 0.471523\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173393; batch adversarial loss: 0.469104\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150738; batch adversarial loss: 0.482589\n",
      "epoch 46; iter: 0; batch classifier loss: 0.201142; batch adversarial loss: 0.412072\n",
      "epoch 47; iter: 0; batch classifier loss: 0.163383; batch adversarial loss: 0.422920\n",
      "epoch 48; iter: 0; batch classifier loss: 0.198951; batch adversarial loss: 0.484495\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165616; batch adversarial loss: 0.523316\n",
      "epoch 50; iter: 0; batch classifier loss: 0.144885; batch adversarial loss: 0.395361\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132612; batch adversarial loss: 0.522369\n",
      "epoch 52; iter: 0; batch classifier loss: 0.209523; batch adversarial loss: 0.468029\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124532; batch adversarial loss: 0.380392\n",
      "epoch 54; iter: 0; batch classifier loss: 0.157961; batch adversarial loss: 0.548620\n",
      "epoch 55; iter: 0; batch classifier loss: 0.213559; batch adversarial loss: 0.377903\n",
      "epoch 56; iter: 0; batch classifier loss: 0.232161; batch adversarial loss: 0.479687\n",
      "epoch 57; iter: 0; batch classifier loss: 0.149838; batch adversarial loss: 0.472770\n",
      "epoch 58; iter: 0; batch classifier loss: 0.174788; batch adversarial loss: 0.470114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079188; batch adversarial loss: 0.510428\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118379; batch adversarial loss: 0.393956\n",
      "epoch 61; iter: 0; batch classifier loss: 0.151562; batch adversarial loss: 0.498417\n",
      "epoch 62; iter: 0; batch classifier loss: 0.143782; batch adversarial loss: 0.434476\n",
      "epoch 63; iter: 0; batch classifier loss: 0.156339; batch adversarial loss: 0.429386\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167172; batch adversarial loss: 0.458366\n",
      "epoch 65; iter: 0; batch classifier loss: 0.146361; batch adversarial loss: 0.476237\n",
      "epoch 66; iter: 0; batch classifier loss: 0.236594; batch adversarial loss: 0.469530\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173384; batch adversarial loss: 0.427898\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107515; batch adversarial loss: 0.539598\n",
      "epoch 69; iter: 0; batch classifier loss: 0.219736; batch adversarial loss: 0.314859\n",
      "epoch 70; iter: 0; batch classifier loss: 0.152661; batch adversarial loss: 0.497001\n",
      "epoch 71; iter: 0; batch classifier loss: 0.137875; batch adversarial loss: 0.416301\n",
      "epoch 72; iter: 0; batch classifier loss: 0.182365; batch adversarial loss: 0.436982\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126196; batch adversarial loss: 0.567452\n",
      "epoch 74; iter: 0; batch classifier loss: 0.132195; batch adversarial loss: 0.533350\n",
      "epoch 75; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.431092\n",
      "epoch 76; iter: 0; batch classifier loss: 0.165823; batch adversarial loss: 0.474077\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228249; batch adversarial loss: 0.394294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.151620; batch adversarial loss: 0.411433\n",
      "epoch 79; iter: 0; batch classifier loss: 0.173773; batch adversarial loss: 0.457320\n",
      "epoch 80; iter: 0; batch classifier loss: 0.232888; batch adversarial loss: 0.493459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.182231; batch adversarial loss: 0.393948\n",
      "epoch 82; iter: 0; batch classifier loss: 0.242782; batch adversarial loss: 0.474313\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122771; batch adversarial loss: 0.422764\n",
      "epoch 84; iter: 0; batch classifier loss: 0.148416; batch adversarial loss: 0.440935\n",
      "epoch 85; iter: 0; batch classifier loss: 0.160381; batch adversarial loss: 0.417153\n",
      "epoch 86; iter: 0; batch classifier loss: 0.156028; batch adversarial loss: 0.469252\n",
      "epoch 87; iter: 0; batch classifier loss: 0.132320; batch adversarial loss: 0.509686\n",
      "epoch 88; iter: 0; batch classifier loss: 0.152304; batch adversarial loss: 0.409007\n",
      "epoch 89; iter: 0; batch classifier loss: 0.143445; batch adversarial loss: 0.450257\n",
      "epoch 90; iter: 0; batch classifier loss: 0.161473; batch adversarial loss: 0.429286\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166025; batch adversarial loss: 0.476375\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101725; batch adversarial loss: 0.384310\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104418; batch adversarial loss: 0.411527\n",
      "epoch 94; iter: 0; batch classifier loss: 0.158502; batch adversarial loss: 0.447270\n",
      "epoch 95; iter: 0; batch classifier loss: 0.161414; batch adversarial loss: 0.427357\n",
      "epoch 96; iter: 0; batch classifier loss: 0.173197; batch adversarial loss: 0.474824\n",
      "epoch 97; iter: 0; batch classifier loss: 0.130146; batch adversarial loss: 0.579567\n",
      "epoch 98; iter: 0; batch classifier loss: 0.152774; batch adversarial loss: 0.395116\n",
      "epoch 99; iter: 0; batch classifier loss: 0.191215; batch adversarial loss: 0.398928\n",
      "epoch 100; iter: 0; batch classifier loss: 0.127177; batch adversarial loss: 0.474022\n",
      "epoch 101; iter: 0; batch classifier loss: 0.139711; batch adversarial loss: 0.441035\n",
      "epoch 102; iter: 0; batch classifier loss: 0.112640; batch adversarial loss: 0.472778\n",
      "epoch 103; iter: 0; batch classifier loss: 0.133948; batch adversarial loss: 0.453225\n",
      "epoch 104; iter: 0; batch classifier loss: 0.146017; batch adversarial loss: 0.439611\n",
      "epoch 105; iter: 0; batch classifier loss: 0.169134; batch adversarial loss: 0.353497\n",
      "epoch 106; iter: 0; batch classifier loss: 0.114848; batch adversarial loss: 0.482040\n",
      "epoch 107; iter: 0; batch classifier loss: 0.142149; batch adversarial loss: 0.447088\n",
      "epoch 108; iter: 0; batch classifier loss: 0.171094; batch adversarial loss: 0.390058\n",
      "epoch 109; iter: 0; batch classifier loss: 0.154529; batch adversarial loss: 0.420476\n",
      "epoch 110; iter: 0; batch classifier loss: 0.176240; batch adversarial loss: 0.413733\n",
      "epoch 111; iter: 0; batch classifier loss: 0.146684; batch adversarial loss: 0.467967\n",
      "epoch 112; iter: 0; batch classifier loss: 0.147414; batch adversarial loss: 0.496609\n",
      "epoch 113; iter: 0; batch classifier loss: 0.220813; batch adversarial loss: 0.421938\n",
      "epoch 114; iter: 0; batch classifier loss: 0.202584; batch adversarial loss: 0.510774\n",
      "epoch 115; iter: 0; batch classifier loss: 0.158020; batch adversarial loss: 0.476243\n",
      "epoch 116; iter: 0; batch classifier loss: 0.169946; batch adversarial loss: 0.434989\n",
      "epoch 117; iter: 0; batch classifier loss: 0.200508; batch adversarial loss: 0.448596\n",
      "epoch 118; iter: 0; batch classifier loss: 0.219460; batch adversarial loss: 0.497086\n",
      "epoch 119; iter: 0; batch classifier loss: 0.227027; batch adversarial loss: 0.474043\n",
      "epoch 120; iter: 0; batch classifier loss: 0.230267; batch adversarial loss: 0.437165\n",
      "epoch 121; iter: 0; batch classifier loss: 0.255868; batch adversarial loss: 0.462598\n",
      "epoch 122; iter: 0; batch classifier loss: 0.225489; batch adversarial loss: 0.411943\n",
      "epoch 123; iter: 0; batch classifier loss: 0.291215; batch adversarial loss: 0.482062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.189234; batch adversarial loss: 0.448290\n",
      "epoch 125; iter: 0; batch classifier loss: 0.186454; batch adversarial loss: 0.568757\n",
      "epoch 126; iter: 0; batch classifier loss: 0.208934; batch adversarial loss: 0.458620\n",
      "epoch 127; iter: 0; batch classifier loss: 0.237119; batch adversarial loss: 0.471888\n",
      "epoch 128; iter: 0; batch classifier loss: 0.238602; batch adversarial loss: 0.435038\n",
      "epoch 129; iter: 0; batch classifier loss: 0.299808; batch adversarial loss: 0.446340\n",
      "epoch 130; iter: 0; batch classifier loss: 0.182317; batch adversarial loss: 0.483438\n",
      "epoch 131; iter: 0; batch classifier loss: 0.199136; batch adversarial loss: 0.371876\n",
      "epoch 132; iter: 0; batch classifier loss: 0.251413; batch adversarial loss: 0.409913\n",
      "epoch 133; iter: 0; batch classifier loss: 0.164848; batch adversarial loss: 0.422208\n",
      "epoch 134; iter: 0; batch classifier loss: 0.191081; batch adversarial loss: 0.558896\n",
      "epoch 135; iter: 0; batch classifier loss: 0.169754; batch adversarial loss: 0.507904\n",
      "epoch 136; iter: 0; batch classifier loss: 0.192492; batch adversarial loss: 0.507898\n",
      "epoch 137; iter: 0; batch classifier loss: 0.186964; batch adversarial loss: 0.482944\n",
      "epoch 138; iter: 0; batch classifier loss: 0.230360; batch adversarial loss: 0.445678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.186724; batch adversarial loss: 0.385415\n",
      "epoch 140; iter: 0; batch classifier loss: 0.218350; batch adversarial loss: 0.384518\n",
      "epoch 141; iter: 0; batch classifier loss: 0.215436; batch adversarial loss: 0.421975\n",
      "epoch 142; iter: 0; batch classifier loss: 0.243465; batch adversarial loss: 0.508172\n",
      "epoch 143; iter: 0; batch classifier loss: 0.202115; batch adversarial loss: 0.409320\n",
      "epoch 144; iter: 0; batch classifier loss: 0.092669; batch adversarial loss: 0.507339\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062308; batch adversarial loss: 0.444748\n",
      "epoch 146; iter: 0; batch classifier loss: 0.124485; batch adversarial loss: 0.396250\n",
      "epoch 147; iter: 0; batch classifier loss: 0.097519; batch adversarial loss: 0.493762\n",
      "epoch 148; iter: 0; batch classifier loss: 0.148354; batch adversarial loss: 0.486040\n",
      "epoch 149; iter: 0; batch classifier loss: 0.103506; batch adversarial loss: 0.431594\n",
      "epoch 150; iter: 0; batch classifier loss: 0.198502; batch adversarial loss: 0.421323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.118196; batch adversarial loss: 0.523615\n",
      "epoch 152; iter: 0; batch classifier loss: 0.156804; batch adversarial loss: 0.453399\n",
      "epoch 153; iter: 0; batch classifier loss: 0.102535; batch adversarial loss: 0.441084\n",
      "epoch 154; iter: 0; batch classifier loss: 0.096212; batch adversarial loss: 0.492224\n",
      "epoch 155; iter: 0; batch classifier loss: 0.086427; batch adversarial loss: 0.456055\n",
      "epoch 156; iter: 0; batch classifier loss: 0.101238; batch adversarial loss: 0.416573\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053738; batch adversarial loss: 0.417367\n",
      "epoch 158; iter: 0; batch classifier loss: 0.084894; batch adversarial loss: 0.548194\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044254; batch adversarial loss: 0.470780\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058360; batch adversarial loss: 0.424827\n",
      "epoch 161; iter: 0; batch classifier loss: 0.063244; batch adversarial loss: 0.369307\n",
      "epoch 162; iter: 0; batch classifier loss: 0.067193; batch adversarial loss: 0.417969\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029617; batch adversarial loss: 0.410860\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039618; batch adversarial loss: 0.425788\n",
      "epoch 165; iter: 0; batch classifier loss: 0.083477; batch adversarial loss: 0.407421\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034245; batch adversarial loss: 0.500035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045652; batch adversarial loss: 0.530571\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031777; batch adversarial loss: 0.451389\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037807; batch adversarial loss: 0.400913\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027376; batch adversarial loss: 0.448496\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029157; batch adversarial loss: 0.414891\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053417; batch adversarial loss: 0.472250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041858; batch adversarial loss: 0.401967\n",
      "epoch 174; iter: 0; batch classifier loss: 0.031257; batch adversarial loss: 0.432354\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039523; batch adversarial loss: 0.397643\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033525; batch adversarial loss: 0.495044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.021198; batch adversarial loss: 0.516322\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033090; batch adversarial loss: 0.441482\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026712; batch adversarial loss: 0.422083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023626; batch adversarial loss: 0.517586\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028374; batch adversarial loss: 0.412793\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026091; batch adversarial loss: 0.452985\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028887; batch adversarial loss: 0.496031\n",
      "epoch 184; iter: 0; batch classifier loss: 0.051181; batch adversarial loss: 0.499767\n",
      "epoch 185; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.411849\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035200; batch adversarial loss: 0.449439\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034658; batch adversarial loss: 0.533073\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022331; batch adversarial loss: 0.414644\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020901; batch adversarial loss: 0.421039\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015752; batch adversarial loss: 0.452381\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024176; batch adversarial loss: 0.583664\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031311; batch adversarial loss: 0.458513\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025338; batch adversarial loss: 0.392825\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013059; batch adversarial loss: 0.332342\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029817; batch adversarial loss: 0.426660\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012785; batch adversarial loss: 0.440024\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010199; batch adversarial loss: 0.384900\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027686; batch adversarial loss: 0.486595\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014911; batch adversarial loss: 0.488690\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688432; batch adversarial loss: 0.664787\n",
      "epoch 1; iter: 0; batch classifier loss: 0.500260; batch adversarial loss: 0.646815\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444626; batch adversarial loss: 0.592859\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350699; batch adversarial loss: 0.567323\n",
      "epoch 4; iter: 0; batch classifier loss: 0.309200; batch adversarial loss: 0.572290\n",
      "epoch 5; iter: 0; batch classifier loss: 0.300503; batch adversarial loss: 0.610230\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316544; batch adversarial loss: 0.608289\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280300; batch adversarial loss: 0.549491\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313785; batch adversarial loss: 0.558185\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243836; batch adversarial loss: 0.552291\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325517; batch adversarial loss: 0.528327\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309527; batch adversarial loss: 0.569063\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277247; batch adversarial loss: 0.529832\n",
      "epoch 13; iter: 0; batch classifier loss: 0.231989; batch adversarial loss: 0.426668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319212; batch adversarial loss: 0.545910\n",
      "epoch 15; iter: 0; batch classifier loss: 0.152368; batch adversarial loss: 0.468922\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199734; batch adversarial loss: 0.482283\n",
      "epoch 17; iter: 0; batch classifier loss: 0.244082; batch adversarial loss: 0.490356\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224485; batch adversarial loss: 0.434699\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261396; batch adversarial loss: 0.427043\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199853; batch adversarial loss: 0.472284\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240620; batch adversarial loss: 0.474932\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226242; batch adversarial loss: 0.466892\n",
      "epoch 23; iter: 0; batch classifier loss: 0.182719; batch adversarial loss: 0.477071\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190137; batch adversarial loss: 0.435622\n",
      "epoch 25; iter: 0; batch classifier loss: 0.136095; batch adversarial loss: 0.514296\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194632; batch adversarial loss: 0.391237\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196992; batch adversarial loss: 0.455584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156863; batch adversarial loss: 0.496120\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227156; batch adversarial loss: 0.439854\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187866; batch adversarial loss: 0.524338\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177490; batch adversarial loss: 0.477925\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256375; batch adversarial loss: 0.425555\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119503; batch adversarial loss: 0.475766\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231868; batch adversarial loss: 0.475549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178047; batch adversarial loss: 0.420366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187277; batch adversarial loss: 0.515735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186505; batch adversarial loss: 0.486437\n",
      "epoch 38; iter: 0; batch classifier loss: 0.178039; batch adversarial loss: 0.495219\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168372; batch adversarial loss: 0.555492\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184843; batch adversarial loss: 0.479221\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225378; batch adversarial loss: 0.438864\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181746; batch adversarial loss: 0.484681\n",
      "epoch 43; iter: 0; batch classifier loss: 0.189736; batch adversarial loss: 0.411627\n",
      "epoch 44; iter: 0; batch classifier loss: 0.230767; batch adversarial loss: 0.378584\n",
      "epoch 45; iter: 0; batch classifier loss: 0.250565; batch adversarial loss: 0.510744\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224921; batch adversarial loss: 0.438731\n",
      "epoch 47; iter: 0; batch classifier loss: 0.207298; batch adversarial loss: 0.482765\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171098; batch adversarial loss: 0.470361\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198763; batch adversarial loss: 0.460847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.273386; batch adversarial loss: 0.529836\n",
      "epoch 51; iter: 0; batch classifier loss: 0.197510; batch adversarial loss: 0.353495\n",
      "epoch 52; iter: 0; batch classifier loss: 0.104132; batch adversarial loss: 0.565707\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166490; batch adversarial loss: 0.458513\n",
      "epoch 54; iter: 0; batch classifier loss: 0.144469; batch adversarial loss: 0.412064\n",
      "epoch 55; iter: 0; batch classifier loss: 0.216786; batch adversarial loss: 0.458761\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136881; batch adversarial loss: 0.422439\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117567; batch adversarial loss: 0.435978\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128730; batch adversarial loss: 0.433742\n",
      "epoch 59; iter: 0; batch classifier loss: 0.135066; batch adversarial loss: 0.446840\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124476; batch adversarial loss: 0.472272\n",
      "epoch 61; iter: 0; batch classifier loss: 0.200024; batch adversarial loss: 0.471635\n",
      "epoch 62; iter: 0; batch classifier loss: 0.129007; batch adversarial loss: 0.483744\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096358; batch adversarial loss: 0.469063\n",
      "epoch 64; iter: 0; batch classifier loss: 0.157910; batch adversarial loss: 0.447259\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153347; batch adversarial loss: 0.543805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110027; batch adversarial loss: 0.517626\n",
      "epoch 67; iter: 0; batch classifier loss: 0.167462; batch adversarial loss: 0.471264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.154481; batch adversarial loss: 0.446684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.161159; batch adversarial loss: 0.447291\n",
      "epoch 70; iter: 0; batch classifier loss: 0.099797; batch adversarial loss: 0.482703\n",
      "epoch 71; iter: 0; batch classifier loss: 0.223183; batch adversarial loss: 0.410884\n",
      "epoch 72; iter: 0; batch classifier loss: 0.106660; batch adversarial loss: 0.530076\n",
      "epoch 73; iter: 0; batch classifier loss: 0.193980; batch adversarial loss: 0.482531\n",
      "epoch 74; iter: 0; batch classifier loss: 0.179860; batch adversarial loss: 0.471350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.186016; batch adversarial loss: 0.470941\n",
      "epoch 76; iter: 0; batch classifier loss: 0.267009; batch adversarial loss: 0.470951\n",
      "epoch 77; iter: 0; batch classifier loss: 0.148558; batch adversarial loss: 0.398320\n",
      "epoch 78; iter: 0; batch classifier loss: 0.197253; batch adversarial loss: 0.483248\n",
      "epoch 79; iter: 0; batch classifier loss: 0.148179; batch adversarial loss: 0.422234\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126240; batch adversarial loss: 0.568168\n",
      "epoch 81; iter: 0; batch classifier loss: 0.165871; batch adversarial loss: 0.421607\n",
      "epoch 82; iter: 0; batch classifier loss: 0.228260; batch adversarial loss: 0.434686\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126421; batch adversarial loss: 0.543272\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085997; batch adversarial loss: 0.493971\n",
      "epoch 85; iter: 0; batch classifier loss: 0.231680; batch adversarial loss: 0.507856\n",
      "epoch 86; iter: 0; batch classifier loss: 0.193431; batch adversarial loss: 0.408813\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081178; batch adversarial loss: 0.483487\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125900; batch adversarial loss: 0.544373\n",
      "epoch 89; iter: 0; batch classifier loss: 0.164875; batch adversarial loss: 0.430610\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118506; batch adversarial loss: 0.542846\n",
      "epoch 91; iter: 0; batch classifier loss: 0.185303; batch adversarial loss: 0.463288\n",
      "epoch 92; iter: 0; batch classifier loss: 0.118302; batch adversarial loss: 0.470700\n",
      "epoch 93; iter: 0; batch classifier loss: 0.123675; batch adversarial loss: 0.456007\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135925; batch adversarial loss: 0.486227\n",
      "epoch 95; iter: 0; batch classifier loss: 0.126659; batch adversarial loss: 0.445791\n",
      "epoch 96; iter: 0; batch classifier loss: 0.123584; batch adversarial loss: 0.459281\n",
      "epoch 97; iter: 0; batch classifier loss: 0.115564; batch adversarial loss: 0.518950\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100629; batch adversarial loss: 0.409491\n",
      "epoch 99; iter: 0; batch classifier loss: 0.097550; batch adversarial loss: 0.383682\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077461; batch adversarial loss: 0.479230\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097558; batch adversarial loss: 0.440762\n",
      "epoch 102; iter: 0; batch classifier loss: 0.108568; batch adversarial loss: 0.454970\n",
      "epoch 103; iter: 0; batch classifier loss: 0.136582; batch adversarial loss: 0.513395\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083094; batch adversarial loss: 0.434388\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054499; batch adversarial loss: 0.492819\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069187; batch adversarial loss: 0.554879\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073154; batch adversarial loss: 0.405179\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058903; batch adversarial loss: 0.361744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069742; batch adversarial loss: 0.484428\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033472; batch adversarial loss: 0.430915\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035565; batch adversarial loss: 0.503236\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033911; batch adversarial loss: 0.435646\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032576; batch adversarial loss: 0.423058\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026101; batch adversarial loss: 0.454323\n",
      "epoch 115; iter: 0; batch classifier loss: 0.084833; batch adversarial loss: 0.476098\n",
      "epoch 116; iter: 0; batch classifier loss: 0.017833; batch adversarial loss: 0.455383\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029117; batch adversarial loss: 0.488122\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031792; batch adversarial loss: 0.469052\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021248; batch adversarial loss: 0.505204\n",
      "epoch 120; iter: 0; batch classifier loss: 0.018404; batch adversarial loss: 0.587320\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026991; batch adversarial loss: 0.422677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057077; batch adversarial loss: 0.439096\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041066; batch adversarial loss: 0.396242\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038584; batch adversarial loss: 0.428340\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.426126\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034214; batch adversarial loss: 0.516359\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019830; batch adversarial loss: 0.475692\n",
      "epoch 128; iter: 0; batch classifier loss: 0.010714; batch adversarial loss: 0.420885\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020938; batch adversarial loss: 0.465315\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028981; batch adversarial loss: 0.474524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017934; batch adversarial loss: 0.361764\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021245; batch adversarial loss: 0.330211\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016840; batch adversarial loss: 0.410636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050056; batch adversarial loss: 0.446606\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039626; batch adversarial loss: 0.380817\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036299; batch adversarial loss: 0.500041\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.442733\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.519178\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026670; batch adversarial loss: 0.500432\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016849; batch adversarial loss: 0.473514\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017064; batch adversarial loss: 0.459506\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025987; batch adversarial loss: 0.464585\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026569; batch adversarial loss: 0.397084\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033148; batch adversarial loss: 0.478290\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014246; batch adversarial loss: 0.431915\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033690; batch adversarial loss: 0.471131\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.391477\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024892; batch adversarial loss: 0.380909\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015193; batch adversarial loss: 0.491552\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013547; batch adversarial loss: 0.429444\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026528; batch adversarial loss: 0.322149\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028550; batch adversarial loss: 0.424455\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017479; batch adversarial loss: 0.576167\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036612; batch adversarial loss: 0.496641\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027648; batch adversarial loss: 0.463798\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007715; batch adversarial loss: 0.474371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026431; batch adversarial loss: 0.440692\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044391; batch adversarial loss: 0.452254\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017829; batch adversarial loss: 0.475526\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010886; batch adversarial loss: 0.433240\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036377; batch adversarial loss: 0.363590\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012005; batch adversarial loss: 0.443672\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007581; batch adversarial loss: 0.410531\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039316; batch adversarial loss: 0.520269\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038813; batch adversarial loss: 0.441414\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045834; batch adversarial loss: 0.429366\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017162; batch adversarial loss: 0.395862\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025790; batch adversarial loss: 0.530704\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028715; batch adversarial loss: 0.427476\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008539; batch adversarial loss: 0.511266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.051516; batch adversarial loss: 0.491006\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019154; batch adversarial loss: 0.448009\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.362559\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007248; batch adversarial loss: 0.501756\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015919; batch adversarial loss: 0.494297\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020758; batch adversarial loss: 0.468662\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033486; batch adversarial loss: 0.441007\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040069; batch adversarial loss: 0.575839\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.401849\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032799; batch adversarial loss: 0.462203\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013835; batch adversarial loss: 0.493235\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015335; batch adversarial loss: 0.438975\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027483; batch adversarial loss: 0.438458\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017270; batch adversarial loss: 0.525326\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006091; batch adversarial loss: 0.492415\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015416; batch adversarial loss: 0.515736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010323; batch adversarial loss: 0.475397\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020714; batch adversarial loss: 0.420402\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007376; batch adversarial loss: 0.496924\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025210; batch adversarial loss: 0.425998\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.420073\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009139; batch adversarial loss: 0.441171\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007230; batch adversarial loss: 0.478497\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013386; batch adversarial loss: 0.424047\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015058; batch adversarial loss: 0.435128\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004108; batch adversarial loss: 0.380030\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022796; batch adversarial loss: 0.503486\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016293; batch adversarial loss: 0.493550\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030271; batch adversarial loss: 0.489920\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698817; batch adversarial loss: 0.570300\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542405; batch adversarial loss: 0.577104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419007; batch adversarial loss: 0.626074\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371392; batch adversarial loss: 0.602965\n",
      "epoch 4; iter: 0; batch classifier loss: 0.410593; batch adversarial loss: 0.555625\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391511; batch adversarial loss: 0.650690\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461786; batch adversarial loss: 0.613127\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367217; batch adversarial loss: 0.576655\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554103; batch adversarial loss: 0.510130\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466609; batch adversarial loss: 0.506219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441500; batch adversarial loss: 0.483468\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381691; batch adversarial loss: 0.536281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251614; batch adversarial loss: 0.507613\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247970; batch adversarial loss: 0.477414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192473; batch adversarial loss: 0.513871\n",
      "epoch 15; iter: 0; batch classifier loss: 0.238907; batch adversarial loss: 0.548832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264868; batch adversarial loss: 0.504984\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240178; batch adversarial loss: 0.490870\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172993; batch adversarial loss: 0.488949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157013; batch adversarial loss: 0.395695\n",
      "epoch 20; iter: 0; batch classifier loss: 0.169233; batch adversarial loss: 0.522712\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225831; batch adversarial loss: 0.451257\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166345; batch adversarial loss: 0.590117\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189815; batch adversarial loss: 0.459605\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153962; batch adversarial loss: 0.471275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125556; batch adversarial loss: 0.450227\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214375; batch adversarial loss: 0.529437\n",
      "epoch 27; iter: 0; batch classifier loss: 0.111478; batch adversarial loss: 0.442971\n",
      "epoch 28; iter: 0; batch classifier loss: 0.126000; batch adversarial loss: 0.454949\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137845; batch adversarial loss: 0.385614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.121278; batch adversarial loss: 0.451042\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149194; batch adversarial loss: 0.452003\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108081; batch adversarial loss: 0.449317\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092368; batch adversarial loss: 0.460814\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151091; batch adversarial loss: 0.421813\n",
      "epoch 35; iter: 0; batch classifier loss: 0.072293; batch adversarial loss: 0.508097\n",
      "epoch 36; iter: 0; batch classifier loss: 0.101995; batch adversarial loss: 0.491948\n",
      "epoch 37; iter: 0; batch classifier loss: 0.142081; batch adversarial loss: 0.475163\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090450; batch adversarial loss: 0.397334\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163955; batch adversarial loss: 0.399970\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164176; batch adversarial loss: 0.423376\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108744; batch adversarial loss: 0.415927\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108890; batch adversarial loss: 0.484809\n",
      "epoch 43; iter: 0; batch classifier loss: 0.120645; batch adversarial loss: 0.414533\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105803; batch adversarial loss: 0.482649\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097310; batch adversarial loss: 0.522733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092335; batch adversarial loss: 0.578026\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098553; batch adversarial loss: 0.442867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102165; batch adversarial loss: 0.391823\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121927; batch adversarial loss: 0.429370\n",
      "epoch 50; iter: 0; batch classifier loss: 0.143917; batch adversarial loss: 0.426880\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134621; batch adversarial loss: 0.490289\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103266; batch adversarial loss: 0.444587\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079695; batch adversarial loss: 0.436739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113103; batch adversarial loss: 0.499256\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189103; batch adversarial loss: 0.457556\n",
      "epoch 56; iter: 0; batch classifier loss: 0.107516; batch adversarial loss: 0.533247\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080670; batch adversarial loss: 0.563897\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116283; batch adversarial loss: 0.394451\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172317; batch adversarial loss: 0.411393\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116295; batch adversarial loss: 0.437802\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125527; batch adversarial loss: 0.450191\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140697; batch adversarial loss: 0.448681\n",
      "epoch 63; iter: 0; batch classifier loss: 0.127532; batch adversarial loss: 0.465758\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090726; batch adversarial loss: 0.444278\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110518; batch adversarial loss: 0.455280\n",
      "epoch 66; iter: 0; batch classifier loss: 0.116102; batch adversarial loss: 0.451372\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134600; batch adversarial loss: 0.381266\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094154; batch adversarial loss: 0.397544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.143093; batch adversarial loss: 0.470959\n",
      "epoch 70; iter: 0; batch classifier loss: 0.111006; batch adversarial loss: 0.496663\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112706; batch adversarial loss: 0.530273\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082302; batch adversarial loss: 0.574203\n",
      "epoch 73; iter: 0; batch classifier loss: 0.145027; batch adversarial loss: 0.481992\n",
      "epoch 74; iter: 0; batch classifier loss: 0.140313; batch adversarial loss: 0.496274\n",
      "epoch 75; iter: 0; batch classifier loss: 0.203986; batch adversarial loss: 0.414553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.161939; batch adversarial loss: 0.443914\n",
      "epoch 77; iter: 0; batch classifier loss: 0.154772; batch adversarial loss: 0.383482\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173289; batch adversarial loss: 0.481327\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090607; batch adversarial loss: 0.399005\n",
      "epoch 80; iter: 0; batch classifier loss: 0.153264; batch adversarial loss: 0.446890\n",
      "epoch 81; iter: 0; batch classifier loss: 0.132406; batch adversarial loss: 0.456699\n",
      "epoch 82; iter: 0; batch classifier loss: 0.145929; batch adversarial loss: 0.460728\n",
      "epoch 83; iter: 0; batch classifier loss: 0.200270; batch adversarial loss: 0.409854\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109101; batch adversarial loss: 0.469256\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084704; batch adversarial loss: 0.444666\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118336; batch adversarial loss: 0.474557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.132006; batch adversarial loss: 0.498910\n",
      "epoch 88; iter: 0; batch classifier loss: 0.112843; batch adversarial loss: 0.397939\n",
      "epoch 89; iter: 0; batch classifier loss: 0.112051; batch adversarial loss: 0.472016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089048; batch adversarial loss: 0.521928\n",
      "epoch 91; iter: 0; batch classifier loss: 0.102827; batch adversarial loss: 0.466350\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117393; batch adversarial loss: 0.475033\n",
      "epoch 93; iter: 0; batch classifier loss: 0.105033; batch adversarial loss: 0.510460\n",
      "epoch 94; iter: 0; batch classifier loss: 0.126778; batch adversarial loss: 0.323101\n",
      "epoch 95; iter: 0; batch classifier loss: 0.132169; batch adversarial loss: 0.534086\n",
      "epoch 96; iter: 0; batch classifier loss: 0.130460; batch adversarial loss: 0.455185\n",
      "epoch 97; iter: 0; batch classifier loss: 0.117285; batch adversarial loss: 0.380147\n",
      "epoch 98; iter: 0; batch classifier loss: 0.135362; batch adversarial loss: 0.569248\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107990; batch adversarial loss: 0.391425\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109020; batch adversarial loss: 0.518664\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095930; batch adversarial loss: 0.497164\n",
      "epoch 102; iter: 0; batch classifier loss: 0.135312; batch adversarial loss: 0.411193\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070626; batch adversarial loss: 0.468629\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151450; batch adversarial loss: 0.525771\n",
      "epoch 105; iter: 0; batch classifier loss: 0.112681; batch adversarial loss: 0.447545\n",
      "epoch 106; iter: 0; batch classifier loss: 0.112608; batch adversarial loss: 0.452420\n",
      "epoch 107; iter: 0; batch classifier loss: 0.124485; batch adversarial loss: 0.459655\n",
      "epoch 108; iter: 0; batch classifier loss: 0.113393; batch adversarial loss: 0.498227\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082056; batch adversarial loss: 0.540728\n",
      "epoch 110; iter: 0; batch classifier loss: 0.113678; batch adversarial loss: 0.464593\n",
      "epoch 111; iter: 0; batch classifier loss: 0.091548; batch adversarial loss: 0.472531\n",
      "epoch 112; iter: 0; batch classifier loss: 0.108747; batch adversarial loss: 0.419868\n",
      "epoch 113; iter: 0; batch classifier loss: 0.103965; batch adversarial loss: 0.431137\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071562; batch adversarial loss: 0.415607\n",
      "epoch 115; iter: 0; batch classifier loss: 0.121832; batch adversarial loss: 0.437229\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058894; batch adversarial loss: 0.462931\n",
      "epoch 117; iter: 0; batch classifier loss: 0.153306; batch adversarial loss: 0.472707\n",
      "epoch 118; iter: 0; batch classifier loss: 0.132311; batch adversarial loss: 0.404286\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083984; batch adversarial loss: 0.507289\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066609; batch adversarial loss: 0.453761\n",
      "epoch 121; iter: 0; batch classifier loss: 0.086364; batch adversarial loss: 0.444939\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057109; batch adversarial loss: 0.485555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.087221; batch adversarial loss: 0.392401\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069236; batch adversarial loss: 0.435426\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055354; batch adversarial loss: 0.473131\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062793; batch adversarial loss: 0.451920\n",
      "epoch 127; iter: 0; batch classifier loss: 0.071577; batch adversarial loss: 0.405325\n",
      "epoch 128; iter: 0; batch classifier loss: 0.078556; batch adversarial loss: 0.449196\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050952; batch adversarial loss: 0.465434\n",
      "epoch 130; iter: 0; batch classifier loss: 0.107650; batch adversarial loss: 0.496552\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056919; batch adversarial loss: 0.449264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044204; batch adversarial loss: 0.475859\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032478; batch adversarial loss: 0.379054\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038831; batch adversarial loss: 0.450682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045501; batch adversarial loss: 0.465681\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039680; batch adversarial loss: 0.487466\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033879; batch adversarial loss: 0.384136\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034437; batch adversarial loss: 0.477199\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022327; batch adversarial loss: 0.505364\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034604; batch adversarial loss: 0.408198\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042866; batch adversarial loss: 0.545877\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058697; batch adversarial loss: 0.472167\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040681; batch adversarial loss: 0.447800\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053557; batch adversarial loss: 0.384774\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034357; batch adversarial loss: 0.456255\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035406; batch adversarial loss: 0.451904\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045288; batch adversarial loss: 0.487747\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026600; batch adversarial loss: 0.423794\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040525; batch adversarial loss: 0.437047\n",
      "epoch 150; iter: 0; batch classifier loss: 0.006899; batch adversarial loss: 0.445186\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039989; batch adversarial loss: 0.364090\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037143; batch adversarial loss: 0.403378\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034944; batch adversarial loss: 0.468360\n",
      "epoch 154; iter: 0; batch classifier loss: 0.083160; batch adversarial loss: 0.419837\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021811; batch adversarial loss: 0.443032\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034331; batch adversarial loss: 0.444510\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053851; batch adversarial loss: 0.412611\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029523; batch adversarial loss: 0.418353\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.552584\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014773; batch adversarial loss: 0.424242\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012950; batch adversarial loss: 0.548436\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048791; batch adversarial loss: 0.445700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017340; batch adversarial loss: 0.452969\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023330; batch adversarial loss: 0.434060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.029147; batch adversarial loss: 0.560595\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024605; batch adversarial loss: 0.529379\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030779; batch adversarial loss: 0.510562\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013507; batch adversarial loss: 0.407699\n",
      "epoch 169; iter: 0; batch classifier loss: 0.060510; batch adversarial loss: 0.459118\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020743; batch adversarial loss: 0.440086\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010679; batch adversarial loss: 0.534514\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008039; batch adversarial loss: 0.394969\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012741; batch adversarial loss: 0.424999\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022201; batch adversarial loss: 0.493412\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035876; batch adversarial loss: 0.507609\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017203; batch adversarial loss: 0.497863\n",
      "epoch 177; iter: 0; batch classifier loss: 0.003579; batch adversarial loss: 0.407569\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011928; batch adversarial loss: 0.446376\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028279; batch adversarial loss: 0.538172\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015219; batch adversarial loss: 0.459059\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019840; batch adversarial loss: 0.412846\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036501; batch adversarial loss: 0.504434\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015954; batch adversarial loss: 0.465383\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019246; batch adversarial loss: 0.394297\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038068; batch adversarial loss: 0.458078\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041624; batch adversarial loss: 0.527567\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.448622\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014088; batch adversarial loss: 0.408988\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.497705\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034787; batch adversarial loss: 0.419070\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035285; batch adversarial loss: 0.440680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021389; batch adversarial loss: 0.444054\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007812; batch adversarial loss: 0.422646\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017051; batch adversarial loss: 0.465896\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004090; batch adversarial loss: 0.438357\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027607; batch adversarial loss: 0.465001\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035291; batch adversarial loss: 0.468053\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014328; batch adversarial loss: 0.442467\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006730; batch adversarial loss: 0.429405\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662953; batch adversarial loss: 0.747810\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466492; batch adversarial loss: 0.695926\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425137; batch adversarial loss: 0.646066\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351759; batch adversarial loss: 0.619349\n",
      "epoch 4; iter: 0; batch classifier loss: 0.311388; batch adversarial loss: 0.602010\n",
      "epoch 5; iter: 0; batch classifier loss: 0.397925; batch adversarial loss: 0.569546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330703; batch adversarial loss: 0.589153\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338045; batch adversarial loss: 0.578534\n",
      "epoch 8; iter: 0; batch classifier loss: 0.214948; batch adversarial loss: 0.580269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445075; batch adversarial loss: 0.550166\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319599; batch adversarial loss: 0.517950\n",
      "epoch 11; iter: 0; batch classifier loss: 0.439734; batch adversarial loss: 0.534021\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418097; batch adversarial loss: 0.520003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.405843; batch adversarial loss: 0.484721\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450038; batch adversarial loss: 0.498142\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311014; batch adversarial loss: 0.527270\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270011; batch adversarial loss: 0.506434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331545; batch adversarial loss: 0.502442\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339420; batch adversarial loss: 0.424067\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336244; batch adversarial loss: 0.466713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387438; batch adversarial loss: 0.507540\n",
      "epoch 21; iter: 0; batch classifier loss: 0.286374; batch adversarial loss: 0.479028\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277913; batch adversarial loss: 0.497538\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318092; batch adversarial loss: 0.530876\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266707; batch adversarial loss: 0.474484\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242128; batch adversarial loss: 0.429692\n",
      "epoch 26; iter: 0; batch classifier loss: 0.283785; batch adversarial loss: 0.417725\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344883; batch adversarial loss: 0.499250\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347455; batch adversarial loss: 0.394408\n",
      "epoch 29; iter: 0; batch classifier loss: 0.275973; batch adversarial loss: 0.494252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264878; batch adversarial loss: 0.392698\n",
      "epoch 31; iter: 0; batch classifier loss: 0.294147; batch adversarial loss: 0.440656\n",
      "epoch 32; iter: 0; batch classifier loss: 0.253346; batch adversarial loss: 0.523509\n",
      "epoch 33; iter: 0; batch classifier loss: 0.214633; batch adversarial loss: 0.422026\n",
      "epoch 34; iter: 0; batch classifier loss: 0.229287; batch adversarial loss: 0.463135\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256551; batch adversarial loss: 0.427091\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247171; batch adversarial loss: 0.439239\n",
      "epoch 37; iter: 0; batch classifier loss: 0.217528; batch adversarial loss: 0.450678\n",
      "epoch 38; iter: 0; batch classifier loss: 0.253488; batch adversarial loss: 0.486827\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231647; batch adversarial loss: 0.524360\n",
      "epoch 40; iter: 0; batch classifier loss: 0.250346; batch adversarial loss: 0.451322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291318; batch adversarial loss: 0.406787\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217329; batch adversarial loss: 0.470050\n",
      "epoch 43; iter: 0; batch classifier loss: 0.182111; batch adversarial loss: 0.564890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.236028; batch adversarial loss: 0.542718\n",
      "epoch 45; iter: 0; batch classifier loss: 0.247930; batch adversarial loss: 0.544320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.226406; batch adversarial loss: 0.494387\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230682; batch adversarial loss: 0.483132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142817; batch adversarial loss: 0.575703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.211164; batch adversarial loss: 0.517540\n",
      "epoch 50; iter: 0; batch classifier loss: 0.122496; batch adversarial loss: 0.482840\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135566; batch adversarial loss: 0.434238\n",
      "epoch 52; iter: 0; batch classifier loss: 0.140210; batch adversarial loss: 0.412727\n",
      "epoch 53; iter: 0; batch classifier loss: 0.289346; batch adversarial loss: 0.556189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.181271; batch adversarial loss: 0.496324\n",
      "epoch 55; iter: 0; batch classifier loss: 0.167383; batch adversarial loss: 0.484493\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250706; batch adversarial loss: 0.399040\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175729; batch adversarial loss: 0.446716\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152260; batch adversarial loss: 0.507258\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174321; batch adversarial loss: 0.482304\n",
      "epoch 60; iter: 0; batch classifier loss: 0.118208; batch adversarial loss: 0.421917\n",
      "epoch 61; iter: 0; batch classifier loss: 0.203473; batch adversarial loss: 0.384682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.170157; batch adversarial loss: 0.423049\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158393; batch adversarial loss: 0.543420\n",
      "epoch 64; iter: 0; batch classifier loss: 0.156613; batch adversarial loss: 0.495712\n",
      "epoch 65; iter: 0; batch classifier loss: 0.206266; batch adversarial loss: 0.458155\n",
      "epoch 66; iter: 0; batch classifier loss: 0.227273; batch adversarial loss: 0.471361\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184123; batch adversarial loss: 0.483194\n",
      "epoch 68; iter: 0; batch classifier loss: 0.128382; batch adversarial loss: 0.482771\n",
      "epoch 69; iter: 0; batch classifier loss: 0.159772; batch adversarial loss: 0.457936\n",
      "epoch 70; iter: 0; batch classifier loss: 0.210643; batch adversarial loss: 0.498018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.163976; batch adversarial loss: 0.495996\n",
      "epoch 72; iter: 0; batch classifier loss: 0.153458; batch adversarial loss: 0.506240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.183464; batch adversarial loss: 0.493583\n",
      "epoch 74; iter: 0; batch classifier loss: 0.241736; batch adversarial loss: 0.433800\n",
      "epoch 75; iter: 0; batch classifier loss: 0.201274; batch adversarial loss: 0.530601\n",
      "epoch 76; iter: 0; batch classifier loss: 0.197001; batch adversarial loss: 0.543991\n",
      "epoch 77; iter: 0; batch classifier loss: 0.203513; batch adversarial loss: 0.422910\n",
      "epoch 78; iter: 0; batch classifier loss: 0.173676; batch adversarial loss: 0.362025\n",
      "epoch 79; iter: 0; batch classifier loss: 0.173534; batch adversarial loss: 0.458748\n",
      "epoch 80; iter: 0; batch classifier loss: 0.187770; batch adversarial loss: 0.458201\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221177; batch adversarial loss: 0.387239\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156335; batch adversarial loss: 0.410757\n",
      "epoch 83; iter: 0; batch classifier loss: 0.176928; batch adversarial loss: 0.470980\n",
      "epoch 84; iter: 0; batch classifier loss: 0.189397; batch adversarial loss: 0.507395\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157970; batch adversarial loss: 0.471080\n",
      "epoch 86; iter: 0; batch classifier loss: 0.185801; batch adversarial loss: 0.495691\n",
      "epoch 87; iter: 0; batch classifier loss: 0.105331; batch adversarial loss: 0.592456\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076227; batch adversarial loss: 0.458742\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063424; batch adversarial loss: 0.472477\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040905; batch adversarial loss: 0.470724\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078469; batch adversarial loss: 0.492271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055933; batch adversarial loss: 0.508941\n",
      "epoch 93; iter: 0; batch classifier loss: 0.081069; batch adversarial loss: 0.449598\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047092; batch adversarial loss: 0.421952\n",
      "epoch 95; iter: 0; batch classifier loss: 0.111430; batch adversarial loss: 0.482626\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090749; batch adversarial loss: 0.404298\n",
      "epoch 97; iter: 0; batch classifier loss: 0.082427; batch adversarial loss: 0.514326\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077392; batch adversarial loss: 0.387358\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048748; batch adversarial loss: 0.441343\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059869; batch adversarial loss: 0.505414\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072290; batch adversarial loss: 0.468495\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059809; batch adversarial loss: 0.458459\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064052; batch adversarial loss: 0.418569\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053330; batch adversarial loss: 0.463125\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042672; batch adversarial loss: 0.552029\n",
      "epoch 106; iter: 0; batch classifier loss: 0.031438; batch adversarial loss: 0.364601\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050197; batch adversarial loss: 0.475108\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056158; batch adversarial loss: 0.332877\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029304; batch adversarial loss: 0.536846\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046867; batch adversarial loss: 0.475458\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026851; batch adversarial loss: 0.426711\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037678; batch adversarial loss: 0.409985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038673; batch adversarial loss: 0.440653\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063097; batch adversarial loss: 0.549741\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026437; batch adversarial loss: 0.500668\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.423885\n",
      "epoch 117; iter: 0; batch classifier loss: 0.011488; batch adversarial loss: 0.466903\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025632; batch adversarial loss: 0.360171\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021349; batch adversarial loss: 0.493640\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024360; batch adversarial loss: 0.439181\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071525; batch adversarial loss: 0.486764\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030594; batch adversarial loss: 0.432683\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033471; batch adversarial loss: 0.549173\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022016; batch adversarial loss: 0.517677\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022660; batch adversarial loss: 0.468271\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023627; batch adversarial loss: 0.501679\n",
      "epoch 127; iter: 0; batch classifier loss: 0.007043; batch adversarial loss: 0.483829\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025876; batch adversarial loss: 0.444826\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021757; batch adversarial loss: 0.432416\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028002; batch adversarial loss: 0.385324\n",
      "epoch 131; iter: 0; batch classifier loss: 0.012172; batch adversarial loss: 0.415003\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020439; batch adversarial loss: 0.480386\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046053; batch adversarial loss: 0.462854\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016212; batch adversarial loss: 0.500749\n",
      "epoch 135; iter: 0; batch classifier loss: 0.009949; batch adversarial loss: 0.426603\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047874; batch adversarial loss: 0.531598\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034656; batch adversarial loss: 0.453803\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015858; batch adversarial loss: 0.481099\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032579; batch adversarial loss: 0.435096\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.524838\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040407; batch adversarial loss: 0.531907\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030349; batch adversarial loss: 0.377731\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021475; batch adversarial loss: 0.453344\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023310; batch adversarial loss: 0.421003\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021971; batch adversarial loss: 0.487903\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016175; batch adversarial loss: 0.465819\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035375; batch adversarial loss: 0.400303\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019109; batch adversarial loss: 0.370853\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019618; batch adversarial loss: 0.407451\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014523; batch adversarial loss: 0.521391\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026924; batch adversarial loss: 0.403972\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046351; batch adversarial loss: 0.468928\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007000; batch adversarial loss: 0.511451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012400; batch adversarial loss: 0.436858\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031106; batch adversarial loss: 0.478438\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016946; batch adversarial loss: 0.504536\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008693; batch adversarial loss: 0.471166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.005201; batch adversarial loss: 0.452195\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029189; batch adversarial loss: 0.398910\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009539; batch adversarial loss: 0.520429\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005237; batch adversarial loss: 0.506535\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021456; batch adversarial loss: 0.460129\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011495; batch adversarial loss: 0.473543\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005387; batch adversarial loss: 0.517732\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007798; batch adversarial loss: 0.409011\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031603; batch adversarial loss: 0.499696\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024618; batch adversarial loss: 0.457464\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008370; batch adversarial loss: 0.310190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018113; batch adversarial loss: 0.431900\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042749; batch adversarial loss: 0.419293\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041806; batch adversarial loss: 0.549966\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025862; batch adversarial loss: 0.490926\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006856; batch adversarial loss: 0.375416\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008439; batch adversarial loss: 0.450810\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024942; batch adversarial loss: 0.454846\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028449; batch adversarial loss: 0.437696\n",
      "epoch 177; iter: 0; batch classifier loss: 0.005606; batch adversarial loss: 0.463586\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010508; batch adversarial loss: 0.462678\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023876; batch adversarial loss: 0.455604\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015420; batch adversarial loss: 0.463238\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017287; batch adversarial loss: 0.407742\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019443; batch adversarial loss: 0.477109\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.425692\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012560; batch adversarial loss: 0.429714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.047511; batch adversarial loss: 0.485402\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010689; batch adversarial loss: 0.496714\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010093; batch adversarial loss: 0.526374\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019202; batch adversarial loss: 0.496787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012955; batch adversarial loss: 0.481901\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.528009\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003351; batch adversarial loss: 0.460366\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002338; batch adversarial loss: 0.432795\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005841; batch adversarial loss: 0.513991\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026488; batch adversarial loss: 0.539419\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008854; batch adversarial loss: 0.442968\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022139; batch adversarial loss: 0.447660\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017698; batch adversarial loss: 0.425875\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025483; batch adversarial loss: 0.432399\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024598; batch adversarial loss: 0.375198\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702693; batch adversarial loss: 0.466431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400746; batch adversarial loss: 0.554372\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437607; batch adversarial loss: 0.616004\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395536; batch adversarial loss: 0.555002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354028; batch adversarial loss: 0.538492\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418621; batch adversarial loss: 0.595165\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368471; batch adversarial loss: 0.559512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308702; batch adversarial loss: 0.577752\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273467; batch adversarial loss: 0.561641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326843; batch adversarial loss: 0.552875\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517848; batch adversarial loss: 0.502244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372720; batch adversarial loss: 0.563542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412214; batch adversarial loss: 0.537317\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363643; batch adversarial loss: 0.478661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390094; batch adversarial loss: 0.556374\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505555; batch adversarial loss: 0.559271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.647833; batch adversarial loss: 0.502023\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317304; batch adversarial loss: 0.489580\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245102; batch adversarial loss: 0.483058\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236127; batch adversarial loss: 0.456511\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202099; batch adversarial loss: 0.469565\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138324; batch adversarial loss: 0.474696\n",
      "epoch 22; iter: 0; batch classifier loss: 0.200456; batch adversarial loss: 0.391375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195289; batch adversarial loss: 0.475776\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210369; batch adversarial loss: 0.406797\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196281; batch adversarial loss: 0.452538\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159682; batch adversarial loss: 0.431619\n",
      "epoch 27; iter: 0; batch classifier loss: 0.168542; batch adversarial loss: 0.440158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.128639; batch adversarial loss: 0.503371\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147815; batch adversarial loss: 0.425139\n",
      "epoch 30; iter: 0; batch classifier loss: 0.203622; batch adversarial loss: 0.448350\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160137; batch adversarial loss: 0.510640\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157592; batch adversarial loss: 0.406754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.146810; batch adversarial loss: 0.425939\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118002; batch adversarial loss: 0.447942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148269; batch adversarial loss: 0.454241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102830; batch adversarial loss: 0.495118\n",
      "epoch 37; iter: 0; batch classifier loss: 0.135784; batch adversarial loss: 0.422149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115591; batch adversarial loss: 0.415098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125505; batch adversarial loss: 0.407230\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137141; batch adversarial loss: 0.492320\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144655; batch adversarial loss: 0.344142\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151228; batch adversarial loss: 0.444284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.154627; batch adversarial loss: 0.437891\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118612; batch adversarial loss: 0.473676\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119992; batch adversarial loss: 0.478268\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098341; batch adversarial loss: 0.367052\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109538; batch adversarial loss: 0.456372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112268; batch adversarial loss: 0.437728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092669; batch adversarial loss: 0.512527\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117767; batch adversarial loss: 0.410709\n",
      "epoch 51; iter: 0; batch classifier loss: 0.138992; batch adversarial loss: 0.414131\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125909; batch adversarial loss: 0.486992\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125528; batch adversarial loss: 0.465496\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142063; batch adversarial loss: 0.462894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55; iter: 0; batch classifier loss: 0.221200; batch adversarial loss: 0.420210\n",
      "epoch 56; iter: 0; batch classifier loss: 0.163405; batch adversarial loss: 0.470696\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125316; batch adversarial loss: 0.428654\n",
      "epoch 58; iter: 0; batch classifier loss: 0.224872; batch adversarial loss: 0.448488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.145061; batch adversarial loss: 0.495720\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115035; batch adversarial loss: 0.452086\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133116; batch adversarial loss: 0.395574\n",
      "epoch 62; iter: 0; batch classifier loss: 0.110776; batch adversarial loss: 0.467902\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095713; batch adversarial loss: 0.372704\n",
      "epoch 64; iter: 0; batch classifier loss: 0.132674; batch adversarial loss: 0.505750\n",
      "epoch 65; iter: 0; batch classifier loss: 0.154390; batch adversarial loss: 0.435548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.131926; batch adversarial loss: 0.430634\n",
      "epoch 67; iter: 0; batch classifier loss: 0.158384; batch adversarial loss: 0.452678\n",
      "epoch 68; iter: 0; batch classifier loss: 0.128939; batch adversarial loss: 0.453151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122249; batch adversarial loss: 0.495999\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131645; batch adversarial loss: 0.425688\n",
      "epoch 71; iter: 0; batch classifier loss: 0.138846; batch adversarial loss: 0.463591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.161854; batch adversarial loss: 0.508661\n",
      "epoch 73; iter: 0; batch classifier loss: 0.162164; batch adversarial loss: 0.445128\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075795; batch adversarial loss: 0.528024\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159271; batch adversarial loss: 0.554686\n",
      "epoch 76; iter: 0; batch classifier loss: 0.111483; batch adversarial loss: 0.482352\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086718; batch adversarial loss: 0.456733\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112961; batch adversarial loss: 0.396880\n",
      "epoch 79; iter: 0; batch classifier loss: 0.154495; batch adversarial loss: 0.419327\n",
      "epoch 80; iter: 0; batch classifier loss: 0.128629; batch adversarial loss: 0.441394\n",
      "epoch 81; iter: 0; batch classifier loss: 0.131004; batch adversarial loss: 0.495034\n",
      "epoch 82; iter: 0; batch classifier loss: 0.129815; batch adversarial loss: 0.483166\n",
      "epoch 83; iter: 0; batch classifier loss: 0.103209; batch adversarial loss: 0.530483\n",
      "epoch 84; iter: 0; batch classifier loss: 0.175908; batch adversarial loss: 0.486860\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091663; batch adversarial loss: 0.448561\n",
      "epoch 86; iter: 0; batch classifier loss: 0.226010; batch adversarial loss: 0.432449\n",
      "epoch 87; iter: 0; batch classifier loss: 0.084909; batch adversarial loss: 0.508796\n",
      "epoch 88; iter: 0; batch classifier loss: 0.141051; batch adversarial loss: 0.366954\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074714; batch adversarial loss: 0.471517\n",
      "epoch 90; iter: 0; batch classifier loss: 0.109475; batch adversarial loss: 0.523293\n",
      "epoch 91; iter: 0; batch classifier loss: 0.129487; batch adversarial loss: 0.389904\n",
      "epoch 92; iter: 0; batch classifier loss: 0.103159; batch adversarial loss: 0.466544\n",
      "epoch 93; iter: 0; batch classifier loss: 0.106450; batch adversarial loss: 0.478285\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093902; batch adversarial loss: 0.473583\n",
      "epoch 95; iter: 0; batch classifier loss: 0.110761; batch adversarial loss: 0.458180\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085090; batch adversarial loss: 0.465701\n",
      "epoch 97; iter: 0; batch classifier loss: 0.140006; batch adversarial loss: 0.360819\n",
      "epoch 98; iter: 0; batch classifier loss: 0.069124; batch adversarial loss: 0.563809\n",
      "epoch 99; iter: 0; batch classifier loss: 0.108961; batch adversarial loss: 0.407341\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057520; batch adversarial loss: 0.635946\n",
      "epoch 101; iter: 0; batch classifier loss: 0.096115; batch adversarial loss: 0.480926\n",
      "epoch 102; iter: 0; batch classifier loss: 0.201863; batch adversarial loss: 0.430566\n",
      "epoch 103; iter: 0; batch classifier loss: 0.146726; batch adversarial loss: 0.411596\n",
      "epoch 104; iter: 0; batch classifier loss: 0.097219; batch adversarial loss: 0.443960\n",
      "epoch 105; iter: 0; batch classifier loss: 0.122322; batch adversarial loss: 0.396264\n",
      "epoch 106; iter: 0; batch classifier loss: 0.184676; batch adversarial loss: 0.395818\n",
      "epoch 107; iter: 0; batch classifier loss: 0.131235; batch adversarial loss: 0.404231\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042009; batch adversarial loss: 0.581749\n",
      "epoch 109; iter: 0; batch classifier loss: 0.083952; batch adversarial loss: 0.458768\n",
      "epoch 110; iter: 0; batch classifier loss: 0.126609; batch adversarial loss: 0.504687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.103892; batch adversarial loss: 0.400590\n",
      "epoch 112; iter: 0; batch classifier loss: 0.116836; batch adversarial loss: 0.493287\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052112; batch adversarial loss: 0.464970\n",
      "epoch 114; iter: 0; batch classifier loss: 0.072054; batch adversarial loss: 0.510321\n",
      "epoch 115; iter: 0; batch classifier loss: 0.087719; batch adversarial loss: 0.508775\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048015; batch adversarial loss: 0.520970\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056055; batch adversarial loss: 0.421297\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039700; batch adversarial loss: 0.411571\n",
      "epoch 119; iter: 0; batch classifier loss: 0.104644; batch adversarial loss: 0.427296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.093658; batch adversarial loss: 0.453903\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046222; batch adversarial loss: 0.412467\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035249; batch adversarial loss: 0.489373\n",
      "epoch 123; iter: 0; batch classifier loss: 0.079388; batch adversarial loss: 0.451010\n",
      "epoch 124; iter: 0; batch classifier loss: 0.090530; batch adversarial loss: 0.578809\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044444; batch adversarial loss: 0.496498\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034158; batch adversarial loss: 0.398886\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039846; batch adversarial loss: 0.415922\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041921; batch adversarial loss: 0.504468\n",
      "epoch 129; iter: 0; batch classifier loss: 0.095040; batch adversarial loss: 0.392320\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034151; batch adversarial loss: 0.465265\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049028; batch adversarial loss: 0.449179\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068717; batch adversarial loss: 0.536475\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056840; batch adversarial loss: 0.506148\n",
      "epoch 134; iter: 0; batch classifier loss: 0.058805; batch adversarial loss: 0.416481\n",
      "epoch 135; iter: 0; batch classifier loss: 0.064363; batch adversarial loss: 0.496962\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035205; batch adversarial loss: 0.482646\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048333; batch adversarial loss: 0.457270\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060165; batch adversarial loss: 0.404186\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031376; batch adversarial loss: 0.449650\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068530; batch adversarial loss: 0.439886\n",
      "epoch 141; iter: 0; batch classifier loss: 0.071115; batch adversarial loss: 0.398211\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057732; batch adversarial loss: 0.462556\n",
      "epoch 143; iter: 0; batch classifier loss: 0.048930; batch adversarial loss: 0.514045\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053805; batch adversarial loss: 0.344186\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040630; batch adversarial loss: 0.405597\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052336; batch adversarial loss: 0.409386\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062723; batch adversarial loss: 0.497567\n",
      "epoch 148; iter: 0; batch classifier loss: 0.058055; batch adversarial loss: 0.468406\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038418; batch adversarial loss: 0.388865\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037507; batch adversarial loss: 0.441928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.074045; batch adversarial loss: 0.382185\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.472580\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031721; batch adversarial loss: 0.446070\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036929; batch adversarial loss: 0.344708\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030402; batch adversarial loss: 0.544096\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041699; batch adversarial loss: 0.433327\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030770; batch adversarial loss: 0.470512\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037827; batch adversarial loss: 0.441299\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032044; batch adversarial loss: 0.421126\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027011; batch adversarial loss: 0.462967\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036552; batch adversarial loss: 0.474768\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020785; batch adversarial loss: 0.683219\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045171; batch adversarial loss: 0.411872\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054604; batch adversarial loss: 0.477603\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010289; batch adversarial loss: 0.431655\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062086; batch adversarial loss: 0.391954\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040388; batch adversarial loss: 0.420083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037228; batch adversarial loss: 0.562345\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043673; batch adversarial loss: 0.393300\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011983; batch adversarial loss: 0.485724\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018855; batch adversarial loss: 0.421228\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016583; batch adversarial loss: 0.405129\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041715; batch adversarial loss: 0.372517\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016227; batch adversarial loss: 0.389196\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040458; batch adversarial loss: 0.381237\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053279; batch adversarial loss: 0.417612\n",
      "epoch 177; iter: 0; batch classifier loss: 0.089496; batch adversarial loss: 0.436134\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049336; batch adversarial loss: 0.422505\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025426; batch adversarial loss: 0.477116\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032311; batch adversarial loss: 0.454737\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035973; batch adversarial loss: 0.485099\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029168; batch adversarial loss: 0.451124\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029985; batch adversarial loss: 0.437186\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011640; batch adversarial loss: 0.455176\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027827; batch adversarial loss: 0.380096\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023915; batch adversarial loss: 0.429712\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019089; batch adversarial loss: 0.464035\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015228; batch adversarial loss: 0.535957\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023168; batch adversarial loss: 0.406148\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012472; batch adversarial loss: 0.320719\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014100; batch adversarial loss: 0.482629\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009999; batch adversarial loss: 0.432153\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026822; batch adversarial loss: 0.406464\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040410; batch adversarial loss: 0.430287\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033400; batch adversarial loss: 0.396537\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025152; batch adversarial loss: 0.502438\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019948; batch adversarial loss: 0.504871\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019372; batch adversarial loss: 0.446026\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024107; batch adversarial loss: 0.358806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689402; batch adversarial loss: 0.994969\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718808; batch adversarial loss: 1.195656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.840632; batch adversarial loss: 1.220296\n",
      "epoch 3; iter: 0; batch classifier loss: 0.969261; batch adversarial loss: 1.127576\n",
      "epoch 4; iter: 0; batch classifier loss: 0.881304; batch adversarial loss: 0.994547\n",
      "epoch 5; iter: 0; batch classifier loss: 1.158532; batch adversarial loss: 0.919224\n",
      "epoch 6; iter: 0; batch classifier loss: 1.033332; batch adversarial loss: 0.834769\n",
      "epoch 7; iter: 0; batch classifier loss: 1.173496; batch adversarial loss: 0.766864\n",
      "epoch 8; iter: 0; batch classifier loss: 1.138116; batch adversarial loss: 0.687583\n",
      "epoch 9; iter: 0; batch classifier loss: 0.934535; batch adversarial loss: 0.698813\n",
      "epoch 10; iter: 0; batch classifier loss: 0.933707; batch adversarial loss: 0.602113\n",
      "epoch 11; iter: 0; batch classifier loss: 1.019747; batch adversarial loss: 0.559724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.844641; batch adversarial loss: 0.530853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390803; batch adversarial loss: 0.516993\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298015; batch adversarial loss: 0.480680\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318916; batch adversarial loss: 0.498382\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311436; batch adversarial loss: 0.491382\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294611; batch adversarial loss: 0.478384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250973; batch adversarial loss: 0.527146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.246127; batch adversarial loss: 0.486993\n",
      "epoch 20; iter: 0; batch classifier loss: 0.323982; batch adversarial loss: 0.498041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.471942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.337520; batch adversarial loss: 0.481446\n",
      "epoch 23; iter: 0; batch classifier loss: 0.337685; batch adversarial loss: 0.448547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267940; batch adversarial loss: 0.480724\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290984; batch adversarial loss: 0.475315\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329089; batch adversarial loss: 0.460129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254232; batch adversarial loss: 0.442990\n",
      "epoch 28; iter: 0; batch classifier loss: 0.240891; batch adversarial loss: 0.510999\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258355; batch adversarial loss: 0.527622\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205930; batch adversarial loss: 0.432411\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226443; batch adversarial loss: 0.486700\n",
      "epoch 32; iter: 0; batch classifier loss: 0.260348; batch adversarial loss: 0.500178\n",
      "epoch 33; iter: 0; batch classifier loss: 0.200377; batch adversarial loss: 0.481931\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202895; batch adversarial loss: 0.555036\n",
      "epoch 35; iter: 0; batch classifier loss: 0.186620; batch adversarial loss: 0.506932\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165548; batch adversarial loss: 0.522011\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202271; batch adversarial loss: 0.442827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209863; batch adversarial loss: 0.457482\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185195; batch adversarial loss: 0.553582\n",
      "epoch 40; iter: 0; batch classifier loss: 0.178652; batch adversarial loss: 0.446327\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140014; batch adversarial loss: 0.525364\n",
      "epoch 42; iter: 0; batch classifier loss: 0.181362; batch adversarial loss: 0.431773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128885; batch adversarial loss: 0.444756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123773; batch adversarial loss: 0.462991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130801; batch adversarial loss: 0.395320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.137097; batch adversarial loss: 0.467472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 0; batch classifier loss: 0.152315; batch adversarial loss: 0.488799\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157224; batch adversarial loss: 0.530897\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155823; batch adversarial loss: 0.500821\n",
      "epoch 50; iter: 0; batch classifier loss: 0.146587; batch adversarial loss: 0.392828\n",
      "epoch 51; iter: 0; batch classifier loss: 0.160105; batch adversarial loss: 0.465310\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134377; batch adversarial loss: 0.413294\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171279; batch adversarial loss: 0.366596\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158429; batch adversarial loss: 0.518482\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077301; batch adversarial loss: 0.476987\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153863; batch adversarial loss: 0.382644\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127527; batch adversarial loss: 0.454899\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132068; batch adversarial loss: 0.439914\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109551; batch adversarial loss: 0.565530\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132164; batch adversarial loss: 0.566683\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152682; batch adversarial loss: 0.368465\n",
      "epoch 62; iter: 0; batch classifier loss: 0.126179; batch adversarial loss: 0.433291\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121398; batch adversarial loss: 0.400992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.095077; batch adversarial loss: 0.425230\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080195; batch adversarial loss: 0.456238\n",
      "epoch 66; iter: 0; batch classifier loss: 0.130720; batch adversarial loss: 0.432235\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135368; batch adversarial loss: 0.440602\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106046; batch adversarial loss: 0.426426\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110864; batch adversarial loss: 0.494294\n",
      "epoch 70; iter: 0; batch classifier loss: 0.154549; batch adversarial loss: 0.409881\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088211; batch adversarial loss: 0.448777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103494; batch adversarial loss: 0.520557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090004; batch adversarial loss: 0.456810\n",
      "epoch 74; iter: 0; batch classifier loss: 0.117045; batch adversarial loss: 0.372447\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104319; batch adversarial loss: 0.357097\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091522; batch adversarial loss: 0.453087\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114491; batch adversarial loss: 0.522417\n",
      "epoch 78; iter: 0; batch classifier loss: 0.069733; batch adversarial loss: 0.481465\n",
      "epoch 79; iter: 0; batch classifier loss: 0.111424; batch adversarial loss: 0.423463\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137935; batch adversarial loss: 0.471502\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105274; batch adversarial loss: 0.495646\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068923; batch adversarial loss: 0.434912\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073486; batch adversarial loss: 0.415472\n",
      "epoch 84; iter: 0; batch classifier loss: 0.125146; batch adversarial loss: 0.420878\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085036; batch adversarial loss: 0.400724\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076263; batch adversarial loss: 0.465216\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085835; batch adversarial loss: 0.483288\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054652; batch adversarial loss: 0.451801\n",
      "epoch 89; iter: 0; batch classifier loss: 0.110181; batch adversarial loss: 0.411974\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059971; batch adversarial loss: 0.512797\n",
      "epoch 91; iter: 0; batch classifier loss: 0.108756; batch adversarial loss: 0.418080\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063216; batch adversarial loss: 0.472725\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113980; batch adversarial loss: 0.446816\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073724; batch adversarial loss: 0.507365\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074150; batch adversarial loss: 0.532150\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068664; batch adversarial loss: 0.534488\n",
      "epoch 97; iter: 0; batch classifier loss: 0.113590; batch adversarial loss: 0.451652\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081650; batch adversarial loss: 0.472512\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070505; batch adversarial loss: 0.531574\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049521; batch adversarial loss: 0.482492\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063087; batch adversarial loss: 0.524128\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048608; batch adversarial loss: 0.404087\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091537; batch adversarial loss: 0.508774\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059678; batch adversarial loss: 0.563886\n",
      "epoch 105; iter: 0; batch classifier loss: 0.023152; batch adversarial loss: 0.461050\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087988; batch adversarial loss: 0.449051\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066078; batch adversarial loss: 0.433003\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041465; batch adversarial loss: 0.526868\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030267; batch adversarial loss: 0.466020\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092732; batch adversarial loss: 0.422050\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073746; batch adversarial loss: 0.560743\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057256; batch adversarial loss: 0.419895\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046795; batch adversarial loss: 0.410836\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082742; batch adversarial loss: 0.440015\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045885; batch adversarial loss: 0.452851\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050273; batch adversarial loss: 0.509760\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040955; batch adversarial loss: 0.406481\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024568; batch adversarial loss: 0.520793\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036843; batch adversarial loss: 0.513984\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049779; batch adversarial loss: 0.402402\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037735; batch adversarial loss: 0.438201\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063952; batch adversarial loss: 0.508525\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057692; batch adversarial loss: 0.490087\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059047; batch adversarial loss: 0.394659\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027194; batch adversarial loss: 0.431725\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040301; batch adversarial loss: 0.354945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067663; batch adversarial loss: 0.419742\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035334; batch adversarial loss: 0.503225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033270; batch adversarial loss: 0.454707\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052392; batch adversarial loss: 0.433287\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041908; batch adversarial loss: 0.475995\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024862; batch adversarial loss: 0.377637\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034411; batch adversarial loss: 0.487263\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063116; batch adversarial loss: 0.430858\n",
      "epoch 135; iter: 0; batch classifier loss: 0.085795; batch adversarial loss: 0.496198\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048063; batch adversarial loss: 0.411083\n",
      "epoch 137; iter: 0; batch classifier loss: 0.013065; batch adversarial loss: 0.376442\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.410446\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036412; batch adversarial loss: 0.382847\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019577; batch adversarial loss: 0.383326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061245; batch adversarial loss: 0.497738\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041808; batch adversarial loss: 0.408263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 143; iter: 0; batch classifier loss: 0.017082; batch adversarial loss: 0.452559\n",
      "epoch 144; iter: 0; batch classifier loss: 0.006777; batch adversarial loss: 0.586832\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055229; batch adversarial loss: 0.513477\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038476; batch adversarial loss: 0.450020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029899; batch adversarial loss: 0.391603\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021264; batch adversarial loss: 0.301357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020181; batch adversarial loss: 0.488258\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038867; batch adversarial loss: 0.421738\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021586; batch adversarial loss: 0.445501\n",
      "epoch 152; iter: 0; batch classifier loss: 0.064061; batch adversarial loss: 0.496174\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015976; batch adversarial loss: 0.522331\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021807; batch adversarial loss: 0.463677\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034126; batch adversarial loss: 0.439108\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037464; batch adversarial loss: 0.409950\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030380; batch adversarial loss: 0.444194\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041447; batch adversarial loss: 0.479119\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031836; batch adversarial loss: 0.457518\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019591; batch adversarial loss: 0.357430\n",
      "epoch 161; iter: 0; batch classifier loss: 0.051068; batch adversarial loss: 0.439572\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044037; batch adversarial loss: 0.457851\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006158; batch adversarial loss: 0.466416\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030797; batch adversarial loss: 0.395945\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012027; batch adversarial loss: 0.419496\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032042; batch adversarial loss: 0.542407\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034944; batch adversarial loss: 0.473954\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044367; batch adversarial loss: 0.594698\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017313; batch adversarial loss: 0.418275\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009344; batch adversarial loss: 0.485106\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013484; batch adversarial loss: 0.364031\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051691; batch adversarial loss: 0.504866\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012149; batch adversarial loss: 0.437040\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033565; batch adversarial loss: 0.544445\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049734; batch adversarial loss: 0.389987\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022326; batch adversarial loss: 0.457909\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008920; batch adversarial loss: 0.390650\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022838; batch adversarial loss: 0.436411\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044990; batch adversarial loss: 0.494569\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041245; batch adversarial loss: 0.350816\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030651; batch adversarial loss: 0.418175\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024716; batch adversarial loss: 0.492307\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.484973\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010863; batch adversarial loss: 0.441530\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008255; batch adversarial loss: 0.448663\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055561; batch adversarial loss: 0.438963\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039989; batch adversarial loss: 0.372934\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019910; batch adversarial loss: 0.409080\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015508; batch adversarial loss: 0.473691\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.463878\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029671; batch adversarial loss: 0.433328\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021506; batch adversarial loss: 0.467391\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018083; batch adversarial loss: 0.452332\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005519; batch adversarial loss: 0.467597\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.418032\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007161; batch adversarial loss: 0.430737\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015142; batch adversarial loss: 0.427803\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021822; batch adversarial loss: 0.449556\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012867; batch adversarial loss: 0.536351\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662979; batch adversarial loss: 0.537686\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472053; batch adversarial loss: 0.601331\n",
      "epoch 2; iter: 0; batch classifier loss: 0.405825; batch adversarial loss: 0.619325\n",
      "epoch 3; iter: 0; batch classifier loss: 0.389527; batch adversarial loss: 0.633880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.383764; batch adversarial loss: 0.547021\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447968; batch adversarial loss: 0.544697\n",
      "epoch 6; iter: 0; batch classifier loss: 0.525517; batch adversarial loss: 0.611526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539487; batch adversarial loss: 0.631031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.626447; batch adversarial loss: 0.619835\n",
      "epoch 9; iter: 0; batch classifier loss: 0.620870; batch adversarial loss: 0.577698\n",
      "epoch 10; iter: 0; batch classifier loss: 0.524280; batch adversarial loss: 0.512409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551074; batch adversarial loss: 0.498190\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372401; batch adversarial loss: 0.466002\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258201; batch adversarial loss: 0.554227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302049; batch adversarial loss: 0.453694\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277219; batch adversarial loss: 0.504425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223448; batch adversarial loss: 0.483620\n",
      "epoch 17; iter: 0; batch classifier loss: 0.324669; batch adversarial loss: 0.485384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175392; batch adversarial loss: 0.444084\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182077; batch adversarial loss: 0.439591\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252804; batch adversarial loss: 0.431909\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169454; batch adversarial loss: 0.497629\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222642; batch adversarial loss: 0.401721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179449; batch adversarial loss: 0.431488\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193924; batch adversarial loss: 0.411869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.186026; batch adversarial loss: 0.478800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201245; batch adversarial loss: 0.447445\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164892; batch adversarial loss: 0.499607\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160777; batch adversarial loss: 0.489555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168602; batch adversarial loss: 0.434002\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171989; batch adversarial loss: 0.470592\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152894; batch adversarial loss: 0.445578\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159904; batch adversarial loss: 0.469572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207563; batch adversarial loss: 0.426076\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144537; batch adversarial loss: 0.387485\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125065; batch adversarial loss: 0.474693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189730; batch adversarial loss: 0.479303\n",
      "epoch 37; iter: 0; batch classifier loss: 0.188347; batch adversarial loss: 0.444366\n",
      "epoch 38; iter: 0; batch classifier loss: 0.127265; batch adversarial loss: 0.417845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.152142; batch adversarial loss: 0.502657\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148169; batch adversarial loss: 0.482289\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156310; batch adversarial loss: 0.473785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124522; batch adversarial loss: 0.498821\n",
      "epoch 43; iter: 0; batch classifier loss: 0.192812; batch adversarial loss: 0.433206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.152629; batch adversarial loss: 0.589664\n",
      "epoch 45; iter: 0; batch classifier loss: 0.143145; batch adversarial loss: 0.436003\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187758; batch adversarial loss: 0.525243\n",
      "epoch 47; iter: 0; batch classifier loss: 0.204282; batch adversarial loss: 0.468586\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180588; batch adversarial loss: 0.408597\n",
      "epoch 49; iter: 0; batch classifier loss: 0.139879; batch adversarial loss: 0.444153\n",
      "epoch 50; iter: 0; batch classifier loss: 0.172658; batch adversarial loss: 0.476711\n",
      "epoch 51; iter: 0; batch classifier loss: 0.194404; batch adversarial loss: 0.449256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.219550; batch adversarial loss: 0.460060\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191586; batch adversarial loss: 0.433234\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158188; batch adversarial loss: 0.531634\n",
      "epoch 55; iter: 0; batch classifier loss: 0.196749; batch adversarial loss: 0.380000\n",
      "epoch 56; iter: 0; batch classifier loss: 0.179422; batch adversarial loss: 0.484840\n",
      "epoch 57; iter: 0; batch classifier loss: 0.184082; batch adversarial loss: 0.493036\n",
      "epoch 58; iter: 0; batch classifier loss: 0.237252; batch adversarial loss: 0.511321\n",
      "epoch 59; iter: 0; batch classifier loss: 0.182622; batch adversarial loss: 0.424080\n",
      "epoch 60; iter: 0; batch classifier loss: 0.222705; batch adversarial loss: 0.446570\n",
      "epoch 61; iter: 0; batch classifier loss: 0.232644; batch adversarial loss: 0.362458\n",
      "epoch 62; iter: 0; batch classifier loss: 0.172980; batch adversarial loss: 0.410546\n",
      "epoch 63; iter: 0; batch classifier loss: 0.259569; batch adversarial loss: 0.411822\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167560; batch adversarial loss: 0.459056\n",
      "epoch 65; iter: 0; batch classifier loss: 0.173740; batch adversarial loss: 0.448508\n",
      "epoch 66; iter: 0; batch classifier loss: 0.248258; batch adversarial loss: 0.497004\n",
      "epoch 67; iter: 0; batch classifier loss: 0.198638; batch adversarial loss: 0.422246\n",
      "epoch 68; iter: 0; batch classifier loss: 0.240070; batch adversarial loss: 0.519391\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073011; batch adversarial loss: 0.531414\n",
      "epoch 70; iter: 0; batch classifier loss: 0.134282; batch adversarial loss: 0.468243\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087105; batch adversarial loss: 0.508274\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072842; batch adversarial loss: 0.393719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068091; batch adversarial loss: 0.441806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061377; batch adversarial loss: 0.457705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057888; batch adversarial loss: 0.452787\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085698; batch adversarial loss: 0.472817\n",
      "epoch 77; iter: 0; batch classifier loss: 0.058490; batch adversarial loss: 0.475798\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077612; batch adversarial loss: 0.521174\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.455446\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066213; batch adversarial loss: 0.473299\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048411; batch adversarial loss: 0.493246\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045134; batch adversarial loss: 0.485278\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043832; batch adversarial loss: 0.481564\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056043; batch adversarial loss: 0.448546\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054923; batch adversarial loss: 0.427697\n",
      "epoch 86; iter: 0; batch classifier loss: 0.030195; batch adversarial loss: 0.518752\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038680; batch adversarial loss: 0.499378\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043939; batch adversarial loss: 0.488649\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064802; batch adversarial loss: 0.487120\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028137; batch adversarial loss: 0.498527\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028879; batch adversarial loss: 0.374560\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047597; batch adversarial loss: 0.407616\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038857; batch adversarial loss: 0.473099\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035762; batch adversarial loss: 0.368273\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036857; batch adversarial loss: 0.491669\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036569; batch adversarial loss: 0.389845\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041634; batch adversarial loss: 0.470625\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047457; batch adversarial loss: 0.425399\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052603; batch adversarial loss: 0.438848\n",
      "epoch 100; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.493777\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027805; batch adversarial loss: 0.513854\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081279; batch adversarial loss: 0.417260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071283; batch adversarial loss: 0.420357\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058789; batch adversarial loss: 0.398095\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051822; batch adversarial loss: 0.436807\n",
      "epoch 106; iter: 0; batch classifier loss: 0.082771; batch adversarial loss: 0.523018\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044853; batch adversarial loss: 0.455916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070034; batch adversarial loss: 0.471904\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069486; batch adversarial loss: 0.471224\n",
      "epoch 110; iter: 0; batch classifier loss: 0.095861; batch adversarial loss: 0.490948\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075072; batch adversarial loss: 0.395052\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052830; batch adversarial loss: 0.398380\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056566; batch adversarial loss: 0.415337\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061116; batch adversarial loss: 0.421616\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070880; batch adversarial loss: 0.427123\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038808; batch adversarial loss: 0.421477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060358; batch adversarial loss: 0.476974\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049167; batch adversarial loss: 0.456758\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.400190\n",
      "epoch 120; iter: 0; batch classifier loss: 0.087425; batch adversarial loss: 0.448401\n",
      "epoch 121; iter: 0; batch classifier loss: 0.073270; batch adversarial loss: 0.483228\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049029; batch adversarial loss: 0.461991\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050875; batch adversarial loss: 0.425565\n",
      "epoch 124; iter: 0; batch classifier loss: 0.061534; batch adversarial loss: 0.395922\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056507; batch adversarial loss: 0.513048\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036172; batch adversarial loss: 0.442627\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044734; batch adversarial loss: 0.423735\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033248; batch adversarial loss: 0.446419\n",
      "epoch 129; iter: 0; batch classifier loss: 0.061070; batch adversarial loss: 0.457674\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056347; batch adversarial loss: 0.469177\n",
      "epoch 131; iter: 0; batch classifier loss: 0.075352; batch adversarial loss: 0.382628\n",
      "epoch 132; iter: 0; batch classifier loss: 0.090591; batch adversarial loss: 0.432370\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.444380\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081244; batch adversarial loss: 0.484753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 135; iter: 0; batch classifier loss: 0.084765; batch adversarial loss: 0.394957\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057726; batch adversarial loss: 0.425021\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053492; batch adversarial loss: 0.491915\n",
      "epoch 138; iter: 0; batch classifier loss: 0.076242; batch adversarial loss: 0.419072\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050000; batch adversarial loss: 0.359192\n",
      "epoch 140; iter: 0; batch classifier loss: 0.061145; batch adversarial loss: 0.387751\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072140; batch adversarial loss: 0.380833\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041980; batch adversarial loss: 0.360968\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054462; batch adversarial loss: 0.410200\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049836; batch adversarial loss: 0.473616\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026276; batch adversarial loss: 0.462291\n",
      "epoch 146; iter: 0; batch classifier loss: 0.064779; batch adversarial loss: 0.443686\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039886; batch adversarial loss: 0.508211\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025191; batch adversarial loss: 0.414635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053673; batch adversarial loss: 0.519386\n",
      "epoch 150; iter: 0; batch classifier loss: 0.096374; batch adversarial loss: 0.443809\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.381395\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066337; batch adversarial loss: 0.391099\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027634; batch adversarial loss: 0.517964\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054330; batch adversarial loss: 0.367556\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045626; batch adversarial loss: 0.423235\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067143; batch adversarial loss: 0.435256\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057182; batch adversarial loss: 0.383827\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063573; batch adversarial loss: 0.437248\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043449; batch adversarial loss: 0.495745\n",
      "epoch 160; iter: 0; batch classifier loss: 0.069285; batch adversarial loss: 0.490662\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037923; batch adversarial loss: 0.479744\n",
      "epoch 162; iter: 0; batch classifier loss: 0.066777; batch adversarial loss: 0.432270\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060251; batch adversarial loss: 0.338762\n",
      "epoch 164; iter: 0; batch classifier loss: 0.064741; batch adversarial loss: 0.507922\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038916; batch adversarial loss: 0.391582\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041989; batch adversarial loss: 0.357060\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042819; batch adversarial loss: 0.525605\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052957; batch adversarial loss: 0.403593\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029338; batch adversarial loss: 0.407008\n",
      "epoch 170; iter: 0; batch classifier loss: 0.072613; batch adversarial loss: 0.373796\n",
      "epoch 171; iter: 0; batch classifier loss: 0.059001; batch adversarial loss: 0.449844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.051174; batch adversarial loss: 0.428151\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028230; batch adversarial loss: 0.526082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.038483; batch adversarial loss: 0.394358\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042267; batch adversarial loss: 0.397132\n",
      "epoch 176; iter: 0; batch classifier loss: 0.062418; batch adversarial loss: 0.436052\n",
      "epoch 177; iter: 0; batch classifier loss: 0.077742; batch adversarial loss: 0.506618\n",
      "epoch 178; iter: 0; batch classifier loss: 0.056144; batch adversarial loss: 0.444247\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.402425\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023412; batch adversarial loss: 0.497028\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020724; batch adversarial loss: 0.393509\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027004; batch adversarial loss: 0.538317\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045632; batch adversarial loss: 0.381579\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049359; batch adversarial loss: 0.424317\n",
      "epoch 185; iter: 0; batch classifier loss: 0.056200; batch adversarial loss: 0.436857\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040274; batch adversarial loss: 0.408694\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027989; batch adversarial loss: 0.448334\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043019; batch adversarial loss: 0.413191\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022471; batch adversarial loss: 0.468753\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020522; batch adversarial loss: 0.449759\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024194; batch adversarial loss: 0.375990\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023543; batch adversarial loss: 0.513304\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025549; batch adversarial loss: 0.376813\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020369; batch adversarial loss: 0.391369\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011715; batch adversarial loss: 0.459833\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.441494\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022211; batch adversarial loss: 0.388894\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020122; batch adversarial loss: 0.472082\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.477918\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682858; batch adversarial loss: 0.652674\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464695; batch adversarial loss: 0.626170\n",
      "epoch 2; iter: 0; batch classifier loss: 0.418229; batch adversarial loss: 0.612848\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314686; batch adversarial loss: 0.566595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342738; batch adversarial loss: 0.521688\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322487; batch adversarial loss: 0.546688\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339084; batch adversarial loss: 0.483983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.331892; batch adversarial loss: 0.520131\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314476; batch adversarial loss: 0.465805\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251459; batch adversarial loss: 0.505943\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232897; batch adversarial loss: 0.462206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220446; batch adversarial loss: 0.411380\n",
      "epoch 12; iter: 0; batch classifier loss: 0.204166; batch adversarial loss: 0.487921\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229457; batch adversarial loss: 0.460811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.221038; batch adversarial loss: 0.460875\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190583; batch adversarial loss: 0.452655\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190391; batch adversarial loss: 0.471360\n",
      "epoch 17; iter: 0; batch classifier loss: 0.169872; batch adversarial loss: 0.471900\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208015; batch adversarial loss: 0.507126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204283; batch adversarial loss: 0.432701\n",
      "epoch 20; iter: 0; batch classifier loss: 0.184531; batch adversarial loss: 0.420422\n",
      "epoch 21; iter: 0; batch classifier loss: 0.245017; batch adversarial loss: 0.481384\n",
      "epoch 22; iter: 0; batch classifier loss: 0.191267; batch adversarial loss: 0.430091\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195077; batch adversarial loss: 0.480231\n",
      "epoch 24; iter: 0; batch classifier loss: 0.127329; batch adversarial loss: 0.500496\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244081; batch adversarial loss: 0.518925\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165452; batch adversarial loss: 0.474872\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224602; batch adversarial loss: 0.531939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.272551; batch adversarial loss: 0.476581\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204586; batch adversarial loss: 0.435717\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368438; batch adversarial loss: 0.521355\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353996; batch adversarial loss: 0.433651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.345493; batch adversarial loss: 0.433611\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144684; batch adversarial loss: 0.459357\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149553; batch adversarial loss: 0.378166\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146592; batch adversarial loss: 0.508880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132231; batch adversarial loss: 0.506003\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104153; batch adversarial loss: 0.429768\n",
      "epoch 38; iter: 0; batch classifier loss: 0.084260; batch adversarial loss: 0.495788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.091492; batch adversarial loss: 0.409445\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091749; batch adversarial loss: 0.463698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174838; batch adversarial loss: 0.342295\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172018; batch adversarial loss: 0.488713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098222; batch adversarial loss: 0.461381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112228; batch adversarial loss: 0.510433\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115489; batch adversarial loss: 0.464772\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133087; batch adversarial loss: 0.403046\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105117; batch adversarial loss: 0.483397\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172711; batch adversarial loss: 0.308578\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125503; batch adversarial loss: 0.546432\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108386; batch adversarial loss: 0.444577\n",
      "epoch 51; iter: 0; batch classifier loss: 0.135405; batch adversarial loss: 0.414439\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112154; batch adversarial loss: 0.337031\n",
      "epoch 53; iter: 0; batch classifier loss: 0.145601; batch adversarial loss: 0.354365\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099405; batch adversarial loss: 0.442428\n",
      "epoch 55; iter: 0; batch classifier loss: 0.195022; batch adversarial loss: 0.455056\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105433; batch adversarial loss: 0.464055\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112229; batch adversarial loss: 0.448569\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087588; batch adversarial loss: 0.372907\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147871; batch adversarial loss: 0.411477\n",
      "epoch 60; iter: 0; batch classifier loss: 0.264446; batch adversarial loss: 0.443455\n",
      "epoch 61; iter: 0; batch classifier loss: 0.138236; batch adversarial loss: 0.407504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.163259; batch adversarial loss: 0.498908\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124799; batch adversarial loss: 0.268792\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125317; batch adversarial loss: 0.479903\n",
      "epoch 65; iter: 0; batch classifier loss: 0.102386; batch adversarial loss: 0.378193\n",
      "epoch 66; iter: 0; batch classifier loss: 0.137156; batch adversarial loss: 0.551429\n",
      "epoch 67; iter: 0; batch classifier loss: 0.138036; batch adversarial loss: 0.474141\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094742; batch adversarial loss: 0.524988\n",
      "epoch 69; iter: 0; batch classifier loss: 0.151960; batch adversarial loss: 0.375529\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125353; batch adversarial loss: 0.489916\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134693; batch adversarial loss: 0.524642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097749; batch adversarial loss: 0.423535\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061501; batch adversarial loss: 0.484550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.157067; batch adversarial loss: 0.441227\n",
      "epoch 75; iter: 0; batch classifier loss: 0.159517; batch adversarial loss: 0.549853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110417; batch adversarial loss: 0.469300\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101117; batch adversarial loss: 0.457709\n",
      "epoch 78; iter: 0; batch classifier loss: 0.149381; batch adversarial loss: 0.496441\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128126; batch adversarial loss: 0.436421\n",
      "epoch 80; iter: 0; batch classifier loss: 0.120175; batch adversarial loss: 0.446413\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106140; batch adversarial loss: 0.521265\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109314; batch adversarial loss: 0.398918\n",
      "epoch 83; iter: 0; batch classifier loss: 0.110734; batch adversarial loss: 0.410492\n",
      "epoch 84; iter: 0; batch classifier loss: 0.122292; batch adversarial loss: 0.422102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.164818; batch adversarial loss: 0.403047\n",
      "epoch 86; iter: 0; batch classifier loss: 0.147246; batch adversarial loss: 0.416338\n",
      "epoch 87; iter: 0; batch classifier loss: 0.141021; batch adversarial loss: 0.436655\n",
      "epoch 88; iter: 0; batch classifier loss: 0.138857; batch adversarial loss: 0.451557\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126630; batch adversarial loss: 0.463725\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106900; batch adversarial loss: 0.461496\n",
      "epoch 91; iter: 0; batch classifier loss: 0.157313; batch adversarial loss: 0.533707\n",
      "epoch 92; iter: 0; batch classifier loss: 0.163265; batch adversarial loss: 0.397265\n",
      "epoch 93; iter: 0; batch classifier loss: 0.146245; batch adversarial loss: 0.416861\n",
      "epoch 94; iter: 0; batch classifier loss: 0.130439; batch adversarial loss: 0.437913\n",
      "epoch 95; iter: 0; batch classifier loss: 0.112856; batch adversarial loss: 0.465492\n",
      "epoch 96; iter: 0; batch classifier loss: 0.115292; batch adversarial loss: 0.422626\n",
      "epoch 97; iter: 0; batch classifier loss: 0.122100; batch adversarial loss: 0.462123\n",
      "epoch 98; iter: 0; batch classifier loss: 0.118121; batch adversarial loss: 0.417826\n",
      "epoch 99; iter: 0; batch classifier loss: 0.112755; batch adversarial loss: 0.565277\n",
      "epoch 100; iter: 0; batch classifier loss: 0.118397; batch adversarial loss: 0.500482\n",
      "epoch 101; iter: 0; batch classifier loss: 0.120011; batch adversarial loss: 0.381051\n",
      "epoch 102; iter: 0; batch classifier loss: 0.189231; batch adversarial loss: 0.428180\n",
      "epoch 103; iter: 0; batch classifier loss: 0.109802; batch adversarial loss: 0.412218\n",
      "epoch 104; iter: 0; batch classifier loss: 0.163890; batch adversarial loss: 0.324295\n",
      "epoch 105; iter: 0; batch classifier loss: 0.111553; batch adversarial loss: 0.404856\n",
      "epoch 106; iter: 0; batch classifier loss: 0.104632; batch adversarial loss: 0.438669\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100622; batch adversarial loss: 0.423025\n",
      "epoch 108; iter: 0; batch classifier loss: 0.162314; batch adversarial loss: 0.398304\n",
      "epoch 109; iter: 0; batch classifier loss: 0.127378; batch adversarial loss: 0.488296\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071491; batch adversarial loss: 0.467159\n",
      "epoch 111; iter: 0; batch classifier loss: 0.140084; batch adversarial loss: 0.401943\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079212; batch adversarial loss: 0.516835\n",
      "epoch 113; iter: 0; batch classifier loss: 0.131985; batch adversarial loss: 0.352201\n",
      "epoch 114; iter: 0; batch classifier loss: 0.102614; batch adversarial loss: 0.479582\n",
      "epoch 115; iter: 0; batch classifier loss: 0.105128; batch adversarial loss: 0.485363\n",
      "epoch 116; iter: 0; batch classifier loss: 0.139433; batch adversarial loss: 0.484234\n",
      "epoch 117; iter: 0; batch classifier loss: 0.140454; batch adversarial loss: 0.338992\n",
      "epoch 118; iter: 0; batch classifier loss: 0.094734; batch adversarial loss: 0.390809\n",
      "epoch 119; iter: 0; batch classifier loss: 0.075398; batch adversarial loss: 0.415208\n",
      "epoch 120; iter: 0; batch classifier loss: 0.131349; batch adversarial loss: 0.427173\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082766; batch adversarial loss: 0.387705\n",
      "epoch 122; iter: 0; batch classifier loss: 0.089932; batch adversarial loss: 0.420586\n",
      "epoch 123; iter: 0; batch classifier loss: 0.125188; batch adversarial loss: 0.427535\n",
      "epoch 124; iter: 0; batch classifier loss: 0.107434; batch adversarial loss: 0.445167\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042706; batch adversarial loss: 0.391171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.081523; batch adversarial loss: 0.472868\n",
      "epoch 127; iter: 0; batch classifier loss: 0.096874; batch adversarial loss: 0.521608\n",
      "epoch 128; iter: 0; batch classifier loss: 0.101095; batch adversarial loss: 0.335603\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055095; batch adversarial loss: 0.462098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.055909; batch adversarial loss: 0.496447\n",
      "epoch 131; iter: 0; batch classifier loss: 0.093230; batch adversarial loss: 0.462718\n",
      "epoch 132; iter: 0; batch classifier loss: 0.055508; batch adversarial loss: 0.488180\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026906; batch adversarial loss: 0.418850\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072039; batch adversarial loss: 0.425915\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060676; batch adversarial loss: 0.456735\n",
      "epoch 136; iter: 0; batch classifier loss: 0.076590; batch adversarial loss: 0.345185\n",
      "epoch 137; iter: 0; batch classifier loss: 0.061808; batch adversarial loss: 0.376652\n",
      "epoch 138; iter: 0; batch classifier loss: 0.078564; batch adversarial loss: 0.366603\n",
      "epoch 139; iter: 0; batch classifier loss: 0.082684; batch adversarial loss: 0.390338\n",
      "epoch 140; iter: 0; batch classifier loss: 0.084519; batch adversarial loss: 0.398830\n",
      "epoch 141; iter: 0; batch classifier loss: 0.075941; batch adversarial loss: 0.471716\n",
      "epoch 142; iter: 0; batch classifier loss: 0.068958; batch adversarial loss: 0.482355\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039540; batch adversarial loss: 0.471369\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032004; batch adversarial loss: 0.380965\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039493; batch adversarial loss: 0.491659\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049812; batch adversarial loss: 0.436648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041753; batch adversarial loss: 0.478590\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015289; batch adversarial loss: 0.387739\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032688; batch adversarial loss: 0.450832\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037912; batch adversarial loss: 0.468451\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042431; batch adversarial loss: 0.457072\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014368; batch adversarial loss: 0.467153\n",
      "epoch 153; iter: 0; batch classifier loss: 0.063561; batch adversarial loss: 0.413553\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026835; batch adversarial loss: 0.434429\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020239; batch adversarial loss: 0.415964\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050583; batch adversarial loss: 0.380309\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052787; batch adversarial loss: 0.395904\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038709; batch adversarial loss: 0.499060\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030539; batch adversarial loss: 0.424027\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026014; batch adversarial loss: 0.439926\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055454; batch adversarial loss: 0.447889\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029181; batch adversarial loss: 0.402571\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015490; batch adversarial loss: 0.574470\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024848; batch adversarial loss: 0.478429\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041662; batch adversarial loss: 0.451905\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022450; batch adversarial loss: 0.414963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.056105; batch adversarial loss: 0.430116\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014533; batch adversarial loss: 0.489803\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029493; batch adversarial loss: 0.492575\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.473918\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052078; batch adversarial loss: 0.405718\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008242; batch adversarial loss: 0.468100\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026807; batch adversarial loss: 0.525106\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020965; batch adversarial loss: 0.421328\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014708; batch adversarial loss: 0.371404\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032498; batch adversarial loss: 0.529774\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031143; batch adversarial loss: 0.403938\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025009; batch adversarial loss: 0.441874\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028058; batch adversarial loss: 0.406630\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025303; batch adversarial loss: 0.546409\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028156; batch adversarial loss: 0.515323\n",
      "epoch 182; iter: 0; batch classifier loss: 0.042627; batch adversarial loss: 0.502039\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016875; batch adversarial loss: 0.366832\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010758; batch adversarial loss: 0.388231\n",
      "epoch 185; iter: 0; batch classifier loss: 0.054623; batch adversarial loss: 0.408240\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021552; batch adversarial loss: 0.474604\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028385; batch adversarial loss: 0.393612\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035516; batch adversarial loss: 0.486429\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023653; batch adversarial loss: 0.552692\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012754; batch adversarial loss: 0.441882\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015988; batch adversarial loss: 0.438162\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024830; batch adversarial loss: 0.378667\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046347; batch adversarial loss: 0.460565\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028759; batch adversarial loss: 0.456779\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.448015\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023979; batch adversarial loss: 0.479668\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009047; batch adversarial loss: 0.354147\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028114; batch adversarial loss: 0.479282\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014868; batch adversarial loss: 0.325037\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703590; batch adversarial loss: 0.533096\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430426; batch adversarial loss: 0.603397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.349910; batch adversarial loss: 0.587345\n",
      "epoch 3; iter: 0; batch classifier loss: 0.327547; batch adversarial loss: 0.549294\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335458; batch adversarial loss: 0.541178\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357630; batch adversarial loss: 0.534310\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349464; batch adversarial loss: 0.502508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319966; batch adversarial loss: 0.511942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.346246; batch adversarial loss: 0.493868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345956; batch adversarial loss: 0.527745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305201; batch adversarial loss: 0.549767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235765; batch adversarial loss: 0.448841\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335067; batch adversarial loss: 0.584736\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236297; batch adversarial loss: 0.539343\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321397; batch adversarial loss: 0.571272\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250677; batch adversarial loss: 0.501961\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345103; batch adversarial loss: 0.482977\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287740; batch adversarial loss: 0.454524\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354227; batch adversarial loss: 0.525345\n",
      "epoch 19; iter: 0; batch classifier loss: 0.540787; batch adversarial loss: 0.544201\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470375; batch adversarial loss: 0.458531\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308074; batch adversarial loss: 0.516996\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192762; batch adversarial loss: 0.463557\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169959; batch adversarial loss: 0.488301\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169618; batch adversarial loss: 0.432388\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181865; batch adversarial loss: 0.436898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.183304; batch adversarial loss: 0.518995\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146154; batch adversarial loss: 0.437723\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167415; batch adversarial loss: 0.460451\n",
      "epoch 29; iter: 0; batch classifier loss: 0.192832; batch adversarial loss: 0.472584\n",
      "epoch 30; iter: 0; batch classifier loss: 0.113496; batch adversarial loss: 0.469465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143341; batch adversarial loss: 0.348463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216425; batch adversarial loss: 0.452352\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140873; batch adversarial loss: 0.367935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165229; batch adversarial loss: 0.386659\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151704; batch adversarial loss: 0.450009\n",
      "epoch 36; iter: 0; batch classifier loss: 0.164592; batch adversarial loss: 0.506249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.181726; batch adversarial loss: 0.408478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100253; batch adversarial loss: 0.543226\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162483; batch adversarial loss: 0.444768\n",
      "epoch 40; iter: 0; batch classifier loss: 0.170303; batch adversarial loss: 0.440977\n",
      "epoch 41; iter: 0; batch classifier loss: 0.086681; batch adversarial loss: 0.471227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142915; batch adversarial loss: 0.479668\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096684; batch adversarial loss: 0.468092\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116295; batch adversarial loss: 0.434102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097268; batch adversarial loss: 0.490635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.125545; batch adversarial loss: 0.418308\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190203; batch adversarial loss: 0.383098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.149709; batch adversarial loss: 0.433903\n",
      "epoch 49; iter: 0; batch classifier loss: 0.185216; batch adversarial loss: 0.381830\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129967; batch adversarial loss: 0.431439\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090723; batch adversarial loss: 0.476532\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137767; batch adversarial loss: 0.376259\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111886; batch adversarial loss: 0.454122\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119257; batch adversarial loss: 0.585683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112989; batch adversarial loss: 0.468974\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132116; batch adversarial loss: 0.471979\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090620; batch adversarial loss: 0.542869\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090143; batch adversarial loss: 0.419242\n",
      "epoch 59; iter: 0; batch classifier loss: 0.146604; batch adversarial loss: 0.471323\n",
      "epoch 60; iter: 0; batch classifier loss: 0.152140; batch adversarial loss: 0.458613\n",
      "epoch 61; iter: 0; batch classifier loss: 0.154408; batch adversarial loss: 0.414844\n",
      "epoch 62; iter: 0; batch classifier loss: 0.135083; batch adversarial loss: 0.448327\n",
      "epoch 63; iter: 0; batch classifier loss: 0.150141; batch adversarial loss: 0.540308\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109171; batch adversarial loss: 0.405377\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105585; batch adversarial loss: 0.489626\n",
      "epoch 66; iter: 0; batch classifier loss: 0.158432; batch adversarial loss: 0.499119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147476; batch adversarial loss: 0.482946\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140802; batch adversarial loss: 0.469433\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115232; batch adversarial loss: 0.488708\n",
      "epoch 70; iter: 0; batch classifier loss: 0.148799; batch adversarial loss: 0.463614\n",
      "epoch 71; iter: 0; batch classifier loss: 0.118267; batch adversarial loss: 0.461169\n",
      "epoch 72; iter: 0; batch classifier loss: 0.131130; batch adversarial loss: 0.443734\n",
      "epoch 73; iter: 0; batch classifier loss: 0.134944; batch adversarial loss: 0.449236\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126181; batch adversarial loss: 0.399343\n",
      "epoch 75; iter: 0; batch classifier loss: 0.140111; batch adversarial loss: 0.405682\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118665; batch adversarial loss: 0.391830\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079363; batch adversarial loss: 0.469561\n",
      "epoch 78; iter: 0; batch classifier loss: 0.094434; batch adversarial loss: 0.436796\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080534; batch adversarial loss: 0.459883\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179468; batch adversarial loss: 0.437919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.139369; batch adversarial loss: 0.392841\n",
      "epoch 82; iter: 0; batch classifier loss: 0.069462; batch adversarial loss: 0.441919\n",
      "epoch 83; iter: 0; batch classifier loss: 0.135788; batch adversarial loss: 0.483633\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114595; batch adversarial loss: 0.408984\n",
      "epoch 85; iter: 0; batch classifier loss: 0.131552; batch adversarial loss: 0.463017\n",
      "epoch 86; iter: 0; batch classifier loss: 0.135820; batch adversarial loss: 0.400604\n",
      "epoch 87; iter: 0; batch classifier loss: 0.152815; batch adversarial loss: 0.570939\n",
      "epoch 88; iter: 0; batch classifier loss: 0.125776; batch adversarial loss: 0.374302\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102976; batch adversarial loss: 0.613334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.112607; batch adversarial loss: 0.429818\n",
      "epoch 91; iter: 0; batch classifier loss: 0.091570; batch adversarial loss: 0.513717\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106932; batch adversarial loss: 0.385444\n",
      "epoch 93; iter: 0; batch classifier loss: 0.117936; batch adversarial loss: 0.414315\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053669; batch adversarial loss: 0.376155\n",
      "epoch 95; iter: 0; batch classifier loss: 0.167814; batch adversarial loss: 0.342234\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067295; batch adversarial loss: 0.367763\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073042; batch adversarial loss: 0.378615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090346; batch adversarial loss: 0.473401\n",
      "epoch 99; iter: 0; batch classifier loss: 0.105940; batch adversarial loss: 0.519024\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047800; batch adversarial loss: 0.448060\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078632; batch adversarial loss: 0.496577\n",
      "epoch 102; iter: 0; batch classifier loss: 0.087538; batch adversarial loss: 0.462216\n",
      "epoch 103; iter: 0; batch classifier loss: 0.092281; batch adversarial loss: 0.473701\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095570; batch adversarial loss: 0.415794\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047021; batch adversarial loss: 0.424519\n",
      "epoch 106; iter: 0; batch classifier loss: 0.065993; batch adversarial loss: 0.448626\n",
      "epoch 107; iter: 0; batch classifier loss: 0.107052; batch adversarial loss: 0.402881\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069383; batch adversarial loss: 0.490217\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053615; batch adversarial loss: 0.447922\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048648; batch adversarial loss: 0.476828\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053854; batch adversarial loss: 0.453376\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044923; batch adversarial loss: 0.433227\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061671; batch adversarial loss: 0.405671\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043791; batch adversarial loss: 0.472565\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052228; batch adversarial loss: 0.402483\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071609; batch adversarial loss: 0.520704\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067005; batch adversarial loss: 0.497284\n",
      "epoch 118; iter: 0; batch classifier loss: 0.069573; batch adversarial loss: 0.392093\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083058; batch adversarial loss: 0.370565\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027894; batch adversarial loss: 0.440473\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074514; batch adversarial loss: 0.392822\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.403655\n",
      "epoch 123; iter: 0; batch classifier loss: 0.096858; batch adversarial loss: 0.447661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.037223; batch adversarial loss: 0.484064\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051570; batch adversarial loss: 0.412427\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023754; batch adversarial loss: 0.404179\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042495; batch adversarial loss: 0.386328\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065050; batch adversarial loss: 0.465216\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019141; batch adversarial loss: 0.478968\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037898; batch adversarial loss: 0.481034\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036313; batch adversarial loss: 0.452958\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031172; batch adversarial loss: 0.424280\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053859; batch adversarial loss: 0.458074\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037910; batch adversarial loss: 0.527677\n",
      "epoch 135; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.458080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033201; batch adversarial loss: 0.405912\n",
      "epoch 137; iter: 0; batch classifier loss: 0.060363; batch adversarial loss: 0.456770\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017438; batch adversarial loss: 0.488047\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037058; batch adversarial loss: 0.437629\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032677; batch adversarial loss: 0.413165\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046573; batch adversarial loss: 0.438437\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048882; batch adversarial loss: 0.532591\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026798; batch adversarial loss: 0.360681\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031408; batch adversarial loss: 0.530633\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015642; batch adversarial loss: 0.388861\n",
      "epoch 146; iter: 0; batch classifier loss: 0.055353; batch adversarial loss: 0.421441\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025415; batch adversarial loss: 0.495376\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028201; batch adversarial loss: 0.441102\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014725; batch adversarial loss: 0.449418\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023238; batch adversarial loss: 0.401767\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050114; batch adversarial loss: 0.521197\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020354; batch adversarial loss: 0.511939\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039451; batch adversarial loss: 0.429612\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.445337\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019151; batch adversarial loss: 0.481864\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043597; batch adversarial loss: 0.514780\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051042; batch adversarial loss: 0.380980\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.473293\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047187; batch adversarial loss: 0.448945\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032189; batch adversarial loss: 0.432913\n",
      "epoch 161; iter: 0; batch classifier loss: 0.060323; batch adversarial loss: 0.464604\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010136; batch adversarial loss: 0.550854\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035258; batch adversarial loss: 0.464495\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035186; batch adversarial loss: 0.546706\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011201; batch adversarial loss: 0.400823\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033687; batch adversarial loss: 0.440240\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013315; batch adversarial loss: 0.482250\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016063; batch adversarial loss: 0.425194\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042753; batch adversarial loss: 0.434881\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007094; batch adversarial loss: 0.517082\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036424; batch adversarial loss: 0.462489\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007883; batch adversarial loss: 0.525388\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029031; batch adversarial loss: 0.464024\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028490; batch adversarial loss: 0.505928\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.426776\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016626; batch adversarial loss: 0.428158\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016289; batch adversarial loss: 0.433260\n",
      "epoch 178; iter: 0; batch classifier loss: 0.067746; batch adversarial loss: 0.443207\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024000; batch adversarial loss: 0.399783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027765; batch adversarial loss: 0.404941\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017589; batch adversarial loss: 0.361199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018205; batch adversarial loss: 0.484200\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037853; batch adversarial loss: 0.413151\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021788; batch adversarial loss: 0.423265\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012332; batch adversarial loss: 0.521557\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036972; batch adversarial loss: 0.491481\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021957; batch adversarial loss: 0.452331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033393; batch adversarial loss: 0.471206\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016828; batch adversarial loss: 0.437581\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017845; batch adversarial loss: 0.457724\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014652; batch adversarial loss: 0.449678\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026980; batch adversarial loss: 0.403476\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018832; batch adversarial loss: 0.525113\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033424; batch adversarial loss: 0.510392\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010699; batch adversarial loss: 0.428229\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039509; batch adversarial loss: 0.365606\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015963; batch adversarial loss: 0.413314\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028004; batch adversarial loss: 0.437098\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034101; batch adversarial loss: 0.525764\n",
      "epoch 0; iter: 0; batch classifier loss: 0.721280; batch adversarial loss: 1.056662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.717200; batch adversarial loss: 1.186095\n",
      "epoch 2; iter: 0; batch classifier loss: 0.920031; batch adversarial loss: 1.143792\n",
      "epoch 3; iter: 0; batch classifier loss: 1.142412; batch adversarial loss: 1.073183\n",
      "epoch 4; iter: 0; batch classifier loss: 1.212570; batch adversarial loss: 0.969358\n",
      "epoch 5; iter: 0; batch classifier loss: 1.127692; batch adversarial loss: 0.877874\n",
      "epoch 6; iter: 0; batch classifier loss: 1.030345; batch adversarial loss: 0.798787\n",
      "epoch 7; iter: 0; batch classifier loss: 1.049236; batch adversarial loss: 0.724980\n",
      "epoch 8; iter: 0; batch classifier loss: 1.076764; batch adversarial loss: 0.669594\n",
      "epoch 9; iter: 0; batch classifier loss: 0.931226; batch adversarial loss: 0.643642\n",
      "epoch 10; iter: 0; batch classifier loss: 0.946173; batch adversarial loss: 0.558819\n",
      "epoch 11; iter: 0; batch classifier loss: 0.642090; batch adversarial loss: 0.524834\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481240; batch adversarial loss: 0.511864\n",
      "epoch 13; iter: 0; batch classifier loss: 0.243729; batch adversarial loss: 0.514368\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308248; batch adversarial loss: 0.469880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266607; batch adversarial loss: 0.520378\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282459; batch adversarial loss: 0.499906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290648; batch adversarial loss: 0.504266\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322361; batch adversarial loss: 0.499257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259267; batch adversarial loss: 0.486571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229065; batch adversarial loss: 0.479216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.253836; batch adversarial loss: 0.461492\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288494; batch adversarial loss: 0.470613\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196154; batch adversarial loss: 0.447876\n",
      "epoch 24; iter: 0; batch classifier loss: 0.236987; batch adversarial loss: 0.525638\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266728; batch adversarial loss: 0.486850\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232891; batch adversarial loss: 0.489911\n",
      "epoch 27; iter: 0; batch classifier loss: 0.270390; batch adversarial loss: 0.451989\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218462; batch adversarial loss: 0.539118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204202; batch adversarial loss: 0.497963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.243147; batch adversarial loss: 0.455472\n",
      "epoch 31; iter: 0; batch classifier loss: 0.289705; batch adversarial loss: 0.386728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.231243; batch adversarial loss: 0.449162\n",
      "epoch 33; iter: 0; batch classifier loss: 0.253296; batch adversarial loss: 0.436259\n",
      "epoch 34; iter: 0; batch classifier loss: 0.255230; batch adversarial loss: 0.455428\n",
      "epoch 35; iter: 0; batch classifier loss: 0.218823; batch adversarial loss: 0.404137\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241001; batch adversarial loss: 0.444083\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225258; batch adversarial loss: 0.495070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.211610; batch adversarial loss: 0.565269\n",
      "epoch 39; iter: 0; batch classifier loss: 0.281840; batch adversarial loss: 0.405837\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315289; batch adversarial loss: 0.341933\n",
      "epoch 41; iter: 0; batch classifier loss: 0.251497; batch adversarial loss: 0.476185\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302198; batch adversarial loss: 0.410217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220428; batch adversarial loss: 0.433365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226324; batch adversarial loss: 0.504367\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164832; batch adversarial loss: 0.448735\n",
      "epoch 46; iter: 0; batch classifier loss: 0.285458; batch adversarial loss: 0.416154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213544; batch adversarial loss: 0.408733\n",
      "epoch 48; iter: 0; batch classifier loss: 0.260502; batch adversarial loss: 0.432908\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248192; batch adversarial loss: 0.467117\n",
      "epoch 50; iter: 0; batch classifier loss: 0.325068; batch adversarial loss: 0.396483\n",
      "epoch 51; iter: 0; batch classifier loss: 0.215759; batch adversarial loss: 0.477264\n",
      "epoch 52; iter: 0; batch classifier loss: 0.233385; batch adversarial loss: 0.376127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.263724; batch adversarial loss: 0.458610\n",
      "epoch 54; iter: 0; batch classifier loss: 0.294936; batch adversarial loss: 0.383408\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189753; batch adversarial loss: 0.387214\n",
      "epoch 56; iter: 0; batch classifier loss: 0.209617; batch adversarial loss: 0.512589\n",
      "epoch 57; iter: 0; batch classifier loss: 0.309440; batch adversarial loss: 0.432917\n",
      "epoch 58; iter: 0; batch classifier loss: 0.185330; batch adversarial loss: 0.434551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.262896; batch adversarial loss: 0.462516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.278389; batch adversarial loss: 0.448566\n",
      "epoch 61; iter: 0; batch classifier loss: 0.198597; batch adversarial loss: 0.532529\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144418; batch adversarial loss: 0.484540\n",
      "epoch 63; iter: 0; batch classifier loss: 0.237871; batch adversarial loss: 0.433500\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188928; batch adversarial loss: 0.410532\n",
      "epoch 65; iter: 0; batch classifier loss: 0.231515; batch adversarial loss: 0.457601\n",
      "epoch 66; iter: 0; batch classifier loss: 0.191931; batch adversarial loss: 0.494463\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180478; batch adversarial loss: 0.408380\n",
      "epoch 68; iter: 0; batch classifier loss: 0.227324; batch adversarial loss: 0.358603\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174303; batch adversarial loss: 0.445499\n",
      "epoch 70; iter: 0; batch classifier loss: 0.252180; batch adversarial loss: 0.432795\n",
      "epoch 71; iter: 0; batch classifier loss: 0.228545; batch adversarial loss: 0.445593\n",
      "epoch 72; iter: 0; batch classifier loss: 0.227912; batch adversarial loss: 0.433324\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198075; batch adversarial loss: 0.419968\n",
      "epoch 74; iter: 0; batch classifier loss: 0.146483; batch adversarial loss: 0.533680\n",
      "epoch 75; iter: 0; batch classifier loss: 0.208804; batch adversarial loss: 0.508515\n",
      "epoch 76; iter: 0; batch classifier loss: 0.299399; batch adversarial loss: 0.383485\n",
      "epoch 77; iter: 0; batch classifier loss: 0.233560; batch adversarial loss: 0.447056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.195756; batch adversarial loss: 0.382878\n",
      "epoch 79; iter: 0; batch classifier loss: 0.200610; batch adversarial loss: 0.421669\n",
      "epoch 80; iter: 0; batch classifier loss: 0.245311; batch adversarial loss: 0.433977\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193097; batch adversarial loss: 0.420861\n",
      "epoch 82; iter: 0; batch classifier loss: 0.146716; batch adversarial loss: 0.446536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.168267; batch adversarial loss: 0.446381\n",
      "epoch 84; iter: 0; batch classifier loss: 0.126970; batch adversarial loss: 0.459210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.158323; batch adversarial loss: 0.434155\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066050; batch adversarial loss: 0.395223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.131307; batch adversarial loss: 0.422255\n",
      "epoch 88; iter: 0; batch classifier loss: 0.264419; batch adversarial loss: 0.510585\n",
      "epoch 89; iter: 0; batch classifier loss: 0.176466; batch adversarial loss: 0.538857\n",
      "epoch 90; iter: 0; batch classifier loss: 0.282164; batch adversarial loss: 0.344840\n",
      "epoch 91; iter: 0; batch classifier loss: 0.207669; batch adversarial loss: 0.496451\n",
      "epoch 92; iter: 0; batch classifier loss: 0.172501; batch adversarial loss: 0.396630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195449; batch adversarial loss: 0.407592\n",
      "epoch 94; iter: 0; batch classifier loss: 0.131786; batch adversarial loss: 0.522920\n",
      "epoch 95; iter: 0; batch classifier loss: 0.219588; batch adversarial loss: 0.370367\n",
      "epoch 96; iter: 0; batch classifier loss: 0.258400; batch adversarial loss: 0.484418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.166964; batch adversarial loss: 0.433171\n",
      "epoch 98; iter: 0; batch classifier loss: 0.187610; batch adversarial loss: 0.523197\n",
      "epoch 99; iter: 0; batch classifier loss: 0.136420; batch adversarial loss: 0.522525\n",
      "epoch 100; iter: 0; batch classifier loss: 0.239353; batch adversarial loss: 0.407067\n",
      "epoch 101; iter: 0; batch classifier loss: 0.208033; batch adversarial loss: 0.573645\n",
      "epoch 102; iter: 0; batch classifier loss: 0.144388; batch adversarial loss: 0.458882\n",
      "epoch 103; iter: 0; batch classifier loss: 0.227938; batch adversarial loss: 0.458839\n",
      "epoch 104; iter: 0; batch classifier loss: 0.189806; batch adversarial loss: 0.458887\n",
      "epoch 105; iter: 0; batch classifier loss: 0.161598; batch adversarial loss: 0.459273\n",
      "epoch 106; iter: 0; batch classifier loss: 0.249032; batch adversarial loss: 0.522276\n",
      "epoch 107; iter: 0; batch classifier loss: 0.206782; batch adversarial loss: 0.496963\n",
      "epoch 108; iter: 0; batch classifier loss: 0.143583; batch adversarial loss: 0.433716\n",
      "epoch 109; iter: 0; batch classifier loss: 0.202309; batch adversarial loss: 0.382875\n",
      "epoch 110; iter: 0; batch classifier loss: 0.251412; batch adversarial loss: 0.497113\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090677; batch adversarial loss: 0.369896\n",
      "epoch 112; iter: 0; batch classifier loss: 0.141686; batch adversarial loss: 0.379641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162891; batch adversarial loss: 0.405726\n",
      "epoch 114; iter: 0; batch classifier loss: 0.288951; batch adversarial loss: 0.445153\n",
      "epoch 115; iter: 0; batch classifier loss: 0.177936; batch adversarial loss: 0.521419\n",
      "epoch 116; iter: 0; batch classifier loss: 0.190002; batch adversarial loss: 0.472394\n",
      "epoch 117; iter: 0; batch classifier loss: 0.134371; batch adversarial loss: 0.395995\n",
      "epoch 118; iter: 0; batch classifier loss: 0.227847; batch adversarial loss: 0.420630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 119; iter: 0; batch classifier loss: 0.199711; batch adversarial loss: 0.547333\n",
      "epoch 120; iter: 0; batch classifier loss: 0.257948; batch adversarial loss: 0.408203\n",
      "epoch 121; iter: 0; batch classifier loss: 0.157352; batch adversarial loss: 0.370759\n",
      "epoch 122; iter: 0; batch classifier loss: 0.106426; batch adversarial loss: 0.472003\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063584; batch adversarial loss: 0.391187\n",
      "epoch 124; iter: 0; batch classifier loss: 0.113073; batch adversarial loss: 0.483199\n",
      "epoch 125; iter: 0; batch classifier loss: 0.095204; batch adversarial loss: 0.411819\n",
      "epoch 126; iter: 0; batch classifier loss: 0.138553; batch adversarial loss: 0.458696\n",
      "epoch 127; iter: 0; batch classifier loss: 0.089456; batch adversarial loss: 0.486582\n",
      "epoch 128; iter: 0; batch classifier loss: 0.168897; batch adversarial loss: 0.499399\n",
      "epoch 129; iter: 0; batch classifier loss: 0.162855; batch adversarial loss: 0.422633\n",
      "epoch 130; iter: 0; batch classifier loss: 0.127536; batch adversarial loss: 0.481800\n",
      "epoch 131; iter: 0; batch classifier loss: 0.102872; batch adversarial loss: 0.457170\n",
      "epoch 132; iter: 0; batch classifier loss: 0.111396; batch adversarial loss: 0.469169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078078; batch adversarial loss: 0.460713\n",
      "epoch 134; iter: 0; batch classifier loss: 0.102464; batch adversarial loss: 0.517614\n",
      "epoch 135; iter: 0; batch classifier loss: 0.098431; batch adversarial loss: 0.464104\n",
      "epoch 136; iter: 0; batch classifier loss: 0.124734; batch adversarial loss: 0.467219\n",
      "epoch 137; iter: 0; batch classifier loss: 0.097603; batch adversarial loss: 0.529851\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049019; batch adversarial loss: 0.508549\n",
      "epoch 139; iter: 0; batch classifier loss: 0.104457; batch adversarial loss: 0.431461\n",
      "epoch 140; iter: 0; batch classifier loss: 0.078069; batch adversarial loss: 0.510809\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026386; batch adversarial loss: 0.405104\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060627; batch adversarial loss: 0.318404\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037222; batch adversarial loss: 0.425855\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052176; batch adversarial loss: 0.426338\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058610; batch adversarial loss: 0.409156\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059045; batch adversarial loss: 0.409566\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018023; batch adversarial loss: 0.503698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047970; batch adversarial loss: 0.487019\n",
      "epoch 149; iter: 0; batch classifier loss: 0.066497; batch adversarial loss: 0.522782\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051869; batch adversarial loss: 0.379289\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045756; batch adversarial loss: 0.414168\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018065; batch adversarial loss: 0.469306\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027147; batch adversarial loss: 0.351145\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024050; batch adversarial loss: 0.524327\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027189; batch adversarial loss: 0.443784\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017773; batch adversarial loss: 0.391063\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041312; batch adversarial loss: 0.491748\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028482; batch adversarial loss: 0.492927\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038801; batch adversarial loss: 0.436749\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055991; batch adversarial loss: 0.444279\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026884; batch adversarial loss: 0.416223\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025616; batch adversarial loss: 0.369201\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026468; batch adversarial loss: 0.418851\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016127; batch adversarial loss: 0.522308\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021568; batch adversarial loss: 0.503635\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035127; batch adversarial loss: 0.422886\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033642; batch adversarial loss: 0.516796\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027278; batch adversarial loss: 0.577994\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023225; batch adversarial loss: 0.612895\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014564; batch adversarial loss: 0.462866\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027661; batch adversarial loss: 0.452781\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049027; batch adversarial loss: 0.436179\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030204; batch adversarial loss: 0.458877\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029236; batch adversarial loss: 0.495671\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021282; batch adversarial loss: 0.486202\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007372; batch adversarial loss: 0.493087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016242; batch adversarial loss: 0.408269\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017618; batch adversarial loss: 0.444434\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015990; batch adversarial loss: 0.328761\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011966; batch adversarial loss: 0.405726\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008009; batch adversarial loss: 0.489839\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024192; batch adversarial loss: 0.359004\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012880; batch adversarial loss: 0.394378\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026228; batch adversarial loss: 0.419547\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011399; batch adversarial loss: 0.483263\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.491928\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017155; batch adversarial loss: 0.489745\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016787; batch adversarial loss: 0.486318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.354533\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025404; batch adversarial loss: 0.458376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012482; batch adversarial loss: 0.460076\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028870; batch adversarial loss: 0.368533\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005598; batch adversarial loss: 0.484864\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025935; batch adversarial loss: 0.393011\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012716; batch adversarial loss: 0.528025\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005183; batch adversarial loss: 0.485765\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014389; batch adversarial loss: 0.445426\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009340; batch adversarial loss: 0.481938\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015282; batch adversarial loss: 0.428435\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696683; batch adversarial loss: 0.609547\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441242; batch adversarial loss: 0.618671\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466063; batch adversarial loss: 0.616063\n",
      "epoch 3; iter: 0; batch classifier loss: 0.428802; batch adversarial loss: 0.670908\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458723; batch adversarial loss: 0.630888\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520350; batch adversarial loss: 0.567972\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593520; batch adversarial loss: 0.574097\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574240; batch adversarial loss: 0.600361\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523005; batch adversarial loss: 0.538554\n",
      "epoch 9; iter: 0; batch classifier loss: 0.410741; batch adversarial loss: 0.555100\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344971; batch adversarial loss: 0.517818\n",
      "epoch 11; iter: 0; batch classifier loss: 0.355674; batch adversarial loss: 0.459236\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307276; batch adversarial loss: 0.554460\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373332; batch adversarial loss: 0.447782\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335566; batch adversarial loss: 0.463898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.354512; batch adversarial loss: 0.537849\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298634; batch adversarial loss: 0.508324\n",
      "epoch 17; iter: 0; batch classifier loss: 0.350757; batch adversarial loss: 0.490562\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243566; batch adversarial loss: 0.460326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284996; batch adversarial loss: 0.437967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280901; batch adversarial loss: 0.481212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246751; batch adversarial loss: 0.550114\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273533; batch adversarial loss: 0.470543\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218320; batch adversarial loss: 0.449297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293263; batch adversarial loss: 0.478047\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277966; batch adversarial loss: 0.486740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228074; batch adversarial loss: 0.486403\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226428; batch adversarial loss: 0.437104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197538; batch adversarial loss: 0.521738\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210363; batch adversarial loss: 0.441433\n",
      "epoch 30; iter: 0; batch classifier loss: 0.247691; batch adversarial loss: 0.495956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211413; batch adversarial loss: 0.519098\n",
      "epoch 32; iter: 0; batch classifier loss: 0.250476; batch adversarial loss: 0.439457\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190482; batch adversarial loss: 0.443842\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232896; batch adversarial loss: 0.468891\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277065; batch adversarial loss: 0.411916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268355; batch adversarial loss: 0.422002\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214609; batch adversarial loss: 0.445305\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261807; batch adversarial loss: 0.422845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168960; batch adversarial loss: 0.456009\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184957; batch adversarial loss: 0.413838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.259814; batch adversarial loss: 0.376547\n",
      "epoch 42; iter: 0; batch classifier loss: 0.294946; batch adversarial loss: 0.377924\n",
      "epoch 43; iter: 0; batch classifier loss: 0.276584; batch adversarial loss: 0.404514\n",
      "epoch 44; iter: 0; batch classifier loss: 0.222925; batch adversarial loss: 0.460062\n",
      "epoch 45; iter: 0; batch classifier loss: 0.226691; batch adversarial loss: 0.475930\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228617; batch adversarial loss: 0.449117\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213548; batch adversarial loss: 0.449073\n",
      "epoch 48; iter: 0; batch classifier loss: 0.278236; batch adversarial loss: 0.506298\n",
      "epoch 49; iter: 0; batch classifier loss: 0.218696; batch adversarial loss: 0.447233\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177940; batch adversarial loss: 0.470651\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238910; batch adversarial loss: 0.507940\n",
      "epoch 52; iter: 0; batch classifier loss: 0.222644; batch adversarial loss: 0.555062\n",
      "epoch 53; iter: 0; batch classifier loss: 0.182840; batch adversarial loss: 0.411456\n",
      "epoch 54; iter: 0; batch classifier loss: 0.253987; batch adversarial loss: 0.400449\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175527; batch adversarial loss: 0.470018\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151142; batch adversarial loss: 0.413317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.268382; batch adversarial loss: 0.413599\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194477; batch adversarial loss: 0.507764\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206914; batch adversarial loss: 0.398052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.220457; batch adversarial loss: 0.459668\n",
      "epoch 61; iter: 0; batch classifier loss: 0.195897; batch adversarial loss: 0.435116\n",
      "epoch 62; iter: 0; batch classifier loss: 0.204278; batch adversarial loss: 0.482330\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142115; batch adversarial loss: 0.398913\n",
      "epoch 64; iter: 0; batch classifier loss: 0.114741; batch adversarial loss: 0.565936\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115045; batch adversarial loss: 0.431268\n",
      "epoch 66; iter: 0; batch classifier loss: 0.147679; batch adversarial loss: 0.441687\n",
      "epoch 67; iter: 0; batch classifier loss: 0.223631; batch adversarial loss: 0.422526\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184379; batch adversarial loss: 0.434030\n",
      "epoch 69; iter: 0; batch classifier loss: 0.187294; batch adversarial loss: 0.577367\n",
      "epoch 70; iter: 0; batch classifier loss: 0.219517; batch adversarial loss: 0.300613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.293924; batch adversarial loss: 0.448493\n",
      "epoch 72; iter: 0; batch classifier loss: 0.218623; batch adversarial loss: 0.469699\n",
      "epoch 73; iter: 0; batch classifier loss: 0.158728; batch adversarial loss: 0.518916\n",
      "epoch 74; iter: 0; batch classifier loss: 0.214113; batch adversarial loss: 0.469505\n",
      "epoch 75; iter: 0; batch classifier loss: 0.163814; batch adversarial loss: 0.447713\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156447; batch adversarial loss: 0.494439\n",
      "epoch 77; iter: 0; batch classifier loss: 0.208947; batch adversarial loss: 0.448281\n",
      "epoch 78; iter: 0; batch classifier loss: 0.225696; batch adversarial loss: 0.423337\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160082; batch adversarial loss: 0.493894\n",
      "epoch 80; iter: 0; batch classifier loss: 0.211169; batch adversarial loss: 0.482931\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114205; batch adversarial loss: 0.494190\n",
      "epoch 82; iter: 0; batch classifier loss: 0.133422; batch adversarial loss: 0.456947\n",
      "epoch 83; iter: 0; batch classifier loss: 0.102501; batch adversarial loss: 0.506697\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106237; batch adversarial loss: 0.521036\n",
      "epoch 85; iter: 0; batch classifier loss: 0.177719; batch adversarial loss: 0.500974\n",
      "epoch 86; iter: 0; batch classifier loss: 0.225265; batch adversarial loss: 0.434684\n",
      "epoch 87; iter: 0; batch classifier loss: 0.144862; batch adversarial loss: 0.448735\n",
      "epoch 88; iter: 0; batch classifier loss: 0.170829; batch adversarial loss: 0.496254\n",
      "epoch 89; iter: 0; batch classifier loss: 0.113836; batch adversarial loss: 0.511120\n",
      "epoch 90; iter: 0; batch classifier loss: 0.193841; batch adversarial loss: 0.480748\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110483; batch adversarial loss: 0.480993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.183397; batch adversarial loss: 0.458816\n",
      "epoch 93; iter: 0; batch classifier loss: 0.152380; batch adversarial loss: 0.434610\n",
      "epoch 94; iter: 0; batch classifier loss: 0.187371; batch adversarial loss: 0.468058\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075567; batch adversarial loss: 0.538670\n",
      "epoch 96; iter: 0; batch classifier loss: 0.127907; batch adversarial loss: 0.488403\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064801; batch adversarial loss: 0.548696\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089751; batch adversarial loss: 0.455191\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078025; batch adversarial loss: 0.390585\n",
      "epoch 100; iter: 0; batch classifier loss: 0.108252; batch adversarial loss: 0.456113\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072960; batch adversarial loss: 0.386155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.165545; batch adversarial loss: 0.473572\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060388; batch adversarial loss: 0.484518\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089482; batch adversarial loss: 0.487419\n",
      "epoch 105; iter: 0; batch classifier loss: 0.108518; batch adversarial loss: 0.413052\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062636; batch adversarial loss: 0.418148\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055183; batch adversarial loss: 0.466600\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044306; batch adversarial loss: 0.452174\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041670; batch adversarial loss: 0.418663\n",
      "epoch 110; iter: 0; batch classifier loss: 0.093174; batch adversarial loss: 0.450822\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078552; batch adversarial loss: 0.547780\n",
      "epoch 112; iter: 0; batch classifier loss: 0.112210; batch adversarial loss: 0.398431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.030590; batch adversarial loss: 0.522068\n",
      "epoch 114; iter: 0; batch classifier loss: 0.084664; batch adversarial loss: 0.487654\n",
      "epoch 115; iter: 0; batch classifier loss: 0.018908; batch adversarial loss: 0.460837\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042978; batch adversarial loss: 0.422023\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046550; batch adversarial loss: 0.415379\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051417; batch adversarial loss: 0.477483\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048946; batch adversarial loss: 0.514895\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051403; batch adversarial loss: 0.456367\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018369; batch adversarial loss: 0.397119\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032519; batch adversarial loss: 0.500661\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055764; batch adversarial loss: 0.461245\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053842; batch adversarial loss: 0.466784\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014938; batch adversarial loss: 0.408927\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042688; batch adversarial loss: 0.476916\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.361192\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048546; batch adversarial loss: 0.469084\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018085; batch adversarial loss: 0.507758\n",
      "epoch 130; iter: 0; batch classifier loss: 0.069704; batch adversarial loss: 0.432928\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.425009\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034512; batch adversarial loss: 0.499182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.438858\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045908; batch adversarial loss: 0.457518\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040602; batch adversarial loss: 0.421621\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023447; batch adversarial loss: 0.470661\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034599; batch adversarial loss: 0.427008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032634; batch adversarial loss: 0.548330\n",
      "epoch 139; iter: 0; batch classifier loss: 0.007772; batch adversarial loss: 0.473310\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013051; batch adversarial loss: 0.396470\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035709; batch adversarial loss: 0.472470\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053962; batch adversarial loss: 0.458619\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018422; batch adversarial loss: 0.480552\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021648; batch adversarial loss: 0.463612\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047326; batch adversarial loss: 0.507510\n",
      "epoch 146; iter: 0; batch classifier loss: 0.004987; batch adversarial loss: 0.595076\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035931; batch adversarial loss: 0.462831\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027447; batch adversarial loss: 0.378589\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022708; batch adversarial loss: 0.457106\n",
      "epoch 150; iter: 0; batch classifier loss: 0.006607; batch adversarial loss: 0.457650\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020423; batch adversarial loss: 0.468898\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023691; batch adversarial loss: 0.471237\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018896; batch adversarial loss: 0.422883\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015345; batch adversarial loss: 0.396402\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017313; batch adversarial loss: 0.494688\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040041; batch adversarial loss: 0.405974\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015175; batch adversarial loss: 0.456732\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034094; batch adversarial loss: 0.488929\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026236; batch adversarial loss: 0.419880\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032247; batch adversarial loss: 0.473590\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021223; batch adversarial loss: 0.535859\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006824; batch adversarial loss: 0.457746\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016990; batch adversarial loss: 0.428192\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011744; batch adversarial loss: 0.408580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020930; batch adversarial loss: 0.444590\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013055; batch adversarial loss: 0.429053\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015218; batch adversarial loss: 0.427231\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010509; batch adversarial loss: 0.480534\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012731; batch adversarial loss: 0.487020\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006350; batch adversarial loss: 0.431286\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015520; batch adversarial loss: 0.465238\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058772; batch adversarial loss: 0.507522\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009673; batch adversarial loss: 0.517125\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026105; batch adversarial loss: 0.447149\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006876; batch adversarial loss: 0.366651\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026055; batch adversarial loss: 0.382118\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037306; batch adversarial loss: 0.467017\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019737; batch adversarial loss: 0.491283\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014840; batch adversarial loss: 0.408063\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.430608\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011763; batch adversarial loss: 0.393456\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021536; batch adversarial loss: 0.465557\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040180; batch adversarial loss: 0.518746\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014037; batch adversarial loss: 0.471409\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014079; batch adversarial loss: 0.421434\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003535; batch adversarial loss: 0.460176\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024814; batch adversarial loss: 0.523035\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005362; batch adversarial loss: 0.364853\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009344; batch adversarial loss: 0.505971\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020384; batch adversarial loss: 0.499222\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020168; batch adversarial loss: 0.428255\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026427; batch adversarial loss: 0.447972\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012322; batch adversarial loss: 0.419061\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012393; batch adversarial loss: 0.413637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008116; batch adversarial loss: 0.393822\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019184; batch adversarial loss: 0.456172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021358; batch adversarial loss: 0.452557\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018677; batch adversarial loss: 0.485106\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011583; batch adversarial loss: 0.420379\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676063; batch adversarial loss: 0.843449\n",
      "epoch 1; iter: 0; batch classifier loss: 0.564943; batch adversarial loss: 0.833925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.675284; batch adversarial loss: 0.822459\n",
      "epoch 3; iter: 0; batch classifier loss: 0.837049; batch adversarial loss: 0.757152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.752076; batch adversarial loss: 0.680585\n",
      "epoch 5; iter: 0; batch classifier loss: 0.734504; batch adversarial loss: 0.627256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502433; batch adversarial loss: 0.575537\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386912; batch adversarial loss: 0.557697\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373862; batch adversarial loss: 0.556382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342079; batch adversarial loss: 0.555151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.418158; batch adversarial loss: 0.531225\n",
      "epoch 11; iter: 0; batch classifier loss: 0.302821; batch adversarial loss: 0.484925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.279078; batch adversarial loss: 0.518331\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309912; batch adversarial loss: 0.537530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.323250; batch adversarial loss: 0.475177\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287904; batch adversarial loss: 0.499080\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311235; batch adversarial loss: 0.456760\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312469; batch adversarial loss: 0.491953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269377; batch adversarial loss: 0.444542\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375533; batch adversarial loss: 0.454509\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337302; batch adversarial loss: 0.463775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333732; batch adversarial loss: 0.478630\n",
      "epoch 22; iter: 0; batch classifier loss: 0.322867; batch adversarial loss: 0.415317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318672; batch adversarial loss: 0.427108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296982; batch adversarial loss: 0.520647\n",
      "epoch 25; iter: 0; batch classifier loss: 0.387511; batch adversarial loss: 0.450373\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257782; batch adversarial loss: 0.420614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.292337; batch adversarial loss: 0.455744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.292173; batch adversarial loss: 0.447341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223695; batch adversarial loss: 0.430449\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319376; batch adversarial loss: 0.466646\n",
      "epoch 31; iter: 0; batch classifier loss: 0.273445; batch adversarial loss: 0.435155\n",
      "epoch 32; iter: 0; batch classifier loss: 0.272183; batch adversarial loss: 0.529573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.423749; batch adversarial loss: 0.359249\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236661; batch adversarial loss: 0.524870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.318411; batch adversarial loss: 0.463054\n",
      "epoch 36; iter: 0; batch classifier loss: 0.265687; batch adversarial loss: 0.439781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288794; batch adversarial loss: 0.384976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.306305; batch adversarial loss: 0.407056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.300875; batch adversarial loss: 0.441990\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246348; batch adversarial loss: 0.457609\n",
      "epoch 41; iter: 0; batch classifier loss: 0.294365; batch adversarial loss: 0.404530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234928; batch adversarial loss: 0.466138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237255; batch adversarial loss: 0.370815\n",
      "epoch 44; iter: 0; batch classifier loss: 0.258637; batch adversarial loss: 0.351564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183716; batch adversarial loss: 0.489446\n",
      "epoch 46; iter: 0; batch classifier loss: 0.336225; batch adversarial loss: 0.431148\n",
      "epoch 47; iter: 0; batch classifier loss: 0.221140; batch adversarial loss: 0.520596\n",
      "epoch 48; iter: 0; batch classifier loss: 0.218334; batch adversarial loss: 0.424618\n",
      "epoch 49; iter: 0; batch classifier loss: 0.256187; batch adversarial loss: 0.392781\n",
      "epoch 50; iter: 0; batch classifier loss: 0.273036; batch adversarial loss: 0.440082\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238784; batch adversarial loss: 0.471097\n",
      "epoch 52; iter: 0; batch classifier loss: 0.207384; batch adversarial loss: 0.465251\n",
      "epoch 53; iter: 0; batch classifier loss: 0.228240; batch adversarial loss: 0.454793\n",
      "epoch 54; iter: 0; batch classifier loss: 0.290952; batch adversarial loss: 0.445893\n",
      "epoch 55; iter: 0; batch classifier loss: 0.260332; batch adversarial loss: 0.454020\n",
      "epoch 56; iter: 0; batch classifier loss: 0.271813; batch adversarial loss: 0.463187\n",
      "epoch 57; iter: 0; batch classifier loss: 0.274229; batch adversarial loss: 0.451647\n",
      "epoch 58; iter: 0; batch classifier loss: 0.174542; batch adversarial loss: 0.426017\n",
      "epoch 59; iter: 0; batch classifier loss: 0.211070; batch adversarial loss: 0.412847\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245393; batch adversarial loss: 0.382444\n",
      "epoch 61; iter: 0; batch classifier loss: 0.280442; batch adversarial loss: 0.483364\n",
      "epoch 62; iter: 0; batch classifier loss: 0.177367; batch adversarial loss: 0.537667\n",
      "epoch 63; iter: 0; batch classifier loss: 0.249082; batch adversarial loss: 0.475514\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249318; batch adversarial loss: 0.461711\n",
      "epoch 65; iter: 0; batch classifier loss: 0.273981; batch adversarial loss: 0.461226\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206351; batch adversarial loss: 0.366329\n",
      "epoch 67; iter: 0; batch classifier loss: 0.235994; batch adversarial loss: 0.423091\n",
      "epoch 68; iter: 0; batch classifier loss: 0.269896; batch adversarial loss: 0.397486\n",
      "epoch 69; iter: 0; batch classifier loss: 0.278244; batch adversarial loss: 0.510038\n",
      "epoch 70; iter: 0; batch classifier loss: 0.275801; batch adversarial loss: 0.433318\n",
      "epoch 71; iter: 0; batch classifier loss: 0.165834; batch adversarial loss: 0.472486\n",
      "epoch 72; iter: 0; batch classifier loss: 0.222778; batch adversarial loss: 0.396583\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240960; batch adversarial loss: 0.421009\n",
      "epoch 74; iter: 0; batch classifier loss: 0.231562; batch adversarial loss: 0.421355\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213518; batch adversarial loss: 0.458426\n",
      "epoch 76; iter: 0; batch classifier loss: 0.225416; batch adversarial loss: 0.509814\n",
      "epoch 77; iter: 0; batch classifier loss: 0.204642; batch adversarial loss: 0.509702\n",
      "epoch 78; iter: 0; batch classifier loss: 0.196899; batch adversarial loss: 0.396511\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090698; batch adversarial loss: 0.430231\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088399; batch adversarial loss: 0.483100\n",
      "epoch 81; iter: 0; batch classifier loss: 0.209539; batch adversarial loss: 0.508995\n",
      "epoch 82; iter: 0; batch classifier loss: 0.348849; batch adversarial loss: 0.421014\n",
      "epoch 83; iter: 0; batch classifier loss: 0.228579; batch adversarial loss: 0.585747\n",
      "epoch 84; iter: 0; batch classifier loss: 0.251185; batch adversarial loss: 0.407575\n",
      "epoch 85; iter: 0; batch classifier loss: 0.216304; batch adversarial loss: 0.484363\n",
      "epoch 86; iter: 0; batch classifier loss: 0.229761; batch adversarial loss: 0.420758\n",
      "epoch 87; iter: 0; batch classifier loss: 0.212166; batch adversarial loss: 0.521725\n",
      "epoch 88; iter: 0; batch classifier loss: 0.210698; batch adversarial loss: 0.446191\n",
      "epoch 89; iter: 0; batch classifier loss: 0.270435; batch adversarial loss: 0.445803\n",
      "epoch 90; iter: 0; batch classifier loss: 0.195759; batch adversarial loss: 0.560785\n",
      "epoch 91; iter: 0; batch classifier loss: 0.123846; batch adversarial loss: 0.420827\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109834; batch adversarial loss: 0.379686\n",
      "epoch 93; iter: 0; batch classifier loss: 0.138482; batch adversarial loss: 0.462688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.171775; batch adversarial loss: 0.432569\n",
      "epoch 95; iter: 0; batch classifier loss: 0.308868; batch adversarial loss: 0.370913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.212059; batch adversarial loss: 0.460922\n",
      "epoch 97; iter: 0; batch classifier loss: 0.221423; batch adversarial loss: 0.497782\n",
      "epoch 98; iter: 0; batch classifier loss: 0.161006; batch adversarial loss: 0.395405\n",
      "epoch 99; iter: 0; batch classifier loss: 0.226903; batch adversarial loss: 0.369747\n",
      "epoch 100; iter: 0; batch classifier loss: 0.205810; batch adversarial loss: 0.472105\n",
      "epoch 101; iter: 0; batch classifier loss: 0.205072; batch adversarial loss: 0.407453\n",
      "epoch 102; iter: 0; batch classifier loss: 0.315947; batch adversarial loss: 0.459059\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071487; batch adversarial loss: 0.573404\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061964; batch adversarial loss: 0.443185\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042901; batch adversarial loss: 0.406192\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055954; batch adversarial loss: 0.481221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.046032; batch adversarial loss: 0.358364\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081390; batch adversarial loss: 0.424667\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030908; batch adversarial loss: 0.444894\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031351; batch adversarial loss: 0.333433\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025396; batch adversarial loss: 0.336235\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071972; batch adversarial loss: 0.387447\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050474; batch adversarial loss: 0.326406\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026584; batch adversarial loss: 0.518051\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042307; batch adversarial loss: 0.389057\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028286; batch adversarial loss: 0.364954\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.493395\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046684; batch adversarial loss: 0.429603\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046351; batch adversarial loss: 0.440081\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037086; batch adversarial loss: 0.461274\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044011; batch adversarial loss: 0.441269\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024128; batch adversarial loss: 0.351264\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045077; batch adversarial loss: 0.553112\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033259; batch adversarial loss: 0.458026\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028102; batch adversarial loss: 0.483932\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041280; batch adversarial loss: 0.461924\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014929; batch adversarial loss: 0.382833\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026866; batch adversarial loss: 0.333412\n",
      "epoch 129; iter: 0; batch classifier loss: 0.010930; batch adversarial loss: 0.413351\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033009; batch adversarial loss: 0.390792\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014935; batch adversarial loss: 0.557791\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037692; batch adversarial loss: 0.416743\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021816; batch adversarial loss: 0.377429\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009535; batch adversarial loss: 0.490609\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021570; batch adversarial loss: 0.446593\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051403; batch adversarial loss: 0.427522\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035847; batch adversarial loss: 0.460692\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014405; batch adversarial loss: 0.304371\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008742; batch adversarial loss: 0.319870\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034321; batch adversarial loss: 0.407165\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013014; batch adversarial loss: 0.388569\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011709; batch adversarial loss: 0.436618\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031658; batch adversarial loss: 0.419307\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.484214\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024068; batch adversarial loss: 0.475299\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016038; batch adversarial loss: 0.411952\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027681; batch adversarial loss: 0.464985\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031044; batch adversarial loss: 0.332588\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023394; batch adversarial loss: 0.416429\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010464; batch adversarial loss: 0.417279\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019356; batch adversarial loss: 0.429006\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008150; batch adversarial loss: 0.462766\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.481116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035474; batch adversarial loss: 0.379127\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026774; batch adversarial loss: 0.387289\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037852; batch adversarial loss: 0.541619\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030361; batch adversarial loss: 0.404661\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011759; batch adversarial loss: 0.428287\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024423; batch adversarial loss: 0.440084\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.529067\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011671; batch adversarial loss: 0.392490\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015831; batch adversarial loss: 0.453995\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007672; batch adversarial loss: 0.456537\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011377; batch adversarial loss: 0.440840\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041920; batch adversarial loss: 0.434152\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033300; batch adversarial loss: 0.496389\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009861; batch adversarial loss: 0.366665\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027494; batch adversarial loss: 0.411209\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.517477\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023759; batch adversarial loss: 0.455442\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013657; batch adversarial loss: 0.446009\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022230; batch adversarial loss: 0.349556\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019465; batch adversarial loss: 0.304270\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021716; batch adversarial loss: 0.463211\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020654; batch adversarial loss: 0.399474\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018411; batch adversarial loss: 0.436172\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013564; batch adversarial loss: 0.424608\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038134; batch adversarial loss: 0.447111\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021543; batch adversarial loss: 0.333561\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014539; batch adversarial loss: 0.503767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.361267\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037137; batch adversarial loss: 0.475120\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004966; batch adversarial loss: 0.460946\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016196; batch adversarial loss: 0.503774\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040717; batch adversarial loss: 0.478575\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021886; batch adversarial loss: 0.510311\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013252; batch adversarial loss: 0.484009\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015195; batch adversarial loss: 0.423988\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032758; batch adversarial loss: 0.338402\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014068; batch adversarial loss: 0.428853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026218; batch adversarial loss: 0.391771\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013188; batch adversarial loss: 0.309382\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009635; batch adversarial loss: 0.453746\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039496; batch adversarial loss: 0.509506\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015914; batch adversarial loss: 0.424429\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013605; batch adversarial loss: 0.424838\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014308; batch adversarial loss: 0.398867\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006824; batch adversarial loss: 0.444426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009280; batch adversarial loss: 0.400296\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693085; batch adversarial loss: 0.662281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459249; batch adversarial loss: 0.641616\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447500; batch adversarial loss: 0.620363\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417321; batch adversarial loss: 0.614013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.472611; batch adversarial loss: 0.611212\n",
      "epoch 5; iter: 0; batch classifier loss: 0.388456; batch adversarial loss: 0.598769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.468645; batch adversarial loss: 0.573083\n",
      "epoch 7; iter: 0; batch classifier loss: 0.395378; batch adversarial loss: 0.596248\n",
      "epoch 8; iter: 0; batch classifier loss: 0.332513; batch adversarial loss: 0.547391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441985; batch adversarial loss: 0.488250\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417680; batch adversarial loss: 0.465647\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328005; batch adversarial loss: 0.494190\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350969; batch adversarial loss: 0.570630\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.524883\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308391; batch adversarial loss: 0.488772\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284033; batch adversarial loss: 0.480851\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281018; batch adversarial loss: 0.475543\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287877; batch adversarial loss: 0.493921\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258771; batch adversarial loss: 0.515615\n",
      "epoch 19; iter: 0; batch classifier loss: 0.292685; batch adversarial loss: 0.496348\n",
      "epoch 20; iter: 0; batch classifier loss: 0.292560; batch adversarial loss: 0.490115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279218; batch adversarial loss: 0.419826\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242494; batch adversarial loss: 0.531816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241196; batch adversarial loss: 0.486927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276351; batch adversarial loss: 0.470615\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275091; batch adversarial loss: 0.508006\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307434; batch adversarial loss: 0.469554\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237340; batch adversarial loss: 0.477429\n",
      "epoch 28; iter: 0; batch classifier loss: 0.290988; batch adversarial loss: 0.457327\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199280; batch adversarial loss: 0.522835\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254156; batch adversarial loss: 0.493034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275077; batch adversarial loss: 0.549678\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233250; batch adversarial loss: 0.450590\n",
      "epoch 33; iter: 0; batch classifier loss: 0.280732; batch adversarial loss: 0.506075\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266267; batch adversarial loss: 0.477052\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206368; batch adversarial loss: 0.454302\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224367; batch adversarial loss: 0.542848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230237; batch adversarial loss: 0.447229\n",
      "epoch 38; iter: 0; batch classifier loss: 0.275628; batch adversarial loss: 0.509693\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315788; batch adversarial loss: 0.542513\n",
      "epoch 40; iter: 0; batch classifier loss: 0.237254; batch adversarial loss: 0.530994\n",
      "epoch 41; iter: 0; batch classifier loss: 0.263721; batch adversarial loss: 0.461171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247246; batch adversarial loss: 0.472925\n",
      "epoch 43; iter: 0; batch classifier loss: 0.273321; batch adversarial loss: 0.368453\n",
      "epoch 44; iter: 0; batch classifier loss: 0.215345; batch adversarial loss: 0.541626\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135869; batch adversarial loss: 0.447735\n",
      "epoch 46; iter: 0; batch classifier loss: 0.218697; batch adversarial loss: 0.459830\n",
      "epoch 47; iter: 0; batch classifier loss: 0.273158; batch adversarial loss: 0.470811\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126933; batch adversarial loss: 0.493677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099558; batch adversarial loss: 0.590653\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123307; batch adversarial loss: 0.495296\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105648; batch adversarial loss: 0.562736\n",
      "epoch 52; iter: 0; batch classifier loss: 0.193992; batch adversarial loss: 0.485855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.210242; batch adversarial loss: 0.457080\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122267; batch adversarial loss: 0.484358\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141533; batch adversarial loss: 0.471353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.183923; batch adversarial loss: 0.519616\n",
      "epoch 57; iter: 0; batch classifier loss: 0.188705; batch adversarial loss: 0.508581\n",
      "epoch 58; iter: 0; batch classifier loss: 0.157608; batch adversarial loss: 0.471547\n",
      "epoch 59; iter: 0; batch classifier loss: 0.209153; batch adversarial loss: 0.423039\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161690; batch adversarial loss: 0.483726\n",
      "epoch 61; iter: 0; batch classifier loss: 0.231551; batch adversarial loss: 0.385736\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078010; batch adversarial loss: 0.433605\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090402; batch adversarial loss: 0.466165\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066654; batch adversarial loss: 0.372152\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153065; batch adversarial loss: 0.421455\n",
      "epoch 66; iter: 0; batch classifier loss: 0.217939; batch adversarial loss: 0.523616\n",
      "epoch 67; iter: 0; batch classifier loss: 0.236140; batch adversarial loss: 0.434859\n",
      "epoch 68; iter: 0; batch classifier loss: 0.159362; batch adversarial loss: 0.435263\n",
      "epoch 69; iter: 0; batch classifier loss: 0.192105; batch adversarial loss: 0.418825\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173401; batch adversarial loss: 0.459385\n",
      "epoch 71; iter: 0; batch classifier loss: 0.161948; batch adversarial loss: 0.409243\n",
      "epoch 72; iter: 0; batch classifier loss: 0.154585; batch adversarial loss: 0.445771\n",
      "epoch 73; iter: 0; batch classifier loss: 0.222827; batch adversarial loss: 0.508523\n",
      "epoch 74; iter: 0; batch classifier loss: 0.218868; batch adversarial loss: 0.483771\n",
      "epoch 75; iter: 0; batch classifier loss: 0.198787; batch adversarial loss: 0.495716\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218579; batch adversarial loss: 0.458483\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170230; batch adversarial loss: 0.397664\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083651; batch adversarial loss: 0.397175\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081819; batch adversarial loss: 0.458394\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065795; batch adversarial loss: 0.433661\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075602; batch adversarial loss: 0.467735\n",
      "epoch 82; iter: 0; batch classifier loss: 0.162708; batch adversarial loss: 0.433521\n",
      "epoch 83; iter: 0; batch classifier loss: 0.199472; batch adversarial loss: 0.347448\n",
      "epoch 84; iter: 0; batch classifier loss: 0.223312; batch adversarial loss: 0.470486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.225977; batch adversarial loss: 0.473462\n",
      "epoch 86; iter: 0; batch classifier loss: 0.147745; batch adversarial loss: 0.421251\n",
      "epoch 87; iter: 0; batch classifier loss: 0.154711; batch adversarial loss: 0.520294\n",
      "epoch 88; iter: 0; batch classifier loss: 0.145294; batch adversarial loss: 0.495581\n",
      "epoch 89; iter: 0; batch classifier loss: 0.174975; batch adversarial loss: 0.409637\n",
      "epoch 90; iter: 0; batch classifier loss: 0.217554; batch adversarial loss: 0.383003\n",
      "epoch 91; iter: 0; batch classifier loss: 0.198974; batch adversarial loss: 0.347906\n",
      "epoch 92; iter: 0; batch classifier loss: 0.164137; batch adversarial loss: 0.359574\n",
      "epoch 93; iter: 0; batch classifier loss: 0.195770; batch adversarial loss: 0.421894\n",
      "epoch 94; iter: 0; batch classifier loss: 0.184073; batch adversarial loss: 0.495451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.158961; batch adversarial loss: 0.421465\n",
      "epoch 96; iter: 0; batch classifier loss: 0.154033; batch adversarial loss: 0.371166\n",
      "epoch 97; iter: 0; batch classifier loss: 0.104291; batch adversarial loss: 0.406768\n",
      "epoch 98; iter: 0; batch classifier loss: 0.133575; batch adversarial loss: 0.434148\n",
      "epoch 99; iter: 0; batch classifier loss: 0.094548; batch adversarial loss: 0.512909\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109288; batch adversarial loss: 0.534285\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097142; batch adversarial loss: 0.332888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.099719; batch adversarial loss: 0.588608\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076624; batch adversarial loss: 0.579868\n",
      "epoch 104; iter: 0; batch classifier loss: 0.096004; batch adversarial loss: 0.428487\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040945; batch adversarial loss: 0.433206\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071173; batch adversarial loss: 0.448050\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037174; batch adversarial loss: 0.500313\n",
      "epoch 108; iter: 0; batch classifier loss: 0.084204; batch adversarial loss: 0.400052\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053179; batch adversarial loss: 0.554778\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041349; batch adversarial loss: 0.447944\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029339; batch adversarial loss: 0.406087\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075347; batch adversarial loss: 0.434353\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087026; batch adversarial loss: 0.500524\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039364; batch adversarial loss: 0.466914\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039634; batch adversarial loss: 0.517326\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035686; batch adversarial loss: 0.445073\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053491; batch adversarial loss: 0.448487\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041200; batch adversarial loss: 0.448621\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032083; batch adversarial loss: 0.417373\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037236; batch adversarial loss: 0.456034\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029462; batch adversarial loss: 0.415405\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041890; batch adversarial loss: 0.465129\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062895; batch adversarial loss: 0.392118\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056565; batch adversarial loss: 0.451159\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050805; batch adversarial loss: 0.371470\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028422; batch adversarial loss: 0.516682\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031574; batch adversarial loss: 0.438138\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044579; batch adversarial loss: 0.330268\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017921; batch adversarial loss: 0.373132\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019821; batch adversarial loss: 0.421796\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055141; batch adversarial loss: 0.453493\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025851; batch adversarial loss: 0.406154\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026327; batch adversarial loss: 0.487330\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045377; batch adversarial loss: 0.428682\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014885; batch adversarial loss: 0.488482\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038886; batch adversarial loss: 0.455733\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028592; batch adversarial loss: 0.486886\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014470; batch adversarial loss: 0.474487\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034356; batch adversarial loss: 0.383112\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024950; batch adversarial loss: 0.480038\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029268; batch adversarial loss: 0.451002\n",
      "epoch 142; iter: 0; batch classifier loss: 0.069304; batch adversarial loss: 0.318381\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019939; batch adversarial loss: 0.524773\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018288; batch adversarial loss: 0.457066\n",
      "epoch 145; iter: 0; batch classifier loss: 0.016692; batch adversarial loss: 0.482261\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031785; batch adversarial loss: 0.491223\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015302; batch adversarial loss: 0.382310\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014636; batch adversarial loss: 0.450364\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013991; batch adversarial loss: 0.539956\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036022; batch adversarial loss: 0.445002\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019834; batch adversarial loss: 0.591777\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030749; batch adversarial loss: 0.444303\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.511254\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036836; batch adversarial loss: 0.405929\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013980; batch adversarial loss: 0.460842\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022565; batch adversarial loss: 0.368507\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016959; batch adversarial loss: 0.385896\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014648; batch adversarial loss: 0.359435\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024464; batch adversarial loss: 0.499865\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047501; batch adversarial loss: 0.348020\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031083; batch adversarial loss: 0.496812\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007365; batch adversarial loss: 0.384821\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007979; batch adversarial loss: 0.416228\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031702; batch adversarial loss: 0.588951\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023348; batch adversarial loss: 0.368931\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027697; batch adversarial loss: 0.522163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030900; batch adversarial loss: 0.426266\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017144; batch adversarial loss: 0.503968\n",
      "epoch 169; iter: 0; batch classifier loss: 0.050494; batch adversarial loss: 0.420866\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013257; batch adversarial loss: 0.396672\n",
      "epoch 171; iter: 0; batch classifier loss: 0.046690; batch adversarial loss: 0.422430\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023546; batch adversarial loss: 0.408290\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014137; batch adversarial loss: 0.378014\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006447; batch adversarial loss: 0.384531\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.447194\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016709; batch adversarial loss: 0.433343\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024862; batch adversarial loss: 0.396011\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023155; batch adversarial loss: 0.465729\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013402; batch adversarial loss: 0.456012\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.517276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022930; batch adversarial loss: 0.572163\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005298; batch adversarial loss: 0.425883\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024027; batch adversarial loss: 0.487095\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040935; batch adversarial loss: 0.408667\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007055; batch adversarial loss: 0.458079\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022543; batch adversarial loss: 0.487328\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013903; batch adversarial loss: 0.590941\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014476; batch adversarial loss: 0.428056\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014485; batch adversarial loss: 0.360809\n",
      "epoch 190; iter: 0; batch classifier loss: 0.005652; batch adversarial loss: 0.541979\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005105; batch adversarial loss: 0.438248\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008276; batch adversarial loss: 0.422873\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031553; batch adversarial loss: 0.480759\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009125; batch adversarial loss: 0.491077\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004060; batch adversarial loss: 0.407978\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009282; batch adversarial loss: 0.548120\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014492; batch adversarial loss: 0.424183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.025182; batch adversarial loss: 0.493333\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016597; batch adversarial loss: 0.477309\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687904; batch adversarial loss: 0.605483\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466511; batch adversarial loss: 0.600555\n",
      "epoch 2; iter: 0; batch classifier loss: 0.377914; batch adversarial loss: 0.610660\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442957; batch adversarial loss: 0.588390\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419407; batch adversarial loss: 0.565516\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495587; batch adversarial loss: 0.566339\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626238; batch adversarial loss: 0.567574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541967; batch adversarial loss: 0.591873\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581442; batch adversarial loss: 0.562209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525864; batch adversarial loss: 0.559617\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437490; batch adversarial loss: 0.523616\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445348; batch adversarial loss: 0.460504\n",
      "epoch 12; iter: 0; batch classifier loss: 0.261032; batch adversarial loss: 0.471290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302074; batch adversarial loss: 0.512173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340636; batch adversarial loss: 0.531971\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265455; batch adversarial loss: 0.482620\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270829; batch adversarial loss: 0.546171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265383; batch adversarial loss: 0.500631\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313881; batch adversarial loss: 0.463518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247632; batch adversarial loss: 0.433918\n",
      "epoch 20; iter: 0; batch classifier loss: 0.275486; batch adversarial loss: 0.469120\n",
      "epoch 21; iter: 0; batch classifier loss: 0.276330; batch adversarial loss: 0.491863\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214262; batch adversarial loss: 0.507362\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206219; batch adversarial loss: 0.466799\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188442; batch adversarial loss: 0.498866\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254160; batch adversarial loss: 0.430087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182061; batch adversarial loss: 0.497125\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258122; batch adversarial loss: 0.389313\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204272; batch adversarial loss: 0.502933\n",
      "epoch 29; iter: 0; batch classifier loss: 0.287004; batch adversarial loss: 0.418205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.245705; batch adversarial loss: 0.449619\n",
      "epoch 31; iter: 0; batch classifier loss: 0.255871; batch adversarial loss: 0.432582\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218558; batch adversarial loss: 0.483337\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164723; batch adversarial loss: 0.397049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230540; batch adversarial loss: 0.484264\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215665; batch adversarial loss: 0.443468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215941; batch adversarial loss: 0.422892\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222070; batch adversarial loss: 0.463872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.315033; batch adversarial loss: 0.452837\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268458; batch adversarial loss: 0.477565\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272410; batch adversarial loss: 0.422849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.289054; batch adversarial loss: 0.356824\n",
      "epoch 42; iter: 0; batch classifier loss: 0.274688; batch adversarial loss: 0.437745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.250166; batch adversarial loss: 0.395519\n",
      "epoch 44; iter: 0; batch classifier loss: 0.266665; batch adversarial loss: 0.470399\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277918; batch adversarial loss: 0.366977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.190383; batch adversarial loss: 0.526560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259667; batch adversarial loss: 0.549957\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228083; batch adversarial loss: 0.400964\n",
      "epoch 49; iter: 0; batch classifier loss: 0.202145; batch adversarial loss: 0.459282\n",
      "epoch 50; iter: 0; batch classifier loss: 0.292846; batch adversarial loss: 0.459622\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124992; batch adversarial loss: 0.494624\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.470736\n",
      "epoch 53; iter: 0; batch classifier loss: 0.162769; batch adversarial loss: 0.513939\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147807; batch adversarial loss: 0.555699\n",
      "epoch 55; iter: 0; batch classifier loss: 0.179673; batch adversarial loss: 0.412280\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184850; batch adversarial loss: 0.411856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179788; batch adversarial loss: 0.505891\n",
      "epoch 58; iter: 0; batch classifier loss: 0.182801; batch adversarial loss: 0.519115\n",
      "epoch 59; iter: 0; batch classifier loss: 0.217738; batch adversarial loss: 0.432873\n",
      "epoch 60; iter: 0; batch classifier loss: 0.184532; batch adversarial loss: 0.520534\n",
      "epoch 61; iter: 0; batch classifier loss: 0.234415; batch adversarial loss: 0.409834\n",
      "epoch 62; iter: 0; batch classifier loss: 0.251917; batch adversarial loss: 0.495099\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175033; batch adversarial loss: 0.447335\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120518; batch adversarial loss: 0.446492\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130967; batch adversarial loss: 0.521481\n",
      "epoch 66; iter: 0; batch classifier loss: 0.171359; batch adversarial loss: 0.547117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.238593; batch adversarial loss: 0.446828\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132465; batch adversarial loss: 0.532336\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174439; batch adversarial loss: 0.460538\n",
      "epoch 70; iter: 0; batch classifier loss: 0.206046; batch adversarial loss: 0.434343\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178064; batch adversarial loss: 0.519585\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191442; batch adversarial loss: 0.458374\n",
      "epoch 73; iter: 0; batch classifier loss: 0.225486; batch adversarial loss: 0.471246\n",
      "epoch 74; iter: 0; batch classifier loss: 0.258401; batch adversarial loss: 0.301009\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067473; batch adversarial loss: 0.349035\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103800; batch adversarial loss: 0.519314\n",
      "epoch 77; iter: 0; batch classifier loss: 0.190047; batch adversarial loss: 0.460018\n",
      "epoch 78; iter: 0; batch classifier loss: 0.224045; batch adversarial loss: 0.472223\n",
      "epoch 79; iter: 0; batch classifier loss: 0.197588; batch adversarial loss: 0.471275\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206283; batch adversarial loss: 0.520736\n",
      "epoch 81; iter: 0; batch classifier loss: 0.238859; batch adversarial loss: 0.483565\n",
      "epoch 82; iter: 0; batch classifier loss: 0.247102; batch adversarial loss: 0.446702\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111129; batch adversarial loss: 0.519237\n",
      "epoch 84; iter: 0; batch classifier loss: 0.123304; batch adversarial loss: 0.509441\n",
      "epoch 85; iter: 0; batch classifier loss: 0.202308; batch adversarial loss: 0.443977\n",
      "epoch 86; iter: 0; batch classifier loss: 0.271653; batch adversarial loss: 0.422774\n",
      "epoch 87; iter: 0; batch classifier loss: 0.246930; batch adversarial loss: 0.534192\n",
      "epoch 88; iter: 0; batch classifier loss: 0.167563; batch adversarial loss: 0.461273\n",
      "epoch 89; iter: 0; batch classifier loss: 0.127750; batch adversarial loss: 0.471271\n",
      "epoch 90; iter: 0; batch classifier loss: 0.131664; batch adversarial loss: 0.493806\n",
      "epoch 91; iter: 0; batch classifier loss: 0.257113; batch adversarial loss: 0.446643\n",
      "epoch 92; iter: 0; batch classifier loss: 0.203467; batch adversarial loss: 0.373555\n",
      "epoch 93; iter: 0; batch classifier loss: 0.145045; batch adversarial loss: 0.483594\n",
      "epoch 94; iter: 0; batch classifier loss: 0.222802; batch adversarial loss: 0.435056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.089605; batch adversarial loss: 0.495246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071679; batch adversarial loss: 0.506383\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049022; batch adversarial loss: 0.439166\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048960; batch adversarial loss: 0.417905\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051762; batch adversarial loss: 0.445371\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034892; batch adversarial loss: 0.440375\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048655; batch adversarial loss: 0.404657\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062507; batch adversarial loss: 0.644776\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044812; batch adversarial loss: 0.406369\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040833; batch adversarial loss: 0.423333\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041882; batch adversarial loss: 0.461110\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044051; batch adversarial loss: 0.424585\n",
      "epoch 107; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.459323\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028617; batch adversarial loss: 0.461199\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045961; batch adversarial loss: 0.472002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030125; batch adversarial loss: 0.500724\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023373; batch adversarial loss: 0.415509\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033340; batch adversarial loss: 0.439486\n",
      "epoch 113; iter: 0; batch classifier loss: 0.019914; batch adversarial loss: 0.387887\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028562; batch adversarial loss: 0.509668\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032807; batch adversarial loss: 0.456324\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025926; batch adversarial loss: 0.513025\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033185; batch adversarial loss: 0.432081\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015977; batch adversarial loss: 0.398156\n",
      "epoch 119; iter: 0; batch classifier loss: 0.030340; batch adversarial loss: 0.498414\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015871; batch adversarial loss: 0.494025\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019904; batch adversarial loss: 0.505190\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032550; batch adversarial loss: 0.392692\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027270; batch adversarial loss: 0.430841\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027316; batch adversarial loss: 0.468782\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022325; batch adversarial loss: 0.406529\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021891; batch adversarial loss: 0.567121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062398; batch adversarial loss: 0.550322\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022388; batch adversarial loss: 0.541902\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047696; batch adversarial loss: 0.332991\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019420; batch adversarial loss: 0.485103\n",
      "epoch 131; iter: 0; batch classifier loss: 0.013987; batch adversarial loss: 0.518932\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021143; batch adversarial loss: 0.504801\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025752; batch adversarial loss: 0.538768\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012003; batch adversarial loss: 0.485159\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021119; batch adversarial loss: 0.407638\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026568; batch adversarial loss: 0.548258\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019067; batch adversarial loss: 0.382954\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031206; batch adversarial loss: 0.475523\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016586; batch adversarial loss: 0.477770\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024828; batch adversarial loss: 0.557963\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036692; batch adversarial loss: 0.497013\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016187; batch adversarial loss: 0.440643\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011886; batch adversarial loss: 0.420177\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029773; batch adversarial loss: 0.390889\n",
      "epoch 145; iter: 0; batch classifier loss: 0.008822; batch adversarial loss: 0.460026\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021458; batch adversarial loss: 0.478698\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014977; batch adversarial loss: 0.433591\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022847; batch adversarial loss: 0.494779\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013180; batch adversarial loss: 0.366853\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034525; batch adversarial loss: 0.450892\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022940; batch adversarial loss: 0.547591\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019460; batch adversarial loss: 0.486841\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033394; batch adversarial loss: 0.448544\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008680; batch adversarial loss: 0.469183\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010863; batch adversarial loss: 0.498329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016746; batch adversarial loss: 0.441447\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020682; batch adversarial loss: 0.414962\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042020; batch adversarial loss: 0.390806\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011716; batch adversarial loss: 0.476458\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005613; batch adversarial loss: 0.555755\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016627; batch adversarial loss: 0.399564\n",
      "epoch 162; iter: 0; batch classifier loss: 0.006843; batch adversarial loss: 0.491678\n",
      "epoch 163; iter: 0; batch classifier loss: 0.004344; batch adversarial loss: 0.555849\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011489; batch adversarial loss: 0.497205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.395287\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020884; batch adversarial loss: 0.404166\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014838; batch adversarial loss: 0.436464\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005713; batch adversarial loss: 0.493860\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.435678\n",
      "epoch 170; iter: 0; batch classifier loss: 0.065615; batch adversarial loss: 0.346988\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012758; batch adversarial loss: 0.522928\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008653; batch adversarial loss: 0.416313\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013083; batch adversarial loss: 0.556099\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015873; batch adversarial loss: 0.441077\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011183; batch adversarial loss: 0.479859\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016384; batch adversarial loss: 0.446201\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011816; batch adversarial loss: 0.584622\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020499; batch adversarial loss: 0.492156\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011131; batch adversarial loss: 0.489502\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020984; batch adversarial loss: 0.410370\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014642; batch adversarial loss: 0.515835\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003637; batch adversarial loss: 0.373405\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014603; batch adversarial loss: 0.410650\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015244; batch adversarial loss: 0.431031\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004923; batch adversarial loss: 0.443508\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011848; batch adversarial loss: 0.452230\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018077; batch adversarial loss: 0.444947\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012696; batch adversarial loss: 0.546763\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007202; batch adversarial loss: 0.399201\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009280; batch adversarial loss: 0.317563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.003153; batch adversarial loss: 0.490663\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028295; batch adversarial loss: 0.482563\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018358; batch adversarial loss: 0.467973\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025584; batch adversarial loss: 0.488597\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027996; batch adversarial loss: 0.367032\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007516; batch adversarial loss: 0.527783\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016119; batch adversarial loss: 0.449419\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018130; batch adversarial loss: 0.385654\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017514; batch adversarial loss: 0.454934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669190; batch adversarial loss: 0.540461\n",
      "epoch 1; iter: 0; batch classifier loss: 0.485269; batch adversarial loss: 0.598299\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537995; batch adversarial loss: 0.615017\n",
      "epoch 3; iter: 0; batch classifier loss: 0.443046; batch adversarial loss: 0.610766\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349527; batch adversarial loss: 0.600310\n",
      "epoch 5; iter: 0; batch classifier loss: 0.484478; batch adversarial loss: 0.621613\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481975; batch adversarial loss: 0.547283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512785; batch adversarial loss: 0.608883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467190; batch adversarial loss: 0.591053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561447; batch adversarial loss: 0.490669\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579251; batch adversarial loss: 0.568023\n",
      "epoch 11; iter: 0; batch classifier loss: 0.486778; batch adversarial loss: 0.518364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368662; batch adversarial loss: 0.519093\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357998; batch adversarial loss: 0.440356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318462; batch adversarial loss: 0.540602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286597; batch adversarial loss: 0.541830\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207251; batch adversarial loss: 0.455770\n",
      "epoch 17; iter: 0; batch classifier loss: 0.236505; batch adversarial loss: 0.372372\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204799; batch adversarial loss: 0.585578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.165698; batch adversarial loss: 0.455274\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200472; batch adversarial loss: 0.453226\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204086; batch adversarial loss: 0.389838\n",
      "epoch 22; iter: 0; batch classifier loss: 0.239656; batch adversarial loss: 0.457758\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145425; batch adversarial loss: 0.454817\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186547; batch adversarial loss: 0.388395\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166029; batch adversarial loss: 0.530414\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212527; batch adversarial loss: 0.481171\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163793; batch adversarial loss: 0.481831\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158002; batch adversarial loss: 0.555208\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166343; batch adversarial loss: 0.496228\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172092; batch adversarial loss: 0.473443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134219; batch adversarial loss: 0.483847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168666; batch adversarial loss: 0.378030\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102050; batch adversarial loss: 0.478504\n",
      "epoch 34; iter: 0; batch classifier loss: 0.150643; batch adversarial loss: 0.472410\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139839; batch adversarial loss: 0.521863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109089; batch adversarial loss: 0.534533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107287; batch adversarial loss: 0.433686\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156076; batch adversarial loss: 0.509236\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176091; batch adversarial loss: 0.512790\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108126; batch adversarial loss: 0.478771\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129477; batch adversarial loss: 0.391655\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129014; batch adversarial loss: 0.371919\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130327; batch adversarial loss: 0.444217\n",
      "epoch 44; iter: 0; batch classifier loss: 0.115119; batch adversarial loss: 0.396090\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142904; batch adversarial loss: 0.420538\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122245; batch adversarial loss: 0.480521\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128060; batch adversarial loss: 0.541593\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125461; batch adversarial loss: 0.454392\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155366; batch adversarial loss: 0.396261\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102422; batch adversarial loss: 0.472383\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114532; batch adversarial loss: 0.508536\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142915; batch adversarial loss: 0.434414\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081467; batch adversarial loss: 0.433716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.134686; batch adversarial loss: 0.480143\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125805; batch adversarial loss: 0.428621\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124765; batch adversarial loss: 0.456359\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099695; batch adversarial loss: 0.500718\n",
      "epoch 58; iter: 0; batch classifier loss: 0.142202; batch adversarial loss: 0.467257\n",
      "epoch 59; iter: 0; batch classifier loss: 0.113954; batch adversarial loss: 0.473229\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157725; batch adversarial loss: 0.488144\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103809; batch adversarial loss: 0.510914\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078534; batch adversarial loss: 0.385049\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137410; batch adversarial loss: 0.443498\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109073; batch adversarial loss: 0.436179\n",
      "epoch 65; iter: 0; batch classifier loss: 0.117861; batch adversarial loss: 0.471259\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121840; batch adversarial loss: 0.420331\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116432; batch adversarial loss: 0.357735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123881; batch adversarial loss: 0.419275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.116766; batch adversarial loss: 0.558619\n",
      "epoch 70; iter: 0; batch classifier loss: 0.132253; batch adversarial loss: 0.446624\n",
      "epoch 71; iter: 0; batch classifier loss: 0.142559; batch adversarial loss: 0.409980\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097755; batch adversarial loss: 0.544407\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155554; batch adversarial loss: 0.432644\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084214; batch adversarial loss: 0.443748\n",
      "epoch 75; iter: 0; batch classifier loss: 0.131482; batch adversarial loss: 0.447977\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102366; batch adversarial loss: 0.487534\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103326; batch adversarial loss: 0.459088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155566; batch adversarial loss: 0.431764\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075974; batch adversarial loss: 0.490008\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074088; batch adversarial loss: 0.401048\n",
      "epoch 81; iter: 0; batch classifier loss: 0.123908; batch adversarial loss: 0.437327\n",
      "epoch 82; iter: 0; batch classifier loss: 0.184820; batch adversarial loss: 0.406186\n",
      "epoch 83; iter: 0; batch classifier loss: 0.121093; batch adversarial loss: 0.365687\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070081; batch adversarial loss: 0.497590\n",
      "epoch 85; iter: 0; batch classifier loss: 0.121705; batch adversarial loss: 0.416477\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089892; batch adversarial loss: 0.359267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118837; batch adversarial loss: 0.435081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.140556; batch adversarial loss: 0.429294\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099457; batch adversarial loss: 0.403710\n",
      "epoch 90; iter: 0; batch classifier loss: 0.108963; batch adversarial loss: 0.499880\n",
      "epoch 91; iter: 0; batch classifier loss: 0.105581; batch adversarial loss: 0.420521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089551; batch adversarial loss: 0.467877\n",
      "epoch 93; iter: 0; batch classifier loss: 0.095160; batch adversarial loss: 0.460039\n",
      "epoch 94; iter: 0; batch classifier loss: 0.125058; batch adversarial loss: 0.527708\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091173; batch adversarial loss: 0.419343\n",
      "epoch 96; iter: 0; batch classifier loss: 0.107517; batch adversarial loss: 0.491861\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075198; batch adversarial loss: 0.498573\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045949; batch adversarial loss: 0.498641\n",
      "epoch 99; iter: 0; batch classifier loss: 0.131996; batch adversarial loss: 0.378685\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047039; batch adversarial loss: 0.553400\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080506; batch adversarial loss: 0.462259\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084096; batch adversarial loss: 0.454198\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065702; batch adversarial loss: 0.436673\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070103; batch adversarial loss: 0.435573\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117625; batch adversarial loss: 0.447148\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095457; batch adversarial loss: 0.436720\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056190; batch adversarial loss: 0.522631\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053755; batch adversarial loss: 0.571385\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034585; batch adversarial loss: 0.438284\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051988; batch adversarial loss: 0.413198\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076990; batch adversarial loss: 0.391965\n",
      "epoch 112; iter: 0; batch classifier loss: 0.086246; batch adversarial loss: 0.488343\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052452; batch adversarial loss: 0.413561\n",
      "epoch 114; iter: 0; batch classifier loss: 0.114416; batch adversarial loss: 0.368195\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056686; batch adversarial loss: 0.452452\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084338; batch adversarial loss: 0.450806\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043722; batch adversarial loss: 0.413328\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085366; batch adversarial loss: 0.473255\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036054; batch adversarial loss: 0.569114\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045062; batch adversarial loss: 0.447783\n",
      "epoch 121; iter: 0; batch classifier loss: 0.088909; batch adversarial loss: 0.498568\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035740; batch adversarial loss: 0.384428\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041112; batch adversarial loss: 0.528714\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058400; batch adversarial loss: 0.455188\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058850; batch adversarial loss: 0.513847\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043394; batch adversarial loss: 0.392833\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032405; batch adversarial loss: 0.433192\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038424; batch adversarial loss: 0.392525\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048000; batch adversarial loss: 0.370101\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018552; batch adversarial loss: 0.435057\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070991; batch adversarial loss: 0.430656\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056203; batch adversarial loss: 0.547384\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028663; batch adversarial loss: 0.437771\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044534; batch adversarial loss: 0.411713\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031149; batch adversarial loss: 0.501723\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057414; batch adversarial loss: 0.528372\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022992; batch adversarial loss: 0.382257\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014533; batch adversarial loss: 0.460439\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038997; batch adversarial loss: 0.465993\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.447440\n",
      "epoch 141; iter: 0; batch classifier loss: 0.055423; batch adversarial loss: 0.520024\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047155; batch adversarial loss: 0.447609\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037649; batch adversarial loss: 0.369611\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011702; batch adversarial loss: 0.443021\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018956; batch adversarial loss: 0.492126\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025415; batch adversarial loss: 0.525060\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016567; batch adversarial loss: 0.441270\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055694; batch adversarial loss: 0.519444\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015095; batch adversarial loss: 0.425812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018292; batch adversarial loss: 0.387421\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045614; batch adversarial loss: 0.454794\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031093; batch adversarial loss: 0.495900\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033864; batch adversarial loss: 0.517037\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029264; batch adversarial loss: 0.541295\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065069; batch adversarial loss: 0.396101\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023192; batch adversarial loss: 0.394881\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040538; batch adversarial loss: 0.386197\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047892; batch adversarial loss: 0.517162\n",
      "epoch 159; iter: 0; batch classifier loss: 0.069493; batch adversarial loss: 0.451350\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017853; batch adversarial loss: 0.541323\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023467; batch adversarial loss: 0.355099\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031735; batch adversarial loss: 0.410966\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015225; batch adversarial loss: 0.447329\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059136; batch adversarial loss: 0.465697\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010034; batch adversarial loss: 0.387463\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048037; batch adversarial loss: 0.393627\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029889; batch adversarial loss: 0.396279\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026480; batch adversarial loss: 0.399104\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007841; batch adversarial loss: 0.454221\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008534; batch adversarial loss: 0.438413\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.449510\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021151; batch adversarial loss: 0.495424\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012774; batch adversarial loss: 0.412307\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012789; batch adversarial loss: 0.555952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.054102; batch adversarial loss: 0.429337\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009945; batch adversarial loss: 0.362652\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024329; batch adversarial loss: 0.454478\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008924; batch adversarial loss: 0.452476\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023667; batch adversarial loss: 0.507783\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024874; batch adversarial loss: 0.408257\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046488; batch adversarial loss: 0.432509\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022862; batch adversarial loss: 0.498737\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043796; batch adversarial loss: 0.385155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.035814; batch adversarial loss: 0.388545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.498168\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.436483\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018241; batch adversarial loss: 0.368673\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003522; batch adversarial loss: 0.447566\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016189; batch adversarial loss: 0.433651\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030803; batch adversarial loss: 0.460440\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021076; batch adversarial loss: 0.568572\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013822; batch adversarial loss: 0.415409\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023748; batch adversarial loss: 0.381072\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013654; batch adversarial loss: 0.457845\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035112; batch adversarial loss: 0.460607\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039658; batch adversarial loss: 0.510655\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013341; batch adversarial loss: 0.445430\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012285; batch adversarial loss: 0.340842\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029024; batch adversarial loss: 0.376444\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709405; batch adversarial loss: 0.889961\n",
      "epoch 1; iter: 0; batch classifier loss: 0.737672; batch adversarial loss: 0.975437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.820024; batch adversarial loss: 0.896696\n",
      "epoch 3; iter: 0; batch classifier loss: 0.869951; batch adversarial loss: 0.820197\n",
      "epoch 4; iter: 0; batch classifier loss: 0.847585; batch adversarial loss: 0.761525\n",
      "epoch 5; iter: 0; batch classifier loss: 0.764180; batch adversarial loss: 0.706103\n",
      "epoch 6; iter: 0; batch classifier loss: 0.764514; batch adversarial loss: 0.644597\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528621; batch adversarial loss: 0.598996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416838; batch adversarial loss: 0.590414\n",
      "epoch 9; iter: 0; batch classifier loss: 0.393470; batch adversarial loss: 0.495750\n",
      "epoch 10; iter: 0; batch classifier loss: 0.385817; batch adversarial loss: 0.504795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.234006; batch adversarial loss: 0.544526\n",
      "epoch 12; iter: 0; batch classifier loss: 0.268535; batch adversarial loss: 0.494313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234700; batch adversarial loss: 0.549812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208834; batch adversarial loss: 0.503384\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353703; batch adversarial loss: 0.460676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301986; batch adversarial loss: 0.467362\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262049; batch adversarial loss: 0.473389\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232673; batch adversarial loss: 0.479103\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271168; batch adversarial loss: 0.472037\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251519; batch adversarial loss: 0.569254\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287419; batch adversarial loss: 0.479100\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252753; batch adversarial loss: 0.508336\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236285; batch adversarial loss: 0.456443\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188843; batch adversarial loss: 0.420858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192802; batch adversarial loss: 0.504847\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197646; batch adversarial loss: 0.414037\n",
      "epoch 27; iter: 0; batch classifier loss: 0.145887; batch adversarial loss: 0.501821\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187617; batch adversarial loss: 0.419221\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206501; batch adversarial loss: 0.492903\n",
      "epoch 30; iter: 0; batch classifier loss: 0.221127; batch adversarial loss: 0.442337\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208913; batch adversarial loss: 0.383044\n",
      "epoch 32; iter: 0; batch classifier loss: 0.205594; batch adversarial loss: 0.571229\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168038; batch adversarial loss: 0.447335\n",
      "epoch 34; iter: 0; batch classifier loss: 0.158545; batch adversarial loss: 0.411578\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127071; batch adversarial loss: 0.414314\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131499; batch adversarial loss: 0.414949\n",
      "epoch 37; iter: 0; batch classifier loss: 0.171195; batch adversarial loss: 0.393014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122377; batch adversarial loss: 0.477510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122723; batch adversarial loss: 0.489925\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101834; batch adversarial loss: 0.423722\n",
      "epoch 41; iter: 0; batch classifier loss: 0.183354; batch adversarial loss: 0.367017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111614; batch adversarial loss: 0.487457\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149194; batch adversarial loss: 0.513705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110748; batch adversarial loss: 0.438347\n",
      "epoch 45; iter: 0; batch classifier loss: 0.149035; batch adversarial loss: 0.487379\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124961; batch adversarial loss: 0.391110\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117767; batch adversarial loss: 0.476690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109230; batch adversarial loss: 0.480287\n",
      "epoch 49; iter: 0; batch classifier loss: 0.132396; batch adversarial loss: 0.453856\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125643; batch adversarial loss: 0.538957\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129709; batch adversarial loss: 0.522865\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074397; batch adversarial loss: 0.579949\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119577; batch adversarial loss: 0.489921\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132740; batch adversarial loss: 0.424347\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099466; batch adversarial loss: 0.425463\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101113; batch adversarial loss: 0.444949\n",
      "epoch 57; iter: 0; batch classifier loss: 0.176459; batch adversarial loss: 0.431354\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103964; batch adversarial loss: 0.432952\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101201; batch adversarial loss: 0.418959\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074573; batch adversarial loss: 0.493386\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083366; batch adversarial loss: 0.466728\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082063; batch adversarial loss: 0.497052\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070452; batch adversarial loss: 0.434296\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105443; batch adversarial loss: 0.447029\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094723; batch adversarial loss: 0.376870\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070862; batch adversarial loss: 0.442899\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099506; batch adversarial loss: 0.387072\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109766; batch adversarial loss: 0.328567\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094695; batch adversarial loss: 0.449116\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090416; batch adversarial loss: 0.436381\n",
      "epoch 71; iter: 0; batch classifier loss: 0.072911; batch adversarial loss: 0.471837\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062150; batch adversarial loss: 0.432262\n",
      "epoch 73; iter: 0; batch classifier loss: 0.093666; batch adversarial loss: 0.423356\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068897; batch adversarial loss: 0.375928\n",
      "epoch 75; iter: 0; batch classifier loss: 0.113726; batch adversarial loss: 0.425924\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085355; batch adversarial loss: 0.463908\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104832; batch adversarial loss: 0.511263\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090826; batch adversarial loss: 0.460644\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068637; batch adversarial loss: 0.506285\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081055; batch adversarial loss: 0.496208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071697; batch adversarial loss: 0.419019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.088909; batch adversarial loss: 0.396583\n",
      "epoch 83; iter: 0; batch classifier loss: 0.101322; batch adversarial loss: 0.522033\n",
      "epoch 84; iter: 0; batch classifier loss: 0.030301; batch adversarial loss: 0.413131\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052191; batch adversarial loss: 0.364985\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044667; batch adversarial loss: 0.436677\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056229; batch adversarial loss: 0.388269\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077344; batch adversarial loss: 0.505638\n",
      "epoch 89; iter: 0; batch classifier loss: 0.125218; batch adversarial loss: 0.480126\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069121; batch adversarial loss: 0.419531\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043665; batch adversarial loss: 0.401905\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077006; batch adversarial loss: 0.446069\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051346; batch adversarial loss: 0.504821\n",
      "epoch 94; iter: 0; batch classifier loss: 0.025801; batch adversarial loss: 0.408188\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087811; batch adversarial loss: 0.449696\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042030; batch adversarial loss: 0.405670\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089346; batch adversarial loss: 0.424732\n",
      "epoch 98; iter: 0; batch classifier loss: 0.026672; batch adversarial loss: 0.500648\n",
      "epoch 99; iter: 0; batch classifier loss: 0.080233; batch adversarial loss: 0.458990\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064314; batch adversarial loss: 0.478646\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052042; batch adversarial loss: 0.479962\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066324; batch adversarial loss: 0.504690\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075074; batch adversarial loss: 0.490352\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048520; batch adversarial loss: 0.372217\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051927; batch adversarial loss: 0.447084\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039317; batch adversarial loss: 0.545417\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039180; batch adversarial loss: 0.445829\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054436; batch adversarial loss: 0.436650\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047512; batch adversarial loss: 0.428627\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049341; batch adversarial loss: 0.450655\n",
      "epoch 111; iter: 0; batch classifier loss: 0.032618; batch adversarial loss: 0.401559\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036083; batch adversarial loss: 0.455598\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032789; batch adversarial loss: 0.605314\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044728; batch adversarial loss: 0.409738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052003; batch adversarial loss: 0.399004\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034279; batch adversarial loss: 0.527626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.064629; batch adversarial loss: 0.500032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037917; batch adversarial loss: 0.485004\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071442; batch adversarial loss: 0.393355\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026694; batch adversarial loss: 0.480426\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032395; batch adversarial loss: 0.550224\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042148; batch adversarial loss: 0.538016\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049327; batch adversarial loss: 0.370889\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017064; batch adversarial loss: 0.428314\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020212; batch adversarial loss: 0.447250\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022431; batch adversarial loss: 0.486075\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045241; batch adversarial loss: 0.475404\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025642; batch adversarial loss: 0.470951\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048425; batch adversarial loss: 0.515546\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.489842\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046002; batch adversarial loss: 0.491002\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032725; batch adversarial loss: 0.447836\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042193; batch adversarial loss: 0.529988\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029967; batch adversarial loss: 0.428224\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022664; batch adversarial loss: 0.384826\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033051; batch adversarial loss: 0.513098\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020265; batch adversarial loss: 0.448122\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052403; batch adversarial loss: 0.401451\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024244; batch adversarial loss: 0.357320\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048764; batch adversarial loss: 0.467191\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034924; batch adversarial loss: 0.410595\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016863; batch adversarial loss: 0.367115\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015390; batch adversarial loss: 0.473257\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028892; batch adversarial loss: 0.386489\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034307; batch adversarial loss: 0.453424\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028840; batch adversarial loss: 0.442809\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031472; batch adversarial loss: 0.468584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031424; batch adversarial loss: 0.530453\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040309; batch adversarial loss: 0.318032\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034680; batch adversarial loss: 0.401588\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011860; batch adversarial loss: 0.490236\n",
      "epoch 152; iter: 0; batch classifier loss: 0.092311; batch adversarial loss: 0.361808\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020642; batch adversarial loss: 0.413273\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015890; batch adversarial loss: 0.433802\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022408; batch adversarial loss: 0.419765\n",
      "epoch 156; iter: 0; batch classifier loss: 0.049626; batch adversarial loss: 0.431726\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029195; batch adversarial loss: 0.488934\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035763; batch adversarial loss: 0.485139\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024907; batch adversarial loss: 0.479578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034803; batch adversarial loss: 0.443639\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040920; batch adversarial loss: 0.482204\n",
      "epoch 162; iter: 0; batch classifier loss: 0.057809; batch adversarial loss: 0.549158\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036870; batch adversarial loss: 0.372775\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008242; batch adversarial loss: 0.462461\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028244; batch adversarial loss: 0.458476\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021500; batch adversarial loss: 0.454809\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009614; batch adversarial loss: 0.431994\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014227; batch adversarial loss: 0.378741\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009971; batch adversarial loss: 0.416437\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008475; batch adversarial loss: 0.431680\n",
      "epoch 171; iter: 0; batch classifier loss: 0.003433; batch adversarial loss: 0.406659\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042971; batch adversarial loss: 0.392850\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030286; batch adversarial loss: 0.418424\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016419; batch adversarial loss: 0.474326\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016101; batch adversarial loss: 0.578043\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017607; batch adversarial loss: 0.555293\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.523062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.005015; batch adversarial loss: 0.383422\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015636; batch adversarial loss: 0.432386\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011644; batch adversarial loss: 0.409222\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010244; batch adversarial loss: 0.428185\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022626; batch adversarial loss: 0.496227\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018049; batch adversarial loss: 0.527631\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007443; batch adversarial loss: 0.409783\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045317; batch adversarial loss: 0.475157\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015269; batch adversarial loss: 0.403087\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026993; batch adversarial loss: 0.399395\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011795; batch adversarial loss: 0.445988\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011832; batch adversarial loss: 0.412982\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011877; batch adversarial loss: 0.514992\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018817; batch adversarial loss: 0.423853\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007195; batch adversarial loss: 0.402153\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004982; batch adversarial loss: 0.413787\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019154; batch adversarial loss: 0.467818\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012663; batch adversarial loss: 0.393135\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.434869\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006128; batch adversarial loss: 0.444215\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019618; batch adversarial loss: 0.453515\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005743; batch adversarial loss: 0.452438\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699462; batch adversarial loss: 0.864717\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477536; batch adversarial loss: 0.827698\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422792; batch adversarial loss: 0.795414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461528; batch adversarial loss: 0.740643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328220; batch adversarial loss: 0.680879\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346605; batch adversarial loss: 0.640156\n",
      "epoch 6; iter: 0; batch classifier loss: 0.304056; batch adversarial loss: 0.633450\n",
      "epoch 7; iter: 0; batch classifier loss: 0.263196; batch adversarial loss: 0.579359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285720; batch adversarial loss: 0.576830\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241462; batch adversarial loss: 0.553514\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334956; batch adversarial loss: 0.554640\n",
      "epoch 11; iter: 0; batch classifier loss: 0.257503; batch adversarial loss: 0.513429\n",
      "epoch 12; iter: 0; batch classifier loss: 0.172522; batch adversarial loss: 0.517982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248792; batch adversarial loss: 0.496715\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233493; batch adversarial loss: 0.502646\n",
      "epoch 15; iter: 0; batch classifier loss: 0.214096; batch adversarial loss: 0.439761\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191791; batch adversarial loss: 0.480880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.167057; batch adversarial loss: 0.462473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181773; batch adversarial loss: 0.431834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.122266; batch adversarial loss: 0.441389\n",
      "epoch 20; iter: 0; batch classifier loss: 0.130649; batch adversarial loss: 0.390088\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187553; batch adversarial loss: 0.462929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197498; batch adversarial loss: 0.419997\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203237; batch adversarial loss: 0.445794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130207; batch adversarial loss: 0.433270\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146054; batch adversarial loss: 0.409235\n",
      "epoch 26; iter: 0; batch classifier loss: 0.110301; batch adversarial loss: 0.430955\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134402; batch adversarial loss: 0.459812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146146; batch adversarial loss: 0.481008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200927; batch adversarial loss: 0.461274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.128259; batch adversarial loss: 0.389243\n",
      "epoch 31; iter: 0; batch classifier loss: 0.107560; batch adversarial loss: 0.524022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126491; batch adversarial loss: 0.415159\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112384; batch adversarial loss: 0.480254\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118610; batch adversarial loss: 0.486148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.097961; batch adversarial loss: 0.449603\n",
      "epoch 36; iter: 0; batch classifier loss: 0.091991; batch adversarial loss: 0.443094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.071816; batch adversarial loss: 0.442353\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110306; batch adversarial loss: 0.426999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101659; batch adversarial loss: 0.498043\n",
      "epoch 40; iter: 0; batch classifier loss: 0.093366; batch adversarial loss: 0.394151\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125313; batch adversarial loss: 0.434256\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122490; batch adversarial loss: 0.531361\n",
      "epoch 43; iter: 0; batch classifier loss: 0.092353; batch adversarial loss: 0.462260\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125453; batch adversarial loss: 0.544677\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091932; batch adversarial loss: 0.410313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118012; batch adversarial loss: 0.468128\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111524; batch adversarial loss: 0.411545\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126542; batch adversarial loss: 0.383230\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126528; batch adversarial loss: 0.442774\n",
      "epoch 50; iter: 0; batch classifier loss: 0.159861; batch adversarial loss: 0.500742\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120677; batch adversarial loss: 0.412127\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063821; batch adversarial loss: 0.479229\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113598; batch adversarial loss: 0.381845\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110393; batch adversarial loss: 0.459516\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095421; batch adversarial loss: 0.409692\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103152; batch adversarial loss: 0.435260\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094108; batch adversarial loss: 0.389920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080706; batch adversarial loss: 0.475432\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076775; batch adversarial loss: 0.437717\n",
      "epoch 60; iter: 0; batch classifier loss: 0.132557; batch adversarial loss: 0.459437\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065104; batch adversarial loss: 0.394099\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088188; batch adversarial loss: 0.401650\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073673; batch adversarial loss: 0.524839\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057982; batch adversarial loss: 0.390360\n",
      "epoch 65; iter: 0; batch classifier loss: 0.095871; batch adversarial loss: 0.455806\n",
      "epoch 66; iter: 0; batch classifier loss: 0.049333; batch adversarial loss: 0.424008\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063277; batch adversarial loss: 0.370477\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051099; batch adversarial loss: 0.330930\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056050; batch adversarial loss: 0.392312\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068237; batch adversarial loss: 0.400297\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074341; batch adversarial loss: 0.419859\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095512; batch adversarial loss: 0.419397\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106029; batch adversarial loss: 0.470759\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101778; batch adversarial loss: 0.498357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.036719; batch adversarial loss: 0.352613\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082055; batch adversarial loss: 0.377386\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109419; batch adversarial loss: 0.339058\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074528; batch adversarial loss: 0.465320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053538; batch adversarial loss: 0.410722\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090115; batch adversarial loss: 0.381830\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099153; batch adversarial loss: 0.490256\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054639; batch adversarial loss: 0.408721\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063549; batch adversarial loss: 0.424525\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080962; batch adversarial loss: 0.484482\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055557; batch adversarial loss: 0.372908\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075277; batch adversarial loss: 0.424218\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072420; batch adversarial loss: 0.440795\n",
      "epoch 88; iter: 0; batch classifier loss: 0.085257; batch adversarial loss: 0.451267\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106875; batch adversarial loss: 0.465478\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080003; batch adversarial loss: 0.426062\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067801; batch adversarial loss: 0.408877\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073640; batch adversarial loss: 0.454935\n",
      "epoch 93; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.462667\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064907; batch adversarial loss: 0.451642\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065596; batch adversarial loss: 0.477363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050071; batch adversarial loss: 0.374486\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096332; batch adversarial loss: 0.470591\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054649; batch adversarial loss: 0.484953\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041477; batch adversarial loss: 0.428010\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064799; batch adversarial loss: 0.448597\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090526; batch adversarial loss: 0.476801\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079974; batch adversarial loss: 0.424911\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078333; batch adversarial loss: 0.420515\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064819; batch adversarial loss: 0.414743\n",
      "epoch 105; iter: 0; batch classifier loss: 0.091544; batch adversarial loss: 0.396571\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074345; batch adversarial loss: 0.422627\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079471; batch adversarial loss: 0.504864\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061632; batch adversarial loss: 0.530132\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088552; batch adversarial loss: 0.462348\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055832; batch adversarial loss: 0.415273\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071160; batch adversarial loss: 0.465476\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067581; batch adversarial loss: 0.400874\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059116; batch adversarial loss: 0.484829\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035583; batch adversarial loss: 0.463838\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050212; batch adversarial loss: 0.460084\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061103; batch adversarial loss: 0.442665\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050847; batch adversarial loss: 0.449174\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040127; batch adversarial loss: 0.330944\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072542; batch adversarial loss: 0.432820\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051501; batch adversarial loss: 0.489372\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056586; batch adversarial loss: 0.331683\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050231; batch adversarial loss: 0.396267\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060330; batch adversarial loss: 0.418529\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017933; batch adversarial loss: 0.330467\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075694; batch adversarial loss: 0.398773\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059742; batch adversarial loss: 0.453406\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031459; batch adversarial loss: 0.282901\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058997; batch adversarial loss: 0.431036\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054662; batch adversarial loss: 0.463822\n",
      "epoch 130; iter: 0; batch classifier loss: 0.083239; batch adversarial loss: 0.408953\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053316; batch adversarial loss: 0.518261\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022056; batch adversarial loss: 0.386351\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029081; batch adversarial loss: 0.450281\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062903; batch adversarial loss: 0.371060\n",
      "epoch 135; iter: 0; batch classifier loss: 0.074078; batch adversarial loss: 0.417614\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028059; batch adversarial loss: 0.405780\n",
      "epoch 137; iter: 0; batch classifier loss: 0.092538; batch adversarial loss: 0.459561\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038156; batch adversarial loss: 0.391228\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067263; batch adversarial loss: 0.439090\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056892; batch adversarial loss: 0.477069\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051636; batch adversarial loss: 0.482232\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032561; batch adversarial loss: 0.449774\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032203; batch adversarial loss: 0.345305\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046841; batch adversarial loss: 0.421727\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045743; batch adversarial loss: 0.451409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.085731; batch adversarial loss: 0.448747\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057362; batch adversarial loss: 0.425956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033784; batch adversarial loss: 0.367899\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048175; batch adversarial loss: 0.422724\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042250; batch adversarial loss: 0.510023\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044317; batch adversarial loss: 0.442933\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058707; batch adversarial loss: 0.445441\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044665; batch adversarial loss: 0.438583\n",
      "epoch 154; iter: 0; batch classifier loss: 0.049404; batch adversarial loss: 0.457093\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036284; batch adversarial loss: 0.426851\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037967; batch adversarial loss: 0.474932\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040861; batch adversarial loss: 0.543870\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043968; batch adversarial loss: 0.410216\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029828; batch adversarial loss: 0.448677\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025911; batch adversarial loss: 0.443783\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036495; batch adversarial loss: 0.412984\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040272; batch adversarial loss: 0.420797\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032668; batch adversarial loss: 0.398614\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050313; batch adversarial loss: 0.512272\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048063; batch adversarial loss: 0.416731\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040211; batch adversarial loss: 0.413971\n",
      "epoch 167; iter: 0; batch classifier loss: 0.053427; batch adversarial loss: 0.415123\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045357; batch adversarial loss: 0.435150\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025894; batch adversarial loss: 0.422366\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028376; batch adversarial loss: 0.445464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.027317; batch adversarial loss: 0.456844\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034435; batch adversarial loss: 0.453120\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025402; batch adversarial loss: 0.469119\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059488; batch adversarial loss: 0.550227\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019020; batch adversarial loss: 0.403957\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028941; batch adversarial loss: 0.432563\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037077; batch adversarial loss: 0.441746\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043888; batch adversarial loss: 0.469441\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037760; batch adversarial loss: 0.439651\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036957; batch adversarial loss: 0.470651\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027157; batch adversarial loss: 0.533218\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022330; batch adversarial loss: 0.411729\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015351; batch adversarial loss: 0.426154\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.339417\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023810; batch adversarial loss: 0.385811\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026812; batch adversarial loss: 0.480601\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033163; batch adversarial loss: 0.510415\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.412878\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024946; batch adversarial loss: 0.436223\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036349; batch adversarial loss: 0.415266\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023716; batch adversarial loss: 0.449280\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007458; batch adversarial loss: 0.495564\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020195; batch adversarial loss: 0.481505\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024570; batch adversarial loss: 0.443229\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020000; batch adversarial loss: 0.500392\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006676; batch adversarial loss: 0.432599\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014792; batch adversarial loss: 0.369110\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013028; batch adversarial loss: 0.426390\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048276; batch adversarial loss: 0.395393\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699327; batch adversarial loss: 0.592778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.406590; batch adversarial loss: 0.601580\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426633; batch adversarial loss: 0.599262\n",
      "epoch 3; iter: 0; batch classifier loss: 0.496835; batch adversarial loss: 0.660700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555189; batch adversarial loss: 0.583806\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582709; batch adversarial loss: 0.622596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.662729; batch adversarial loss: 0.584833\n",
      "epoch 7; iter: 0; batch classifier loss: 0.691311; batch adversarial loss: 0.550494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.720680; batch adversarial loss: 0.556589\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374766; batch adversarial loss: 0.519170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326314; batch adversarial loss: 0.525845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348616; batch adversarial loss: 0.513385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344004; batch adversarial loss: 0.492076\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284463; batch adversarial loss: 0.462422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367595; batch adversarial loss: 0.434288\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329419; batch adversarial loss: 0.518500\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335701; batch adversarial loss: 0.468557\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268143; batch adversarial loss: 0.503340\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237850; batch adversarial loss: 0.463025\n",
      "epoch 19; iter: 0; batch classifier loss: 0.346860; batch adversarial loss: 0.462800\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305790; batch adversarial loss: 0.419539\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255310; batch adversarial loss: 0.445756\n",
      "epoch 22; iter: 0; batch classifier loss: 0.306919; batch adversarial loss: 0.375265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351499; batch adversarial loss: 0.432882\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300893; batch adversarial loss: 0.462797\n",
      "epoch 25; iter: 0; batch classifier loss: 0.283374; batch adversarial loss: 0.463243\n",
      "epoch 26; iter: 0; batch classifier loss: 0.321150; batch adversarial loss: 0.432279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.282397; batch adversarial loss: 0.430878\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235489; batch adversarial loss: 0.501962\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270096; batch adversarial loss: 0.411283\n",
      "epoch 30; iter: 0; batch classifier loss: 0.246898; batch adversarial loss: 0.455694\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260877; batch adversarial loss: 0.560097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.214327; batch adversarial loss: 0.439792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219242; batch adversarial loss: 0.447593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222074; batch adversarial loss: 0.405587\n",
      "epoch 35; iter: 0; batch classifier loss: 0.193898; batch adversarial loss: 0.485310\n",
      "epoch 36; iter: 0; batch classifier loss: 0.269699; batch adversarial loss: 0.408540\n",
      "epoch 37; iter: 0; batch classifier loss: 0.223573; batch adversarial loss: 0.496232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200069; batch adversarial loss: 0.470260\n",
      "epoch 39; iter: 0; batch classifier loss: 0.247803; batch adversarial loss: 0.478200\n",
      "epoch 40; iter: 0; batch classifier loss: 0.226488; batch adversarial loss: 0.457912\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226401; batch adversarial loss: 0.450328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179016; batch adversarial loss: 0.468253\n",
      "epoch 43; iter: 0; batch classifier loss: 0.228954; batch adversarial loss: 0.476628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237149; batch adversarial loss: 0.483190\n",
      "epoch 45; iter: 0; batch classifier loss: 0.220844; batch adversarial loss: 0.393957\n",
      "epoch 46; iter: 0; batch classifier loss: 0.237769; batch adversarial loss: 0.419448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.213426; batch adversarial loss: 0.457977\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232749; batch adversarial loss: 0.424086\n",
      "epoch 49; iter: 0; batch classifier loss: 0.211355; batch adversarial loss: 0.455344\n",
      "epoch 50; iter: 0; batch classifier loss: 0.180260; batch adversarial loss: 0.451070\n",
      "epoch 51; iter: 0; batch classifier loss: 0.222216; batch adversarial loss: 0.400610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.249062; batch adversarial loss: 0.524425\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222855; batch adversarial loss: 0.509875\n",
      "epoch 54; iter: 0; batch classifier loss: 0.261721; batch adversarial loss: 0.458988\n",
      "epoch 55; iter: 0; batch classifier loss: 0.248546; batch adversarial loss: 0.497027\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184749; batch adversarial loss: 0.571593\n",
      "epoch 57; iter: 0; batch classifier loss: 0.253795; batch adversarial loss: 0.384276\n",
      "epoch 58; iter: 0; batch classifier loss: 0.306417; batch adversarial loss: 0.484051\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141530; batch adversarial loss: 0.433573\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104376; batch adversarial loss: 0.432982\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113234; batch adversarial loss: 0.471527\n",
      "epoch 62; iter: 0; batch classifier loss: 0.095638; batch adversarial loss: 0.415641\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074861; batch adversarial loss: 0.390702\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077695; batch adversarial loss: 0.470090\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075828; batch adversarial loss: 0.459253\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057636; batch adversarial loss: 0.451431\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100961; batch adversarial loss: 0.288302\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059500; batch adversarial loss: 0.428117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.045110; batch adversarial loss: 0.402386\n",
      "epoch 70; iter: 0; batch classifier loss: 0.056881; batch adversarial loss: 0.397085\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092361; batch adversarial loss: 0.515553\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066337; batch adversarial loss: 0.540022\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052215; batch adversarial loss: 0.463844\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070595; batch adversarial loss: 0.420206\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069154; batch adversarial loss: 0.421819\n",
      "epoch 76; iter: 0; batch classifier loss: 0.141908; batch adversarial loss: 0.497478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069151; batch adversarial loss: 0.523479\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061405; batch adversarial loss: 0.398494\n",
      "epoch 79; iter: 0; batch classifier loss: 0.018210; batch adversarial loss: 0.420248\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068101; batch adversarial loss: 0.533557\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064527; batch adversarial loss: 0.359993\n",
      "epoch 82; iter: 0; batch classifier loss: 0.030363; batch adversarial loss: 0.439901\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092807; batch adversarial loss: 0.512011\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060624; batch adversarial loss: 0.421433\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075187; batch adversarial loss: 0.373816\n",
      "epoch 86; iter: 0; batch classifier loss: 0.080895; batch adversarial loss: 0.333180\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057475; batch adversarial loss: 0.389334\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058202; batch adversarial loss: 0.395542\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063812; batch adversarial loss: 0.387086\n",
      "epoch 90; iter: 0; batch classifier loss: 0.026041; batch adversarial loss: 0.454281\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032147; batch adversarial loss: 0.407575\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042356; batch adversarial loss: 0.429644\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061775; batch adversarial loss: 0.492336\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042542; batch adversarial loss: 0.397230\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045784; batch adversarial loss: 0.422365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.021311; batch adversarial loss: 0.594476\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050909; batch adversarial loss: 0.354598\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041220; batch adversarial loss: 0.427274\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053761; batch adversarial loss: 0.383544\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067645; batch adversarial loss: 0.445803\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064033; batch adversarial loss: 0.348282\n",
      "epoch 102; iter: 0; batch classifier loss: 0.017054; batch adversarial loss: 0.545871\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037040; batch adversarial loss: 0.387842\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027281; batch adversarial loss: 0.400466\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038518; batch adversarial loss: 0.438160\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068927; batch adversarial loss: 0.454310\n",
      "epoch 107; iter: 0; batch classifier loss: 0.017809; batch adversarial loss: 0.475777\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098892; batch adversarial loss: 0.439270\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021627; batch adversarial loss: 0.505614\n",
      "epoch 110; iter: 0; batch classifier loss: 0.031861; batch adversarial loss: 0.367935\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036769; batch adversarial loss: 0.436497\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.485102\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050319; batch adversarial loss: 0.456127\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033747; batch adversarial loss: 0.321525\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.475839\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039536; batch adversarial loss: 0.461585\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030335; batch adversarial loss: 0.406475\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059573; batch adversarial loss: 0.410442\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037145; batch adversarial loss: 0.443467\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056744; batch adversarial loss: 0.490255\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065940; batch adversarial loss: 0.515903\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025222; batch adversarial loss: 0.467258\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053997; batch adversarial loss: 0.452961\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045725; batch adversarial loss: 0.410734\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037025; batch adversarial loss: 0.466958\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032562; batch adversarial loss: 0.503616\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026024; batch adversarial loss: 0.378095\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036596; batch adversarial loss: 0.445410\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072437; batch adversarial loss: 0.523732\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023065; batch adversarial loss: 0.457357\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014895; batch adversarial loss: 0.402985\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.442797\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016837; batch adversarial loss: 0.439467\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029024; batch adversarial loss: 0.375596\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029881; batch adversarial loss: 0.576409\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029701; batch adversarial loss: 0.563550\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023930; batch adversarial loss: 0.402055\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016841; batch adversarial loss: 0.413086\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010184; batch adversarial loss: 0.455402\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033736; batch adversarial loss: 0.359954\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058604; batch adversarial loss: 0.389025\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012523; batch adversarial loss: 0.409584\n",
      "epoch 143; iter: 0; batch classifier loss: 0.012170; batch adversarial loss: 0.388795\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042001; batch adversarial loss: 0.457373\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027233; batch adversarial loss: 0.448180\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.444181\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011784; batch adversarial loss: 0.557400\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015463; batch adversarial loss: 0.352581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019984; batch adversarial loss: 0.395071\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046274; batch adversarial loss: 0.473308\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.324062\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026459; batch adversarial loss: 0.506393\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049987; batch adversarial loss: 0.425634\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011081; batch adversarial loss: 0.545109\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011144; batch adversarial loss: 0.443596\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.456958\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041054; batch adversarial loss: 0.466831\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021748; batch adversarial loss: 0.419791\n",
      "epoch 159; iter: 0; batch classifier loss: 0.005450; batch adversarial loss: 0.384343\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017480; batch adversarial loss: 0.375852\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027712; batch adversarial loss: 0.414043\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020060; batch adversarial loss: 0.404077\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032388; batch adversarial loss: 0.496572\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009446; batch adversarial loss: 0.541084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.019782; batch adversarial loss: 0.324051\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046606; batch adversarial loss: 0.430579\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025959; batch adversarial loss: 0.456646\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039666; batch adversarial loss: 0.356260\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015220; batch adversarial loss: 0.327541\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012106; batch adversarial loss: 0.439651\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028760; batch adversarial loss: 0.377464\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028516; batch adversarial loss: 0.453468\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022727; batch adversarial loss: 0.446458\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017072; batch adversarial loss: 0.447582\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014626; batch adversarial loss: 0.437604\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010884; batch adversarial loss: 0.430271\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016584; batch adversarial loss: 0.361242\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015006; batch adversarial loss: 0.430677\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029179; batch adversarial loss: 0.408632\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039051; batch adversarial loss: 0.408735\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033815; batch adversarial loss: 0.393023\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009738; batch adversarial loss: 0.464180\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040276; batch adversarial loss: 0.398320\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015089; batch adversarial loss: 0.368951\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025663; batch adversarial loss: 0.552204\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023527; batch adversarial loss: 0.452085\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.494303\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009914; batch adversarial loss: 0.398311\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029780; batch adversarial loss: 0.470610\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019987; batch adversarial loss: 0.531883\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035796; batch adversarial loss: 0.472249\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013290; batch adversarial loss: 0.423172\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016809; batch adversarial loss: 0.445024\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033490; batch adversarial loss: 0.446186\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023319; batch adversarial loss: 0.429919\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045808; batch adversarial loss: 0.404208\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015255; batch adversarial loss: 0.407981\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025066; batch adversarial loss: 0.552531\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011795; batch adversarial loss: 0.397002\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691685; batch adversarial loss: 0.604002\n",
      "epoch 1; iter: 0; batch classifier loss: 0.377428; batch adversarial loss: 0.632926\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415260; batch adversarial loss: 0.572991\n",
      "epoch 3; iter: 0; batch classifier loss: 0.408606; batch adversarial loss: 0.498220\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333113; batch adversarial loss: 0.540228\n",
      "epoch 5; iter: 0; batch classifier loss: 0.319559; batch adversarial loss: 0.629902\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331586; batch adversarial loss: 0.612921\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273803; batch adversarial loss: 0.614756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339782; batch adversarial loss: 0.492008\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238731; batch adversarial loss: 0.491765\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261513; batch adversarial loss: 0.485523\n",
      "epoch 11; iter: 0; batch classifier loss: 0.184163; batch adversarial loss: 0.542300\n",
      "epoch 12; iter: 0; batch classifier loss: 0.185426; batch adversarial loss: 0.582958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247942; batch adversarial loss: 0.532590\n",
      "epoch 14; iter: 0; batch classifier loss: 0.291643; batch adversarial loss: 0.534819\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181171; batch adversarial loss: 0.488082\n",
      "epoch 16; iter: 0; batch classifier loss: 0.184554; batch adversarial loss: 0.492621\n",
      "epoch 17; iter: 0; batch classifier loss: 0.189461; batch adversarial loss: 0.443770\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261536; batch adversarial loss: 0.481299\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228946; batch adversarial loss: 0.441219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159422; batch adversarial loss: 0.462615\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209573; batch adversarial loss: 0.469287\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169716; batch adversarial loss: 0.467966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188111; batch adversarial loss: 0.468608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.142817; batch adversarial loss: 0.456614\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157422; batch adversarial loss: 0.427174\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136223; batch adversarial loss: 0.512753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139363; batch adversarial loss: 0.518861\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161331; batch adversarial loss: 0.445057\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120169; batch adversarial loss: 0.480535\n",
      "epoch 30; iter: 0; batch classifier loss: 0.150662; batch adversarial loss: 0.379998\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139601; batch adversarial loss: 0.424145\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141122; batch adversarial loss: 0.444937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129187; batch adversarial loss: 0.424701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.142670; batch adversarial loss: 0.484417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125638; batch adversarial loss: 0.451498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.142573; batch adversarial loss: 0.483047\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124066; batch adversarial loss: 0.445936\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179845; batch adversarial loss: 0.464702\n",
      "epoch 39; iter: 0; batch classifier loss: 0.172385; batch adversarial loss: 0.463197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103431; batch adversarial loss: 0.453366\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176030; batch adversarial loss: 0.394087\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168751; batch adversarial loss: 0.430125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112150; batch adversarial loss: 0.498822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099781; batch adversarial loss: 0.488266\n",
      "epoch 45; iter: 0; batch classifier loss: 0.195961; batch adversarial loss: 0.416970\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150409; batch adversarial loss: 0.459015\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114299; batch adversarial loss: 0.392227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.123981; batch adversarial loss: 0.456768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124603; batch adversarial loss: 0.415435\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152866; batch adversarial loss: 0.437633\n",
      "epoch 51; iter: 0; batch classifier loss: 0.174916; batch adversarial loss: 0.438288\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102455; batch adversarial loss: 0.473655\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152468; batch adversarial loss: 0.411031\n",
      "epoch 54; iter: 0; batch classifier loss: 0.149655; batch adversarial loss: 0.406200\n",
      "epoch 55; iter: 0; batch classifier loss: 0.141229; batch adversarial loss: 0.475368\n",
      "epoch 56; iter: 0; batch classifier loss: 0.174847; batch adversarial loss: 0.467889\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136546; batch adversarial loss: 0.518544\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177730; batch adversarial loss: 0.467061\n",
      "epoch 59; iter: 0; batch classifier loss: 0.146630; batch adversarial loss: 0.379660\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088147; batch adversarial loss: 0.486173\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164331; batch adversarial loss: 0.474165\n",
      "epoch 62; iter: 0; batch classifier loss: 0.140679; batch adversarial loss: 0.493763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.129829; batch adversarial loss: 0.490340\n",
      "epoch 64; iter: 0; batch classifier loss: 0.187718; batch adversarial loss: 0.409363\n",
      "epoch 65; iter: 0; batch classifier loss: 0.187550; batch adversarial loss: 0.394647\n",
      "epoch 66; iter: 0; batch classifier loss: 0.116917; batch adversarial loss: 0.435188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105043; batch adversarial loss: 0.473980\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107460; batch adversarial loss: 0.452994\n",
      "epoch 69; iter: 0; batch classifier loss: 0.136654; batch adversarial loss: 0.410074\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098125; batch adversarial loss: 0.455978\n",
      "epoch 71; iter: 0; batch classifier loss: 0.164612; batch adversarial loss: 0.420163\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119933; batch adversarial loss: 0.470273\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103650; batch adversarial loss: 0.470076\n",
      "epoch 74; iter: 0; batch classifier loss: 0.133122; batch adversarial loss: 0.471976\n",
      "epoch 75; iter: 0; batch classifier loss: 0.154460; batch adversarial loss: 0.460869\n",
      "epoch 76; iter: 0; batch classifier loss: 0.146629; batch adversarial loss: 0.484732\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104172; batch adversarial loss: 0.483583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.163493; batch adversarial loss: 0.576605\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151526; batch adversarial loss: 0.457949\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143062; batch adversarial loss: 0.433272\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113358; batch adversarial loss: 0.448590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073541; batch adversarial loss: 0.504788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.148302; batch adversarial loss: 0.464884\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153130; batch adversarial loss: 0.359344\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095273; batch adversarial loss: 0.478235\n",
      "epoch 86; iter: 0; batch classifier loss: 0.130998; batch adversarial loss: 0.480472\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100026; batch adversarial loss: 0.445015\n",
      "epoch 88; iter: 0; batch classifier loss: 0.142132; batch adversarial loss: 0.514586\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075756; batch adversarial loss: 0.539663\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075029; batch adversarial loss: 0.574117\n",
      "epoch 91; iter: 0; batch classifier loss: 0.111450; batch adversarial loss: 0.446236\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066897; batch adversarial loss: 0.490573\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102560; batch adversarial loss: 0.567140\n",
      "epoch 94; iter: 0; batch classifier loss: 0.117755; batch adversarial loss: 0.447960\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074046; batch adversarial loss: 0.441764\n",
      "epoch 96; iter: 0; batch classifier loss: 0.083835; batch adversarial loss: 0.363622\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077533; batch adversarial loss: 0.473522\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059583; batch adversarial loss: 0.578222\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041883; batch adversarial loss: 0.502628\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039068; batch adversarial loss: 0.481595\n",
      "epoch 101; iter: 0; batch classifier loss: 0.091067; batch adversarial loss: 0.589777\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053408; batch adversarial loss: 0.485819\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064521; batch adversarial loss: 0.435242\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080326; batch adversarial loss: 0.564821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076756; batch adversarial loss: 0.494145\n",
      "epoch 106; iter: 0; batch classifier loss: 0.100135; batch adversarial loss: 0.420759\n",
      "epoch 107; iter: 0; batch classifier loss: 0.086427; batch adversarial loss: 0.494324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067119; batch adversarial loss: 0.374491\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046929; batch adversarial loss: 0.458066\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054635; batch adversarial loss: 0.465969\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035131; batch adversarial loss: 0.353989\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021579; batch adversarial loss: 0.398691\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013281; batch adversarial loss: 0.449968\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061913; batch adversarial loss: 0.415326\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035756; batch adversarial loss: 0.491181\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044464; batch adversarial loss: 0.478606\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044798; batch adversarial loss: 0.520489\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034473; batch adversarial loss: 0.509991\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.421986\n",
      "epoch 120; iter: 0; batch classifier loss: 0.097329; batch adversarial loss: 0.486019\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031542; batch adversarial loss: 0.467376\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043974; batch adversarial loss: 0.409936\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039298; batch adversarial loss: 0.482261\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012831; batch adversarial loss: 0.408846\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056185; batch adversarial loss: 0.462222\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030439; batch adversarial loss: 0.538181\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019425; batch adversarial loss: 0.402506\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058717; batch adversarial loss: 0.507994\n",
      "epoch 129; iter: 0; batch classifier loss: 0.075091; batch adversarial loss: 0.462096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024646; batch adversarial loss: 0.461237\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031902; batch adversarial loss: 0.356350\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.492865\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016352; batch adversarial loss: 0.519133\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020954; batch adversarial loss: 0.455419\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033000; batch adversarial loss: 0.441933\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024961; batch adversarial loss: 0.502775\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018651; batch adversarial loss: 0.448326\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029793; batch adversarial loss: 0.362146\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015464; batch adversarial loss: 0.493082\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059212; batch adversarial loss: 0.455259\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043725; batch adversarial loss: 0.476766\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024048; batch adversarial loss: 0.472619\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033781; batch adversarial loss: 0.501221\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034417; batch adversarial loss: 0.364270\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053635; batch adversarial loss: 0.474611\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016367; batch adversarial loss: 0.386140\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020961; batch adversarial loss: 0.425292\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019777; batch adversarial loss: 0.419058\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.491006\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027178; batch adversarial loss: 0.418811\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022277; batch adversarial loss: 0.407336\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.421092\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.497656\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031230; batch adversarial loss: 0.545605\n",
      "epoch 155; iter: 0; batch classifier loss: 0.053936; batch adversarial loss: 0.362906\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015662; batch adversarial loss: 0.449544\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014346; batch adversarial loss: 0.442462\n",
      "epoch 158; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.421330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.026559; batch adversarial loss: 0.388998\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.481506\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019204; batch adversarial loss: 0.541366\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034431; batch adversarial loss: 0.419688\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025977; batch adversarial loss: 0.509433\n",
      "epoch 164; iter: 0; batch classifier loss: 0.052933; batch adversarial loss: 0.448580\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012724; batch adversarial loss: 0.456212\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014920; batch adversarial loss: 0.456176\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030031; batch adversarial loss: 0.406297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055889; batch adversarial loss: 0.384843\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010312; batch adversarial loss: 0.417582\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018460; batch adversarial loss: 0.523908\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018611; batch adversarial loss: 0.503705\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015261; batch adversarial loss: 0.434946\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013888; batch adversarial loss: 0.335388\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022006; batch adversarial loss: 0.446695\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018735; batch adversarial loss: 0.503832\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015160; batch adversarial loss: 0.447944\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010960; batch adversarial loss: 0.560310\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054666; batch adversarial loss: 0.457021\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015145; batch adversarial loss: 0.378750\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028032; batch adversarial loss: 0.395793\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021135; batch adversarial loss: 0.451047\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017526; batch adversarial loss: 0.546286\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027517; batch adversarial loss: 0.437093\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035557; batch adversarial loss: 0.420095\n",
      "epoch 185; iter: 0; batch classifier loss: 0.040707; batch adversarial loss: 0.531429\n",
      "epoch 186; iter: 0; batch classifier loss: 0.026026; batch adversarial loss: 0.454018\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033705; batch adversarial loss: 0.433998\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027268; batch adversarial loss: 0.433688\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021722; batch adversarial loss: 0.488731\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008521; batch adversarial loss: 0.419076\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027621; batch adversarial loss: 0.450793\n",
      "epoch 192; iter: 0; batch classifier loss: 0.083172; batch adversarial loss: 0.398766\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022340; batch adversarial loss: 0.502082\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033204; batch adversarial loss: 0.426716\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022862; batch adversarial loss: 0.480880\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017621; batch adversarial loss: 0.495754\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013671; batch adversarial loss: 0.458055\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039343; batch adversarial loss: 0.506327\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008531; batch adversarial loss: 0.362501\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697088; batch adversarial loss: 0.595651\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471218; batch adversarial loss: 0.595881\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459048; batch adversarial loss: 0.572447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.412944; batch adversarial loss: 0.579955\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335556; batch adversarial loss: 0.537065\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309395; batch adversarial loss: 0.583271\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305436; batch adversarial loss: 0.577106\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301359; batch adversarial loss: 0.521851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270524; batch adversarial loss: 0.448466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.236659; batch adversarial loss: 0.526368\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321377; batch adversarial loss: 0.498576\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359135; batch adversarial loss: 0.586484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242520; batch adversarial loss: 0.444860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.228074; batch adversarial loss: 0.543538\n",
      "epoch 14; iter: 0; batch classifier loss: 0.252592; batch adversarial loss: 0.613580\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247474; batch adversarial loss: 0.578149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197171; batch adversarial loss: 0.577605\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270952; batch adversarial loss: 0.533473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310366; batch adversarial loss: 0.503824\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266621; batch adversarial loss: 0.401945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.298079; batch adversarial loss: 0.440124\n",
      "epoch 21; iter: 0; batch classifier loss: 0.395115; batch adversarial loss: 0.537927\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354131; batch adversarial loss: 0.430200\n",
      "epoch 23; iter: 0; batch classifier loss: 0.449460; batch adversarial loss: 0.450291\n",
      "epoch 24; iter: 0; batch classifier loss: 0.237845; batch adversarial loss: 0.437016\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148649; batch adversarial loss: 0.505110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167683; batch adversarial loss: 0.392038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192424; batch adversarial loss: 0.382122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.138158; batch adversarial loss: 0.463791\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140270; batch adversarial loss: 0.554242\n",
      "epoch 30; iter: 0; batch classifier loss: 0.119571; batch adversarial loss: 0.412539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124386; batch adversarial loss: 0.406569\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162995; batch adversarial loss: 0.432266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.165518; batch adversarial loss: 0.426273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146255; batch adversarial loss: 0.373519\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119931; batch adversarial loss: 0.454570\n",
      "epoch 36; iter: 0; batch classifier loss: 0.077307; batch adversarial loss: 0.476231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105857; batch adversarial loss: 0.457073\n",
      "epoch 38; iter: 0; batch classifier loss: 0.088289; batch adversarial loss: 0.424175\n",
      "epoch 39; iter: 0; batch classifier loss: 0.072676; batch adversarial loss: 0.401591\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115418; batch adversarial loss: 0.519847\n",
      "epoch 41; iter: 0; batch classifier loss: 0.157348; batch adversarial loss: 0.317260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113436; batch adversarial loss: 0.455300\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088798; batch adversarial loss: 0.413244\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128314; batch adversarial loss: 0.450612\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094978; batch adversarial loss: 0.486580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103530; batch adversarial loss: 0.418289\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107347; batch adversarial loss: 0.437297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100844; batch adversarial loss: 0.462563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076407; batch adversarial loss: 0.441438\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079586; batch adversarial loss: 0.344804\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108312; batch adversarial loss: 0.462963\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095496; batch adversarial loss: 0.456401\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090718; batch adversarial loss: 0.404411\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079857; batch adversarial loss: 0.379844\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124062; batch adversarial loss: 0.394234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.108162; batch adversarial loss: 0.377011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.157985; batch adversarial loss: 0.365588\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106394; batch adversarial loss: 0.505561\n",
      "epoch 59; iter: 0; batch classifier loss: 0.135076; batch adversarial loss: 0.438299\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085793; batch adversarial loss: 0.443131\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145733; batch adversarial loss: 0.352558\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080498; batch adversarial loss: 0.449248\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080509; batch adversarial loss: 0.418659\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073858; batch adversarial loss: 0.488347\n",
      "epoch 65; iter: 0; batch classifier loss: 0.128290; batch adversarial loss: 0.491219\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119995; batch adversarial loss: 0.405227\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071696; batch adversarial loss: 0.480208\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066131; batch adversarial loss: 0.461237\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086918; batch adversarial loss: 0.475544\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123461; batch adversarial loss: 0.521022\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078048; batch adversarial loss: 0.488287\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077114; batch adversarial loss: 0.525611\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089766; batch adversarial loss: 0.434560\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095344; batch adversarial loss: 0.401406\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086804; batch adversarial loss: 0.465574\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061147; batch adversarial loss: 0.513611\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078990; batch adversarial loss: 0.403365\n",
      "epoch 78; iter: 0; batch classifier loss: 0.098671; batch adversarial loss: 0.494830\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076608; batch adversarial loss: 0.488249\n",
      "epoch 80; iter: 0; batch classifier loss: 0.115821; batch adversarial loss: 0.500338\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075549; batch adversarial loss: 0.412244\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086873; batch adversarial loss: 0.454245\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049816; batch adversarial loss: 0.516696\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089571; batch adversarial loss: 0.469590\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090491; batch adversarial loss: 0.377106\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034592; batch adversarial loss: 0.464200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049012; batch adversarial loss: 0.434130\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071877; batch adversarial loss: 0.462678\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056826; batch adversarial loss: 0.385491\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060257; batch adversarial loss: 0.446721\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060544; batch adversarial loss: 0.485119\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052555; batch adversarial loss: 0.469126\n",
      "epoch 93; iter: 0; batch classifier loss: 0.122102; batch adversarial loss: 0.395374\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052040; batch adversarial loss: 0.374896\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.480570\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069953; batch adversarial loss: 0.383418\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070603; batch adversarial loss: 0.417917\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033553; batch adversarial loss: 0.480844\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040767; batch adversarial loss: 0.482591\n",
      "epoch 100; iter: 0; batch classifier loss: 0.115168; batch adversarial loss: 0.477300\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066577; batch adversarial loss: 0.388747\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038294; batch adversarial loss: 0.463541\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065502; batch adversarial loss: 0.326186\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031071; batch adversarial loss: 0.469859\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043748; batch adversarial loss: 0.501883\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057165; batch adversarial loss: 0.581306\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062524; batch adversarial loss: 0.374957\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026098; batch adversarial loss: 0.500287\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053881; batch adversarial loss: 0.349148\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039961; batch adversarial loss: 0.478927\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047859; batch adversarial loss: 0.428080\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075949; batch adversarial loss: 0.350765\n",
      "epoch 113; iter: 0; batch classifier loss: 0.099773; batch adversarial loss: 0.414625\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039916; batch adversarial loss: 0.460117\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031250; batch adversarial loss: 0.517904\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059272; batch adversarial loss: 0.417624\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043457; batch adversarial loss: 0.492476\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054049; batch adversarial loss: 0.397581\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034846; batch adversarial loss: 0.483755\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037159; batch adversarial loss: 0.396704\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060470; batch adversarial loss: 0.395059\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035560; batch adversarial loss: 0.448383\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046765; batch adversarial loss: 0.351183\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041135; batch adversarial loss: 0.546590\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032430; batch adversarial loss: 0.461836\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039995; batch adversarial loss: 0.398536\n",
      "epoch 127; iter: 0; batch classifier loss: 0.072103; batch adversarial loss: 0.500898\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042714; batch adversarial loss: 0.458445\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.412018\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029230; batch adversarial loss: 0.502781\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078663; batch adversarial loss: 0.438991\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023401; batch adversarial loss: 0.516279\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019743; batch adversarial loss: 0.409268\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.554118\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050489; batch adversarial loss: 0.408384\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054754; batch adversarial loss: 0.414614\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055256; batch adversarial loss: 0.342032\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021162; batch adversarial loss: 0.551496\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039190; batch adversarial loss: 0.443348\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020993; batch adversarial loss: 0.382956\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037724; batch adversarial loss: 0.514296\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020833; batch adversarial loss: 0.374788\n",
      "epoch 143; iter: 0; batch classifier loss: 0.063239; batch adversarial loss: 0.399254\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.499464\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021810; batch adversarial loss: 0.445630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037688; batch adversarial loss: 0.358442\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054058; batch adversarial loss: 0.503970\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035942; batch adversarial loss: 0.400967\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024218; batch adversarial loss: 0.317148\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014615; batch adversarial loss: 0.445972\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019159; batch adversarial loss: 0.421257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.027940; batch adversarial loss: 0.391586\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022182; batch adversarial loss: 0.503922\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027717; batch adversarial loss: 0.346091\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039997; batch adversarial loss: 0.432836\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.439500\n",
      "epoch 157; iter: 0; batch classifier loss: 0.008360; batch adversarial loss: 0.411105\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015429; batch adversarial loss: 0.446814\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010921; batch adversarial loss: 0.445028\n",
      "epoch 160; iter: 0; batch classifier loss: 0.065725; batch adversarial loss: 0.496211\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014375; batch adversarial loss: 0.374971\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025538; batch adversarial loss: 0.464850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019281; batch adversarial loss: 0.461081\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041084; batch adversarial loss: 0.365360\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040913; batch adversarial loss: 0.517959\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012219; batch adversarial loss: 0.520616\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016120; batch adversarial loss: 0.449180\n",
      "epoch 168; iter: 0; batch classifier loss: 0.046259; batch adversarial loss: 0.477567\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016297; batch adversarial loss: 0.454181\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047802; batch adversarial loss: 0.441885\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024054; batch adversarial loss: 0.317927\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030730; batch adversarial loss: 0.456604\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016686; batch adversarial loss: 0.400770\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037157; batch adversarial loss: 0.424829\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028061; batch adversarial loss: 0.355123\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024313; batch adversarial loss: 0.449655\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033661; batch adversarial loss: 0.509789\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.441066\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026499; batch adversarial loss: 0.562403\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037257; batch adversarial loss: 0.512999\n",
      "epoch 181; iter: 0; batch classifier loss: 0.041271; batch adversarial loss: 0.433055\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024458; batch adversarial loss: 0.540038\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008229; batch adversarial loss: 0.489169\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040882; batch adversarial loss: 0.412942\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034953; batch adversarial loss: 0.533535\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021968; batch adversarial loss: 0.430896\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023055; batch adversarial loss: 0.426647\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040024; batch adversarial loss: 0.415631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018141; batch adversarial loss: 0.456416\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022381; batch adversarial loss: 0.530633\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023469; batch adversarial loss: 0.441420\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009601; batch adversarial loss: 0.373894\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032448; batch adversarial loss: 0.476346\n",
      "epoch 194; iter: 0; batch classifier loss: 0.062865; batch adversarial loss: 0.364734\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036791; batch adversarial loss: 0.490080\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021139; batch adversarial loss: 0.413659\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029076; batch adversarial loss: 0.417943\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012839; batch adversarial loss: 0.459068\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024392; batch adversarial loss: 0.502443\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719454; batch adversarial loss: 0.460263\n",
      "epoch 1; iter: 0; batch classifier loss: 0.393046; batch adversarial loss: 0.562961\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467215; batch adversarial loss: 0.576494\n",
      "epoch 3; iter: 0; batch classifier loss: 0.330837; batch adversarial loss: 0.593394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387506; batch adversarial loss: 0.554661\n",
      "epoch 5; iter: 0; batch classifier loss: 0.395455; batch adversarial loss: 0.575525\n",
      "epoch 6; iter: 0; batch classifier loss: 0.398587; batch adversarial loss: 0.627498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353044; batch adversarial loss: 0.629463\n",
      "epoch 8; iter: 0; batch classifier loss: 0.442716; batch adversarial loss: 0.579941\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413425; batch adversarial loss: 0.569680\n",
      "epoch 10; iter: 0; batch classifier loss: 0.476152; batch adversarial loss: 0.505345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.586241; batch adversarial loss: 0.599340\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555415; batch adversarial loss: 0.545280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417081; batch adversarial loss: 0.554254\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345811; batch adversarial loss: 0.478464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338728; batch adversarial loss: 0.436525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299017; batch adversarial loss: 0.514001\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300500; batch adversarial loss: 0.410099\n",
      "epoch 18; iter: 0; batch classifier loss: 0.160145; batch adversarial loss: 0.509286\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228857; batch adversarial loss: 0.458511\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162846; batch adversarial loss: 0.446089\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214866; batch adversarial loss: 0.436069\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224565; batch adversarial loss: 0.434941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225151; batch adversarial loss: 0.414912\n",
      "epoch 24; iter: 0; batch classifier loss: 0.208014; batch adversarial loss: 0.425040\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189493; batch adversarial loss: 0.485726\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168553; batch adversarial loss: 0.430865\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159645; batch adversarial loss: 0.422434\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141773; batch adversarial loss: 0.421015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146199; batch adversarial loss: 0.486112\n",
      "epoch 30; iter: 0; batch classifier loss: 0.106996; batch adversarial loss: 0.444252\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179511; batch adversarial loss: 0.490566\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102592; batch adversarial loss: 0.425791\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135888; batch adversarial loss: 0.498822\n",
      "epoch 34; iter: 0; batch classifier loss: 0.117048; batch adversarial loss: 0.460782\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110257; batch adversarial loss: 0.480932\n",
      "epoch 36; iter: 0; batch classifier loss: 0.105490; batch adversarial loss: 0.496103\n",
      "epoch 37; iter: 0; batch classifier loss: 0.138238; batch adversarial loss: 0.361351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110172; batch adversarial loss: 0.525163\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095356; batch adversarial loss: 0.455331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153274; batch adversarial loss: 0.491019\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135855; batch adversarial loss: 0.519281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.134954; batch adversarial loss: 0.414072\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125248; batch adversarial loss: 0.482259\n",
      "epoch 44; iter: 0; batch classifier loss: 0.138673; batch adversarial loss: 0.448003\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118099; batch adversarial loss: 0.487620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.137317; batch adversarial loss: 0.482118\n",
      "epoch 47; iter: 0; batch classifier loss: 0.127686; batch adversarial loss: 0.417920\n",
      "epoch 48; iter: 0; batch classifier loss: 0.137192; batch adversarial loss: 0.383036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.137924; batch adversarial loss: 0.399540\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114396; batch adversarial loss: 0.433909\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139586; batch adversarial loss: 0.509664\n",
      "epoch 52; iter: 0; batch classifier loss: 0.150642; batch adversarial loss: 0.532271\n",
      "epoch 53; iter: 0; batch classifier loss: 0.138188; batch adversarial loss: 0.416871\n",
      "epoch 54; iter: 0; batch classifier loss: 0.181415; batch adversarial loss: 0.415215\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099731; batch adversarial loss: 0.426129\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128261; batch adversarial loss: 0.412991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083978; batch adversarial loss: 0.469936\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076764; batch adversarial loss: 0.441082\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167423; batch adversarial loss: 0.415109\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110956; batch adversarial loss: 0.456077\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108899; batch adversarial loss: 0.533510\n",
      "epoch 62; iter: 0; batch classifier loss: 0.182219; batch adversarial loss: 0.436869\n",
      "epoch 63; iter: 0; batch classifier loss: 0.139674; batch adversarial loss: 0.405363\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134882; batch adversarial loss: 0.394850\n",
      "epoch 65; iter: 0; batch classifier loss: 0.121142; batch adversarial loss: 0.442574\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102236; batch adversarial loss: 0.511862\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123001; batch adversarial loss: 0.471788\n",
      "epoch 68; iter: 0; batch classifier loss: 0.121018; batch adversarial loss: 0.481689\n",
      "epoch 69; iter: 0; batch classifier loss: 0.104004; batch adversarial loss: 0.446609\n",
      "epoch 70; iter: 0; batch classifier loss: 0.202702; batch adversarial loss: 0.499972\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083909; batch adversarial loss: 0.441919\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108216; batch adversarial loss: 0.410205\n",
      "epoch 73; iter: 0; batch classifier loss: 0.171468; batch adversarial loss: 0.329369\n",
      "epoch 74; iter: 0; batch classifier loss: 0.128344; batch adversarial loss: 0.468356\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088366; batch adversarial loss: 0.438302\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102986; batch adversarial loss: 0.416993\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104541; batch adversarial loss: 0.477141\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182866; batch adversarial loss: 0.368473\n",
      "epoch 79; iter: 0; batch classifier loss: 0.162773; batch adversarial loss: 0.377688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.138660; batch adversarial loss: 0.396279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.098370; batch adversarial loss: 0.460656\n",
      "epoch 82; iter: 0; batch classifier loss: 0.109112; batch adversarial loss: 0.499539\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090254; batch adversarial loss: 0.343298\n",
      "epoch 84; iter: 0; batch classifier loss: 0.119685; batch adversarial loss: 0.413922\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083785; batch adversarial loss: 0.434921\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103603; batch adversarial loss: 0.375784\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100704; batch adversarial loss: 0.392907\n",
      "epoch 88; iter: 0; batch classifier loss: 0.131625; batch adversarial loss: 0.529196\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073890; batch adversarial loss: 0.461544\n",
      "epoch 90; iter: 0; batch classifier loss: 0.147937; batch adversarial loss: 0.478675\n",
      "epoch 91; iter: 0; batch classifier loss: 0.115525; batch adversarial loss: 0.376513\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106085; batch adversarial loss: 0.450413\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074280; batch adversarial loss: 0.416355\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094132; batch adversarial loss: 0.414973\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091932; batch adversarial loss: 0.451001\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117637; batch adversarial loss: 0.438372\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062203; batch adversarial loss: 0.422529\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097469; batch adversarial loss: 0.429693\n",
      "epoch 99; iter: 0; batch classifier loss: 0.107505; batch adversarial loss: 0.352472\n",
      "epoch 100; iter: 0; batch classifier loss: 0.112954; batch adversarial loss: 0.497144\n",
      "epoch 101; iter: 0; batch classifier loss: 0.103958; batch adversarial loss: 0.329172\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062853; batch adversarial loss: 0.455284\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045781; batch adversarial loss: 0.449872\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075423; batch adversarial loss: 0.480046\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045027; batch adversarial loss: 0.486304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053366; batch adversarial loss: 0.436010\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.388559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061950; batch adversarial loss: 0.495267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071483; batch adversarial loss: 0.415769\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064540; batch adversarial loss: 0.485894\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059280; batch adversarial loss: 0.451002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051568; batch adversarial loss: 0.433238\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042375; batch adversarial loss: 0.469795\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040700; batch adversarial loss: 0.402392\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053974; batch adversarial loss: 0.489808\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062041; batch adversarial loss: 0.390139\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038804; batch adversarial loss: 0.471166\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062770; batch adversarial loss: 0.410411\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057654; batch adversarial loss: 0.459904\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.346449\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050357; batch adversarial loss: 0.426354\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042967; batch adversarial loss: 0.464297\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045849; batch adversarial loss: 0.474611\n",
      "epoch 124; iter: 0; batch classifier loss: 0.015561; batch adversarial loss: 0.481293\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056043; batch adversarial loss: 0.490116\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041552; batch adversarial loss: 0.449607\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024251; batch adversarial loss: 0.493374\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069431; batch adversarial loss: 0.412830\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029304; batch adversarial loss: 0.419852\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029919; batch adversarial loss: 0.423111\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023380; batch adversarial loss: 0.534191\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045758; batch adversarial loss: 0.491368\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021215; batch adversarial loss: 0.427629\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026915; batch adversarial loss: 0.544814\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034016; batch adversarial loss: 0.368687\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050603; batch adversarial loss: 0.479389\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.380617\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064647; batch adversarial loss: 0.462948\n",
      "epoch 139; iter: 0; batch classifier loss: 0.014105; batch adversarial loss: 0.553195\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018334; batch adversarial loss: 0.470319\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036580; batch adversarial loss: 0.491689\n",
      "epoch 142; iter: 0; batch classifier loss: 0.008383; batch adversarial loss: 0.334547\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020169; batch adversarial loss: 0.493594\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026115; batch adversarial loss: 0.502084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.086839; batch adversarial loss: 0.532651\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017178; batch adversarial loss: 0.401636\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.380480\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019898; batch adversarial loss: 0.410292\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021840; batch adversarial loss: 0.369189\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019602; batch adversarial loss: 0.438316\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037197; batch adversarial loss: 0.393126\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018300; batch adversarial loss: 0.418372\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049175; batch adversarial loss: 0.406387\n",
      "epoch 154; iter: 0; batch classifier loss: 0.062437; batch adversarial loss: 0.478816\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041905; batch adversarial loss: 0.401009\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014396; batch adversarial loss: 0.366573\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048791; batch adversarial loss: 0.362314\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031307; batch adversarial loss: 0.455254\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022243; batch adversarial loss: 0.464529\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030322; batch adversarial loss: 0.467665\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017426; batch adversarial loss: 0.477635\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044256; batch adversarial loss: 0.424803\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009010; batch adversarial loss: 0.415645\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010450; batch adversarial loss: 0.515778\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023014; batch adversarial loss: 0.404286\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038964; batch adversarial loss: 0.560344\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021293; batch adversarial loss: 0.462581\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012037; batch adversarial loss: 0.466577\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.570662\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020052; batch adversarial loss: 0.553445\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031170; batch adversarial loss: 0.379410\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007560; batch adversarial loss: 0.448272\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013127; batch adversarial loss: 0.381898\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016728; batch adversarial loss: 0.445723\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029882; batch adversarial loss: 0.503672\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009207; batch adversarial loss: 0.388943\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044322; batch adversarial loss: 0.429977\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021960; batch adversarial loss: 0.337710\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011163; batch adversarial loss: 0.376845\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011633; batch adversarial loss: 0.518458\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060237; batch adversarial loss: 0.448386\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010965; batch adversarial loss: 0.430975\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036642; batch adversarial loss: 0.411108\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006592; batch adversarial loss: 0.430528\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011273; batch adversarial loss: 0.552612\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009986; batch adversarial loss: 0.430500\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038085; batch adversarial loss: 0.404324\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009554; batch adversarial loss: 0.429409\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017532; batch adversarial loss: 0.418124\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008283; batch adversarial loss: 0.485836\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030712; batch adversarial loss: 0.448334\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019870; batch adversarial loss: 0.491547\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011871; batch adversarial loss: 0.491678\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005629; batch adversarial loss: 0.459496\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012680; batch adversarial loss: 0.535372\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016726; batch adversarial loss: 0.461392\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008552; batch adversarial loss: 0.434816\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006105; batch adversarial loss: 0.512645\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004036; batch adversarial loss: 0.477934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.668410; batch adversarial loss: 0.717871\n",
      "epoch 1; iter: 0; batch classifier loss: 0.533275; batch adversarial loss: 0.657768\n",
      "epoch 2; iter: 0; batch classifier loss: 0.426937; batch adversarial loss: 0.605937\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348534; batch adversarial loss: 0.568274\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357517; batch adversarial loss: 0.574002\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382205; batch adversarial loss: 0.527539\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340220; batch adversarial loss: 0.564814\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330380; batch adversarial loss: 0.561990\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282635; batch adversarial loss: 0.548632\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299108; batch adversarial loss: 0.511085\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307361; batch adversarial loss: 0.529435\n",
      "epoch 11; iter: 0; batch classifier loss: 0.314380; batch adversarial loss: 0.518219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318475; batch adversarial loss: 0.473479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.287060; batch adversarial loss: 0.449798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.275541; batch adversarial loss: 0.494229\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323372; batch adversarial loss: 0.451984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344937; batch adversarial loss: 0.526407\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322720; batch adversarial loss: 0.449115\n",
      "epoch 18; iter: 0; batch classifier loss: 0.351173; batch adversarial loss: 0.503275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287943; batch adversarial loss: 0.477535\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307988; batch adversarial loss: 0.493170\n",
      "epoch 21; iter: 0; batch classifier loss: 0.274654; batch adversarial loss: 0.505776\n",
      "epoch 22; iter: 0; batch classifier loss: 0.274771; batch adversarial loss: 0.433123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247774; batch adversarial loss: 0.397196\n",
      "epoch 24; iter: 0; batch classifier loss: 0.242490; batch adversarial loss: 0.500777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272106; batch adversarial loss: 0.473305\n",
      "epoch 26; iter: 0; batch classifier loss: 0.311899; batch adversarial loss: 0.418086\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389191; batch adversarial loss: 0.437358\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223092; batch adversarial loss: 0.496247\n",
      "epoch 29; iter: 0; batch classifier loss: 0.246545; batch adversarial loss: 0.443808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234322; batch adversarial loss: 0.496714\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269695; batch adversarial loss: 0.522789\n",
      "epoch 32; iter: 0; batch classifier loss: 0.319827; batch adversarial loss: 0.417936\n",
      "epoch 33; iter: 0; batch classifier loss: 0.283737; batch adversarial loss: 0.480788\n",
      "epoch 34; iter: 0; batch classifier loss: 0.259477; batch adversarial loss: 0.500324\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319996; batch adversarial loss: 0.444430\n",
      "epoch 36; iter: 0; batch classifier loss: 0.292342; batch adversarial loss: 0.504476\n",
      "epoch 37; iter: 0; batch classifier loss: 0.282005; batch adversarial loss: 0.413772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296244; batch adversarial loss: 0.437862\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288858; batch adversarial loss: 0.449550\n",
      "epoch 40; iter: 0; batch classifier loss: 0.230252; batch adversarial loss: 0.430065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 0; batch classifier loss: 0.296835; batch adversarial loss: 0.424306\n",
      "epoch 42; iter: 0; batch classifier loss: 0.261737; batch adversarial loss: 0.404685\n",
      "epoch 43; iter: 0; batch classifier loss: 0.279941; batch adversarial loss: 0.538909\n",
      "epoch 44; iter: 0; batch classifier loss: 0.260772; batch adversarial loss: 0.426006\n",
      "epoch 45; iter: 0; batch classifier loss: 0.254681; batch adversarial loss: 0.440125\n",
      "epoch 46; iter: 0; batch classifier loss: 0.297364; batch adversarial loss: 0.424227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.304848; batch adversarial loss: 0.515546\n",
      "epoch 48; iter: 0; batch classifier loss: 0.307261; batch adversarial loss: 0.542740\n",
      "epoch 49; iter: 0; batch classifier loss: 0.266715; batch adversarial loss: 0.414523\n",
      "epoch 50; iter: 0; batch classifier loss: 0.299365; batch adversarial loss: 0.506546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120209; batch adversarial loss: 0.493858\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130538; batch adversarial loss: 0.493529\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077915; batch adversarial loss: 0.589432\n",
      "epoch 54; iter: 0; batch classifier loss: 0.059291; batch adversarial loss: 0.393303\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109356; batch adversarial loss: 0.450008\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065151; batch adversarial loss: 0.546010\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069184; batch adversarial loss: 0.469473\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077477; batch adversarial loss: 0.447323\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072966; batch adversarial loss: 0.505052\n",
      "epoch 60; iter: 0; batch classifier loss: 0.073073; batch adversarial loss: 0.404659\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066929; batch adversarial loss: 0.387317\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066270; batch adversarial loss: 0.426831\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079541; batch adversarial loss: 0.491053\n",
      "epoch 64; iter: 0; batch classifier loss: 0.129439; batch adversarial loss: 0.382175\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065812; batch adversarial loss: 0.462097\n",
      "epoch 66; iter: 0; batch classifier loss: 0.065725; batch adversarial loss: 0.358373\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110610; batch adversarial loss: 0.408333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076548; batch adversarial loss: 0.392153\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052493; batch adversarial loss: 0.494506\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059167; batch adversarial loss: 0.378669\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073228; batch adversarial loss: 0.320355\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086434; batch adversarial loss: 0.479784\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065128; batch adversarial loss: 0.446395\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101915; batch adversarial loss: 0.439842\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060414; batch adversarial loss: 0.452343\n",
      "epoch 76; iter: 0; batch classifier loss: 0.034566; batch adversarial loss: 0.431125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052462; batch adversarial loss: 0.415254\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057983; batch adversarial loss: 0.466595\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049769; batch adversarial loss: 0.426362\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067136; batch adversarial loss: 0.468712\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057114; batch adversarial loss: 0.413758\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045057; batch adversarial loss: 0.503570\n",
      "epoch 83; iter: 0; batch classifier loss: 0.045616; batch adversarial loss: 0.425974\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070080; batch adversarial loss: 0.427770\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059709; batch adversarial loss: 0.473972\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054209; batch adversarial loss: 0.441215\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057982; batch adversarial loss: 0.482971\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087337; batch adversarial loss: 0.437630\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065601; batch adversarial loss: 0.409698\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053983; batch adversarial loss: 0.449592\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058161; batch adversarial loss: 0.430852\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032410; batch adversarial loss: 0.420989\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051908; batch adversarial loss: 0.407260\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050666; batch adversarial loss: 0.384924\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080794; batch adversarial loss: 0.343848\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064315; batch adversarial loss: 0.350191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044950; batch adversarial loss: 0.427122\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048945; batch adversarial loss: 0.586837\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058364; batch adversarial loss: 0.461902\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054222; batch adversarial loss: 0.485945\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050801; batch adversarial loss: 0.384531\n",
      "epoch 102; iter: 0; batch classifier loss: 0.081712; batch adversarial loss: 0.443250\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054869; batch adversarial loss: 0.389390\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037033; batch adversarial loss: 0.435766\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063417; batch adversarial loss: 0.363570\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025347; batch adversarial loss: 0.431960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082139; batch adversarial loss: 0.479394\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064560; batch adversarial loss: 0.483817\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067596; batch adversarial loss: 0.545778\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055277; batch adversarial loss: 0.397349\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035317; batch adversarial loss: 0.395379\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042785; batch adversarial loss: 0.450426\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063828; batch adversarial loss: 0.429766\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039161; batch adversarial loss: 0.445816\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039155; batch adversarial loss: 0.444050\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039487; batch adversarial loss: 0.459500\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062630; batch adversarial loss: 0.423946\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073918; batch adversarial loss: 0.371358\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057376; batch adversarial loss: 0.444064\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045148; batch adversarial loss: 0.424689\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059275; batch adversarial loss: 0.439986\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045512; batch adversarial loss: 0.446831\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045833; batch adversarial loss: 0.336283\n",
      "epoch 124; iter: 0; batch classifier loss: 0.078470; batch adversarial loss: 0.475124\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051875; batch adversarial loss: 0.412705\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027621; batch adversarial loss: 0.474075\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019647; batch adversarial loss: 0.524534\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055967; batch adversarial loss: 0.353149\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050147; batch adversarial loss: 0.471419\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031456; batch adversarial loss: 0.410322\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042292; batch adversarial loss: 0.435749\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029145; batch adversarial loss: 0.411233\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028871; batch adversarial loss: 0.379849\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041833; batch adversarial loss: 0.476082\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019032; batch adversarial loss: 0.528494\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040870; batch adversarial loss: 0.394769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 137; iter: 0; batch classifier loss: 0.031434; batch adversarial loss: 0.418317\n",
      "epoch 138; iter: 0; batch classifier loss: 0.073337; batch adversarial loss: 0.360927\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021269; batch adversarial loss: 0.409260\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026220; batch adversarial loss: 0.485857\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030407; batch adversarial loss: 0.485784\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056842; batch adversarial loss: 0.457456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039058; batch adversarial loss: 0.460683\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027124; batch adversarial loss: 0.564667\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018063; batch adversarial loss: 0.450278\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025898; batch adversarial loss: 0.413195\n",
      "epoch 147; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.488582\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.489364\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020822; batch adversarial loss: 0.431598\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021429; batch adversarial loss: 0.461851\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016397; batch adversarial loss: 0.433904\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013771; batch adversarial loss: 0.433576\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028105; batch adversarial loss: 0.350149\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020255; batch adversarial loss: 0.463407\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.475211\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039237; batch adversarial loss: 0.526113\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023015; batch adversarial loss: 0.439068\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019534; batch adversarial loss: 0.586091\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023288; batch adversarial loss: 0.509337\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030326; batch adversarial loss: 0.377823\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024099; batch adversarial loss: 0.464009\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.447290\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023224; batch adversarial loss: 0.372677\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.554504\n",
      "epoch 165; iter: 0; batch classifier loss: 0.045338; batch adversarial loss: 0.475339\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034504; batch adversarial loss: 0.388040\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015621; batch adversarial loss: 0.456171\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016367; batch adversarial loss: 0.454433\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028695; batch adversarial loss: 0.449912\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025808; batch adversarial loss: 0.368756\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031095; batch adversarial loss: 0.380573\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020404; batch adversarial loss: 0.461450\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014810; batch adversarial loss: 0.435715\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027127; batch adversarial loss: 0.415568\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020404; batch adversarial loss: 0.439863\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018659; batch adversarial loss: 0.471100\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027485; batch adversarial loss: 0.470752\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052640; batch adversarial loss: 0.527502\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030190; batch adversarial loss: 0.486165\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012552; batch adversarial loss: 0.388249\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017129; batch adversarial loss: 0.504631\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020345; batch adversarial loss: 0.481417\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027946; batch adversarial loss: 0.462511\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040040; batch adversarial loss: 0.555533\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013971; batch adversarial loss: 0.630712\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023412; batch adversarial loss: 0.487288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032936; batch adversarial loss: 0.507066\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018789; batch adversarial loss: 0.420945\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037803; batch adversarial loss: 0.429862\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018786; batch adversarial loss: 0.416602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026934; batch adversarial loss: 0.413042\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017040; batch adversarial loss: 0.457770\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023751; batch adversarial loss: 0.423756\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019148; batch adversarial loss: 0.519345\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021299; batch adversarial loss: 0.402418\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031258; batch adversarial loss: 0.394797\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015595; batch adversarial loss: 0.464505\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018135; batch adversarial loss: 0.416203\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026844; batch adversarial loss: 0.479312\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674724; batch adversarial loss: 0.586574\n",
      "epoch 1; iter: 0; batch classifier loss: 0.465863; batch adversarial loss: 0.626099\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434103; batch adversarial loss: 0.626440\n",
      "epoch 3; iter: 0; batch classifier loss: 0.491471; batch adversarial loss: 0.532727\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548398; batch adversarial loss: 0.590857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505389; batch adversarial loss: 0.582364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.436064; batch adversarial loss: 0.568988\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546987; batch adversarial loss: 0.595239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699132; batch adversarial loss: 0.609672\n",
      "epoch 9; iter: 0; batch classifier loss: 0.638083; batch adversarial loss: 0.539595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.396577; batch adversarial loss: 0.539687\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342262; batch adversarial loss: 0.566957\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334790; batch adversarial loss: 0.544218\n",
      "epoch 13; iter: 0; batch classifier loss: 0.359289; batch adversarial loss: 0.478768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331283; batch adversarial loss: 0.507569\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302261; batch adversarial loss: 0.455871\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378955; batch adversarial loss: 0.477792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354499; batch adversarial loss: 0.470662\n",
      "epoch 18; iter: 0; batch classifier loss: 0.321540; batch adversarial loss: 0.498367\n",
      "epoch 19; iter: 0; batch classifier loss: 0.401598; batch adversarial loss: 0.433362\n",
      "epoch 20; iter: 0; batch classifier loss: 0.330264; batch adversarial loss: 0.458850\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338271; batch adversarial loss: 0.469223\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336726; batch adversarial loss: 0.466271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218202; batch adversarial loss: 0.490927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.243748; batch adversarial loss: 0.513184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327807; batch adversarial loss: 0.470837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251000; batch adversarial loss: 0.447838\n",
      "epoch 27; iter: 0; batch classifier loss: 0.264614; batch adversarial loss: 0.487204\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220430; batch adversarial loss: 0.398518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.298048; batch adversarial loss: 0.530518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223756; batch adversarial loss: 0.475327\n",
      "epoch 31; iter: 0; batch classifier loss: 0.208273; batch adversarial loss: 0.441418\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233601; batch adversarial loss: 0.431946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.259756; batch adversarial loss: 0.441805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.247375; batch adversarial loss: 0.438111\n",
      "epoch 35; iter: 0; batch classifier loss: 0.262699; batch adversarial loss: 0.450068\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261271; batch adversarial loss: 0.415987\n",
      "epoch 37; iter: 0; batch classifier loss: 0.359367; batch adversarial loss: 0.412870\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251736; batch adversarial loss: 0.428450\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327341; batch adversarial loss: 0.403327\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315249; batch adversarial loss: 0.436972\n",
      "epoch 41; iter: 0; batch classifier loss: 0.262169; batch adversarial loss: 0.436712\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299800; batch adversarial loss: 0.412537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.250870; batch adversarial loss: 0.470964\n",
      "epoch 44; iter: 0; batch classifier loss: 0.189868; batch adversarial loss: 0.386083\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118772; batch adversarial loss: 0.445556\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098446; batch adversarial loss: 0.456927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111972; batch adversarial loss: 0.402380\n",
      "epoch 48; iter: 0; batch classifier loss: 0.062606; batch adversarial loss: 0.422643\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143780; batch adversarial loss: 0.468972\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114868; batch adversarial loss: 0.435503\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178924; batch adversarial loss: 0.396555\n",
      "epoch 52; iter: 0; batch classifier loss: 0.341807; batch adversarial loss: 0.471156\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221382; batch adversarial loss: 0.497868\n",
      "epoch 54; iter: 0; batch classifier loss: 0.180051; batch adversarial loss: 0.459297\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205348; batch adversarial loss: 0.434440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.220211; batch adversarial loss: 0.483123\n",
      "epoch 57; iter: 0; batch classifier loss: 0.199875; batch adversarial loss: 0.447093\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201642; batch adversarial loss: 0.483087\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170150; batch adversarial loss: 0.557908\n",
      "epoch 60; iter: 0; batch classifier loss: 0.206009; batch adversarial loss: 0.535983\n",
      "epoch 61; iter: 0; batch classifier loss: 0.275401; batch adversarial loss: 0.434506\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162212; batch adversarial loss: 0.447227\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157141; batch adversarial loss: 0.459291\n",
      "epoch 64; iter: 0; batch classifier loss: 0.188840; batch adversarial loss: 0.557738\n",
      "epoch 65; iter: 0; batch classifier loss: 0.146828; batch adversarial loss: 0.446595\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115749; batch adversarial loss: 0.457784\n",
      "epoch 67; iter: 0; batch classifier loss: 0.071969; batch adversarial loss: 0.459905\n",
      "epoch 68; iter: 0; batch classifier loss: 0.092265; batch adversarial loss: 0.505787\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114116; batch adversarial loss: 0.523050\n",
      "epoch 70; iter: 0; batch classifier loss: 0.200375; batch adversarial loss: 0.483407\n",
      "epoch 71; iter: 0; batch classifier loss: 0.204142; batch adversarial loss: 0.447396\n",
      "epoch 72; iter: 0; batch classifier loss: 0.208817; batch adversarial loss: 0.458427\n",
      "epoch 73; iter: 0; batch classifier loss: 0.167435; batch adversarial loss: 0.532491\n",
      "epoch 74; iter: 0; batch classifier loss: 0.155173; batch adversarial loss: 0.419831\n",
      "epoch 75; iter: 0; batch classifier loss: 0.256463; batch adversarial loss: 0.459627\n",
      "epoch 76; iter: 0; batch classifier loss: 0.211565; batch adversarial loss: 0.372415\n",
      "epoch 77; iter: 0; batch classifier loss: 0.209108; batch adversarial loss: 0.347329\n",
      "epoch 78; iter: 0; batch classifier loss: 0.155691; batch adversarial loss: 0.496023\n",
      "epoch 79; iter: 0; batch classifier loss: 0.179753; batch adversarial loss: 0.447089\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209704; batch adversarial loss: 0.471532\n",
      "epoch 81; iter: 0; batch classifier loss: 0.150519; batch adversarial loss: 0.384958\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058069; batch adversarial loss: 0.535287\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082871; batch adversarial loss: 0.481309\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.492065\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045700; batch adversarial loss: 0.431296\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047285; batch adversarial loss: 0.412142\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040960; batch adversarial loss: 0.438300\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066097; batch adversarial loss: 0.464110\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036378; batch adversarial loss: 0.565879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.451481\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041852; batch adversarial loss: 0.339377\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036639; batch adversarial loss: 0.405854\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033744; batch adversarial loss: 0.525811\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044524; batch adversarial loss: 0.455074\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042418; batch adversarial loss: 0.488199\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056646; batch adversarial loss: 0.372514\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051455; batch adversarial loss: 0.445061\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071685; batch adversarial loss: 0.473253\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051260; batch adversarial loss: 0.490536\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042545; batch adversarial loss: 0.473398\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039764; batch adversarial loss: 0.485631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032949; batch adversarial loss: 0.420713\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043092; batch adversarial loss: 0.444091\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.390401\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035666; batch adversarial loss: 0.416396\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077390; batch adversarial loss: 0.395834\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050949; batch adversarial loss: 0.416017\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054643; batch adversarial loss: 0.513554\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070463; batch adversarial loss: 0.441613\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054452; batch adversarial loss: 0.359439\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050280; batch adversarial loss: 0.439610\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060087; batch adversarial loss: 0.440823\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035136; batch adversarial loss: 0.466139\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065473; batch adversarial loss: 0.438898\n",
      "epoch 115; iter: 0; batch classifier loss: 0.102736; batch adversarial loss: 0.428947\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053659; batch adversarial loss: 0.416988\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056146; batch adversarial loss: 0.534379\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028740; batch adversarial loss: 0.442796\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061125; batch adversarial loss: 0.474586\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024968; batch adversarial loss: 0.430904\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089366; batch adversarial loss: 0.466920\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044022; batch adversarial loss: 0.391587\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051953; batch adversarial loss: 0.371038\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059519; batch adversarial loss: 0.392787\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051109; batch adversarial loss: 0.378153\n",
      "epoch 126; iter: 0; batch classifier loss: 0.100934; batch adversarial loss: 0.464458\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055661; batch adversarial loss: 0.440767\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036960; batch adversarial loss: 0.307256\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056070; batch adversarial loss: 0.495524\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028684; batch adversarial loss: 0.427816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.038244; batch adversarial loss: 0.465534\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057272; batch adversarial loss: 0.403366\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036628; batch adversarial loss: 0.422230\n",
      "epoch 134; iter: 0; batch classifier loss: 0.097483; batch adversarial loss: 0.427143\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042443; batch adversarial loss: 0.508629\n",
      "epoch 136; iter: 0; batch classifier loss: 0.070039; batch adversarial loss: 0.442744\n",
      "epoch 137; iter: 0; batch classifier loss: 0.044817; batch adversarial loss: 0.420651\n",
      "epoch 138; iter: 0; batch classifier loss: 0.088381; batch adversarial loss: 0.417276\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048291; batch adversarial loss: 0.496820\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041972; batch adversarial loss: 0.358748\n",
      "epoch 141; iter: 0; batch classifier loss: 0.083956; batch adversarial loss: 0.441079\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048747; batch adversarial loss: 0.413169\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020924; batch adversarial loss: 0.351114\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041285; batch adversarial loss: 0.432771\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076323; batch adversarial loss: 0.407066\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052244; batch adversarial loss: 0.387838\n",
      "epoch 147; iter: 0; batch classifier loss: 0.086049; batch adversarial loss: 0.525386\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033573; batch adversarial loss: 0.487442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.456191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043232; batch adversarial loss: 0.499031\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043216; batch adversarial loss: 0.454402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070853; batch adversarial loss: 0.444353\n",
      "epoch 153; iter: 0; batch classifier loss: 0.059827; batch adversarial loss: 0.374397\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042667; batch adversarial loss: 0.459742\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037098; batch adversarial loss: 0.433322\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032007; batch adversarial loss: 0.436354\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052082; batch adversarial loss: 0.420249\n",
      "epoch 158; iter: 0; batch classifier loss: 0.075006; batch adversarial loss: 0.357400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046329; batch adversarial loss: 0.435341\n",
      "epoch 160; iter: 0; batch classifier loss: 0.056396; batch adversarial loss: 0.438972\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.375630\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059109; batch adversarial loss: 0.399526\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039790; batch adversarial loss: 0.420472\n",
      "epoch 164; iter: 0; batch classifier loss: 0.116127; batch adversarial loss: 0.459940\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052872; batch adversarial loss: 0.436934\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032439; batch adversarial loss: 0.506865\n",
      "epoch 167; iter: 0; batch classifier loss: 0.089727; batch adversarial loss: 0.404207\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032895; batch adversarial loss: 0.387012\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030777; batch adversarial loss: 0.397164\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043410; batch adversarial loss: 0.372001\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047284; batch adversarial loss: 0.355093\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058547; batch adversarial loss: 0.439039\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035564; batch adversarial loss: 0.420863\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054680; batch adversarial loss: 0.389839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.057072; batch adversarial loss: 0.414742\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035350; batch adversarial loss: 0.477181\n",
      "epoch 177; iter: 0; batch classifier loss: 0.058393; batch adversarial loss: 0.450244\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041549; batch adversarial loss: 0.434261\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045710; batch adversarial loss: 0.405310\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054404; batch adversarial loss: 0.440533\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060495; batch adversarial loss: 0.359279\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051840; batch adversarial loss: 0.412084\n",
      "epoch 183; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.453949\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045419; batch adversarial loss: 0.467237\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042000; batch adversarial loss: 0.444588\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031036; batch adversarial loss: 0.405081\n",
      "epoch 187; iter: 0; batch classifier loss: 0.052464; batch adversarial loss: 0.413140\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026594; batch adversarial loss: 0.409970\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039156; batch adversarial loss: 0.536739\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020978; batch adversarial loss: 0.428796\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036517; batch adversarial loss: 0.414540\n",
      "epoch 192; iter: 0; batch classifier loss: 0.055995; batch adversarial loss: 0.416762\n",
      "epoch 193; iter: 0; batch classifier loss: 0.069129; batch adversarial loss: 0.395418\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043242; batch adversarial loss: 0.512345\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025424; batch adversarial loss: 0.363409\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025395; batch adversarial loss: 0.477597\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029945; batch adversarial loss: 0.423095\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018894; batch adversarial loss: 0.516148\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028427; batch adversarial loss: 0.391853\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688709; batch adversarial loss: 0.737701\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565140; batch adversarial loss: 0.704864\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445621; batch adversarial loss: 0.623769\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350764; batch adversarial loss: 0.593957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.365699; batch adversarial loss: 0.577572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315584; batch adversarial loss: 0.601670\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348787; batch adversarial loss: 0.568173\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337205; batch adversarial loss: 0.521416\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402236; batch adversarial loss: 0.514717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244035; batch adversarial loss: 0.534692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338821; batch adversarial loss: 0.561582\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313675; batch adversarial loss: 0.533301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284338; batch adversarial loss: 0.516230\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221412; batch adversarial loss: 0.507457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240830; batch adversarial loss: 0.459208\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316886; batch adversarial loss: 0.452812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255227; batch adversarial loss: 0.442122\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183195; batch adversarial loss: 0.533392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231509; batch adversarial loss: 0.574983\n",
      "epoch 19; iter: 0; batch classifier loss: 0.202767; batch adversarial loss: 0.452112\n",
      "epoch 20; iter: 0; batch classifier loss: 0.242386; batch adversarial loss: 0.393513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190576; batch adversarial loss: 0.378312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.153572; batch adversarial loss: 0.486162\n",
      "epoch 23; iter: 0; batch classifier loss: 0.142255; batch adversarial loss: 0.467668\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188671; batch adversarial loss: 0.432108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.139919; batch adversarial loss: 0.513222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218516; batch adversarial loss: 0.545506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184701; batch adversarial loss: 0.531265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.118402; batch adversarial loss: 0.494718\n",
      "epoch 29; iter: 0; batch classifier loss: 0.203186; batch adversarial loss: 0.474782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162266; batch adversarial loss: 0.505996\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132735; batch adversarial loss: 0.540305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143594; batch adversarial loss: 0.402735\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127731; batch adversarial loss: 0.413059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.110848; batch adversarial loss: 0.433531\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118530; batch adversarial loss: 0.451361\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110814; batch adversarial loss: 0.401777\n",
      "epoch 37; iter: 0; batch classifier loss: 0.135839; batch adversarial loss: 0.368856\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120764; batch adversarial loss: 0.455999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093800; batch adversarial loss: 0.468921\n",
      "epoch 40; iter: 0; batch classifier loss: 0.070402; batch adversarial loss: 0.372838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112608; batch adversarial loss: 0.483118\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076194; batch adversarial loss: 0.538618\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118510; batch adversarial loss: 0.545795\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140584; batch adversarial loss: 0.432274\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081842; batch adversarial loss: 0.424690\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132174; batch adversarial loss: 0.482192\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097266; batch adversarial loss: 0.480823\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072531; batch adversarial loss: 0.419604\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101007; batch adversarial loss: 0.455826\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096406; batch adversarial loss: 0.514507\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106204; batch adversarial loss: 0.487220\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105226; batch adversarial loss: 0.414800\n",
      "epoch 53; iter: 0; batch classifier loss: 0.058054; batch adversarial loss: 0.461835\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069393; batch adversarial loss: 0.396293\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077139; batch adversarial loss: 0.432805\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069118; batch adversarial loss: 0.450033\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091076; batch adversarial loss: 0.401580\n",
      "epoch 58; iter: 0; batch classifier loss: 0.058109; batch adversarial loss: 0.446988\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050763; batch adversarial loss: 0.425050\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081537; batch adversarial loss: 0.519480\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078117; batch adversarial loss: 0.492226\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081750; batch adversarial loss: 0.442806\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067465; batch adversarial loss: 0.491083\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082787; batch adversarial loss: 0.444852\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075066; batch adversarial loss: 0.475560\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067007; batch adversarial loss: 0.375506\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061300; batch adversarial loss: 0.423290\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081613; batch adversarial loss: 0.410821\n",
      "epoch 69; iter: 0; batch classifier loss: 0.039735; batch adversarial loss: 0.438490\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076166; batch adversarial loss: 0.535290\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081506; batch adversarial loss: 0.472158\n",
      "epoch 72; iter: 0; batch classifier loss: 0.030317; batch adversarial loss: 0.472299\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072983; batch adversarial loss: 0.451626\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098888; batch adversarial loss: 0.488276\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067119; batch adversarial loss: 0.492899\n",
      "epoch 76; iter: 0; batch classifier loss: 0.115762; batch adversarial loss: 0.511648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064826; batch adversarial loss: 0.365268\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085767; batch adversarial loss: 0.450635\n",
      "epoch 79; iter: 0; batch classifier loss: 0.032470; batch adversarial loss: 0.441631\n",
      "epoch 80; iter: 0; batch classifier loss: 0.037484; batch adversarial loss: 0.609084\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057423; batch adversarial loss: 0.542593\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061120; batch adversarial loss: 0.458692\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093986; batch adversarial loss: 0.453331\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059890; batch adversarial loss: 0.535510\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040664; batch adversarial loss: 0.603473\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036877; batch adversarial loss: 0.407620\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059083; batch adversarial loss: 0.483280\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069096; batch adversarial loss: 0.494860\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046782; batch adversarial loss: 0.420658\n",
      "epoch 90; iter: 0; batch classifier loss: 0.029732; batch adversarial loss: 0.451216\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079137; batch adversarial loss: 0.478229\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060099; batch adversarial loss: 0.528154\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052720; batch adversarial loss: 0.454641\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039115; batch adversarial loss: 0.473309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030744; batch adversarial loss: 0.497452\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025457; batch adversarial loss: 0.454300\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069793; batch adversarial loss: 0.497978\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050444; batch adversarial loss: 0.517815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028876; batch adversarial loss: 0.431820\n",
      "epoch 100; iter: 0; batch classifier loss: 0.025946; batch adversarial loss: 0.493000\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054318; batch adversarial loss: 0.478763\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054299; batch adversarial loss: 0.423401\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086407; batch adversarial loss: 0.439098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044508; batch adversarial loss: 0.477524\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043915; batch adversarial loss: 0.419200\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070344; batch adversarial loss: 0.373207\n",
      "epoch 107; iter: 0; batch classifier loss: 0.026616; batch adversarial loss: 0.488917\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032589; batch adversarial loss: 0.554788\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041885; batch adversarial loss: 0.404143\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042878; batch adversarial loss: 0.357284\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023976; batch adversarial loss: 0.522431\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036623; batch adversarial loss: 0.492083\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080030; batch adversarial loss: 0.503888\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035046; batch adversarial loss: 0.442493\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049537; batch adversarial loss: 0.479649\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043143; batch adversarial loss: 0.406737\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034938; batch adversarial loss: 0.435087\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038759; batch adversarial loss: 0.465511\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026101; batch adversarial loss: 0.542598\n",
      "epoch 120; iter: 0; batch classifier loss: 0.014971; batch adversarial loss: 0.405429\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030746; batch adversarial loss: 0.462625\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031310; batch adversarial loss: 0.512565\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033026; batch adversarial loss: 0.418555\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035097; batch adversarial loss: 0.392867\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052457; batch adversarial loss: 0.427482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.049790; batch adversarial loss: 0.461573\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028069; batch adversarial loss: 0.436253\n",
      "epoch 128; iter: 0; batch classifier loss: 0.011337; batch adversarial loss: 0.456999\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042499; batch adversarial loss: 0.486085\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018413; batch adversarial loss: 0.429434\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039440; batch adversarial loss: 0.544916\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026394; batch adversarial loss: 0.416691\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023095; batch adversarial loss: 0.451809\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019364; batch adversarial loss: 0.435366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023338; batch adversarial loss: 0.418934\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025171; batch adversarial loss: 0.403979\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030144; batch adversarial loss: 0.506888\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052288; batch adversarial loss: 0.445753\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039781; batch adversarial loss: 0.431790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013108; batch adversarial loss: 0.380338\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.448778\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023890; batch adversarial loss: 0.505932\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029135; batch adversarial loss: 0.434285\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016900; batch adversarial loss: 0.431162\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020940; batch adversarial loss: 0.546238\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045970; batch adversarial loss: 0.423076\n",
      "epoch 147; iter: 0; batch classifier loss: 0.007946; batch adversarial loss: 0.337799\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043032; batch adversarial loss: 0.585753\n",
      "epoch 149; iter: 0; batch classifier loss: 0.007648; batch adversarial loss: 0.380266\n",
      "epoch 150; iter: 0; batch classifier loss: 0.075686; batch adversarial loss: 0.340425\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015166; batch adversarial loss: 0.401293\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016862; batch adversarial loss: 0.481213\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011189; batch adversarial loss: 0.408460\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015638; batch adversarial loss: 0.504099\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016150; batch adversarial loss: 0.513758\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037760; batch adversarial loss: 0.453434\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013454; batch adversarial loss: 0.386509\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046191; batch adversarial loss: 0.386902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012514; batch adversarial loss: 0.517090\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024510; batch adversarial loss: 0.437656\n",
      "epoch 161; iter: 0; batch classifier loss: 0.055648; batch adversarial loss: 0.506027\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050698; batch adversarial loss: 0.424554\n",
      "epoch 163; iter: 0; batch classifier loss: 0.049774; batch adversarial loss: 0.462655\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018898; batch adversarial loss: 0.444442\n",
      "epoch 165; iter: 0; batch classifier loss: 0.050257; batch adversarial loss: 0.491500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018499; batch adversarial loss: 0.436359\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026345; batch adversarial loss: 0.319114\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014832; batch adversarial loss: 0.414178\n",
      "epoch 169; iter: 0; batch classifier loss: 0.061311; batch adversarial loss: 0.427372\n",
      "epoch 170; iter: 0; batch classifier loss: 0.081926; batch adversarial loss: 0.408838\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020360; batch adversarial loss: 0.479363\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017889; batch adversarial loss: 0.516267\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040232; batch adversarial loss: 0.462525\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008311; batch adversarial loss: 0.375054\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028245; batch adversarial loss: 0.348735\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037314; batch adversarial loss: 0.387637\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011603; batch adversarial loss: 0.405255\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036955; batch adversarial loss: 0.425964\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019604; batch adversarial loss: 0.357759\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010181; batch adversarial loss: 0.497822\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.473098\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006025; batch adversarial loss: 0.491263\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015714; batch adversarial loss: 0.426754\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024744; batch adversarial loss: 0.522287\n",
      "epoch 185; iter: 0; batch classifier loss: 0.074915; batch adversarial loss: 0.391392\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047792; batch adversarial loss: 0.320144\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015542; batch adversarial loss: 0.385848\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034304; batch adversarial loss: 0.466579\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018670; batch adversarial loss: 0.491849\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024813; batch adversarial loss: 0.483675\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020864; batch adversarial loss: 0.470435\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040739; batch adversarial loss: 0.401479\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040652; batch adversarial loss: 0.462367\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014062; batch adversarial loss: 0.485363\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.518092\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017867; batch adversarial loss: 0.447596\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024172; batch adversarial loss: 0.457796\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.558102\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049087; batch adversarial loss: 0.478960\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686587; batch adversarial loss: 0.622810\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484586; batch adversarial loss: 0.619806\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396514; batch adversarial loss: 0.606928\n",
      "epoch 3; iter: 0; batch classifier loss: 0.324859; batch adversarial loss: 0.569952\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401415; batch adversarial loss: 0.547070\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299535; batch adversarial loss: 0.538456\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253720; batch adversarial loss: 0.564551\n",
      "epoch 7; iter: 0; batch classifier loss: 0.275522; batch adversarial loss: 0.506788\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303509; batch adversarial loss: 0.564151\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280372; batch adversarial loss: 0.541487\n",
      "epoch 10; iter: 0; batch classifier loss: 0.293636; batch adversarial loss: 0.532666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.221464; batch adversarial loss: 0.426636\n",
      "epoch 12; iter: 0; batch classifier loss: 0.214227; batch adversarial loss: 0.471308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220913; batch adversarial loss: 0.550629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.244505; batch adversarial loss: 0.506779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302168; batch adversarial loss: 0.462180\n",
      "epoch 16; iter: 0; batch classifier loss: 0.205679; batch adversarial loss: 0.490203\n",
      "epoch 17; iter: 0; batch classifier loss: 0.271014; batch adversarial loss: 0.632336\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272666; batch adversarial loss: 0.481403\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297460; batch adversarial loss: 0.563533\n",
      "epoch 20; iter: 0; batch classifier loss: 0.336338; batch adversarial loss: 0.590086\n",
      "epoch 21; iter: 0; batch classifier loss: 0.396585; batch adversarial loss: 0.498111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.406956; batch adversarial loss: 0.511332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534721; batch adversarial loss: 0.435393\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271095; batch adversarial loss: 0.510031\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223511; batch adversarial loss: 0.436857\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177950; batch adversarial loss: 0.442095\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150505; batch adversarial loss: 0.492472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170263; batch adversarial loss: 0.481685\n",
      "epoch 29; iter: 0; batch classifier loss: 0.122259; batch adversarial loss: 0.472143\n",
      "epoch 30; iter: 0; batch classifier loss: 0.138554; batch adversarial loss: 0.478394\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179812; batch adversarial loss: 0.547000\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143262; batch adversarial loss: 0.410454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.090243; batch adversarial loss: 0.475850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140569; batch adversarial loss: 0.463028\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113723; batch adversarial loss: 0.555454\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123203; batch adversarial loss: 0.474308\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093847; batch adversarial loss: 0.464939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129045; batch adversarial loss: 0.505355\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125100; batch adversarial loss: 0.503940\n",
      "epoch 40; iter: 0; batch classifier loss: 0.165569; batch adversarial loss: 0.474247\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156009; batch adversarial loss: 0.395086\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135753; batch adversarial loss: 0.462440\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114405; batch adversarial loss: 0.413882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.186363; batch adversarial loss: 0.482811\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122345; batch adversarial loss: 0.474207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119596; batch adversarial loss: 0.401885\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133588; batch adversarial loss: 0.471581\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109737; batch adversarial loss: 0.431800\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122025; batch adversarial loss: 0.408258\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138079; batch adversarial loss: 0.572094\n",
      "epoch 51; iter: 0; batch classifier loss: 0.177114; batch adversarial loss: 0.442340\n",
      "epoch 52; iter: 0; batch classifier loss: 0.170167; batch adversarial loss: 0.474135\n",
      "epoch 53; iter: 0; batch classifier loss: 0.229909; batch adversarial loss: 0.426659\n",
      "epoch 54; iter: 0; batch classifier loss: 0.170273; batch adversarial loss: 0.362107\n",
      "epoch 55; iter: 0; batch classifier loss: 0.113460; batch adversarial loss: 0.495308\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097487; batch adversarial loss: 0.392528\n",
      "epoch 57; iter: 0; batch classifier loss: 0.148709; batch adversarial loss: 0.433324\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128164; batch adversarial loss: 0.498249\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133535; batch adversarial loss: 0.376442\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114336; batch adversarial loss: 0.437061\n",
      "epoch 61; iter: 0; batch classifier loss: 0.136362; batch adversarial loss: 0.430922\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108795; batch adversarial loss: 0.424725\n",
      "epoch 63; iter: 0; batch classifier loss: 0.199424; batch adversarial loss: 0.359509\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124718; batch adversarial loss: 0.418483\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098721; batch adversarial loss: 0.450915\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132990; batch adversarial loss: 0.385068\n",
      "epoch 67; iter: 0; batch classifier loss: 0.106186; batch adversarial loss: 0.519074\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117822; batch adversarial loss: 0.476342\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064838; batch adversarial loss: 0.407199\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123402; batch adversarial loss: 0.377202\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074132; batch adversarial loss: 0.328867\n",
      "epoch 72; iter: 0; batch classifier loss: 0.128155; batch adversarial loss: 0.454913\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155082; batch adversarial loss: 0.484107\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067351; batch adversarial loss: 0.465730\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147444; batch adversarial loss: 0.354116\n",
      "epoch 76; iter: 0; batch classifier loss: 0.178390; batch adversarial loss: 0.387831\n",
      "epoch 77; iter: 0; batch classifier loss: 0.100336; batch adversarial loss: 0.425831\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081527; batch adversarial loss: 0.464547\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109612; batch adversarial loss: 0.494216\n",
      "epoch 80; iter: 0; batch classifier loss: 0.125535; batch adversarial loss: 0.364795\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078477; batch adversarial loss: 0.425916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070521; batch adversarial loss: 0.416796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115295; batch adversarial loss: 0.472809\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084330; batch adversarial loss: 0.440818\n",
      "epoch 85; iter: 0; batch classifier loss: 0.104220; batch adversarial loss: 0.480171\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074748; batch adversarial loss: 0.433138\n",
      "epoch 87; iter: 0; batch classifier loss: 0.112745; batch adversarial loss: 0.385194\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093507; batch adversarial loss: 0.407903\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098071; batch adversarial loss: 0.424201\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077101; batch adversarial loss: 0.405740\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107192; batch adversarial loss: 0.513723\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091569; batch adversarial loss: 0.398802\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082970; batch adversarial loss: 0.305953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050387; batch adversarial loss: 0.525874\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108294; batch adversarial loss: 0.423709\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070885; batch adversarial loss: 0.424628\n",
      "epoch 97; iter: 0; batch classifier loss: 0.151256; batch adversarial loss: 0.524656\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051091; batch adversarial loss: 0.412297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.060140; batch adversarial loss: 0.406133\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057346; batch adversarial loss: 0.467215\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062359; batch adversarial loss: 0.390739\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038026; batch adversarial loss: 0.441156\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082784; batch adversarial loss: 0.513742\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043898; batch adversarial loss: 0.456731\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064486; batch adversarial loss: 0.428400\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037946; batch adversarial loss: 0.430813\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055281; batch adversarial loss: 0.377133\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051909; batch adversarial loss: 0.515663\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054344; batch adversarial loss: 0.467654\n",
      "epoch 110; iter: 0; batch classifier loss: 0.117223; batch adversarial loss: 0.339555\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024895; batch adversarial loss: 0.495661\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061233; batch adversarial loss: 0.556039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036674; batch adversarial loss: 0.526420\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043697; batch adversarial loss: 0.528833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.082641; batch adversarial loss: 0.395820\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053688; batch adversarial loss: 0.432233\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057777; batch adversarial loss: 0.334886\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035779; batch adversarial loss: 0.493119\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.490302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.021085; batch adversarial loss: 0.426083\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036307; batch adversarial loss: 0.455509\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031546; batch adversarial loss: 0.413071\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017351; batch adversarial loss: 0.515463\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031273; batch adversarial loss: 0.484876\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042565; batch adversarial loss: 0.487998\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038434; batch adversarial loss: 0.490962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022587; batch adversarial loss: 0.481822\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034354; batch adversarial loss: 0.357309\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033969; batch adversarial loss: 0.448222\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036983; batch adversarial loss: 0.414671\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035254; batch adversarial loss: 0.346632\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045588; batch adversarial loss: 0.439239\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034527; batch adversarial loss: 0.418470\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031182; batch adversarial loss: 0.539450\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026545; batch adversarial loss: 0.548671\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021887; batch adversarial loss: 0.405571\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037519; batch adversarial loss: 0.384120\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037956; batch adversarial loss: 0.411840\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.382955\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.393409\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029568; batch adversarial loss: 0.530807\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019573; batch adversarial loss: 0.420419\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010288; batch adversarial loss: 0.522270\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031351; batch adversarial loss: 0.523236\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035084; batch adversarial loss: 0.424787\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017991; batch adversarial loss: 0.449220\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038573; batch adversarial loss: 0.457313\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026529; batch adversarial loss: 0.426025\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059419; batch adversarial loss: 0.353776\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025605; batch adversarial loss: 0.444199\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019027; batch adversarial loss: 0.420552\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.389311\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032584; batch adversarial loss: 0.376357\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042602; batch adversarial loss: 0.426004\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036567; batch adversarial loss: 0.376604\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016545; batch adversarial loss: 0.343318\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016453; batch adversarial loss: 0.486121\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019893; batch adversarial loss: 0.423743\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042793; batch adversarial loss: 0.462625\n",
      "epoch 160; iter: 0; batch classifier loss: 0.011202; batch adversarial loss: 0.465107\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033919; batch adversarial loss: 0.414788\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041233; batch adversarial loss: 0.428764\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045174; batch adversarial loss: 0.456925\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033732; batch adversarial loss: 0.419995\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049012; batch adversarial loss: 0.477082\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017940; batch adversarial loss: 0.451104\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022067; batch adversarial loss: 0.383060\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015239; batch adversarial loss: 0.464880\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018387; batch adversarial loss: 0.436001\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032845; batch adversarial loss: 0.485088\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014940; batch adversarial loss: 0.449372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.076467; batch adversarial loss: 0.477853\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020423; batch adversarial loss: 0.515097\n",
      "epoch 174; iter: 0; batch classifier loss: 0.058140; batch adversarial loss: 0.495069\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039733; batch adversarial loss: 0.409774\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018819; batch adversarial loss: 0.498965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010798; batch adversarial loss: 0.531975\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.417939\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010051; batch adversarial loss: 0.617470\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023835; batch adversarial loss: 0.484676\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013604; batch adversarial loss: 0.492615\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027904; batch adversarial loss: 0.439715\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035500; batch adversarial loss: 0.413018\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007725; batch adversarial loss: 0.414153\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017159; batch adversarial loss: 0.390998\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.464075\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020145; batch adversarial loss: 0.459753\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016125; batch adversarial loss: 0.485083\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.420105\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009334; batch adversarial loss: 0.391466\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013450; batch adversarial loss: 0.463420\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047956; batch adversarial loss: 0.469547\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037567; batch adversarial loss: 0.496495\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011449; batch adversarial loss: 0.447925\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035284; batch adversarial loss: 0.507006\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021448; batch adversarial loss: 0.387694\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008703; batch adversarial loss: 0.420059\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016935; batch adversarial loss: 0.495745\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026050; batch adversarial loss: 0.526742\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697502; batch adversarial loss: 0.743664\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461341; batch adversarial loss: 0.698520\n",
      "epoch 2; iter: 0; batch classifier loss: 0.476402; batch adversarial loss: 0.668733\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362370; batch adversarial loss: 0.643464\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386621; batch adversarial loss: 0.602829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.393313; batch adversarial loss: 0.589770\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253299; batch adversarial loss: 0.523029\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372009; batch adversarial loss: 0.548579\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278779; batch adversarial loss: 0.524621\n",
      "epoch 9; iter: 0; batch classifier loss: 0.240057; batch adversarial loss: 0.536730\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240687; batch adversarial loss: 0.511946\n",
      "epoch 11; iter: 0; batch classifier loss: 0.208804; batch adversarial loss: 0.483662\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234348; batch adversarial loss: 0.445761\n",
      "epoch 13; iter: 0; batch classifier loss: 0.179978; batch adversarial loss: 0.440968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210117; batch adversarial loss: 0.437438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.135222; batch adversarial loss: 0.417603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190379; batch adversarial loss: 0.436099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.193279; batch adversarial loss: 0.456147\n",
      "epoch 18; iter: 0; batch classifier loss: 0.203241; batch adversarial loss: 0.461306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160400; batch adversarial loss: 0.434753\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191181; batch adversarial loss: 0.388495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149959; batch adversarial loss: 0.438210\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196402; batch adversarial loss: 0.375554\n",
      "epoch 23; iter: 0; batch classifier loss: 0.149560; batch adversarial loss: 0.372745\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191547; batch adversarial loss: 0.390488\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155992; batch adversarial loss: 0.441194\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180535; batch adversarial loss: 0.378032\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163724; batch adversarial loss: 0.391864\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139923; batch adversarial loss: 0.408549\n",
      "epoch 29; iter: 0; batch classifier loss: 0.124502; batch adversarial loss: 0.380225\n",
      "epoch 30; iter: 0; batch classifier loss: 0.123116; batch adversarial loss: 0.421705\n",
      "epoch 31; iter: 0; batch classifier loss: 0.170316; batch adversarial loss: 0.441506\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145133; batch adversarial loss: 0.351879\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163099; batch adversarial loss: 0.391031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157382; batch adversarial loss: 0.355973\n",
      "epoch 35; iter: 0; batch classifier loss: 0.154851; batch adversarial loss: 0.337132\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118450; batch adversarial loss: 0.381766\n",
      "epoch 37; iter: 0; batch classifier loss: 0.159621; batch adversarial loss: 0.469959\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106460; batch adversarial loss: 0.430720\n",
      "epoch 39; iter: 0; batch classifier loss: 0.057789; batch adversarial loss: 0.420462\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113226; batch adversarial loss: 0.400994\n",
      "epoch 41; iter: 0; batch classifier loss: 0.074536; batch adversarial loss: 0.291814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102651; batch adversarial loss: 0.405126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116157; batch adversarial loss: 0.424755\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101094; batch adversarial loss: 0.319485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087608; batch adversarial loss: 0.412408\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112070; batch adversarial loss: 0.396360\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076674; batch adversarial loss: 0.379672\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072033; batch adversarial loss: 0.481458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083100; batch adversarial loss: 0.410563\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087719; batch adversarial loss: 0.373363\n",
      "epoch 51; iter: 0; batch classifier loss: 0.092506; batch adversarial loss: 0.464129\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114727; batch adversarial loss: 0.433043\n",
      "epoch 53; iter: 0; batch classifier loss: 0.078327; batch adversarial loss: 0.417800\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076896; batch adversarial loss: 0.389415\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102436; batch adversarial loss: 0.400228\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071263; batch adversarial loss: 0.397791\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080258; batch adversarial loss: 0.417215\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066984; batch adversarial loss: 0.419122\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092122; batch adversarial loss: 0.393107\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078551; batch adversarial loss: 0.396383\n",
      "epoch 61; iter: 0; batch classifier loss: 0.105534; batch adversarial loss: 0.589465\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094645; batch adversarial loss: 0.400442\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067036; batch adversarial loss: 0.476578\n",
      "epoch 64; iter: 0; batch classifier loss: 0.056713; batch adversarial loss: 0.365718\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071837; batch adversarial loss: 0.346829\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102703; batch adversarial loss: 0.466878\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092780; batch adversarial loss: 0.309801\n",
      "epoch 68; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.327741\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099192; batch adversarial loss: 0.465521\n",
      "epoch 70; iter: 0; batch classifier loss: 0.035701; batch adversarial loss: 0.380946\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070125; batch adversarial loss: 0.463618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066060; batch adversarial loss: 0.483850\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058840; batch adversarial loss: 0.362414\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071959; batch adversarial loss: 0.467844\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063005; batch adversarial loss: 0.436090\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072570; batch adversarial loss: 0.428451\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087657; batch adversarial loss: 0.388108\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059937; batch adversarial loss: 0.460980\n",
      "epoch 79; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.465302\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080123; batch adversarial loss: 0.412671\n",
      "epoch 81; iter: 0; batch classifier loss: 0.039877; batch adversarial loss: 0.301408\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068898; batch adversarial loss: 0.325163\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078791; batch adversarial loss: 0.385756\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053005; batch adversarial loss: 0.333836\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057855; batch adversarial loss: 0.494656\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054716; batch adversarial loss: 0.265333\n",
      "epoch 87; iter: 0; batch classifier loss: 0.106939; batch adversarial loss: 0.449136\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046508; batch adversarial loss: 0.396469\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117786; batch adversarial loss: 0.434333\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059650; batch adversarial loss: 0.451949\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073074; batch adversarial loss: 0.445556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.051209; batch adversarial loss: 0.454232\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053366; batch adversarial loss: 0.420911\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093008; batch adversarial loss: 0.392112\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085280; batch adversarial loss: 0.358414\n",
      "epoch 96; iter: 0; batch classifier loss: 0.120808; batch adversarial loss: 0.525300\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077682; batch adversarial loss: 0.455482\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079540; batch adversarial loss: 0.349019\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085350; batch adversarial loss: 0.430660\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065262; batch adversarial loss: 0.439183\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044537; batch adversarial loss: 0.441220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054681; batch adversarial loss: 0.395886\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026938; batch adversarial loss: 0.379930\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060487; batch adversarial loss: 0.428751\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075234; batch adversarial loss: 0.405688\n",
      "epoch 106; iter: 0; batch classifier loss: 0.118251; batch adversarial loss: 0.427796\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044830; batch adversarial loss: 0.404590\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038098; batch adversarial loss: 0.479779\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051938; batch adversarial loss: 0.457702\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051510; batch adversarial loss: 0.449906\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075300; batch adversarial loss: 0.362537\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045119; batch adversarial loss: 0.387939\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.372406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.070713; batch adversarial loss: 0.451678\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053750; batch adversarial loss: 0.338442\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042007; batch adversarial loss: 0.428976\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049569; batch adversarial loss: 0.423006\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029398; batch adversarial loss: 0.422119\n",
      "epoch 119; iter: 0; batch classifier loss: 0.062776; batch adversarial loss: 0.408645\n",
      "epoch 120; iter: 0; batch classifier loss: 0.078891; batch adversarial loss: 0.489058\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047032; batch adversarial loss: 0.392447\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067149; batch adversarial loss: 0.348449\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052415; batch adversarial loss: 0.391845\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026351; batch adversarial loss: 0.449241\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048800; batch adversarial loss: 0.525070\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044382; batch adversarial loss: 0.440619\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038299; batch adversarial loss: 0.595248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026228; batch adversarial loss: 0.419587\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050394; batch adversarial loss: 0.429933\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019601; batch adversarial loss: 0.434277\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032338; batch adversarial loss: 0.374745\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034561; batch adversarial loss: 0.401457\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032654; batch adversarial loss: 0.407738\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048703; batch adversarial loss: 0.395368\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.444514\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029479; batch adversarial loss: 0.442968\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024133; batch adversarial loss: 0.472521\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035582; batch adversarial loss: 0.430539\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053114; batch adversarial loss: 0.400321\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023237; batch adversarial loss: 0.396679\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045781; batch adversarial loss: 0.443170\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.412140\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035516; batch adversarial loss: 0.461699\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020757; batch adversarial loss: 0.418888\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014444; batch adversarial loss: 0.443029\n",
      "epoch 146; iter: 0; batch classifier loss: 0.049256; batch adversarial loss: 0.474732\n",
      "epoch 147; iter: 0; batch classifier loss: 0.054522; batch adversarial loss: 0.452969\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011986; batch adversarial loss: 0.549484\n",
      "epoch 149; iter: 0; batch classifier loss: 0.016046; batch adversarial loss: 0.467087\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038667; batch adversarial loss: 0.485198\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035248; batch adversarial loss: 0.375294\n",
      "epoch 152; iter: 0; batch classifier loss: 0.075695; batch adversarial loss: 0.585929\n",
      "epoch 153; iter: 0; batch classifier loss: 0.064712; batch adversarial loss: 0.383844\n",
      "epoch 154; iter: 0; batch classifier loss: 0.153293; batch adversarial loss: 0.707718\n",
      "epoch 155; iter: 0; batch classifier loss: 0.120718; batch adversarial loss: 0.618693\n",
      "epoch 156; iter: 0; batch classifier loss: 0.066915; batch adversarial loss: 0.467446\n",
      "epoch 157; iter: 0; batch classifier loss: 0.081186; batch adversarial loss: 0.595102\n",
      "epoch 158; iter: 0; batch classifier loss: 0.092261; batch adversarial loss: 0.560566\n",
      "epoch 159; iter: 0; batch classifier loss: 0.174263; batch adversarial loss: 0.769419\n",
      "epoch 160; iter: 0; batch classifier loss: 0.135933; batch adversarial loss: 0.763340\n",
      "epoch 161; iter: 0; batch classifier loss: 0.095610; batch adversarial loss: 0.544723\n",
      "epoch 162; iter: 0; batch classifier loss: 0.118315; batch adversarial loss: 0.681894\n",
      "epoch 163; iter: 0; batch classifier loss: 0.179696; batch adversarial loss: 0.795435\n",
      "epoch 164; iter: 0; batch classifier loss: 0.137954; batch adversarial loss: 0.570483\n",
      "epoch 165; iter: 0; batch classifier loss: 0.238613; batch adversarial loss: 0.768272\n",
      "epoch 166; iter: 0; batch classifier loss: 0.174211; batch adversarial loss: 0.780732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.111808; batch adversarial loss: 0.633722\n",
      "epoch 168; iter: 0; batch classifier loss: 0.220885; batch adversarial loss: 0.721927\n",
      "epoch 169; iter: 0; batch classifier loss: 0.191117; batch adversarial loss: 0.674381\n",
      "epoch 170; iter: 0; batch classifier loss: 0.162170; batch adversarial loss: 0.751980\n",
      "epoch 171; iter: 0; batch classifier loss: 0.173860; batch adversarial loss: 0.697848\n",
      "epoch 172; iter: 0; batch classifier loss: 0.078963; batch adversarial loss: 0.442681\n",
      "epoch 173; iter: 0; batch classifier loss: 0.141177; batch adversarial loss: 0.597387\n",
      "epoch 174; iter: 0; batch classifier loss: 0.117985; batch adversarial loss: 0.520289\n",
      "epoch 175; iter: 0; batch classifier loss: 0.162331; batch adversarial loss: 0.579880\n",
      "epoch 176; iter: 0; batch classifier loss: 0.102151; batch adversarial loss: 0.533455\n",
      "epoch 177; iter: 0; batch classifier loss: 0.253335; batch adversarial loss: 0.716218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.189482; batch adversarial loss: 0.711327\n",
      "epoch 179; iter: 0; batch classifier loss: 0.185908; batch adversarial loss: 0.616700\n",
      "epoch 180; iter: 0; batch classifier loss: 0.187313; batch adversarial loss: 0.632618\n",
      "epoch 181; iter: 0; batch classifier loss: 0.242726; batch adversarial loss: 0.695303\n",
      "epoch 182; iter: 0; batch classifier loss: 0.206540; batch adversarial loss: 0.712775\n",
      "epoch 183; iter: 0; batch classifier loss: 0.208772; batch adversarial loss: 0.601955\n",
      "epoch 184; iter: 0; batch classifier loss: 0.137988; batch adversarial loss: 0.510051\n",
      "epoch 185; iter: 0; batch classifier loss: 0.144791; batch adversarial loss: 0.518016\n",
      "epoch 186; iter: 0; batch classifier loss: 0.095458; batch adversarial loss: 0.416512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.175648; batch adversarial loss: 0.610648\n",
      "epoch 188; iter: 0; batch classifier loss: 0.136906; batch adversarial loss: 0.534242\n",
      "epoch 189; iter: 0; batch classifier loss: 0.170065; batch adversarial loss: 0.624766\n",
      "epoch 190; iter: 0; batch classifier loss: 0.136787; batch adversarial loss: 0.553694\n",
      "epoch 191; iter: 0; batch classifier loss: 0.100392; batch adversarial loss: 0.416049\n",
      "epoch 192; iter: 0; batch classifier loss: 0.135649; batch adversarial loss: 0.593477\n",
      "epoch 193; iter: 0; batch classifier loss: 0.145233; batch adversarial loss: 0.583840\n",
      "epoch 194; iter: 0; batch classifier loss: 0.158013; batch adversarial loss: 0.565996\n",
      "epoch 195; iter: 0; batch classifier loss: 0.105711; batch adversarial loss: 0.466406\n",
      "epoch 196; iter: 0; batch classifier loss: 0.119075; batch adversarial loss: 0.478964\n",
      "epoch 197; iter: 0; batch classifier loss: 0.072139; batch adversarial loss: 0.428890\n",
      "epoch 198; iter: 0; batch classifier loss: 0.127130; batch adversarial loss: 0.431464\n",
      "epoch 199; iter: 0; batch classifier loss: 0.145904; batch adversarial loss: 0.543382\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687215; batch adversarial loss: 0.534354\n",
      "epoch 1; iter: 0; batch classifier loss: 0.388634; batch adversarial loss: 0.635414\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432628; batch adversarial loss: 0.599469\n",
      "epoch 3; iter: 0; batch classifier loss: 0.405450; batch adversarial loss: 0.609449\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364819; batch adversarial loss: 0.598326\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339960; batch adversarial loss: 0.536272\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284756; batch adversarial loss: 0.548696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337407; batch adversarial loss: 0.521364\n",
      "epoch 8; iter: 0; batch classifier loss: 0.344929; batch adversarial loss: 0.586345\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320929; batch adversarial loss: 0.602195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394472; batch adversarial loss: 0.511232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.339268; batch adversarial loss: 0.579144\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321918; batch adversarial loss: 0.540436\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453509; batch adversarial loss: 0.538225\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563976; batch adversarial loss: 0.485119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.577334; batch adversarial loss: 0.537377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.561764; batch adversarial loss: 0.511627\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300344; batch adversarial loss: 0.527396\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274239; batch adversarial loss: 0.426263\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276796; batch adversarial loss: 0.506535\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238189; batch adversarial loss: 0.480801\n",
      "epoch 21; iter: 0; batch classifier loss: 0.185950; batch adversarial loss: 0.487712\n",
      "epoch 22; iter: 0; batch classifier loss: 0.180475; batch adversarial loss: 0.416449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211664; batch adversarial loss: 0.432004\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218427; batch adversarial loss: 0.364156\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200266; batch adversarial loss: 0.480348\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158407; batch adversarial loss: 0.515072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169492; batch adversarial loss: 0.577418\n",
      "epoch 28; iter: 0; batch classifier loss: 0.222217; batch adversarial loss: 0.434875\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162372; batch adversarial loss: 0.493381\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170211; batch adversarial loss: 0.428239\n",
      "epoch 31; iter: 0; batch classifier loss: 0.175951; batch adversarial loss: 0.524946\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148298; batch adversarial loss: 0.425681\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187975; batch adversarial loss: 0.395527\n",
      "epoch 34; iter: 0; batch classifier loss: 0.205055; batch adversarial loss: 0.405069\n",
      "epoch 35; iter: 0; batch classifier loss: 0.182237; batch adversarial loss: 0.437052\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175508; batch adversarial loss: 0.414015\n",
      "epoch 37; iter: 0; batch classifier loss: 0.223664; batch adversarial loss: 0.441402\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219428; batch adversarial loss: 0.488547\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138112; batch adversarial loss: 0.412226\n",
      "epoch 40; iter: 0; batch classifier loss: 0.182870; batch adversarial loss: 0.478853\n",
      "epoch 41; iter: 0; batch classifier loss: 0.180489; batch adversarial loss: 0.514832\n",
      "epoch 42; iter: 0; batch classifier loss: 0.226798; batch adversarial loss: 0.501353\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219353; batch adversarial loss: 0.414449\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194427; batch adversarial loss: 0.470762\n",
      "epoch 45; iter: 0; batch classifier loss: 0.169130; batch adversarial loss: 0.499025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.239980; batch adversarial loss: 0.409802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.217880; batch adversarial loss: 0.460079\n",
      "epoch 48; iter: 0; batch classifier loss: 0.160918; batch adversarial loss: 0.505489\n",
      "epoch 49; iter: 0; batch classifier loss: 0.167444; batch adversarial loss: 0.482982\n",
      "epoch 50; iter: 0; batch classifier loss: 0.193638; batch adversarial loss: 0.436610\n",
      "epoch 51; iter: 0; batch classifier loss: 0.213145; batch adversarial loss: 0.471810\n",
      "epoch 52; iter: 0; batch classifier loss: 0.252441; batch adversarial loss: 0.372066\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165823; batch adversarial loss: 0.481281\n",
      "epoch 54; iter: 0; batch classifier loss: 0.199825; batch adversarial loss: 0.421978\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158647; batch adversarial loss: 0.508046\n",
      "epoch 56; iter: 0; batch classifier loss: 0.283025; batch adversarial loss: 0.509058\n",
      "epoch 57; iter: 0; batch classifier loss: 0.234180; batch adversarial loss: 0.409855\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238779; batch adversarial loss: 0.507813\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174788; batch adversarial loss: 0.507919\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164790; batch adversarial loss: 0.581674\n",
      "epoch 61; iter: 0; batch classifier loss: 0.132897; batch adversarial loss: 0.409191\n",
      "epoch 62; iter: 0; batch classifier loss: 0.170639; batch adversarial loss: 0.446295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.212040; batch adversarial loss: 0.496606\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125603; batch adversarial loss: 0.521543\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204636; batch adversarial loss: 0.409311\n",
      "epoch 66; iter: 0; batch classifier loss: 0.185353; batch adversarial loss: 0.434250\n",
      "epoch 67; iter: 0; batch classifier loss: 0.120759; batch adversarial loss: 0.409034\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080657; batch adversarial loss: 0.395124\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099467; batch adversarial loss: 0.394791\n",
      "epoch 70; iter: 0; batch classifier loss: 0.124519; batch adversarial loss: 0.494202\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099647; batch adversarial loss: 0.364230\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079110; batch adversarial loss: 0.405838\n",
      "epoch 73; iter: 0; batch classifier loss: 0.194815; batch adversarial loss: 0.479782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.211426; batch adversarial loss: 0.423025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.173049; batch adversarial loss: 0.579842\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163193; batch adversarial loss: 0.557898\n",
      "epoch 77; iter: 0; batch classifier loss: 0.164480; batch adversarial loss: 0.421718\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158444; batch adversarial loss: 0.422319\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206600; batch adversarial loss: 0.409016\n",
      "epoch 80; iter: 0; batch classifier loss: 0.204018; batch adversarial loss: 0.470279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.168891; batch adversarial loss: 0.434476\n",
      "epoch 82; iter: 0; batch classifier loss: 0.154081; batch adversarial loss: 0.449615\n",
      "epoch 83; iter: 0; batch classifier loss: 0.138672; batch adversarial loss: 0.408994\n",
      "epoch 84; iter: 0; batch classifier loss: 0.266619; batch adversarial loss: 0.359803\n",
      "epoch 85; iter: 0; batch classifier loss: 0.183938; batch adversarial loss: 0.421639\n",
      "epoch 86; iter: 0; batch classifier loss: 0.228460; batch adversarial loss: 0.421697\n",
      "epoch 87; iter: 0; batch classifier loss: 0.108601; batch adversarial loss: 0.484971\n",
      "epoch 88; iter: 0; batch classifier loss: 0.227660; batch adversarial loss: 0.447440\n",
      "epoch 89; iter: 0; batch classifier loss: 0.262008; batch adversarial loss: 0.433549\n",
      "epoch 90; iter: 0; batch classifier loss: 0.260983; batch adversarial loss: 0.471088\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075214; batch adversarial loss: 0.483367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077390; batch adversarial loss: 0.396301\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058254; batch adversarial loss: 0.556736\n",
      "epoch 94; iter: 0; batch classifier loss: 0.087549; batch adversarial loss: 0.500392\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073576; batch adversarial loss: 0.372349\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039774; batch adversarial loss: 0.298293\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038409; batch adversarial loss: 0.429526\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065747; batch adversarial loss: 0.450190\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053174; batch adversarial loss: 0.462704\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055703; batch adversarial loss: 0.474135\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083167; batch adversarial loss: 0.423631\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037149; batch adversarial loss: 0.477639\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082396; batch adversarial loss: 0.412950\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051858; batch adversarial loss: 0.445408\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.424418\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050772; batch adversarial loss: 0.468684\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064042; batch adversarial loss: 0.410177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055693; batch adversarial loss: 0.408324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.027498; batch adversarial loss: 0.351649\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060447; batch adversarial loss: 0.440596\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060048; batch adversarial loss: 0.443062\n",
      "epoch 112; iter: 0; batch classifier loss: 0.107723; batch adversarial loss: 0.484086\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047814; batch adversarial loss: 0.427930\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078047; batch adversarial loss: 0.447469\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058170; batch adversarial loss: 0.434747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062907; batch adversarial loss: 0.468533\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030266; batch adversarial loss: 0.455106\n",
      "epoch 118; iter: 0; batch classifier loss: 0.116750; batch adversarial loss: 0.381607\n",
      "epoch 119; iter: 0; batch classifier loss: 0.106487; batch adversarial loss: 0.471651\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053994; batch adversarial loss: 0.455196\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.473433\n",
      "epoch 122; iter: 0; batch classifier loss: 0.095158; batch adversarial loss: 0.475197\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066461; batch adversarial loss: 0.475959\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048146; batch adversarial loss: 0.308325\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043931; batch adversarial loss: 0.489779\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051859; batch adversarial loss: 0.469796\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063078; batch adversarial loss: 0.512189\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087348; batch adversarial loss: 0.478200\n",
      "epoch 129; iter: 0; batch classifier loss: 0.086906; batch adversarial loss: 0.389487\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055593; batch adversarial loss: 0.472033\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036842; batch adversarial loss: 0.431908\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073871; batch adversarial loss: 0.521304\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040717; batch adversarial loss: 0.416821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059201; batch adversarial loss: 0.442316\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037425; batch adversarial loss: 0.419913\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061041; batch adversarial loss: 0.474570\n",
      "epoch 137; iter: 0; batch classifier loss: 0.073376; batch adversarial loss: 0.464122\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060595; batch adversarial loss: 0.399891\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054819; batch adversarial loss: 0.378963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.348279\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051461; batch adversarial loss: 0.447340\n",
      "epoch 142; iter: 0; batch classifier loss: 0.089174; batch adversarial loss: 0.419915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.066298; batch adversarial loss: 0.409574\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045615; batch adversarial loss: 0.356508\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067017; batch adversarial loss: 0.427333\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060198; batch adversarial loss: 0.500656\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039778; batch adversarial loss: 0.382348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046414; batch adversarial loss: 0.457066\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044602; batch adversarial loss: 0.429184\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036616; batch adversarial loss: 0.469082\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053435; batch adversarial loss: 0.398907\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070707; batch adversarial loss: 0.425424\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046797; batch adversarial loss: 0.398957\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046924; batch adversarial loss: 0.452424\n",
      "epoch 155; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.370586\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044426; batch adversarial loss: 0.486772\n",
      "epoch 157; iter: 0; batch classifier loss: 0.066277; batch adversarial loss: 0.480192\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053968; batch adversarial loss: 0.442986\n",
      "epoch 159; iter: 0; batch classifier loss: 0.058875; batch adversarial loss: 0.463454\n",
      "epoch 160; iter: 0; batch classifier loss: 0.062645; batch adversarial loss: 0.382255\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037026; batch adversarial loss: 0.433646\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051705; batch adversarial loss: 0.494270\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061191; batch adversarial loss: 0.437976\n",
      "epoch 164; iter: 0; batch classifier loss: 0.074085; batch adversarial loss: 0.481708\n",
      "epoch 165; iter: 0; batch classifier loss: 0.061268; batch adversarial loss: 0.447795\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050768; batch adversarial loss: 0.463687\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049728; batch adversarial loss: 0.346842\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059301; batch adversarial loss: 0.374031\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.454393\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038718; batch adversarial loss: 0.412058\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035659; batch adversarial loss: 0.319766\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042730; batch adversarial loss: 0.423658\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046363; batch adversarial loss: 0.401672\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047722; batch adversarial loss: 0.447457\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047328; batch adversarial loss: 0.459646\n",
      "epoch 176; iter: 0; batch classifier loss: 0.078285; batch adversarial loss: 0.394849\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046172; batch adversarial loss: 0.393342\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045371; batch adversarial loss: 0.359519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040401; batch adversarial loss: 0.396155\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054490; batch adversarial loss: 0.403635\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037581; batch adversarial loss: 0.441358\n",
      "epoch 182; iter: 0; batch classifier loss: 0.047708; batch adversarial loss: 0.430206\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046220; batch adversarial loss: 0.364906\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058675; batch adversarial loss: 0.346510\n",
      "epoch 185; iter: 0; batch classifier loss: 0.057128; batch adversarial loss: 0.342959\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047552; batch adversarial loss: 0.448209\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044199; batch adversarial loss: 0.482900\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044283; batch adversarial loss: 0.382076\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030070; batch adversarial loss: 0.407802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036060; batch adversarial loss: 0.386578\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031727; batch adversarial loss: 0.365832\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044130; batch adversarial loss: 0.378847\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046435; batch adversarial loss: 0.481641\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046756; batch adversarial loss: 0.429876\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047745; batch adversarial loss: 0.451536\n",
      "epoch 196; iter: 0; batch classifier loss: 0.053750; batch adversarial loss: 0.364818\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.373804\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044925; batch adversarial loss: 0.399015\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037578; batch adversarial loss: 0.439574\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750335; batch adversarial loss: 0.643109\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441184; batch adversarial loss: 0.652994\n",
      "epoch 2; iter: 0; batch classifier loss: 0.496083; batch adversarial loss: 0.592486\n",
      "epoch 3; iter: 0; batch classifier loss: 0.323638; batch adversarial loss: 0.618516\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310145; batch adversarial loss: 0.569453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.335307; batch adversarial loss: 0.531298\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319449; batch adversarial loss: 0.592918\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302938; batch adversarial loss: 0.563765\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275088; batch adversarial loss: 0.560450\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291683; batch adversarial loss: 0.591465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321131; batch adversarial loss: 0.489107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.249098; batch adversarial loss: 0.512393\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305477; batch adversarial loss: 0.521140\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302132; batch adversarial loss: 0.489948\n",
      "epoch 14; iter: 0; batch classifier loss: 0.205291; batch adversarial loss: 0.499383\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370262; batch adversarial loss: 0.478395\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279530; batch adversarial loss: 0.504512\n",
      "epoch 17; iter: 0; batch classifier loss: 0.193842; batch adversarial loss: 0.546469\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241315; batch adversarial loss: 0.450524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174854; batch adversarial loss: 0.513847\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172439; batch adversarial loss: 0.521635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.156966; batch adversarial loss: 0.443636\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241242; batch adversarial loss: 0.530136\n",
      "epoch 23; iter: 0; batch classifier loss: 0.185468; batch adversarial loss: 0.488726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162976; batch adversarial loss: 0.384508\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223002; batch adversarial loss: 0.504268\n",
      "epoch 26; iter: 0; batch classifier loss: 0.169655; batch adversarial loss: 0.473586\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184278; batch adversarial loss: 0.453232\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183393; batch adversarial loss: 0.562965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163371; batch adversarial loss: 0.470654\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144137; batch adversarial loss: 0.498649\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179640; batch adversarial loss: 0.385536\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146035; batch adversarial loss: 0.428791\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154930; batch adversarial loss: 0.438366\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111032; batch adversarial loss: 0.518569\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109051; batch adversarial loss: 0.509376\n",
      "epoch 36; iter: 0; batch classifier loss: 0.088986; batch adversarial loss: 0.506886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.153559; batch adversarial loss: 0.469932\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157842; batch adversarial loss: 0.421334\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162691; batch adversarial loss: 0.407347\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115338; batch adversarial loss: 0.464615\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153679; batch adversarial loss: 0.485379\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088232; batch adversarial loss: 0.420801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136600; batch adversarial loss: 0.492812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119768; batch adversarial loss: 0.521030\n",
      "epoch 45; iter: 0; batch classifier loss: 0.129221; batch adversarial loss: 0.489710\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118485; batch adversarial loss: 0.472386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132229; batch adversarial loss: 0.437585\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098961; batch adversarial loss: 0.444592\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085743; batch adversarial loss: 0.516625\n",
      "epoch 50; iter: 0; batch classifier loss: 0.134635; batch adversarial loss: 0.456183\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115248; batch adversarial loss: 0.485795\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094256; batch adversarial loss: 0.405268\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139035; batch adversarial loss: 0.432918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.134266; batch adversarial loss: 0.390343\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087245; batch adversarial loss: 0.472615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065007; batch adversarial loss: 0.554785\n",
      "epoch 57; iter: 0; batch classifier loss: 0.058824; batch adversarial loss: 0.343242\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061378; batch adversarial loss: 0.485512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101868; batch adversarial loss: 0.383635\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090294; batch adversarial loss: 0.499243\n",
      "epoch 61; iter: 0; batch classifier loss: 0.152281; batch adversarial loss: 0.404985\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113588; batch adversarial loss: 0.497632\n",
      "epoch 63; iter: 0; batch classifier loss: 0.121214; batch adversarial loss: 0.519661\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068383; batch adversarial loss: 0.375765\n",
      "epoch 65; iter: 0; batch classifier loss: 0.141975; batch adversarial loss: 0.514377\n",
      "epoch 66; iter: 0; batch classifier loss: 0.123316; batch adversarial loss: 0.396398\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097406; batch adversarial loss: 0.406373\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123984; batch adversarial loss: 0.406400\n",
      "epoch 69; iter: 0; batch classifier loss: 0.053570; batch adversarial loss: 0.479307\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073294; batch adversarial loss: 0.352576\n",
      "epoch 71; iter: 0; batch classifier loss: 0.126821; batch adversarial loss: 0.447256\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100869; batch adversarial loss: 0.461887\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072259; batch adversarial loss: 0.453384\n",
      "epoch 74; iter: 0; batch classifier loss: 0.140113; batch adversarial loss: 0.504343\n",
      "epoch 75; iter: 0; batch classifier loss: 0.115631; batch adversarial loss: 0.443400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068165; batch adversarial loss: 0.446890\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063943; batch adversarial loss: 0.509738\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073668; batch adversarial loss: 0.529897\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089419; batch adversarial loss: 0.444724\n",
      "epoch 80; iter: 0; batch classifier loss: 0.093780; batch adversarial loss: 0.432793\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084770; batch adversarial loss: 0.404061\n",
      "epoch 82; iter: 0; batch classifier loss: 0.118628; batch adversarial loss: 0.522348\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.517548\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060053; batch adversarial loss: 0.384802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097513; batch adversarial loss: 0.478548\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049013; batch adversarial loss: 0.419446\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041222; batch adversarial loss: 0.462952\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057930; batch adversarial loss: 0.436304\n",
      "epoch 89; iter: 0; batch classifier loss: 0.090286; batch adversarial loss: 0.379341\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074025; batch adversarial loss: 0.402000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093051; batch adversarial loss: 0.427624\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045671; batch adversarial loss: 0.490900\n",
      "epoch 93; iter: 0; batch classifier loss: 0.042165; batch adversarial loss: 0.525257\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081933; batch adversarial loss: 0.446174\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062786; batch adversarial loss: 0.499464\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046565; batch adversarial loss: 0.503655\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043357; batch adversarial loss: 0.505280\n",
      "epoch 98; iter: 0; batch classifier loss: 0.073844; batch adversarial loss: 0.447678\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072751; batch adversarial loss: 0.482891\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089851; batch adversarial loss: 0.437559\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057116; batch adversarial loss: 0.462806\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.413898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.049021; batch adversarial loss: 0.478513\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033223; batch adversarial loss: 0.475841\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025111; batch adversarial loss: 0.498761\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052533; batch adversarial loss: 0.444603\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045664; batch adversarial loss: 0.462437\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037589; batch adversarial loss: 0.434245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036089; batch adversarial loss: 0.409977\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.444687\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045225; batch adversarial loss: 0.523987\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030569; batch adversarial loss: 0.482431\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039739; batch adversarial loss: 0.423005\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035615; batch adversarial loss: 0.470454\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042900; batch adversarial loss: 0.512003\n",
      "epoch 116; iter: 0; batch classifier loss: 0.010610; batch adversarial loss: 0.457391\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049764; batch adversarial loss: 0.470630\n",
      "epoch 118; iter: 0; batch classifier loss: 0.033713; batch adversarial loss: 0.534176\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041193; batch adversarial loss: 0.506335\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043433; batch adversarial loss: 0.519567\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049567; batch adversarial loss: 0.431338\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032111; batch adversarial loss: 0.440954\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044735; batch adversarial loss: 0.432526\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033647; batch adversarial loss: 0.431214\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036230; batch adversarial loss: 0.418438\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027940; batch adversarial loss: 0.493571\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031705; batch adversarial loss: 0.420135\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044530; batch adversarial loss: 0.451647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032041; batch adversarial loss: 0.372248\n",
      "epoch 130; iter: 0; batch classifier loss: 0.014020; batch adversarial loss: 0.424455\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030443; batch adversarial loss: 0.476127\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068416; batch adversarial loss: 0.395913\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024269; batch adversarial loss: 0.486540\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029563; batch adversarial loss: 0.411817\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021463; batch adversarial loss: 0.491688\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031287; batch adversarial loss: 0.421026\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025696; batch adversarial loss: 0.457800\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015477; batch adversarial loss: 0.472935\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040846; batch adversarial loss: 0.428120\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033716; batch adversarial loss: 0.489090\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033617; batch adversarial loss: 0.460423\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041161; batch adversarial loss: 0.488726\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014662; batch adversarial loss: 0.305353\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.508894\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009121; batch adversarial loss: 0.438514\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034864; batch adversarial loss: 0.480256\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.351597\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022412; batch adversarial loss: 0.452313\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027259; batch adversarial loss: 0.493596\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009656; batch adversarial loss: 0.481623\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008409; batch adversarial loss: 0.455654\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013673; batch adversarial loss: 0.421624\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013809; batch adversarial loss: 0.548096\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030234; batch adversarial loss: 0.363159\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015932; batch adversarial loss: 0.407615\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022266; batch adversarial loss: 0.481429\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014587; batch adversarial loss: 0.466884\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028287; batch adversarial loss: 0.502164\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012749; batch adversarial loss: 0.335578\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044313; batch adversarial loss: 0.339116\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022195; batch adversarial loss: 0.426536\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046250; batch adversarial loss: 0.477511\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042029; batch adversarial loss: 0.461964\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038475; batch adversarial loss: 0.424220\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012410; batch adversarial loss: 0.430023\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025149; batch adversarial loss: 0.505935\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018589; batch adversarial loss: 0.432218\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015566; batch adversarial loss: 0.441765\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007182; batch adversarial loss: 0.513230\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036411; batch adversarial loss: 0.528940\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023049; batch adversarial loss: 0.421886\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012618; batch adversarial loss: 0.464695\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011416; batch adversarial loss: 0.405414\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019434; batch adversarial loss: 0.384528\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017407; batch adversarial loss: 0.427501\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033041; batch adversarial loss: 0.460773\n",
      "epoch 177; iter: 0; batch classifier loss: 0.004641; batch adversarial loss: 0.394372\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024338; batch adversarial loss: 0.356588\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008040; batch adversarial loss: 0.380300\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.475551\n",
      "epoch 181; iter: 0; batch classifier loss: 0.063842; batch adversarial loss: 0.500745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022890; batch adversarial loss: 0.430167\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029217; batch adversarial loss: 0.460393\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005370; batch adversarial loss: 0.428974\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016507; batch adversarial loss: 0.458116\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013151; batch adversarial loss: 0.453491\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016538; batch adversarial loss: 0.521657\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010411; batch adversarial loss: 0.425488\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015882; batch adversarial loss: 0.367941\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027535; batch adversarial loss: 0.546073\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007460; batch adversarial loss: 0.446941\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046563; batch adversarial loss: 0.433785\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029567; batch adversarial loss: 0.439334\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012503; batch adversarial loss: 0.394846\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004760; batch adversarial loss: 0.414131\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016108; batch adversarial loss: 0.391890\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010541; batch adversarial loss: 0.514710\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012035; batch adversarial loss: 0.410016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.014480; batch adversarial loss: 0.375705\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710806; batch adversarial loss: 0.829401\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480139; batch adversarial loss: 0.850789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400767; batch adversarial loss: 0.785924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406466; batch adversarial loss: 0.766464\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352589; batch adversarial loss: 0.669981\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350307; batch adversarial loss: 0.654421\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315090; batch adversarial loss: 0.668351\n",
      "epoch 7; iter: 0; batch classifier loss: 0.374477; batch adversarial loss: 0.658194\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349386; batch adversarial loss: 0.577297\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343695; batch adversarial loss: 0.559759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.287136; batch adversarial loss: 0.536045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.282731; batch adversarial loss: 0.492137\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349428; batch adversarial loss: 0.430211\n",
      "epoch 13; iter: 0; batch classifier loss: 0.259662; batch adversarial loss: 0.463193\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210229; batch adversarial loss: 0.464231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.262842; batch adversarial loss: 0.418450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247568; batch adversarial loss: 0.444171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258978; batch adversarial loss: 0.410452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230063; batch adversarial loss: 0.412743\n",
      "epoch 19; iter: 0; batch classifier loss: 0.233717; batch adversarial loss: 0.439466\n",
      "epoch 20; iter: 0; batch classifier loss: 0.188297; batch adversarial loss: 0.427956\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218879; batch adversarial loss: 0.365130\n",
      "epoch 22; iter: 0; batch classifier loss: 0.164881; batch adversarial loss: 0.461169\n",
      "epoch 23; iter: 0; batch classifier loss: 0.183348; batch adversarial loss: 0.376011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.221586; batch adversarial loss: 0.392395\n",
      "epoch 25; iter: 0; batch classifier loss: 0.165779; batch adversarial loss: 0.344955\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160293; batch adversarial loss: 0.422059\n",
      "epoch 27; iter: 0; batch classifier loss: 0.180136; batch adversarial loss: 0.440214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172887; batch adversarial loss: 0.375497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165770; batch adversarial loss: 0.381882\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151760; batch adversarial loss: 0.422527\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173162; batch adversarial loss: 0.357228\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175605; batch adversarial loss: 0.417250\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151149; batch adversarial loss: 0.399226\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100798; batch adversarial loss: 0.491554\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184426; batch adversarial loss: 0.397450\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124050; batch adversarial loss: 0.394901\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139996; batch adversarial loss: 0.415906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099463; batch adversarial loss: 0.453259\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140689; batch adversarial loss: 0.400334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110124; batch adversarial loss: 0.324053\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113635; batch adversarial loss: 0.369528\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112253; batch adversarial loss: 0.398052\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098447; batch adversarial loss: 0.452876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106139; batch adversarial loss: 0.417114\n",
      "epoch 45; iter: 0; batch classifier loss: 0.114040; batch adversarial loss: 0.379930\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121246; batch adversarial loss: 0.336070\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085565; batch adversarial loss: 0.379941\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141142; batch adversarial loss: 0.424208\n",
      "epoch 49; iter: 0; batch classifier loss: 0.143494; batch adversarial loss: 0.430910\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107467; batch adversarial loss: 0.416228\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104821; batch adversarial loss: 0.364449\n",
      "epoch 52; iter: 0; batch classifier loss: 0.068650; batch adversarial loss: 0.419643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.387685\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090751; batch adversarial loss: 0.436749\n",
      "epoch 55; iter: 0; batch classifier loss: 0.132680; batch adversarial loss: 0.425982\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082553; batch adversarial loss: 0.292915\n",
      "epoch 57; iter: 0; batch classifier loss: 0.109633; batch adversarial loss: 0.477475\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077399; batch adversarial loss: 0.440744\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063563; batch adversarial loss: 0.377938\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066401; batch adversarial loss: 0.393867\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091162; batch adversarial loss: 0.471133\n",
      "epoch 62; iter: 0; batch classifier loss: 0.115950; batch adversarial loss: 0.482136\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074641; batch adversarial loss: 0.360125\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068335; batch adversarial loss: 0.390399\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078171; batch adversarial loss: 0.410223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.050740; batch adversarial loss: 0.371754\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064682; batch adversarial loss: 0.567433\n",
      "epoch 68; iter: 0; batch classifier loss: 0.115780; batch adversarial loss: 0.487625\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064039; batch adversarial loss: 0.368672\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081532; batch adversarial loss: 0.442855\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059281; batch adversarial loss: 0.306629\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058880; batch adversarial loss: 0.293913\n",
      "epoch 73; iter: 0; batch classifier loss: 0.093841; batch adversarial loss: 0.396628\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116540; batch adversarial loss: 0.405952\n",
      "epoch 75; iter: 0; batch classifier loss: 0.071718; batch adversarial loss: 0.349063\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066194; batch adversarial loss: 0.414544\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043425; batch adversarial loss: 0.475073\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052863; batch adversarial loss: 0.397572\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099798; batch adversarial loss: 0.353045\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046556; batch adversarial loss: 0.347781\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066718; batch adversarial loss: 0.315638\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076524; batch adversarial loss: 0.425691\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091120; batch adversarial loss: 0.423181\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060027; batch adversarial loss: 0.412711\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074278; batch adversarial loss: 0.435014\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063935; batch adversarial loss: 0.387324\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076594; batch adversarial loss: 0.469368\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054123; batch adversarial loss: 0.444157\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083624; batch adversarial loss: 0.525812\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044473; batch adversarial loss: 0.462026\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083280; batch adversarial loss: 0.430018\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077664; batch adversarial loss: 0.362342\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054080; batch adversarial loss: 0.426986\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051082; batch adversarial loss: 0.436828\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071571; batch adversarial loss: 0.397536\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039520; batch adversarial loss: 0.388576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.048208; batch adversarial loss: 0.418479\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042545; batch adversarial loss: 0.435662\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047645; batch adversarial loss: 0.428565\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041451; batch adversarial loss: 0.337526\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035849; batch adversarial loss: 0.509470\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044777; batch adversarial loss: 0.395376\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032954; batch adversarial loss: 0.365813\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049033; batch adversarial loss: 0.374858\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044021; batch adversarial loss: 0.520383\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041329; batch adversarial loss: 0.436650\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048671; batch adversarial loss: 0.392918\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030480; batch adversarial loss: 0.493773\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045243; batch adversarial loss: 0.391541\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043998; batch adversarial loss: 0.512022\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035561; batch adversarial loss: 0.430050\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017259; batch adversarial loss: 0.361779\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038561; batch adversarial loss: 0.422367\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036385; batch adversarial loss: 0.529670\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062793; batch adversarial loss: 0.439501\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043183; batch adversarial loss: 0.410372\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052448; batch adversarial loss: 0.364924\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044395; batch adversarial loss: 0.536037\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018912; batch adversarial loss: 0.441801\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033884; batch adversarial loss: 0.515855\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041934; batch adversarial loss: 0.416836\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035431; batch adversarial loss: 0.427385\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027657; batch adversarial loss: 0.330339\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032139; batch adversarial loss: 0.314438\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032416; batch adversarial loss: 0.397974\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015700; batch adversarial loss: 0.460308\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011768; batch adversarial loss: 0.563183\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032262; batch adversarial loss: 0.414369\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013690; batch adversarial loss: 0.383608\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040398; batch adversarial loss: 0.483404\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028839; batch adversarial loss: 0.525858\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015412; batch adversarial loss: 0.426385\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021415; batch adversarial loss: 0.433935\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032547; batch adversarial loss: 0.484679\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027677; batch adversarial loss: 0.397441\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023075; batch adversarial loss: 0.394594\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029018; batch adversarial loss: 0.341777\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035317; batch adversarial loss: 0.442753\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045391; batch adversarial loss: 0.519008\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063189; batch adversarial loss: 0.648626\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040825; batch adversarial loss: 0.457755\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055217; batch adversarial loss: 0.462737\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053349; batch adversarial loss: 0.388695\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036787; batch adversarial loss: 0.407996\n",
      "epoch 145; iter: 0; batch classifier loss: 0.126168; batch adversarial loss: 0.686231\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052980; batch adversarial loss: 0.454203\n",
      "epoch 147; iter: 0; batch classifier loss: 0.066636; batch adversarial loss: 0.417162\n",
      "epoch 148; iter: 0; batch classifier loss: 0.077704; batch adversarial loss: 0.558861\n",
      "epoch 149; iter: 0; batch classifier loss: 0.070660; batch adversarial loss: 0.528072\n",
      "epoch 150; iter: 0; batch classifier loss: 0.066844; batch adversarial loss: 0.514807\n",
      "epoch 151; iter: 0; batch classifier loss: 0.172162; batch adversarial loss: 0.798990\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058996; batch adversarial loss: 0.490071\n",
      "epoch 153; iter: 0; batch classifier loss: 0.081058; batch adversarial loss: 0.497596\n",
      "epoch 154; iter: 0; batch classifier loss: 0.091441; batch adversarial loss: 0.539424\n",
      "epoch 155; iter: 0; batch classifier loss: 0.158549; batch adversarial loss: 0.599613\n",
      "epoch 156; iter: 0; batch classifier loss: 0.137720; batch adversarial loss: 0.708941\n",
      "epoch 157; iter: 0; batch classifier loss: 0.187092; batch adversarial loss: 0.690948\n",
      "epoch 158; iter: 0; batch classifier loss: 0.100662; batch adversarial loss: 0.467451\n",
      "epoch 159; iter: 0; batch classifier loss: 0.124335; batch adversarial loss: 0.486593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.090531; batch adversarial loss: 0.570817\n",
      "epoch 161; iter: 0; batch classifier loss: 0.137214; batch adversarial loss: 0.532955\n",
      "epoch 162; iter: 0; batch classifier loss: 0.107054; batch adversarial loss: 0.510406\n",
      "epoch 163; iter: 0; batch classifier loss: 0.117196; batch adversarial loss: 0.624193\n",
      "epoch 164; iter: 0; batch classifier loss: 0.194354; batch adversarial loss: 0.704084\n",
      "epoch 165; iter: 0; batch classifier loss: 0.138844; batch adversarial loss: 0.619405\n",
      "epoch 166; iter: 0; batch classifier loss: 0.116481; batch adversarial loss: 0.490432\n",
      "epoch 167; iter: 0; batch classifier loss: 0.139674; batch adversarial loss: 0.641948\n",
      "epoch 168; iter: 0; batch classifier loss: 0.101683; batch adversarial loss: 0.441909\n",
      "epoch 169; iter: 0; batch classifier loss: 0.087499; batch adversarial loss: 0.527638\n",
      "epoch 170; iter: 0; batch classifier loss: 0.235886; batch adversarial loss: 0.672879\n",
      "epoch 171; iter: 0; batch classifier loss: 0.162671; batch adversarial loss: 0.532918\n",
      "epoch 172; iter: 0; batch classifier loss: 0.183467; batch adversarial loss: 0.691267\n",
      "epoch 173; iter: 0; batch classifier loss: 0.184359; batch adversarial loss: 0.593263\n",
      "epoch 174; iter: 0; batch classifier loss: 0.163192; batch adversarial loss: 0.618032\n",
      "epoch 175; iter: 0; batch classifier loss: 0.095446; batch adversarial loss: 0.454695\n",
      "epoch 176; iter: 0; batch classifier loss: 0.146113; batch adversarial loss: 0.546090\n",
      "epoch 177; iter: 0; batch classifier loss: 0.113144; batch adversarial loss: 0.405351\n",
      "epoch 178; iter: 0; batch classifier loss: 0.102831; batch adversarial loss: 0.442437\n",
      "epoch 179; iter: 0; batch classifier loss: 0.259968; batch adversarial loss: 0.709780\n",
      "epoch 180; iter: 0; batch classifier loss: 0.161950; batch adversarial loss: 0.681308\n",
      "epoch 181; iter: 0; batch classifier loss: 0.107670; batch adversarial loss: 0.462030\n",
      "epoch 182; iter: 0; batch classifier loss: 0.155448; batch adversarial loss: 0.501383\n",
      "epoch 183; iter: 0; batch classifier loss: 0.147826; batch adversarial loss: 0.487444\n",
      "epoch 184; iter: 0; batch classifier loss: 0.139647; batch adversarial loss: 0.443229\n",
      "epoch 185; iter: 0; batch classifier loss: 0.137466; batch adversarial loss: 0.526687\n",
      "epoch 186; iter: 0; batch classifier loss: 0.132353; batch adversarial loss: 0.493230\n",
      "epoch 187; iter: 0; batch classifier loss: 0.085853; batch adversarial loss: 0.483792\n",
      "epoch 188; iter: 0; batch classifier loss: 0.085138; batch adversarial loss: 0.433949\n",
      "epoch 189; iter: 0; batch classifier loss: 0.077663; batch adversarial loss: 0.395001\n",
      "epoch 190; iter: 0; batch classifier loss: 0.073666; batch adversarial loss: 0.387902\n",
      "epoch 191; iter: 0; batch classifier loss: 0.141232; batch adversarial loss: 0.470539\n",
      "epoch 192; iter: 0; batch classifier loss: 0.095774; batch adversarial loss: 0.433798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.077890; batch adversarial loss: 0.396696\n",
      "epoch 194; iter: 0; batch classifier loss: 0.135916; batch adversarial loss: 0.503262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.146012; batch adversarial loss: 0.454999\n",
      "epoch 196; iter: 0; batch classifier loss: 0.076375; batch adversarial loss: 0.486494\n",
      "epoch 197; iter: 0; batch classifier loss: 0.134247; batch adversarial loss: 0.475889\n",
      "epoch 198; iter: 0; batch classifier loss: 0.117893; batch adversarial loss: 0.495559\n",
      "epoch 199; iter: 0; batch classifier loss: 0.088356; batch adversarial loss: 0.407096\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689429; batch adversarial loss: 0.544970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417753; batch adversarial loss: 0.600684\n",
      "epoch 2; iter: 0; batch classifier loss: 0.341585; batch adversarial loss: 0.632667\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348736; batch adversarial loss: 0.628349\n",
      "epoch 4; iter: 0; batch classifier loss: 0.361098; batch adversarial loss: 0.570399\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324301; batch adversarial loss: 0.535199\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254261; batch adversarial loss: 0.558790\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411118; batch adversarial loss: 0.575082\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318215; batch adversarial loss: 0.561332\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305453; batch adversarial loss: 0.539378\n",
      "epoch 10; iter: 0; batch classifier loss: 0.318650; batch adversarial loss: 0.472326\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301039; batch adversarial loss: 0.494073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370953; batch adversarial loss: 0.587326\n",
      "epoch 13; iter: 0; batch classifier loss: 0.320385; batch adversarial loss: 0.498742\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340911; batch adversarial loss: 0.490642\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443810; batch adversarial loss: 0.512403\n",
      "epoch 16; iter: 0; batch classifier loss: 0.630046; batch adversarial loss: 0.532623\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374748; batch adversarial loss: 0.573392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245764; batch adversarial loss: 0.489126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240440; batch adversarial loss: 0.505865\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179498; batch adversarial loss: 0.513372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205163; batch adversarial loss: 0.473266\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271654; batch adversarial loss: 0.466583\n",
      "epoch 23; iter: 0; batch classifier loss: 0.112989; batch adversarial loss: 0.519589\n",
      "epoch 24; iter: 0; batch classifier loss: 0.219873; batch adversarial loss: 0.458904\n",
      "epoch 25; iter: 0; batch classifier loss: 0.220087; batch adversarial loss: 0.486475\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188608; batch adversarial loss: 0.511891\n",
      "epoch 27; iter: 0; batch classifier loss: 0.156453; batch adversarial loss: 0.398101\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139719; batch adversarial loss: 0.501159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.114750; batch adversarial loss: 0.539572\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163512; batch adversarial loss: 0.482557\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162447; batch adversarial loss: 0.587741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163418; batch adversarial loss: 0.396285\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138071; batch adversarial loss: 0.559262\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175472; batch adversarial loss: 0.463980\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120097; batch adversarial loss: 0.483328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126817; batch adversarial loss: 0.445457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.127193; batch adversarial loss: 0.501365\n",
      "epoch 38; iter: 0; batch classifier loss: 0.133028; batch adversarial loss: 0.404777\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122089; batch adversarial loss: 0.534193\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091169; batch adversarial loss: 0.438323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099458; batch adversarial loss: 0.456362\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113381; batch adversarial loss: 0.533236\n",
      "epoch 43; iter: 0; batch classifier loss: 0.150336; batch adversarial loss: 0.362315\n",
      "epoch 44; iter: 0; batch classifier loss: 0.189485; batch adversarial loss: 0.404728\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094320; batch adversarial loss: 0.444960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123577; batch adversarial loss: 0.375608\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123494; batch adversarial loss: 0.524541\n",
      "epoch 48; iter: 0; batch classifier loss: 0.122035; batch adversarial loss: 0.479743\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077884; batch adversarial loss: 0.529603\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113254; batch adversarial loss: 0.369643\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097157; batch adversarial loss: 0.396570\n",
      "epoch 52; iter: 0; batch classifier loss: 0.136997; batch adversarial loss: 0.435510\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096933; batch adversarial loss: 0.437892\n",
      "epoch 54; iter: 0; batch classifier loss: 0.126840; batch adversarial loss: 0.463813\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107535; batch adversarial loss: 0.439467\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136756; batch adversarial loss: 0.484474\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097866; batch adversarial loss: 0.367906\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132470; batch adversarial loss: 0.358822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170838; batch adversarial loss: 0.411482\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101853; batch adversarial loss: 0.525127\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120615; batch adversarial loss: 0.397965\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142782; batch adversarial loss: 0.487530\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175563; batch adversarial loss: 0.446782\n",
      "epoch 64; iter: 0; batch classifier loss: 0.077973; batch adversarial loss: 0.475754\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153986; batch adversarial loss: 0.361172\n",
      "epoch 66; iter: 0; batch classifier loss: 0.103245; batch adversarial loss: 0.563449\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121508; batch adversarial loss: 0.440965\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144052; batch adversarial loss: 0.497728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168229; batch adversarial loss: 0.441247\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094416; batch adversarial loss: 0.502765\n",
      "epoch 71; iter: 0; batch classifier loss: 0.173314; batch adversarial loss: 0.469187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.137192; batch adversarial loss: 0.530971\n",
      "epoch 73; iter: 0; batch classifier loss: 0.146243; batch adversarial loss: 0.386732\n",
      "epoch 74; iter: 0; batch classifier loss: 0.145969; batch adversarial loss: 0.449655\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142250; batch adversarial loss: 0.479339\n",
      "epoch 76; iter: 0; batch classifier loss: 0.142989; batch adversarial loss: 0.517435\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082341; batch adversarial loss: 0.367681\n",
      "epoch 78; iter: 0; batch classifier loss: 0.127664; batch adversarial loss: 0.477274\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138153; batch adversarial loss: 0.331128\n",
      "epoch 80; iter: 0; batch classifier loss: 0.110299; batch adversarial loss: 0.406071\n",
      "epoch 81; iter: 0; batch classifier loss: 0.160491; batch adversarial loss: 0.476005\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102825; batch adversarial loss: 0.414581\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105977; batch adversarial loss: 0.406544\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113570; batch adversarial loss: 0.504269\n",
      "epoch 85; iter: 0; batch classifier loss: 0.164062; batch adversarial loss: 0.525439\n",
      "epoch 86; iter: 0; batch classifier loss: 0.144300; batch adversarial loss: 0.402607\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100922; batch adversarial loss: 0.539121\n",
      "epoch 88; iter: 0; batch classifier loss: 0.147180; batch adversarial loss: 0.435302\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101094; batch adversarial loss: 0.487274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.123796; batch adversarial loss: 0.483315\n",
      "epoch 91; iter: 0; batch classifier loss: 0.147768; batch adversarial loss: 0.505445\n",
      "epoch 92; iter: 0; batch classifier loss: 0.175283; batch adversarial loss: 0.486458\n",
      "epoch 93; iter: 0; batch classifier loss: 0.150850; batch adversarial loss: 0.385281\n",
      "epoch 94; iter: 0; batch classifier loss: 0.107986; batch adversarial loss: 0.432390\n",
      "epoch 95; iter: 0; batch classifier loss: 0.147095; batch adversarial loss: 0.420385\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116595; batch adversarial loss: 0.365148\n",
      "epoch 97; iter: 0; batch classifier loss: 0.133282; batch adversarial loss: 0.498841\n",
      "epoch 98; iter: 0; batch classifier loss: 0.100171; batch adversarial loss: 0.393735\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110803; batch adversarial loss: 0.473230\n",
      "epoch 100; iter: 0; batch classifier loss: 0.122481; batch adversarial loss: 0.444801\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083815; batch adversarial loss: 0.413476\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086660; batch adversarial loss: 0.479235\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077857; batch adversarial loss: 0.394415\n",
      "epoch 104; iter: 0; batch classifier loss: 0.151909; batch adversarial loss: 0.436368\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101321; batch adversarial loss: 0.479508\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069120; batch adversarial loss: 0.482960\n",
      "epoch 107; iter: 0; batch classifier loss: 0.100664; batch adversarial loss: 0.403285\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075536; batch adversarial loss: 0.449888\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079014; batch adversarial loss: 0.372895\n",
      "epoch 110; iter: 0; batch classifier loss: 0.099908; batch adversarial loss: 0.596099\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048963; batch adversarial loss: 0.431878\n",
      "epoch 112; iter: 0; batch classifier loss: 0.091195; batch adversarial loss: 0.391666\n",
      "epoch 113; iter: 0; batch classifier loss: 0.072584; batch adversarial loss: 0.444105\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029330; batch adversarial loss: 0.551361\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040312; batch adversarial loss: 0.467969\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087519; batch adversarial loss: 0.537440\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065283; batch adversarial loss: 0.581259\n",
      "epoch 118; iter: 0; batch classifier loss: 0.072437; batch adversarial loss: 0.480194\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039275; batch adversarial loss: 0.484910\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050873; batch adversarial loss: 0.448007\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038875; batch adversarial loss: 0.440255\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033407; batch adversarial loss: 0.473409\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067754; batch adversarial loss: 0.477269\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043873; batch adversarial loss: 0.461514\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048799; batch adversarial loss: 0.461114\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053788; batch adversarial loss: 0.503490\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053459; batch adversarial loss: 0.454039\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.443419\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038399; batch adversarial loss: 0.389004\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052107; batch adversarial loss: 0.431269\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054759; batch adversarial loss: 0.453131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053767; batch adversarial loss: 0.497826\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035025; batch adversarial loss: 0.440964\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040732; batch adversarial loss: 0.482101\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041365; batch adversarial loss: 0.503821\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021530; batch adversarial loss: 0.346013\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052669; batch adversarial loss: 0.357421\n",
      "epoch 138; iter: 0; batch classifier loss: 0.069632; batch adversarial loss: 0.462872\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037190; batch adversarial loss: 0.537135\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042121; batch adversarial loss: 0.415056\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030216; batch adversarial loss: 0.463583\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026576; batch adversarial loss: 0.508148\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037670; batch adversarial loss: 0.489538\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031315; batch adversarial loss: 0.384310\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020940; batch adversarial loss: 0.519788\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024716; batch adversarial loss: 0.412733\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017326; batch adversarial loss: 0.400824\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017642; batch adversarial loss: 0.409493\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017516; batch adversarial loss: 0.424337\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042454; batch adversarial loss: 0.492771\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016334; batch adversarial loss: 0.503978\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035880; batch adversarial loss: 0.424907\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026922; batch adversarial loss: 0.476961\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025394; batch adversarial loss: 0.458290\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026329; batch adversarial loss: 0.343425\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012124; batch adversarial loss: 0.470183\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027158; batch adversarial loss: 0.464021\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048022; batch adversarial loss: 0.454530\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014684; batch adversarial loss: 0.420564\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025350; batch adversarial loss: 0.439378\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014051; batch adversarial loss: 0.357526\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022121; batch adversarial loss: 0.369030\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018800; batch adversarial loss: 0.517666\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.412164\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023657; batch adversarial loss: 0.523229\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048482; batch adversarial loss: 0.375241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026711; batch adversarial loss: 0.508053\n",
      "epoch 168; iter: 0; batch classifier loss: 0.039292; batch adversarial loss: 0.414286\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009089; batch adversarial loss: 0.475524\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043924; batch adversarial loss: 0.475183\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012244; batch adversarial loss: 0.405523\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052655; batch adversarial loss: 0.526194\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048362; batch adversarial loss: 0.480762\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030683; batch adversarial loss: 0.419284\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029925; batch adversarial loss: 0.432453\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.443423\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032901; batch adversarial loss: 0.514249\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009101; batch adversarial loss: 0.430604\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017620; batch adversarial loss: 0.429120\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027762; batch adversarial loss: 0.466406\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016214; batch adversarial loss: 0.442344\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008549; batch adversarial loss: 0.520955\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013145; batch adversarial loss: 0.385541\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016323; batch adversarial loss: 0.432808\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042934; batch adversarial loss: 0.566625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.017851; batch adversarial loss: 0.418187\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007319; batch adversarial loss: 0.482557\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021182; batch adversarial loss: 0.473382\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013199; batch adversarial loss: 0.361204\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020568; batch adversarial loss: 0.317642\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026728; batch adversarial loss: 0.429115\n",
      "epoch 192; iter: 0; batch classifier loss: 0.066296; batch adversarial loss: 0.484359\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.471018\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023203; batch adversarial loss: 0.313120\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014031; batch adversarial loss: 0.404939\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018002; batch adversarial loss: 0.462854\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027817; batch adversarial loss: 0.394727\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021574; batch adversarial loss: 0.515689\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021221; batch adversarial loss: 0.437115\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732631; batch adversarial loss: 0.764261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.587575; batch adversarial loss: 0.711014\n",
      "epoch 2; iter: 0; batch classifier loss: 0.432351; batch adversarial loss: 0.705565\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.658420\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398851; batch adversarial loss: 0.641776\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344084; batch adversarial loss: 0.585716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.279891; batch adversarial loss: 0.551549\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335058; batch adversarial loss: 0.545460\n",
      "epoch 8; iter: 0; batch classifier loss: 0.213287; batch adversarial loss: 0.522724\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251389; batch adversarial loss: 0.468935\n",
      "epoch 10; iter: 0; batch classifier loss: 0.237329; batch adversarial loss: 0.496431\n",
      "epoch 11; iter: 0; batch classifier loss: 0.246272; batch adversarial loss: 0.424840\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312491; batch adversarial loss: 0.473867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234415; batch adversarial loss: 0.475535\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200314; batch adversarial loss: 0.439388\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212409; batch adversarial loss: 0.391013\n",
      "epoch 16; iter: 0; batch classifier loss: 0.164091; batch adversarial loss: 0.439409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224783; batch adversarial loss: 0.416131\n",
      "epoch 18; iter: 0; batch classifier loss: 0.126254; batch adversarial loss: 0.400934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132003; batch adversarial loss: 0.464378\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254793; batch adversarial loss: 0.394132\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175485; batch adversarial loss: 0.410170\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189525; batch adversarial loss: 0.410431\n",
      "epoch 23; iter: 0; batch classifier loss: 0.114947; batch adversarial loss: 0.389507\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172126; batch adversarial loss: 0.374639\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130357; batch adversarial loss: 0.414472\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194998; batch adversarial loss: 0.395413\n",
      "epoch 27; iter: 0; batch classifier loss: 0.107697; batch adversarial loss: 0.476476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199253; batch adversarial loss: 0.415746\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154728; batch adversarial loss: 0.436482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137365; batch adversarial loss: 0.529039\n",
      "epoch 31; iter: 0; batch classifier loss: 0.103259; batch adversarial loss: 0.380199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.132956; batch adversarial loss: 0.405833\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144316; batch adversarial loss: 0.400769\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151898; batch adversarial loss: 0.393828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151785; batch adversarial loss: 0.415439\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108474; batch adversarial loss: 0.456038\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166312; batch adversarial loss: 0.398788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104990; batch adversarial loss: 0.284401\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146916; batch adversarial loss: 0.340880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136107; batch adversarial loss: 0.406289\n",
      "epoch 41; iter: 0; batch classifier loss: 0.131846; batch adversarial loss: 0.447768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106393; batch adversarial loss: 0.326273\n",
      "epoch 43; iter: 0; batch classifier loss: 0.075563; batch adversarial loss: 0.352955\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098891; batch adversarial loss: 0.402799\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102302; batch adversarial loss: 0.446243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101190; batch adversarial loss: 0.358314\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118242; batch adversarial loss: 0.464694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106992; batch adversarial loss: 0.313017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102159; batch adversarial loss: 0.396341\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092455; batch adversarial loss: 0.416382\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106894; batch adversarial loss: 0.365361\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113424; batch adversarial loss: 0.296839\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100241; batch adversarial loss: 0.470109\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130525; batch adversarial loss: 0.363373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096217; batch adversarial loss: 0.502197\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095641; batch adversarial loss: 0.337404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080349; batch adversarial loss: 0.399158\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079192; batch adversarial loss: 0.412141\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065120; batch adversarial loss: 0.441510\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090986; batch adversarial loss: 0.410335\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087203; batch adversarial loss: 0.454118\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090645; batch adversarial loss: 0.382322\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079782; batch adversarial loss: 0.450811\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084690; batch adversarial loss: 0.444880\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113363; batch adversarial loss: 0.420016\n",
      "epoch 66; iter: 0; batch classifier loss: 0.104526; batch adversarial loss: 0.444160\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083801; batch adversarial loss: 0.409762\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052542; batch adversarial loss: 0.335676\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099241; batch adversarial loss: 0.388931\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088773; batch adversarial loss: 0.402533\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054780; batch adversarial loss: 0.458672\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070192; batch adversarial loss: 0.549240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050342; batch adversarial loss: 0.395730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063965; batch adversarial loss: 0.491131\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059149; batch adversarial loss: 0.425467\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060595; batch adversarial loss: 0.403485\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056342; batch adversarial loss: 0.268542\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064875; batch adversarial loss: 0.399458\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052517; batch adversarial loss: 0.366524\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067455; batch adversarial loss: 0.353552\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049772; batch adversarial loss: 0.373178\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090233; batch adversarial loss: 0.504874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.052777; batch adversarial loss: 0.429319\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045620; batch adversarial loss: 0.372510\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065918; batch adversarial loss: 0.406435\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065846; batch adversarial loss: 0.365035\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053425; batch adversarial loss: 0.503760\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041238; batch adversarial loss: 0.331870\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048773; batch adversarial loss: 0.437724\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041521; batch adversarial loss: 0.483988\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059762; batch adversarial loss: 0.502543\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040702; batch adversarial loss: 0.358465\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036906; batch adversarial loss: 0.351109\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043921; batch adversarial loss: 0.510644\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044535; batch adversarial loss: 0.426849\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044682; batch adversarial loss: 0.379626\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027594; batch adversarial loss: 0.442717\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031258; batch adversarial loss: 0.523146\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024056; batch adversarial loss: 0.551538\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046881; batch adversarial loss: 0.410537\n",
      "epoch 101; iter: 0; batch classifier loss: 0.021447; batch adversarial loss: 0.494845\n",
      "epoch 102; iter: 0; batch classifier loss: 0.025773; batch adversarial loss: 0.470333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044482; batch adversarial loss: 0.474710\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043971; batch adversarial loss: 0.432396\n",
      "epoch 105; iter: 0; batch classifier loss: 0.016834; batch adversarial loss: 0.507352\n",
      "epoch 106; iter: 0; batch classifier loss: 0.026854; batch adversarial loss: 0.374029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.481242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048794; batch adversarial loss: 0.535662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065728; batch adversarial loss: 0.532306\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050471; batch adversarial loss: 0.538983\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037530; batch adversarial loss: 0.446710\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078360; batch adversarial loss: 0.473973\n",
      "epoch 113; iter: 0; batch classifier loss: 0.093323; batch adversarial loss: 0.635221\n",
      "epoch 114; iter: 0; batch classifier loss: 0.184021; batch adversarial loss: 0.748735\n",
      "epoch 115; iter: 0; batch classifier loss: 0.112941; batch adversarial loss: 0.639198\n",
      "epoch 116; iter: 0; batch classifier loss: 0.156161; batch adversarial loss: 0.617003\n",
      "epoch 117; iter: 0; batch classifier loss: 0.102089; batch adversarial loss: 0.617890\n",
      "epoch 118; iter: 0; batch classifier loss: 0.194645; batch adversarial loss: 0.719830\n",
      "epoch 119; iter: 0; batch classifier loss: 0.143562; batch adversarial loss: 0.569742\n",
      "epoch 120; iter: 0; batch classifier loss: 0.195197; batch adversarial loss: 0.770912\n",
      "epoch 121; iter: 0; batch classifier loss: 0.181153; batch adversarial loss: 0.641532\n",
      "epoch 122; iter: 0; batch classifier loss: 0.114456; batch adversarial loss: 0.539659\n",
      "epoch 123; iter: 0; batch classifier loss: 0.153602; batch adversarial loss: 0.527838\n",
      "epoch 124; iter: 0; batch classifier loss: 0.143716; batch adversarial loss: 0.607607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.143943; batch adversarial loss: 0.511207\n",
      "epoch 126; iter: 0; batch classifier loss: 0.102157; batch adversarial loss: 0.550121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.148115; batch adversarial loss: 0.547015\n",
      "epoch 128; iter: 0; batch classifier loss: 0.140670; batch adversarial loss: 0.474100\n",
      "epoch 129; iter: 0; batch classifier loss: 0.206985; batch adversarial loss: 0.614241\n",
      "epoch 130; iter: 0; batch classifier loss: 0.116816; batch adversarial loss: 0.558080\n",
      "epoch 131; iter: 0; batch classifier loss: 0.150864; batch adversarial loss: 0.631151\n",
      "epoch 132; iter: 0; batch classifier loss: 0.184620; batch adversarial loss: 0.596529\n",
      "epoch 133; iter: 0; batch classifier loss: 0.185882; batch adversarial loss: 0.602497\n",
      "epoch 134; iter: 0; batch classifier loss: 0.168774; batch adversarial loss: 0.572465\n",
      "epoch 135; iter: 0; batch classifier loss: 0.125661; batch adversarial loss: 0.505636\n",
      "epoch 136; iter: 0; batch classifier loss: 0.146933; batch adversarial loss: 0.510985\n",
      "epoch 137; iter: 0; batch classifier loss: 0.189770; batch adversarial loss: 0.557175\n",
      "epoch 138; iter: 0; batch classifier loss: 0.132370; batch adversarial loss: 0.549203\n",
      "epoch 139; iter: 0; batch classifier loss: 0.082920; batch adversarial loss: 0.432384\n",
      "epoch 140; iter: 0; batch classifier loss: 0.148511; batch adversarial loss: 0.510650\n",
      "epoch 141; iter: 0; batch classifier loss: 0.140397; batch adversarial loss: 0.525795\n",
      "epoch 142; iter: 0; batch classifier loss: 0.094596; batch adversarial loss: 0.408685\n",
      "epoch 143; iter: 0; batch classifier loss: 0.112401; batch adversarial loss: 0.498289\n",
      "epoch 144; iter: 0; batch classifier loss: 0.126790; batch adversarial loss: 0.501088\n",
      "epoch 145; iter: 0; batch classifier loss: 0.090578; batch adversarial loss: 0.427115\n",
      "epoch 146; iter: 0; batch classifier loss: 0.102615; batch adversarial loss: 0.371925\n",
      "epoch 147; iter: 0; batch classifier loss: 0.094268; batch adversarial loss: 0.531235\n",
      "epoch 148; iter: 0; batch classifier loss: 0.091998; batch adversarial loss: 0.477824\n",
      "epoch 149; iter: 0; batch classifier loss: 0.072241; batch adversarial loss: 0.402411\n",
      "epoch 150; iter: 0; batch classifier loss: 0.114492; batch adversarial loss: 0.525003\n",
      "epoch 151; iter: 0; batch classifier loss: 0.135948; batch adversarial loss: 0.544285\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056937; batch adversarial loss: 0.396247\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034685; batch adversarial loss: 0.519346\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032371; batch adversarial loss: 0.535945\n",
      "epoch 155; iter: 0; batch classifier loss: 0.069506; batch adversarial loss: 0.452405\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.385197\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049049; batch adversarial loss: 0.447977\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076983; batch adversarial loss: 0.424775\n",
      "epoch 159; iter: 0; batch classifier loss: 0.052599; batch adversarial loss: 0.456596\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052626; batch adversarial loss: 0.496862\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018680; batch adversarial loss: 0.499176\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030442; batch adversarial loss: 0.413430\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023566; batch adversarial loss: 0.456585\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056377; batch adversarial loss: 0.422022\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029851; batch adversarial loss: 0.473141\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017520; batch adversarial loss: 0.556216\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034868; batch adversarial loss: 0.500455\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.460289\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025761; batch adversarial loss: 0.504946\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045367; batch adversarial loss: 0.412737\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052311; batch adversarial loss: 0.467954\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057631; batch adversarial loss: 0.506914\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037294; batch adversarial loss: 0.394109\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066272; batch adversarial loss: 0.373127\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047766; batch adversarial loss: 0.469083\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.417775\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037853; batch adversarial loss: 0.439479\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037699; batch adversarial loss: 0.497206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.065091; batch adversarial loss: 0.436396\n",
      "epoch 180; iter: 0; batch classifier loss: 0.057111; batch adversarial loss: 0.451546\n",
      "epoch 181; iter: 0; batch classifier loss: 0.126887; batch adversarial loss: 0.496321\n",
      "epoch 182; iter: 0; batch classifier loss: 0.097325; batch adversarial loss: 0.393672\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032789; batch adversarial loss: 0.556337\n",
      "epoch 184; iter: 0; batch classifier loss: 0.066754; batch adversarial loss: 0.435351\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045591; batch adversarial loss: 0.542086\n",
      "epoch 186; iter: 0; batch classifier loss: 0.075949; batch adversarial loss: 0.401425\n",
      "epoch 187; iter: 0; batch classifier loss: 0.085439; batch adversarial loss: 0.510860\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029257; batch adversarial loss: 0.394041\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037455; batch adversarial loss: 0.530382\n",
      "epoch 190; iter: 0; batch classifier loss: 0.088396; batch adversarial loss: 0.513522\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048424; batch adversarial loss: 0.396828\n",
      "epoch 192; iter: 0; batch classifier loss: 0.058371; batch adversarial loss: 0.474697\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.404104\n",
      "epoch 194; iter: 0; batch classifier loss: 0.084921; batch adversarial loss: 0.374571\n",
      "epoch 195; iter: 0; batch classifier loss: 0.052021; batch adversarial loss: 0.605149\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050952; batch adversarial loss: 0.410137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.053319; batch adversarial loss: 0.427212\n",
      "epoch 198; iter: 0; batch classifier loss: 0.070345; batch adversarial loss: 0.461930\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042163; batch adversarial loss: 0.559715\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733407; batch adversarial loss: 0.925228\n",
      "epoch 1; iter: 0; batch classifier loss: 0.588600; batch adversarial loss: 0.933172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.839340; batch adversarial loss: 0.974395\n",
      "epoch 3; iter: 0; batch classifier loss: 1.047910; batch adversarial loss: 0.947289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.850903; batch adversarial loss: 0.799808\n",
      "epoch 5; iter: 0; batch classifier loss: 0.914491; batch adversarial loss: 0.772004\n",
      "epoch 6; iter: 0; batch classifier loss: 0.716721; batch adversarial loss: 0.676447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632933; batch adversarial loss: 0.648836\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568787; batch adversarial loss: 0.593566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462372; batch adversarial loss: 0.519044\n",
      "epoch 10; iter: 0; batch classifier loss: 0.416355; batch adversarial loss: 0.484467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.263745; batch adversarial loss: 0.510595\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299639; batch adversarial loss: 0.484392\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225079; batch adversarial loss: 0.560017\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281867; batch adversarial loss: 0.480782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253157; batch adversarial loss: 0.471335\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261014; batch adversarial loss: 0.526365\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221716; batch adversarial loss: 0.479979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.207765; batch adversarial loss: 0.533022\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243644; batch adversarial loss: 0.494244\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230544; batch adversarial loss: 0.514931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283789; batch adversarial loss: 0.550762\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276797; batch adversarial loss: 0.426892\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224495; batch adversarial loss: 0.457201\n",
      "epoch 24; iter: 0; batch classifier loss: 0.186396; batch adversarial loss: 0.471352\n",
      "epoch 25; iter: 0; batch classifier loss: 0.251070; batch adversarial loss: 0.516141\n",
      "epoch 26; iter: 0; batch classifier loss: 0.195826; batch adversarial loss: 0.404152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.290311; batch adversarial loss: 0.513206\n",
      "epoch 28; iter: 0; batch classifier loss: 0.198075; batch adversarial loss: 0.456824\n",
      "epoch 29; iter: 0; batch classifier loss: 0.181126; batch adversarial loss: 0.480583\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195006; batch adversarial loss: 0.544305\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146614; batch adversarial loss: 0.455509\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185364; batch adversarial loss: 0.460505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.292600; batch adversarial loss: 0.423074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132476; batch adversarial loss: 0.433871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167412; batch adversarial loss: 0.486438\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140699; batch adversarial loss: 0.485482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163384; batch adversarial loss: 0.428915\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148914; batch adversarial loss: 0.530552\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149677; batch adversarial loss: 0.380260\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150345; batch adversarial loss: 0.493036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136166; batch adversarial loss: 0.492490\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114591; batch adversarial loss: 0.501876\n",
      "epoch 43; iter: 0; batch classifier loss: 0.127876; batch adversarial loss: 0.486656\n",
      "epoch 44; iter: 0; batch classifier loss: 0.150068; batch adversarial loss: 0.499970\n",
      "epoch 45; iter: 0; batch classifier loss: 0.143941; batch adversarial loss: 0.516186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189810; batch adversarial loss: 0.523454\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088431; batch adversarial loss: 0.546042\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102414; batch adversarial loss: 0.420736\n",
      "epoch 49; iter: 0; batch classifier loss: 0.188292; batch adversarial loss: 0.398648\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129044; batch adversarial loss: 0.519322\n",
      "epoch 51; iter: 0; batch classifier loss: 0.143958; batch adversarial loss: 0.411173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099990; batch adversarial loss: 0.457734\n",
      "epoch 53; iter: 0; batch classifier loss: 0.090361; batch adversarial loss: 0.396773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140996; batch adversarial loss: 0.448692\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103849; batch adversarial loss: 0.499490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085102; batch adversarial loss: 0.416394\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086792; batch adversarial loss: 0.570900\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071528; batch adversarial loss: 0.556058\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106226; batch adversarial loss: 0.375512\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102969; batch adversarial loss: 0.512652\n",
      "epoch 61; iter: 0; batch classifier loss: 0.110402; batch adversarial loss: 0.380502\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077371; batch adversarial loss: 0.557148\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059784; batch adversarial loss: 0.498627\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057015; batch adversarial loss: 0.529395\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063267; batch adversarial loss: 0.507514\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075497; batch adversarial loss: 0.406193\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078806; batch adversarial loss: 0.494759\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094269; batch adversarial loss: 0.448687\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115409; batch adversarial loss: 0.441793\n",
      "epoch 70; iter: 0; batch classifier loss: 0.059144; batch adversarial loss: 0.430630\n",
      "epoch 71; iter: 0; batch classifier loss: 0.131178; batch adversarial loss: 0.502693\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055085; batch adversarial loss: 0.376781\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091596; batch adversarial loss: 0.422860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104457; batch adversarial loss: 0.519741\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059913; batch adversarial loss: 0.370793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.043198; batch adversarial loss: 0.494793\n",
      "epoch 77; iter: 0; batch classifier loss: 0.105400; batch adversarial loss: 0.465939\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097262; batch adversarial loss: 0.449868\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108797; batch adversarial loss: 0.406354\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091237; batch adversarial loss: 0.395152\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103710; batch adversarial loss: 0.492883\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063331; batch adversarial loss: 0.435727\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080505; batch adversarial loss: 0.491215\n",
      "epoch 84; iter: 0; batch classifier loss: 0.041873; batch adversarial loss: 0.458071\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055223; batch adversarial loss: 0.425812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062390; batch adversarial loss: 0.506567\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067003; batch adversarial loss: 0.577771\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056768; batch adversarial loss: 0.393323\n",
      "epoch 89; iter: 0; batch classifier loss: 0.039472; batch adversarial loss: 0.521745\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064249; batch adversarial loss: 0.444553\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048691; batch adversarial loss: 0.531356\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097156; batch adversarial loss: 0.459180\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074299; batch adversarial loss: 0.402921\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036672; batch adversarial loss: 0.457544\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073946; batch adversarial loss: 0.516936\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080959; batch adversarial loss: 0.558855\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068891; batch adversarial loss: 0.434857\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047901; batch adversarial loss: 0.449521\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074672; batch adversarial loss: 0.434385\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060212; batch adversarial loss: 0.493291\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055597; batch adversarial loss: 0.418467\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053045; batch adversarial loss: 0.475823\n",
      "epoch 103; iter: 0; batch classifier loss: 0.009666; batch adversarial loss: 0.464779\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.408684\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066923; batch adversarial loss: 0.460077\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054835; batch adversarial loss: 0.441512\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021059; batch adversarial loss: 0.378054\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055090; batch adversarial loss: 0.420382\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027205; batch adversarial loss: 0.531173\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039065; batch adversarial loss: 0.528129\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030707; batch adversarial loss: 0.387543\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052122; batch adversarial loss: 0.402009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028881; batch adversarial loss: 0.455721\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056368; batch adversarial loss: 0.464789\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021027; batch adversarial loss: 0.462619\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022544; batch adversarial loss: 0.546975\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067502; batch adversarial loss: 0.490899\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023512; batch adversarial loss: 0.379087\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026471; batch adversarial loss: 0.498732\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045082; batch adversarial loss: 0.510898\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035794; batch adversarial loss: 0.458663\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049611; batch adversarial loss: 0.424969\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045850; batch adversarial loss: 0.392084\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053717; batch adversarial loss: 0.423311\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022703; batch adversarial loss: 0.550202\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026501; batch adversarial loss: 0.485647\n",
      "epoch 127; iter: 0; batch classifier loss: 0.010404; batch adversarial loss: 0.431356\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021909; batch adversarial loss: 0.482681\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057699; batch adversarial loss: 0.432151\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046250; batch adversarial loss: 0.537524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017263; batch adversarial loss: 0.451914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018431; batch adversarial loss: 0.440858\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011925; batch adversarial loss: 0.425821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012074; batch adversarial loss: 0.438899\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015280; batch adversarial loss: 0.487156\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032389; batch adversarial loss: 0.332676\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037317; batch adversarial loss: 0.460218\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027784; batch adversarial loss: 0.465572\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031290; batch adversarial loss: 0.463648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012126; batch adversarial loss: 0.450091\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025073; batch adversarial loss: 0.547500\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011073; batch adversarial loss: 0.463364\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013504; batch adversarial loss: 0.436662\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026542; batch adversarial loss: 0.415588\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037917; batch adversarial loss: 0.359495\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041934; batch adversarial loss: 0.457794\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024156; batch adversarial loss: 0.438790\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023771; batch adversarial loss: 0.451776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029422; batch adversarial loss: 0.441934\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005057; batch adversarial loss: 0.443309\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037003; batch adversarial loss: 0.506170\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028253; batch adversarial loss: 0.469801\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032497; batch adversarial loss: 0.426150\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016184; batch adversarial loss: 0.491956\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040626; batch adversarial loss: 0.421753\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025903; batch adversarial loss: 0.414126\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015647; batch adversarial loss: 0.455690\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009910; batch adversarial loss: 0.475165\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021008; batch adversarial loss: 0.550064\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021764; batch adversarial loss: 0.452997\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010466; batch adversarial loss: 0.420809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040494; batch adversarial loss: 0.394414\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033340; batch adversarial loss: 0.461635\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015859; batch adversarial loss: 0.465253\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022889; batch adversarial loss: 0.342528\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009182; batch adversarial loss: 0.439864\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011355; batch adversarial loss: 0.493146\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026284; batch adversarial loss: 0.517149\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044348; batch adversarial loss: 0.419291\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017318; batch adversarial loss: 0.427571\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013866; batch adversarial loss: 0.490949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.008598; batch adversarial loss: 0.470352\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013520; batch adversarial loss: 0.406107\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023418; batch adversarial loss: 0.448793\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010883; batch adversarial loss: 0.509430\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013527; batch adversarial loss: 0.435773\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038228; batch adversarial loss: 0.477796\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013156; batch adversarial loss: 0.439137\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008199; batch adversarial loss: 0.494766\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020765; batch adversarial loss: 0.419914\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006427; batch adversarial loss: 0.416125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015027; batch adversarial loss: 0.501862\n",
      "epoch 183; iter: 0; batch classifier loss: 0.002868; batch adversarial loss: 0.422315\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.460613\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019523; batch adversarial loss: 0.422084\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021045; batch adversarial loss: 0.432212\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005763; batch adversarial loss: 0.555216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014545; batch adversarial loss: 0.456084\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025553; batch adversarial loss: 0.500540\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004933; batch adversarial loss: 0.455492\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012137; batch adversarial loss: 0.405116\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022993; batch adversarial loss: 0.408287\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036682; batch adversarial loss: 0.430568\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018554; batch adversarial loss: 0.376278\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032698; batch adversarial loss: 0.419168\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004211; batch adversarial loss: 0.507546\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016738; batch adversarial loss: 0.411773\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007760; batch adversarial loss: 0.555135\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015531; batch adversarial loss: 0.441335\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703851; batch adversarial loss: 0.599654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.439171; batch adversarial loss: 0.616798\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443994; batch adversarial loss: 0.568031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.443701; batch adversarial loss: 0.581960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.263100; batch adversarial loss: 0.575699\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298895; batch adversarial loss: 0.530365\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312039; batch adversarial loss: 0.524701\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272976; batch adversarial loss: 0.545143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316128; batch adversarial loss: 0.512777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.290311; batch adversarial loss: 0.448818\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281651; batch adversarial loss: 0.478834\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243146; batch adversarial loss: 0.499790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256731; batch adversarial loss: 0.558679\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338476; batch adversarial loss: 0.561381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311132; batch adversarial loss: 0.601012\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236862; batch adversarial loss: 0.516994\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384558; batch adversarial loss: 0.559312\n",
      "epoch 17; iter: 0; batch classifier loss: 0.318054; batch adversarial loss: 0.449123\n",
      "epoch 18; iter: 0; batch classifier loss: 0.321718; batch adversarial loss: 0.540429\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472474; batch adversarial loss: 0.438113\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518726; batch adversarial loss: 0.509240\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387961; batch adversarial loss: 0.486019\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249265; batch adversarial loss: 0.451091\n",
      "epoch 23; iter: 0; batch classifier loss: 0.235224; batch adversarial loss: 0.449254\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182111; batch adversarial loss: 0.442691\n",
      "epoch 25; iter: 0; batch classifier loss: 0.140494; batch adversarial loss: 0.441709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146658; batch adversarial loss: 0.409220\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148667; batch adversarial loss: 0.451425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127130; batch adversarial loss: 0.484310\n",
      "epoch 29; iter: 0; batch classifier loss: 0.127714; batch adversarial loss: 0.450422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153184; batch adversarial loss: 0.516150\n",
      "epoch 31; iter: 0; batch classifier loss: 0.095751; batch adversarial loss: 0.554124\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177026; batch adversarial loss: 0.413137\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162127; batch adversarial loss: 0.488281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131090; batch adversarial loss: 0.430378\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137012; batch adversarial loss: 0.390366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162746; batch adversarial loss: 0.489635\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136988; batch adversarial loss: 0.484024\n",
      "epoch 38; iter: 0; batch classifier loss: 0.073758; batch adversarial loss: 0.469291\n",
      "epoch 39; iter: 0; batch classifier loss: 0.083864; batch adversarial loss: 0.461594\n",
      "epoch 40; iter: 0; batch classifier loss: 0.097192; batch adversarial loss: 0.488052\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091549; batch adversarial loss: 0.467232\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102419; batch adversarial loss: 0.390115\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146564; batch adversarial loss: 0.504969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105302; batch adversarial loss: 0.559627\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111580; batch adversarial loss: 0.478642\n",
      "epoch 46; iter: 0; batch classifier loss: 0.058190; batch adversarial loss: 0.468139\n",
      "epoch 47; iter: 0; batch classifier loss: 0.151172; batch adversarial loss: 0.428990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103355; batch adversarial loss: 0.393772\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125290; batch adversarial loss: 0.397786\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128677; batch adversarial loss: 0.410303\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099447; batch adversarial loss: 0.345856\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119911; batch adversarial loss: 0.448814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.111717; batch adversarial loss: 0.412745\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096359; batch adversarial loss: 0.514091\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123951; batch adversarial loss: 0.492182\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122016; batch adversarial loss: 0.479287\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126017; batch adversarial loss: 0.425597\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152257; batch adversarial loss: 0.465974\n",
      "epoch 59; iter: 0; batch classifier loss: 0.139501; batch adversarial loss: 0.342477\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137273; batch adversarial loss: 0.549273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101341; batch adversarial loss: 0.490764\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069389; batch adversarial loss: 0.437723\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120986; batch adversarial loss: 0.440251\n",
      "epoch 64; iter: 0; batch classifier loss: 0.135651; batch adversarial loss: 0.533105\n",
      "epoch 65; iter: 0; batch classifier loss: 0.135302; batch adversarial loss: 0.523103\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087973; batch adversarial loss: 0.463782\n",
      "epoch 67; iter: 0; batch classifier loss: 0.184343; batch adversarial loss: 0.344313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.169686; batch adversarial loss: 0.465406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.081302; batch adversarial loss: 0.471265\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082906; batch adversarial loss: 0.416187\n",
      "epoch 71; iter: 0; batch classifier loss: 0.127537; batch adversarial loss: 0.439366\n",
      "epoch 72; iter: 0; batch classifier loss: 0.117379; batch adversarial loss: 0.538275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.115517; batch adversarial loss: 0.453071\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112817; batch adversarial loss: 0.554208\n",
      "epoch 75; iter: 0; batch classifier loss: 0.111060; batch adversarial loss: 0.479762\n",
      "epoch 76; iter: 0; batch classifier loss: 0.130377; batch adversarial loss: 0.439847\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090628; batch adversarial loss: 0.413141\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129776; batch adversarial loss: 0.437108\n",
      "epoch 79; iter: 0; batch classifier loss: 0.105475; batch adversarial loss: 0.480072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095724; batch adversarial loss: 0.506062\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096612; batch adversarial loss: 0.437911\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113134; batch adversarial loss: 0.409707\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092872; batch adversarial loss: 0.472444\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103462; batch adversarial loss: 0.496222\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065375; batch adversarial loss: 0.413765\n",
      "epoch 86; iter: 0; batch classifier loss: 0.176936; batch adversarial loss: 0.389460\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093233; batch adversarial loss: 0.448613\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132813; batch adversarial loss: 0.439902\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056054; batch adversarial loss: 0.524391\n",
      "epoch 90; iter: 0; batch classifier loss: 0.125132; batch adversarial loss: 0.374778\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122501; batch adversarial loss: 0.489403\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105245; batch adversarial loss: 0.446953\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054070; batch adversarial loss: 0.588504\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086482; batch adversarial loss: 0.480028\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073377; batch adversarial loss: 0.593473\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058707; batch adversarial loss: 0.437239\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097628; batch adversarial loss: 0.470682\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052581; batch adversarial loss: 0.549354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078493; batch adversarial loss: 0.450820\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088803; batch adversarial loss: 0.362529\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085162; batch adversarial loss: 0.416230\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059037; batch adversarial loss: 0.409681\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049617; batch adversarial loss: 0.408100\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056812; batch adversarial loss: 0.498731\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064869; batch adversarial loss: 0.372321\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037084; batch adversarial loss: 0.505086\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072926; batch adversarial loss: 0.451308\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060075; batch adversarial loss: 0.424971\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066528; batch adversarial loss: 0.478184\n",
      "epoch 110; iter: 0; batch classifier loss: 0.098677; batch adversarial loss: 0.372729\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035120; batch adversarial loss: 0.464611\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045979; batch adversarial loss: 0.415665\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063436; batch adversarial loss: 0.390157\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052906; batch adversarial loss: 0.468799\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059319; batch adversarial loss: 0.452466\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023434; batch adversarial loss: 0.523386\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058130; batch adversarial loss: 0.439193\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057629; batch adversarial loss: 0.519780\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046270; batch adversarial loss: 0.531120\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051031; batch adversarial loss: 0.476405\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072449; batch adversarial loss: 0.521947\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032307; batch adversarial loss: 0.390171\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020241; batch adversarial loss: 0.407417\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037721; batch adversarial loss: 0.402993\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015698; batch adversarial loss: 0.427475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062759; batch adversarial loss: 0.427607\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043346; batch adversarial loss: 0.474434\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.425383\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023913; batch adversarial loss: 0.450601\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029608; batch adversarial loss: 0.430524\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068778; batch adversarial loss: 0.425912\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058424; batch adversarial loss: 0.472321\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.428300\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063580; batch adversarial loss: 0.432183\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059619; batch adversarial loss: 0.429609\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018429; batch adversarial loss: 0.407046\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064879; batch adversarial loss: 0.430885\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030992; batch adversarial loss: 0.533958\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043508; batch adversarial loss: 0.557267\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.496436\n",
      "epoch 141; iter: 0; batch classifier loss: 0.009936; batch adversarial loss: 0.449422\n",
      "epoch 142; iter: 0; batch classifier loss: 0.071061; batch adversarial loss: 0.560770\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028713; batch adversarial loss: 0.433826\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024120; batch adversarial loss: 0.437005\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033460; batch adversarial loss: 0.399630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023720; batch adversarial loss: 0.412429\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029012; batch adversarial loss: 0.440825\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033683; batch adversarial loss: 0.484940\n",
      "epoch 149; iter: 0; batch classifier loss: 0.022567; batch adversarial loss: 0.495082\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061622; batch adversarial loss: 0.386840\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.446288\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018093; batch adversarial loss: 0.495995\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045309; batch adversarial loss: 0.507127\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019474; batch adversarial loss: 0.451908\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051482; batch adversarial loss: 0.486240\n",
      "epoch 156; iter: 0; batch classifier loss: 0.051485; batch adversarial loss: 0.482306\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017137; batch adversarial loss: 0.489272\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029097; batch adversarial loss: 0.438890\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026718; batch adversarial loss: 0.389726\n",
      "epoch 160; iter: 0; batch classifier loss: 0.061525; batch adversarial loss: 0.448815\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025780; batch adversarial loss: 0.443908\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027987; batch adversarial loss: 0.453592\n",
      "epoch 163; iter: 0; batch classifier loss: 0.063168; batch adversarial loss: 0.371821\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020729; batch adversarial loss: 0.384202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.031702; batch adversarial loss: 0.416502\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023963; batch adversarial loss: 0.448660\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030069; batch adversarial loss: 0.411965\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016994; batch adversarial loss: 0.518613\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022940; batch adversarial loss: 0.426261\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029873; batch adversarial loss: 0.476065\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021020; batch adversarial loss: 0.481400\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019410; batch adversarial loss: 0.464743\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016489; batch adversarial loss: 0.517968\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032015; batch adversarial loss: 0.276937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021788; batch adversarial loss: 0.575772\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011392; batch adversarial loss: 0.358614\n",
      "epoch 177; iter: 0; batch classifier loss: 0.003538; batch adversarial loss: 0.379922\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013301; batch adversarial loss: 0.399438\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020924; batch adversarial loss: 0.385134\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025481; batch adversarial loss: 0.388826\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030039; batch adversarial loss: 0.437895\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015185; batch adversarial loss: 0.493159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028621; batch adversarial loss: 0.386885\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011800; batch adversarial loss: 0.456340\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019684; batch adversarial loss: 0.485651\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.435451\n",
      "epoch 187; iter: 0; batch classifier loss: 0.067875; batch adversarial loss: 0.464263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019315; batch adversarial loss: 0.434998\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042571; batch adversarial loss: 0.436635\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022700; batch adversarial loss: 0.481105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018422; batch adversarial loss: 0.571732\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014126; batch adversarial loss: 0.426064\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008440; batch adversarial loss: 0.459537\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016095; batch adversarial loss: 0.528028\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013224; batch adversarial loss: 0.416817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004648; batch adversarial loss: 0.467877\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019961; batch adversarial loss: 0.475081\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015623; batch adversarial loss: 0.506839\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015625; batch adversarial loss: 0.386739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666970; batch adversarial loss: 0.609618\n",
      "epoch 1; iter: 0; batch classifier loss: 0.453775; batch adversarial loss: 0.629882\n",
      "epoch 2; iter: 0; batch classifier loss: 0.443615; batch adversarial loss: 0.596491\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362561; batch adversarial loss: 0.586172\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318453; batch adversarial loss: 0.584534\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421333; batch adversarial loss: 0.583778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.374777; batch adversarial loss: 0.579012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524639; batch adversarial loss: 0.596313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.694685; batch adversarial loss: 0.571742\n",
      "epoch 9; iter: 0; batch classifier loss: 0.664581; batch adversarial loss: 0.572672\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464590; batch adversarial loss: 0.526693\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407559; batch adversarial loss: 0.550160\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329750; batch adversarial loss: 0.506215\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336558; batch adversarial loss: 0.461661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351286; batch adversarial loss: 0.527943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279379; batch adversarial loss: 0.460101\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286866; batch adversarial loss: 0.470209\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339132; batch adversarial loss: 0.513264\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196955; batch adversarial loss: 0.455745\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222366; batch adversarial loss: 0.557106\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314285; batch adversarial loss: 0.434955\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262342; batch adversarial loss: 0.500261\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273940; batch adversarial loss: 0.450307\n",
      "epoch 23; iter: 0; batch classifier loss: 0.228931; batch adversarial loss: 0.467456\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211908; batch adversarial loss: 0.472792\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241874; batch adversarial loss: 0.462602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223573; batch adversarial loss: 0.518698\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210305; batch adversarial loss: 0.474346\n",
      "epoch 28; iter: 0; batch classifier loss: 0.174967; batch adversarial loss: 0.567576\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200253; batch adversarial loss: 0.543350\n",
      "epoch 30; iter: 0; batch classifier loss: 0.278911; batch adversarial loss: 0.548580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244240; batch adversarial loss: 0.398420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258102; batch adversarial loss: 0.472898\n",
      "epoch 33; iter: 0; batch classifier loss: 0.297288; batch adversarial loss: 0.417377\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176561; batch adversarial loss: 0.472432\n",
      "epoch 35; iter: 0; batch classifier loss: 0.207872; batch adversarial loss: 0.406644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229844; batch adversarial loss: 0.446981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235840; batch adversarial loss: 0.365564\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223349; batch adversarial loss: 0.444624\n",
      "epoch 39; iter: 0; batch classifier loss: 0.244065; batch adversarial loss: 0.534979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.228816; batch adversarial loss: 0.517784\n",
      "epoch 41; iter: 0; batch classifier loss: 0.161686; batch adversarial loss: 0.451808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.193066; batch adversarial loss: 0.413270\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261595; batch adversarial loss: 0.450470\n",
      "epoch 44; iter: 0; batch classifier loss: 0.234961; batch adversarial loss: 0.524334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215993; batch adversarial loss: 0.444276\n",
      "epoch 46; iter: 0; batch classifier loss: 0.257435; batch adversarial loss: 0.493687\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190540; batch adversarial loss: 0.440275\n",
      "epoch 48; iter: 0; batch classifier loss: 0.230427; batch adversarial loss: 0.471254\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269025; batch adversarial loss: 0.558571\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222563; batch adversarial loss: 0.534566\n",
      "epoch 51; iter: 0; batch classifier loss: 0.247611; batch adversarial loss: 0.482531\n",
      "epoch 52; iter: 0; batch classifier loss: 0.219127; batch adversarial loss: 0.472138\n",
      "epoch 53; iter: 0; batch classifier loss: 0.241940; batch adversarial loss: 0.565614\n",
      "epoch 54; iter: 0; batch classifier loss: 0.147263; batch adversarial loss: 0.495480\n",
      "epoch 55; iter: 0; batch classifier loss: 0.266977; batch adversarial loss: 0.436092\n",
      "epoch 56; iter: 0; batch classifier loss: 0.207204; batch adversarial loss: 0.434625\n",
      "epoch 57; iter: 0; batch classifier loss: 0.214721; batch adversarial loss: 0.422981\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152242; batch adversarial loss: 0.399015\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071153; batch adversarial loss: 0.444486\n",
      "epoch 60; iter: 0; batch classifier loss: 0.169894; batch adversarial loss: 0.433065\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193406; batch adversarial loss: 0.468254\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203034; batch adversarial loss: 0.535418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63; iter: 0; batch classifier loss: 0.145327; batch adversarial loss: 0.519322\n",
      "epoch 64; iter: 0; batch classifier loss: 0.094717; batch adversarial loss: 0.456741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.143823; batch adversarial loss: 0.527598\n",
      "epoch 66; iter: 0; batch classifier loss: 0.219861; batch adversarial loss: 0.433473\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145837; batch adversarial loss: 0.484029\n",
      "epoch 68; iter: 0; batch classifier loss: 0.181656; batch adversarial loss: 0.445427\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202144; batch adversarial loss: 0.483071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.189751; batch adversarial loss: 0.472322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.234447; batch adversarial loss: 0.519300\n",
      "epoch 72; iter: 0; batch classifier loss: 0.226610; batch adversarial loss: 0.576109\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191833; batch adversarial loss: 0.458194\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209829; batch adversarial loss: 0.445476\n",
      "epoch 75; iter: 0; batch classifier loss: 0.161633; batch adversarial loss: 0.483925\n",
      "epoch 76; iter: 0; batch classifier loss: 0.164733; batch adversarial loss: 0.484139\n",
      "epoch 77; iter: 0; batch classifier loss: 0.243884; batch adversarial loss: 0.410931\n",
      "epoch 78; iter: 0; batch classifier loss: 0.159263; batch adversarial loss: 0.460729\n",
      "epoch 79; iter: 0; batch classifier loss: 0.224559; batch adversarial loss: 0.471893\n",
      "epoch 80; iter: 0; batch classifier loss: 0.175464; batch adversarial loss: 0.435536\n",
      "epoch 81; iter: 0; batch classifier loss: 0.217882; batch adversarial loss: 0.423042\n",
      "epoch 82; iter: 0; batch classifier loss: 0.250112; batch adversarial loss: 0.397595\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183415; batch adversarial loss: 0.445920\n",
      "epoch 84; iter: 0; batch classifier loss: 0.247165; batch adversarial loss: 0.508221\n",
      "epoch 85; iter: 0; batch classifier loss: 0.171612; batch adversarial loss: 0.495812\n",
      "epoch 86; iter: 0; batch classifier loss: 0.164797; batch adversarial loss: 0.471870\n",
      "epoch 87; iter: 0; batch classifier loss: 0.162502; batch adversarial loss: 0.532821\n",
      "epoch 88; iter: 0; batch classifier loss: 0.195151; batch adversarial loss: 0.459431\n",
      "epoch 89; iter: 0; batch classifier loss: 0.145799; batch adversarial loss: 0.458740\n",
      "epoch 90; iter: 0; batch classifier loss: 0.149074; batch adversarial loss: 0.434112\n",
      "epoch 91; iter: 0; batch classifier loss: 0.186419; batch adversarial loss: 0.458568\n",
      "epoch 92; iter: 0; batch classifier loss: 0.151750; batch adversarial loss: 0.519523\n",
      "epoch 93; iter: 0; batch classifier loss: 0.118572; batch adversarial loss: 0.446419\n",
      "epoch 94; iter: 0; batch classifier loss: 0.116149; batch adversarial loss: 0.396133\n",
      "epoch 95; iter: 0; batch classifier loss: 0.138926; batch adversarial loss: 0.470816\n",
      "epoch 96; iter: 0; batch classifier loss: 0.176434; batch adversarial loss: 0.459040\n",
      "epoch 97; iter: 0; batch classifier loss: 0.106374; batch adversarial loss: 0.548568\n",
      "epoch 98; iter: 0; batch classifier loss: 0.136631; batch adversarial loss: 0.516096\n",
      "epoch 99; iter: 0; batch classifier loss: 0.119148; batch adversarial loss: 0.381877\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075743; batch adversarial loss: 0.465989\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093329; batch adversarial loss: 0.464681\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075999; batch adversarial loss: 0.410554\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072143; batch adversarial loss: 0.456019\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058023; batch adversarial loss: 0.434074\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077779; batch adversarial loss: 0.412134\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035296; batch adversarial loss: 0.469646\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057896; batch adversarial loss: 0.350640\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054534; batch adversarial loss: 0.514567\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043462; batch adversarial loss: 0.511867\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034399; batch adversarial loss: 0.490287\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042393; batch adversarial loss: 0.481374\n",
      "epoch 112; iter: 0; batch classifier loss: 0.022453; batch adversarial loss: 0.434995\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048732; batch adversarial loss: 0.499942\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047937; batch adversarial loss: 0.501337\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023374; batch adversarial loss: 0.452404\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057351; batch adversarial loss: 0.508183\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028274; batch adversarial loss: 0.444995\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031417; batch adversarial loss: 0.527365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098486; batch adversarial loss: 0.431929\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017453; batch adversarial loss: 0.391196\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044566; batch adversarial loss: 0.454351\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030530; batch adversarial loss: 0.429089\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020235; batch adversarial loss: 0.498154\n",
      "epoch 124; iter: 0; batch classifier loss: 0.011798; batch adversarial loss: 0.521990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022685; batch adversarial loss: 0.508482\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023787; batch adversarial loss: 0.443553\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033668; batch adversarial loss: 0.512481\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031114; batch adversarial loss: 0.454324\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031235; batch adversarial loss: 0.420571\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021729; batch adversarial loss: 0.511061\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.464619\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048318; batch adversarial loss: 0.526131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019443; batch adversarial loss: 0.349755\n",
      "epoch 134; iter: 0; batch classifier loss: 0.063947; batch adversarial loss: 0.377634\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029004; batch adversarial loss: 0.411672\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023121; batch adversarial loss: 0.473771\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014896; batch adversarial loss: 0.444974\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011981; batch adversarial loss: 0.381739\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015536; batch adversarial loss: 0.497696\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.461435\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025290; batch adversarial loss: 0.539703\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.452350\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030541; batch adversarial loss: 0.383729\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021795; batch adversarial loss: 0.385259\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015756; batch adversarial loss: 0.337604\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013505; batch adversarial loss: 0.485774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010099; batch adversarial loss: 0.488914\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027300; batch adversarial loss: 0.482378\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025872; batch adversarial loss: 0.459245\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043297; batch adversarial loss: 0.420694\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017941; batch adversarial loss: 0.427062\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034784; batch adversarial loss: 0.514433\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035011; batch adversarial loss: 0.388862\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022011; batch adversarial loss: 0.379363\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041013; batch adversarial loss: 0.459735\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013792; batch adversarial loss: 0.354641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006599; batch adversarial loss: 0.521884\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018017; batch adversarial loss: 0.493987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 159; iter: 0; batch classifier loss: 0.025591; batch adversarial loss: 0.470219\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013120; batch adversarial loss: 0.507483\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027954; batch adversarial loss: 0.487094\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036152; batch adversarial loss: 0.376759\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006620; batch adversarial loss: 0.490064\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018507; batch adversarial loss: 0.431778\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012209; batch adversarial loss: 0.491188\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033520; batch adversarial loss: 0.388554\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012512; batch adversarial loss: 0.427969\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020261; batch adversarial loss: 0.427404\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004281; batch adversarial loss: 0.386958\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029918; batch adversarial loss: 0.454848\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010792; batch adversarial loss: 0.375095\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008406; batch adversarial loss: 0.402926\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011983; batch adversarial loss: 0.422246\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005067; batch adversarial loss: 0.453700\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009772; batch adversarial loss: 0.432081\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011093; batch adversarial loss: 0.419978\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009559; batch adversarial loss: 0.531314\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024581; batch adversarial loss: 0.423277\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016367; batch adversarial loss: 0.403321\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004332; batch adversarial loss: 0.524545\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013782; batch adversarial loss: 0.399402\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011502; batch adversarial loss: 0.519979\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.483020\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011649; batch adversarial loss: 0.491014\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015137; batch adversarial loss: 0.468452\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003904; batch adversarial loss: 0.384353\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048478; batch adversarial loss: 0.412254\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012418; batch adversarial loss: 0.434965\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015537; batch adversarial loss: 0.455984\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023321; batch adversarial loss: 0.475087\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018252; batch adversarial loss: 0.521333\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018104; batch adversarial loss: 0.444723\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012197; batch adversarial loss: 0.519890\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.450711\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014514; batch adversarial loss: 0.494699\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017227; batch adversarial loss: 0.481833\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014509; batch adversarial loss: 0.476966\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011659; batch adversarial loss: 0.479152\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005894; batch adversarial loss: 0.429546\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705396; batch adversarial loss: 0.530129\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443977; batch adversarial loss: 0.591289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378930; batch adversarial loss: 0.597197\n",
      "epoch 3; iter: 0; batch classifier loss: 0.482237; batch adversarial loss: 0.555959\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460079; batch adversarial loss: 0.541969\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362313; batch adversarial loss: 0.563800\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501403; batch adversarial loss: 0.663447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.660402; batch adversarial loss: 0.651554\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552261; batch adversarial loss: 0.571348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540064; batch adversarial loss: 0.558284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510597; batch adversarial loss: 0.501212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464181; batch adversarial loss: 0.513344\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422760; batch adversarial loss: 0.482728\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273664; batch adversarial loss: 0.496822\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206995; batch adversarial loss: 0.536782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335664; batch adversarial loss: 0.480289\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286021; batch adversarial loss: 0.474229\n",
      "epoch 17; iter: 0; batch classifier loss: 0.266368; batch adversarial loss: 0.512813\n",
      "epoch 18; iter: 0; batch classifier loss: 0.222327; batch adversarial loss: 0.559115\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257700; batch adversarial loss: 0.413752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260043; batch adversarial loss: 0.509227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.218999; batch adversarial loss: 0.469096\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254722; batch adversarial loss: 0.486788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232162; batch adversarial loss: 0.470369\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203907; batch adversarial loss: 0.507400\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172918; batch adversarial loss: 0.530365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181800; batch adversarial loss: 0.394090\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230784; batch adversarial loss: 0.443233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207821; batch adversarial loss: 0.456645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208284; batch adversarial loss: 0.474972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.198822; batch adversarial loss: 0.445689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174586; batch adversarial loss: 0.480699\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228819; batch adversarial loss: 0.445657\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213586; batch adversarial loss: 0.508343\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233567; batch adversarial loss: 0.483793\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137095; batch adversarial loss: 0.456931\n",
      "epoch 36; iter: 0; batch classifier loss: 0.168701; batch adversarial loss: 0.446572\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148437; batch adversarial loss: 0.427623\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138775; batch adversarial loss: 0.389100\n",
      "epoch 39; iter: 0; batch classifier loss: 0.173516; batch adversarial loss: 0.397991\n",
      "epoch 40; iter: 0; batch classifier loss: 0.213530; batch adversarial loss: 0.356787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.170641; batch adversarial loss: 0.515513\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179097; batch adversarial loss: 0.379063\n",
      "epoch 43; iter: 0; batch classifier loss: 0.208707; batch adversarial loss: 0.351273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127290; batch adversarial loss: 0.516104\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178984; batch adversarial loss: 0.409186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.197239; batch adversarial loss: 0.459335\n",
      "epoch 47; iter: 0; batch classifier loss: 0.181309; batch adversarial loss: 0.515064\n",
      "epoch 48; iter: 0; batch classifier loss: 0.143457; batch adversarial loss: 0.489266\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136810; batch adversarial loss: 0.590397\n",
      "epoch 50; iter: 0; batch classifier loss: 0.184458; batch adversarial loss: 0.557072\n",
      "epoch 51; iter: 0; batch classifier loss: 0.191544; batch adversarial loss: 0.459084\n",
      "epoch 52; iter: 0; batch classifier loss: 0.192551; batch adversarial loss: 0.480931\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143369; batch adversarial loss: 0.568823\n",
      "epoch 54; iter: 0; batch classifier loss: 0.205891; batch adversarial loss: 0.444236\n",
      "epoch 55; iter: 0; batch classifier loss: 0.206882; batch adversarial loss: 0.485065\n",
      "epoch 56; iter: 0; batch classifier loss: 0.172416; batch adversarial loss: 0.495389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.174191; batch adversarial loss: 0.436103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.212982; batch adversarial loss: 0.398068\n",
      "epoch 59; iter: 0; batch classifier loss: 0.190804; batch adversarial loss: 0.455330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165044; batch adversarial loss: 0.447342\n",
      "epoch 61; iter: 0; batch classifier loss: 0.205285; batch adversarial loss: 0.470423\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185209; batch adversarial loss: 0.435075\n",
      "epoch 63; iter: 0; batch classifier loss: 0.179028; batch adversarial loss: 0.423040\n",
      "epoch 64; iter: 0; batch classifier loss: 0.163401; batch adversarial loss: 0.421014\n",
      "epoch 65; iter: 0; batch classifier loss: 0.213215; batch adversarial loss: 0.446635\n",
      "epoch 66; iter: 0; batch classifier loss: 0.260741; batch adversarial loss: 0.409467\n",
      "epoch 67; iter: 0; batch classifier loss: 0.151822; batch adversarial loss: 0.434333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.133724; batch adversarial loss: 0.472199\n",
      "epoch 69; iter: 0; batch classifier loss: 0.226335; batch adversarial loss: 0.458391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101462; batch adversarial loss: 0.421673\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073310; batch adversarial loss: 0.420141\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187616; batch adversarial loss: 0.358906\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187404; batch adversarial loss: 0.421961\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130099; batch adversarial loss: 0.483652\n",
      "epoch 75; iter: 0; batch classifier loss: 0.226022; batch adversarial loss: 0.543531\n",
      "epoch 76; iter: 0; batch classifier loss: 0.167814; batch adversarial loss: 0.483080\n",
      "epoch 77; iter: 0; batch classifier loss: 0.206691; batch adversarial loss: 0.421037\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104639; batch adversarial loss: 0.446834\n",
      "epoch 79; iter: 0; batch classifier loss: 0.183645; batch adversarial loss: 0.395717\n",
      "epoch 80; iter: 0; batch classifier loss: 0.176337; batch adversarial loss: 0.384217\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120014; batch adversarial loss: 0.483992\n",
      "epoch 82; iter: 0; batch classifier loss: 0.148184; batch adversarial loss: 0.582188\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154230; batch adversarial loss: 0.383389\n",
      "epoch 84; iter: 0; batch classifier loss: 0.185140; batch adversarial loss: 0.396607\n",
      "epoch 85; iter: 0; batch classifier loss: 0.208747; batch adversarial loss: 0.422573\n",
      "epoch 86; iter: 0; batch classifier loss: 0.152546; batch adversarial loss: 0.569878\n",
      "epoch 87; iter: 0; batch classifier loss: 0.189097; batch adversarial loss: 0.383861\n",
      "epoch 88; iter: 0; batch classifier loss: 0.131792; batch adversarial loss: 0.507913\n",
      "epoch 89; iter: 0; batch classifier loss: 0.158537; batch adversarial loss: 0.471146\n",
      "epoch 90; iter: 0; batch classifier loss: 0.194647; batch adversarial loss: 0.460595\n",
      "epoch 91; iter: 0; batch classifier loss: 0.106030; batch adversarial loss: 0.457376\n",
      "epoch 92; iter: 0; batch classifier loss: 0.216349; batch adversarial loss: 0.520782\n",
      "epoch 93; iter: 0; batch classifier loss: 0.087465; batch adversarial loss: 0.483334\n",
      "epoch 94; iter: 0; batch classifier loss: 0.173280; batch adversarial loss: 0.346979\n",
      "epoch 95; iter: 0; batch classifier loss: 0.176213; batch adversarial loss: 0.409223\n",
      "epoch 96; iter: 0; batch classifier loss: 0.153269; batch adversarial loss: 0.496900\n",
      "epoch 97; iter: 0; batch classifier loss: 0.142797; batch adversarial loss: 0.421653\n",
      "epoch 98; iter: 0; batch classifier loss: 0.177999; batch adversarial loss: 0.446279\n",
      "epoch 99; iter: 0; batch classifier loss: 0.183041; batch adversarial loss: 0.532647\n",
      "epoch 100; iter: 0; batch classifier loss: 0.174951; batch adversarial loss: 0.346636\n",
      "epoch 101; iter: 0; batch classifier loss: 0.208578; batch adversarial loss: 0.532555\n",
      "epoch 102; iter: 0; batch classifier loss: 0.121654; batch adversarial loss: 0.432874\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216904; batch adversarial loss: 0.370439\n",
      "epoch 104; iter: 0; batch classifier loss: 0.212765; batch adversarial loss: 0.448062\n",
      "epoch 105; iter: 0; batch classifier loss: 0.197053; batch adversarial loss: 0.432732\n",
      "epoch 106; iter: 0; batch classifier loss: 0.148624; batch adversarial loss: 0.520604\n",
      "epoch 107; iter: 0; batch classifier loss: 0.135371; batch adversarial loss: 0.471821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.113826; batch adversarial loss: 0.484110\n",
      "epoch 109; iter: 0; batch classifier loss: 0.129418; batch adversarial loss: 0.419517\n",
      "epoch 110; iter: 0; batch classifier loss: 0.108500; batch adversarial loss: 0.444624\n",
      "epoch 111; iter: 0; batch classifier loss: 0.173766; batch adversarial loss: 0.486024\n",
      "epoch 112; iter: 0; batch classifier loss: 0.199076; batch adversarial loss: 0.395447\n",
      "epoch 113; iter: 0; batch classifier loss: 0.113760; batch adversarial loss: 0.382486\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082272; batch adversarial loss: 0.585436\n",
      "epoch 115; iter: 0; batch classifier loss: 0.137068; batch adversarial loss: 0.432986\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084587; batch adversarial loss: 0.485344\n",
      "epoch 117; iter: 0; batch classifier loss: 0.096027; batch adversarial loss: 0.466872\n",
      "epoch 118; iter: 0; batch classifier loss: 0.114666; batch adversarial loss: 0.370640\n",
      "epoch 119; iter: 0; batch classifier loss: 0.074138; batch adversarial loss: 0.536933\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062141; batch adversarial loss: 0.431546\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072536; batch adversarial loss: 0.418624\n",
      "epoch 122; iter: 0; batch classifier loss: 0.091202; batch adversarial loss: 0.453400\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057405; batch adversarial loss: 0.435146\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053746; batch adversarial loss: 0.514872\n",
      "epoch 125; iter: 0; batch classifier loss: 0.085320; batch adversarial loss: 0.395471\n",
      "epoch 126; iter: 0; batch classifier loss: 0.053715; batch adversarial loss: 0.474730\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053100; batch adversarial loss: 0.491195\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050652; batch adversarial loss: 0.424522\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062001; batch adversarial loss: 0.385008\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034318; batch adversarial loss: 0.449941\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043681; batch adversarial loss: 0.443306\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054070; batch adversarial loss: 0.373771\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046380; batch adversarial loss: 0.443852\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056780; batch adversarial loss: 0.451187\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058135; batch adversarial loss: 0.516806\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058076; batch adversarial loss: 0.436031\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047615; batch adversarial loss: 0.442155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052888; batch adversarial loss: 0.433587\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040364; batch adversarial loss: 0.488270\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037623; batch adversarial loss: 0.396971\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046925; batch adversarial loss: 0.462790\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027047; batch adversarial loss: 0.400262\n",
      "epoch 143; iter: 0; batch classifier loss: 0.056751; batch adversarial loss: 0.469744\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046718; batch adversarial loss: 0.480361\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039561; batch adversarial loss: 0.507196\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021120; batch adversarial loss: 0.464199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.570422\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036111; batch adversarial loss: 0.387442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045932; batch adversarial loss: 0.464196\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057906; batch adversarial loss: 0.509633\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021561; batch adversarial loss: 0.475808\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024443; batch adversarial loss: 0.414700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.018577; batch adversarial loss: 0.465454\n",
      "epoch 154; iter: 0; batch classifier loss: 0.054123; batch adversarial loss: 0.427389\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029254; batch adversarial loss: 0.413338\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.428715\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032183; batch adversarial loss: 0.384974\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032025; batch adversarial loss: 0.451469\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012872; batch adversarial loss: 0.450069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033517; batch adversarial loss: 0.482158\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045065; batch adversarial loss: 0.542873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033597; batch adversarial loss: 0.476194\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061630; batch adversarial loss: 0.471360\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.490886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028980; batch adversarial loss: 0.453566\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015839; batch adversarial loss: 0.411992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021393; batch adversarial loss: 0.400241\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030031; batch adversarial loss: 0.470696\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027811; batch adversarial loss: 0.576828\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016353; batch adversarial loss: 0.456919\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022254; batch adversarial loss: 0.478344\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018217; batch adversarial loss: 0.386016\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013613; batch adversarial loss: 0.538894\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016280; batch adversarial loss: 0.518949\n",
      "epoch 175; iter: 0; batch classifier loss: 0.060488; batch adversarial loss: 0.406998\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009516; batch adversarial loss: 0.432053\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021886; batch adversarial loss: 0.550918\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019962; batch adversarial loss: 0.437842\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026614; batch adversarial loss: 0.496147\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027056; batch adversarial loss: 0.460113\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.527933\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014306; batch adversarial loss: 0.475104\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039833; batch adversarial loss: 0.318392\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011604; batch adversarial loss: 0.448435\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007894; batch adversarial loss: 0.436250\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.471815\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021666; batch adversarial loss: 0.423389\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026402; batch adversarial loss: 0.416985\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025155; batch adversarial loss: 0.432949\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030360; batch adversarial loss: 0.425156\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012474; batch adversarial loss: 0.369628\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017170; batch adversarial loss: 0.551091\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011869; batch adversarial loss: 0.436550\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027850; batch adversarial loss: 0.453645\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024225; batch adversarial loss: 0.461709\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023119; batch adversarial loss: 0.524472\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006780; batch adversarial loss: 0.496197\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021989; batch adversarial loss: 0.442720\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023859; batch adversarial loss: 0.463730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679755; batch adversarial loss: 0.705044\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493110; batch adversarial loss: 0.631179\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445812; batch adversarial loss: 0.601820\n",
      "epoch 3; iter: 0; batch classifier loss: 0.421594; batch adversarial loss: 0.575783\n",
      "epoch 4; iter: 0; batch classifier loss: 0.395049; batch adversarial loss: 0.595273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339180; batch adversarial loss: 0.568228\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390616; batch adversarial loss: 0.566501\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310014; batch adversarial loss: 0.571511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312164; batch adversarial loss: 0.528420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.232742; batch adversarial loss: 0.539669\n",
      "epoch 10; iter: 0; batch classifier loss: 0.318976; batch adversarial loss: 0.551806\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264380; batch adversarial loss: 0.479917\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269893; batch adversarial loss: 0.542507\n",
      "epoch 13; iter: 0; batch classifier loss: 0.289510; batch adversarial loss: 0.507936\n",
      "epoch 14; iter: 0; batch classifier loss: 0.323533; batch adversarial loss: 0.417239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.262539; batch adversarial loss: 0.530993\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336738; batch adversarial loss: 0.517076\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283630; batch adversarial loss: 0.477955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184476; batch adversarial loss: 0.495981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278651; batch adversarial loss: 0.476085\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219385; batch adversarial loss: 0.510679\n",
      "epoch 21; iter: 0; batch classifier loss: 0.241093; batch adversarial loss: 0.593346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235785; batch adversarial loss: 0.407082\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206063; batch adversarial loss: 0.449899\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300531; batch adversarial loss: 0.402492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209659; batch adversarial loss: 0.495421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197014; batch adversarial loss: 0.532600\n",
      "epoch 27; iter: 0; batch classifier loss: 0.235092; batch adversarial loss: 0.456876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255660; batch adversarial loss: 0.502518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180020; batch adversarial loss: 0.464897\n",
      "epoch 30; iter: 0; batch classifier loss: 0.226015; batch adversarial loss: 0.464274\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227435; batch adversarial loss: 0.525328\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227476; batch adversarial loss: 0.453050\n",
      "epoch 33; iter: 0; batch classifier loss: 0.248010; batch adversarial loss: 0.416351\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214646; batch adversarial loss: 0.481830\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235791; batch adversarial loss: 0.413554\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274944; batch adversarial loss: 0.553018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.181662; batch adversarial loss: 0.445824\n",
      "epoch 38; iter: 0; batch classifier loss: 0.251809; batch adversarial loss: 0.462592\n",
      "epoch 39; iter: 0; batch classifier loss: 0.261313; batch adversarial loss: 0.433694\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229448; batch adversarial loss: 0.445494\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222978; batch adversarial loss: 0.499144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172487; batch adversarial loss: 0.470552\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227281; batch adversarial loss: 0.449078\n",
      "epoch 44; iter: 0; batch classifier loss: 0.204462; batch adversarial loss: 0.359203\n",
      "epoch 45; iter: 0; batch classifier loss: 0.196447; batch adversarial loss: 0.403461\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245725; batch adversarial loss: 0.411511\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192762; batch adversarial loss: 0.449945\n",
      "epoch 48; iter: 0; batch classifier loss: 0.273593; batch adversarial loss: 0.402832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.193283; batch adversarial loss: 0.412413\n",
      "epoch 50; iter: 0; batch classifier loss: 0.221824; batch adversarial loss: 0.422945\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214539; batch adversarial loss: 0.495968\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155240; batch adversarial loss: 0.422831\n",
      "epoch 53; iter: 0; batch classifier loss: 0.270241; batch adversarial loss: 0.495682\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146373; batch adversarial loss: 0.434865\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099252; batch adversarial loss: 0.445048\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079176; batch adversarial loss: 0.471782\n",
      "epoch 57; iter: 0; batch classifier loss: 0.237331; batch adversarial loss: 0.468046\n",
      "epoch 58; iter: 0; batch classifier loss: 0.169724; batch adversarial loss: 0.446425\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115857; batch adversarial loss: 0.483292\n",
      "epoch 60; iter: 0; batch classifier loss: 0.140131; batch adversarial loss: 0.507683\n",
      "epoch 61; iter: 0; batch classifier loss: 0.251438; batch adversarial loss: 0.433710\n",
      "epoch 62; iter: 0; batch classifier loss: 0.214209; batch adversarial loss: 0.324275\n",
      "epoch 63; iter: 0; batch classifier loss: 0.140288; batch adversarial loss: 0.397214\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189801; batch adversarial loss: 0.470923\n",
      "epoch 65; iter: 0; batch classifier loss: 0.140701; batch adversarial loss: 0.385342\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126381; batch adversarial loss: 0.421235\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122988; batch adversarial loss: 0.356902\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094691; batch adversarial loss: 0.521526\n",
      "epoch 69; iter: 0; batch classifier loss: 0.134734; batch adversarial loss: 0.479931\n",
      "epoch 70; iter: 0; batch classifier loss: 0.147730; batch adversarial loss: 0.462721\n",
      "epoch 71; iter: 0; batch classifier loss: 0.118713; batch adversarial loss: 0.459116\n",
      "epoch 72; iter: 0; batch classifier loss: 0.214295; batch adversarial loss: 0.359260\n",
      "epoch 73; iter: 0; batch classifier loss: 0.152918; batch adversarial loss: 0.391588\n",
      "epoch 74; iter: 0; batch classifier loss: 0.167748; batch adversarial loss: 0.408826\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091463; batch adversarial loss: 0.455164\n",
      "epoch 76; iter: 0; batch classifier loss: 0.151094; batch adversarial loss: 0.459357\n",
      "epoch 77; iter: 0; batch classifier loss: 0.179920; batch adversarial loss: 0.423263\n",
      "epoch 78; iter: 0; batch classifier loss: 0.175608; batch adversarial loss: 0.430779\n",
      "epoch 79; iter: 0; batch classifier loss: 0.119630; batch adversarial loss: 0.448729\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118555; batch adversarial loss: 0.406909\n",
      "epoch 81; iter: 0; batch classifier loss: 0.160319; batch adversarial loss: 0.350542\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088534; batch adversarial loss: 0.436643\n",
      "epoch 83; iter: 0; batch classifier loss: 0.119650; batch adversarial loss: 0.467149\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106612; batch adversarial loss: 0.528563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082250; batch adversarial loss: 0.531758\n",
      "epoch 86; iter: 0; batch classifier loss: 0.136773; batch adversarial loss: 0.448295\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067595; batch adversarial loss: 0.507180\n",
      "epoch 88; iter: 0; batch classifier loss: 0.094535; batch adversarial loss: 0.525962\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056008; batch adversarial loss: 0.460791\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078066; batch adversarial loss: 0.389516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074540; batch adversarial loss: 0.475884\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067254; batch adversarial loss: 0.371792\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061618; batch adversarial loss: 0.385086\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098633; batch adversarial loss: 0.479973\n",
      "epoch 95; iter: 0; batch classifier loss: 0.101379; batch adversarial loss: 0.475338\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058892; batch adversarial loss: 0.435747\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048214; batch adversarial loss: 0.522725\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074314; batch adversarial loss: 0.429364\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091610; batch adversarial loss: 0.485145\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041412; batch adversarial loss: 0.380120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.020373; batch adversarial loss: 0.603722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030464; batch adversarial loss: 0.429391\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072875; batch adversarial loss: 0.404039\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.479186\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067649; batch adversarial loss: 0.463645\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058861; batch adversarial loss: 0.411528\n",
      "epoch 107; iter: 0; batch classifier loss: 0.068407; batch adversarial loss: 0.430506\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043903; batch adversarial loss: 0.579451\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027765; batch adversarial loss: 0.382074\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034720; batch adversarial loss: 0.444783\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064005; batch adversarial loss: 0.421260\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032046; batch adversarial loss: 0.445304\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033110; batch adversarial loss: 0.494285\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024284; batch adversarial loss: 0.470360\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032377; batch adversarial loss: 0.369995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040888; batch adversarial loss: 0.459527\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028535; batch adversarial loss: 0.461718\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028217; batch adversarial loss: 0.495072\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068374; batch adversarial loss: 0.427584\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022732; batch adversarial loss: 0.451166\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044115; batch adversarial loss: 0.455324\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033348; batch adversarial loss: 0.407120\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038780; batch adversarial loss: 0.464191\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019571; batch adversarial loss: 0.360754\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064325; batch adversarial loss: 0.338900\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047455; batch adversarial loss: 0.423136\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028320; batch adversarial loss: 0.428196\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031636; batch adversarial loss: 0.442903\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017385; batch adversarial loss: 0.526289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.014330; batch adversarial loss: 0.525561\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059731; batch adversarial loss: 0.371247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.531424\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010986; batch adversarial loss: 0.437981\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020015; batch adversarial loss: 0.376264\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027549; batch adversarial loss: 0.392067\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020423; batch adversarial loss: 0.468498\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017407; batch adversarial loss: 0.490349\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018750; batch adversarial loss: 0.472501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012811; batch adversarial loss: 0.424959\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017304; batch adversarial loss: 0.429306\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036348; batch adversarial loss: 0.443456\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029472; batch adversarial loss: 0.398756\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037832; batch adversarial loss: 0.400423\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021669; batch adversarial loss: 0.430878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.033916; batch adversarial loss: 0.352101\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025635; batch adversarial loss: 0.437751\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013370; batch adversarial loss: 0.452394\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015110; batch adversarial loss: 0.484521\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015604; batch adversarial loss: 0.483883\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020575; batch adversarial loss: 0.534817\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014995; batch adversarial loss: 0.517618\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024916; batch adversarial loss: 0.446310\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016790; batch adversarial loss: 0.392196\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036325; batch adversarial loss: 0.441034\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018027; batch adversarial loss: 0.446596\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006815; batch adversarial loss: 0.383922\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016686; batch adversarial loss: 0.498643\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012068; batch adversarial loss: 0.496369\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014151; batch adversarial loss: 0.404154\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022619; batch adversarial loss: 0.459359\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033044; batch adversarial loss: 0.385772\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032979; batch adversarial loss: 0.459432\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007399; batch adversarial loss: 0.386452\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010887; batch adversarial loss: 0.436138\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008776; batch adversarial loss: 0.429054\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010023; batch adversarial loss: 0.502823\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009505; batch adversarial loss: 0.388853\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014364; batch adversarial loss: 0.523783\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013364; batch adversarial loss: 0.449239\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016908; batch adversarial loss: 0.395762\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024163; batch adversarial loss: 0.453220\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009336; batch adversarial loss: 0.448346\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015832; batch adversarial loss: 0.470082\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006763; batch adversarial loss: 0.493955\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014491; batch adversarial loss: 0.484745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008762; batch adversarial loss: 0.455133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020873; batch adversarial loss: 0.435683\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009055; batch adversarial loss: 0.492363\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019836; batch adversarial loss: 0.545955\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018110; batch adversarial loss: 0.402468\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008170; batch adversarial loss: 0.493740\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007472; batch adversarial loss: 0.413684\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016111; batch adversarial loss: 0.501036\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042191; batch adversarial loss: 0.497353\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010141; batch adversarial loss: 0.495680\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006485; batch adversarial loss: 0.350789\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015064; batch adversarial loss: 0.414581\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024506; batch adversarial loss: 0.412303\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010118; batch adversarial loss: 0.509732\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018449; batch adversarial loss: 0.515412\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024402; batch adversarial loss: 0.465770\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015761; batch adversarial loss: 0.428298\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005339; batch adversarial loss: 0.390538\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042213; batch adversarial loss: 0.470210\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015910; batch adversarial loss: 0.462943\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024854; batch adversarial loss: 0.513487\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021136; batch adversarial loss: 0.484152\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014017; batch adversarial loss: 0.396991\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010974; batch adversarial loss: 0.436305\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693666; batch adversarial loss: 0.956216\n",
      "epoch 1; iter: 0; batch classifier loss: 0.545979; batch adversarial loss: 0.939185\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645767; batch adversarial loss: 0.914544\n",
      "epoch 3; iter: 0; batch classifier loss: 0.964007; batch adversarial loss: 0.921909\n",
      "epoch 4; iter: 0; batch classifier loss: 1.001555; batch adversarial loss: 0.819181\n",
      "epoch 5; iter: 0; batch classifier loss: 0.831367; batch adversarial loss: 0.745870\n",
      "epoch 6; iter: 0; batch classifier loss: 0.901284; batch adversarial loss: 0.669870\n",
      "epoch 7; iter: 0; batch classifier loss: 0.856059; batch adversarial loss: 0.625062\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607331; batch adversarial loss: 0.551067\n",
      "epoch 9; iter: 0; batch classifier loss: 0.393985; batch adversarial loss: 0.562764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400855; batch adversarial loss: 0.531834\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360137; batch adversarial loss: 0.536798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339338; batch adversarial loss: 0.494523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308005; batch adversarial loss: 0.498835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.243658; batch adversarial loss: 0.501982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.177870; batch adversarial loss: 0.495290\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215536; batch adversarial loss: 0.507578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208386; batch adversarial loss: 0.451736\n",
      "epoch 18; iter: 0; batch classifier loss: 0.220403; batch adversarial loss: 0.457295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.184782; batch adversarial loss: 0.460853\n",
      "epoch 20; iter: 0; batch classifier loss: 0.143589; batch adversarial loss: 0.497774\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182714; batch adversarial loss: 0.460712\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166191; batch adversarial loss: 0.441242\n",
      "epoch 23; iter: 0; batch classifier loss: 0.123629; batch adversarial loss: 0.422703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.094686; batch adversarial loss: 0.424006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.133140; batch adversarial loss: 0.453063\n",
      "epoch 26; iter: 0; batch classifier loss: 0.115741; batch adversarial loss: 0.430685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.103335; batch adversarial loss: 0.502437\n",
      "epoch 28; iter: 0; batch classifier loss: 0.121019; batch adversarial loss: 0.448867\n",
      "epoch 29; iter: 0; batch classifier loss: 0.094021; batch adversarial loss: 0.479714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.110093; batch adversarial loss: 0.478024\n",
      "epoch 31; iter: 0; batch classifier loss: 0.066154; batch adversarial loss: 0.460361\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118962; batch adversarial loss: 0.432125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.086019; batch adversarial loss: 0.433904\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111385; batch adversarial loss: 0.399393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127958; batch adversarial loss: 0.482816\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092072; batch adversarial loss: 0.362979\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130594; batch adversarial loss: 0.533793\n",
      "epoch 38; iter: 0; batch classifier loss: 0.072010; batch adversarial loss: 0.420916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.057681; batch adversarial loss: 0.371563\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089427; batch adversarial loss: 0.468322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098140; batch adversarial loss: 0.497670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.061338; batch adversarial loss: 0.429449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.079925; batch adversarial loss: 0.457918\n",
      "epoch 44; iter: 0; batch classifier loss: 0.094232; batch adversarial loss: 0.415310\n",
      "epoch 45; iter: 0; batch classifier loss: 0.044900; batch adversarial loss: 0.437236\n",
      "epoch 46; iter: 0; batch classifier loss: 0.058860; batch adversarial loss: 0.459996\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084938; batch adversarial loss: 0.516635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075604; batch adversarial loss: 0.503645\n",
      "epoch 49; iter: 0; batch classifier loss: 0.055877; batch adversarial loss: 0.427701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.049454; batch adversarial loss: 0.410918\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067644; batch adversarial loss: 0.409769\n",
      "epoch 52; iter: 0; batch classifier loss: 0.091097; batch adversarial loss: 0.484338\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077881; batch adversarial loss: 0.489090\n",
      "epoch 54; iter: 0; batch classifier loss: 0.049911; batch adversarial loss: 0.491267\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068463; batch adversarial loss: 0.494735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082765; batch adversarial loss: 0.451996\n",
      "epoch 57; iter: 0; batch classifier loss: 0.070085; batch adversarial loss: 0.458406\n",
      "epoch 58; iter: 0; batch classifier loss: 0.061427; batch adversarial loss: 0.421503\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050267; batch adversarial loss: 0.427387\n",
      "epoch 60; iter: 0; batch classifier loss: 0.107177; batch adversarial loss: 0.512853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084469; batch adversarial loss: 0.391889\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080445; batch adversarial loss: 0.424001\n",
      "epoch 63; iter: 0; batch classifier loss: 0.043935; batch adversarial loss: 0.532356\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058339; batch adversarial loss: 0.482967\n",
      "epoch 65; iter: 0; batch classifier loss: 0.046152; batch adversarial loss: 0.402599\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058074; batch adversarial loss: 0.442641\n",
      "epoch 67; iter: 0; batch classifier loss: 0.045806; batch adversarial loss: 0.383808\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051619; batch adversarial loss: 0.508521\n",
      "epoch 69; iter: 0; batch classifier loss: 0.062315; batch adversarial loss: 0.407150\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112482; batch adversarial loss: 0.495947\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054131; batch adversarial loss: 0.392435\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056623; batch adversarial loss: 0.495759\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104167; batch adversarial loss: 0.462511\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060090; batch adversarial loss: 0.400194\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079665; batch adversarial loss: 0.485503\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048621; batch adversarial loss: 0.508001\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052818; batch adversarial loss: 0.434664\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077471; batch adversarial loss: 0.510035\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069421; batch adversarial loss: 0.427024\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049162; batch adversarial loss: 0.487979\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065676; batch adversarial loss: 0.425383\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065077; batch adversarial loss: 0.469338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057566; batch adversarial loss: 0.401794\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049146; batch adversarial loss: 0.470716\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076242; batch adversarial loss: 0.553688\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061348; batch adversarial loss: 0.339757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071210; batch adversarial loss: 0.388711\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057599; batch adversarial loss: 0.582118\n",
      "epoch 89; iter: 0; batch classifier loss: 0.052580; batch adversarial loss: 0.462960\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056735; batch adversarial loss: 0.455313\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056504; batch adversarial loss: 0.439551\n",
      "epoch 92; iter: 0; batch classifier loss: 0.029852; batch adversarial loss: 0.413232\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070061; batch adversarial loss: 0.455822\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061513; batch adversarial loss: 0.448926\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068226; batch adversarial loss: 0.352211\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.442356\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055368; batch adversarial loss: 0.469539\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086658; batch adversarial loss: 0.433601\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047150; batch adversarial loss: 0.503910\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.479849\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045475; batch adversarial loss: 0.524726\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037060; batch adversarial loss: 0.444134\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057295; batch adversarial loss: 0.498943\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061767; batch adversarial loss: 0.368500\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037966; batch adversarial loss: 0.449718\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.437121\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028772; batch adversarial loss: 0.401748\n",
      "epoch 108; iter: 0; batch classifier loss: 0.023195; batch adversarial loss: 0.447923\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.378405\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069183; batch adversarial loss: 0.442412\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069505; batch adversarial loss: 0.559114\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047337; batch adversarial loss: 0.465009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033591; batch adversarial loss: 0.516279\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052306; batch adversarial loss: 0.420180\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042122; batch adversarial loss: 0.513468\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024898; batch adversarial loss: 0.463979\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029330; batch adversarial loss: 0.404457\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057919; batch adversarial loss: 0.380678\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.470087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037581; batch adversarial loss: 0.436361\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068857; batch adversarial loss: 0.438802\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071826; batch adversarial loss: 0.439661\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038873; batch adversarial loss: 0.459226\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054498; batch adversarial loss: 0.420970\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047134; batch adversarial loss: 0.395034\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029204; batch adversarial loss: 0.405721\n",
      "epoch 127; iter: 0; batch classifier loss: 0.064728; batch adversarial loss: 0.473354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043882; batch adversarial loss: 0.364877\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062039; batch adversarial loss: 0.551062\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045595; batch adversarial loss: 0.427920\n",
      "epoch 131; iter: 0; batch classifier loss: 0.092631; batch adversarial loss: 0.404281\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041971; batch adversarial loss: 0.477706\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.459433\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061868; batch adversarial loss: 0.455190\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025800; batch adversarial loss: 0.444686\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026591; batch adversarial loss: 0.444030\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056761; batch adversarial loss: 0.448786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.036555; batch adversarial loss: 0.441971\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048520; batch adversarial loss: 0.441167\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039102; batch adversarial loss: 0.430483\n",
      "epoch 141; iter: 0; batch classifier loss: 0.095058; batch adversarial loss: 0.531504\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040442; batch adversarial loss: 0.452069\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059401; batch adversarial loss: 0.359116\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017972; batch adversarial loss: 0.327088\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054075; batch adversarial loss: 0.495206\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054785; batch adversarial loss: 0.417020\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039750; batch adversarial loss: 0.404037\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026107; batch adversarial loss: 0.472406\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038459; batch adversarial loss: 0.459104\n",
      "epoch 150; iter: 0; batch classifier loss: 0.064602; batch adversarial loss: 0.355167\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025894; batch adversarial loss: 0.412444\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041598; batch adversarial loss: 0.411785\n",
      "epoch 153; iter: 0; batch classifier loss: 0.061711; batch adversarial loss: 0.489034\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036328; batch adversarial loss: 0.467206\n",
      "epoch 155; iter: 0; batch classifier loss: 0.054354; batch adversarial loss: 0.424463\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039139; batch adversarial loss: 0.433528\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039450; batch adversarial loss: 0.365118\n",
      "epoch 158; iter: 0; batch classifier loss: 0.061422; batch adversarial loss: 0.360819\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039422; batch adversarial loss: 0.457755\n",
      "epoch 160; iter: 0; batch classifier loss: 0.048530; batch adversarial loss: 0.416160\n",
      "epoch 161; iter: 0; batch classifier loss: 0.065652; batch adversarial loss: 0.545705\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040215; batch adversarial loss: 0.437227\n",
      "epoch 163; iter: 0; batch classifier loss: 0.051332; batch adversarial loss: 0.478485\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053052; batch adversarial loss: 0.468377\n",
      "epoch 165; iter: 0; batch classifier loss: 0.072515; batch adversarial loss: 0.594548\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046738; batch adversarial loss: 0.505746\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044432; batch adversarial loss: 0.480057\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044890; batch adversarial loss: 0.415351\n",
      "epoch 169; iter: 0; batch classifier loss: 0.064875; batch adversarial loss: 0.503491\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033473; batch adversarial loss: 0.474031\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040647; batch adversarial loss: 0.496731\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024324; batch adversarial loss: 0.604961\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037922; batch adversarial loss: 0.392518\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021647; batch adversarial loss: 0.412543\n",
      "epoch 175; iter: 0; batch classifier loss: 0.056704; batch adversarial loss: 0.402119\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029184; batch adversarial loss: 0.464183\n",
      "epoch 177; iter: 0; batch classifier loss: 0.053073; batch adversarial loss: 0.395191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033733; batch adversarial loss: 0.434708\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021753; batch adversarial loss: 0.527708\n",
      "epoch 180; iter: 0; batch classifier loss: 0.053283; batch adversarial loss: 0.401789\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.444798\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027215; batch adversarial loss: 0.455290\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034309; batch adversarial loss: 0.385415\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.417581\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041849; batch adversarial loss: 0.515567\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043228; batch adversarial loss: 0.430152\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038798; batch adversarial loss: 0.441975\n",
      "epoch 188; iter: 0; batch classifier loss: 0.054088; batch adversarial loss: 0.365227\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039135; batch adversarial loss: 0.451804\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024300; batch adversarial loss: 0.411080\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052420; batch adversarial loss: 0.465508\n",
      "epoch 192; iter: 0; batch classifier loss: 0.045696; batch adversarial loss: 0.450270\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047656; batch adversarial loss: 0.413504\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055861; batch adversarial loss: 0.463627\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036836; batch adversarial loss: 0.480156\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029484; batch adversarial loss: 0.416109\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022819; batch adversarial loss: 0.424900\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017697; batch adversarial loss: 0.384912\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040796; batch adversarial loss: 0.499349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678633; batch adversarial loss: 0.667073\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518689; batch adversarial loss: 0.642674\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385697; batch adversarial loss: 0.628088\n",
      "epoch 3; iter: 0; batch classifier loss: 0.511912; batch adversarial loss: 0.608793\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359925; batch adversarial loss: 0.601734\n",
      "epoch 5; iter: 0; batch classifier loss: 0.484037; batch adversarial loss: 0.568840\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396213; batch adversarial loss: 0.554158\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431918; batch adversarial loss: 0.525415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397124; batch adversarial loss: 0.550569\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408884; batch adversarial loss: 0.487459\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374430; batch adversarial loss: 0.563027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353964; batch adversarial loss: 0.536701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315548; batch adversarial loss: 0.590265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350130; batch adversarial loss: 0.468588\n",
      "epoch 14; iter: 0; batch classifier loss: 0.277367; batch adversarial loss: 0.477959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266662; batch adversarial loss: 0.524834\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304557; batch adversarial loss: 0.514517\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242409; batch adversarial loss: 0.494107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.247101; batch adversarial loss: 0.481056\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249118; batch adversarial loss: 0.481919\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249705; batch adversarial loss: 0.513764\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258425; batch adversarial loss: 0.445165\n",
      "epoch 22; iter: 0; batch classifier loss: 0.254369; batch adversarial loss: 0.512675\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213344; batch adversarial loss: 0.518477\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273914; batch adversarial loss: 0.424649\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250874; batch adversarial loss: 0.478883\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257253; batch adversarial loss: 0.505157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218522; batch adversarial loss: 0.518579\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265901; batch adversarial loss: 0.427181\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269129; batch adversarial loss: 0.510850\n",
      "epoch 30; iter: 0; batch classifier loss: 0.258451; batch adversarial loss: 0.467580\n",
      "epoch 31; iter: 0; batch classifier loss: 0.298976; batch adversarial loss: 0.461090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275177; batch adversarial loss: 0.476378\n",
      "epoch 33; iter: 0; batch classifier loss: 0.268442; batch adversarial loss: 0.371885\n",
      "epoch 34; iter: 0; batch classifier loss: 0.242491; batch adversarial loss: 0.420960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.208156; batch adversarial loss: 0.455561\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228279; batch adversarial loss: 0.478449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206547; batch adversarial loss: 0.350246\n",
      "epoch 38; iter: 0; batch classifier loss: 0.299432; batch adversarial loss: 0.519712\n",
      "epoch 39; iter: 0; batch classifier loss: 0.237369; batch adversarial loss: 0.530612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232661; batch adversarial loss: 0.463555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184795; batch adversarial loss: 0.481417\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356969; batch adversarial loss: 0.424482\n",
      "epoch 43; iter: 0; batch classifier loss: 0.333617; batch adversarial loss: 0.460847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220414; batch adversarial loss: 0.482651\n",
      "epoch 45; iter: 0; batch classifier loss: 0.264660; batch adversarial loss: 0.482266\n",
      "epoch 46; iter: 0; batch classifier loss: 0.175091; batch adversarial loss: 0.482413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096325; batch adversarial loss: 0.456152\n",
      "epoch 48; iter: 0; batch classifier loss: 0.073798; batch adversarial loss: 0.473658\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116079; batch adversarial loss: 0.381500\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119204; batch adversarial loss: 0.505593\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126765; batch adversarial loss: 0.525914\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089597; batch adversarial loss: 0.446430\n",
      "epoch 53; iter: 0; batch classifier loss: 0.109405; batch adversarial loss: 0.512317\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095034; batch adversarial loss: 0.487773\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106975; batch adversarial loss: 0.377016\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096798; batch adversarial loss: 0.458316\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086909; batch adversarial loss: 0.502487\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135529; batch adversarial loss: 0.435902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.114463; batch adversarial loss: 0.492582\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061346; batch adversarial loss: 0.390884\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083826; batch adversarial loss: 0.463286\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074925; batch adversarial loss: 0.391785\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087791; batch adversarial loss: 0.449977\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107654; batch adversarial loss: 0.380611\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126851; batch adversarial loss: 0.405058\n",
      "epoch 66; iter: 0; batch classifier loss: 0.037500; batch adversarial loss: 0.468916\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088746; batch adversarial loss: 0.396745\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070612; batch adversarial loss: 0.463142\n",
      "epoch 69; iter: 0; batch classifier loss: 0.077696; batch adversarial loss: 0.485385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052122; batch adversarial loss: 0.393444\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079858; batch adversarial loss: 0.419937\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077367; batch adversarial loss: 0.507206\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097946; batch adversarial loss: 0.492216\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077743; batch adversarial loss: 0.356961\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072174; batch adversarial loss: 0.433344\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063863; batch adversarial loss: 0.371694\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068674; batch adversarial loss: 0.441275\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064698; batch adversarial loss: 0.490730\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071928; batch adversarial loss: 0.344323\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070071; batch adversarial loss: 0.473891\n",
      "epoch 81; iter: 0; batch classifier loss: 0.060851; batch adversarial loss: 0.460575\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062752; batch adversarial loss: 0.433788\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051021; batch adversarial loss: 0.459722\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053504; batch adversarial loss: 0.362005\n",
      "epoch 85; iter: 0; batch classifier loss: 0.063776; batch adversarial loss: 0.424595\n",
      "epoch 86; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.483220\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069342; batch adversarial loss: 0.403225\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056098; batch adversarial loss: 0.446522\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061495; batch adversarial loss: 0.412388\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079066; batch adversarial loss: 0.421590\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096613; batch adversarial loss: 0.466459\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058687; batch adversarial loss: 0.452165\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090669; batch adversarial loss: 0.362394\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071525; batch adversarial loss: 0.413888\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066558; batch adversarial loss: 0.367571\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042465; batch adversarial loss: 0.425165\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090053; batch adversarial loss: 0.436362\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049964; batch adversarial loss: 0.440246\n",
      "epoch 99; iter: 0; batch classifier loss: 0.106462; batch adversarial loss: 0.491811\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066214; batch adversarial loss: 0.484173\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063841; batch adversarial loss: 0.404895\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046326; batch adversarial loss: 0.415431\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051119; batch adversarial loss: 0.435172\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060583; batch adversarial loss: 0.474224\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076310; batch adversarial loss: 0.422277\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041173; batch adversarial loss: 0.393633\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078245; batch adversarial loss: 0.435838\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038114; batch adversarial loss: 0.445695\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057721; batch adversarial loss: 0.389722\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088813; batch adversarial loss: 0.397358\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046095; batch adversarial loss: 0.428118\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046019; batch adversarial loss: 0.420391\n",
      "epoch 113; iter: 0; batch classifier loss: 0.078419; batch adversarial loss: 0.410243\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048147; batch adversarial loss: 0.526945\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067709; batch adversarial loss: 0.465390\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046140; batch adversarial loss: 0.401850\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053388; batch adversarial loss: 0.419129\n",
      "epoch 118; iter: 0; batch classifier loss: 0.034166; batch adversarial loss: 0.470020\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039045; batch adversarial loss: 0.390569\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044337; batch adversarial loss: 0.379752\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035366; batch adversarial loss: 0.461368\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077695; batch adversarial loss: 0.492897\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041502; batch adversarial loss: 0.463081\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059190; batch adversarial loss: 0.380324\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040655; batch adversarial loss: 0.450029\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029849; batch adversarial loss: 0.432948\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026267; batch adversarial loss: 0.511460\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028380; batch adversarial loss: 0.398308\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026463; batch adversarial loss: 0.395072\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046242; batch adversarial loss: 0.444895\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022639; batch adversarial loss: 0.370244\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036556; batch adversarial loss: 0.490246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.027435; batch adversarial loss: 0.452019\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029420; batch adversarial loss: 0.497037\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054593; batch adversarial loss: 0.442866\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035237; batch adversarial loss: 0.457340\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053137; batch adversarial loss: 0.332393\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048947; batch adversarial loss: 0.464813\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044543; batch adversarial loss: 0.456232\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030655; batch adversarial loss: 0.401296\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039060; batch adversarial loss: 0.422623\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039869; batch adversarial loss: 0.470332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023768; batch adversarial loss: 0.479679\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026861; batch adversarial loss: 0.368883\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017817; batch adversarial loss: 0.511268\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019697; batch adversarial loss: 0.533735\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033473; batch adversarial loss: 0.520303\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028402; batch adversarial loss: 0.379732\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055997; batch adversarial loss: 0.402013\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026925; batch adversarial loss: 0.423325\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014442; batch adversarial loss: 0.388770\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013719; batch adversarial loss: 0.519578\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015297; batch adversarial loss: 0.507180\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034847; batch adversarial loss: 0.536992\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048490; batch adversarial loss: 0.477046\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039088; batch adversarial loss: 0.453316\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035103; batch adversarial loss: 0.378850\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017175; batch adversarial loss: 0.413112\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015778; batch adversarial loss: 0.455654\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016820; batch adversarial loss: 0.467072\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022883; batch adversarial loss: 0.425249\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021476; batch adversarial loss: 0.449314\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009530; batch adversarial loss: 0.502274\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015908; batch adversarial loss: 0.390150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.057505; batch adversarial loss: 0.507316\n",
      "epoch 166; iter: 0; batch classifier loss: 0.047547; batch adversarial loss: 0.422719\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017506; batch adversarial loss: 0.529773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015439; batch adversarial loss: 0.520821\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.485532\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012085; batch adversarial loss: 0.456269\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024972; batch adversarial loss: 0.465418\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010341; batch adversarial loss: 0.434218\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015902; batch adversarial loss: 0.497431\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026590; batch adversarial loss: 0.432530\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036896; batch adversarial loss: 0.467944\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.506155\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009454; batch adversarial loss: 0.443345\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011312; batch adversarial loss: 0.388359\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021611; batch adversarial loss: 0.327622\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018608; batch adversarial loss: 0.402953\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029524; batch adversarial loss: 0.444064\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022289; batch adversarial loss: 0.437554\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018009; batch adversarial loss: 0.485988\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009417; batch adversarial loss: 0.444723\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.468643\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020335; batch adversarial loss: 0.427753\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007083; batch adversarial loss: 0.447563\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010231; batch adversarial loss: 0.449476\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010519; batch adversarial loss: 0.463666\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017810; batch adversarial loss: 0.467770\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022473; batch adversarial loss: 0.418405\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007809; batch adversarial loss: 0.477293\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028281; batch adversarial loss: 0.456471\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020318; batch adversarial loss: 0.493166\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018993; batch adversarial loss: 0.492224\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015214; batch adversarial loss: 0.498955\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015843; batch adversarial loss: 0.469824\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023337; batch adversarial loss: 0.475863\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012414; batch adversarial loss: 0.512154\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687580; batch adversarial loss: 0.735458\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509643; batch adversarial loss: 0.693289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416867; batch adversarial loss: 0.633011\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374066; batch adversarial loss: 0.618502\n",
      "epoch 4; iter: 0; batch classifier loss: 0.403354; batch adversarial loss: 0.598603\n",
      "epoch 5; iter: 0; batch classifier loss: 0.456845; batch adversarial loss: 0.583427\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327909; batch adversarial loss: 0.564492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335282; batch adversarial loss: 0.568174\n",
      "epoch 8; iter: 0; batch classifier loss: 0.319567; batch adversarial loss: 0.533810\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361421; batch adversarial loss: 0.530798\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405486; batch adversarial loss: 0.505181\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507487; batch adversarial loss: 0.500397\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385242; batch adversarial loss: 0.526547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374909; batch adversarial loss: 0.524863\n",
      "epoch 14; iter: 0; batch classifier loss: 0.337715; batch adversarial loss: 0.511885\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344288; batch adversarial loss: 0.514389\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296842; batch adversarial loss: 0.568328\n",
      "epoch 17; iter: 0; batch classifier loss: 0.351983; batch adversarial loss: 0.507637\n",
      "epoch 18; iter: 0; batch classifier loss: 0.277196; batch adversarial loss: 0.485118\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331883; batch adversarial loss: 0.474775\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340800; batch adversarial loss: 0.442882\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354595; batch adversarial loss: 0.388289\n",
      "epoch 22; iter: 0; batch classifier loss: 0.360689; batch adversarial loss: 0.468251\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333124; batch adversarial loss: 0.515935\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300945; batch adversarial loss: 0.510553\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247772; batch adversarial loss: 0.437270\n",
      "epoch 26; iter: 0; batch classifier loss: 0.321090; batch adversarial loss: 0.486359\n",
      "epoch 27; iter: 0; batch classifier loss: 0.296950; batch adversarial loss: 0.409544\n",
      "epoch 28; iter: 0; batch classifier loss: 0.233637; batch adversarial loss: 0.506434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.257289; batch adversarial loss: 0.439261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.263698; batch adversarial loss: 0.467687\n",
      "epoch 31; iter: 0; batch classifier loss: 0.264582; batch adversarial loss: 0.416822\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190357; batch adversarial loss: 0.480673\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215034; batch adversarial loss: 0.495329\n",
      "epoch 34; iter: 0; batch classifier loss: 0.226301; batch adversarial loss: 0.474104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257785; batch adversarial loss: 0.450781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.234677; batch adversarial loss: 0.427400\n",
      "epoch 37; iter: 0; batch classifier loss: 0.300422; batch adversarial loss: 0.408613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.271916; batch adversarial loss: 0.425941\n",
      "epoch 39; iter: 0; batch classifier loss: 0.208597; batch adversarial loss: 0.474735\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214758; batch adversarial loss: 0.427400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.231589; batch adversarial loss: 0.493450\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242462; batch adversarial loss: 0.492312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229723; batch adversarial loss: 0.446457\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175035; batch adversarial loss: 0.437690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.272740; batch adversarial loss: 0.367285\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187766; batch adversarial loss: 0.567560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.271463; batch adversarial loss: 0.436252\n",
      "epoch 48; iter: 0; batch classifier loss: 0.219714; batch adversarial loss: 0.471762\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206733; batch adversarial loss: 0.544829\n",
      "epoch 50; iter: 0; batch classifier loss: 0.250252; batch adversarial loss: 0.423686\n",
      "epoch 51; iter: 0; batch classifier loss: 0.219752; batch adversarial loss: 0.410291\n",
      "epoch 52; iter: 0; batch classifier loss: 0.214186; batch adversarial loss: 0.471274\n",
      "epoch 53; iter: 0; batch classifier loss: 0.225227; batch adversarial loss: 0.362973\n",
      "epoch 54; iter: 0; batch classifier loss: 0.173805; batch adversarial loss: 0.470987\n",
      "epoch 55; iter: 0; batch classifier loss: 0.168328; batch adversarial loss: 0.432705\n",
      "epoch 56; iter: 0; batch classifier loss: 0.173243; batch adversarial loss: 0.397414\n",
      "epoch 57; iter: 0; batch classifier loss: 0.220172; batch adversarial loss: 0.472030\n",
      "epoch 58; iter: 0; batch classifier loss: 0.189297; batch adversarial loss: 0.495957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212843; batch adversarial loss: 0.496741\n",
      "epoch 60; iter: 0; batch classifier loss: 0.157433; batch adversarial loss: 0.520272\n",
      "epoch 61; iter: 0; batch classifier loss: 0.212184; batch adversarial loss: 0.446796\n",
      "epoch 62; iter: 0; batch classifier loss: 0.193164; batch adversarial loss: 0.519987\n",
      "epoch 63; iter: 0; batch classifier loss: 0.207065; batch adversarial loss: 0.507661\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249584; batch adversarial loss: 0.496306\n",
      "epoch 65; iter: 0; batch classifier loss: 0.167943; batch adversarial loss: 0.359687\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126779; batch adversarial loss: 0.457062\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133179; batch adversarial loss: 0.484115\n",
      "epoch 68; iter: 0; batch classifier loss: 0.179815; batch adversarial loss: 0.486164\n",
      "epoch 69; iter: 0; batch classifier loss: 0.213083; batch adversarial loss: 0.448136\n",
      "epoch 70; iter: 0; batch classifier loss: 0.153962; batch adversarial loss: 0.422692\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169533; batch adversarial loss: 0.458484\n",
      "epoch 72; iter: 0; batch classifier loss: 0.159066; batch adversarial loss: 0.458862\n",
      "epoch 73; iter: 0; batch classifier loss: 0.208391; batch adversarial loss: 0.470081\n",
      "epoch 74; iter: 0; batch classifier loss: 0.195876; batch adversarial loss: 0.437568\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177044; batch adversarial loss: 0.509199\n",
      "epoch 76; iter: 0; batch classifier loss: 0.320935; batch adversarial loss: 0.447936\n",
      "epoch 77; iter: 0; batch classifier loss: 0.155609; batch adversarial loss: 0.519306\n",
      "epoch 78; iter: 0; batch classifier loss: 0.188068; batch adversarial loss: 0.421802\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184966; batch adversarial loss: 0.433525\n",
      "epoch 80; iter: 0; batch classifier loss: 0.226345; batch adversarial loss: 0.494912\n",
      "epoch 81; iter: 0; batch classifier loss: 0.210284; batch adversarial loss: 0.397056\n",
      "epoch 82; iter: 0; batch classifier loss: 0.156408; batch adversarial loss: 0.484201\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153590; batch adversarial loss: 0.484370\n",
      "epoch 84; iter: 0; batch classifier loss: 0.215421; batch adversarial loss: 0.422100\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154704; batch adversarial loss: 0.397420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.159051; batch adversarial loss: 0.471289\n",
      "epoch 87; iter: 0; batch classifier loss: 0.187937; batch adversarial loss: 0.384506\n",
      "epoch 88; iter: 0; batch classifier loss: 0.162057; batch adversarial loss: 0.384672\n",
      "epoch 89; iter: 0; batch classifier loss: 0.179458; batch adversarial loss: 0.433860\n",
      "epoch 90; iter: 0; batch classifier loss: 0.157216; batch adversarial loss: 0.494639\n",
      "epoch 91; iter: 0; batch classifier loss: 0.199363; batch adversarial loss: 0.470557\n",
      "epoch 92; iter: 0; batch classifier loss: 0.160387; batch adversarial loss: 0.496248\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169588; batch adversarial loss: 0.422094\n",
      "epoch 94; iter: 0; batch classifier loss: 0.174938; batch adversarial loss: 0.397111\n",
      "epoch 95; iter: 0; batch classifier loss: 0.149387; batch adversarial loss: 0.533278\n",
      "epoch 96; iter: 0; batch classifier loss: 0.118671; batch adversarial loss: 0.406890\n",
      "epoch 97; iter: 0; batch classifier loss: 0.169756; batch adversarial loss: 0.508889\n",
      "epoch 98; iter: 0; batch classifier loss: 0.133268; batch adversarial loss: 0.485486\n",
      "epoch 99; iter: 0; batch classifier loss: 0.139731; batch adversarial loss: 0.445976\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057829; batch adversarial loss: 0.417655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.061500; batch adversarial loss: 0.456820\n",
      "epoch 102; iter: 0; batch classifier loss: 0.097558; batch adversarial loss: 0.409978\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068271; batch adversarial loss: 0.420244\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046962; batch adversarial loss: 0.587402\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049140; batch adversarial loss: 0.379788\n",
      "epoch 106; iter: 0; batch classifier loss: 0.072560; batch adversarial loss: 0.422474\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048612; batch adversarial loss: 0.472956\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031296; batch adversarial loss: 0.439098\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052711; batch adversarial loss: 0.432484\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060579; batch adversarial loss: 0.501623\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027323; batch adversarial loss: 0.574332\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052134; batch adversarial loss: 0.404965\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049317; batch adversarial loss: 0.579146\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056992; batch adversarial loss: 0.389898\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037300; batch adversarial loss: 0.434437\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023971; batch adversarial loss: 0.395095\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028718; batch adversarial loss: 0.472035\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051320; batch adversarial loss: 0.427449\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065998; batch adversarial loss: 0.444409\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044980; batch adversarial loss: 0.412514\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049083; batch adversarial loss: 0.289052\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034032; batch adversarial loss: 0.552210\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030788; batch adversarial loss: 0.396973\n",
      "epoch 124; iter: 0; batch classifier loss: 0.022158; batch adversarial loss: 0.525294\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036111; batch adversarial loss: 0.441753\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030836; batch adversarial loss: 0.413560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127; iter: 0; batch classifier loss: 0.030916; batch adversarial loss: 0.532535\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023768; batch adversarial loss: 0.387172\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.475041\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020852; batch adversarial loss: 0.470998\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052614; batch adversarial loss: 0.377794\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022414; batch adversarial loss: 0.448727\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029990; batch adversarial loss: 0.424825\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032767; batch adversarial loss: 0.472325\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025306; batch adversarial loss: 0.417911\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022557; batch adversarial loss: 0.438431\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026921; batch adversarial loss: 0.440294\n",
      "epoch 138; iter: 0; batch classifier loss: 0.008879; batch adversarial loss: 0.389678\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054585; batch adversarial loss: 0.442343\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023532; batch adversarial loss: 0.451060\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028466; batch adversarial loss: 0.437099\n",
      "epoch 142; iter: 0; batch classifier loss: 0.067050; batch adversarial loss: 0.472780\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028405; batch adversarial loss: 0.524301\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021076; batch adversarial loss: 0.483112\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020540; batch adversarial loss: 0.489016\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023227; batch adversarial loss: 0.390327\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040493; batch adversarial loss: 0.408863\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028642; batch adversarial loss: 0.447947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.048691; batch adversarial loss: 0.363188\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025824; batch adversarial loss: 0.495928\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.422160\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037017; batch adversarial loss: 0.397559\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023879; batch adversarial loss: 0.423433\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019775; batch adversarial loss: 0.529820\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018802; batch adversarial loss: 0.440990\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033804; batch adversarial loss: 0.370992\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029901; batch adversarial loss: 0.427316\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009755; batch adversarial loss: 0.515653\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026695; batch adversarial loss: 0.495483\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045019; batch adversarial loss: 0.440740\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017010; batch adversarial loss: 0.418966\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023738; batch adversarial loss: 0.448400\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023602; batch adversarial loss: 0.506922\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.460694\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015811; batch adversarial loss: 0.510189\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028941; batch adversarial loss: 0.401388\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010478; batch adversarial loss: 0.401816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.470022\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022719; batch adversarial loss: 0.502090\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009527; batch adversarial loss: 0.426265\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025113; batch adversarial loss: 0.481403\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019851; batch adversarial loss: 0.371186\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028161; batch adversarial loss: 0.493643\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005614; batch adversarial loss: 0.434714\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022560; batch adversarial loss: 0.460677\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015585; batch adversarial loss: 0.413510\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014372; batch adversarial loss: 0.538046\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006159; batch adversarial loss: 0.485788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011580; batch adversarial loss: 0.443627\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019127; batch adversarial loss: 0.445324\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020039; batch adversarial loss: 0.411715\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009120; batch adversarial loss: 0.504526\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030365; batch adversarial loss: 0.492606\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031236; batch adversarial loss: 0.528944\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020211; batch adversarial loss: 0.432397\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016529; batch adversarial loss: 0.532480\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047516; batch adversarial loss: 0.479854\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014197; batch adversarial loss: 0.413874\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022108; batch adversarial loss: 0.412841\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011244; batch adversarial loss: 0.512983\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024984; batch adversarial loss: 0.438776\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034834; batch adversarial loss: 0.375960\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007391; batch adversarial loss: 0.417470\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018524; batch adversarial loss: 0.482343\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017296; batch adversarial loss: 0.453220\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007213; batch adversarial loss: 0.427420\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006059; batch adversarial loss: 0.491268\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037183; batch adversarial loss: 0.442934\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015557; batch adversarial loss: 0.517905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673794; batch adversarial loss: 0.694648\n",
      "epoch 1; iter: 0; batch classifier loss: 0.488320; batch adversarial loss: 0.697439\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424642; batch adversarial loss: 0.663925\n",
      "epoch 3; iter: 0; batch classifier loss: 0.383933; batch adversarial loss: 0.618605\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336663; batch adversarial loss: 0.605204\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313923; batch adversarial loss: 0.580553\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358386; batch adversarial loss: 0.538407\n",
      "epoch 7; iter: 0; batch classifier loss: 0.251212; batch adversarial loss: 0.538288\n",
      "epoch 8; iter: 0; batch classifier loss: 0.250610; batch adversarial loss: 0.492236\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269593; batch adversarial loss: 0.481230\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270634; batch adversarial loss: 0.445375\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223274; batch adversarial loss: 0.440630\n",
      "epoch 12; iter: 0; batch classifier loss: 0.206265; batch adversarial loss: 0.435906\n",
      "epoch 13; iter: 0; batch classifier loss: 0.221697; batch adversarial loss: 0.453284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.195688; batch adversarial loss: 0.479380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.163865; batch adversarial loss: 0.453017\n",
      "epoch 16; iter: 0; batch classifier loss: 0.121964; batch adversarial loss: 0.474078\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178761; batch adversarial loss: 0.501169\n",
      "epoch 18; iter: 0; batch classifier loss: 0.137993; batch adversarial loss: 0.421123\n",
      "epoch 19; iter: 0; batch classifier loss: 0.125176; batch adversarial loss: 0.476000\n",
      "epoch 20; iter: 0; batch classifier loss: 0.142693; batch adversarial loss: 0.393532\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137798; batch adversarial loss: 0.471843\n",
      "epoch 22; iter: 0; batch classifier loss: 0.117985; batch adversarial loss: 0.457827\n",
      "epoch 23; iter: 0; batch classifier loss: 0.126591; batch adversarial loss: 0.433916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.107940; batch adversarial loss: 0.479806\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121976; batch adversarial loss: 0.541991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.128761; batch adversarial loss: 0.447420\n",
      "epoch 27; iter: 0; batch classifier loss: 0.098316; batch adversarial loss: 0.412635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.101841; batch adversarial loss: 0.447223\n",
      "epoch 29; iter: 0; batch classifier loss: 0.127955; batch adversarial loss: 0.468183\n",
      "epoch 30; iter: 0; batch classifier loss: 0.189957; batch adversarial loss: 0.492683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104399; batch adversarial loss: 0.427826\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174000; batch adversarial loss: 0.459119\n",
      "epoch 33; iter: 0; batch classifier loss: 0.119378; batch adversarial loss: 0.471001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.107389; batch adversarial loss: 0.509371\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177427; batch adversarial loss: 0.561624\n",
      "epoch 36; iter: 0; batch classifier loss: 0.229479; batch adversarial loss: 0.462353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211974; batch adversarial loss: 0.616835\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153043; batch adversarial loss: 0.493704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131007; batch adversarial loss: 0.407948\n",
      "epoch 40; iter: 0; batch classifier loss: 0.158322; batch adversarial loss: 0.482808\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155136; batch adversarial loss: 0.511623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131638; batch adversarial loss: 0.447919\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168953; batch adversarial loss: 0.512194\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117614; batch adversarial loss: 0.379617\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124014; batch adversarial loss: 0.411265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.248365; batch adversarial loss: 0.527131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164920; batch adversarial loss: 0.532314\n",
      "epoch 48; iter: 0; batch classifier loss: 0.182130; batch adversarial loss: 0.535928\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076358; batch adversarial loss: 0.442460\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082245; batch adversarial loss: 0.368984\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126041; batch adversarial loss: 0.504456\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088888; batch adversarial loss: 0.412192\n",
      "epoch 53; iter: 0; batch classifier loss: 0.052647; batch adversarial loss: 0.435827\n",
      "epoch 54; iter: 0; batch classifier loss: 0.049932; batch adversarial loss: 0.389243\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080942; batch adversarial loss: 0.456783\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076533; batch adversarial loss: 0.375613\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082638; batch adversarial loss: 0.423186\n",
      "epoch 58; iter: 0; batch classifier loss: 0.068877; batch adversarial loss: 0.409318\n",
      "epoch 59; iter: 0; batch classifier loss: 0.052982; batch adversarial loss: 0.477879\n",
      "epoch 60; iter: 0; batch classifier loss: 0.050942; batch adversarial loss: 0.382869\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109025; batch adversarial loss: 0.487671\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064088; batch adversarial loss: 0.426419\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072000; batch adversarial loss: 0.433766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070484; batch adversarial loss: 0.431556\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099836; batch adversarial loss: 0.350297\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060993; batch adversarial loss: 0.482867\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107202; batch adversarial loss: 0.405243\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088273; batch adversarial loss: 0.478639\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071982; batch adversarial loss: 0.429993\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135664; batch adversarial loss: 0.439223\n",
      "epoch 71; iter: 0; batch classifier loss: 0.113792; batch adversarial loss: 0.382113\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074561; batch adversarial loss: 0.405690\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075418; batch adversarial loss: 0.378841\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058462; batch adversarial loss: 0.480090\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097286; batch adversarial loss: 0.382607\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102403; batch adversarial loss: 0.425893\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043287; batch adversarial loss: 0.465960\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049056; batch adversarial loss: 0.450055\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084963; batch adversarial loss: 0.348055\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052563; batch adversarial loss: 0.492208\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072370; batch adversarial loss: 0.480761\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113496; batch adversarial loss: 0.422107\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074906; batch adversarial loss: 0.442741\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056596; batch adversarial loss: 0.464979\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072865; batch adversarial loss: 0.400187\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035410; batch adversarial loss: 0.379360\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072100; batch adversarial loss: 0.450864\n",
      "epoch 88; iter: 0; batch classifier loss: 0.092079; batch adversarial loss: 0.515738\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106178; batch adversarial loss: 0.333497\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064123; batch adversarial loss: 0.453789\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082931; batch adversarial loss: 0.505617\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074517; batch adversarial loss: 0.473947\n",
      "epoch 93; iter: 0; batch classifier loss: 0.071164; batch adversarial loss: 0.415093\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042460; batch adversarial loss: 0.542125\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064842; batch adversarial loss: 0.469777\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063755; batch adversarial loss: 0.438785\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080568; batch adversarial loss: 0.505621\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056466; batch adversarial loss: 0.451279\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062049; batch adversarial loss: 0.442776\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060332; batch adversarial loss: 0.499604\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048962; batch adversarial loss: 0.439515\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094317; batch adversarial loss: 0.416937\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.270071\n",
      "epoch 104; iter: 0; batch classifier loss: 0.081744; batch adversarial loss: 0.454553\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066742; batch adversarial loss: 0.389115\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046486; batch adversarial loss: 0.489373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048170; batch adversarial loss: 0.450314\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070092; batch adversarial loss: 0.463005\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046217; batch adversarial loss: 0.359681\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058164; batch adversarial loss: 0.489146\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047527; batch adversarial loss: 0.407477\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039086; batch adversarial loss: 0.494573\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082919; batch adversarial loss: 0.516734\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056744; batch adversarial loss: 0.461238\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039192; batch adversarial loss: 0.431463\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033214; batch adversarial loss: 0.355492\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033823; batch adversarial loss: 0.493731\n",
      "epoch 118; iter: 0; batch classifier loss: 0.011495; batch adversarial loss: 0.481001\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063439; batch adversarial loss: 0.441947\n",
      "epoch 120; iter: 0; batch classifier loss: 0.063647; batch adversarial loss: 0.514217\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027472; batch adversarial loss: 0.467380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.053211; batch adversarial loss: 0.435151\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030116; batch adversarial loss: 0.420990\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054574; batch adversarial loss: 0.460207\n",
      "epoch 125; iter: 0; batch classifier loss: 0.088242; batch adversarial loss: 0.457723\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036411; batch adversarial loss: 0.371821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041085; batch adversarial loss: 0.462284\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031788; batch adversarial loss: 0.433474\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053918; batch adversarial loss: 0.511276\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055318; batch adversarial loss: 0.427893\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037287; batch adversarial loss: 0.450689\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033750; batch adversarial loss: 0.444294\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046930; batch adversarial loss: 0.460287\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039494; batch adversarial loss: 0.334706\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046437; batch adversarial loss: 0.408255\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035869; batch adversarial loss: 0.481993\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017932; batch adversarial loss: 0.415981\n",
      "epoch 138; iter: 0; batch classifier loss: 0.096189; batch adversarial loss: 0.418501\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026384; batch adversarial loss: 0.511316\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025238; batch adversarial loss: 0.571882\n",
      "epoch 141; iter: 0; batch classifier loss: 0.010307; batch adversarial loss: 0.522857\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016102; batch adversarial loss: 0.372901\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033447; batch adversarial loss: 0.432562\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021222; batch adversarial loss: 0.503919\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038747; batch adversarial loss: 0.384637\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013023; batch adversarial loss: 0.358649\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031676; batch adversarial loss: 0.465469\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017817; batch adversarial loss: 0.456375\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013566; batch adversarial loss: 0.452029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.049475; batch adversarial loss: 0.474289\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019152; batch adversarial loss: 0.450649\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033745; batch adversarial loss: 0.540519\n",
      "epoch 153; iter: 0; batch classifier loss: 0.068963; batch adversarial loss: 0.522850\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019263; batch adversarial loss: 0.471019\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034605; batch adversarial loss: 0.429670\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020581; batch adversarial loss: 0.459549\n",
      "epoch 157; iter: 0; batch classifier loss: 0.059374; batch adversarial loss: 0.392463\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040934; batch adversarial loss: 0.507687\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023745; batch adversarial loss: 0.485405\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034426; batch adversarial loss: 0.487323\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.460721\n",
      "epoch 162; iter: 0; batch classifier loss: 0.058641; batch adversarial loss: 0.414268\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042070; batch adversarial loss: 0.415488\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040307; batch adversarial loss: 0.393563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.040759; batch adversarial loss: 0.420479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026095; batch adversarial loss: 0.482235\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026492; batch adversarial loss: 0.384964\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021245; batch adversarial loss: 0.404657\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022217; batch adversarial loss: 0.417886\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012919; batch adversarial loss: 0.475368\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.442442\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027008; batch adversarial loss: 0.439247\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017905; batch adversarial loss: 0.496300\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054828; batch adversarial loss: 0.490592\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045613; batch adversarial loss: 0.421521\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009343; batch adversarial loss: 0.477793\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017673; batch adversarial loss: 0.526720\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025173; batch adversarial loss: 0.524090\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031213; batch adversarial loss: 0.450961\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015390; batch adversarial loss: 0.360908\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013345; batch adversarial loss: 0.453680\n",
      "epoch 182; iter: 0; batch classifier loss: 0.056039; batch adversarial loss: 0.431618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014815; batch adversarial loss: 0.465540\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023985; batch adversarial loss: 0.506643\n",
      "epoch 185; iter: 0; batch classifier loss: 0.058565; batch adversarial loss: 0.388536\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013853; batch adversarial loss: 0.453160\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030952; batch adversarial loss: 0.419567\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016086; batch adversarial loss: 0.416800\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015119; batch adversarial loss: 0.514669\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008492; batch adversarial loss: 0.425763\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008854; batch adversarial loss: 0.441656\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008331; batch adversarial loss: 0.524707\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007275; batch adversarial loss: 0.455395\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008232; batch adversarial loss: 0.445316\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027165; batch adversarial loss: 0.440045\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025975; batch adversarial loss: 0.480967\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039410; batch adversarial loss: 0.374229\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002419; batch adversarial loss: 0.504837\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033821; batch adversarial loss: 0.419329\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676004; batch adversarial loss: 0.567295\n",
      "epoch 1; iter: 0; batch classifier loss: 0.349910; batch adversarial loss: 0.624053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.247745; batch adversarial loss: 0.596210\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451653; batch adversarial loss: 0.544695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279496; batch adversarial loss: 0.540163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362606; batch adversarial loss: 0.503329\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254719; batch adversarial loss: 0.505160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.330191; batch adversarial loss: 0.532061\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273396; batch adversarial loss: 0.495655\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320686; batch adversarial loss: 0.489886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.219449; batch adversarial loss: 0.491891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228398; batch adversarial loss: 0.479027\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301489; batch adversarial loss: 0.482884\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265164; batch adversarial loss: 0.510197\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223825; batch adversarial loss: 0.429117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268817; batch adversarial loss: 0.536718\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249988; batch adversarial loss: 0.596774\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259278; batch adversarial loss: 0.485877\n",
      "epoch 18; iter: 0; batch classifier loss: 0.188343; batch adversarial loss: 0.473724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.247629; batch adversarial loss: 0.491455\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212724; batch adversarial loss: 0.450069\n",
      "epoch 21; iter: 0; batch classifier loss: 0.153209; batch adversarial loss: 0.440945\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335936; batch adversarial loss: 0.528856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187059; batch adversarial loss: 0.499068\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229438; batch adversarial loss: 0.502236\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266670; batch adversarial loss: 0.439310\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298749; batch adversarial loss: 0.510836\n",
      "epoch 27; iter: 0; batch classifier loss: 0.365444; batch adversarial loss: 0.518301\n",
      "epoch 28; iter: 0; batch classifier loss: 0.478640; batch adversarial loss: 0.544710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257485; batch adversarial loss: 0.466761\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157438; batch adversarial loss: 0.422897\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116058; batch adversarial loss: 0.361036\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140729; batch adversarial loss: 0.361692\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120206; batch adversarial loss: 0.438108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160787; batch adversarial loss: 0.403871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116253; batch adversarial loss: 0.435321\n",
      "epoch 36; iter: 0; batch classifier loss: 0.087630; batch adversarial loss: 0.484231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114658; batch adversarial loss: 0.472040\n",
      "epoch 38; iter: 0; batch classifier loss: 0.087535; batch adversarial loss: 0.543104\n",
      "epoch 39; iter: 0; batch classifier loss: 0.106333; batch adversarial loss: 0.452804\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088000; batch adversarial loss: 0.407620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115593; batch adversarial loss: 0.434188\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163413; batch adversarial loss: 0.418090\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114457; batch adversarial loss: 0.536917\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086162; batch adversarial loss: 0.482289\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101998; batch adversarial loss: 0.466172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131405; batch adversarial loss: 0.505941\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103730; batch adversarial loss: 0.476039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104888; batch adversarial loss: 0.466703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.114177; batch adversarial loss: 0.518832\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109126; batch adversarial loss: 0.465663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108531; batch adversarial loss: 0.417572\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101975; batch adversarial loss: 0.424477\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166810; batch adversarial loss: 0.430975\n",
      "epoch 54; iter: 0; batch classifier loss: 0.175233; batch adversarial loss: 0.502552\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178653; batch adversarial loss: 0.407092\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142505; batch adversarial loss: 0.552192\n",
      "epoch 57; iter: 0; batch classifier loss: 0.160800; batch adversarial loss: 0.507075\n",
      "epoch 58; iter: 0; batch classifier loss: 0.160035; batch adversarial loss: 0.494407\n",
      "epoch 59; iter: 0; batch classifier loss: 0.121529; batch adversarial loss: 0.522175\n",
      "epoch 60; iter: 0; batch classifier loss: 0.159008; batch adversarial loss: 0.473254\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164338; batch adversarial loss: 0.414410\n",
      "epoch 62; iter: 0; batch classifier loss: 0.167846; batch adversarial loss: 0.460182\n",
      "epoch 63; iter: 0; batch classifier loss: 0.143773; batch adversarial loss: 0.545752\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149216; batch adversarial loss: 0.475251\n",
      "epoch 65; iter: 0; batch classifier loss: 0.169485; batch adversarial loss: 0.502972\n",
      "epoch 66; iter: 0; batch classifier loss: 0.251525; batch adversarial loss: 0.440541\n",
      "epoch 67; iter: 0; batch classifier loss: 0.193712; batch adversarial loss: 0.438085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.252348; batch adversarial loss: 0.448739\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174824; batch adversarial loss: 0.464646\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122087; batch adversarial loss: 0.599798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.165060; batch adversarial loss: 0.420804\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179063; batch adversarial loss: 0.466816\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181598; batch adversarial loss: 0.507441\n",
      "epoch 74; iter: 0; batch classifier loss: 0.137610; batch adversarial loss: 0.530305\n",
      "epoch 75; iter: 0; batch classifier loss: 0.205553; batch adversarial loss: 0.456523\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170142; batch adversarial loss: 0.468235\n",
      "epoch 77; iter: 0; batch classifier loss: 0.168503; batch adversarial loss: 0.485932\n",
      "epoch 78; iter: 0; batch classifier loss: 0.151662; batch adversarial loss: 0.443215\n",
      "epoch 79; iter: 0; batch classifier loss: 0.263460; batch adversarial loss: 0.454151\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164699; batch adversarial loss: 0.441024\n",
      "epoch 81; iter: 0; batch classifier loss: 0.192251; batch adversarial loss: 0.509898\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189292; batch adversarial loss: 0.525187\n",
      "epoch 83; iter: 0; batch classifier loss: 0.213236; batch adversarial loss: 0.517456\n",
      "epoch 84; iter: 0; batch classifier loss: 0.201640; batch adversarial loss: 0.541943\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182796; batch adversarial loss: 0.436027\n",
      "epoch 86; iter: 0; batch classifier loss: 0.255040; batch adversarial loss: 0.541853\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153142; batch adversarial loss: 0.444467\n",
      "epoch 88; iter: 0; batch classifier loss: 0.224815; batch adversarial loss: 0.373212\n",
      "epoch 89; iter: 0; batch classifier loss: 0.169085; batch adversarial loss: 0.492790\n",
      "epoch 90; iter: 0; batch classifier loss: 0.220353; batch adversarial loss: 0.433992\n",
      "epoch 91; iter: 0; batch classifier loss: 0.243159; batch adversarial loss: 0.461996\n",
      "epoch 92; iter: 0; batch classifier loss: 0.204753; batch adversarial loss: 0.459416\n",
      "epoch 93; iter: 0; batch classifier loss: 0.263504; batch adversarial loss: 0.460149\n",
      "epoch 94; iter: 0; batch classifier loss: 0.215669; batch adversarial loss: 0.507877\n",
      "epoch 95; iter: 0; batch classifier loss: 0.243777; batch adversarial loss: 0.433904\n",
      "epoch 96; iter: 0; batch classifier loss: 0.289939; batch adversarial loss: 0.422199\n",
      "epoch 97; iter: 0; batch classifier loss: 0.119151; batch adversarial loss: 0.385168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.198292; batch adversarial loss: 0.483246\n",
      "epoch 99; iter: 0; batch classifier loss: 0.296595; batch adversarial loss: 0.520223\n",
      "epoch 100; iter: 0; batch classifier loss: 0.224543; batch adversarial loss: 0.458493\n",
      "epoch 101; iter: 0; batch classifier loss: 0.190712; batch adversarial loss: 0.459297\n",
      "epoch 102; iter: 0; batch classifier loss: 0.108756; batch adversarial loss: 0.470714\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216031; batch adversarial loss: 0.458345\n",
      "epoch 104; iter: 0; batch classifier loss: 0.170772; batch adversarial loss: 0.422758\n",
      "epoch 105; iter: 0; batch classifier loss: 0.233000; batch adversarial loss: 0.409679\n",
      "epoch 106; iter: 0; batch classifier loss: 0.220710; batch adversarial loss: 0.520244\n",
      "epoch 107; iter: 0; batch classifier loss: 0.213815; batch adversarial loss: 0.471502\n",
      "epoch 108; iter: 0; batch classifier loss: 0.182939; batch adversarial loss: 0.385254\n",
      "epoch 109; iter: 0; batch classifier loss: 0.208954; batch adversarial loss: 0.483002\n",
      "epoch 110; iter: 0; batch classifier loss: 0.244463; batch adversarial loss: 0.434195\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191883; batch adversarial loss: 0.495752\n",
      "epoch 112; iter: 0; batch classifier loss: 0.136732; batch adversarial loss: 0.470594\n",
      "epoch 113; iter: 0; batch classifier loss: 0.118846; batch adversarial loss: 0.461313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.200129; batch adversarial loss: 0.459981\n",
      "epoch 115; iter: 0; batch classifier loss: 0.202560; batch adversarial loss: 0.485995\n",
      "epoch 116; iter: 0; batch classifier loss: 0.171167; batch adversarial loss: 0.509717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.271081; batch adversarial loss: 0.385348\n",
      "epoch 118; iter: 0; batch classifier loss: 0.157152; batch adversarial loss: 0.544296\n",
      "epoch 119; iter: 0; batch classifier loss: 0.181504; batch adversarial loss: 0.484608\n",
      "epoch 120; iter: 0; batch classifier loss: 0.278767; batch adversarial loss: 0.422456\n",
      "epoch 121; iter: 0; batch classifier loss: 0.289763; batch adversarial loss: 0.520247\n",
      "epoch 122; iter: 0; batch classifier loss: 0.242241; batch adversarial loss: 0.520217\n",
      "epoch 123; iter: 0; batch classifier loss: 0.083362; batch adversarial loss: 0.518467\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057310; batch adversarial loss: 0.544172\n",
      "epoch 125; iter: 0; batch classifier loss: 0.076426; batch adversarial loss: 0.407357\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025748; batch adversarial loss: 0.506815\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066317; batch adversarial loss: 0.469445\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056144; batch adversarial loss: 0.483856\n",
      "epoch 129; iter: 0; batch classifier loss: 0.064568; batch adversarial loss: 0.383596\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031939; batch adversarial loss: 0.486051\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071716; batch adversarial loss: 0.425466\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054552; batch adversarial loss: 0.456883\n",
      "epoch 133; iter: 0; batch classifier loss: 0.066489; batch adversarial loss: 0.320593\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042235; batch adversarial loss: 0.363308\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050646; batch adversarial loss: 0.431177\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041135; batch adversarial loss: 0.425022\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049359; batch adversarial loss: 0.439572\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054003; batch adversarial loss: 0.394227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046898; batch adversarial loss: 0.549801\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054203; batch adversarial loss: 0.540169\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046496; batch adversarial loss: 0.503844\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058149; batch adversarial loss: 0.441580\n",
      "epoch 143; iter: 0; batch classifier loss: 0.058635; batch adversarial loss: 0.353228\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057211; batch adversarial loss: 0.534424\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037286; batch adversarial loss: 0.437875\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061167; batch adversarial loss: 0.405283\n",
      "epoch 147; iter: 0; batch classifier loss: 0.086635; batch adversarial loss: 0.348549\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050100; batch adversarial loss: 0.465523\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047666; batch adversarial loss: 0.451424\n",
      "epoch 150; iter: 0; batch classifier loss: 0.053707; batch adversarial loss: 0.538890\n",
      "epoch 151; iter: 0; batch classifier loss: 0.086705; batch adversarial loss: 0.498363\n",
      "epoch 152; iter: 0; batch classifier loss: 0.059418; batch adversarial loss: 0.381582\n",
      "epoch 153; iter: 0; batch classifier loss: 0.070198; batch adversarial loss: 0.410888\n",
      "epoch 154; iter: 0; batch classifier loss: 0.071714; batch adversarial loss: 0.466322\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048113; batch adversarial loss: 0.391068\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056242; batch adversarial loss: 0.513196\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041112; batch adversarial loss: 0.388436\n",
      "epoch 158; iter: 0; batch classifier loss: 0.086164; batch adversarial loss: 0.500785\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038078; batch adversarial loss: 0.478396\n",
      "epoch 160; iter: 0; batch classifier loss: 0.088121; batch adversarial loss: 0.435408\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043801; batch adversarial loss: 0.401704\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055863; batch adversarial loss: 0.403333\n",
      "epoch 163; iter: 0; batch classifier loss: 0.057353; batch adversarial loss: 0.411172\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059235; batch adversarial loss: 0.316524\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033024; batch adversarial loss: 0.444890\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062794; batch adversarial loss: 0.419654\n",
      "epoch 167; iter: 0; batch classifier loss: 0.062327; batch adversarial loss: 0.513851\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025272; batch adversarial loss: 0.377178\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038204; batch adversarial loss: 0.360145\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022316; batch adversarial loss: 0.374107\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055820; batch adversarial loss: 0.506654\n",
      "epoch 172; iter: 0; batch classifier loss: 0.055418; batch adversarial loss: 0.442423\n",
      "epoch 173; iter: 0; batch classifier loss: 0.067217; batch adversarial loss: 0.413030\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029750; batch adversarial loss: 0.470798\n",
      "epoch 175; iter: 0; batch classifier loss: 0.065998; batch adversarial loss: 0.329259\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034765; batch adversarial loss: 0.389828\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052936; batch adversarial loss: 0.495338\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052768; batch adversarial loss: 0.410341\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033966; batch adversarial loss: 0.342351\n",
      "epoch 180; iter: 0; batch classifier loss: 0.057201; batch adversarial loss: 0.424015\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049333; batch adversarial loss: 0.388979\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038006; batch adversarial loss: 0.409025\n",
      "epoch 183; iter: 0; batch classifier loss: 0.053551; batch adversarial loss: 0.346858\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039849; batch adversarial loss: 0.393081\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043948; batch adversarial loss: 0.332345\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041587; batch adversarial loss: 0.373310\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027561; batch adversarial loss: 0.404057\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068174; batch adversarial loss: 0.458594\n",
      "epoch 189; iter: 0; batch classifier loss: 0.054423; batch adversarial loss: 0.426005\n",
      "epoch 190; iter: 0; batch classifier loss: 0.085768; batch adversarial loss: 0.416311\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052477; batch adversarial loss: 0.355401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046203; batch adversarial loss: 0.467952\n",
      "epoch 193; iter: 0; batch classifier loss: 0.073563; batch adversarial loss: 0.369021\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032031; batch adversarial loss: 0.544384\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031188; batch adversarial loss: 0.432987\n",
      "epoch 196; iter: 0; batch classifier loss: 0.048093; batch adversarial loss: 0.444537\n",
      "epoch 197; iter: 0; batch classifier loss: 0.051090; batch adversarial loss: 0.434743\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054922; batch adversarial loss: 0.383522\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045239; batch adversarial loss: 0.479869\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696039; batch adversarial loss: 0.542509\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445022; batch adversarial loss: 0.587104\n",
      "epoch 2; iter: 0; batch classifier loss: 0.448939; batch adversarial loss: 0.624939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468201; batch adversarial loss: 0.611843\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377185; batch adversarial loss: 0.566132\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317647; batch adversarial loss: 0.594248\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421377; batch adversarial loss: 0.600714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309544; batch adversarial loss: 0.579397\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387223; batch adversarial loss: 0.548489\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398418; batch adversarial loss: 0.542461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.378895; batch adversarial loss: 0.506232\n",
      "epoch 11; iter: 0; batch classifier loss: 0.502049; batch adversarial loss: 0.520351\n",
      "epoch 12; iter: 0; batch classifier loss: 0.521488; batch adversarial loss: 0.602501\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584374; batch adversarial loss: 0.600517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.382590; batch adversarial loss: 0.503636\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327321; batch adversarial loss: 0.488764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242634; batch adversarial loss: 0.449494\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246204; batch adversarial loss: 0.495722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236113; batch adversarial loss: 0.475003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243153; batch adversarial loss: 0.563534\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233521; batch adversarial loss: 0.432149\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208507; batch adversarial loss: 0.466996\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189670; batch adversarial loss: 0.474146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190521; batch adversarial loss: 0.480924\n",
      "epoch 24; iter: 0; batch classifier loss: 0.119461; batch adversarial loss: 0.508589\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146866; batch adversarial loss: 0.503100\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223916; batch adversarial loss: 0.503883\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135112; batch adversarial loss: 0.388695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154460; batch adversarial loss: 0.509130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161419; batch adversarial loss: 0.379951\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155265; batch adversarial loss: 0.414553\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157855; batch adversarial loss: 0.368567\n",
      "epoch 32; iter: 0; batch classifier loss: 0.160035; batch adversarial loss: 0.426485\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190381; batch adversarial loss: 0.376514\n",
      "epoch 34; iter: 0; batch classifier loss: 0.191964; batch adversarial loss: 0.418937\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181726; batch adversarial loss: 0.430057\n",
      "epoch 36; iter: 0; batch classifier loss: 0.127083; batch adversarial loss: 0.387077\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145040; batch adversarial loss: 0.465982\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142495; batch adversarial loss: 0.439098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103052; batch adversarial loss: 0.500409\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116530; batch adversarial loss: 0.451926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.141521; batch adversarial loss: 0.408592\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097365; batch adversarial loss: 0.561510\n",
      "epoch 43; iter: 0; batch classifier loss: 0.146646; batch adversarial loss: 0.435575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.140449; batch adversarial loss: 0.520081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102382; batch adversarial loss: 0.469148\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122600; batch adversarial loss: 0.340990\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107454; batch adversarial loss: 0.469449\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129941; batch adversarial loss: 0.443695\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113059; batch adversarial loss: 0.447081\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109152; batch adversarial loss: 0.447231\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116818; batch adversarial loss: 0.447211\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110642; batch adversarial loss: 0.450608\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094811; batch adversarial loss: 0.496454\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131152; batch adversarial loss: 0.460521\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126478; batch adversarial loss: 0.441677\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114018; batch adversarial loss: 0.447441\n",
      "epoch 57; iter: 0; batch classifier loss: 0.071341; batch adversarial loss: 0.489727\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116308; batch adversarial loss: 0.461593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081571; batch adversarial loss: 0.546834\n",
      "epoch 60; iter: 0; batch classifier loss: 0.124901; batch adversarial loss: 0.421826\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115275; batch adversarial loss: 0.427760\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122501; batch adversarial loss: 0.408693\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096057; batch adversarial loss: 0.441446\n",
      "epoch 64; iter: 0; batch classifier loss: 0.109067; batch adversarial loss: 0.419240\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097128; batch adversarial loss: 0.456018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082747; batch adversarial loss: 0.522088\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055023; batch adversarial loss: 0.427921\n",
      "epoch 68; iter: 0; batch classifier loss: 0.142455; batch adversarial loss: 0.411593\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078539; batch adversarial loss: 0.430201\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082521; batch adversarial loss: 0.374259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.122138; batch adversarial loss: 0.485943\n",
      "epoch 72; iter: 0; batch classifier loss: 0.119583; batch adversarial loss: 0.531812\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074533; batch adversarial loss: 0.487431\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105935; batch adversarial loss: 0.523445\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054951; batch adversarial loss: 0.479526\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101314; batch adversarial loss: 0.459866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126328; batch adversarial loss: 0.485172\n",
      "epoch 78; iter: 0; batch classifier loss: 0.131638; batch adversarial loss: 0.506484\n",
      "epoch 79; iter: 0; batch classifier loss: 0.164055; batch adversarial loss: 0.396768\n",
      "epoch 80; iter: 0; batch classifier loss: 0.132052; batch adversarial loss: 0.444230\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152071; batch adversarial loss: 0.412549\n",
      "epoch 82; iter: 0; batch classifier loss: 0.106010; batch adversarial loss: 0.551825\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063911; batch adversarial loss: 0.518090\n",
      "epoch 84; iter: 0; batch classifier loss: 0.073788; batch adversarial loss: 0.459867\n",
      "epoch 85; iter: 0; batch classifier loss: 0.101161; batch adversarial loss: 0.324073\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087816; batch adversarial loss: 0.465364\n",
      "epoch 87; iter: 0; batch classifier loss: 0.113168; batch adversarial loss: 0.426528\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055370; batch adversarial loss: 0.467203\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120834; batch adversarial loss: 0.466212\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058218; batch adversarial loss: 0.510901\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085825; batch adversarial loss: 0.390356\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089363; batch adversarial loss: 0.503111\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076645; batch adversarial loss: 0.380559\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051285; batch adversarial loss: 0.452126\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055337; batch adversarial loss: 0.460623\n",
      "epoch 96; iter: 0; batch classifier loss: 0.128943; batch adversarial loss: 0.448639\n",
      "epoch 97; iter: 0; batch classifier loss: 0.097990; batch adversarial loss: 0.383305\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049131; batch adversarial loss: 0.443667\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067979; batch adversarial loss: 0.471022\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059785; batch adversarial loss: 0.410413\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070868; batch adversarial loss: 0.550158\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043649; batch adversarial loss: 0.388412\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083054; batch adversarial loss: 0.412084\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062932; batch adversarial loss: 0.485155\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064463; batch adversarial loss: 0.425326\n",
      "epoch 106; iter: 0; batch classifier loss: 0.163617; batch adversarial loss: 0.387192\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079406; batch adversarial loss: 0.452617\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062887; batch adversarial loss: 0.387381\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.482087\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027155; batch adversarial loss: 0.496936\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059442; batch adversarial loss: 0.432422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.054556; batch adversarial loss: 0.367405\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060856; batch adversarial loss: 0.493926\n",
      "epoch 114; iter: 0; batch classifier loss: 0.087430; batch adversarial loss: 0.357965\n",
      "epoch 115; iter: 0; batch classifier loss: 0.080440; batch adversarial loss: 0.501937\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045701; batch adversarial loss: 0.441551\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057978; batch adversarial loss: 0.492290\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085989; batch adversarial loss: 0.400420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032149; batch adversarial loss: 0.526127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057058; batch adversarial loss: 0.450143\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030778; batch adversarial loss: 0.438118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042967; batch adversarial loss: 0.401735\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063301; batch adversarial loss: 0.356603\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071544; batch adversarial loss: 0.465893\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.483409\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017776; batch adversarial loss: 0.505134\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049540; batch adversarial loss: 0.520706\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035736; batch adversarial loss: 0.330374\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043975; batch adversarial loss: 0.456536\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027905; batch adversarial loss: 0.507436\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032301; batch adversarial loss: 0.410555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030344; batch adversarial loss: 0.404236\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033914; batch adversarial loss: 0.445872\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035542; batch adversarial loss: 0.454314\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046833; batch adversarial loss: 0.473768\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050188; batch adversarial loss: 0.451068\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049409; batch adversarial loss: 0.415982\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059442; batch adversarial loss: 0.477944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037360; batch adversarial loss: 0.403536\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024729; batch adversarial loss: 0.479210\n",
      "epoch 141; iter: 0; batch classifier loss: 0.042814; batch adversarial loss: 0.432448\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022801; batch adversarial loss: 0.419484\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028804; batch adversarial loss: 0.413842\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034827; batch adversarial loss: 0.468568\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048704; batch adversarial loss: 0.438973\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008263; batch adversarial loss: 0.513931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037765; batch adversarial loss: 0.518568\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032910; batch adversarial loss: 0.409466\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017077; batch adversarial loss: 0.395940\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032363; batch adversarial loss: 0.435355\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016329; batch adversarial loss: 0.409802\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024484; batch adversarial loss: 0.489457\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015219; batch adversarial loss: 0.473764\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.498513\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025935; batch adversarial loss: 0.440476\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033627; batch adversarial loss: 0.471287\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028124; batch adversarial loss: 0.373815\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017631; batch adversarial loss: 0.483024\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049994; batch adversarial loss: 0.469168\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013323; batch adversarial loss: 0.432195\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043761; batch adversarial loss: 0.497491\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033741; batch adversarial loss: 0.399323\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030320; batch adversarial loss: 0.452750\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019889; batch adversarial loss: 0.373902\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018652; batch adversarial loss: 0.461017\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023307; batch adversarial loss: 0.436147\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022609; batch adversarial loss: 0.498896\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011578; batch adversarial loss: 0.528143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049860; batch adversarial loss: 0.544964\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029493; batch adversarial loss: 0.503868\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022583; batch adversarial loss: 0.469292\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024144; batch adversarial loss: 0.521870\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026113; batch adversarial loss: 0.461877\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020714; batch adversarial loss: 0.542557\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.416851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024407; batch adversarial loss: 0.557623\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009839; batch adversarial loss: 0.447168\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014267; batch adversarial loss: 0.468322\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035620; batch adversarial loss: 0.393185\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.442173\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025625; batch adversarial loss: 0.423119\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012427; batch adversarial loss: 0.437366\n",
      "epoch 183; iter: 0; batch classifier loss: 0.006805; batch adversarial loss: 0.501281\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027898; batch adversarial loss: 0.487775\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004256; batch adversarial loss: 0.468282\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035466; batch adversarial loss: 0.478361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016866; batch adversarial loss: 0.365584\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028696; batch adversarial loss: 0.413753\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007843; batch adversarial loss: 0.365960\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033330; batch adversarial loss: 0.406347\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035208; batch adversarial loss: 0.454880\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012373; batch adversarial loss: 0.410421\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012498; batch adversarial loss: 0.412399\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011366; batch adversarial loss: 0.460841\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009446; batch adversarial loss: 0.544844\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022933; batch adversarial loss: 0.414802\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023376; batch adversarial loss: 0.474004\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014959; batch adversarial loss: 0.391802\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023753; batch adversarial loss: 0.361955\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675643; batch adversarial loss: 0.788964\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419552; batch adversarial loss: 0.820286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383217; batch adversarial loss: 0.790740\n",
      "epoch 3; iter: 0; batch classifier loss: 0.315217; batch adversarial loss: 0.709036\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354655; batch adversarial loss: 0.651557\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392214; batch adversarial loss: 0.650917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307836; batch adversarial loss: 0.599844\n",
      "epoch 7; iter: 0; batch classifier loss: 0.305494; batch adversarial loss: 0.600185\n",
      "epoch 8; iter: 0; batch classifier loss: 0.242157; batch adversarial loss: 0.596544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.255023; batch adversarial loss: 0.541410\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231498; batch adversarial loss: 0.537025\n",
      "epoch 11; iter: 0; batch classifier loss: 0.255950; batch adversarial loss: 0.496917\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342553; batch adversarial loss: 0.469342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.230159; batch adversarial loss: 0.480673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245459; batch adversarial loss: 0.511759\n",
      "epoch 15; iter: 0; batch classifier loss: 0.261286; batch adversarial loss: 0.467519\n",
      "epoch 16; iter: 0; batch classifier loss: 0.223928; batch adversarial loss: 0.435016\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242152; batch adversarial loss: 0.519234\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190759; batch adversarial loss: 0.365955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217200; batch adversarial loss: 0.391400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.239628; batch adversarial loss: 0.418763\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194751; batch adversarial loss: 0.422745\n",
      "epoch 22; iter: 0; batch classifier loss: 0.211637; batch adversarial loss: 0.443857\n",
      "epoch 23; iter: 0; batch classifier loss: 0.169639; batch adversarial loss: 0.514930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185458; batch adversarial loss: 0.449423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.136373; batch adversarial loss: 0.439304\n",
      "epoch 26; iter: 0; batch classifier loss: 0.206536; batch adversarial loss: 0.423143\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199894; batch adversarial loss: 0.406916\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151807; batch adversarial loss: 0.410013\n",
      "epoch 29; iter: 0; batch classifier loss: 0.137221; batch adversarial loss: 0.401323\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179574; batch adversarial loss: 0.411139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143879; batch adversarial loss: 0.373459\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133605; batch adversarial loss: 0.396694\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201796; batch adversarial loss: 0.407247\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148368; batch adversarial loss: 0.461811\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162024; batch adversarial loss: 0.426173\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148580; batch adversarial loss: 0.440895\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136743; batch adversarial loss: 0.371524\n",
      "epoch 38; iter: 0; batch classifier loss: 0.102232; batch adversarial loss: 0.407795\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129085; batch adversarial loss: 0.383673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.203500; batch adversarial loss: 0.395498\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116044; batch adversarial loss: 0.409027\n",
      "epoch 42; iter: 0; batch classifier loss: 0.124199; batch adversarial loss: 0.372803\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124592; batch adversarial loss: 0.321500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.089208; batch adversarial loss: 0.451322\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090692; batch adversarial loss: 0.494904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095214; batch adversarial loss: 0.416392\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106039; batch adversarial loss: 0.347683\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101570; batch adversarial loss: 0.358739\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096241; batch adversarial loss: 0.450711\n",
      "epoch 50; iter: 0; batch classifier loss: 0.122310; batch adversarial loss: 0.393576\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106949; batch adversarial loss: 0.401518\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099923; batch adversarial loss: 0.453719\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095039; batch adversarial loss: 0.440853\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085510; batch adversarial loss: 0.408374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093234; batch adversarial loss: 0.427131\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078338; batch adversarial loss: 0.377059\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089058; batch adversarial loss: 0.379794\n",
      "epoch 58; iter: 0; batch classifier loss: 0.108288; batch adversarial loss: 0.425497\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092743; batch adversarial loss: 0.350863\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092591; batch adversarial loss: 0.436174\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108596; batch adversarial loss: 0.443434\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113749; batch adversarial loss: 0.419304\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084809; batch adversarial loss: 0.438691\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070147; batch adversarial loss: 0.390628\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060303; batch adversarial loss: 0.387402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098238; batch adversarial loss: 0.388051\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068814; batch adversarial loss: 0.413143\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078814; batch adversarial loss: 0.320772\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092382; batch adversarial loss: 0.436877\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061474; batch adversarial loss: 0.438195\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060260; batch adversarial loss: 0.438470\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109557; batch adversarial loss: 0.355392\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042710; batch adversarial loss: 0.395176\n",
      "epoch 74; iter: 0; batch classifier loss: 0.045033; batch adversarial loss: 0.376561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075252; batch adversarial loss: 0.372013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071443; batch adversarial loss: 0.411106\n",
      "epoch 77; iter: 0; batch classifier loss: 0.050567; batch adversarial loss: 0.396569\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074054; batch adversarial loss: 0.387145\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062190; batch adversarial loss: 0.469843\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059706; batch adversarial loss: 0.454095\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058447; batch adversarial loss: 0.454402\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090961; batch adversarial loss: 0.437328\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060635; batch adversarial loss: 0.495964\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075440; batch adversarial loss: 0.446056\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078499; batch adversarial loss: 0.333981\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041867; batch adversarial loss: 0.438178\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075091; batch adversarial loss: 0.431460\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052265; batch adversarial loss: 0.479744\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045799; batch adversarial loss: 0.401935\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042932; batch adversarial loss: 0.415363\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036984; batch adversarial loss: 0.343386\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038970; batch adversarial loss: 0.411062\n",
      "epoch 93; iter: 0; batch classifier loss: 0.018618; batch adversarial loss: 0.419265\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036711; batch adversarial loss: 0.492191\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046182; batch adversarial loss: 0.382338\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048019; batch adversarial loss: 0.455768\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042499; batch adversarial loss: 0.424965\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043944; batch adversarial loss: 0.437077\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056109; batch adversarial loss: 0.382533\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035617; batch adversarial loss: 0.421386\n",
      "epoch 101; iter: 0; batch classifier loss: 0.021550; batch adversarial loss: 0.447505\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026005; batch adversarial loss: 0.464307\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029009; batch adversarial loss: 0.435797\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.492543\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.427604\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038528; batch adversarial loss: 0.437484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.055964; batch adversarial loss: 0.463168\n",
      "epoch 108; iter: 0; batch classifier loss: 0.114564; batch adversarial loss: 0.670358\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053749; batch adversarial loss: 0.503961\n",
      "epoch 110; iter: 0; batch classifier loss: 0.130803; batch adversarial loss: 0.642380\n",
      "epoch 111; iter: 0; batch classifier loss: 0.080414; batch adversarial loss: 0.552723\n",
      "epoch 112; iter: 0; batch classifier loss: 0.164141; batch adversarial loss: 0.727706\n",
      "epoch 113; iter: 0; batch classifier loss: 0.145895; batch adversarial loss: 0.675251\n",
      "epoch 114; iter: 0; batch classifier loss: 0.156542; batch adversarial loss: 0.674172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.174166; batch adversarial loss: 0.583532\n",
      "epoch 116; iter: 0; batch classifier loss: 0.146876; batch adversarial loss: 0.583008\n",
      "epoch 117; iter: 0; batch classifier loss: 0.189043; batch adversarial loss: 0.602076\n",
      "epoch 118; iter: 0; batch classifier loss: 0.114572; batch adversarial loss: 0.486714\n",
      "epoch 119; iter: 0; batch classifier loss: 0.118786; batch adversarial loss: 0.491354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.141571; batch adversarial loss: 0.638688\n",
      "epoch 121; iter: 0; batch classifier loss: 0.140901; batch adversarial loss: 0.591426\n",
      "epoch 122; iter: 0; batch classifier loss: 0.171156; batch adversarial loss: 0.529710\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.495661\n",
      "epoch 124; iter: 0; batch classifier loss: 0.166986; batch adversarial loss: 0.580041\n",
      "epoch 125; iter: 0; batch classifier loss: 0.096353; batch adversarial loss: 0.414021\n",
      "epoch 126; iter: 0; batch classifier loss: 0.169514; batch adversarial loss: 0.635666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.166691; batch adversarial loss: 0.543490\n",
      "epoch 128; iter: 0; batch classifier loss: 0.115189; batch adversarial loss: 0.548796\n",
      "epoch 129; iter: 0; batch classifier loss: 0.179400; batch adversarial loss: 0.565188\n",
      "epoch 130; iter: 0; batch classifier loss: 0.181446; batch adversarial loss: 0.656724\n",
      "epoch 131; iter: 0; batch classifier loss: 0.115539; batch adversarial loss: 0.526690\n",
      "epoch 132; iter: 0; batch classifier loss: 0.167547; batch adversarial loss: 0.557126\n",
      "epoch 133; iter: 0; batch classifier loss: 0.094942; batch adversarial loss: 0.433434\n",
      "epoch 134; iter: 0; batch classifier loss: 0.123161; batch adversarial loss: 0.502279\n",
      "epoch 135; iter: 0; batch classifier loss: 0.111014; batch adversarial loss: 0.485250\n",
      "epoch 136; iter: 0; batch classifier loss: 0.084280; batch adversarial loss: 0.424921\n",
      "epoch 137; iter: 0; batch classifier loss: 0.164810; batch adversarial loss: 0.533394\n",
      "epoch 138; iter: 0; batch classifier loss: 0.132107; batch adversarial loss: 0.456594\n",
      "epoch 139; iter: 0; batch classifier loss: 0.132391; batch adversarial loss: 0.441986\n",
      "epoch 140; iter: 0; batch classifier loss: 0.131110; batch adversarial loss: 0.554272\n",
      "epoch 141; iter: 0; batch classifier loss: 0.094618; batch adversarial loss: 0.538189\n",
      "epoch 142; iter: 0; batch classifier loss: 0.118382; batch adversarial loss: 0.529387\n",
      "epoch 143; iter: 0; batch classifier loss: 0.071468; batch adversarial loss: 0.436942\n",
      "epoch 144; iter: 0; batch classifier loss: 0.165367; batch adversarial loss: 0.512248\n",
      "epoch 145; iter: 0; batch classifier loss: 0.140592; batch adversarial loss: 0.580095\n",
      "epoch 146; iter: 0; batch classifier loss: 0.115119; batch adversarial loss: 0.415155\n",
      "epoch 147; iter: 0; batch classifier loss: 0.142173; batch adversarial loss: 0.549376\n",
      "epoch 148; iter: 0; batch classifier loss: 0.090577; batch adversarial loss: 0.457684\n",
      "epoch 149; iter: 0; batch classifier loss: 0.134870; batch adversarial loss: 0.408150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030916; batch adversarial loss: 0.446516\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045357; batch adversarial loss: 0.553903\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041985; batch adversarial loss: 0.518233\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052507; batch adversarial loss: 0.479969\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017362; batch adversarial loss: 0.486182\n",
      "epoch 155; iter: 0; batch classifier loss: 0.070731; batch adversarial loss: 0.401162\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039859; batch adversarial loss: 0.419483\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010626; batch adversarial loss: 0.459367\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.523290\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037104; batch adversarial loss: 0.441481\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032772; batch adversarial loss: 0.474845\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035043; batch adversarial loss: 0.488447\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043111; batch adversarial loss: 0.404501\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037190; batch adversarial loss: 0.519629\n",
      "epoch 164; iter: 0; batch classifier loss: 0.048582; batch adversarial loss: 0.494815\n",
      "epoch 165; iter: 0; batch classifier loss: 0.102457; batch adversarial loss: 0.411616\n",
      "epoch 166; iter: 0; batch classifier loss: 0.062296; batch adversarial loss: 0.400719\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045135; batch adversarial loss: 0.422775\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022236; batch adversarial loss: 0.445258\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024557; batch adversarial loss: 0.421004\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045428; batch adversarial loss: 0.469505\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049807; batch adversarial loss: 0.501700\n",
      "epoch 172; iter: 0; batch classifier loss: 0.101662; batch adversarial loss: 0.475385\n",
      "epoch 173; iter: 0; batch classifier loss: 0.051756; batch adversarial loss: 0.492395\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046722; batch adversarial loss: 0.430203\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058834; batch adversarial loss: 0.507568\n",
      "epoch 176; iter: 0; batch classifier loss: 0.056529; batch adversarial loss: 0.517243\n",
      "epoch 177; iter: 0; batch classifier loss: 0.089017; batch adversarial loss: 0.401993\n",
      "epoch 178; iter: 0; batch classifier loss: 0.090289; batch adversarial loss: 0.512842\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021549; batch adversarial loss: 0.462128\n",
      "epoch 180; iter: 0; batch classifier loss: 0.068734; batch adversarial loss: 0.487488\n",
      "epoch 181; iter: 0; batch classifier loss: 0.070101; batch adversarial loss: 0.432142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.070723; batch adversarial loss: 0.456408\n",
      "epoch 183; iter: 0; batch classifier loss: 0.077479; batch adversarial loss: 0.489638\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041309; batch adversarial loss: 0.463042\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.426393\n",
      "epoch 186; iter: 0; batch classifier loss: 0.072725; batch adversarial loss: 0.482986\n",
      "epoch 187; iter: 0; batch classifier loss: 0.086007; batch adversarial loss: 0.466000\n",
      "epoch 188; iter: 0; batch classifier loss: 0.068954; batch adversarial loss: 0.512987\n",
      "epoch 189; iter: 0; batch classifier loss: 0.039361; batch adversarial loss: 0.411364\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074765; batch adversarial loss: 0.417609\n",
      "epoch 191; iter: 0; batch classifier loss: 0.083814; batch adversarial loss: 0.439883\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033422; batch adversarial loss: 0.349543\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049082; batch adversarial loss: 0.539173\n",
      "epoch 194; iter: 0; batch classifier loss: 0.059353; batch adversarial loss: 0.380684\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037247; batch adversarial loss: 0.512787\n",
      "epoch 196; iter: 0; batch classifier loss: 0.086577; batch adversarial loss: 0.437005\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045882; batch adversarial loss: 0.375210\n",
      "epoch 198; iter: 0; batch classifier loss: 0.059818; batch adversarial loss: 0.467577\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048221; batch adversarial loss: 0.476459\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679085; batch adversarial loss: 0.659692\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469816; batch adversarial loss: 0.628673\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383029; batch adversarial loss: 0.600458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.291464; batch adversarial loss: 0.587109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.305766; batch adversarial loss: 0.537864\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.535579\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280906; batch adversarial loss: 0.507123\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271267; batch adversarial loss: 0.506895\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339959; batch adversarial loss: 0.477099\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233922; batch adversarial loss: 0.450884\n",
      "epoch 10; iter: 0; batch classifier loss: 0.247668; batch adversarial loss: 0.510430\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253920; batch adversarial loss: 0.425622\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303279; batch adversarial loss: 0.473997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219591; batch adversarial loss: 0.514883\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241908; batch adversarial loss: 0.469868\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223672; batch adversarial loss: 0.415842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.188501; batch adversarial loss: 0.421936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197943; batch adversarial loss: 0.511194\n",
      "epoch 18; iter: 0; batch classifier loss: 0.167289; batch adversarial loss: 0.494034\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262609; batch adversarial loss: 0.540052\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204653; batch adversarial loss: 0.538447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140344; batch adversarial loss: 0.528944\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245925; batch adversarial loss: 0.540070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.272055; batch adversarial loss: 0.561278\n",
      "epoch 24; iter: 0; batch classifier loss: 0.204155; batch adversarial loss: 0.447118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237518; batch adversarial loss: 0.558349\n",
      "epoch 26; iter: 0; batch classifier loss: 0.227064; batch adversarial loss: 0.455459\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325301; batch adversarial loss: 0.532106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462000; batch adversarial loss: 0.457067\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216129; batch adversarial loss: 0.485829\n",
      "epoch 30; iter: 0; batch classifier loss: 0.189674; batch adversarial loss: 0.480671\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131828; batch adversarial loss: 0.464706\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163164; batch adversarial loss: 0.448752\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125920; batch adversarial loss: 0.498232\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123155; batch adversarial loss: 0.476861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112040; batch adversarial loss: 0.486410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131942; batch adversarial loss: 0.396465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110701; batch adversarial loss: 0.429544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.102499; batch adversarial loss: 0.434823\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140509; batch adversarial loss: 0.360388\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100792; batch adversarial loss: 0.333899\n",
      "epoch 41; iter: 0; batch classifier loss: 0.062609; batch adversarial loss: 0.432808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117014; batch adversarial loss: 0.424018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063437; batch adversarial loss: 0.394107\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092787; batch adversarial loss: 0.399929\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099681; batch adversarial loss: 0.446815\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069446; batch adversarial loss: 0.533299\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103719; batch adversarial loss: 0.439547\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099778; batch adversarial loss: 0.444011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.078203; batch adversarial loss: 0.515871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073105; batch adversarial loss: 0.448047\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086874; batch adversarial loss: 0.461811\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071515; batch adversarial loss: 0.444527\n",
      "epoch 53; iter: 0; batch classifier loss: 0.063409; batch adversarial loss: 0.581931\n",
      "epoch 54; iter: 0; batch classifier loss: 0.055742; batch adversarial loss: 0.498263\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093169; batch adversarial loss: 0.497247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098602; batch adversarial loss: 0.452504\n",
      "epoch 57; iter: 0; batch classifier loss: 0.075103; batch adversarial loss: 0.392601\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102650; batch adversarial loss: 0.367238\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099106; batch adversarial loss: 0.407258\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079263; batch adversarial loss: 0.572655\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069156; batch adversarial loss: 0.448557\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053219; batch adversarial loss: 0.427967\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082864; batch adversarial loss: 0.392182\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082916; batch adversarial loss: 0.465527\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057502; batch adversarial loss: 0.414028\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091765; batch adversarial loss: 0.381626\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111130; batch adversarial loss: 0.452463\n",
      "epoch 68; iter: 0; batch classifier loss: 0.046082; batch adversarial loss: 0.567820\n",
      "epoch 69; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.499286\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063502; batch adversarial loss: 0.492074\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050706; batch adversarial loss: 0.500406\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051475; batch adversarial loss: 0.426562\n",
      "epoch 73; iter: 0; batch classifier loss: 0.045296; batch adversarial loss: 0.454211\n",
      "epoch 74; iter: 0; batch classifier loss: 0.037716; batch adversarial loss: 0.435154\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065556; batch adversarial loss: 0.390358\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088760; batch adversarial loss: 0.370858\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053204; batch adversarial loss: 0.417645\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043439; batch adversarial loss: 0.499711\n",
      "epoch 79; iter: 0; batch classifier loss: 0.046503; batch adversarial loss: 0.598689\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076564; batch adversarial loss: 0.503745\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072153; batch adversarial loss: 0.383209\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034787; batch adversarial loss: 0.462034\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044887; batch adversarial loss: 0.442426\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093747; batch adversarial loss: 0.441582\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089407; batch adversarial loss: 0.362609\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047309; batch adversarial loss: 0.456235\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059763; batch adversarial loss: 0.408562\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040308; batch adversarial loss: 0.458526\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050745; batch adversarial loss: 0.443199\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042214; batch adversarial loss: 0.442994\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064033; batch adversarial loss: 0.493362\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038789; batch adversarial loss: 0.384583\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086750; batch adversarial loss: 0.433977\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068781; batch adversarial loss: 0.434251\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.446347\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041249; batch adversarial loss: 0.449056\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084109; batch adversarial loss: 0.433445\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046847; batch adversarial loss: 0.496817\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031364; batch adversarial loss: 0.513471\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039652; batch adversarial loss: 0.367805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.065897; batch adversarial loss: 0.440326\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039173; batch adversarial loss: 0.423448\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039608; batch adversarial loss: 0.468547\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072604; batch adversarial loss: 0.445801\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053866; batch adversarial loss: 0.437534\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051146; batch adversarial loss: 0.484634\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044862; batch adversarial loss: 0.503618\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043159; batch adversarial loss: 0.423125\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024876; batch adversarial loss: 0.444969\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057530; batch adversarial loss: 0.313203\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047535; batch adversarial loss: 0.469280\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035200; batch adversarial loss: 0.408922\n",
      "epoch 113; iter: 0; batch classifier loss: 0.017720; batch adversarial loss: 0.388885\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039121; batch adversarial loss: 0.377454\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090716; batch adversarial loss: 0.433330\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033375; batch adversarial loss: 0.401129\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032705; batch adversarial loss: 0.405382\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037118; batch adversarial loss: 0.581845\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019548; batch adversarial loss: 0.476836\n",
      "epoch 120; iter: 0; batch classifier loss: 0.015484; batch adversarial loss: 0.455982\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057585; batch adversarial loss: 0.389052\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.596117\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026929; batch adversarial loss: 0.454213\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023008; batch adversarial loss: 0.492795\n",
      "epoch 125; iter: 0; batch classifier loss: 0.031289; batch adversarial loss: 0.400452\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039719; batch adversarial loss: 0.480714\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021250; batch adversarial loss: 0.360397\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015068; batch adversarial loss: 0.435075\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045258; batch adversarial loss: 0.335811\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033923; batch adversarial loss: 0.449393\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024476; batch adversarial loss: 0.400785\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.468756\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028337; batch adversarial loss: 0.505970\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.400393\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060866; batch adversarial loss: 0.425090\n",
      "epoch 136; iter: 0; batch classifier loss: 0.007599; batch adversarial loss: 0.431028\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028353; batch adversarial loss: 0.484131\n",
      "epoch 138; iter: 0; batch classifier loss: 0.009109; batch adversarial loss: 0.439159\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034326; batch adversarial loss: 0.455501\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029362; batch adversarial loss: 0.498720\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057503; batch adversarial loss: 0.376697\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023684; batch adversarial loss: 0.415841\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020821; batch adversarial loss: 0.425062\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039379; batch adversarial loss: 0.458436\n",
      "epoch 145; iter: 0; batch classifier loss: 0.083503; batch adversarial loss: 0.425568\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.513119\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022972; batch adversarial loss: 0.485468\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012451; batch adversarial loss: 0.537722\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019544; batch adversarial loss: 0.447055\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031871; batch adversarial loss: 0.472791\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033480; batch adversarial loss: 0.470132\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070266; batch adversarial loss: 0.426935\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025901; batch adversarial loss: 0.491207\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013763; batch adversarial loss: 0.455065\n",
      "epoch 155; iter: 0; batch classifier loss: 0.065642; batch adversarial loss: 0.406293\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016785; batch adversarial loss: 0.447268\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056928; batch adversarial loss: 0.343027\n",
      "epoch 158; iter: 0; batch classifier loss: 0.006048; batch adversarial loss: 0.376696\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013731; batch adversarial loss: 0.392657\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025235; batch adversarial loss: 0.502717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024971; batch adversarial loss: 0.464179\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018930; batch adversarial loss: 0.499607\n",
      "epoch 163; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.414211\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014990; batch adversarial loss: 0.440038\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038226; batch adversarial loss: 0.445435\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023577; batch adversarial loss: 0.419798\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021993; batch adversarial loss: 0.427786\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018226; batch adversarial loss: 0.404792\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027671; batch adversarial loss: 0.485065\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012827; batch adversarial loss: 0.378841\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011614; batch adversarial loss: 0.457366\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040010; batch adversarial loss: 0.379625\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025516; batch adversarial loss: 0.442766\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015709; batch adversarial loss: 0.407408\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014965; batch adversarial loss: 0.515225\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026655; batch adversarial loss: 0.518811\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009542; batch adversarial loss: 0.561355\n",
      "epoch 178; iter: 0; batch classifier loss: 0.054871; batch adversarial loss: 0.496937\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019251; batch adversarial loss: 0.514021\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026862; batch adversarial loss: 0.399336\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025019; batch adversarial loss: 0.499453\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021971; batch adversarial loss: 0.449457\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013037; batch adversarial loss: 0.457597\n",
      "epoch 184; iter: 0; batch classifier loss: 0.028488; batch adversarial loss: 0.464683\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043796; batch adversarial loss: 0.430839\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009761; batch adversarial loss: 0.486348\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034727; batch adversarial loss: 0.414774\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015926; batch adversarial loss: 0.466110\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036786; batch adversarial loss: 0.367339\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028876; batch adversarial loss: 0.404826\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018275; batch adversarial loss: 0.484414\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016387; batch adversarial loss: 0.504982\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007520; batch adversarial loss: 0.438947\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006149; batch adversarial loss: 0.468490\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021693; batch adversarial loss: 0.384130\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011168; batch adversarial loss: 0.410546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.014619; batch adversarial loss: 0.475435\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018874; batch adversarial loss: 0.501299\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015384; batch adversarial loss: 0.392697\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691326; batch adversarial loss: 0.811418\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430236; batch adversarial loss: 0.829320\n",
      "epoch 2; iter: 0; batch classifier loss: 0.445880; batch adversarial loss: 0.793801\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362439; batch adversarial loss: 0.715501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.332317; batch adversarial loss: 0.685941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331340; batch adversarial loss: 0.668852\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320257; batch adversarial loss: 0.669251\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290012; batch adversarial loss: 0.609572\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289668; batch adversarial loss: 0.556985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323090; batch adversarial loss: 0.554181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274896; batch adversarial loss: 0.555266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315470; batch adversarial loss: 0.462389\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270237; batch adversarial loss: 0.478767\n",
      "epoch 13; iter: 0; batch classifier loss: 0.230154; batch adversarial loss: 0.463972\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318372; batch adversarial loss: 0.437262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.227497; batch adversarial loss: 0.417919\n",
      "epoch 16; iter: 0; batch classifier loss: 0.198535; batch adversarial loss: 0.457622\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241094; batch adversarial loss: 0.445368\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205054; batch adversarial loss: 0.384905\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176406; batch adversarial loss: 0.409091\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217793; batch adversarial loss: 0.508407\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169659; batch adversarial loss: 0.396181\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168146; batch adversarial loss: 0.415651\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159199; batch adversarial loss: 0.465953\n",
      "epoch 24; iter: 0; batch classifier loss: 0.117751; batch adversarial loss: 0.600335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121238; batch adversarial loss: 0.461595\n",
      "epoch 26; iter: 0; batch classifier loss: 0.113927; batch adversarial loss: 0.400583\n",
      "epoch 27; iter: 0; batch classifier loss: 0.155533; batch adversarial loss: 0.391012\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143264; batch adversarial loss: 0.437590\n",
      "epoch 29; iter: 0; batch classifier loss: 0.075282; batch adversarial loss: 0.400022\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132091; batch adversarial loss: 0.437822\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124073; batch adversarial loss: 0.434315\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112560; batch adversarial loss: 0.389563\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107387; batch adversarial loss: 0.484251\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106008; batch adversarial loss: 0.410717\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116554; batch adversarial loss: 0.442137\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125530; batch adversarial loss: 0.412604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110616; batch adversarial loss: 0.379886\n",
      "epoch 38; iter: 0; batch classifier loss: 0.097590; batch adversarial loss: 0.354381\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131037; batch adversarial loss: 0.470130\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119742; batch adversarial loss: 0.420838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110612; batch adversarial loss: 0.364548\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096998; batch adversarial loss: 0.385126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095755; batch adversarial loss: 0.366763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097750; batch adversarial loss: 0.336637\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117777; batch adversarial loss: 0.394536\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101821; batch adversarial loss: 0.369569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101151; batch adversarial loss: 0.466108\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092915; batch adversarial loss: 0.384991\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107406; batch adversarial loss: 0.379523\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112280; batch adversarial loss: 0.412367\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087587; batch adversarial loss: 0.408345\n",
      "epoch 52; iter: 0; batch classifier loss: 0.153837; batch adversarial loss: 0.513062\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117210; batch adversarial loss: 0.393181\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133784; batch adversarial loss: 0.494395\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082047; batch adversarial loss: 0.395041\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116832; batch adversarial loss: 0.381392\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079410; batch adversarial loss: 0.393721\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103914; batch adversarial loss: 0.405302\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099181; batch adversarial loss: 0.408042\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054371; batch adversarial loss: 0.279704\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090345; batch adversarial loss: 0.419857\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074964; batch adversarial loss: 0.337203\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096935; batch adversarial loss: 0.470836\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076262; batch adversarial loss: 0.404131\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.400614\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075407; batch adversarial loss: 0.368267\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074722; batch adversarial loss: 0.365783\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059383; batch adversarial loss: 0.424901\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057072; batch adversarial loss: 0.386935\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072731; batch adversarial loss: 0.458374\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054448; batch adversarial loss: 0.471266\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095856; batch adversarial loss: 0.369743\n",
      "epoch 73; iter: 0; batch classifier loss: 0.047214; batch adversarial loss: 0.425600\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049540; batch adversarial loss: 0.396086\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065549; batch adversarial loss: 0.469803\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067470; batch adversarial loss: 0.326224\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044705; batch adversarial loss: 0.367481\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048831; batch adversarial loss: 0.483977\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049772; batch adversarial loss: 0.465994\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046322; batch adversarial loss: 0.399343\n",
      "epoch 81; iter: 0; batch classifier loss: 0.034211; batch adversarial loss: 0.453588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058479; batch adversarial loss: 0.465194\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054624; batch adversarial loss: 0.404328\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054960; batch adversarial loss: 0.451410\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056144; batch adversarial loss: 0.426501\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056073; batch adversarial loss: 0.390561\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032350; batch adversarial loss: 0.418360\n",
      "epoch 88; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.452959\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060149; batch adversarial loss: 0.470481\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047488; batch adversarial loss: 0.366728\n",
      "epoch 91; iter: 0; batch classifier loss: 0.024828; batch adversarial loss: 0.472317\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040661; batch adversarial loss: 0.483896\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072546; batch adversarial loss: 0.511833\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047724; batch adversarial loss: 0.469692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.039050; batch adversarial loss: 0.430723\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035810; batch adversarial loss: 0.445571\n",
      "epoch 97; iter: 0; batch classifier loss: 0.018879; batch adversarial loss: 0.380784\n",
      "epoch 98; iter: 0; batch classifier loss: 0.021386; batch adversarial loss: 0.440478\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053281; batch adversarial loss: 0.346809\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046276; batch adversarial loss: 0.460104\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047628; batch adversarial loss: 0.477919\n",
      "epoch 102; iter: 0; batch classifier loss: 0.086562; batch adversarial loss: 0.463117\n",
      "epoch 103; iter: 0; batch classifier loss: 0.128832; batch adversarial loss: 0.641572\n",
      "epoch 104; iter: 0; batch classifier loss: 0.068763; batch adversarial loss: 0.559542\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040022; batch adversarial loss: 0.463702\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095633; batch adversarial loss: 0.559877\n",
      "epoch 107; iter: 0; batch classifier loss: 0.108835; batch adversarial loss: 0.557584\n",
      "epoch 108; iter: 0; batch classifier loss: 0.088645; batch adversarial loss: 0.521014\n",
      "epoch 109; iter: 0; batch classifier loss: 0.124979; batch adversarial loss: 0.570391\n",
      "epoch 110; iter: 0; batch classifier loss: 0.132441; batch adversarial loss: 0.604800\n",
      "epoch 111; iter: 0; batch classifier loss: 0.150126; batch adversarial loss: 0.583216\n",
      "epoch 112; iter: 0; batch classifier loss: 0.088136; batch adversarial loss: 0.510322\n",
      "epoch 113; iter: 0; batch classifier loss: 0.212589; batch adversarial loss: 0.829705\n",
      "epoch 114; iter: 0; batch classifier loss: 0.103394; batch adversarial loss: 0.481630\n",
      "epoch 115; iter: 0; batch classifier loss: 0.168245; batch adversarial loss: 0.635593\n",
      "epoch 116; iter: 0; batch classifier loss: 0.137565; batch adversarial loss: 0.471403\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087286; batch adversarial loss: 0.444602\n",
      "epoch 118; iter: 0; batch classifier loss: 0.131590; batch adversarial loss: 0.562012\n",
      "epoch 119; iter: 0; batch classifier loss: 0.153281; batch adversarial loss: 0.577079\n",
      "epoch 120; iter: 0; batch classifier loss: 0.204274; batch adversarial loss: 0.609576\n",
      "epoch 121; iter: 0; batch classifier loss: 0.163749; batch adversarial loss: 0.520186\n",
      "epoch 122; iter: 0; batch classifier loss: 0.180121; batch adversarial loss: 0.525141\n",
      "epoch 123; iter: 0; batch classifier loss: 0.105822; batch adversarial loss: 0.420347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.165156; batch adversarial loss: 0.634673\n",
      "epoch 125; iter: 0; batch classifier loss: 0.156916; batch adversarial loss: 0.571806\n",
      "epoch 126; iter: 0; batch classifier loss: 0.248638; batch adversarial loss: 0.678356\n",
      "epoch 127; iter: 0; batch classifier loss: 0.160223; batch adversarial loss: 0.524290\n",
      "epoch 128; iter: 0; batch classifier loss: 0.135356; batch adversarial loss: 0.542584\n",
      "epoch 129; iter: 0; batch classifier loss: 0.118031; batch adversarial loss: 0.512511\n",
      "epoch 130; iter: 0; batch classifier loss: 0.120508; batch adversarial loss: 0.535248\n",
      "epoch 131; iter: 0; batch classifier loss: 0.181968; batch adversarial loss: 0.508859\n",
      "epoch 132; iter: 0; batch classifier loss: 0.170419; batch adversarial loss: 0.547985\n",
      "epoch 133; iter: 0; batch classifier loss: 0.139387; batch adversarial loss: 0.546804\n",
      "epoch 134; iter: 0; batch classifier loss: 0.120970; batch adversarial loss: 0.477496\n",
      "epoch 135; iter: 0; batch classifier loss: 0.153320; batch adversarial loss: 0.522580\n",
      "epoch 136; iter: 0; batch classifier loss: 0.169792; batch adversarial loss: 0.539200\n",
      "epoch 137; iter: 0; batch classifier loss: 0.134426; batch adversarial loss: 0.488482\n",
      "epoch 138; iter: 0; batch classifier loss: 0.138926; batch adversarial loss: 0.499752\n",
      "epoch 139; iter: 0; batch classifier loss: 0.108876; batch adversarial loss: 0.421451\n",
      "epoch 140; iter: 0; batch classifier loss: 0.158019; batch adversarial loss: 0.543044\n",
      "epoch 141; iter: 0; batch classifier loss: 0.136125; batch adversarial loss: 0.501549\n",
      "epoch 142; iter: 0; batch classifier loss: 0.136776; batch adversarial loss: 0.534669\n",
      "epoch 143; iter: 0; batch classifier loss: 0.142030; batch adversarial loss: 0.491099\n",
      "epoch 144; iter: 0; batch classifier loss: 0.069802; batch adversarial loss: 0.442313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076563; batch adversarial loss: 0.480949\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050791; batch adversarial loss: 0.535613\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019010; batch adversarial loss: 0.448525\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035130; batch adversarial loss: 0.425894\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027859; batch adversarial loss: 0.394772\n",
      "epoch 150; iter: 0; batch classifier loss: 0.120979; batch adversarial loss: 0.506970\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015879; batch adversarial loss: 0.486773\n",
      "epoch 152; iter: 0; batch classifier loss: 0.087308; batch adversarial loss: 0.318896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056318; batch adversarial loss: 0.411823\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.497374\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036844; batch adversarial loss: 0.448329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039733; batch adversarial loss: 0.501576\n",
      "epoch 157; iter: 0; batch classifier loss: 0.061819; batch adversarial loss: 0.345903\n",
      "epoch 158; iter: 0; batch classifier loss: 0.066836; batch adversarial loss: 0.445344\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054968; batch adversarial loss: 0.449296\n",
      "epoch 160; iter: 0; batch classifier loss: 0.079481; batch adversarial loss: 0.404685\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052835; batch adversarial loss: 0.405653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.068131; batch adversarial loss: 0.440695\n",
      "epoch 163; iter: 0; batch classifier loss: 0.069268; batch adversarial loss: 0.426132\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065548; batch adversarial loss: 0.491297\n",
      "epoch 165; iter: 0; batch classifier loss: 0.069356; batch adversarial loss: 0.402512\n",
      "epoch 166; iter: 0; batch classifier loss: 0.090246; batch adversarial loss: 0.425951\n",
      "epoch 167; iter: 0; batch classifier loss: 0.041115; batch adversarial loss: 0.465023\n",
      "epoch 168; iter: 0; batch classifier loss: 0.071913; batch adversarial loss: 0.519247\n",
      "epoch 169; iter: 0; batch classifier loss: 0.072872; batch adversarial loss: 0.417390\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052240; batch adversarial loss: 0.447285\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044965; batch adversarial loss: 0.571633\n",
      "epoch 172; iter: 0; batch classifier loss: 0.097900; batch adversarial loss: 0.440126\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036055; batch adversarial loss: 0.474535\n",
      "epoch 174; iter: 0; batch classifier loss: 0.080054; batch adversarial loss: 0.333811\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031576; batch adversarial loss: 0.388013\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038394; batch adversarial loss: 0.459518\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050235; batch adversarial loss: 0.506568\n",
      "epoch 178; iter: 0; batch classifier loss: 0.075363; batch adversarial loss: 0.461894\n",
      "epoch 179; iter: 0; batch classifier loss: 0.077904; batch adversarial loss: 0.525882\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047803; batch adversarial loss: 0.437196\n",
      "epoch 181; iter: 0; batch classifier loss: 0.040708; batch adversarial loss: 0.416605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.063292; batch adversarial loss: 0.519263\n",
      "epoch 183; iter: 0; batch classifier loss: 0.118780; batch adversarial loss: 0.430572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.061168; batch adversarial loss: 0.476565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060431; batch adversarial loss: 0.482052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.061689; batch adversarial loss: 0.388108\n",
      "epoch 187; iter: 0; batch classifier loss: 0.069341; batch adversarial loss: 0.524485\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037845; batch adversarial loss: 0.507017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.069634; batch adversarial loss: 0.375469\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043894; batch adversarial loss: 0.405948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.029163; batch adversarial loss: 0.411356\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.491954\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035093; batch adversarial loss: 0.467792\n",
      "epoch 194; iter: 0; batch classifier loss: 0.047720; batch adversarial loss: 0.453998\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047882; batch adversarial loss: 0.513760\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051884; batch adversarial loss: 0.421678\n",
      "epoch 197; iter: 0; batch classifier loss: 0.054408; batch adversarial loss: 0.481116\n",
      "epoch 198; iter: 0; batch classifier loss: 0.043941; batch adversarial loss: 0.349807\n",
      "epoch 199; iter: 0; batch classifier loss: 0.090855; batch adversarial loss: 0.481850\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699345; batch adversarial loss: 0.513333\n",
      "epoch 1; iter: 0; batch classifier loss: 0.398015; batch adversarial loss: 0.571881\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468745; batch adversarial loss: 0.578896\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431816; batch adversarial loss: 0.545990\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336573; batch adversarial loss: 0.582911\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373486; batch adversarial loss: 0.602385\n",
      "epoch 6; iter: 0; batch classifier loss: 0.313376; batch adversarial loss: 0.587723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462970; batch adversarial loss: 0.673505\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301381; batch adversarial loss: 0.520521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426765; batch adversarial loss: 0.628911\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430680; batch adversarial loss: 0.586128\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496887; batch adversarial loss: 0.603396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.511743; batch adversarial loss: 0.639212\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578271; batch adversarial loss: 0.488371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516956; batch adversarial loss: 0.513397\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468386; batch adversarial loss: 0.559627\n",
      "epoch 16; iter: 0; batch classifier loss: 0.361185; batch adversarial loss: 0.430856\n",
      "epoch 17; iter: 0; batch classifier loss: 0.254934; batch adversarial loss: 0.537091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245245; batch adversarial loss: 0.424834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192731; batch adversarial loss: 0.508309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.186419; batch adversarial loss: 0.497915\n",
      "epoch 21; iter: 0; batch classifier loss: 0.137244; batch adversarial loss: 0.510833\n",
      "epoch 22; iter: 0; batch classifier loss: 0.161907; batch adversarial loss: 0.477645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177143; batch adversarial loss: 0.490740\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226185; batch adversarial loss: 0.417370\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192355; batch adversarial loss: 0.527982\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178211; batch adversarial loss: 0.479705\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146012; batch adversarial loss: 0.441655\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153990; batch adversarial loss: 0.524340\n",
      "epoch 29; iter: 0; batch classifier loss: 0.141203; batch adversarial loss: 0.414030\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158892; batch adversarial loss: 0.430757\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124863; batch adversarial loss: 0.473923\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143609; batch adversarial loss: 0.403332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107288; batch adversarial loss: 0.506283\n",
      "epoch 34; iter: 0; batch classifier loss: 0.213593; batch adversarial loss: 0.456549\n",
      "epoch 35; iter: 0; batch classifier loss: 0.085704; batch adversarial loss: 0.509666\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123865; batch adversarial loss: 0.512970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107030; batch adversarial loss: 0.424724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.084297; batch adversarial loss: 0.460492\n",
      "epoch 39; iter: 0; batch classifier loss: 0.104898; batch adversarial loss: 0.503442\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145430; batch adversarial loss: 0.438540\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103595; batch adversarial loss: 0.468568\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105633; batch adversarial loss: 0.500187\n",
      "epoch 43; iter: 0; batch classifier loss: 0.148386; batch adversarial loss: 0.475038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134702; batch adversarial loss: 0.535340\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124849; batch adversarial loss: 0.507161\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112890; batch adversarial loss: 0.381378\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085159; batch adversarial loss: 0.487817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155705; batch adversarial loss: 0.472414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.112495; batch adversarial loss: 0.460854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088385; batch adversarial loss: 0.592469\n",
      "epoch 51; iter: 0; batch classifier loss: 0.110212; batch adversarial loss: 0.507527\n",
      "epoch 52; iter: 0; batch classifier loss: 0.133549; batch adversarial loss: 0.409460\n",
      "epoch 53; iter: 0; batch classifier loss: 0.143670; batch adversarial loss: 0.430418\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104542; batch adversarial loss: 0.530022\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086245; batch adversarial loss: 0.483521\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131963; batch adversarial loss: 0.395240\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124740; batch adversarial loss: 0.508980\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113542; batch adversarial loss: 0.400379\n",
      "epoch 59; iter: 0; batch classifier loss: 0.137136; batch adversarial loss: 0.498101\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148817; batch adversarial loss: 0.452212\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093308; batch adversarial loss: 0.445386\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098620; batch adversarial loss: 0.504620\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095292; batch adversarial loss: 0.474857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082859; batch adversarial loss: 0.492932\n",
      "epoch 65; iter: 0; batch classifier loss: 0.165988; batch adversarial loss: 0.394548\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154382; batch adversarial loss: 0.452019\n",
      "epoch 67; iter: 0; batch classifier loss: 0.074519; batch adversarial loss: 0.532272\n",
      "epoch 68; iter: 0; batch classifier loss: 0.135382; batch adversarial loss: 0.484000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.167365; batch adversarial loss: 0.533123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.118792; batch adversarial loss: 0.444808\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084956; batch adversarial loss: 0.460972\n",
      "epoch 72; iter: 0; batch classifier loss: 0.146411; batch adversarial loss: 0.497636\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102147; batch adversarial loss: 0.380550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122890; batch adversarial loss: 0.470718\n",
      "epoch 75; iter: 0; batch classifier loss: 0.124850; batch adversarial loss: 0.487381\n",
      "epoch 76; iter: 0; batch classifier loss: 0.103234; batch adversarial loss: 0.490847\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087696; batch adversarial loss: 0.531240\n",
      "epoch 78; iter: 0; batch classifier loss: 0.093009; batch adversarial loss: 0.559643\n",
      "epoch 79; iter: 0; batch classifier loss: 0.151359; batch adversarial loss: 0.426084\n",
      "epoch 80; iter: 0; batch classifier loss: 0.109062; batch adversarial loss: 0.474627\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118686; batch adversarial loss: 0.508387\n",
      "epoch 82; iter: 0; batch classifier loss: 0.190968; batch adversarial loss: 0.447748\n",
      "epoch 83; iter: 0; batch classifier loss: 0.120546; batch adversarial loss: 0.473867\n",
      "epoch 84; iter: 0; batch classifier loss: 0.149038; batch adversarial loss: 0.469203\n",
      "epoch 85; iter: 0; batch classifier loss: 0.129320; batch adversarial loss: 0.531558\n",
      "epoch 86; iter: 0; batch classifier loss: 0.095536; batch adversarial loss: 0.409518\n",
      "epoch 87; iter: 0; batch classifier loss: 0.183728; batch adversarial loss: 0.483356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074790; batch adversarial loss: 0.501832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.061097; batch adversarial loss: 0.418963\n",
      "epoch 90; iter: 0; batch classifier loss: 0.105944; batch adversarial loss: 0.388549\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055668; batch adversarial loss: 0.462993\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117159; batch adversarial loss: 0.464263\n",
      "epoch 93; iter: 0; batch classifier loss: 0.126766; batch adversarial loss: 0.461953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.117380; batch adversarial loss: 0.420025\n",
      "epoch 95; iter: 0; batch classifier loss: 0.153312; batch adversarial loss: 0.444483\n",
      "epoch 96; iter: 0; batch classifier loss: 0.110631; batch adversarial loss: 0.461009\n",
      "epoch 97; iter: 0; batch classifier loss: 0.135116; batch adversarial loss: 0.437402\n",
      "epoch 98; iter: 0; batch classifier loss: 0.178599; batch adversarial loss: 0.418993\n",
      "epoch 99; iter: 0; batch classifier loss: 0.134572; batch adversarial loss: 0.442888\n",
      "epoch 100; iter: 0; batch classifier loss: 0.134440; batch adversarial loss: 0.445834\n",
      "epoch 101; iter: 0; batch classifier loss: 0.130961; batch adversarial loss: 0.435924\n",
      "epoch 102; iter: 0; batch classifier loss: 0.121239; batch adversarial loss: 0.469631\n",
      "epoch 103; iter: 0; batch classifier loss: 0.160649; batch adversarial loss: 0.494697\n",
      "epoch 104; iter: 0; batch classifier loss: 0.112626; batch adversarial loss: 0.503962\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089111; batch adversarial loss: 0.476248\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075550; batch adversarial loss: 0.469501\n",
      "epoch 107; iter: 0; batch classifier loss: 0.092255; batch adversarial loss: 0.432501\n",
      "epoch 108; iter: 0; batch classifier loss: 0.118955; batch adversarial loss: 0.502851\n",
      "epoch 109; iter: 0; batch classifier loss: 0.112646; batch adversarial loss: 0.449015\n",
      "epoch 110; iter: 0; batch classifier loss: 0.099876; batch adversarial loss: 0.508468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.135744; batch adversarial loss: 0.406526\n",
      "epoch 112; iter: 0; batch classifier loss: 0.147791; batch adversarial loss: 0.335645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.106904; batch adversarial loss: 0.532683\n",
      "epoch 114; iter: 0; batch classifier loss: 0.131773; batch adversarial loss: 0.399580\n",
      "epoch 115; iter: 0; batch classifier loss: 0.098337; batch adversarial loss: 0.412086\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063787; batch adversarial loss: 0.483184\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060014; batch adversarial loss: 0.462241\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074691; batch adversarial loss: 0.464081\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054289; batch adversarial loss: 0.446763\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046190; batch adversarial loss: 0.415058\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044791; batch adversarial loss: 0.483574\n",
      "epoch 122; iter: 0; batch classifier loss: 0.087116; batch adversarial loss: 0.511353\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051445; batch adversarial loss: 0.528126\n",
      "epoch 124; iter: 0; batch classifier loss: 0.074921; batch adversarial loss: 0.410198\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071629; batch adversarial loss: 0.421381\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051677; batch adversarial loss: 0.501373\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033963; batch adversarial loss: 0.570197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047236; batch adversarial loss: 0.413941\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051959; batch adversarial loss: 0.445798\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053412; batch adversarial loss: 0.409384\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037539; batch adversarial loss: 0.433125\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070908; batch adversarial loss: 0.475733\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046257; batch adversarial loss: 0.429077\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030857; batch adversarial loss: 0.439582\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023330; batch adversarial loss: 0.526756\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045510; batch adversarial loss: 0.563123\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022509; batch adversarial loss: 0.476634\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031765; batch adversarial loss: 0.513500\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050593; batch adversarial loss: 0.569110\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031816; batch adversarial loss: 0.388528\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033929; batch adversarial loss: 0.505868\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033719; batch adversarial loss: 0.441990\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031607; batch adversarial loss: 0.513307\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030323; batch adversarial loss: 0.452276\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024427; batch adversarial loss: 0.418998\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.462947\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017692; batch adversarial loss: 0.409900\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029673; batch adversarial loss: 0.405801\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047879; batch adversarial loss: 0.416683\n",
      "epoch 150; iter: 0; batch classifier loss: 0.082375; batch adversarial loss: 0.395251\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032705; batch adversarial loss: 0.461194\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045962; batch adversarial loss: 0.434444\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042826; batch adversarial loss: 0.476318\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017045; batch adversarial loss: 0.594135\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019611; batch adversarial loss: 0.555539\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021802; batch adversarial loss: 0.489509\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023114; batch adversarial loss: 0.515131\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016546; batch adversarial loss: 0.472474\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040741; batch adversarial loss: 0.408483\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.538159\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031476; batch adversarial loss: 0.458824\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037361; batch adversarial loss: 0.373278\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026194; batch adversarial loss: 0.396649\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026089; batch adversarial loss: 0.539770\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029141; batch adversarial loss: 0.485283\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021082; batch adversarial loss: 0.462950\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026019; batch adversarial loss: 0.472422\n",
      "epoch 168; iter: 0; batch classifier loss: 0.008622; batch adversarial loss: 0.422059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023692; batch adversarial loss: 0.519124\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023135; batch adversarial loss: 0.506414\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058862; batch adversarial loss: 0.443308\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028832; batch adversarial loss: 0.500187\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021982; batch adversarial loss: 0.505015\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012444; batch adversarial loss: 0.417821\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.428960\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032809; batch adversarial loss: 0.485479\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013310; batch adversarial loss: 0.398144\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031992; batch adversarial loss: 0.461248\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011924; batch adversarial loss: 0.464013\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022065; batch adversarial loss: 0.430236\n",
      "epoch 181; iter: 0; batch classifier loss: 0.069542; batch adversarial loss: 0.389849\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009693; batch adversarial loss: 0.484469\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016570; batch adversarial loss: 0.531224\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026069; batch adversarial loss: 0.353450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.037600; batch adversarial loss: 0.392251\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033334; batch adversarial loss: 0.500861\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027661; batch adversarial loss: 0.432701\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021001; batch adversarial loss: 0.371017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033487; batch adversarial loss: 0.471707\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028592; batch adversarial loss: 0.499093\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023217; batch adversarial loss: 0.438146\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025953; batch adversarial loss: 0.421823\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035255; batch adversarial loss: 0.448201\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027416; batch adversarial loss: 0.423444\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010501; batch adversarial loss: 0.391638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035313; batch adversarial loss: 0.491426\n",
      "epoch 197; iter: 0; batch classifier loss: 0.038776; batch adversarial loss: 0.373621\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017915; batch adversarial loss: 0.403980\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007182; batch adversarial loss: 0.445933\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731133; batch adversarial loss: 0.942237\n",
      "epoch 1; iter: 0; batch classifier loss: 0.513086; batch adversarial loss: 0.933032\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375004; batch adversarial loss: 0.880010\n",
      "epoch 3; iter: 0; batch classifier loss: 0.426534; batch adversarial loss: 0.821938\n",
      "epoch 4; iter: 0; batch classifier loss: 0.383319; batch adversarial loss: 0.737051\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299071; batch adversarial loss: 0.717830\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315224; batch adversarial loss: 0.639211\n",
      "epoch 7; iter: 0; batch classifier loss: 0.277114; batch adversarial loss: 0.643153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302365; batch adversarial loss: 0.604507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286563; batch adversarial loss: 0.584125\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316050; batch adversarial loss: 0.541598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266251; batch adversarial loss: 0.555095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277168; batch adversarial loss: 0.539985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308005; batch adversarial loss: 0.542611\n",
      "epoch 14; iter: 0; batch classifier loss: 0.264583; batch adversarial loss: 0.518362\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204749; batch adversarial loss: 0.512114\n",
      "epoch 16; iter: 0; batch classifier loss: 0.266771; batch adversarial loss: 0.543801\n",
      "epoch 17; iter: 0; batch classifier loss: 0.268947; batch adversarial loss: 0.440729\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238855; batch adversarial loss: 0.516269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.188661; batch adversarial loss: 0.476781\n",
      "epoch 20; iter: 0; batch classifier loss: 0.254064; batch adversarial loss: 0.465229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261339; batch adversarial loss: 0.470847\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226494; batch adversarial loss: 0.489065\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191548; batch adversarial loss: 0.444815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189538; batch adversarial loss: 0.478127\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145836; batch adversarial loss: 0.464438\n",
      "epoch 26; iter: 0; batch classifier loss: 0.158463; batch adversarial loss: 0.371873\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166511; batch adversarial loss: 0.437384\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153807; batch adversarial loss: 0.363996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164181; batch adversarial loss: 0.355896\n",
      "epoch 30; iter: 0; batch classifier loss: 0.125645; batch adversarial loss: 0.470886\n",
      "epoch 31; iter: 0; batch classifier loss: 0.086334; batch adversarial loss: 0.513327\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154833; batch adversarial loss: 0.461718\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148761; batch adversarial loss: 0.393464\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139503; batch adversarial loss: 0.446408\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118094; batch adversarial loss: 0.354127\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129918; batch adversarial loss: 0.427315\n",
      "epoch 37; iter: 0; batch classifier loss: 0.091265; batch adversarial loss: 0.540935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120464; batch adversarial loss: 0.383920\n",
      "epoch 39; iter: 0; batch classifier loss: 0.144979; batch adversarial loss: 0.479513\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127024; batch adversarial loss: 0.381321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109204; batch adversarial loss: 0.349116\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100145; batch adversarial loss: 0.372379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107589; batch adversarial loss: 0.480944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086788; batch adversarial loss: 0.539016\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069494; batch adversarial loss: 0.493174\n",
      "epoch 46; iter: 0; batch classifier loss: 0.067817; batch adversarial loss: 0.381440\n",
      "epoch 47; iter: 0; batch classifier loss: 0.103561; batch adversarial loss: 0.497137\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089660; batch adversarial loss: 0.434672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105173; batch adversarial loss: 0.491766\n",
      "epoch 50; iter: 0; batch classifier loss: 0.107095; batch adversarial loss: 0.463156\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090123; batch adversarial loss: 0.456746\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078716; batch adversarial loss: 0.431834\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099211; batch adversarial loss: 0.325501\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130679; batch adversarial loss: 0.431440\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114930; batch adversarial loss: 0.407733\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124632; batch adversarial loss: 0.412141\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087300; batch adversarial loss: 0.435549\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100045; batch adversarial loss: 0.430828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100781; batch adversarial loss: 0.479042\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062902; batch adversarial loss: 0.385919\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080175; batch adversarial loss: 0.349694\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114395; batch adversarial loss: 0.429038\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067785; batch adversarial loss: 0.442588\n",
      "epoch 64; iter: 0; batch classifier loss: 0.118884; batch adversarial loss: 0.518233\n",
      "epoch 65; iter: 0; batch classifier loss: 0.087610; batch adversarial loss: 0.436637\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057634; batch adversarial loss: 0.425047\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091894; batch adversarial loss: 0.523330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084840; batch adversarial loss: 0.467045\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087277; batch adversarial loss: 0.480653\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079636; batch adversarial loss: 0.393605\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058894; batch adversarial loss: 0.519894\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068758; batch adversarial loss: 0.384375\n",
      "epoch 73; iter: 0; batch classifier loss: 0.100659; batch adversarial loss: 0.391179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063774; batch adversarial loss: 0.337145\n",
      "epoch 75; iter: 0; batch classifier loss: 0.094442; batch adversarial loss: 0.446811\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114529; batch adversarial loss: 0.461281\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.421009\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102037; batch adversarial loss: 0.400746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080264; batch adversarial loss: 0.401353\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092552; batch adversarial loss: 0.493710\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095529; batch adversarial loss: 0.401363\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060330; batch adversarial loss: 0.393893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83; iter: 0; batch classifier loss: 0.078645; batch adversarial loss: 0.438227\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062304; batch adversarial loss: 0.501276\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067147; batch adversarial loss: 0.489291\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035583; batch adversarial loss: 0.379929\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055198; batch adversarial loss: 0.392622\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048319; batch adversarial loss: 0.417041\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077743; batch adversarial loss: 0.392715\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036033; batch adversarial loss: 0.416632\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072922; batch adversarial loss: 0.501050\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058377; batch adversarial loss: 0.452622\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040419; batch adversarial loss: 0.412634\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085002; batch adversarial loss: 0.392505\n",
      "epoch 95; iter: 0; batch classifier loss: 0.052120; batch adversarial loss: 0.397212\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052621; batch adversarial loss: 0.448491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087045; batch adversarial loss: 0.438487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061251; batch adversarial loss: 0.442924\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063994; batch adversarial loss: 0.338507\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049035; batch adversarial loss: 0.351325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.108234; batch adversarial loss: 0.546235\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.438483\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065105; batch adversarial loss: 0.419671\n",
      "epoch 104; iter: 0; batch classifier loss: 0.086095; batch adversarial loss: 0.373949\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060056; batch adversarial loss: 0.416287\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063714; batch adversarial loss: 0.473850\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058787; batch adversarial loss: 0.505959\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040052; batch adversarial loss: 0.502152\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059023; batch adversarial loss: 0.411319\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042895; batch adversarial loss: 0.433659\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053308; batch adversarial loss: 0.385351\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059960; batch adversarial loss: 0.347707\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038611; batch adversarial loss: 0.352381\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043837; batch adversarial loss: 0.445053\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046446; batch adversarial loss: 0.379213\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074157; batch adversarial loss: 0.472408\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058333; batch adversarial loss: 0.381742\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052064; batch adversarial loss: 0.420424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.061205; batch adversarial loss: 0.430734\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050715; batch adversarial loss: 0.399277\n",
      "epoch 121; iter: 0; batch classifier loss: 0.064598; batch adversarial loss: 0.448962\n",
      "epoch 122; iter: 0; batch classifier loss: 0.080757; batch adversarial loss: 0.396474\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056112; batch adversarial loss: 0.444996\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059123; batch adversarial loss: 0.459597\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059314; batch adversarial loss: 0.380175\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038061; batch adversarial loss: 0.411677\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067839; batch adversarial loss: 0.409438\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041977; batch adversarial loss: 0.402501\n",
      "epoch 129; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.432155\n",
      "epoch 130; iter: 0; batch classifier loss: 0.059063; batch adversarial loss: 0.473672\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038784; batch adversarial loss: 0.387914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035600; batch adversarial loss: 0.440025\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060029; batch adversarial loss: 0.408448\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059693; batch adversarial loss: 0.410957\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026495; batch adversarial loss: 0.300277\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023976; batch adversarial loss: 0.515934\n",
      "epoch 137; iter: 0; batch classifier loss: 0.051054; batch adversarial loss: 0.488735\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037510; batch adversarial loss: 0.428267\n",
      "epoch 139; iter: 0; batch classifier loss: 0.047404; batch adversarial loss: 0.441443\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033143; batch adversarial loss: 0.393670\n",
      "epoch 141; iter: 0; batch classifier loss: 0.070493; batch adversarial loss: 0.438666\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043141; batch adversarial loss: 0.363688\n",
      "epoch 143; iter: 0; batch classifier loss: 0.052636; batch adversarial loss: 0.506431\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052182; batch adversarial loss: 0.505967\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055266; batch adversarial loss: 0.420852\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044082; batch adversarial loss: 0.429099\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039949; batch adversarial loss: 0.409336\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.443991\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049251; batch adversarial loss: 0.445499\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029373; batch adversarial loss: 0.440834\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033813; batch adversarial loss: 0.442343\n",
      "epoch 152; iter: 0; batch classifier loss: 0.059586; batch adversarial loss: 0.457120\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020550; batch adversarial loss: 0.406162\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022411; batch adversarial loss: 0.414207\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046018; batch adversarial loss: 0.451305\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.491870\n",
      "epoch 157; iter: 0; batch classifier loss: 0.039395; batch adversarial loss: 0.536215\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030090; batch adversarial loss: 0.462125\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026253; batch adversarial loss: 0.446778\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020714; batch adversarial loss: 0.514031\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037516; batch adversarial loss: 0.376271\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021585; batch adversarial loss: 0.489780\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012877; batch adversarial loss: 0.501529\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037322; batch adversarial loss: 0.350080\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027215; batch adversarial loss: 0.419912\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020475; batch adversarial loss: 0.451973\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026606; batch adversarial loss: 0.407529\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022869; batch adversarial loss: 0.524815\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030136; batch adversarial loss: 0.492983\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025649; batch adversarial loss: 0.502975\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023766; batch adversarial loss: 0.471452\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026196; batch adversarial loss: 0.492480\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016782; batch adversarial loss: 0.469596\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035332; batch adversarial loss: 0.488087\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020510; batch adversarial loss: 0.516690\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018518; batch adversarial loss: 0.418002\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049142; batch adversarial loss: 0.547857\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038953; batch adversarial loss: 0.507305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 179; iter: 0; batch classifier loss: 0.045284; batch adversarial loss: 0.520088\n",
      "epoch 180; iter: 0; batch classifier loss: 0.105075; batch adversarial loss: 0.515121\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060998; batch adversarial loss: 0.556006\n",
      "epoch 182; iter: 0; batch classifier loss: 0.094083; batch adversarial loss: 0.559710\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088359; batch adversarial loss: 0.683881\n",
      "epoch 184; iter: 0; batch classifier loss: 0.124809; batch adversarial loss: 0.611597\n",
      "epoch 185; iter: 0; batch classifier loss: 0.070716; batch adversarial loss: 0.587505\n",
      "epoch 186; iter: 0; batch classifier loss: 0.132535; batch adversarial loss: 0.752850\n",
      "epoch 187; iter: 0; batch classifier loss: 0.087188; batch adversarial loss: 0.478400\n",
      "epoch 188; iter: 0; batch classifier loss: 0.130015; batch adversarial loss: 0.548640\n",
      "epoch 189; iter: 0; batch classifier loss: 0.141861; batch adversarial loss: 0.736869\n",
      "epoch 190; iter: 0; batch classifier loss: 0.229539; batch adversarial loss: 0.755614\n",
      "epoch 191; iter: 0; batch classifier loss: 0.124848; batch adversarial loss: 0.655136\n",
      "epoch 192; iter: 0; batch classifier loss: 0.101437; batch adversarial loss: 0.560413\n",
      "epoch 193; iter: 0; batch classifier loss: 0.130688; batch adversarial loss: 0.602967\n",
      "epoch 194; iter: 0; batch classifier loss: 0.115416; batch adversarial loss: 0.549056\n",
      "epoch 195; iter: 0; batch classifier loss: 0.163369; batch adversarial loss: 0.641906\n",
      "epoch 196; iter: 0; batch classifier loss: 0.110403; batch adversarial loss: 0.682383\n",
      "epoch 197; iter: 0; batch classifier loss: 0.153221; batch adversarial loss: 0.662659\n",
      "epoch 198; iter: 0; batch classifier loss: 0.089284; batch adversarial loss: 0.502612\n",
      "epoch 199; iter: 0; batch classifier loss: 0.175557; batch adversarial loss: 0.657135\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685155; batch adversarial loss: 0.831592\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375970; batch adversarial loss: 0.823592\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338077; batch adversarial loss: 0.748982\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356757; batch adversarial loss: 0.722981\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400703; batch adversarial loss: 0.663176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373852; batch adversarial loss: 0.636964\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331963; batch adversarial loss: 0.609272\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325579; batch adversarial loss: 0.594094\n",
      "epoch 8; iter: 0; batch classifier loss: 0.320089; batch adversarial loss: 0.563858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281403; batch adversarial loss: 0.545922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363089; batch adversarial loss: 0.504323\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311235; batch adversarial loss: 0.503568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244790; batch adversarial loss: 0.551277\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273337; batch adversarial loss: 0.448341\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233972; batch adversarial loss: 0.464692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290745; batch adversarial loss: 0.414269\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240078; batch adversarial loss: 0.418964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.258486; batch adversarial loss: 0.424386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259685; batch adversarial loss: 0.403559\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200766; batch adversarial loss: 0.375098\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232375; batch adversarial loss: 0.435032\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215115; batch adversarial loss: 0.379048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229160; batch adversarial loss: 0.476343\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209093; batch adversarial loss: 0.435364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222712; batch adversarial loss: 0.433312\n",
      "epoch 25; iter: 0; batch classifier loss: 0.219364; batch adversarial loss: 0.322998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.184358; batch adversarial loss: 0.388791\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163628; batch adversarial loss: 0.461003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.212745; batch adversarial loss: 0.389729\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177542; batch adversarial loss: 0.387026\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142428; batch adversarial loss: 0.392040\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207573; batch adversarial loss: 0.417185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.155337; batch adversarial loss: 0.408875\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249176; batch adversarial loss: 0.466074\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153077; batch adversarial loss: 0.392582\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151257; batch adversarial loss: 0.300232\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137572; batch adversarial loss: 0.314199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.195774; batch adversarial loss: 0.491076\n",
      "epoch 38; iter: 0; batch classifier loss: 0.156745; batch adversarial loss: 0.437665\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137504; batch adversarial loss: 0.341894\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091371; batch adversarial loss: 0.399337\n",
      "epoch 41; iter: 0; batch classifier loss: 0.128806; batch adversarial loss: 0.418783\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106627; batch adversarial loss: 0.372271\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112622; batch adversarial loss: 0.481534\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096038; batch adversarial loss: 0.374999\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111905; batch adversarial loss: 0.394545\n",
      "epoch 46; iter: 0; batch classifier loss: 0.087519; batch adversarial loss: 0.379811\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110265; batch adversarial loss: 0.431848\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083439; batch adversarial loss: 0.356826\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124672; batch adversarial loss: 0.386805\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094406; batch adversarial loss: 0.457493\n",
      "epoch 51; iter: 0; batch classifier loss: 0.125800; batch adversarial loss: 0.357194\n",
      "epoch 52; iter: 0; batch classifier loss: 0.128260; batch adversarial loss: 0.467542\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160263; batch adversarial loss: 0.459230\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133087; batch adversarial loss: 0.437135\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096013; batch adversarial loss: 0.364013\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095560; batch adversarial loss: 0.428653\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072222; batch adversarial loss: 0.427750\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107831; batch adversarial loss: 0.477390\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103365; batch adversarial loss: 0.400996\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083800; batch adversarial loss: 0.452743\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119409; batch adversarial loss: 0.504666\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141005; batch adversarial loss: 0.474826\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096457; batch adversarial loss: 0.436375\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071011; batch adversarial loss: 0.330349\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076069; batch adversarial loss: 0.479986\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073844; batch adversarial loss: 0.540417\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089149; batch adversarial loss: 0.468222\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094312; batch adversarial loss: 0.504424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067757; batch adversarial loss: 0.331216\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098512; batch adversarial loss: 0.404614\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079988; batch adversarial loss: 0.338717\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095420; batch adversarial loss: 0.390752\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048050; batch adversarial loss: 0.406855\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110479; batch adversarial loss: 0.368753\n",
      "epoch 75; iter: 0; batch classifier loss: 0.092339; batch adversarial loss: 0.410893\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074320; batch adversarial loss: 0.523283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 0; batch classifier loss: 0.118903; batch adversarial loss: 0.394472\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055454; batch adversarial loss: 0.495977\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063370; batch adversarial loss: 0.346562\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083950; batch adversarial loss: 0.473536\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079733; batch adversarial loss: 0.387812\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087654; batch adversarial loss: 0.414866\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073400; batch adversarial loss: 0.373380\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067389; batch adversarial loss: 0.407679\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082849; batch adversarial loss: 0.415612\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063130; batch adversarial loss: 0.398611\n",
      "epoch 87; iter: 0; batch classifier loss: 0.083240; batch adversarial loss: 0.457304\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102475; batch adversarial loss: 0.441038\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053089; batch adversarial loss: 0.439161\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057325; batch adversarial loss: 0.337999\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057861; batch adversarial loss: 0.412215\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078432; batch adversarial loss: 0.468898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075272; batch adversarial loss: 0.518628\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074659; batch adversarial loss: 0.453604\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085866; batch adversarial loss: 0.388735\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061235; batch adversarial loss: 0.394169\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077829; batch adversarial loss: 0.391061\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063252; batch adversarial loss: 0.579849\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069954; batch adversarial loss: 0.464324\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076913; batch adversarial loss: 0.389109\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071303; batch adversarial loss: 0.317920\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063086; batch adversarial loss: 0.457535\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058685; batch adversarial loss: 0.424163\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046008; batch adversarial loss: 0.429150\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084953; batch adversarial loss: 0.306339\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054091; batch adversarial loss: 0.496386\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062354; batch adversarial loss: 0.484704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.080935; batch adversarial loss: 0.452642\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050289; batch adversarial loss: 0.409943\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044127; batch adversarial loss: 0.400416\n",
      "epoch 111; iter: 0; batch classifier loss: 0.052552; batch adversarial loss: 0.375188\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031906; batch adversarial loss: 0.496832\n",
      "epoch 113; iter: 0; batch classifier loss: 0.094393; batch adversarial loss: 0.378590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034886; batch adversarial loss: 0.419602\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045767; batch adversarial loss: 0.347987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.063399; batch adversarial loss: 0.375696\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062449; batch adversarial loss: 0.427839\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036598; batch adversarial loss: 0.427879\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036171; batch adversarial loss: 0.429032\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033044; batch adversarial loss: 0.510860\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061662; batch adversarial loss: 0.452953\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024399; batch adversarial loss: 0.361408\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043121; batch adversarial loss: 0.410265\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042251; batch adversarial loss: 0.429164\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037584; batch adversarial loss: 0.472203\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033652; batch adversarial loss: 0.452450\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062981; batch adversarial loss: 0.453093\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054174; batch adversarial loss: 0.396870\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031039; batch adversarial loss: 0.461917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029183; batch adversarial loss: 0.459287\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.395144\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022756; batch adversarial loss: 0.443510\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049665; batch adversarial loss: 0.460083\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044506; batch adversarial loss: 0.529790\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.468877\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019505; batch adversarial loss: 0.493029\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022646; batch adversarial loss: 0.390057\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041027; batch adversarial loss: 0.448002\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060388; batch adversarial loss: 0.486050\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021168; batch adversarial loss: 0.546657\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018285; batch adversarial loss: 0.528437\n",
      "epoch 142; iter: 0; batch classifier loss: 0.068520; batch adversarial loss: 0.446893\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025119; batch adversarial loss: 0.443889\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036142; batch adversarial loss: 0.466301\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023384; batch adversarial loss: 0.388175\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030412; batch adversarial loss: 0.442981\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049168; batch adversarial loss: 0.517635\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034441; batch adversarial loss: 0.495233\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015489; batch adversarial loss: 0.472404\n",
      "epoch 150; iter: 0; batch classifier loss: 0.094988; batch adversarial loss: 0.561052\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048955; batch adversarial loss: 0.419372\n",
      "epoch 152; iter: 0; batch classifier loss: 0.089963; batch adversarial loss: 0.573536\n",
      "epoch 153; iter: 0; batch classifier loss: 0.095020; batch adversarial loss: 0.565871\n",
      "epoch 154; iter: 0; batch classifier loss: 0.098810; batch adversarial loss: 0.610415\n",
      "epoch 155; iter: 0; batch classifier loss: 0.069937; batch adversarial loss: 0.480682\n",
      "epoch 156; iter: 0; batch classifier loss: 0.120149; batch adversarial loss: 0.670395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.092459; batch adversarial loss: 0.535615\n",
      "epoch 158; iter: 0; batch classifier loss: 0.071817; batch adversarial loss: 0.481505\n",
      "epoch 159; iter: 0; batch classifier loss: 0.170853; batch adversarial loss: 0.719766\n",
      "epoch 160; iter: 0; batch classifier loss: 0.125502; batch adversarial loss: 0.529702\n",
      "epoch 161; iter: 0; batch classifier loss: 0.104687; batch adversarial loss: 0.589875\n",
      "epoch 162; iter: 0; batch classifier loss: 0.179351; batch adversarial loss: 0.729490\n",
      "epoch 163; iter: 0; batch classifier loss: 0.166972; batch adversarial loss: 0.654029\n",
      "epoch 164; iter: 0; batch classifier loss: 0.110887; batch adversarial loss: 0.507448\n",
      "epoch 165; iter: 0; batch classifier loss: 0.180185; batch adversarial loss: 0.704797\n",
      "epoch 166; iter: 0; batch classifier loss: 0.141230; batch adversarial loss: 0.607879\n",
      "epoch 167; iter: 0; batch classifier loss: 0.119469; batch adversarial loss: 0.608568\n",
      "epoch 168; iter: 0; batch classifier loss: 0.177184; batch adversarial loss: 0.672837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.218306; batch adversarial loss: 0.746840\n",
      "epoch 170; iter: 0; batch classifier loss: 0.179061; batch adversarial loss: 0.570421\n",
      "epoch 171; iter: 0; batch classifier loss: 0.153752; batch adversarial loss: 0.611967\n",
      "epoch 172; iter: 0; batch classifier loss: 0.192645; batch adversarial loss: 0.719331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 173; iter: 0; batch classifier loss: 0.194971; batch adversarial loss: 0.650045\n",
      "epoch 174; iter: 0; batch classifier loss: 0.126463; batch adversarial loss: 0.617310\n",
      "epoch 175; iter: 0; batch classifier loss: 0.145220; batch adversarial loss: 0.540051\n",
      "epoch 176; iter: 0; batch classifier loss: 0.247418; batch adversarial loss: 0.776836\n",
      "epoch 177; iter: 0; batch classifier loss: 0.179894; batch adversarial loss: 0.638219\n",
      "epoch 178; iter: 0; batch classifier loss: 0.190599; batch adversarial loss: 0.584016\n",
      "epoch 179; iter: 0; batch classifier loss: 0.144339; batch adversarial loss: 0.549645\n",
      "epoch 180; iter: 0; batch classifier loss: 0.072583; batch adversarial loss: 0.436492\n",
      "epoch 181; iter: 0; batch classifier loss: 0.180057; batch adversarial loss: 0.607620\n",
      "epoch 182; iter: 0; batch classifier loss: 0.218553; batch adversarial loss: 0.848251\n",
      "epoch 183; iter: 0; batch classifier loss: 0.292991; batch adversarial loss: 0.724358\n",
      "epoch 184; iter: 0; batch classifier loss: 0.166360; batch adversarial loss: 0.571937\n",
      "epoch 185; iter: 0; batch classifier loss: 0.189319; batch adversarial loss: 0.584760\n",
      "epoch 186; iter: 0; batch classifier loss: 0.148175; batch adversarial loss: 0.551560\n",
      "epoch 187; iter: 0; batch classifier loss: 0.184036; batch adversarial loss: 0.563090\n",
      "epoch 188; iter: 0; batch classifier loss: 0.133913; batch adversarial loss: 0.473048\n",
      "epoch 189; iter: 0; batch classifier loss: 0.122488; batch adversarial loss: 0.559425\n",
      "epoch 190; iter: 0; batch classifier loss: 0.081472; batch adversarial loss: 0.458307\n",
      "epoch 191; iter: 0; batch classifier loss: 0.092476; batch adversarial loss: 0.507691\n",
      "epoch 192; iter: 0; batch classifier loss: 0.113217; batch adversarial loss: 0.475720\n",
      "epoch 193; iter: 0; batch classifier loss: 0.078694; batch adversarial loss: 0.445881\n",
      "epoch 194; iter: 0; batch classifier loss: 0.138023; batch adversarial loss: 0.504359\n",
      "epoch 195; iter: 0; batch classifier loss: 0.108005; batch adversarial loss: 0.529849\n",
      "epoch 196; iter: 0; batch classifier loss: 0.157190; batch adversarial loss: 0.551695\n",
      "epoch 197; iter: 0; batch classifier loss: 0.087998; batch adversarial loss: 0.435533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.113307; batch adversarial loss: 0.471211\n",
      "epoch 199; iter: 0; batch classifier loss: 0.139833; batch adversarial loss: 0.479155\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672485; batch adversarial loss: 0.602780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421580; batch adversarial loss: 0.618113\n",
      "epoch 2; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.601885\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390522; batch adversarial loss: 0.663518\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387486; batch adversarial loss: 0.627220\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538612; batch adversarial loss: 0.600442\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584665; batch adversarial loss: 0.616388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652183; batch adversarial loss: 0.552857\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449427; batch adversarial loss: 0.563504\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438717; batch adversarial loss: 0.536927\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440822; batch adversarial loss: 0.531704\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414194; batch adversarial loss: 0.530688\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372250; batch adversarial loss: 0.473130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247516; batch adversarial loss: 0.551091\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369274; batch adversarial loss: 0.498730\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318195; batch adversarial loss: 0.456408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335616; batch adversarial loss: 0.420313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302713; batch adversarial loss: 0.490148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272670; batch adversarial loss: 0.469265\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260205; batch adversarial loss: 0.514111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269118; batch adversarial loss: 0.445452\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290216; batch adversarial loss: 0.405433\n",
      "epoch 22; iter: 0; batch classifier loss: 0.306378; batch adversarial loss: 0.457190\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342686; batch adversarial loss: 0.539721\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270263; batch adversarial loss: 0.459637\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215653; batch adversarial loss: 0.426591\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239815; batch adversarial loss: 0.433529\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237520; batch adversarial loss: 0.419340\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285903; batch adversarial loss: 0.478020\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231680; batch adversarial loss: 0.467437\n",
      "epoch 30; iter: 0; batch classifier loss: 0.252371; batch adversarial loss: 0.494255\n",
      "epoch 31; iter: 0; batch classifier loss: 0.287373; batch adversarial loss: 0.391503\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230591; batch adversarial loss: 0.428677\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187691; batch adversarial loss: 0.429538\n",
      "epoch 34; iter: 0; batch classifier loss: 0.246594; batch adversarial loss: 0.463711\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293855; batch adversarial loss: 0.464604\n",
      "epoch 36; iter: 0; batch classifier loss: 0.219602; batch adversarial loss: 0.486221\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210011; batch adversarial loss: 0.416823\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269229; batch adversarial loss: 0.460723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222256; batch adversarial loss: 0.433817\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233188; batch adversarial loss: 0.425474\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275996; batch adversarial loss: 0.570082\n",
      "epoch 42; iter: 0; batch classifier loss: 0.204996; batch adversarial loss: 0.446866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.216407; batch adversarial loss: 0.410937\n",
      "epoch 44; iter: 0; batch classifier loss: 0.236632; batch adversarial loss: 0.452879\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222893; batch adversarial loss: 0.484139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.212664; batch adversarial loss: 0.397739\n",
      "epoch 47; iter: 0; batch classifier loss: 0.274468; batch adversarial loss: 0.482736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.298119; batch adversarial loss: 0.422563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.194142; batch adversarial loss: 0.410847\n",
      "epoch 50; iter: 0; batch classifier loss: 0.228832; batch adversarial loss: 0.447261\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149043; batch adversarial loss: 0.446608\n",
      "epoch 52; iter: 0; batch classifier loss: 0.197819; batch adversarial loss: 0.495885\n",
      "epoch 53; iter: 0; batch classifier loss: 0.240384; batch adversarial loss: 0.458949\n",
      "epoch 54; iter: 0; batch classifier loss: 0.190860; batch adversarial loss: 0.408484\n",
      "epoch 55; iter: 0; batch classifier loss: 0.191601; batch adversarial loss: 0.407236\n",
      "epoch 56; iter: 0; batch classifier loss: 0.249958; batch adversarial loss: 0.471832\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187938; batch adversarial loss: 0.470985\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124919; batch adversarial loss: 0.457303\n",
      "epoch 59; iter: 0; batch classifier loss: 0.227296; batch adversarial loss: 0.497455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.227187; batch adversarial loss: 0.421360\n",
      "epoch 61; iter: 0; batch classifier loss: 0.204673; batch adversarial loss: 0.472020\n",
      "epoch 62; iter: 0; batch classifier loss: 0.164758; batch adversarial loss: 0.471909\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187316; batch adversarial loss: 0.421371\n",
      "epoch 64; iter: 0; batch classifier loss: 0.254533; batch adversarial loss: 0.433823\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096897; batch adversarial loss: 0.420371\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072840; batch adversarial loss: 0.471209\n",
      "epoch 67; iter: 0; batch classifier loss: 0.147907; batch adversarial loss: 0.379287\n",
      "epoch 68; iter: 0; batch classifier loss: 0.192800; batch adversarial loss: 0.499983\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101500; batch adversarial loss: 0.486974\n",
      "epoch 70; iter: 0; batch classifier loss: 0.183425; batch adversarial loss: 0.384957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.220805; batch adversarial loss: 0.445306\n",
      "epoch 72; iter: 0; batch classifier loss: 0.206481; batch adversarial loss: 0.446588\n",
      "epoch 73; iter: 0; batch classifier loss: 0.216548; batch adversarial loss: 0.432779\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160323; batch adversarial loss: 0.534367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.171519; batch adversarial loss: 0.472023\n",
      "epoch 76; iter: 0; batch classifier loss: 0.259531; batch adversarial loss: 0.357803\n",
      "epoch 77; iter: 0; batch classifier loss: 0.140936; batch adversarial loss: 0.497532\n",
      "epoch 78; iter: 0; batch classifier loss: 0.147315; batch adversarial loss: 0.534883\n",
      "epoch 79; iter: 0; batch classifier loss: 0.194259; batch adversarial loss: 0.408356\n",
      "epoch 80; iter: 0; batch classifier loss: 0.142953; batch adversarial loss: 0.458830\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121054; batch adversarial loss: 0.494908\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083257; batch adversarial loss: 0.361816\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065145; batch adversarial loss: 0.537055\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054170; batch adversarial loss: 0.372635\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092908; batch adversarial loss: 0.395131\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070699; batch adversarial loss: 0.520015\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043197; batch adversarial loss: 0.413650\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082897; batch adversarial loss: 0.496432\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065373; batch adversarial loss: 0.438817\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093927; batch adversarial loss: 0.448569\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110356; batch adversarial loss: 0.432458\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043614; batch adversarial loss: 0.416246\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080971; batch adversarial loss: 0.444349\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040495; batch adversarial loss: 0.554622\n",
      "epoch 95; iter: 0; batch classifier loss: 0.099877; batch adversarial loss: 0.388807\n",
      "epoch 96; iter: 0; batch classifier loss: 0.038963; batch adversarial loss: 0.453994\n",
      "epoch 97; iter: 0; batch classifier loss: 0.102783; batch adversarial loss: 0.396449\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049134; batch adversarial loss: 0.435691\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061795; batch adversarial loss: 0.554520\n",
      "epoch 100; iter: 0; batch classifier loss: 0.089473; batch adversarial loss: 0.486698\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047779; batch adversarial loss: 0.436076\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068268; batch adversarial loss: 0.462957\n",
      "epoch 103; iter: 0; batch classifier loss: 0.098253; batch adversarial loss: 0.352513\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033239; batch adversarial loss: 0.445757\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046603; batch adversarial loss: 0.465126\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054332; batch adversarial loss: 0.517691\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057237; batch adversarial loss: 0.432623\n",
      "epoch 108; iter: 0; batch classifier loss: 0.082491; batch adversarial loss: 0.474883\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046924; batch adversarial loss: 0.422130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030271; batch adversarial loss: 0.462293\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042085; batch adversarial loss: 0.390136\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078159; batch adversarial loss: 0.493659\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040404; batch adversarial loss: 0.461088\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071698; batch adversarial loss: 0.459096\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052756; batch adversarial loss: 0.515623\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047604; batch adversarial loss: 0.436763\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062738; batch adversarial loss: 0.506206\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074965; batch adversarial loss: 0.517936\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065400; batch adversarial loss: 0.371546\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036699; batch adversarial loss: 0.512174\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057302; batch adversarial loss: 0.401192\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045248; batch adversarial loss: 0.493253\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038661; batch adversarial loss: 0.526649\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032000; batch adversarial loss: 0.393445\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020619; batch adversarial loss: 0.379150\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.345366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039372; batch adversarial loss: 0.362925\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019416; batch adversarial loss: 0.495080\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032465; batch adversarial loss: 0.449871\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047904; batch adversarial loss: 0.441532\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036581; batch adversarial loss: 0.489919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057654; batch adversarial loss: 0.379627\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053458; batch adversarial loss: 0.418145\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021314; batch adversarial loss: 0.448831\n",
      "epoch 135; iter: 0; batch classifier loss: 0.028803; batch adversarial loss: 0.404206\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030938; batch adversarial loss: 0.481345\n",
      "epoch 137; iter: 0; batch classifier loss: 0.012881; batch adversarial loss: 0.363515\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035843; batch adversarial loss: 0.453144\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042363; batch adversarial loss: 0.430790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034501; batch adversarial loss: 0.495525\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040739; batch adversarial loss: 0.425227\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012307; batch adversarial loss: 0.441169\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050094; batch adversarial loss: 0.413000\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019116; batch adversarial loss: 0.484791\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064417; batch adversarial loss: 0.471600\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024795; batch adversarial loss: 0.424657\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028733; batch adversarial loss: 0.458491\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023842; batch adversarial loss: 0.436202\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015635; batch adversarial loss: 0.382035\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018389; batch adversarial loss: 0.366212\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022219; batch adversarial loss: 0.448836\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015246; batch adversarial loss: 0.464053\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.504336\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017293; batch adversarial loss: 0.417540\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023364; batch adversarial loss: 0.355400\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023362; batch adversarial loss: 0.396358\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029145; batch adversarial loss: 0.469663\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019706; batch adversarial loss: 0.449357\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037973; batch adversarial loss: 0.438451\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031198; batch adversarial loss: 0.441478\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.493098\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019349; batch adversarial loss: 0.517704\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014075; batch adversarial loss: 0.405317\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030057; batch adversarial loss: 0.476003\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022915; batch adversarial loss: 0.471249\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020868; batch adversarial loss: 0.383434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.019061; batch adversarial loss: 0.481791\n",
      "epoch 168; iter: 0; batch classifier loss: 0.005385; batch adversarial loss: 0.366131\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016884; batch adversarial loss: 0.456236\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008800; batch adversarial loss: 0.424537\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015922; batch adversarial loss: 0.373583\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019633; batch adversarial loss: 0.325433\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014273; batch adversarial loss: 0.362950\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016648; batch adversarial loss: 0.352574\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028926; batch adversarial loss: 0.320810\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008207; batch adversarial loss: 0.456983\n",
      "epoch 177; iter: 0; batch classifier loss: 0.034108; batch adversarial loss: 0.464259\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040672; batch adversarial loss: 0.462469\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015124; batch adversarial loss: 0.393833\n",
      "epoch 180; iter: 0; batch classifier loss: 0.008682; batch adversarial loss: 0.485482\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030592; batch adversarial loss: 0.435065\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011324; batch adversarial loss: 0.390688\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051607; batch adversarial loss: 0.391904\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025256; batch adversarial loss: 0.366549\n",
      "epoch 185; iter: 0; batch classifier loss: 0.004909; batch adversarial loss: 0.314985\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037508; batch adversarial loss: 0.439005\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028300; batch adversarial loss: 0.460997\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003773; batch adversarial loss: 0.401078\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021992; batch adversarial loss: 0.407778\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016373; batch adversarial loss: 0.527048\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013347; batch adversarial loss: 0.436171\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020044; batch adversarial loss: 0.476916\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032244; batch adversarial loss: 0.473278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020149; batch adversarial loss: 0.533105\n",
      "epoch 195; iter: 0; batch classifier loss: 0.039834; batch adversarial loss: 0.445043\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019987; batch adversarial loss: 0.423558\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014582; batch adversarial loss: 0.488941\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024398; batch adversarial loss: 0.471231\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004500; batch adversarial loss: 0.410003\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687211; batch adversarial loss: 0.954916\n",
      "epoch 1; iter: 0; batch classifier loss: 0.468020; batch adversarial loss: 1.017117\n",
      "epoch 2; iter: 0; batch classifier loss: 0.533923; batch adversarial loss: 0.971843\n",
      "epoch 3; iter: 0; batch classifier loss: 0.442489; batch adversarial loss: 0.909168\n",
      "epoch 4; iter: 0; batch classifier loss: 0.653386; batch adversarial loss: 0.784569\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345502; batch adversarial loss: 0.733625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.286935; batch adversarial loss: 0.675403\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283087; batch adversarial loss: 0.660677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282282; batch adversarial loss: 0.630623\n",
      "epoch 9; iter: 0; batch classifier loss: 0.277006; batch adversarial loss: 0.588745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.239305; batch adversarial loss: 0.582634\n",
      "epoch 11; iter: 0; batch classifier loss: 0.236993; batch adversarial loss: 0.573780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283563; batch adversarial loss: 0.542106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265751; batch adversarial loss: 0.525486\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287284; batch adversarial loss: 0.505705\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249054; batch adversarial loss: 0.557520\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227445; batch adversarial loss: 0.476313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248762; batch adversarial loss: 0.507634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.153016; batch adversarial loss: 0.528289\n",
      "epoch 19; iter: 0; batch classifier loss: 0.165077; batch adversarial loss: 0.470208\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232059; batch adversarial loss: 0.489228\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176037; batch adversarial loss: 0.480356\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210063; batch adversarial loss: 0.450945\n",
      "epoch 23; iter: 0; batch classifier loss: 0.209530; batch adversarial loss: 0.429770\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240021; batch adversarial loss: 0.450179\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193151; batch adversarial loss: 0.454914\n",
      "epoch 26; iter: 0; batch classifier loss: 0.237074; batch adversarial loss: 0.419075\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146488; batch adversarial loss: 0.406379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163443; batch adversarial loss: 0.487891\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120315; batch adversarial loss: 0.463568\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184294; batch adversarial loss: 0.440275\n",
      "epoch 31; iter: 0; batch classifier loss: 0.093952; batch adversarial loss: 0.438602\n",
      "epoch 32; iter: 0; batch classifier loss: 0.128210; batch adversarial loss: 0.464421\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099085; batch adversarial loss: 0.471384\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168550; batch adversarial loss: 0.379291\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127113; batch adversarial loss: 0.438591\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131980; batch adversarial loss: 0.494599\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137709; batch adversarial loss: 0.396897\n",
      "epoch 38; iter: 0; batch classifier loss: 0.084112; batch adversarial loss: 0.457000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113122; batch adversarial loss: 0.430961\n",
      "epoch 40; iter: 0; batch classifier loss: 0.093551; batch adversarial loss: 0.486759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085331; batch adversarial loss: 0.411485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.080769; batch adversarial loss: 0.467807\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090469; batch adversarial loss: 0.437543\n",
      "epoch 44; iter: 0; batch classifier loss: 0.066440; batch adversarial loss: 0.458898\n",
      "epoch 45; iter: 0; batch classifier loss: 0.107408; batch adversarial loss: 0.420711\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123257; batch adversarial loss: 0.360769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.061864; batch adversarial loss: 0.479434\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081073; batch adversarial loss: 0.451975\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107980; batch adversarial loss: 0.392035\n",
      "epoch 50; iter: 0; batch classifier loss: 0.149752; batch adversarial loss: 0.472718\n",
      "epoch 51; iter: 0; batch classifier loss: 0.040718; batch adversarial loss: 0.452078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.046920; batch adversarial loss: 0.428801\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095944; batch adversarial loss: 0.397918\n",
      "epoch 54; iter: 0; batch classifier loss: 0.091722; batch adversarial loss: 0.439614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121303; batch adversarial loss: 0.387440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103396; batch adversarial loss: 0.427618\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102272; batch adversarial loss: 0.404415\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078971; batch adversarial loss: 0.426649\n",
      "epoch 59; iter: 0; batch classifier loss: 0.047160; batch adversarial loss: 0.418530\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104042; batch adversarial loss: 0.439079\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058693; batch adversarial loss: 0.378353\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067515; batch adversarial loss: 0.494983\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039667; batch adversarial loss: 0.345773\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083770; batch adversarial loss: 0.342223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.117713; batch adversarial loss: 0.399248\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066493; batch adversarial loss: 0.496471\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105773; batch adversarial loss: 0.419150\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084481; batch adversarial loss: 0.466435\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061471; batch adversarial loss: 0.504553\n",
      "epoch 70; iter: 0; batch classifier loss: 0.083372; batch adversarial loss: 0.362697\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055392; batch adversarial loss: 0.419987\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061619; batch adversarial loss: 0.460963\n",
      "epoch 73; iter: 0; batch classifier loss: 0.045740; batch adversarial loss: 0.419117\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062997; batch adversarial loss: 0.462713\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047137; batch adversarial loss: 0.454167\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077626; batch adversarial loss: 0.406240\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069051; batch adversarial loss: 0.415381\n",
      "epoch 78; iter: 0; batch classifier loss: 0.094175; batch adversarial loss: 0.579345\n",
      "epoch 79; iter: 0; batch classifier loss: 0.083870; batch adversarial loss: 0.486055\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048049; batch adversarial loss: 0.395411\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069840; batch adversarial loss: 0.531000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079592; batch adversarial loss: 0.425505\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093882; batch adversarial loss: 0.450068\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053887; batch adversarial loss: 0.390161\n",
      "epoch 85; iter: 0; batch classifier loss: 0.135191; batch adversarial loss: 0.410776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058134; batch adversarial loss: 0.500788\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087227; batch adversarial loss: 0.525895\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058319; batch adversarial loss: 0.388162\n",
      "epoch 89; iter: 0; batch classifier loss: 0.107890; batch adversarial loss: 0.503241\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064530; batch adversarial loss: 0.445249\n",
      "epoch 91; iter: 0; batch classifier loss: 0.123222; batch adversarial loss: 0.469952\n",
      "epoch 92; iter: 0; batch classifier loss: 0.033980; batch adversarial loss: 0.440695\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039758; batch adversarial loss: 0.362713\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042215; batch adversarial loss: 0.362162\n",
      "epoch 95; iter: 0; batch classifier loss: 0.084125; batch adversarial loss: 0.333181\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047287; batch adversarial loss: 0.446710\n",
      "epoch 97; iter: 0; batch classifier loss: 0.034623; batch adversarial loss: 0.414508\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068107; batch adversarial loss: 0.351546\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040702; batch adversarial loss: 0.403206\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060575; batch adversarial loss: 0.447694\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041344; batch adversarial loss: 0.426554\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089710; batch adversarial loss: 0.384234\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.461777\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044624; batch adversarial loss: 0.391620\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035600; batch adversarial loss: 0.386766\n",
      "epoch 106; iter: 0; batch classifier loss: 0.095913; batch adversarial loss: 0.534687\n",
      "epoch 107; iter: 0; batch classifier loss: 0.090018; batch adversarial loss: 0.552957\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055490; batch adversarial loss: 0.485563\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075933; batch adversarial loss: 0.405012\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027659; batch adversarial loss: 0.444724\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059364; batch adversarial loss: 0.420317\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050684; batch adversarial loss: 0.432046\n",
      "epoch 113; iter: 0; batch classifier loss: 0.032408; batch adversarial loss: 0.393708\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075580; batch adversarial loss: 0.434536\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065845; batch adversarial loss: 0.484860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052357; batch adversarial loss: 0.415387\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062736; batch adversarial loss: 0.400315\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073230; batch adversarial loss: 0.447234\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060525; batch adversarial loss: 0.446237\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042054; batch adversarial loss: 0.462005\n",
      "epoch 121; iter: 0; batch classifier loss: 0.100432; batch adversarial loss: 0.360833\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067854; batch adversarial loss: 0.475533\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053368; batch adversarial loss: 0.401100\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055729; batch adversarial loss: 0.418999\n",
      "epoch 125; iter: 0; batch classifier loss: 0.074105; batch adversarial loss: 0.428032\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038244; batch adversarial loss: 0.483216\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048622; batch adversarial loss: 0.352548\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043786; batch adversarial loss: 0.396954\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048396; batch adversarial loss: 0.529608\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041348; batch adversarial loss: 0.430030\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037673; batch adversarial loss: 0.338907\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039898; batch adversarial loss: 0.468640\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039473; batch adversarial loss: 0.345217\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062676; batch adversarial loss: 0.416448\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045223; batch adversarial loss: 0.424999\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037985; batch adversarial loss: 0.437605\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037684; batch adversarial loss: 0.424815\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072449; batch adversarial loss: 0.425043\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055612; batch adversarial loss: 0.449888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045993; batch adversarial loss: 0.516670\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023959; batch adversarial loss: 0.418465\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057295; batch adversarial loss: 0.386879\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040851; batch adversarial loss: 0.392972\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058228; batch adversarial loss: 0.432084\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076830; batch adversarial loss: 0.348898\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043595; batch adversarial loss: 0.389791\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058914; batch adversarial loss: 0.516467\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020081; batch adversarial loss: 0.507983\n",
      "epoch 149; iter: 0; batch classifier loss: 0.072651; batch adversarial loss: 0.522974\n",
      "epoch 150; iter: 0; batch classifier loss: 0.041944; batch adversarial loss: 0.362947\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034767; batch adversarial loss: 0.453760\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027907; batch adversarial loss: 0.360874\n",
      "epoch 153; iter: 0; batch classifier loss: 0.050431; batch adversarial loss: 0.415730\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058756; batch adversarial loss: 0.354762\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045763; batch adversarial loss: 0.325821\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040374; batch adversarial loss: 0.376190\n",
      "epoch 157; iter: 0; batch classifier loss: 0.045436; batch adversarial loss: 0.612337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064334; batch adversarial loss: 0.452855\n",
      "epoch 159; iter: 0; batch classifier loss: 0.067709; batch adversarial loss: 0.348477\n",
      "epoch 160; iter: 0; batch classifier loss: 0.051958; batch adversarial loss: 0.512170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.046815; batch adversarial loss: 0.404208\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042807; batch adversarial loss: 0.486001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040055; batch adversarial loss: 0.376807\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055661; batch adversarial loss: 0.438910\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024815; batch adversarial loss: 0.388638\n",
      "epoch 166; iter: 0; batch classifier loss: 0.051923; batch adversarial loss: 0.430540\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054010; batch adversarial loss: 0.452377\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034339; batch adversarial loss: 0.395278\n",
      "epoch 169; iter: 0; batch classifier loss: 0.054754; batch adversarial loss: 0.411296\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047650; batch adversarial loss: 0.373229\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027208; batch adversarial loss: 0.473372\n",
      "epoch 172; iter: 0; batch classifier loss: 0.060399; batch adversarial loss: 0.479130\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040214; batch adversarial loss: 0.377037\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036395; batch adversarial loss: 0.506321\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039179; batch adversarial loss: 0.426269\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026237; batch adversarial loss: 0.402613\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032797; batch adversarial loss: 0.435896\n",
      "epoch 178; iter: 0; batch classifier loss: 0.044791; batch adversarial loss: 0.416832\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023109; batch adversarial loss: 0.415465\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018937; batch adversarial loss: 0.403118\n",
      "epoch 181; iter: 0; batch classifier loss: 0.066524; batch adversarial loss: 0.439654\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040877; batch adversarial loss: 0.465115\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036242; batch adversarial loss: 0.437955\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049508; batch adversarial loss: 0.463199\n",
      "epoch 185; iter: 0; batch classifier loss: 0.065656; batch adversarial loss: 0.457667\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041530; batch adversarial loss: 0.485122\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025063; batch adversarial loss: 0.432429\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033736; batch adversarial loss: 0.461017\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051014; batch adversarial loss: 0.446721\n",
      "epoch 190; iter: 0; batch classifier loss: 0.054869; batch adversarial loss: 0.396865\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018308; batch adversarial loss: 0.432716\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038385; batch adversarial loss: 0.493151\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025628; batch adversarial loss: 0.418234\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049778; batch adversarial loss: 0.370566\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027798; batch adversarial loss: 0.530139\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033821; batch adversarial loss: 0.455963\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031533; batch adversarial loss: 0.389628\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040154; batch adversarial loss: 0.437253\n",
      "epoch 199; iter: 0; batch classifier loss: 0.033045; batch adversarial loss: 0.347748\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694832; batch adversarial loss: 0.533363\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457547; batch adversarial loss: 0.581067\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384947; batch adversarial loss: 0.558982\n",
      "epoch 3; iter: 0; batch classifier loss: 0.467769; batch adversarial loss: 0.626262\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444567; batch adversarial loss: 0.587084\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398386; batch adversarial loss: 0.596361\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387599; batch adversarial loss: 0.625409\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418916; batch adversarial loss: 0.547832\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396267; batch adversarial loss: 0.510176\n",
      "epoch 9; iter: 0; batch classifier loss: 0.430598; batch adversarial loss: 0.645289\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519827; batch adversarial loss: 0.562509\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601126; batch adversarial loss: 0.589206\n",
      "epoch 12; iter: 0; batch classifier loss: 0.399101; batch adversarial loss: 0.533448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425041; batch adversarial loss: 0.488022\n",
      "epoch 14; iter: 0; batch classifier loss: 0.353227; batch adversarial loss: 0.482919\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338319; batch adversarial loss: 0.512076\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283333; batch adversarial loss: 0.511986\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241384; batch adversarial loss: 0.426559\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226919; batch adversarial loss: 0.465037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174371; batch adversarial loss: 0.455454\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213375; batch adversarial loss: 0.482049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204423; batch adversarial loss: 0.395469\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226522; batch adversarial loss: 0.421611\n",
      "epoch 23; iter: 0; batch classifier loss: 0.189087; batch adversarial loss: 0.553790\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191441; batch adversarial loss: 0.400508\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159536; batch adversarial loss: 0.451455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194772; batch adversarial loss: 0.425822\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191791; batch adversarial loss: 0.409782\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179450; batch adversarial loss: 0.384299\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205293; batch adversarial loss: 0.512968\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130784; batch adversarial loss: 0.469901\n",
      "epoch 31; iter: 0; batch classifier loss: 0.155717; batch adversarial loss: 0.477647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193866; batch adversarial loss: 0.477840\n",
      "epoch 33; iter: 0; batch classifier loss: 0.182345; batch adversarial loss: 0.413128\n",
      "epoch 34; iter: 0; batch classifier loss: 0.174861; batch adversarial loss: 0.442955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.178129; batch adversarial loss: 0.430700\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148690; batch adversarial loss: 0.479000\n",
      "epoch 37; iter: 0; batch classifier loss: 0.139788; batch adversarial loss: 0.474245\n",
      "epoch 38; iter: 0; batch classifier loss: 0.116396; batch adversarial loss: 0.365484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.161229; batch adversarial loss: 0.442270\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104539; batch adversarial loss: 0.338881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129122; batch adversarial loss: 0.369632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.149161; batch adversarial loss: 0.458918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173295; batch adversarial loss: 0.393390\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175783; batch adversarial loss: 0.444490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117511; batch adversarial loss: 0.437512\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141989; batch adversarial loss: 0.422487\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144991; batch adversarial loss: 0.460900\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156927; batch adversarial loss: 0.368015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.191461; batch adversarial loss: 0.472952\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147773; batch adversarial loss: 0.456066\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129703; batch adversarial loss: 0.438124\n",
      "epoch 52; iter: 0; batch classifier loss: 0.188126; batch adversarial loss: 0.503641\n",
      "epoch 53; iter: 0; batch classifier loss: 0.248470; batch adversarial loss: 0.457789\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138504; batch adversarial loss: 0.417157\n",
      "epoch 55; iter: 0; batch classifier loss: 0.153391; batch adversarial loss: 0.489058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157568; batch adversarial loss: 0.385129\n",
      "epoch 57; iter: 0; batch classifier loss: 0.181802; batch adversarial loss: 0.346210\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141615; batch adversarial loss: 0.470613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.162371; batch adversarial loss: 0.505787\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180922; batch adversarial loss: 0.545107\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145508; batch adversarial loss: 0.479535\n",
      "epoch 62; iter: 0; batch classifier loss: 0.162086; batch adversarial loss: 0.434110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.130896; batch adversarial loss: 0.453628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.174431; batch adversarial loss: 0.427094\n",
      "epoch 65; iter: 0; batch classifier loss: 0.260469; batch adversarial loss: 0.421904\n",
      "epoch 66; iter: 0; batch classifier loss: 0.208000; batch adversarial loss: 0.473466\n",
      "epoch 67; iter: 0; batch classifier loss: 0.189832; batch adversarial loss: 0.430719\n",
      "epoch 68; iter: 0; batch classifier loss: 0.167896; batch adversarial loss: 0.332416\n",
      "epoch 69; iter: 0; batch classifier loss: 0.139912; batch adversarial loss: 0.362752\n",
      "epoch 70; iter: 0; batch classifier loss: 0.146780; batch adversarial loss: 0.405769\n",
      "epoch 71; iter: 0; batch classifier loss: 0.142542; batch adversarial loss: 0.479545\n",
      "epoch 72; iter: 0; batch classifier loss: 0.183929; batch adversarial loss: 0.463356\n",
      "epoch 73; iter: 0; batch classifier loss: 0.191436; batch adversarial loss: 0.404004\n",
      "epoch 74; iter: 0; batch classifier loss: 0.154934; batch adversarial loss: 0.507686\n",
      "epoch 75; iter: 0; batch classifier loss: 0.125094; batch adversarial loss: 0.437317\n",
      "epoch 76; iter: 0; batch classifier loss: 0.124715; batch adversarial loss: 0.490007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.125054; batch adversarial loss: 0.503912\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198733; batch adversarial loss: 0.403069\n",
      "epoch 79; iter: 0; batch classifier loss: 0.123876; batch adversarial loss: 0.423806\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096834; batch adversarial loss: 0.493866\n",
      "epoch 81; iter: 0; batch classifier loss: 0.171547; batch adversarial loss: 0.436577\n",
      "epoch 82; iter: 0; batch classifier loss: 0.145927; batch adversarial loss: 0.410338\n",
      "epoch 83; iter: 0; batch classifier loss: 0.126302; batch adversarial loss: 0.448286\n",
      "epoch 84; iter: 0; batch classifier loss: 0.098539; batch adversarial loss: 0.444636\n",
      "epoch 85; iter: 0; batch classifier loss: 0.166433; batch adversarial loss: 0.424930\n",
      "epoch 86; iter: 0; batch classifier loss: 0.151606; batch adversarial loss: 0.505630\n",
      "epoch 87; iter: 0; batch classifier loss: 0.180473; batch adversarial loss: 0.430432\n",
      "epoch 88; iter: 0; batch classifier loss: 0.108018; batch adversarial loss: 0.474293\n",
      "epoch 89; iter: 0; batch classifier loss: 0.126818; batch adversarial loss: 0.491206\n",
      "epoch 90; iter: 0; batch classifier loss: 0.141938; batch adversarial loss: 0.429380\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107614; batch adversarial loss: 0.489256\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095115; batch adversarial loss: 0.457216\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082720; batch adversarial loss: 0.466257\n",
      "epoch 94; iter: 0; batch classifier loss: 0.127532; batch adversarial loss: 0.389917\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097971; batch adversarial loss: 0.514480\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124976; batch adversarial loss: 0.408377\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087875; batch adversarial loss: 0.488269\n",
      "epoch 98; iter: 0; batch classifier loss: 0.158025; batch adversarial loss: 0.431813\n",
      "epoch 99; iter: 0; batch classifier loss: 0.112946; batch adversarial loss: 0.442440\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057749; batch adversarial loss: 0.448503\n",
      "epoch 101; iter: 0; batch classifier loss: 0.097998; batch adversarial loss: 0.467864\n",
      "epoch 102; iter: 0; batch classifier loss: 0.096002; batch adversarial loss: 0.467908\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086591; batch adversarial loss: 0.497396\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082051; batch adversarial loss: 0.435381\n",
      "epoch 105; iter: 0; batch classifier loss: 0.110254; batch adversarial loss: 0.443933\n",
      "epoch 106; iter: 0; batch classifier loss: 0.102428; batch adversarial loss: 0.404039\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059804; batch adversarial loss: 0.432018\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063654; batch adversarial loss: 0.480023\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077435; batch adversarial loss: 0.477596\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051113; batch adversarial loss: 0.511415\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044028; batch adversarial loss: 0.487358\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024165; batch adversarial loss: 0.499881\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077196; batch adversarial loss: 0.436638\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067886; batch adversarial loss: 0.449570\n",
      "epoch 115; iter: 0; batch classifier loss: 0.089972; batch adversarial loss: 0.471227\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053744; batch adversarial loss: 0.459516\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049999; batch adversarial loss: 0.472065\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040901; batch adversarial loss: 0.423424\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048101; batch adversarial loss: 0.504667\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060290; batch adversarial loss: 0.455306\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048709; batch adversarial loss: 0.536116\n",
      "epoch 122; iter: 0; batch classifier loss: 0.071158; batch adversarial loss: 0.462633\n",
      "epoch 123; iter: 0; batch classifier loss: 0.028612; batch adversarial loss: 0.392210\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027503; batch adversarial loss: 0.428658\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043352; batch adversarial loss: 0.452256\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045828; batch adversarial loss: 0.440405\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050779; batch adversarial loss: 0.418527\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021461; batch adversarial loss: 0.493655\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032684; batch adversarial loss: 0.414981\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034623; batch adversarial loss: 0.550091\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051073; batch adversarial loss: 0.399957\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040016; batch adversarial loss: 0.435822\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056350; batch adversarial loss: 0.387796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034057; batch adversarial loss: 0.409887\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030095; batch adversarial loss: 0.468021\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040327; batch adversarial loss: 0.502952\n",
      "epoch 137; iter: 0; batch classifier loss: 0.048896; batch adversarial loss: 0.418363\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029368; batch adversarial loss: 0.508703\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025384; batch adversarial loss: 0.459688\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023813; batch adversarial loss: 0.432930\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019888; batch adversarial loss: 0.468157\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038083; batch adversarial loss: 0.383132\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010422; batch adversarial loss: 0.433209\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030534; batch adversarial loss: 0.424223\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031849; batch adversarial loss: 0.385733\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010325; batch adversarial loss: 0.439931\n",
      "epoch 147; iter: 0; batch classifier loss: 0.017977; batch adversarial loss: 0.585039\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021139; batch adversarial loss: 0.452221\n",
      "epoch 149; iter: 0; batch classifier loss: 0.074254; batch adversarial loss: 0.429174\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018500; batch adversarial loss: 0.428961\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042890; batch adversarial loss: 0.438290\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017841; batch adversarial loss: 0.461766\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.442903\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013158; batch adversarial loss: 0.435847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.033045; batch adversarial loss: 0.428322\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045154; batch adversarial loss: 0.437269\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015601; batch adversarial loss: 0.407804\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026088; batch adversarial loss: 0.463327\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022687; batch adversarial loss: 0.463246\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023160; batch adversarial loss: 0.406004\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021681; batch adversarial loss: 0.406448\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018897; batch adversarial loss: 0.402490\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029045; batch adversarial loss: 0.501600\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023544; batch adversarial loss: 0.378098\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019080; batch adversarial loss: 0.434073\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023734; batch adversarial loss: 0.357998\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016455; batch adversarial loss: 0.339671\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045469; batch adversarial loss: 0.459023\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010684; batch adversarial loss: 0.489091\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038942; batch adversarial loss: 0.435390\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022653; batch adversarial loss: 0.418342\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023351; batch adversarial loss: 0.505721\n",
      "epoch 173; iter: 0; batch classifier loss: 0.011096; batch adversarial loss: 0.507366\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020216; batch adversarial loss: 0.404924\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015930; batch adversarial loss: 0.455941\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018133; batch adversarial loss: 0.497734\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023862; batch adversarial loss: 0.417642\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050478; batch adversarial loss: 0.406829\n",
      "epoch 179; iter: 0; batch classifier loss: 0.046505; batch adversarial loss: 0.483253\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.405992\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015940; batch adversarial loss: 0.549894\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014234; batch adversarial loss: 0.401383\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029586; batch adversarial loss: 0.424571\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017687; batch adversarial loss: 0.486303\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010992; batch adversarial loss: 0.438774\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030314; batch adversarial loss: 0.435550\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026607; batch adversarial loss: 0.472755\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.321790\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026990; batch adversarial loss: 0.489998\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017126; batch adversarial loss: 0.505546\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017353; batch adversarial loss: 0.466516\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013047; batch adversarial loss: 0.466426\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016598; batch adversarial loss: 0.435627\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029078; batch adversarial loss: 0.446471\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005023; batch adversarial loss: 0.540682\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007249; batch adversarial loss: 0.479188\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028652; batch adversarial loss: 0.440042\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005496; batch adversarial loss: 0.429840\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017167; batch adversarial loss: 0.401654\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722434; batch adversarial loss: 0.614367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462791; batch adversarial loss: 0.632383\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383062; batch adversarial loss: 0.601272\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326827; batch adversarial loss: 0.592580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385447; batch adversarial loss: 0.557886\n",
      "epoch 5; iter: 0; batch classifier loss: 0.364670; batch adversarial loss: 0.543875\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323556; batch adversarial loss: 0.555995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.289804; batch adversarial loss: 0.481599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342025; batch adversarial loss: 0.493774\n",
      "epoch 9; iter: 0; batch classifier loss: 0.303141; batch adversarial loss: 0.471785\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314650; batch adversarial loss: 0.465701\n",
      "epoch 11; iter: 0; batch classifier loss: 0.217147; batch adversarial loss: 0.499370\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227525; batch adversarial loss: 0.484023\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272008; batch adversarial loss: 0.528116\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236252; batch adversarial loss: 0.466469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276188; batch adversarial loss: 0.573336\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255134; batch adversarial loss: 0.442729\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276450; batch adversarial loss: 0.489029\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338928; batch adversarial loss: 0.511853\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435054; batch adversarial loss: 0.496070\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420959; batch adversarial loss: 0.486814\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511729; batch adversarial loss: 0.515604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.285206; batch adversarial loss: 0.478652\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251750; batch adversarial loss: 0.421878\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177556; batch adversarial loss: 0.544516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187022; batch adversarial loss: 0.488740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203805; batch adversarial loss: 0.419732\n",
      "epoch 27; iter: 0; batch classifier loss: 0.202774; batch adversarial loss: 0.467484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164055; batch adversarial loss: 0.441368\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129682; batch adversarial loss: 0.343070\n",
      "epoch 30; iter: 0; batch classifier loss: 0.159430; batch adversarial loss: 0.416876\n",
      "epoch 31; iter: 0; batch classifier loss: 0.163640; batch adversarial loss: 0.438712\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130206; batch adversarial loss: 0.455103\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123368; batch adversarial loss: 0.585795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.173192; batch adversarial loss: 0.462787\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160944; batch adversarial loss: 0.527556\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211126; batch adversarial loss: 0.518722\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119129; batch adversarial loss: 0.452101\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182443; batch adversarial loss: 0.467762\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170518; batch adversarial loss: 0.484066\n",
      "epoch 40; iter: 0; batch classifier loss: 0.136234; batch adversarial loss: 0.534713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153239; batch adversarial loss: 0.484316\n",
      "epoch 42; iter: 0; batch classifier loss: 0.178354; batch adversarial loss: 0.391509\n",
      "epoch 43; iter: 0; batch classifier loss: 0.171181; batch adversarial loss: 0.477238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124159; batch adversarial loss: 0.451617\n",
      "epoch 45; iter: 0; batch classifier loss: 0.184013; batch adversarial loss: 0.504860\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152986; batch adversarial loss: 0.427441\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184168; batch adversarial loss: 0.579797\n",
      "epoch 48; iter: 0; batch classifier loss: 0.208298; batch adversarial loss: 0.504965\n",
      "epoch 49; iter: 0; batch classifier loss: 0.172122; batch adversarial loss: 0.410281\n",
      "epoch 50; iter: 0; batch classifier loss: 0.164108; batch adversarial loss: 0.351121\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141504; batch adversarial loss: 0.485991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.187826; batch adversarial loss: 0.481133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223270; batch adversarial loss: 0.410953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.234454; batch adversarial loss: 0.420105\n",
      "epoch 55; iter: 0; batch classifier loss: 0.269719; batch adversarial loss: 0.459532\n",
      "epoch 56; iter: 0; batch classifier loss: 0.164416; batch adversarial loss: 0.408021\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153542; batch adversarial loss: 0.546910\n",
      "epoch 58; iter: 0; batch classifier loss: 0.266020; batch adversarial loss: 0.398108\n",
      "epoch 59; iter: 0; batch classifier loss: 0.257376; batch adversarial loss: 0.480513\n",
      "epoch 60; iter: 0; batch classifier loss: 0.175833; batch adversarial loss: 0.446948\n",
      "epoch 61; iter: 0; batch classifier loss: 0.193618; batch adversarial loss: 0.390508\n",
      "epoch 62; iter: 0; batch classifier loss: 0.169827; batch adversarial loss: 0.374806\n",
      "epoch 63; iter: 0; batch classifier loss: 0.198396; batch adversarial loss: 0.435819\n",
      "epoch 64; iter: 0; batch classifier loss: 0.226184; batch adversarial loss: 0.422065\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228067; batch adversarial loss: 0.421650\n",
      "epoch 66; iter: 0; batch classifier loss: 0.242680; batch adversarial loss: 0.361341\n",
      "epoch 67; iter: 0; batch classifier loss: 0.286541; batch adversarial loss: 0.397696\n",
      "epoch 68; iter: 0; batch classifier loss: 0.214765; batch adversarial loss: 0.396555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.227379; batch adversarial loss: 0.446871\n",
      "epoch 70; iter: 0; batch classifier loss: 0.201143; batch adversarial loss: 0.471018\n",
      "epoch 71; iter: 0; batch classifier loss: 0.175578; batch adversarial loss: 0.581522\n",
      "epoch 72; iter: 0; batch classifier loss: 0.177161; batch adversarial loss: 0.495693\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129861; batch adversarial loss: 0.544735\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093843; batch adversarial loss: 0.483842\n",
      "epoch 75; iter: 0; batch classifier loss: 0.270377; batch adversarial loss: 0.409099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.237794; batch adversarial loss: 0.458800\n",
      "epoch 77; iter: 0; batch classifier loss: 0.201286; batch adversarial loss: 0.372890\n",
      "epoch 78; iter: 0; batch classifier loss: 0.191349; batch adversarial loss: 0.434283\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098777; batch adversarial loss: 0.434101\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107505; batch adversarial loss: 0.332368\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094329; batch adversarial loss: 0.495449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.097507; batch adversarial loss: 0.467219\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115969; batch adversarial loss: 0.439880\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074100; batch adversarial loss: 0.520857\n",
      "epoch 85; iter: 0; batch classifier loss: 0.133601; batch adversarial loss: 0.449474\n",
      "epoch 86; iter: 0; batch classifier loss: 0.161312; batch adversarial loss: 0.470616\n",
      "epoch 87; iter: 0; batch classifier loss: 0.145802; batch adversarial loss: 0.476935\n",
      "epoch 88; iter: 0; batch classifier loss: 0.197696; batch adversarial loss: 0.405454\n",
      "epoch 89; iter: 0; batch classifier loss: 0.234383; batch adversarial loss: 0.432154\n",
      "epoch 90; iter: 0; batch classifier loss: 0.108860; batch adversarial loss: 0.504963\n",
      "epoch 91; iter: 0; batch classifier loss: 0.116994; batch adversarial loss: 0.383545\n",
      "epoch 92; iter: 0; batch classifier loss: 0.126895; batch adversarial loss: 0.438131\n",
      "epoch 93; iter: 0; batch classifier loss: 0.201496; batch adversarial loss: 0.393842\n",
      "epoch 94; iter: 0; batch classifier loss: 0.164595; batch adversarial loss: 0.499617\n",
      "epoch 95; iter: 0; batch classifier loss: 0.137431; batch adversarial loss: 0.394611\n",
      "epoch 96; iter: 0; batch classifier loss: 0.098542; batch adversarial loss: 0.379552\n",
      "epoch 97; iter: 0; batch classifier loss: 0.156320; batch adversarial loss: 0.346578\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086512; batch adversarial loss: 0.531813\n",
      "epoch 99; iter: 0; batch classifier loss: 0.106367; batch adversarial loss: 0.396258\n",
      "epoch 100; iter: 0; batch classifier loss: 0.107402; batch adversarial loss: 0.415111\n",
      "epoch 101; iter: 0; batch classifier loss: 0.149493; batch adversarial loss: 0.547558\n",
      "epoch 102; iter: 0; batch classifier loss: 0.090150; batch adversarial loss: 0.359887\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084368; batch adversarial loss: 0.377884\n",
      "epoch 104; iter: 0; batch classifier loss: 0.121824; batch adversarial loss: 0.457293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.127353; batch adversarial loss: 0.452436\n",
      "epoch 106; iter: 0; batch classifier loss: 0.085895; batch adversarial loss: 0.536619\n",
      "epoch 107; iter: 0; batch classifier loss: 0.106211; batch adversarial loss: 0.431023\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087539; batch adversarial loss: 0.479705\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086051; batch adversarial loss: 0.416131\n",
      "epoch 110; iter: 0; batch classifier loss: 0.072254; batch adversarial loss: 0.448520\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041269; batch adversarial loss: 0.489108\n",
      "epoch 112; iter: 0; batch classifier loss: 0.089310; batch adversarial loss: 0.486776\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075740; batch adversarial loss: 0.399768\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055401; batch adversarial loss: 0.437558\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041811; batch adversarial loss: 0.533921\n",
      "epoch 116; iter: 0; batch classifier loss: 0.069142; batch adversarial loss: 0.491393\n",
      "epoch 117; iter: 0; batch classifier loss: 0.068743; batch adversarial loss: 0.483310\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046394; batch adversarial loss: 0.411974\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063167; batch adversarial loss: 0.478296\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064630; batch adversarial loss: 0.295166\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032430; batch adversarial loss: 0.464569\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030649; batch adversarial loss: 0.389307\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039451; batch adversarial loss: 0.451737\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020841; batch adversarial loss: 0.463292\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054217; batch adversarial loss: 0.499840\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044718; batch adversarial loss: 0.371673\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048235; batch adversarial loss: 0.478096\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068562; batch adversarial loss: 0.402586\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066233; batch adversarial loss: 0.353488\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062799; batch adversarial loss: 0.469833\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036742; batch adversarial loss: 0.479933\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040279; batch adversarial loss: 0.479998\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.377314\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016453; batch adversarial loss: 0.529590\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057017; batch adversarial loss: 0.468524\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046079; batch adversarial loss: 0.419623\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045233; batch adversarial loss: 0.407943\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041805; batch adversarial loss: 0.377811\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029459; batch adversarial loss: 0.466218\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069591; batch adversarial loss: 0.404903\n",
      "epoch 141; iter: 0; batch classifier loss: 0.054597; batch adversarial loss: 0.458050\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023734; batch adversarial loss: 0.445933\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028573; batch adversarial loss: 0.489597\n",
      "epoch 144; iter: 0; batch classifier loss: 0.060649; batch adversarial loss: 0.491805\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067096; batch adversarial loss: 0.432079\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022949; batch adversarial loss: 0.523486\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021634; batch adversarial loss: 0.445279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.043811; batch adversarial loss: 0.455225\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025302; batch adversarial loss: 0.385020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.496481\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024027; batch adversarial loss: 0.425899\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038002; batch adversarial loss: 0.481954\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028893; batch adversarial loss: 0.428791\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024085; batch adversarial loss: 0.468197\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044334; batch adversarial loss: 0.451602\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025810; batch adversarial loss: 0.544231\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029282; batch adversarial loss: 0.503738\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054617; batch adversarial loss: 0.410798\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006260; batch adversarial loss: 0.479746\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033984; batch adversarial loss: 0.466858\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033638; batch adversarial loss: 0.424997\n",
      "epoch 162; iter: 0; batch classifier loss: 0.045732; batch adversarial loss: 0.386279\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025205; batch adversarial loss: 0.442368\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024960; batch adversarial loss: 0.474196\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021406; batch adversarial loss: 0.436332\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019147; batch adversarial loss: 0.436785\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017155; batch adversarial loss: 0.368165\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043912; batch adversarial loss: 0.397891\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025071; batch adversarial loss: 0.418519\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048335; batch adversarial loss: 0.366822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.038206; batch adversarial loss: 0.536538\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047978; batch adversarial loss: 0.427032\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032080; batch adversarial loss: 0.401474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015418; batch adversarial loss: 0.463521\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026401; batch adversarial loss: 0.424062\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007191; batch adversarial loss: 0.501046\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020953; batch adversarial loss: 0.462340\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030861; batch adversarial loss: 0.359701\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024324; batch adversarial loss: 0.507988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.041271; batch adversarial loss: 0.407109\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009680; batch adversarial loss: 0.516495\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.515191\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030094; batch adversarial loss: 0.424147\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010661; batch adversarial loss: 0.398291\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023770; batch adversarial loss: 0.497170\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.464690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.415058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.040632; batch adversarial loss: 0.389003\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017662; batch adversarial loss: 0.410073\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016101; batch adversarial loss: 0.480923\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003110; batch adversarial loss: 0.491784\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021627; batch adversarial loss: 0.484926\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039836; batch adversarial loss: 0.396628\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013745; batch adversarial loss: 0.502386\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009719; batch adversarial loss: 0.423103\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033286; batch adversarial loss: 0.475890\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013079; batch adversarial loss: 0.400948\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008298; batch adversarial loss: 0.490065\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035417; batch adversarial loss: 0.473184\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672875; batch adversarial loss: 0.662044\n",
      "epoch 1; iter: 0; batch classifier loss: 0.481667; batch adversarial loss: 0.625629\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415775; batch adversarial loss: 0.579605\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365877; batch adversarial loss: 0.575237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319281; batch adversarial loss: 0.546834\n",
      "epoch 5; iter: 0; batch classifier loss: 0.264921; batch adversarial loss: 0.523859\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322911; batch adversarial loss: 0.503804\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325946; batch adversarial loss: 0.528391\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298155; batch adversarial loss: 0.490858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.239824; batch adversarial loss: 0.464737\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229386; batch adversarial loss: 0.551835\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274306; batch adversarial loss: 0.498655\n",
      "epoch 12; iter: 0; batch classifier loss: 0.220132; batch adversarial loss: 0.481880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.173579; batch adversarial loss: 0.475751\n",
      "epoch 14; iter: 0; batch classifier loss: 0.219067; batch adversarial loss: 0.470760\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175311; batch adversarial loss: 0.571450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.122938; batch adversarial loss: 0.462286\n",
      "epoch 17; iter: 0; batch classifier loss: 0.229336; batch adversarial loss: 0.445867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.139227; batch adversarial loss: 0.520912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189109; batch adversarial loss: 0.536133\n",
      "epoch 20; iter: 0; batch classifier loss: 0.142742; batch adversarial loss: 0.452483\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172983; batch adversarial loss: 0.451683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162794; batch adversarial loss: 0.588404\n",
      "epoch 23; iter: 0; batch classifier loss: 0.190154; batch adversarial loss: 0.523999\n",
      "epoch 24; iter: 0; batch classifier loss: 0.241520; batch adversarial loss: 0.497211\n",
      "epoch 25; iter: 0; batch classifier loss: 0.153162; batch adversarial loss: 0.478383\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203657; batch adversarial loss: 0.408723\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219015; batch adversarial loss: 0.625405\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214682; batch adversarial loss: 0.515873\n",
      "epoch 29; iter: 0; batch classifier loss: 0.336406; batch adversarial loss: 0.415851\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272052; batch adversarial loss: 0.431788\n",
      "epoch 31; iter: 0; batch classifier loss: 0.295330; batch adversarial loss: 0.561303\n",
      "epoch 32; iter: 0; batch classifier loss: 0.198232; batch adversarial loss: 0.462905\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123792; batch adversarial loss: 0.436425\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111588; batch adversarial loss: 0.385425\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161850; batch adversarial loss: 0.365136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116392; batch adversarial loss: 0.398970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132146; batch adversarial loss: 0.507095\n",
      "epoch 38; iter: 0; batch classifier loss: 0.135579; batch adversarial loss: 0.420940\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107129; batch adversarial loss: 0.330710\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114518; batch adversarial loss: 0.523762\n",
      "epoch 41; iter: 0; batch classifier loss: 0.081852; batch adversarial loss: 0.544000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091355; batch adversarial loss: 0.334415\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089758; batch adversarial loss: 0.408781\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107431; batch adversarial loss: 0.432968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.106278; batch adversarial loss: 0.429497\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075742; batch adversarial loss: 0.487119\n",
      "epoch 47; iter: 0; batch classifier loss: 0.184483; batch adversarial loss: 0.418569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.050941; batch adversarial loss: 0.503225\n",
      "epoch 49; iter: 0; batch classifier loss: 0.122627; batch adversarial loss: 0.381048\n",
      "epoch 50; iter: 0; batch classifier loss: 0.055320; batch adversarial loss: 0.410155\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072000; batch adversarial loss: 0.426085\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146286; batch adversarial loss: 0.442616\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122423; batch adversarial loss: 0.348238\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114888; batch adversarial loss: 0.465548\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077393; batch adversarial loss: 0.472695\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067212; batch adversarial loss: 0.467575\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107459; batch adversarial loss: 0.418165\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103387; batch adversarial loss: 0.401726\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112299; batch adversarial loss: 0.425831\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080836; batch adversarial loss: 0.483512\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071180; batch adversarial loss: 0.423267\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089537; batch adversarial loss: 0.540235\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075503; batch adversarial loss: 0.462882\n",
      "epoch 64; iter: 0; batch classifier loss: 0.119212; batch adversarial loss: 0.525210\n",
      "epoch 65; iter: 0; batch classifier loss: 0.071443; batch adversarial loss: 0.501004\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069014; batch adversarial loss: 0.463178\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054567; batch adversarial loss: 0.410437\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078524; batch adversarial loss: 0.400617\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101717; batch adversarial loss: 0.463334\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107989; batch adversarial loss: 0.430788\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086372; batch adversarial loss: 0.425996\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041800; batch adversarial loss: 0.585306\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075788; batch adversarial loss: 0.523005\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106045; batch adversarial loss: 0.378592\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042550; batch adversarial loss: 0.393156\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069641; batch adversarial loss: 0.511381\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056502; batch adversarial loss: 0.457816\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059647; batch adversarial loss: 0.437679\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055177; batch adversarial loss: 0.574243\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111585; batch adversarial loss: 0.410478\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076622; batch adversarial loss: 0.411994\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088628; batch adversarial loss: 0.379510\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052619; batch adversarial loss: 0.457457\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111007; batch adversarial loss: 0.496683\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041804; batch adversarial loss: 0.472148\n",
      "epoch 86; iter: 0; batch classifier loss: 0.109319; batch adversarial loss: 0.471862\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073154; batch adversarial loss: 0.416090\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089229; batch adversarial loss: 0.495681\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049587; batch adversarial loss: 0.432352\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034026; batch adversarial loss: 0.514197\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073582; batch adversarial loss: 0.506495\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061394; batch adversarial loss: 0.525317\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079333; batch adversarial loss: 0.480613\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070777; batch adversarial loss: 0.427576\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063252; batch adversarial loss: 0.407183\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064927; batch adversarial loss: 0.460846\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089704; batch adversarial loss: 0.415328\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050864; batch adversarial loss: 0.474228\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076246; batch adversarial loss: 0.460925\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043698; batch adversarial loss: 0.472910\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092646; batch adversarial loss: 0.443738\n",
      "epoch 102; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.539739\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035310; batch adversarial loss: 0.449564\n",
      "epoch 104; iter: 0; batch classifier loss: 0.067154; batch adversarial loss: 0.433651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.085287; batch adversarial loss: 0.355921\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060954; batch adversarial loss: 0.491308\n",
      "epoch 107; iter: 0; batch classifier loss: 0.126463; batch adversarial loss: 0.358783\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032310; batch adversarial loss: 0.434009\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038067; batch adversarial loss: 0.389649\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046668; batch adversarial loss: 0.401735\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036083; batch adversarial loss: 0.507810\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062180; batch adversarial loss: 0.370243\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071063; batch adversarial loss: 0.442781\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063934; batch adversarial loss: 0.376481\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040200; batch adversarial loss: 0.497712\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049868; batch adversarial loss: 0.458146\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056287; batch adversarial loss: 0.495755\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022351; batch adversarial loss: 0.455191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059024; batch adversarial loss: 0.463119\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022790; batch adversarial loss: 0.483557\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044010; batch adversarial loss: 0.458109\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027211; batch adversarial loss: 0.506749\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015397; batch adversarial loss: 0.469287\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013539; batch adversarial loss: 0.446407\n",
      "epoch 125; iter: 0; batch classifier loss: 0.071418; batch adversarial loss: 0.461501\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035906; batch adversarial loss: 0.422708\n",
      "epoch 127; iter: 0; batch classifier loss: 0.017828; batch adversarial loss: 0.499476\n",
      "epoch 128; iter: 0; batch classifier loss: 0.066323; batch adversarial loss: 0.432021\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034566; batch adversarial loss: 0.527063\n",
      "epoch 130; iter: 0; batch classifier loss: 0.088499; batch adversarial loss: 0.379650\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017146; batch adversarial loss: 0.461663\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029463; batch adversarial loss: 0.498773\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045451; batch adversarial loss: 0.473029\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043695; batch adversarial loss: 0.468507\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031460; batch adversarial loss: 0.495889\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041262; batch adversarial loss: 0.452762\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023422; batch adversarial loss: 0.442161\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024450; batch adversarial loss: 0.365418\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041689; batch adversarial loss: 0.429519\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026189; batch adversarial loss: 0.467204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.048674; batch adversarial loss: 0.536699\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018645; batch adversarial loss: 0.407738\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051742; batch adversarial loss: 0.402584\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049207; batch adversarial loss: 0.474697\n",
      "epoch 145; iter: 0; batch classifier loss: 0.012968; batch adversarial loss: 0.441663\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063092; batch adversarial loss: 0.362170\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023408; batch adversarial loss: 0.482447\n",
      "epoch 148; iter: 0; batch classifier loss: 0.052967; batch adversarial loss: 0.461570\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063474; batch adversarial loss: 0.388255\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009889; batch adversarial loss: 0.492451\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060980; batch adversarial loss: 0.386735\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.409957\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027716; batch adversarial loss: 0.447335\n",
      "epoch 154; iter: 0; batch classifier loss: 0.074472; batch adversarial loss: 0.497044\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044201; batch adversarial loss: 0.385517\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038402; batch adversarial loss: 0.430780\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.443379\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015636; batch adversarial loss: 0.467091\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039266; batch adversarial loss: 0.536232\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026848; batch adversarial loss: 0.439045\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045912; batch adversarial loss: 0.428664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048647; batch adversarial loss: 0.451645\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037236; batch adversarial loss: 0.505242\n",
      "epoch 164; iter: 0; batch classifier loss: 0.060178; batch adversarial loss: 0.408266\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017655; batch adversarial loss: 0.440378\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042127; batch adversarial loss: 0.419873\n",
      "epoch 167; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.472954\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023768; batch adversarial loss: 0.425290\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021991; batch adversarial loss: 0.466554\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029777; batch adversarial loss: 0.506503\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041673; batch adversarial loss: 0.424878\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008387; batch adversarial loss: 0.422323\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047095; batch adversarial loss: 0.450914\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022308; batch adversarial loss: 0.485709\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045854; batch adversarial loss: 0.503627\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008109; batch adversarial loss: 0.441960\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042421; batch adversarial loss: 0.462594\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041599; batch adversarial loss: 0.495693\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035202; batch adversarial loss: 0.504916\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.536423\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029402; batch adversarial loss: 0.423274\n",
      "epoch 182; iter: 0; batch classifier loss: 0.052184; batch adversarial loss: 0.477930\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016795; batch adversarial loss: 0.467373\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056896; batch adversarial loss: 0.460790\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031166; batch adversarial loss: 0.454343\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018826; batch adversarial loss: 0.411428\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026641; batch adversarial loss: 0.432938\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012593; batch adversarial loss: 0.451975\n",
      "epoch 189; iter: 0; batch classifier loss: 0.033914; batch adversarial loss: 0.358205\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018997; batch adversarial loss: 0.377045\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045901; batch adversarial loss: 0.449450\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017139; batch adversarial loss: 0.462826\n",
      "epoch 193; iter: 0; batch classifier loss: 0.036592; batch adversarial loss: 0.473020\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012219; batch adversarial loss: 0.440309\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016720; batch adversarial loss: 0.480510\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013266; batch adversarial loss: 0.513171\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008717; batch adversarial loss: 0.413754\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023111; batch adversarial loss: 0.488310\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012327; batch adversarial loss: 0.396530\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710654; batch adversarial loss: 0.568532\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493546; batch adversarial loss: 0.628304\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381928; batch adversarial loss: 0.576048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342827; batch adversarial loss: 0.592207\n",
      "epoch 4; iter: 0; batch classifier loss: 0.429323; batch adversarial loss: 0.650225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.394631; batch adversarial loss: 0.607936\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492788; batch adversarial loss: 0.580493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482481; batch adversarial loss: 0.620749\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531659; batch adversarial loss: 0.501444\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414661; batch adversarial loss: 0.491535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435669; batch adversarial loss: 0.531870\n",
      "epoch 11; iter: 0; batch classifier loss: 0.322513; batch adversarial loss: 0.477455\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354029; batch adversarial loss: 0.478617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.296492; batch adversarial loss: 0.516317\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304316; batch adversarial loss: 0.517971\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325586; batch adversarial loss: 0.499148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276557; batch adversarial loss: 0.495569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260920; batch adversarial loss: 0.471432\n",
      "epoch 18; iter: 0; batch classifier loss: 0.215055; batch adversarial loss: 0.535787\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261925; batch adversarial loss: 0.515037\n",
      "epoch 20; iter: 0; batch classifier loss: 0.214483; batch adversarial loss: 0.448180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200218; batch adversarial loss: 0.519372\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225921; batch adversarial loss: 0.440459\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242576; batch adversarial loss: 0.478096\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209162; batch adversarial loss: 0.482982\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201080; batch adversarial loss: 0.468303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180962; batch adversarial loss: 0.462907\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157778; batch adversarial loss: 0.479323\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176023; batch adversarial loss: 0.527583\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220418; batch adversarial loss: 0.401429\n",
      "epoch 30; iter: 0; batch classifier loss: 0.203522; batch adversarial loss: 0.444728\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187242; batch adversarial loss: 0.532755\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127823; batch adversarial loss: 0.539742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224796; batch adversarial loss: 0.498585\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192972; batch adversarial loss: 0.441541\n",
      "epoch 35; iter: 0; batch classifier loss: 0.214996; batch adversarial loss: 0.379733\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189793; batch adversarial loss: 0.424993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 0; batch classifier loss: 0.167746; batch adversarial loss: 0.450194\n",
      "epoch 38; iter: 0; batch classifier loss: 0.216127; batch adversarial loss: 0.491633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.254207; batch adversarial loss: 0.490040\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164361; batch adversarial loss: 0.517797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217183; batch adversarial loss: 0.403226\n",
      "epoch 42; iter: 0; batch classifier loss: 0.217991; batch adversarial loss: 0.434912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212210; batch adversarial loss: 0.413737\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179440; batch adversarial loss: 0.511535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164079; batch adversarial loss: 0.447621\n",
      "epoch 46; iter: 0; batch classifier loss: 0.232804; batch adversarial loss: 0.415866\n",
      "epoch 47; iter: 0; batch classifier loss: 0.198853; batch adversarial loss: 0.493842\n",
      "epoch 48; iter: 0; batch classifier loss: 0.197200; batch adversarial loss: 0.530553\n",
      "epoch 49; iter: 0; batch classifier loss: 0.244343; batch adversarial loss: 0.435532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.200804; batch adversarial loss: 0.460549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211383; batch adversarial loss: 0.506285\n",
      "epoch 52; iter: 0; batch classifier loss: 0.190060; batch adversarial loss: 0.423351\n",
      "epoch 53; iter: 0; batch classifier loss: 0.189200; batch adversarial loss: 0.529735\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118979; batch adversarial loss: 0.471261\n",
      "epoch 55; iter: 0; batch classifier loss: 0.278834; batch adversarial loss: 0.399792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.158166; batch adversarial loss: 0.494146\n",
      "epoch 57; iter: 0; batch classifier loss: 0.055921; batch adversarial loss: 0.553181\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093308; batch adversarial loss: 0.453733\n",
      "epoch 59; iter: 0; batch classifier loss: 0.069623; batch adversarial loss: 0.407503\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080497; batch adversarial loss: 0.497160\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074575; batch adversarial loss: 0.446324\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080347; batch adversarial loss: 0.431698\n",
      "epoch 63; iter: 0; batch classifier loss: 0.047872; batch adversarial loss: 0.522079\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103723; batch adversarial loss: 0.542868\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060147; batch adversarial loss: 0.400860\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060945; batch adversarial loss: 0.444138\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056050; batch adversarial loss: 0.487436\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059091; batch adversarial loss: 0.422819\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064285; batch adversarial loss: 0.591690\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055246; batch adversarial loss: 0.428876\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066426; batch adversarial loss: 0.467976\n",
      "epoch 72; iter: 0; batch classifier loss: 0.041818; batch adversarial loss: 0.487100\n",
      "epoch 73; iter: 0; batch classifier loss: 0.035786; batch adversarial loss: 0.448823\n",
      "epoch 74; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.448617\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050146; batch adversarial loss: 0.490849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048411; batch adversarial loss: 0.379838\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068297; batch adversarial loss: 0.450705\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068126; batch adversarial loss: 0.519088\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043472; batch adversarial loss: 0.454634\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048303; batch adversarial loss: 0.464372\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100948; batch adversarial loss: 0.523925\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074416; batch adversarial loss: 0.551654\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041440; batch adversarial loss: 0.467146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067043; batch adversarial loss: 0.504293\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035302; batch adversarial loss: 0.392633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057646; batch adversarial loss: 0.422896\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062269; batch adversarial loss: 0.481298\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036822; batch adversarial loss: 0.525815\n",
      "epoch 89; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.513263\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058338; batch adversarial loss: 0.447343\n",
      "epoch 91; iter: 0; batch classifier loss: 0.033770; batch adversarial loss: 0.427833\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052793; batch adversarial loss: 0.488528\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058867; batch adversarial loss: 0.422681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077428; batch adversarial loss: 0.517470\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047596; batch adversarial loss: 0.473388\n",
      "epoch 96; iter: 0; batch classifier loss: 0.028274; batch adversarial loss: 0.416542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056881; batch adversarial loss: 0.393324\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067222; batch adversarial loss: 0.354479\n",
      "epoch 99; iter: 0; batch classifier loss: 0.030494; batch adversarial loss: 0.494421\n",
      "epoch 100; iter: 0; batch classifier loss: 0.023833; batch adversarial loss: 0.527540\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079305; batch adversarial loss: 0.446016\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063655; batch adversarial loss: 0.471130\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066386; batch adversarial loss: 0.465983\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048871; batch adversarial loss: 0.445385\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063725; batch adversarial loss: 0.437706\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020028; batch adversarial loss: 0.491174\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030893; batch adversarial loss: 0.507544\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016368; batch adversarial loss: 0.454615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033143; batch adversarial loss: 0.419675\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051801; batch adversarial loss: 0.418386\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068568; batch adversarial loss: 0.495323\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035191; batch adversarial loss: 0.470458\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015479; batch adversarial loss: 0.425404\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041864; batch adversarial loss: 0.488064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034810; batch adversarial loss: 0.482015\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027747; batch adversarial loss: 0.450574\n",
      "epoch 117; iter: 0; batch classifier loss: 0.012659; batch adversarial loss: 0.399039\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035268; batch adversarial loss: 0.543953\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037382; batch adversarial loss: 0.489594\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021069; batch adversarial loss: 0.436506\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045215; batch adversarial loss: 0.470981\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034341; batch adversarial loss: 0.496768\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048364; batch adversarial loss: 0.475267\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048429; batch adversarial loss: 0.359596\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035459; batch adversarial loss: 0.489870\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027882; batch adversarial loss: 0.561963\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040932; batch adversarial loss: 0.472487\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041139; batch adversarial loss: 0.405255\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013349; batch adversarial loss: 0.419567\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021495; batch adversarial loss: 0.415195\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024116; batch adversarial loss: 0.424472\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045474; batch adversarial loss: 0.490668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.036834; batch adversarial loss: 0.459062\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027001; batch adversarial loss: 0.498006\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029386; batch adversarial loss: 0.494137\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033957; batch adversarial loss: 0.471052\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019926; batch adversarial loss: 0.470689\n",
      "epoch 138; iter: 0; batch classifier loss: 0.073218; batch adversarial loss: 0.378168\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025046; batch adversarial loss: 0.471929\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042480; batch adversarial loss: 0.426327\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073944; batch adversarial loss: 0.428614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.006214; batch adversarial loss: 0.457064\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021087; batch adversarial loss: 0.602341\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.494606\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050712; batch adversarial loss: 0.543240\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061491; batch adversarial loss: 0.377169\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026004; batch adversarial loss: 0.510057\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024307; batch adversarial loss: 0.551638\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063920; batch adversarial loss: 0.466812\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.477348\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047023; batch adversarial loss: 0.430291\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013788; batch adversarial loss: 0.486520\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021105; batch adversarial loss: 0.405471\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010442; batch adversarial loss: 0.468781\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015068; batch adversarial loss: 0.382045\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032490; batch adversarial loss: 0.464148\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020143; batch adversarial loss: 0.405528\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016211; batch adversarial loss: 0.461629\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004877; batch adversarial loss: 0.409414\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047954; batch adversarial loss: 0.433021\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008917; batch adversarial loss: 0.488990\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055989; batch adversarial loss: 0.404247\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009199; batch adversarial loss: 0.484323\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017225; batch adversarial loss: 0.375979\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007523; batch adversarial loss: 0.413292\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017116; batch adversarial loss: 0.493143\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023211; batch adversarial loss: 0.515383\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025605; batch adversarial loss: 0.457722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013455; batch adversarial loss: 0.476205\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.490555\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015548; batch adversarial loss: 0.471162\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028388; batch adversarial loss: 0.455230\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020770; batch adversarial loss: 0.364403\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016926; batch adversarial loss: 0.463816\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013871; batch adversarial loss: 0.468239\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010466; batch adversarial loss: 0.466178\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017477; batch adversarial loss: 0.365044\n",
      "epoch 178; iter: 0; batch classifier loss: 0.032302; batch adversarial loss: 0.385551\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016816; batch adversarial loss: 0.517530\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012050; batch adversarial loss: 0.516250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044645; batch adversarial loss: 0.499655\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014829; batch adversarial loss: 0.529839\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014534; batch adversarial loss: 0.422152\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037927; batch adversarial loss: 0.447124\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023245; batch adversarial loss: 0.427188\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014967; batch adversarial loss: 0.478453\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009463; batch adversarial loss: 0.412226\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009734; batch adversarial loss: 0.396691\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034877; batch adversarial loss: 0.500351\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015858; batch adversarial loss: 0.383060\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023372; batch adversarial loss: 0.552556\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017410; batch adversarial loss: 0.400747\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018761; batch adversarial loss: 0.398468\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017318; batch adversarial loss: 0.419414\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021507; batch adversarial loss: 0.388906\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004213; batch adversarial loss: 0.434646\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017841; batch adversarial loss: 0.417391\n",
      "epoch 198; iter: 0; batch classifier loss: 0.034044; batch adversarial loss: 0.470772\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009976; batch adversarial loss: 0.433022\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728760; batch adversarial loss: 1.087008\n",
      "epoch 1; iter: 0; batch classifier loss: 0.599626; batch adversarial loss: 1.034757\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417340; batch adversarial loss: 0.960777\n",
      "epoch 3; iter: 0; batch classifier loss: 0.338677; batch adversarial loss: 0.894271\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316460; batch adversarial loss: 0.814802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.264316; batch adversarial loss: 0.785789\n",
      "epoch 6; iter: 0; batch classifier loss: 0.292636; batch adversarial loss: 0.703460\n",
      "epoch 7; iter: 0; batch classifier loss: 0.263730; batch adversarial loss: 0.659661\n",
      "epoch 8; iter: 0; batch classifier loss: 0.221932; batch adversarial loss: 0.645566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.248851; batch adversarial loss: 0.640529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.201163; batch adversarial loss: 0.599919\n",
      "epoch 11; iter: 0; batch classifier loss: 0.215482; batch adversarial loss: 0.603895\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297191; batch adversarial loss: 0.609969\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236387; batch adversarial loss: 0.539019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210029; batch adversarial loss: 0.583970\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230603; batch adversarial loss: 0.568251\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216639; batch adversarial loss: 0.545057\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210862; batch adversarial loss: 0.500900\n",
      "epoch 18; iter: 0; batch classifier loss: 0.148001; batch adversarial loss: 0.502937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186948; batch adversarial loss: 0.457275\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200689; batch adversarial loss: 0.463240\n",
      "epoch 21; iter: 0; batch classifier loss: 0.143532; batch adversarial loss: 0.480807\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189594; batch adversarial loss: 0.452971\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153090; batch adversarial loss: 0.452023\n",
      "epoch 24; iter: 0; batch classifier loss: 0.212289; batch adversarial loss: 0.468384\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183679; batch adversarial loss: 0.467120\n",
      "epoch 26; iter: 0; batch classifier loss: 0.200942; batch adversarial loss: 0.533292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191428; batch adversarial loss: 0.501184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170342; batch adversarial loss: 0.407190\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221114; batch adversarial loss: 0.398592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.226555; batch adversarial loss: 0.347931\n",
      "epoch 31; iter: 0; batch classifier loss: 0.213036; batch adversarial loss: 0.423942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236607; batch adversarial loss: 0.332512\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195484; batch adversarial loss: 0.468224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.248483; batch adversarial loss: 0.436609\n",
      "epoch 35; iter: 0; batch classifier loss: 0.185705; batch adversarial loss: 0.388378\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174958; batch adversarial loss: 0.404023\n",
      "epoch 37; iter: 0; batch classifier loss: 0.193103; batch adversarial loss: 0.392872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181048; batch adversarial loss: 0.502464\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129450; batch adversarial loss: 0.380331\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204083; batch adversarial loss: 0.442763\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173417; batch adversarial loss: 0.401543\n",
      "epoch 42; iter: 0; batch classifier loss: 0.156427; batch adversarial loss: 0.371687\n",
      "epoch 43; iter: 0; batch classifier loss: 0.193394; batch adversarial loss: 0.465686\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136608; batch adversarial loss: 0.382135\n",
      "epoch 45; iter: 0; batch classifier loss: 0.134686; batch adversarial loss: 0.412065\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154983; batch adversarial loss: 0.358435\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129698; batch adversarial loss: 0.388684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131489; batch adversarial loss: 0.381884\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149880; batch adversarial loss: 0.437669\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095342; batch adversarial loss: 0.389771\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122506; batch adversarial loss: 0.375152\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158596; batch adversarial loss: 0.432393\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133677; batch adversarial loss: 0.412676\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100859; batch adversarial loss: 0.339929\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121614; batch adversarial loss: 0.377500\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102732; batch adversarial loss: 0.411142\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118131; batch adversarial loss: 0.403023\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103274; batch adversarial loss: 0.414455\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077927; batch adversarial loss: 0.374747\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104680; batch adversarial loss: 0.346885\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108699; batch adversarial loss: 0.301210\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097728; batch adversarial loss: 0.397319\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104736; batch adversarial loss: 0.373279\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082934; batch adversarial loss: 0.385239\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118749; batch adversarial loss: 0.306023\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067003; batch adversarial loss: 0.475545\n",
      "epoch 67; iter: 0; batch classifier loss: 0.140384; batch adversarial loss: 0.451014\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111880; batch adversarial loss: 0.411253\n",
      "epoch 69; iter: 0; batch classifier loss: 0.145667; batch adversarial loss: 0.497071\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074918; batch adversarial loss: 0.410072\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092773; batch adversarial loss: 0.466427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.118953; batch adversarial loss: 0.407341\n",
      "epoch 73; iter: 0; batch classifier loss: 0.099033; batch adversarial loss: 0.439423\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092635; batch adversarial loss: 0.488443\n",
      "epoch 75; iter: 0; batch classifier loss: 0.105777; batch adversarial loss: 0.341694\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082740; batch adversarial loss: 0.351892\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056499; batch adversarial loss: 0.483451\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046576; batch adversarial loss: 0.397624\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067997; batch adversarial loss: 0.404626\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059368; batch adversarial loss: 0.378958\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076375; batch adversarial loss: 0.451818\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072261; batch adversarial loss: 0.399291\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080867; batch adversarial loss: 0.454570\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113670; batch adversarial loss: 0.442477\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050853; batch adversarial loss: 0.391976\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089253; batch adversarial loss: 0.466031\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059008; batch adversarial loss: 0.333283\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058520; batch adversarial loss: 0.355565\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055316; batch adversarial loss: 0.499729\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063515; batch adversarial loss: 0.446012\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066402; batch adversarial loss: 0.419414\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095123; batch adversarial loss: 0.401886\n",
      "epoch 93; iter: 0; batch classifier loss: 0.130851; batch adversarial loss: 0.487416\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056647; batch adversarial loss: 0.395734\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077587; batch adversarial loss: 0.486686\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068100; batch adversarial loss: 0.391045\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071063; batch adversarial loss: 0.479873\n",
      "epoch 98; iter: 0; batch classifier loss: 0.107421; batch adversarial loss: 0.424963\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054551; batch adversarial loss: 0.327750\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088323; batch adversarial loss: 0.404862\n",
      "epoch 101; iter: 0; batch classifier loss: 0.159371; batch adversarial loss: 0.369921\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055313; batch adversarial loss: 0.402941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.091071; batch adversarial loss: 0.438892\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070975; batch adversarial loss: 0.392914\n",
      "epoch 105; iter: 0; batch classifier loss: 0.089651; batch adversarial loss: 0.393883\n",
      "epoch 106; iter: 0; batch classifier loss: 0.087328; batch adversarial loss: 0.414847\n",
      "epoch 107; iter: 0; batch classifier loss: 0.088333; batch adversarial loss: 0.495506\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052546; batch adversarial loss: 0.401121\n",
      "epoch 109; iter: 0; batch classifier loss: 0.093476; batch adversarial loss: 0.413711\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089721; batch adversarial loss: 0.382523\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081214; batch adversarial loss: 0.349867\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055191; batch adversarial loss: 0.333070\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.367954\n",
      "epoch 114; iter: 0; batch classifier loss: 0.077242; batch adversarial loss: 0.399583\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050394; batch adversarial loss: 0.441142\n",
      "epoch 116; iter: 0; batch classifier loss: 0.088665; batch adversarial loss: 0.395502\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044675; batch adversarial loss: 0.441264\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051038; batch adversarial loss: 0.508381\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056829; batch adversarial loss: 0.532523\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048645; batch adversarial loss: 0.444159\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045307; batch adversarial loss: 0.409610\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062416; batch adversarial loss: 0.428539\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049230; batch adversarial loss: 0.451194\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055343; batch adversarial loss: 0.446087\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051694; batch adversarial loss: 0.398403\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044115; batch adversarial loss: 0.477711\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041030; batch adversarial loss: 0.428670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.049021; batch adversarial loss: 0.368623\n",
      "epoch 129; iter: 0; batch classifier loss: 0.076195; batch adversarial loss: 0.321581\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035859; batch adversarial loss: 0.390424\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048552; batch adversarial loss: 0.460394\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043572; batch adversarial loss: 0.487389\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056114; batch adversarial loss: 0.551989\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052535; batch adversarial loss: 0.455168\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025810; batch adversarial loss: 0.510888\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016716; batch adversarial loss: 0.385843\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021002; batch adversarial loss: 0.457882\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029742; batch adversarial loss: 0.461643\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043237; batch adversarial loss: 0.420807\n",
      "epoch 140; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.478563\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037265; batch adversarial loss: 0.414080\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031891; batch adversarial loss: 0.385429\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028804; batch adversarial loss: 0.365348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014620; batch adversarial loss: 0.444226\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028014; batch adversarial loss: 0.431907\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018920; batch adversarial loss: 0.501117\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040055; batch adversarial loss: 0.436460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054898; batch adversarial loss: 0.405023\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.445472\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017000; batch adversarial loss: 0.427416\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019502; batch adversarial loss: 0.579490\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046331; batch adversarial loss: 0.525329\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037420; batch adversarial loss: 0.591524\n",
      "epoch 154; iter: 0; batch classifier loss: 0.055853; batch adversarial loss: 0.572980\n",
      "epoch 155; iter: 0; batch classifier loss: 0.094046; batch adversarial loss: 0.570668\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.505306\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027722; batch adversarial loss: 0.435134\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040864; batch adversarial loss: 0.537916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.067577; batch adversarial loss: 0.478104\n",
      "epoch 160; iter: 0; batch classifier loss: 0.131407; batch adversarial loss: 0.752723\n",
      "epoch 161; iter: 0; batch classifier loss: 0.141178; batch adversarial loss: 0.728257\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032382; batch adversarial loss: 0.388900\n",
      "epoch 163; iter: 0; batch classifier loss: 0.183713; batch adversarial loss: 0.680197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.112144; batch adversarial loss: 0.575639\n",
      "epoch 165; iter: 0; batch classifier loss: 0.101823; batch adversarial loss: 0.560346\n",
      "epoch 166; iter: 0; batch classifier loss: 0.148403; batch adversarial loss: 0.699604\n",
      "epoch 167; iter: 0; batch classifier loss: 0.106106; batch adversarial loss: 0.532827\n",
      "epoch 168; iter: 0; batch classifier loss: 0.109085; batch adversarial loss: 0.586747\n",
      "epoch 169; iter: 0; batch classifier loss: 0.126414; batch adversarial loss: 0.565139\n",
      "epoch 170; iter: 0; batch classifier loss: 0.159536; batch adversarial loss: 0.698119\n",
      "epoch 171; iter: 0; batch classifier loss: 0.129451; batch adversarial loss: 0.561769\n",
      "epoch 172; iter: 0; batch classifier loss: 0.112426; batch adversarial loss: 0.540030\n",
      "epoch 173; iter: 0; batch classifier loss: 0.114728; batch adversarial loss: 0.519915\n",
      "epoch 174; iter: 0; batch classifier loss: 0.162752; batch adversarial loss: 0.659420\n",
      "epoch 175; iter: 0; batch classifier loss: 0.175111; batch adversarial loss: 0.542006\n",
      "epoch 176; iter: 0; batch classifier loss: 0.158681; batch adversarial loss: 0.586845\n",
      "epoch 177; iter: 0; batch classifier loss: 0.129336; batch adversarial loss: 0.520678\n",
      "epoch 178; iter: 0; batch classifier loss: 0.216656; batch adversarial loss: 0.657083\n",
      "epoch 179; iter: 0; batch classifier loss: 0.149297; batch adversarial loss: 0.599978\n",
      "epoch 180; iter: 0; batch classifier loss: 0.162425; batch adversarial loss: 0.522675\n",
      "epoch 181; iter: 0; batch classifier loss: 0.084919; batch adversarial loss: 0.451472\n",
      "epoch 182; iter: 0; batch classifier loss: 0.127452; batch adversarial loss: 0.609159\n",
      "epoch 183; iter: 0; batch classifier loss: 0.136553; batch adversarial loss: 0.539933\n",
      "epoch 184; iter: 0; batch classifier loss: 0.148327; batch adversarial loss: 0.487304\n",
      "epoch 185; iter: 0; batch classifier loss: 0.116686; batch adversarial loss: 0.523955\n",
      "epoch 186; iter: 0; batch classifier loss: 0.194729; batch adversarial loss: 0.618018\n",
      "epoch 187; iter: 0; batch classifier loss: 0.175865; batch adversarial loss: 0.555547\n",
      "epoch 188; iter: 0; batch classifier loss: 0.197713; batch adversarial loss: 0.635808\n",
      "epoch 189; iter: 0; batch classifier loss: 0.255430; batch adversarial loss: 0.700401\n",
      "epoch 190; iter: 0; batch classifier loss: 0.162934; batch adversarial loss: 0.481433\n",
      "epoch 191; iter: 0; batch classifier loss: 0.184246; batch adversarial loss: 0.518710\n",
      "epoch 192; iter: 0; batch classifier loss: 0.113035; batch adversarial loss: 0.439236\n",
      "epoch 193; iter: 0; batch classifier loss: 0.137545; batch adversarial loss: 0.551951\n",
      "epoch 194; iter: 0; batch classifier loss: 0.142777; batch adversarial loss: 0.513388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.104230; batch adversarial loss: 0.461459\n",
      "epoch 196; iter: 0; batch classifier loss: 0.106119; batch adversarial loss: 0.487102\n",
      "epoch 197; iter: 0; batch classifier loss: 0.093822; batch adversarial loss: 0.442190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.122167; batch adversarial loss: 0.530757\n",
      "epoch 199; iter: 0; batch classifier loss: 0.141113; batch adversarial loss: 0.429313\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726684; batch adversarial loss: 0.527531\n",
      "epoch 1; iter: 0; batch classifier loss: 0.396746; batch adversarial loss: 0.591250\n",
      "epoch 2; iter: 0; batch classifier loss: 0.410723; batch adversarial loss: 0.595877\n",
      "epoch 3; iter: 0; batch classifier loss: 0.338645; batch adversarial loss: 0.586161\n",
      "epoch 4; iter: 0; batch classifier loss: 0.429481; batch adversarial loss: 0.585051\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317726; batch adversarial loss: 0.582355\n",
      "epoch 6; iter: 0; batch classifier loss: 0.444043; batch adversarial loss: 0.540637\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534541; batch adversarial loss: 0.551978\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438158; batch adversarial loss: 0.621309\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515034; batch adversarial loss: 0.553913\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493573; batch adversarial loss: 0.546712\n",
      "epoch 11; iter: 0; batch classifier loss: 0.571088; batch adversarial loss: 0.522388\n",
      "epoch 12; iter: 0; batch classifier loss: 0.414849; batch adversarial loss: 0.567855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399013; batch adversarial loss: 0.520853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423793; batch adversarial loss: 0.497514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281561; batch adversarial loss: 0.537680\n",
      "epoch 16; iter: 0; batch classifier loss: 0.249669; batch adversarial loss: 0.484343\n",
      "epoch 17; iter: 0; batch classifier loss: 0.274987; batch adversarial loss: 0.532825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246768; batch adversarial loss: 0.504980\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269597; batch adversarial loss: 0.445356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278733; batch adversarial loss: 0.476720\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164392; batch adversarial loss: 0.443543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244512; batch adversarial loss: 0.457797\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171231; batch adversarial loss: 0.457906\n",
      "epoch 24; iter: 0; batch classifier loss: 0.193885; batch adversarial loss: 0.434671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.272282; batch adversarial loss: 0.414572\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141962; batch adversarial loss: 0.489968\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154995; batch adversarial loss: 0.486701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184683; batch adversarial loss: 0.391400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163016; batch adversarial loss: 0.457928\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152226; batch adversarial loss: 0.553705\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109684; batch adversarial loss: 0.431048\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133525; batch adversarial loss: 0.431475\n",
      "epoch 33; iter: 0; batch classifier loss: 0.136050; batch adversarial loss: 0.550971\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080056; batch adversarial loss: 0.489326\n",
      "epoch 35; iter: 0; batch classifier loss: 0.113985; batch adversarial loss: 0.478636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108013; batch adversarial loss: 0.538787\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113846; batch adversarial loss: 0.440460\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100570; batch adversarial loss: 0.508064\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141488; batch adversarial loss: 0.388494\n",
      "epoch 40; iter: 0; batch classifier loss: 0.123801; batch adversarial loss: 0.380187\n",
      "epoch 41; iter: 0; batch classifier loss: 0.172023; batch adversarial loss: 0.348332\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090805; batch adversarial loss: 0.416910\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083146; batch adversarial loss: 0.546203\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112692; batch adversarial loss: 0.452697\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128664; batch adversarial loss: 0.473836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084524; batch adversarial loss: 0.536096\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113230; batch adversarial loss: 0.346111\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115859; batch adversarial loss: 0.373838\n",
      "epoch 49; iter: 0; batch classifier loss: 0.137002; batch adversarial loss: 0.372842\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099349; batch adversarial loss: 0.456717\n",
      "epoch 51; iter: 0; batch classifier loss: 0.041950; batch adversarial loss: 0.577265\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102568; batch adversarial loss: 0.456544\n",
      "epoch 53; iter: 0; batch classifier loss: 0.144652; batch adversarial loss: 0.513074\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133255; batch adversarial loss: 0.478123\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096174; batch adversarial loss: 0.444264\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075159; batch adversarial loss: 0.392691\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090327; batch adversarial loss: 0.419430\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066822; batch adversarial loss: 0.489694\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068075; batch adversarial loss: 0.504063\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069798; batch adversarial loss: 0.508912\n",
      "epoch 61; iter: 0; batch classifier loss: 0.097194; batch adversarial loss: 0.330825\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090657; batch adversarial loss: 0.480290\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078666; batch adversarial loss: 0.397971\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080213; batch adversarial loss: 0.495799\n",
      "epoch 65; iter: 0; batch classifier loss: 0.084679; batch adversarial loss: 0.484711\n",
      "epoch 66; iter: 0; batch classifier loss: 0.178266; batch adversarial loss: 0.372435\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087947; batch adversarial loss: 0.382508\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081676; batch adversarial loss: 0.490101\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095656; batch adversarial loss: 0.461950\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058601; batch adversarial loss: 0.505683\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078578; batch adversarial loss: 0.474512\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091284; batch adversarial loss: 0.555270\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072867; batch adversarial loss: 0.512025\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065090; batch adversarial loss: 0.444930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045312; batch adversarial loss: 0.405144\n",
      "epoch 76; iter: 0; batch classifier loss: 0.043488; batch adversarial loss: 0.372627\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079933; batch adversarial loss: 0.381829\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058153; batch adversarial loss: 0.450180\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075100; batch adversarial loss: 0.490410\n",
      "epoch 80; iter: 0; batch classifier loss: 0.052110; batch adversarial loss: 0.575393\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064421; batch adversarial loss: 0.525924\n",
      "epoch 82; iter: 0; batch classifier loss: 0.092102; batch adversarial loss: 0.452286\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080092; batch adversarial loss: 0.437926\n",
      "epoch 84; iter: 0; batch classifier loss: 0.050999; batch adversarial loss: 0.475324\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054617; batch adversarial loss: 0.516191\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065791; batch adversarial loss: 0.345632\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073604; batch adversarial loss: 0.476827\n",
      "epoch 88; iter: 0; batch classifier loss: 0.090587; batch adversarial loss: 0.378054\n",
      "epoch 89; iter: 0; batch classifier loss: 0.120713; batch adversarial loss: 0.338346\n",
      "epoch 90; iter: 0; batch classifier loss: 0.102075; batch adversarial loss: 0.435127\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048229; batch adversarial loss: 0.561957\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063659; batch adversarial loss: 0.412826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115799; batch adversarial loss: 0.400007\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032607; batch adversarial loss: 0.579317\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056118; batch adversarial loss: 0.350478\n",
      "epoch 96; iter: 0; batch classifier loss: 0.090285; batch adversarial loss: 0.338800\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074256; batch adversarial loss: 0.406793\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038796; batch adversarial loss: 0.475326\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027568; batch adversarial loss: 0.469233\n",
      "epoch 100; iter: 0; batch classifier loss: 0.031613; batch adversarial loss: 0.445061\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080902; batch adversarial loss: 0.527697\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070136; batch adversarial loss: 0.464804\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031918; batch adversarial loss: 0.469514\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038127; batch adversarial loss: 0.399468\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046333; batch adversarial loss: 0.522778\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053773; batch adversarial loss: 0.508368\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025329; batch adversarial loss: 0.507068\n",
      "epoch 108; iter: 0; batch classifier loss: 0.029355; batch adversarial loss: 0.468166\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041551; batch adversarial loss: 0.473091\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025624; batch adversarial loss: 0.478795\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054321; batch adversarial loss: 0.440506\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045060; batch adversarial loss: 0.408989\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043609; batch adversarial loss: 0.490736\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028048; batch adversarial loss: 0.565403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027279; batch adversarial loss: 0.417555\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019354; batch adversarial loss: 0.418402\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058282; batch adversarial loss: 0.443948\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037133; batch adversarial loss: 0.463359\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026283; batch adversarial loss: 0.404205\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049509; batch adversarial loss: 0.362698\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030214; batch adversarial loss: 0.423786\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039450; batch adversarial loss: 0.437067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.058516; batch adversarial loss: 0.376184\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035389; batch adversarial loss: 0.477944\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035372; batch adversarial loss: 0.496687\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042958; batch adversarial loss: 0.528860\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060778; batch adversarial loss: 0.402840\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016014; batch adversarial loss: 0.381500\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030525; batch adversarial loss: 0.515104\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017356; batch adversarial loss: 0.415723\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030523; batch adversarial loss: 0.488247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021803; batch adversarial loss: 0.418887\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.520010\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023162; batch adversarial loss: 0.457992\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017817; batch adversarial loss: 0.503088\n",
      "epoch 136; iter: 0; batch classifier loss: 0.009115; batch adversarial loss: 0.524073\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034120; batch adversarial loss: 0.472376\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050114; batch adversarial loss: 0.423025\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021968; batch adversarial loss: 0.364361\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021399; batch adversarial loss: 0.420013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018312; batch adversarial loss: 0.447955\n",
      "epoch 142; iter: 0; batch classifier loss: 0.070500; batch adversarial loss: 0.419172\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047143; batch adversarial loss: 0.457975\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040098; batch adversarial loss: 0.493659\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.446361\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032119; batch adversarial loss: 0.429829\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068944; batch adversarial loss: 0.517170\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.472501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.506200\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043044; batch adversarial loss: 0.494852\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055650; batch adversarial loss: 0.420460\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014025; batch adversarial loss: 0.444778\n",
      "epoch 153; iter: 0; batch classifier loss: 0.059186; batch adversarial loss: 0.480734\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014166; batch adversarial loss: 0.508836\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013914; batch adversarial loss: 0.364273\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058411; batch adversarial loss: 0.428756\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006496; batch adversarial loss: 0.401003\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015241; batch adversarial loss: 0.488106\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017291; batch adversarial loss: 0.429455\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034354; batch adversarial loss: 0.444842\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022268; batch adversarial loss: 0.456739\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054947; batch adversarial loss: 0.449001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026910; batch adversarial loss: 0.395652\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035400; batch adversarial loss: 0.415787\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018467; batch adversarial loss: 0.486540\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024865; batch adversarial loss: 0.492326\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050106; batch adversarial loss: 0.497489\n",
      "epoch 168; iter: 0; batch classifier loss: 0.044621; batch adversarial loss: 0.451193\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.362039\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013491; batch adversarial loss: 0.405428\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026153; batch adversarial loss: 0.517860\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015781; batch adversarial loss: 0.533693\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015322; batch adversarial loss: 0.427105\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009572; batch adversarial loss: 0.598747\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010508; batch adversarial loss: 0.502897\n",
      "epoch 176; iter: 0; batch classifier loss: 0.056984; batch adversarial loss: 0.483514\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020958; batch adversarial loss: 0.497680\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017784; batch adversarial loss: 0.514733\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016860; batch adversarial loss: 0.411417\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009908; batch adversarial loss: 0.345516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035217; batch adversarial loss: 0.423143\n",
      "epoch 182; iter: 0; batch classifier loss: 0.003546; batch adversarial loss: 0.446397\n",
      "epoch 183; iter: 0; batch classifier loss: 0.003391; batch adversarial loss: 0.476558\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011237; batch adversarial loss: 0.469773\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009964; batch adversarial loss: 0.523529\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003338; batch adversarial loss: 0.482026\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018164; batch adversarial loss: 0.481446\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017138; batch adversarial loss: 0.346334\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013796; batch adversarial loss: 0.444556\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011557; batch adversarial loss: 0.386087\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017304; batch adversarial loss: 0.484183\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031035; batch adversarial loss: 0.440336\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021417; batch adversarial loss: 0.509538\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019208; batch adversarial loss: 0.454203\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017557; batch adversarial loss: 0.457595\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021691; batch adversarial loss: 0.505032\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014834; batch adversarial loss: 0.485044\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007330; batch adversarial loss: 0.511849\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011591; batch adversarial loss: 0.501699\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698663; batch adversarial loss: 0.871021\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492150; batch adversarial loss: 0.933141\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592505; batch adversarial loss: 0.837524\n",
      "epoch 3; iter: 0; batch classifier loss: 0.662515; batch adversarial loss: 0.797176\n",
      "epoch 4; iter: 0; batch classifier loss: 0.814462; batch adversarial loss: 0.728463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.709855; batch adversarial loss: 0.679187\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596712; batch adversarial loss: 0.593242\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296718; batch adversarial loss: 0.566681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.384154; batch adversarial loss: 0.569092\n",
      "epoch 9; iter: 0; batch classifier loss: 0.410607; batch adversarial loss: 0.524396\n",
      "epoch 10; iter: 0; batch classifier loss: 0.357174; batch adversarial loss: 0.545727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.254816; batch adversarial loss: 0.550481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.221024; batch adversarial loss: 0.523697\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292204; batch adversarial loss: 0.510055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240822; batch adversarial loss: 0.476853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.170395; batch adversarial loss: 0.460111\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242294; batch adversarial loss: 0.482612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.204116; batch adversarial loss: 0.424482\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241672; batch adversarial loss: 0.511541\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201717; batch adversarial loss: 0.446448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.131135; batch adversarial loss: 0.434771\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149602; batch adversarial loss: 0.432695\n",
      "epoch 22; iter: 0; batch classifier loss: 0.122427; batch adversarial loss: 0.445243\n",
      "epoch 23; iter: 0; batch classifier loss: 0.143683; batch adversarial loss: 0.418576\n",
      "epoch 24; iter: 0; batch classifier loss: 0.122744; batch adversarial loss: 0.435758\n",
      "epoch 25; iter: 0; batch classifier loss: 0.124750; batch adversarial loss: 0.486888\n",
      "epoch 26; iter: 0; batch classifier loss: 0.108185; batch adversarial loss: 0.412219\n",
      "epoch 27; iter: 0; batch classifier loss: 0.097344; batch adversarial loss: 0.432864\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119572; batch adversarial loss: 0.472044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.116810; batch adversarial loss: 0.469138\n",
      "epoch 30; iter: 0; batch classifier loss: 0.093239; batch adversarial loss: 0.496427\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124861; batch adversarial loss: 0.383082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.082188; batch adversarial loss: 0.503255\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102955; batch adversarial loss: 0.434086\n",
      "epoch 34; iter: 0; batch classifier loss: 0.092246; batch adversarial loss: 0.457121\n",
      "epoch 35; iter: 0; batch classifier loss: 0.101811; batch adversarial loss: 0.310734\n",
      "epoch 36; iter: 0; batch classifier loss: 0.071419; batch adversarial loss: 0.439177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.072087; batch adversarial loss: 0.410610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.079837; batch adversarial loss: 0.491073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082695; batch adversarial loss: 0.448825\n",
      "epoch 40; iter: 0; batch classifier loss: 0.060338; batch adversarial loss: 0.480545\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125343; batch adversarial loss: 0.508171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077028; batch adversarial loss: 0.494491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091883; batch adversarial loss: 0.478094\n",
      "epoch 44; iter: 0; batch classifier loss: 0.091607; batch adversarial loss: 0.458844\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079739; batch adversarial loss: 0.411203\n",
      "epoch 46; iter: 0; batch classifier loss: 0.053331; batch adversarial loss: 0.376651\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071538; batch adversarial loss: 0.428895\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094864; batch adversarial loss: 0.480974\n",
      "epoch 49; iter: 0; batch classifier loss: 0.048834; batch adversarial loss: 0.336742\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088486; batch adversarial loss: 0.412098\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099271; batch adversarial loss: 0.498273\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095992; batch adversarial loss: 0.482679\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098763; batch adversarial loss: 0.473132\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073340; batch adversarial loss: 0.438391\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059777; batch adversarial loss: 0.394678\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067955; batch adversarial loss: 0.469587\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100432; batch adversarial loss: 0.455799\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056005; batch adversarial loss: 0.316533\n",
      "epoch 59; iter: 0; batch classifier loss: 0.054462; batch adversarial loss: 0.395396\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095758; batch adversarial loss: 0.464837\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095085; batch adversarial loss: 0.414900\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092778; batch adversarial loss: 0.448570\n",
      "epoch 63; iter: 0; batch classifier loss: 0.058132; batch adversarial loss: 0.419321\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080304; batch adversarial loss: 0.369840\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053643; batch adversarial loss: 0.366870\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062271; batch adversarial loss: 0.342032\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075322; batch adversarial loss: 0.441501\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070592; batch adversarial loss: 0.421911\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099976; batch adversarial loss: 0.391981\n",
      "epoch 70; iter: 0; batch classifier loss: 0.034132; batch adversarial loss: 0.415315\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058427; batch adversarial loss: 0.503498\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063005; batch adversarial loss: 0.500512\n",
      "epoch 73; iter: 0; batch classifier loss: 0.026120; batch adversarial loss: 0.401813\n",
      "epoch 74; iter: 0; batch classifier loss: 0.042143; batch adversarial loss: 0.419176\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067566; batch adversarial loss: 0.482345\n",
      "epoch 76; iter: 0; batch classifier loss: 0.033771; batch adversarial loss: 0.380953\n",
      "epoch 77; iter: 0; batch classifier loss: 0.021258; batch adversarial loss: 0.376039\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037642; batch adversarial loss: 0.448694\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053607; batch adversarial loss: 0.357729\n",
      "epoch 80; iter: 0; batch classifier loss: 0.033150; batch adversarial loss: 0.379746\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059077; batch adversarial loss: 0.440492\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046365; batch adversarial loss: 0.362216\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034547; batch adversarial loss: 0.417132\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079390; batch adversarial loss: 0.508935\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046209; batch adversarial loss: 0.419527\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053324; batch adversarial loss: 0.456147\n",
      "epoch 87; iter: 0; batch classifier loss: 0.028382; batch adversarial loss: 0.350855\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076326; batch adversarial loss: 0.299994\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053125; batch adversarial loss: 0.417061\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.431986\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064141; batch adversarial loss: 0.425321\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037221; batch adversarial loss: 0.391729\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034529; batch adversarial loss: 0.422215\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068602; batch adversarial loss: 0.410077\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040401; batch adversarial loss: 0.473590\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054545; batch adversarial loss: 0.523287\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054929; batch adversarial loss: 0.455248\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068158; batch adversarial loss: 0.532148\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035482; batch adversarial loss: 0.363518\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054558; batch adversarial loss: 0.401617\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035251; batch adversarial loss: 0.403650\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057199; batch adversarial loss: 0.507172\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037431; batch adversarial loss: 0.405224\n",
      "epoch 104; iter: 0; batch classifier loss: 0.020730; batch adversarial loss: 0.418378\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.356923\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037881; batch adversarial loss: 0.445491\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035386; batch adversarial loss: 0.421144\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030536; batch adversarial loss: 0.428155\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070672; batch adversarial loss: 0.465980\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019506; batch adversarial loss: 0.429211\n",
      "epoch 111; iter: 0; batch classifier loss: 0.026123; batch adversarial loss: 0.476608\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055457; batch adversarial loss: 0.332920\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055841; batch adversarial loss: 0.400403\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065869; batch adversarial loss: 0.378908\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054117; batch adversarial loss: 0.384916\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045131; batch adversarial loss: 0.451731\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039835; batch adversarial loss: 0.501030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.053134; batch adversarial loss: 0.513391\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032899; batch adversarial loss: 0.450571\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028231; batch adversarial loss: 0.397986\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045695; batch adversarial loss: 0.455545\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035576; batch adversarial loss: 0.407126\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084205; batch adversarial loss: 0.337563\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055260; batch adversarial loss: 0.500909\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053243; batch adversarial loss: 0.416673\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057756; batch adversarial loss: 0.424492\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041180; batch adversarial loss: 0.453244\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043048; batch adversarial loss: 0.421517\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044766; batch adversarial loss: 0.346273\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044437; batch adversarial loss: 0.369580\n",
      "epoch 131; iter: 0; batch classifier loss: 0.079172; batch adversarial loss: 0.462275\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043242; batch adversarial loss: 0.388996\n",
      "epoch 133; iter: 0; batch classifier loss: 0.067961; batch adversarial loss: 0.494509\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030572; batch adversarial loss: 0.513643\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037001; batch adversarial loss: 0.419087\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028744; batch adversarial loss: 0.354041\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.392879\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047590; batch adversarial loss: 0.520903\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042407; batch adversarial loss: 0.463464\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060709; batch adversarial loss: 0.362815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.046191; batch adversarial loss: 0.359876\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054757; batch adversarial loss: 0.373371\n",
      "epoch 143; iter: 0; batch classifier loss: 0.083903; batch adversarial loss: 0.524049\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032891; batch adversarial loss: 0.396906\n",
      "epoch 145; iter: 0; batch classifier loss: 0.081201; batch adversarial loss: 0.450803\n",
      "epoch 146; iter: 0; batch classifier loss: 0.068557; batch adversarial loss: 0.418455\n",
      "epoch 147; iter: 0; batch classifier loss: 0.067845; batch adversarial loss: 0.414510\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028667; batch adversarial loss: 0.322853\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032665; batch adversarial loss: 0.333340\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043574; batch adversarial loss: 0.439360\n",
      "epoch 151; iter: 0; batch classifier loss: 0.076861; batch adversarial loss: 0.370562\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070840; batch adversarial loss: 0.429808\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049134; batch adversarial loss: 0.392587\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043947; batch adversarial loss: 0.458200\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048018; batch adversarial loss: 0.472717\n",
      "epoch 156; iter: 0; batch classifier loss: 0.066295; batch adversarial loss: 0.329279\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032727; batch adversarial loss: 0.414069\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025012; batch adversarial loss: 0.447138\n",
      "epoch 159; iter: 0; batch classifier loss: 0.063759; batch adversarial loss: 0.429115\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058568; batch adversarial loss: 0.398859\n",
      "epoch 161; iter: 0; batch classifier loss: 0.057872; batch adversarial loss: 0.468915\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026050; batch adversarial loss: 0.486628\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040611; batch adversarial loss: 0.417553\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062283; batch adversarial loss: 0.473279\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038246; batch adversarial loss: 0.355179\n",
      "epoch 166; iter: 0; batch classifier loss: 0.069958; batch adversarial loss: 0.443291\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039172; batch adversarial loss: 0.496173\n",
      "epoch 168; iter: 0; batch classifier loss: 0.057289; batch adversarial loss: 0.418656\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041924; batch adversarial loss: 0.535850\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040066; batch adversarial loss: 0.418708\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049968; batch adversarial loss: 0.510451\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021591; batch adversarial loss: 0.406204\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046795; batch adversarial loss: 0.408835\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029353; batch adversarial loss: 0.406857\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031797; batch adversarial loss: 0.339639\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055608; batch adversarial loss: 0.337225\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051121; batch adversarial loss: 0.433835\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029622; batch adversarial loss: 0.447803\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016359; batch adversarial loss: 0.362065\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036609; batch adversarial loss: 0.525997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054923; batch adversarial loss: 0.368288\n",
      "epoch 182; iter: 0; batch classifier loss: 0.059720; batch adversarial loss: 0.476217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023461; batch adversarial loss: 0.391204\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031312; batch adversarial loss: 0.505846\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042554; batch adversarial loss: 0.350690\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023941; batch adversarial loss: 0.506405\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024835; batch adversarial loss: 0.391798\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042370; batch adversarial loss: 0.416566\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044748; batch adversarial loss: 0.570140\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034986; batch adversarial loss: 0.433202\n",
      "epoch 191; iter: 0; batch classifier loss: 0.065815; batch adversarial loss: 0.386985\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.467036\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031530; batch adversarial loss: 0.417948\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039443; batch adversarial loss: 0.471996\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034018; batch adversarial loss: 0.385350\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033086; batch adversarial loss: 0.354676\n",
      "epoch 197; iter: 0; batch classifier loss: 0.069851; batch adversarial loss: 0.462202\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030630; batch adversarial loss: 0.417811\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052335; batch adversarial loss: 0.446697\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696145; batch adversarial loss: 0.767424\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476893; batch adversarial loss: 0.717991\n",
      "epoch 2; iter: 0; batch classifier loss: 0.479238; batch adversarial loss: 0.677995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.618452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.305345; batch adversarial loss: 0.608868\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377631; batch adversarial loss: 0.569272\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325938; batch adversarial loss: 0.560398\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304005; batch adversarial loss: 0.572943\n",
      "epoch 8; iter: 0; batch classifier loss: 0.371912; batch adversarial loss: 0.531483\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372948; batch adversarial loss: 0.542226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440224; batch adversarial loss: 0.550579\n",
      "epoch 11; iter: 0; batch classifier loss: 0.418340; batch adversarial loss: 0.533808\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526145; batch adversarial loss: 0.500886\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445844; batch adversarial loss: 0.580940\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403745; batch adversarial loss: 0.528157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.344029; batch adversarial loss: 0.543349\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331757; batch adversarial loss: 0.475602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291092; batch adversarial loss: 0.480159\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303570; batch adversarial loss: 0.438420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.292001; batch adversarial loss: 0.504215\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361579; batch adversarial loss: 0.421690\n",
      "epoch 21; iter: 0; batch classifier loss: 0.239399; batch adversarial loss: 0.501796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.300869; batch adversarial loss: 0.499241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239838; batch adversarial loss: 0.538884\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275367; batch adversarial loss: 0.426154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215679; batch adversarial loss: 0.461199\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217606; batch adversarial loss: 0.529736\n",
      "epoch 27; iter: 0; batch classifier loss: 0.271760; batch adversarial loss: 0.497146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208924; batch adversarial loss: 0.518130\n",
      "epoch 29; iter: 0; batch classifier loss: 0.260237; batch adversarial loss: 0.471534\n",
      "epoch 30; iter: 0; batch classifier loss: 0.232324; batch adversarial loss: 0.451857\n",
      "epoch 31; iter: 0; batch classifier loss: 0.226725; batch adversarial loss: 0.506779\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241506; batch adversarial loss: 0.448843\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198618; batch adversarial loss: 0.436914\n",
      "epoch 34; iter: 0; batch classifier loss: 0.228189; batch adversarial loss: 0.437188\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210921; batch adversarial loss: 0.454172\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215538; batch adversarial loss: 0.450180\n",
      "epoch 37; iter: 0; batch classifier loss: 0.237339; batch adversarial loss: 0.464871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198593; batch adversarial loss: 0.483562\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174212; batch adversarial loss: 0.416435\n",
      "epoch 40; iter: 0; batch classifier loss: 0.163247; batch adversarial loss: 0.371488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249605; batch adversarial loss: 0.352588\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249249; batch adversarial loss: 0.413392\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239149; batch adversarial loss: 0.438207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.227744; batch adversarial loss: 0.438691\n",
      "epoch 45; iter: 0; batch classifier loss: 0.153922; batch adversarial loss: 0.445093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.294794; batch adversarial loss: 0.426857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147597; batch adversarial loss: 0.351772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.273811; batch adversarial loss: 0.399605\n",
      "epoch 49; iter: 0; batch classifier loss: 0.164674; batch adversarial loss: 0.446113\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152978; batch adversarial loss: 0.446631\n",
      "epoch 51; iter: 0; batch classifier loss: 0.195953; batch adversarial loss: 0.434001\n",
      "epoch 52; iter: 0; batch classifier loss: 0.158089; batch adversarial loss: 0.495191\n",
      "epoch 53; iter: 0; batch classifier loss: 0.239498; batch adversarial loss: 0.411677\n",
      "epoch 54; iter: 0; batch classifier loss: 0.131011; batch adversarial loss: 0.494560\n",
      "epoch 55; iter: 0; batch classifier loss: 0.228575; batch adversarial loss: 0.428645\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129540; batch adversarial loss: 0.432732\n",
      "epoch 57; iter: 0; batch classifier loss: 0.193798; batch adversarial loss: 0.407998\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132178; batch adversarial loss: 0.596480\n",
      "epoch 59; iter: 0; batch classifier loss: 0.232865; batch adversarial loss: 0.423328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.161332; batch adversarial loss: 0.447768\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185989; batch adversarial loss: 0.395534\n",
      "epoch 62; iter: 0; batch classifier loss: 0.136407; batch adversarial loss: 0.383247\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111508; batch adversarial loss: 0.482363\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154335; batch adversarial loss: 0.398479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126586; batch adversarial loss: 0.482132\n",
      "epoch 66; iter: 0; batch classifier loss: 0.117696; batch adversarial loss: 0.429199\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112694; batch adversarial loss: 0.542204\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156506; batch adversarial loss: 0.421160\n",
      "epoch 69; iter: 0; batch classifier loss: 0.114507; batch adversarial loss: 0.450063\n",
      "epoch 70; iter: 0; batch classifier loss: 0.096943; batch adversarial loss: 0.479657\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088336; batch adversarial loss: 0.423866\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116297; batch adversarial loss: 0.505667\n",
      "epoch 73; iter: 0; batch classifier loss: 0.097500; batch adversarial loss: 0.411220\n",
      "epoch 74; iter: 0; batch classifier loss: 0.137673; batch adversarial loss: 0.456719\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101866; batch adversarial loss: 0.498895\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068181; batch adversarial loss: 0.403878\n",
      "epoch 77; iter: 0; batch classifier loss: 0.165147; batch adversarial loss: 0.387623\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081072; batch adversarial loss: 0.413291\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094679; batch adversarial loss: 0.409849\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067507; batch adversarial loss: 0.392839\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050557; batch adversarial loss: 0.502738\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055521; batch adversarial loss: 0.434402\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040975; batch adversarial loss: 0.424350\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059258; batch adversarial loss: 0.424517\n",
      "epoch 85; iter: 0; batch classifier loss: 0.030252; batch adversarial loss: 0.447087\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040443; batch adversarial loss: 0.477918\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066150; batch adversarial loss: 0.381146\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032078; batch adversarial loss: 0.516250\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054582; batch adversarial loss: 0.453511\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085268; batch adversarial loss: 0.477355\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066128; batch adversarial loss: 0.447367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.095839; batch adversarial loss: 0.497587\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039484; batch adversarial loss: 0.403264\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069580; batch adversarial loss: 0.352070\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067882; batch adversarial loss: 0.410689\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050955; batch adversarial loss: 0.527028\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043375; batch adversarial loss: 0.399349\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044279; batch adversarial loss: 0.421132\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024973; batch adversarial loss: 0.376312\n",
      "epoch 100; iter: 0; batch classifier loss: 0.034223; batch adversarial loss: 0.382325\n",
      "epoch 101; iter: 0; batch classifier loss: 0.019258; batch adversarial loss: 0.363853\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071242; batch adversarial loss: 0.405224\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.454076\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036862; batch adversarial loss: 0.424397\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030794; batch adversarial loss: 0.485064\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070667; batch adversarial loss: 0.393649\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020788; batch adversarial loss: 0.446644\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.545299\n",
      "epoch 109; iter: 0; batch classifier loss: 0.017597; batch adversarial loss: 0.481568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041217; batch adversarial loss: 0.476759\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045667; batch adversarial loss: 0.418590\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026395; batch adversarial loss: 0.463291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.020729; batch adversarial loss: 0.418543\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038647; batch adversarial loss: 0.527576\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037776; batch adversarial loss: 0.458987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.039617; batch adversarial loss: 0.375158\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057259; batch adversarial loss: 0.439572\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042282; batch adversarial loss: 0.369756\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032318; batch adversarial loss: 0.492552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040898; batch adversarial loss: 0.366313\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038126; batch adversarial loss: 0.533908\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035348; batch adversarial loss: 0.528408\n",
      "epoch 123; iter: 0; batch classifier loss: 0.080700; batch adversarial loss: 0.462584\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045286; batch adversarial loss: 0.459992\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.463565\n",
      "epoch 126; iter: 0; batch classifier loss: 0.077842; batch adversarial loss: 0.379846\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054207; batch adversarial loss: 0.507930\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031593; batch adversarial loss: 0.384658\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015849; batch adversarial loss: 0.444113\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032967; batch adversarial loss: 0.425601\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034123; batch adversarial loss: 0.517427\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042791; batch adversarial loss: 0.429287\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046673; batch adversarial loss: 0.389473\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017633; batch adversarial loss: 0.429743\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012126; batch adversarial loss: 0.433030\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052183; batch adversarial loss: 0.377898\n",
      "epoch 137; iter: 0; batch classifier loss: 0.051082; batch adversarial loss: 0.365150\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032096; batch adversarial loss: 0.366281\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034317; batch adversarial loss: 0.440064\n",
      "epoch 140; iter: 0; batch classifier loss: 0.005473; batch adversarial loss: 0.447580\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015395; batch adversarial loss: 0.322726\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033656; batch adversarial loss: 0.405687\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023717; batch adversarial loss: 0.470389\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030402; batch adversarial loss: 0.460273\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021685; batch adversarial loss: 0.417828\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048666; batch adversarial loss: 0.375316\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026217; batch adversarial loss: 0.399206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034728; batch adversarial loss: 0.409676\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019886; batch adversarial loss: 0.504251\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011555; batch adversarial loss: 0.439703\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023459; batch adversarial loss: 0.426276\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018746; batch adversarial loss: 0.408527\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036254; batch adversarial loss: 0.356480\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024834; batch adversarial loss: 0.385901\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023558; batch adversarial loss: 0.403701\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031023; batch adversarial loss: 0.576675\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018039; batch adversarial loss: 0.546435\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023070; batch adversarial loss: 0.385930\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022090; batch adversarial loss: 0.441898\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032004; batch adversarial loss: 0.438223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033760; batch adversarial loss: 0.421328\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043635; batch adversarial loss: 0.443223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032597; batch adversarial loss: 0.435348\n",
      "epoch 164; iter: 0; batch classifier loss: 0.045547; batch adversarial loss: 0.434893\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046824; batch adversarial loss: 0.419191\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015068; batch adversarial loss: 0.435272\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039844; batch adversarial loss: 0.481873\n",
      "epoch 168; iter: 0; batch classifier loss: 0.054183; batch adversarial loss: 0.397045\n",
      "epoch 169; iter: 0; batch classifier loss: 0.060170; batch adversarial loss: 0.425418\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008173; batch adversarial loss: 0.380407\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041605; batch adversarial loss: 0.449341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020082; batch adversarial loss: 0.448056\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025797; batch adversarial loss: 0.419474\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007810; batch adversarial loss: 0.413384\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022392; batch adversarial loss: 0.386339\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012938; batch adversarial loss: 0.416887\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020021; batch adversarial loss: 0.475040\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015459; batch adversarial loss: 0.465514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011039; batch adversarial loss: 0.394201\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006397; batch adversarial loss: 0.465645\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021147; batch adversarial loss: 0.480166\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019729; batch adversarial loss: 0.439060\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007249; batch adversarial loss: 0.461795\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014959; batch adversarial loss: 0.407227\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020977; batch adversarial loss: 0.443373\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.469564\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036696; batch adversarial loss: 0.497965\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037457; batch adversarial loss: 0.448597\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022374; batch adversarial loss: 0.370175\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025264; batch adversarial loss: 0.429908\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021049; batch adversarial loss: 0.377459\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.437618\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032834; batch adversarial loss: 0.430692\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025754; batch adversarial loss: 0.349262\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022403; batch adversarial loss: 0.412718\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017978; batch adversarial loss: 0.433319\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005569; batch adversarial loss: 0.568889\n",
      "epoch 198; iter: 0; batch classifier loss: 0.032882; batch adversarial loss: 0.458512\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.436697\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666900; batch adversarial loss: 0.741399\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498422; batch adversarial loss: 0.701256\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388994; batch adversarial loss: 0.706415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403115; batch adversarial loss: 0.662371\n",
      "epoch 4; iter: 0; batch classifier loss: 0.329576; batch adversarial loss: 0.631294\n",
      "epoch 5; iter: 0; batch classifier loss: 0.305413; batch adversarial loss: 0.587290\n",
      "epoch 6; iter: 0; batch classifier loss: 0.267538; batch adversarial loss: 0.569848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.327413; batch adversarial loss: 0.552065\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300167; batch adversarial loss: 0.494905\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252559; batch adversarial loss: 0.488461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.244946; batch adversarial loss: 0.505550\n",
      "epoch 11; iter: 0; batch classifier loss: 0.179781; batch adversarial loss: 0.448747\n",
      "epoch 12; iter: 0; batch classifier loss: 0.213284; batch adversarial loss: 0.425466\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267847; batch adversarial loss: 0.446274\n",
      "epoch 14; iter: 0; batch classifier loss: 0.162352; batch adversarial loss: 0.452191\n",
      "epoch 15; iter: 0; batch classifier loss: 0.197742; batch adversarial loss: 0.380323\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190692; batch adversarial loss: 0.405210\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192699; batch adversarial loss: 0.467808\n",
      "epoch 18; iter: 0; batch classifier loss: 0.168321; batch adversarial loss: 0.382068\n",
      "epoch 19; iter: 0; batch classifier loss: 0.242289; batch adversarial loss: 0.393625\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162520; batch adversarial loss: 0.442934\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186503; batch adversarial loss: 0.404789\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177425; batch adversarial loss: 0.369345\n",
      "epoch 23; iter: 0; batch classifier loss: 0.144888; batch adversarial loss: 0.348217\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161807; batch adversarial loss: 0.336711\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157634; batch adversarial loss: 0.410515\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162666; batch adversarial loss: 0.372847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.168903; batch adversarial loss: 0.411298\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167030; batch adversarial loss: 0.351843\n",
      "epoch 29; iter: 0; batch classifier loss: 0.128946; batch adversarial loss: 0.434795\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217275; batch adversarial loss: 0.427552\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193191; batch adversarial loss: 0.378281\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149232; batch adversarial loss: 0.351937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148767; batch adversarial loss: 0.328525\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106660; batch adversarial loss: 0.473122\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110727; batch adversarial loss: 0.454907\n",
      "epoch 36; iter: 0; batch classifier loss: 0.128277; batch adversarial loss: 0.302847\n",
      "epoch 37; iter: 0; batch classifier loss: 0.131197; batch adversarial loss: 0.495188\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124462; batch adversarial loss: 0.350243\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096651; batch adversarial loss: 0.479967\n",
      "epoch 40; iter: 0; batch classifier loss: 0.109735; batch adversarial loss: 0.458198\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107579; batch adversarial loss: 0.324976\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130504; batch adversarial loss: 0.465569\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090459; batch adversarial loss: 0.359764\n",
      "epoch 44; iter: 0; batch classifier loss: 0.084865; batch adversarial loss: 0.411855\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091816; batch adversarial loss: 0.481439\n",
      "epoch 46; iter: 0; batch classifier loss: 0.152331; batch adversarial loss: 0.382016\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087142; batch adversarial loss: 0.500635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106442; batch adversarial loss: 0.397466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101640; batch adversarial loss: 0.406394\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074801; batch adversarial loss: 0.380886\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093346; batch adversarial loss: 0.564595\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090025; batch adversarial loss: 0.369135\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101315; batch adversarial loss: 0.452030\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111574; batch adversarial loss: 0.485733\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087916; batch adversarial loss: 0.461058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.125743; batch adversarial loss: 0.396090\n",
      "epoch 57; iter: 0; batch classifier loss: 0.117050; batch adversarial loss: 0.387680\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089751; batch adversarial loss: 0.425697\n",
      "epoch 59; iter: 0; batch classifier loss: 0.124592; batch adversarial loss: 0.444337\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105738; batch adversarial loss: 0.466391\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095486; batch adversarial loss: 0.358758\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065973; batch adversarial loss: 0.414715\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095105; batch adversarial loss: 0.394385\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062394; batch adversarial loss: 0.375654\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107114; batch adversarial loss: 0.507939\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061963; batch adversarial loss: 0.424494\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121732; batch adversarial loss: 0.471439\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089293; batch adversarial loss: 0.466441\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056780; batch adversarial loss: 0.416240\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067736; batch adversarial loss: 0.478890\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095615; batch adversarial loss: 0.470563\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066834; batch adversarial loss: 0.444708\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.473089\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094899; batch adversarial loss: 0.499684\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077814; batch adversarial loss: 0.408771\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072143; batch adversarial loss: 0.429624\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081402; batch adversarial loss: 0.431090\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077256; batch adversarial loss: 0.443743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.399204\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102041; batch adversarial loss: 0.497692\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057136; batch adversarial loss: 0.436650\n",
      "epoch 82; iter: 0; batch classifier loss: 0.039158; batch adversarial loss: 0.364257\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072848; batch adversarial loss: 0.396666\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053196; batch adversarial loss: 0.443465\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092357; batch adversarial loss: 0.447403\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074728; batch adversarial loss: 0.406463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050510; batch adversarial loss: 0.534347\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068156; batch adversarial loss: 0.401700\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042474; batch adversarial loss: 0.421801\n",
      "epoch 90; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.408339\n",
      "epoch 91; iter: 0; batch classifier loss: 0.038713; batch adversarial loss: 0.412556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.031920; batch adversarial loss: 0.434392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048765; batch adversarial loss: 0.443657\n",
      "epoch 94; iter: 0; batch classifier loss: 0.027739; batch adversarial loss: 0.398886\n",
      "epoch 95; iter: 0; batch classifier loss: 0.027626; batch adversarial loss: 0.423881\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088809; batch adversarial loss: 0.440869\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057330; batch adversarial loss: 0.431450\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035146; batch adversarial loss: 0.347447\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027950; batch adversarial loss: 0.425057\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066080; batch adversarial loss: 0.565507\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032008; batch adversarial loss: 0.476567\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033166; batch adversarial loss: 0.447611\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049833; batch adversarial loss: 0.378375\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030976; batch adversarial loss: 0.490738\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035547; batch adversarial loss: 0.473745\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037019; batch adversarial loss: 0.411592\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056005; batch adversarial loss: 0.334629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.044029; batch adversarial loss: 0.377448\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037348; batch adversarial loss: 0.450393\n",
      "epoch 110; iter: 0; batch classifier loss: 0.018338; batch adversarial loss: 0.368323\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047665; batch adversarial loss: 0.429150\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.439147\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027900; batch adversarial loss: 0.425818\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033047; batch adversarial loss: 0.546231\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044723; batch adversarial loss: 0.386844\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021074; batch adversarial loss: 0.396006\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023681; batch adversarial loss: 0.435811\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.553843\n",
      "epoch 119; iter: 0; batch classifier loss: 0.014162; batch adversarial loss: 0.463434\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045129; batch adversarial loss: 0.349911\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029826; batch adversarial loss: 0.521407\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032083; batch adversarial loss: 0.476560\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021152; batch adversarial loss: 0.477510\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042166; batch adversarial loss: 0.406343\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035964; batch adversarial loss: 0.528311\n",
      "epoch 126; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.522322\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014544; batch adversarial loss: 0.420856\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029938; batch adversarial loss: 0.396808\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.586955\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066354; batch adversarial loss: 0.577297\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078131; batch adversarial loss: 0.504124\n",
      "epoch 132; iter: 0; batch classifier loss: 0.133146; batch adversarial loss: 0.663439\n",
      "epoch 133; iter: 0; batch classifier loss: 0.076937; batch adversarial loss: 0.555055\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072014; batch adversarial loss: 0.519497\n",
      "epoch 135; iter: 0; batch classifier loss: 0.145440; batch adversarial loss: 0.625334\n",
      "epoch 136; iter: 0; batch classifier loss: 0.120980; batch adversarial loss: 0.645675\n",
      "epoch 137; iter: 0; batch classifier loss: 0.089415; batch adversarial loss: 0.646167\n",
      "epoch 138; iter: 0; batch classifier loss: 0.071195; batch adversarial loss: 0.571381\n",
      "epoch 139; iter: 0; batch classifier loss: 0.111121; batch adversarial loss: 0.504044\n",
      "epoch 140; iter: 0; batch classifier loss: 0.096391; batch adversarial loss: 0.555362\n",
      "epoch 141; iter: 0; batch classifier loss: 0.074805; batch adversarial loss: 0.440161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.080243; batch adversarial loss: 0.528068\n",
      "epoch 143; iter: 0; batch classifier loss: 0.169534; batch adversarial loss: 0.648212\n",
      "epoch 144; iter: 0; batch classifier loss: 0.158008; batch adversarial loss: 0.633578\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058353; batch adversarial loss: 0.473404\n",
      "epoch 146; iter: 0; batch classifier loss: 0.078801; batch adversarial loss: 0.401936\n",
      "epoch 147; iter: 0; batch classifier loss: 0.130351; batch adversarial loss: 0.604418\n",
      "epoch 148; iter: 0; batch classifier loss: 0.130789; batch adversarial loss: 0.543974\n",
      "epoch 149; iter: 0; batch classifier loss: 0.168264; batch adversarial loss: 0.715907\n",
      "epoch 150; iter: 0; batch classifier loss: 0.130963; batch adversarial loss: 0.608508\n",
      "epoch 151; iter: 0; batch classifier loss: 0.103628; batch adversarial loss: 0.580320\n",
      "epoch 152; iter: 0; batch classifier loss: 0.077768; batch adversarial loss: 0.459464\n",
      "epoch 153; iter: 0; batch classifier loss: 0.075844; batch adversarial loss: 0.467289\n",
      "epoch 154; iter: 0; batch classifier loss: 0.160059; batch adversarial loss: 0.624877\n",
      "epoch 155; iter: 0; batch classifier loss: 0.062168; batch adversarial loss: 0.511919\n",
      "epoch 156; iter: 0; batch classifier loss: 0.119155; batch adversarial loss: 0.531395\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143428; batch adversarial loss: 0.552238\n",
      "epoch 158; iter: 0; batch classifier loss: 0.173343; batch adversarial loss: 0.588280\n",
      "epoch 159; iter: 0; batch classifier loss: 0.084668; batch adversarial loss: 0.502827\n",
      "epoch 160; iter: 0; batch classifier loss: 0.211330; batch adversarial loss: 0.614562\n",
      "epoch 161; iter: 0; batch classifier loss: 0.096501; batch adversarial loss: 0.542394\n",
      "epoch 162; iter: 0; batch classifier loss: 0.083450; batch adversarial loss: 0.399700\n",
      "epoch 163; iter: 0; batch classifier loss: 0.096878; batch adversarial loss: 0.471906\n",
      "epoch 164; iter: 0; batch classifier loss: 0.096580; batch adversarial loss: 0.583519\n",
      "epoch 165; iter: 0; batch classifier loss: 0.063484; batch adversarial loss: 0.417133\n",
      "epoch 166; iter: 0; batch classifier loss: 0.092549; batch adversarial loss: 0.524329\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036528; batch adversarial loss: 0.340737\n",
      "epoch 168; iter: 0; batch classifier loss: 0.167034; batch adversarial loss: 0.588123\n",
      "epoch 169; iter: 0; batch classifier loss: 0.112135; batch adversarial loss: 0.503759\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044350; batch adversarial loss: 0.432861\n",
      "epoch 171; iter: 0; batch classifier loss: 0.107435; batch adversarial loss: 0.506824\n",
      "epoch 172; iter: 0; batch classifier loss: 0.091599; batch adversarial loss: 0.493950\n",
      "epoch 173; iter: 0; batch classifier loss: 0.094831; batch adversarial loss: 0.430503\n",
      "epoch 174; iter: 0; batch classifier loss: 0.093940; batch adversarial loss: 0.499242\n",
      "epoch 175; iter: 0; batch classifier loss: 0.099069; batch adversarial loss: 0.559301\n",
      "epoch 176; iter: 0; batch classifier loss: 0.062607; batch adversarial loss: 0.431263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.100633; batch adversarial loss: 0.479218\n",
      "epoch 178; iter: 0; batch classifier loss: 0.090063; batch adversarial loss: 0.526361\n",
      "epoch 179; iter: 0; batch classifier loss: 0.096455; batch adversarial loss: 0.425157\n",
      "epoch 180; iter: 0; batch classifier loss: 0.099022; batch adversarial loss: 0.461876\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060034; batch adversarial loss: 0.507026\n",
      "epoch 182; iter: 0; batch classifier loss: 0.047899; batch adversarial loss: 0.424380\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039693; batch adversarial loss: 0.501043\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046807; batch adversarial loss: 0.444353\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016902; batch adversarial loss: 0.392430\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018453; batch adversarial loss: 0.426786\n",
      "epoch 187; iter: 0; batch classifier loss: 0.035008; batch adversarial loss: 0.475447\n",
      "epoch 188; iter: 0; batch classifier loss: 0.053074; batch adversarial loss: 0.442623\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015272; batch adversarial loss: 0.556595\n",
      "epoch 190; iter: 0; batch classifier loss: 0.061709; batch adversarial loss: 0.359992\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020023; batch adversarial loss: 0.350651\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026655; batch adversarial loss: 0.495508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046211; batch adversarial loss: 0.458590\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032738; batch adversarial loss: 0.503287\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041476; batch adversarial loss: 0.501288\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029376; batch adversarial loss: 0.455664\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044642; batch adversarial loss: 0.537296\n",
      "epoch 198; iter: 0; batch classifier loss: 0.078169; batch adversarial loss: 0.411514\n",
      "epoch 199; iter: 0; batch classifier loss: 0.064052; batch adversarial loss: 0.414255\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686697; batch adversarial loss: 0.511148\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446080; batch adversarial loss: 0.551643\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404827; batch adversarial loss: 0.586895\n",
      "epoch 3; iter: 0; batch classifier loss: 0.441248; batch adversarial loss: 0.575899\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399885; batch adversarial loss: 0.523711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.327079; batch adversarial loss: 0.593307\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432368; batch adversarial loss: 0.593606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475996; batch adversarial loss: 0.638511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547968; batch adversarial loss: 0.677138\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584934; batch adversarial loss: 0.579992\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520616; batch adversarial loss: 0.520054\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425354; batch adversarial loss: 0.494760\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275532; batch adversarial loss: 0.548855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290915; batch adversarial loss: 0.476551\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263675; batch adversarial loss: 0.578940\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309476; batch adversarial loss: 0.503728\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265339; batch adversarial loss: 0.448987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172433; batch adversarial loss: 0.424285\n",
      "epoch 18; iter: 0; batch classifier loss: 0.208924; batch adversarial loss: 0.422208\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237301; batch adversarial loss: 0.506112\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272622; batch adversarial loss: 0.506853\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269074; batch adversarial loss: 0.467740\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233730; batch adversarial loss: 0.508324\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219538; batch adversarial loss: 0.508008\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273865; batch adversarial loss: 0.482433\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243810; batch adversarial loss: 0.451516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.205503; batch adversarial loss: 0.447219\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224748; batch adversarial loss: 0.506076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167900; batch adversarial loss: 0.416375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206581; batch adversarial loss: 0.501018\n",
      "epoch 30; iter: 0; batch classifier loss: 0.303730; batch adversarial loss: 0.474086\n",
      "epoch 31; iter: 0; batch classifier loss: 0.192386; batch adversarial loss: 0.490497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.268700; batch adversarial loss: 0.425589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158990; batch adversarial loss: 0.475599\n",
      "epoch 34; iter: 0; batch classifier loss: 0.256142; batch adversarial loss: 0.453216\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223897; batch adversarial loss: 0.434577\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235768; batch adversarial loss: 0.533907\n",
      "epoch 37; iter: 0; batch classifier loss: 0.265241; batch adversarial loss: 0.414736\n",
      "epoch 38; iter: 0; batch classifier loss: 0.310333; batch adversarial loss: 0.446942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.229716; batch adversarial loss: 0.482926\n",
      "epoch 40; iter: 0; batch classifier loss: 0.333460; batch adversarial loss: 0.375233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.227954; batch adversarial loss: 0.479189\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238465; batch adversarial loss: 0.436416\n",
      "epoch 43; iter: 0; batch classifier loss: 0.252853; batch adversarial loss: 0.445851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.311203; batch adversarial loss: 0.425968\n",
      "epoch 45; iter: 0; batch classifier loss: 0.327705; batch adversarial loss: 0.410650\n",
      "epoch 46; iter: 0; batch classifier loss: 0.271528; batch adversarial loss: 0.475157\n",
      "epoch 47; iter: 0; batch classifier loss: 0.228905; batch adversarial loss: 0.389982\n",
      "epoch 48; iter: 0; batch classifier loss: 0.296520; batch adversarial loss: 0.447758\n",
      "epoch 49; iter: 0; batch classifier loss: 0.300486; batch adversarial loss: 0.389369\n",
      "epoch 50; iter: 0; batch classifier loss: 0.261162; batch adversarial loss: 0.508173\n",
      "epoch 51; iter: 0; batch classifier loss: 0.259944; batch adversarial loss: 0.422749\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155571; batch adversarial loss: 0.434118\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133254; batch adversarial loss: 0.492551\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095371; batch adversarial loss: 0.405030\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110268; batch adversarial loss: 0.446363\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102939; batch adversarial loss: 0.469100\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126597; batch adversarial loss: 0.526176\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094055; batch adversarial loss: 0.505567\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141631; batch adversarial loss: 0.394108\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111960; batch adversarial loss: 0.434300\n",
      "epoch 61; iter: 0; batch classifier loss: 0.145540; batch adversarial loss: 0.480852\n",
      "epoch 62; iter: 0; batch classifier loss: 0.199409; batch adversarial loss: 0.468533\n",
      "epoch 63; iter: 0; batch classifier loss: 0.213992; batch adversarial loss: 0.458799\n",
      "epoch 64; iter: 0; batch classifier loss: 0.146350; batch adversarial loss: 0.446741\n",
      "epoch 65; iter: 0; batch classifier loss: 0.192868; batch adversarial loss: 0.524448\n",
      "epoch 66; iter: 0; batch classifier loss: 0.136133; batch adversarial loss: 0.462213\n",
      "epoch 67; iter: 0; batch classifier loss: 0.158270; batch adversarial loss: 0.482829\n",
      "epoch 68; iter: 0; batch classifier loss: 0.199733; batch adversarial loss: 0.370146\n",
      "epoch 69; iter: 0; batch classifier loss: 0.242931; batch adversarial loss: 0.371094\n",
      "epoch 70; iter: 0; batch classifier loss: 0.173726; batch adversarial loss: 0.428345\n",
      "epoch 71; iter: 0; batch classifier loss: 0.225798; batch adversarial loss: 0.411905\n",
      "epoch 72; iter: 0; batch classifier loss: 0.194240; batch adversarial loss: 0.435027\n",
      "epoch 73; iter: 0; batch classifier loss: 0.239953; batch adversarial loss: 0.529448\n",
      "epoch 74; iter: 0; batch classifier loss: 0.208392; batch adversarial loss: 0.479131\n",
      "epoch 75; iter: 0; batch classifier loss: 0.223357; batch adversarial loss: 0.359324\n",
      "epoch 76; iter: 0; batch classifier loss: 0.213750; batch adversarial loss: 0.398909\n",
      "epoch 77; iter: 0; batch classifier loss: 0.235070; batch adversarial loss: 0.424187\n",
      "epoch 78; iter: 0; batch classifier loss: 0.225661; batch adversarial loss: 0.484115\n",
      "epoch 79; iter: 0; batch classifier loss: 0.196841; batch adversarial loss: 0.346900\n",
      "epoch 80; iter: 0; batch classifier loss: 0.314986; batch adversarial loss: 0.494728\n",
      "epoch 81; iter: 0; batch classifier loss: 0.210322; batch adversarial loss: 0.495893\n",
      "epoch 82; iter: 0; batch classifier loss: 0.194342; batch adversarial loss: 0.360028\n",
      "epoch 83; iter: 0; batch classifier loss: 0.201559; batch adversarial loss: 0.434589\n",
      "epoch 84; iter: 0; batch classifier loss: 0.174959; batch adversarial loss: 0.422288\n",
      "epoch 85; iter: 0; batch classifier loss: 0.191943; batch adversarial loss: 0.372125\n",
      "epoch 86; iter: 0; batch classifier loss: 0.114757; batch adversarial loss: 0.433932\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072628; batch adversarial loss: 0.491774\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100655; batch adversarial loss: 0.463327\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061221; batch adversarial loss: 0.402833\n",
      "epoch 90; iter: 0; batch classifier loss: 0.092881; batch adversarial loss: 0.505985\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052061; batch adversarial loss: 0.379911\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064051; batch adversarial loss: 0.372795\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037755; batch adversarial loss: 0.517730\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051810; batch adversarial loss: 0.499690\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039851; batch adversarial loss: 0.409494\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050922; batch adversarial loss: 0.461284\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058641; batch adversarial loss: 0.484479\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.503053\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056293; batch adversarial loss: 0.379229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075679; batch adversarial loss: 0.327617\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051141; batch adversarial loss: 0.388053\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062469; batch adversarial loss: 0.486497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.059694; batch adversarial loss: 0.408350\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058373; batch adversarial loss: 0.472214\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054293; batch adversarial loss: 0.466378\n",
      "epoch 106; iter: 0; batch classifier loss: 0.096998; batch adversarial loss: 0.466142\n",
      "epoch 107; iter: 0; batch classifier loss: 0.077268; batch adversarial loss: 0.504311\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064226; batch adversarial loss: 0.387425\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053179; batch adversarial loss: 0.462661\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059825; batch adversarial loss: 0.538468\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056369; batch adversarial loss: 0.398463\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045735; batch adversarial loss: 0.346963\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028859; batch adversarial loss: 0.453751\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069840; batch adversarial loss: 0.458917\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050539; batch adversarial loss: 0.459875\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028321; batch adversarial loss: 0.389770\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041946; batch adversarial loss: 0.490797\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056960; batch adversarial loss: 0.350006\n",
      "epoch 119; iter: 0; batch classifier loss: 0.058905; batch adversarial loss: 0.397316\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046116; batch adversarial loss: 0.424848\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058465; batch adversarial loss: 0.412346\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061589; batch adversarial loss: 0.454177\n",
      "epoch 123; iter: 0; batch classifier loss: 0.090456; batch adversarial loss: 0.368491\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059522; batch adversarial loss: 0.468175\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066218; batch adversarial loss: 0.414627\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068849; batch adversarial loss: 0.499958\n",
      "epoch 127; iter: 0; batch classifier loss: 0.066555; batch adversarial loss: 0.449339\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031562; batch adversarial loss: 0.403243\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050510; batch adversarial loss: 0.490668\n",
      "epoch 130; iter: 0; batch classifier loss: 0.052801; batch adversarial loss: 0.496366\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043428; batch adversarial loss: 0.393227\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054453; batch adversarial loss: 0.361397\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049696; batch adversarial loss: 0.395344\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072534; batch adversarial loss: 0.390652\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049919; batch adversarial loss: 0.409359\n",
      "epoch 136; iter: 0; batch classifier loss: 0.078531; batch adversarial loss: 0.399281\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055121; batch adversarial loss: 0.414705\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044069; batch adversarial loss: 0.476267\n",
      "epoch 139; iter: 0; batch classifier loss: 0.061475; batch adversarial loss: 0.467443\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060834; batch adversarial loss: 0.422138\n",
      "epoch 141; iter: 0; batch classifier loss: 0.081887; batch adversarial loss: 0.426054\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037843; batch adversarial loss: 0.467185\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044911; batch adversarial loss: 0.401847\n",
      "epoch 144; iter: 0; batch classifier loss: 0.071562; batch adversarial loss: 0.471628\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052198; batch adversarial loss: 0.453534\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046972; batch adversarial loss: 0.395098\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046098; batch adversarial loss: 0.396861\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048158; batch adversarial loss: 0.444705\n",
      "epoch 149; iter: 0; batch classifier loss: 0.057259; batch adversarial loss: 0.437210\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018531; batch adversarial loss: 0.505339\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039569; batch adversarial loss: 0.389147\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036138; batch adversarial loss: 0.356214\n",
      "epoch 153; iter: 0; batch classifier loss: 0.072217; batch adversarial loss: 0.440970\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034273; batch adversarial loss: 0.431501\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040713; batch adversarial loss: 0.426855\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040671; batch adversarial loss: 0.399924\n",
      "epoch 157; iter: 0; batch classifier loss: 0.062771; batch adversarial loss: 0.462034\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076438; batch adversarial loss: 0.328525\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047750; batch adversarial loss: 0.416391\n",
      "epoch 160; iter: 0; batch classifier loss: 0.062231; batch adversarial loss: 0.413634\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054833; batch adversarial loss: 0.462905\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037099; batch adversarial loss: 0.436838\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059157; batch adversarial loss: 0.464693\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041383; batch adversarial loss: 0.490463\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031120; batch adversarial loss: 0.390224\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033253; batch adversarial loss: 0.476336\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043460; batch adversarial loss: 0.392471\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042682; batch adversarial loss: 0.377722\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032639; batch adversarial loss: 0.407490\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028552; batch adversarial loss: 0.391918\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044019; batch adversarial loss: 0.384418\n",
      "epoch 172; iter: 0; batch classifier loss: 0.063057; batch adversarial loss: 0.466305\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039960; batch adversarial loss: 0.511487\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039943; batch adversarial loss: 0.500973\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027943; batch adversarial loss: 0.391922\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.394722\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.444327\n",
      "epoch 178; iter: 0; batch classifier loss: 0.072045; batch adversarial loss: 0.362231\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027846; batch adversarial loss: 0.429818\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039498; batch adversarial loss: 0.471771\n",
      "epoch 181; iter: 0; batch classifier loss: 0.038450; batch adversarial loss: 0.430510\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029830; batch adversarial loss: 0.442008\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023164; batch adversarial loss: 0.499936\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037480; batch adversarial loss: 0.408101\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033967; batch adversarial loss: 0.409372\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036317; batch adversarial loss: 0.449428\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027489; batch adversarial loss: 0.398508\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032163; batch adversarial loss: 0.437012\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013496; batch adversarial loss: 0.569537\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039364; batch adversarial loss: 0.446187\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021191; batch adversarial loss: 0.406714\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017727; batch adversarial loss: 0.450986\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015609; batch adversarial loss: 0.440968\n",
      "epoch 194; iter: 0; batch classifier loss: 0.062564; batch adversarial loss: 0.450489\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024091; batch adversarial loss: 0.452612\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017244; batch adversarial loss: 0.547871\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014884; batch adversarial loss: 0.411362\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028856; batch adversarial loss: 0.555540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.034595; batch adversarial loss: 0.443978\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675375; batch adversarial loss: 0.899496\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605984; batch adversarial loss: 0.880631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.949207; batch adversarial loss: 0.917117\n",
      "epoch 3; iter: 0; batch classifier loss: 0.827757; batch adversarial loss: 0.787392\n",
      "epoch 4; iter: 0; batch classifier loss: 0.901134; batch adversarial loss: 0.752893\n",
      "epoch 5; iter: 0; batch classifier loss: 0.938100; batch adversarial loss: 0.672729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627732; batch adversarial loss: 0.618119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475625; batch adversarial loss: 0.578482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356721; batch adversarial loss: 0.521461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.293167; batch adversarial loss: 0.543674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316546; batch adversarial loss: 0.563095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.276163; batch adversarial loss: 0.527910\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326715; batch adversarial loss: 0.511328\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297743; batch adversarial loss: 0.538428\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315822; batch adversarial loss: 0.535255\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294470; batch adversarial loss: 0.509061\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298595; batch adversarial loss: 0.482216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269859; batch adversarial loss: 0.473245\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255185; batch adversarial loss: 0.514544\n",
      "epoch 19; iter: 0; batch classifier loss: 0.239243; batch adversarial loss: 0.481713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279890; batch adversarial loss: 0.521207\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325651; batch adversarial loss: 0.499928\n",
      "epoch 22; iter: 0; batch classifier loss: 0.299260; batch adversarial loss: 0.447062\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225002; batch adversarial loss: 0.507479\n",
      "epoch 24; iter: 0; batch classifier loss: 0.277950; batch adversarial loss: 0.478528\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279805; batch adversarial loss: 0.477371\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213929; batch adversarial loss: 0.467178\n",
      "epoch 27; iter: 0; batch classifier loss: 0.267787; batch adversarial loss: 0.485232\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214113; batch adversarial loss: 0.499323\n",
      "epoch 29; iter: 0; batch classifier loss: 0.245324; batch adversarial loss: 0.399596\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210447; batch adversarial loss: 0.512701\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222511; batch adversarial loss: 0.516663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242460; batch adversarial loss: 0.457371\n",
      "epoch 33; iter: 0; batch classifier loss: 0.279715; batch adversarial loss: 0.482119\n",
      "epoch 34; iter: 0; batch classifier loss: 0.202994; batch adversarial loss: 0.571426\n",
      "epoch 35; iter: 0; batch classifier loss: 0.261467; batch adversarial loss: 0.426910\n",
      "epoch 36; iter: 0; batch classifier loss: 0.225454; batch adversarial loss: 0.405374\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183319; batch adversarial loss: 0.482762\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217537; batch adversarial loss: 0.533987\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245361; batch adversarial loss: 0.474018\n",
      "epoch 40; iter: 0; batch classifier loss: 0.222069; batch adversarial loss: 0.393907\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184149; batch adversarial loss: 0.428763\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169145; batch adversarial loss: 0.564492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168574; batch adversarial loss: 0.453303\n",
      "epoch 44; iter: 0; batch classifier loss: 0.239847; batch adversarial loss: 0.440660\n",
      "epoch 45; iter: 0; batch classifier loss: 0.224240; batch adversarial loss: 0.464612\n",
      "epoch 46; iter: 0; batch classifier loss: 0.172835; batch adversarial loss: 0.517041\n",
      "epoch 47; iter: 0; batch classifier loss: 0.251583; batch adversarial loss: 0.416518\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236752; batch adversarial loss: 0.396813\n",
      "epoch 49; iter: 0; batch classifier loss: 0.169561; batch adversarial loss: 0.484701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207123; batch adversarial loss: 0.471922\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175044; batch adversarial loss: 0.419310\n",
      "epoch 52; iter: 0; batch classifier loss: 0.156996; batch adversarial loss: 0.471912\n",
      "epoch 53; iter: 0; batch classifier loss: 0.221331; batch adversarial loss: 0.495266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.217626; batch adversarial loss: 0.453505\n",
      "epoch 55; iter: 0; batch classifier loss: 0.188696; batch adversarial loss: 0.514854\n",
      "epoch 56; iter: 0; batch classifier loss: 0.143148; batch adversarial loss: 0.505980\n",
      "epoch 57; iter: 0; batch classifier loss: 0.150398; batch adversarial loss: 0.463436\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180779; batch adversarial loss: 0.410734\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192743; batch adversarial loss: 0.442521\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180498; batch adversarial loss: 0.363129\n",
      "epoch 61; iter: 0; batch classifier loss: 0.207302; batch adversarial loss: 0.421215\n",
      "epoch 62; iter: 0; batch classifier loss: 0.225381; batch adversarial loss: 0.396438\n",
      "epoch 63; iter: 0; batch classifier loss: 0.157039; batch adversarial loss: 0.421916\n",
      "epoch 64; iter: 0; batch classifier loss: 0.147290; batch adversarial loss: 0.468971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.164678; batch adversarial loss: 0.397663\n",
      "epoch 66; iter: 0; batch classifier loss: 0.197678; batch adversarial loss: 0.420501\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122971; batch adversarial loss: 0.417964\n",
      "epoch 68; iter: 0; batch classifier loss: 0.220730; batch adversarial loss: 0.532707\n",
      "epoch 69; iter: 0; batch classifier loss: 0.173010; batch adversarial loss: 0.434222\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131066; batch adversarial loss: 0.408612\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194026; batch adversarial loss: 0.443547\n",
      "epoch 72; iter: 0; batch classifier loss: 0.139920; batch adversarial loss: 0.473131\n",
      "epoch 73; iter: 0; batch classifier loss: 0.170272; batch adversarial loss: 0.407937\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164435; batch adversarial loss: 0.432828\n",
      "epoch 75; iter: 0; batch classifier loss: 0.197556; batch adversarial loss: 0.408619\n",
      "epoch 76; iter: 0; batch classifier loss: 0.183792; batch adversarial loss: 0.458722\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184544; batch adversarial loss: 0.459811\n",
      "epoch 78; iter: 0; batch classifier loss: 0.129891; batch adversarial loss: 0.456331\n",
      "epoch 79; iter: 0; batch classifier loss: 0.173363; batch adversarial loss: 0.460725\n",
      "epoch 80; iter: 0; batch classifier loss: 0.160067; batch adversarial loss: 0.419157\n",
      "epoch 81; iter: 0; batch classifier loss: 0.121410; batch adversarial loss: 0.479937\n",
      "epoch 82; iter: 0; batch classifier loss: 0.200972; batch adversarial loss: 0.468740\n",
      "epoch 83; iter: 0; batch classifier loss: 0.145549; batch adversarial loss: 0.540725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.136068; batch adversarial loss: 0.448588\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154252; batch adversarial loss: 0.436247\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206172; batch adversarial loss: 0.472707\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122784; batch adversarial loss: 0.605094\n",
      "epoch 88; iter: 0; batch classifier loss: 0.176348; batch adversarial loss: 0.496879\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128989; batch adversarial loss: 0.425740\n",
      "epoch 90; iter: 0; batch classifier loss: 0.139908; batch adversarial loss: 0.399211\n",
      "epoch 91; iter: 0; batch classifier loss: 0.138614; batch adversarial loss: 0.526487\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144423; batch adversarial loss: 0.421464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.158413; batch adversarial loss: 0.348788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.140780; batch adversarial loss: 0.399878\n",
      "epoch 95; iter: 0; batch classifier loss: 0.157503; batch adversarial loss: 0.462568\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117970; batch adversarial loss: 0.532693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97; iter: 0; batch classifier loss: 0.160550; batch adversarial loss: 0.461624\n",
      "epoch 98; iter: 0; batch classifier loss: 0.106326; batch adversarial loss: 0.505983\n",
      "epoch 99; iter: 0; batch classifier loss: 0.215361; batch adversarial loss: 0.507318\n",
      "epoch 100; iter: 0; batch classifier loss: 0.163467; batch adversarial loss: 0.469158\n",
      "epoch 101; iter: 0; batch classifier loss: 0.165825; batch adversarial loss: 0.453503\n",
      "epoch 102; iter: 0; batch classifier loss: 0.212209; batch adversarial loss: 0.419961\n",
      "epoch 103; iter: 0; batch classifier loss: 0.143419; batch adversarial loss: 0.421398\n",
      "epoch 104; iter: 0; batch classifier loss: 0.097400; batch adversarial loss: 0.359412\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117755; batch adversarial loss: 0.442513\n",
      "epoch 106; iter: 0; batch classifier loss: 0.140019; batch adversarial loss: 0.468191\n",
      "epoch 107; iter: 0; batch classifier loss: 0.153152; batch adversarial loss: 0.398277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122027; batch adversarial loss: 0.394966\n",
      "epoch 109; iter: 0; batch classifier loss: 0.079067; batch adversarial loss: 0.457130\n",
      "epoch 110; iter: 0; batch classifier loss: 0.139914; batch adversarial loss: 0.556850\n",
      "epoch 111; iter: 0; batch classifier loss: 0.143101; batch adversarial loss: 0.578801\n",
      "epoch 112; iter: 0; batch classifier loss: 0.088238; batch adversarial loss: 0.419766\n",
      "epoch 113; iter: 0; batch classifier loss: 0.080966; batch adversarial loss: 0.418970\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079762; batch adversarial loss: 0.507755\n",
      "epoch 115; iter: 0; batch classifier loss: 0.091974; batch adversarial loss: 0.562528\n",
      "epoch 116; iter: 0; batch classifier loss: 0.125344; batch adversarial loss: 0.402137\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058537; batch adversarial loss: 0.420567\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049449; batch adversarial loss: 0.452146\n",
      "epoch 119; iter: 0; batch classifier loss: 0.095080; batch adversarial loss: 0.425689\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072303; batch adversarial loss: 0.492064\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.508555\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061063; batch adversarial loss: 0.448121\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069257; batch adversarial loss: 0.448836\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.401108\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062802; batch adversarial loss: 0.427846\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048517; batch adversarial loss: 0.507497\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061797; batch adversarial loss: 0.567657\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064008; batch adversarial loss: 0.461551\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036375; batch adversarial loss: 0.500517\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045802; batch adversarial loss: 0.435466\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026494; batch adversarial loss: 0.536644\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049787; batch adversarial loss: 0.482922\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023491; batch adversarial loss: 0.471597\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028378; batch adversarial loss: 0.474586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.059453; batch adversarial loss: 0.482050\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024868; batch adversarial loss: 0.545956\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041904; batch adversarial loss: 0.444402\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039981; batch adversarial loss: 0.475434\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038000; batch adversarial loss: 0.412727\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068876; batch adversarial loss: 0.484249\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029289; batch adversarial loss: 0.526560\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054715; batch adversarial loss: 0.395556\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031511; batch adversarial loss: 0.492226\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021909; batch adversarial loss: 0.388966\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009392; batch adversarial loss: 0.476133\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020309; batch adversarial loss: 0.554052\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037842; batch adversarial loss: 0.461118\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013293; batch adversarial loss: 0.493301\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030972; batch adversarial loss: 0.431763\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026313; batch adversarial loss: 0.496163\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037204; batch adversarial loss: 0.567110\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018356; batch adversarial loss: 0.460046\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.405470\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029235; batch adversarial loss: 0.430137\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031491; batch adversarial loss: 0.429951\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015760; batch adversarial loss: 0.418727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014440; batch adversarial loss: 0.464090\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035876; batch adversarial loss: 0.514382\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035665; batch adversarial loss: 0.481576\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029736; batch adversarial loss: 0.515066\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023814; batch adversarial loss: 0.495710\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012466; batch adversarial loss: 0.362833\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013590; batch adversarial loss: 0.373580\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026949; batch adversarial loss: 0.468397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028270; batch adversarial loss: 0.438922\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.491215\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006101; batch adversarial loss: 0.412955\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011997; batch adversarial loss: 0.490792\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021382; batch adversarial loss: 0.416933\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008720; batch adversarial loss: 0.543036\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014635; batch adversarial loss: 0.390067\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026352; batch adversarial loss: 0.447415\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008880; batch adversarial loss: 0.517676\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026027; batch adversarial loss: 0.440150\n",
      "epoch 175; iter: 0; batch classifier loss: 0.051939; batch adversarial loss: 0.413559\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.467965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017399; batch adversarial loss: 0.366675\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020776; batch adversarial loss: 0.450936\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004507; batch adversarial loss: 0.363768\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016844; batch adversarial loss: 0.418144\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023702; batch adversarial loss: 0.418789\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033973; batch adversarial loss: 0.446470\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015218; batch adversarial loss: 0.367053\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019170; batch adversarial loss: 0.501094\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023555; batch adversarial loss: 0.446486\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005276; batch adversarial loss: 0.407711\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033937; batch adversarial loss: 0.423145\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020833; batch adversarial loss: 0.407540\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024421; batch adversarial loss: 0.390189\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014666; batch adversarial loss: 0.510913\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021619; batch adversarial loss: 0.538749\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017053; batch adversarial loss: 0.369246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 193; iter: 0; batch classifier loss: 0.010315; batch adversarial loss: 0.424689\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020383; batch adversarial loss: 0.468078\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008517; batch adversarial loss: 0.451115\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006727; batch adversarial loss: 0.454243\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008745; batch adversarial loss: 0.518246\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008095; batch adversarial loss: 0.485893\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017254; batch adversarial loss: 0.451082\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680495; batch adversarial loss: 0.808903\n",
      "epoch 1; iter: 0; batch classifier loss: 0.396325; batch adversarial loss: 0.790152\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407950; batch adversarial loss: 0.750204\n",
      "epoch 3; iter: 0; batch classifier loss: 0.354232; batch adversarial loss: 0.700994\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390466; batch adversarial loss: 0.667249\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354470; batch adversarial loss: 0.651015\n",
      "epoch 6; iter: 0; batch classifier loss: 0.352339; batch adversarial loss: 0.639546\n",
      "epoch 7; iter: 0; batch classifier loss: 0.290873; batch adversarial loss: 0.588474\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281907; batch adversarial loss: 0.594054\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300583; batch adversarial loss: 0.512066\n",
      "epoch 10; iter: 0; batch classifier loss: 0.200484; batch adversarial loss: 0.523107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267824; batch adversarial loss: 0.512380\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242816; batch adversarial loss: 0.467547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.217229; batch adversarial loss: 0.474879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256338; batch adversarial loss: 0.434205\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248427; batch adversarial loss: 0.440453\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178501; batch adversarial loss: 0.516395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.173602; batch adversarial loss: 0.512477\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238985; batch adversarial loss: 0.409497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231690; batch adversarial loss: 0.483157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.182907; batch adversarial loss: 0.423824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196150; batch adversarial loss: 0.384591\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187487; batch adversarial loss: 0.462550\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175214; batch adversarial loss: 0.420347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.226886; batch adversarial loss: 0.403215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.226223; batch adversarial loss: 0.390909\n",
      "epoch 26; iter: 0; batch classifier loss: 0.147688; batch adversarial loss: 0.443847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.182618; batch adversarial loss: 0.429536\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173017; batch adversarial loss: 0.326261\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206877; batch adversarial loss: 0.421527\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174398; batch adversarial loss: 0.394698\n",
      "epoch 31; iter: 0; batch classifier loss: 0.263207; batch adversarial loss: 0.412471\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196684; batch adversarial loss: 0.412174\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159199; batch adversarial loss: 0.414980\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132137; batch adversarial loss: 0.433989\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158159; batch adversarial loss: 0.355151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.155593; batch adversarial loss: 0.451262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117703; batch adversarial loss: 0.360239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142745; batch adversarial loss: 0.456403\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149958; batch adversarial loss: 0.350178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.146576; batch adversarial loss: 0.383334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138704; batch adversarial loss: 0.374125\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106440; batch adversarial loss: 0.430415\n",
      "epoch 43; iter: 0; batch classifier loss: 0.106102; batch adversarial loss: 0.375834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.162928; batch adversarial loss: 0.496077\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119684; batch adversarial loss: 0.454378\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111426; batch adversarial loss: 0.445639\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130920; batch adversarial loss: 0.478335\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129001; batch adversarial loss: 0.344992\n",
      "epoch 49; iter: 0; batch classifier loss: 0.102776; batch adversarial loss: 0.378996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091954; batch adversarial loss: 0.340124\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121819; batch adversarial loss: 0.505384\n",
      "epoch 52; iter: 0; batch classifier loss: 0.117332; batch adversarial loss: 0.373398\n",
      "epoch 53; iter: 0; batch classifier loss: 0.157828; batch adversarial loss: 0.434884\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086406; batch adversarial loss: 0.416352\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112242; batch adversarial loss: 0.396491\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103308; batch adversarial loss: 0.419157\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094921; batch adversarial loss: 0.395175\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084774; batch adversarial loss: 0.423297\n",
      "epoch 59; iter: 0; batch classifier loss: 0.089866; batch adversarial loss: 0.461214\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077455; batch adversarial loss: 0.432984\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102608; batch adversarial loss: 0.455347\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078466; batch adversarial loss: 0.398552\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070986; batch adversarial loss: 0.482800\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085875; batch adversarial loss: 0.370310\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088361; batch adversarial loss: 0.386769\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076516; batch adversarial loss: 0.387143\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054311; batch adversarial loss: 0.416949\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061317; batch adversarial loss: 0.433803\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082925; batch adversarial loss: 0.341497\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081012; batch adversarial loss: 0.494433\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079019; batch adversarial loss: 0.391718\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078857; batch adversarial loss: 0.368731\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083285; batch adversarial loss: 0.419392\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044462; batch adversarial loss: 0.358933\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100454; batch adversarial loss: 0.375978\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050317; batch adversarial loss: 0.446101\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062402; batch adversarial loss: 0.428404\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041371; batch adversarial loss: 0.331433\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098502; batch adversarial loss: 0.476972\n",
      "epoch 80; iter: 0; batch classifier loss: 0.058116; batch adversarial loss: 0.334089\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049245; batch adversarial loss: 0.379954\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075962; batch adversarial loss: 0.478539\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056751; batch adversarial loss: 0.486818\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046605; batch adversarial loss: 0.435578\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045805; batch adversarial loss: 0.333397\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054447; batch adversarial loss: 0.513229\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070774; batch adversarial loss: 0.423244\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037884; batch adversarial loss: 0.419246\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051109; batch adversarial loss: 0.444511\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076654; batch adversarial loss: 0.420698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.040066; batch adversarial loss: 0.464418\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034707; batch adversarial loss: 0.449212\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048566; batch adversarial loss: 0.495848\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040164; batch adversarial loss: 0.511355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032642; batch adversarial loss: 0.368365\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047698; batch adversarial loss: 0.391685\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075859; batch adversarial loss: 0.434374\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046150; batch adversarial loss: 0.429510\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049174; batch adversarial loss: 0.486863\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061932; batch adversarial loss: 0.436422\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041518; batch adversarial loss: 0.472483\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023144; batch adversarial loss: 0.502708\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044166; batch adversarial loss: 0.472977\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033812; batch adversarial loss: 0.542337\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022897; batch adversarial loss: 0.439365\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029626; batch adversarial loss: 0.490813\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048407; batch adversarial loss: 0.410053\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044126; batch adversarial loss: 0.417018\n",
      "epoch 109; iter: 0; batch classifier loss: 0.028522; batch adversarial loss: 0.531645\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043343; batch adversarial loss: 0.447753\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025235; batch adversarial loss: 0.351610\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028835; batch adversarial loss: 0.494251\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036685; batch adversarial loss: 0.467316\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028144; batch adversarial loss: 0.498080\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045643; batch adversarial loss: 0.417621\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032473; batch adversarial loss: 0.417284\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038578; batch adversarial loss: 0.439653\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022290; batch adversarial loss: 0.455965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.012017; batch adversarial loss: 0.465074\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030323; batch adversarial loss: 0.505467\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042304; batch adversarial loss: 0.576377\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057040; batch adversarial loss: 0.544904\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039648; batch adversarial loss: 0.494444\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044548; batch adversarial loss: 0.609309\n",
      "epoch 125; iter: 0; batch classifier loss: 0.110955; batch adversarial loss: 0.740830\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046879; batch adversarial loss: 0.482535\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070070; batch adversarial loss: 0.503887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.091343; batch adversarial loss: 0.671932\n",
      "epoch 129; iter: 0; batch classifier loss: 0.153879; batch adversarial loss: 0.709705\n",
      "epoch 130; iter: 0; batch classifier loss: 0.061412; batch adversarial loss: 0.496432\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.421592\n",
      "epoch 132; iter: 0; batch classifier loss: 0.079207; batch adversarial loss: 0.537002\n",
      "epoch 133; iter: 0; batch classifier loss: 0.100837; batch adversarial loss: 0.542756\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060598; batch adversarial loss: 0.531331\n",
      "epoch 135; iter: 0; batch classifier loss: 0.075565; batch adversarial loss: 0.535827\n",
      "epoch 136; iter: 0; batch classifier loss: 0.162470; batch adversarial loss: 0.662315\n",
      "epoch 137; iter: 0; batch classifier loss: 0.104144; batch adversarial loss: 0.647636\n",
      "epoch 138; iter: 0; batch classifier loss: 0.148865; batch adversarial loss: 0.700857\n",
      "epoch 139; iter: 0; batch classifier loss: 0.130922; batch adversarial loss: 0.542720\n",
      "epoch 140; iter: 0; batch classifier loss: 0.068538; batch adversarial loss: 0.475815\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050586; batch adversarial loss: 0.480652\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037753; batch adversarial loss: 0.492241\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076284; batch adversarial loss: 0.428120\n",
      "epoch 144; iter: 0; batch classifier loss: 0.147394; batch adversarial loss: 0.536768\n",
      "epoch 145; iter: 0; batch classifier loss: 0.118838; batch adversarial loss: 0.512520\n",
      "epoch 146; iter: 0; batch classifier loss: 0.133457; batch adversarial loss: 0.593722\n",
      "epoch 147; iter: 0; batch classifier loss: 0.088615; batch adversarial loss: 0.537778\n",
      "epoch 148; iter: 0; batch classifier loss: 0.093076; batch adversarial loss: 0.503553\n",
      "epoch 149; iter: 0; batch classifier loss: 0.139446; batch adversarial loss: 0.571167\n",
      "epoch 150; iter: 0; batch classifier loss: 0.152718; batch adversarial loss: 0.587510\n",
      "epoch 151; iter: 0; batch classifier loss: 0.142094; batch adversarial loss: 0.658061\n",
      "epoch 152; iter: 0; batch classifier loss: 0.103421; batch adversarial loss: 0.537876\n",
      "epoch 153; iter: 0; batch classifier loss: 0.143984; batch adversarial loss: 0.498212\n",
      "epoch 154; iter: 0; batch classifier loss: 0.234618; batch adversarial loss: 0.652085\n",
      "epoch 155; iter: 0; batch classifier loss: 0.136167; batch adversarial loss: 0.585680\n",
      "epoch 156; iter: 0; batch classifier loss: 0.066718; batch adversarial loss: 0.482615\n",
      "epoch 157; iter: 0; batch classifier loss: 0.115795; batch adversarial loss: 0.511117\n",
      "epoch 158; iter: 0; batch classifier loss: 0.066042; batch adversarial loss: 0.510837\n",
      "epoch 159; iter: 0; batch classifier loss: 0.151809; batch adversarial loss: 0.607621\n",
      "epoch 160; iter: 0; batch classifier loss: 0.132147; batch adversarial loss: 0.491602\n",
      "epoch 161; iter: 0; batch classifier loss: 0.099596; batch adversarial loss: 0.558653\n",
      "epoch 162; iter: 0; batch classifier loss: 0.157006; batch adversarial loss: 0.463140\n",
      "epoch 163; iter: 0; batch classifier loss: 0.107372; batch adversarial loss: 0.452219\n",
      "epoch 164; iter: 0; batch classifier loss: 0.107711; batch adversarial loss: 0.444519\n",
      "epoch 165; iter: 0; batch classifier loss: 0.106749; batch adversarial loss: 0.471765\n",
      "epoch 166; iter: 0; batch classifier loss: 0.073261; batch adversarial loss: 0.423809\n",
      "epoch 167; iter: 0; batch classifier loss: 0.050883; batch adversarial loss: 0.387549\n",
      "epoch 168; iter: 0; batch classifier loss: 0.065120; batch adversarial loss: 0.414521\n",
      "epoch 169; iter: 0; batch classifier loss: 0.129508; batch adversarial loss: 0.496084\n",
      "epoch 170; iter: 0; batch classifier loss: 0.066043; batch adversarial loss: 0.418388\n",
      "epoch 171; iter: 0; batch classifier loss: 0.138329; batch adversarial loss: 0.571054\n",
      "epoch 172; iter: 0; batch classifier loss: 0.123406; batch adversarial loss: 0.449744\n",
      "epoch 173; iter: 0; batch classifier loss: 0.123917; batch adversarial loss: 0.465825\n",
      "epoch 174; iter: 0; batch classifier loss: 0.104728; batch adversarial loss: 0.398508\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045879; batch adversarial loss: 0.520072\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038207; batch adversarial loss: 0.521809\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032063; batch adversarial loss: 0.497183\n",
      "epoch 178; iter: 0; batch classifier loss: 0.078469; batch adversarial loss: 0.434447\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024131; batch adversarial loss: 0.521988\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049022; batch adversarial loss: 0.418735\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031133; batch adversarial loss: 0.453392\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031430; batch adversarial loss: 0.439236\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046224; batch adversarial loss: 0.545405\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029318; batch adversarial loss: 0.453634\n",
      "epoch 185; iter: 0; batch classifier loss: 0.077954; batch adversarial loss: 0.448511\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068759; batch adversarial loss: 0.493229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.456231\n",
      "epoch 188; iter: 0; batch classifier loss: 0.049434; batch adversarial loss: 0.398068\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051262; batch adversarial loss: 0.520944\n",
      "epoch 190; iter: 0; batch classifier loss: 0.081489; batch adversarial loss: 0.452891\n",
      "epoch 191; iter: 0; batch classifier loss: 0.081359; batch adversarial loss: 0.438078\n",
      "epoch 192; iter: 0; batch classifier loss: 0.093914; batch adversarial loss: 0.473245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.072621; batch adversarial loss: 0.424785\n",
      "epoch 194; iter: 0; batch classifier loss: 0.093108; batch adversarial loss: 0.466771\n",
      "epoch 195; iter: 0; batch classifier loss: 0.067902; batch adversarial loss: 0.287947\n",
      "epoch 196; iter: 0; batch classifier loss: 0.113870; batch adversarial loss: 0.446652\n",
      "epoch 197; iter: 0; batch classifier loss: 0.114046; batch adversarial loss: 0.396754\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040293; batch adversarial loss: 0.467898\n",
      "epoch 199; iter: 0; batch classifier loss: 0.093539; batch adversarial loss: 0.459774\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695922; batch adversarial loss: 0.826651\n",
      "epoch 1; iter: 0; batch classifier loss: 0.652870; batch adversarial loss: 0.879496\n",
      "epoch 2; iter: 0; batch classifier loss: 0.812152; batch adversarial loss: 0.858614\n",
      "epoch 3; iter: 0; batch classifier loss: 1.033987; batch adversarial loss: 0.816730\n",
      "epoch 4; iter: 0; batch classifier loss: 0.777942; batch adversarial loss: 0.706122\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653044; batch adversarial loss: 0.629630\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486356; batch adversarial loss: 0.569709\n",
      "epoch 7; iter: 0; batch classifier loss: 0.447271; batch adversarial loss: 0.550152\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311940; batch adversarial loss: 0.540503\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373244; batch adversarial loss: 0.555177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303921; batch adversarial loss: 0.535559\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342994; batch adversarial loss: 0.496897\n",
      "epoch 12; iter: 0; batch classifier loss: 0.286434; batch adversarial loss: 0.497496\n",
      "epoch 13; iter: 0; batch classifier loss: 0.298534; batch adversarial loss: 0.487472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312345; batch adversarial loss: 0.478531\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316373; batch adversarial loss: 0.516125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230076; batch adversarial loss: 0.523373\n",
      "epoch 17; iter: 0; batch classifier loss: 0.272356; batch adversarial loss: 0.542731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316955; batch adversarial loss: 0.505054\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257594; batch adversarial loss: 0.451946\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251694; batch adversarial loss: 0.544731\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264338; batch adversarial loss: 0.459255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198696; batch adversarial loss: 0.473430\n",
      "epoch 23; iter: 0; batch classifier loss: 0.215179; batch adversarial loss: 0.497307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194813; batch adversarial loss: 0.476181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213884; batch adversarial loss: 0.462831\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181783; batch adversarial loss: 0.440193\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241074; batch adversarial loss: 0.421412\n",
      "epoch 28; iter: 0; batch classifier loss: 0.156767; batch adversarial loss: 0.455870\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182391; batch adversarial loss: 0.436778\n",
      "epoch 30; iter: 0; batch classifier loss: 0.084376; batch adversarial loss: 0.501784\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151183; batch adversarial loss: 0.516968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157516; batch adversarial loss: 0.541513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170571; batch adversarial loss: 0.483461\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135118; batch adversarial loss: 0.444976\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142377; batch adversarial loss: 0.504582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112687; batch adversarial loss: 0.477609\n",
      "epoch 37; iter: 0; batch classifier loss: 0.104935; batch adversarial loss: 0.429895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.100493; batch adversarial loss: 0.507514\n",
      "epoch 39; iter: 0; batch classifier loss: 0.101102; batch adversarial loss: 0.447170\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116066; batch adversarial loss: 0.454084\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138089; batch adversarial loss: 0.426723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086531; batch adversarial loss: 0.489548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119555; batch adversarial loss: 0.369000\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132503; batch adversarial loss: 0.434305\n",
      "epoch 45; iter: 0; batch classifier loss: 0.202694; batch adversarial loss: 0.454482\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072060; batch adversarial loss: 0.473017\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074989; batch adversarial loss: 0.472459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081945; batch adversarial loss: 0.494356\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111767; batch adversarial loss: 0.473390\n",
      "epoch 50; iter: 0; batch classifier loss: 0.060364; batch adversarial loss: 0.383712\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073147; batch adversarial loss: 0.484514\n",
      "epoch 52; iter: 0; batch classifier loss: 0.057197; batch adversarial loss: 0.435150\n",
      "epoch 53; iter: 0; batch classifier loss: 0.051795; batch adversarial loss: 0.423046\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065311; batch adversarial loss: 0.410663\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086494; batch adversarial loss: 0.490076\n",
      "epoch 56; iter: 0; batch classifier loss: 0.050948; batch adversarial loss: 0.533299\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110435; batch adversarial loss: 0.467491\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063218; batch adversarial loss: 0.434445\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083136; batch adversarial loss: 0.370708\n",
      "epoch 60; iter: 0; batch classifier loss: 0.046497; batch adversarial loss: 0.409570\n",
      "epoch 61; iter: 0; batch classifier loss: 0.060326; batch adversarial loss: 0.410950\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080531; batch adversarial loss: 0.513853\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056122; batch adversarial loss: 0.482671\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068183; batch adversarial loss: 0.496576\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059399; batch adversarial loss: 0.518968\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076255; batch adversarial loss: 0.498346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.042385; batch adversarial loss: 0.443755\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050364; batch adversarial loss: 0.393893\n",
      "epoch 69; iter: 0; batch classifier loss: 0.036483; batch adversarial loss: 0.477709\n",
      "epoch 70; iter: 0; batch classifier loss: 0.031315; batch adversarial loss: 0.508380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.032448; batch adversarial loss: 0.420302\n",
      "epoch 72; iter: 0; batch classifier loss: 0.024991; batch adversarial loss: 0.494988\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038600; batch adversarial loss: 0.507477\n",
      "epoch 74; iter: 0; batch classifier loss: 0.028349; batch adversarial loss: 0.425514\n",
      "epoch 75; iter: 0; batch classifier loss: 0.041327; batch adversarial loss: 0.436047\n",
      "epoch 76; iter: 0; batch classifier loss: 0.046300; batch adversarial loss: 0.382091\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042739; batch adversarial loss: 0.513899\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088001; batch adversarial loss: 0.586940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113329; batch adversarial loss: 0.479741\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072273; batch adversarial loss: 0.319966\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055751; batch adversarial loss: 0.458898\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043799; batch adversarial loss: 0.454706\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071724; batch adversarial loss: 0.440261\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045881; batch adversarial loss: 0.511859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.050065; batch adversarial loss: 0.530972\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049244; batch adversarial loss: 0.448401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040452; batch adversarial loss: 0.454465\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054465; batch adversarial loss: 0.465160\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055903; batch adversarial loss: 0.413264\n",
      "epoch 90; iter: 0; batch classifier loss: 0.031424; batch adversarial loss: 0.422886\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032474; batch adversarial loss: 0.480700\n",
      "epoch 92; iter: 0; batch classifier loss: 0.023574; batch adversarial loss: 0.454447\n",
      "epoch 93; iter: 0; batch classifier loss: 0.022695; batch adversarial loss: 0.405740\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.447856\n",
      "epoch 95; iter: 0; batch classifier loss: 0.022024; batch adversarial loss: 0.439268\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031869; batch adversarial loss: 0.365909\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022863; batch adversarial loss: 0.440344\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037685; batch adversarial loss: 0.314715\n",
      "epoch 99; iter: 0; batch classifier loss: 0.013938; batch adversarial loss: 0.398429\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024031; batch adversarial loss: 0.486926\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030239; batch adversarial loss: 0.441101\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043841; batch adversarial loss: 0.383350\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027900; batch adversarial loss: 0.384209\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034211; batch adversarial loss: 0.464216\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048089; batch adversarial loss: 0.450527\n",
      "epoch 106; iter: 0; batch classifier loss: 0.013955; batch adversarial loss: 0.346312\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027928; batch adversarial loss: 0.422242\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039914; batch adversarial loss: 0.379501\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022673; batch adversarial loss: 0.414793\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020494; batch adversarial loss: 0.365368\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046979; batch adversarial loss: 0.415791\n",
      "epoch 112; iter: 0; batch classifier loss: 0.011243; batch adversarial loss: 0.527279\n",
      "epoch 113; iter: 0; batch classifier loss: 0.016279; batch adversarial loss: 0.466640\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047727; batch adversarial loss: 0.518614\n",
      "epoch 115; iter: 0; batch classifier loss: 0.016388; batch adversarial loss: 0.485257\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021361; batch adversarial loss: 0.358325\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020184; batch adversarial loss: 0.413613\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064523; batch adversarial loss: 0.424630\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027945; batch adversarial loss: 0.482495\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027224; batch adversarial loss: 0.401107\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020694; batch adversarial loss: 0.362665\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023687; batch adversarial loss: 0.443042\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024779; batch adversarial loss: 0.457309\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024536; batch adversarial loss: 0.475086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.009037; batch adversarial loss: 0.513871\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062840; batch adversarial loss: 0.381775\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030516; batch adversarial loss: 0.442323\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018598; batch adversarial loss: 0.516732\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037324; batch adversarial loss: 0.470112\n",
      "epoch 130; iter: 0; batch classifier loss: 0.016333; batch adversarial loss: 0.404184\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020291; batch adversarial loss: 0.457924\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.397609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.006725; batch adversarial loss: 0.430589\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028306; batch adversarial loss: 0.430838\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011431; batch adversarial loss: 0.446160\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030333; batch adversarial loss: 0.432105\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.425989\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024560; batch adversarial loss: 0.422008\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011716; batch adversarial loss: 0.515456\n",
      "epoch 140; iter: 0; batch classifier loss: 0.016592; batch adversarial loss: 0.529686\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029263; batch adversarial loss: 0.420947\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014242; batch adversarial loss: 0.460654\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014533; batch adversarial loss: 0.421775\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024805; batch adversarial loss: 0.533279\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017082; batch adversarial loss: 0.477428\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020583; batch adversarial loss: 0.428023\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013973; batch adversarial loss: 0.507659\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033786; batch adversarial loss: 0.463868\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008730; batch adversarial loss: 0.424416\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029884; batch adversarial loss: 0.423670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.009825; batch adversarial loss: 0.481668\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009424; batch adversarial loss: 0.407096\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014487; batch adversarial loss: 0.447682\n",
      "epoch 154; iter: 0; batch classifier loss: 0.005048; batch adversarial loss: 0.481855\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034519; batch adversarial loss: 0.381464\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006184; batch adversarial loss: 0.440019\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051456; batch adversarial loss: 0.542484\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.490131\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020758; batch adversarial loss: 0.400164\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036094; batch adversarial loss: 0.531718\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010531; batch adversarial loss: 0.504359\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011344; batch adversarial loss: 0.490291\n",
      "epoch 163; iter: 0; batch classifier loss: 0.001384; batch adversarial loss: 0.542194\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013593; batch adversarial loss: 0.355913\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.489910\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017253; batch adversarial loss: 0.327626\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008752; batch adversarial loss: 0.403057\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027855; batch adversarial loss: 0.408488\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015495; batch adversarial loss: 0.547293\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020430; batch adversarial loss: 0.462468\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012739; batch adversarial loss: 0.469637\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029386; batch adversarial loss: 0.380736\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026493; batch adversarial loss: 0.448504\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007148; batch adversarial loss: 0.448183\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023336; batch adversarial loss: 0.355408\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.415254\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015575; batch adversarial loss: 0.346293\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037759; batch adversarial loss: 0.438703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003227; batch adversarial loss: 0.394363\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010967; batch adversarial loss: 0.428142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.004181; batch adversarial loss: 0.493345\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022304; batch adversarial loss: 0.471987\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014577; batch adversarial loss: 0.441659\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035565; batch adversarial loss: 0.518637\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013981; batch adversarial loss: 0.440105\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017104; batch adversarial loss: 0.477564\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039241; batch adversarial loss: 0.551681\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006863; batch adversarial loss: 0.474332\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023579; batch adversarial loss: 0.414487\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020148; batch adversarial loss: 0.438242\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031707; batch adversarial loss: 0.459097\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007366; batch adversarial loss: 0.494981\n",
      "epoch 193; iter: 0; batch classifier loss: 0.002449; batch adversarial loss: 0.471371\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010723; batch adversarial loss: 0.413590\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011250; batch adversarial loss: 0.435030\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011756; batch adversarial loss: 0.458121\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041660; batch adversarial loss: 0.357107\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002350; batch adversarial loss: 0.391665\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032012; batch adversarial loss: 0.340315\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685612; batch adversarial loss: 0.543425\n",
      "epoch 1; iter: 0; batch classifier loss: 0.536949; batch adversarial loss: 0.609767\n",
      "epoch 2; iter: 0; batch classifier loss: 0.484846; batch adversarial loss: 0.594575\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356993; batch adversarial loss: 0.593786\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446607; batch adversarial loss: 0.665275\n",
      "epoch 5; iter: 0; batch classifier loss: 0.434443; batch adversarial loss: 0.588123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381846; batch adversarial loss: 0.549909\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453243; batch adversarial loss: 0.600369\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391242; batch adversarial loss: 0.543800\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531436; batch adversarial loss: 0.587714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.625832; batch adversarial loss: 0.545445\n",
      "epoch 11; iter: 0; batch classifier loss: 0.677907; batch adversarial loss: 0.599553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.458631; batch adversarial loss: 0.529130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321453; batch adversarial loss: 0.555424\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280728; batch adversarial loss: 0.469490\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270315; batch adversarial loss: 0.502834\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271552; batch adversarial loss: 0.474993\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278064; batch adversarial loss: 0.428946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262448; batch adversarial loss: 0.538698\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274390; batch adversarial loss: 0.437907\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260540; batch adversarial loss: 0.466838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282985; batch adversarial loss: 0.415557\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250533; batch adversarial loss: 0.451316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224468; batch adversarial loss: 0.414586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194200; batch adversarial loss: 0.516791\n",
      "epoch 25; iter: 0; batch classifier loss: 0.189871; batch adversarial loss: 0.431948\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167343; batch adversarial loss: 0.473321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152093; batch adversarial loss: 0.475703\n",
      "epoch 28; iter: 0; batch classifier loss: 0.227803; batch adversarial loss: 0.378762\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142642; batch adversarial loss: 0.398427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208209; batch adversarial loss: 0.395151\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176382; batch adversarial loss: 0.483096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138702; batch adversarial loss: 0.468165\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131898; batch adversarial loss: 0.526294\n",
      "epoch 34; iter: 0; batch classifier loss: 0.192931; batch adversarial loss: 0.461032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158177; batch adversarial loss: 0.483640\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172819; batch adversarial loss: 0.421477\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132627; batch adversarial loss: 0.471323\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160030; batch adversarial loss: 0.507496\n",
      "epoch 39; iter: 0; batch classifier loss: 0.142908; batch adversarial loss: 0.406002\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143129; batch adversarial loss: 0.526035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138791; batch adversarial loss: 0.504719\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127540; batch adversarial loss: 0.530454\n",
      "epoch 43; iter: 0; batch classifier loss: 0.136293; batch adversarial loss: 0.482677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.122939; batch adversarial loss: 0.479710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.183782; batch adversarial loss: 0.393259\n",
      "epoch 46; iter: 0; batch classifier loss: 0.117123; batch adversarial loss: 0.495976\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139524; batch adversarial loss: 0.384829\n",
      "epoch 48; iter: 0; batch classifier loss: 0.146980; batch adversarial loss: 0.478799\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110167; batch adversarial loss: 0.478310\n",
      "epoch 50; iter: 0; batch classifier loss: 0.149041; batch adversarial loss: 0.446560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.172958; batch adversarial loss: 0.426710\n",
      "epoch 52; iter: 0; batch classifier loss: 0.149589; batch adversarial loss: 0.373170\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089721; batch adversarial loss: 0.448120\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171866; batch adversarial loss: 0.435419\n",
      "epoch 55; iter: 0; batch classifier loss: 0.114446; batch adversarial loss: 0.461727\n",
      "epoch 56; iter: 0; batch classifier loss: 0.169789; batch adversarial loss: 0.467333\n",
      "epoch 57; iter: 0; batch classifier loss: 0.134722; batch adversarial loss: 0.487117\n",
      "epoch 58; iter: 0; batch classifier loss: 0.123041; batch adversarial loss: 0.531412\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102230; batch adversarial loss: 0.484489\n",
      "epoch 60; iter: 0; batch classifier loss: 0.165518; batch adversarial loss: 0.509659\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114146; batch adversarial loss: 0.385859\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105749; batch adversarial loss: 0.498085\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104434; batch adversarial loss: 0.443180\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117912; batch adversarial loss: 0.368654\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144104; batch adversarial loss: 0.479879\n",
      "epoch 66; iter: 0; batch classifier loss: 0.172081; batch adversarial loss: 0.383760\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101751; batch adversarial loss: 0.489233\n",
      "epoch 68; iter: 0; batch classifier loss: 0.201228; batch adversarial loss: 0.463218\n",
      "epoch 69; iter: 0; batch classifier loss: 0.136620; batch adversarial loss: 0.363142\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214571; batch adversarial loss: 0.507774\n",
      "epoch 71; iter: 0; batch classifier loss: 0.094068; batch adversarial loss: 0.519871\n",
      "epoch 72; iter: 0; batch classifier loss: 0.185857; batch adversarial loss: 0.409275\n",
      "epoch 73; iter: 0; batch classifier loss: 0.127507; batch adversarial loss: 0.471321\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103177; batch adversarial loss: 0.459996\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106310; batch adversarial loss: 0.449731\n",
      "epoch 76; iter: 0; batch classifier loss: 0.134610; batch adversarial loss: 0.443427\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127768; batch adversarial loss: 0.576555\n",
      "epoch 78; iter: 0; batch classifier loss: 0.142157; batch adversarial loss: 0.432857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79; iter: 0; batch classifier loss: 0.103075; batch adversarial loss: 0.632523\n",
      "epoch 80; iter: 0; batch classifier loss: 0.159068; batch adversarial loss: 0.397184\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115623; batch adversarial loss: 0.478231\n",
      "epoch 82; iter: 0; batch classifier loss: 0.145776; batch adversarial loss: 0.349308\n",
      "epoch 83; iter: 0; batch classifier loss: 0.149269; batch adversarial loss: 0.479736\n",
      "epoch 84; iter: 0; batch classifier loss: 0.171020; batch adversarial loss: 0.432838\n",
      "epoch 85; iter: 0; batch classifier loss: 0.105728; batch adversarial loss: 0.431016\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112645; batch adversarial loss: 0.449851\n",
      "epoch 87; iter: 0; batch classifier loss: 0.155416; batch adversarial loss: 0.407658\n",
      "epoch 88; iter: 0; batch classifier loss: 0.187228; batch adversarial loss: 0.488967\n",
      "epoch 89; iter: 0; batch classifier loss: 0.165544; batch adversarial loss: 0.435159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.148487; batch adversarial loss: 0.412071\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101348; batch adversarial loss: 0.427276\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106632; batch adversarial loss: 0.380408\n",
      "epoch 93; iter: 0; batch classifier loss: 0.082867; batch adversarial loss: 0.405643\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082258; batch adversarial loss: 0.497040\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081688; batch adversarial loss: 0.421159\n",
      "epoch 96; iter: 0; batch classifier loss: 0.142740; batch adversarial loss: 0.494374\n",
      "epoch 97; iter: 0; batch classifier loss: 0.110693; batch adversarial loss: 0.448699\n",
      "epoch 98; iter: 0; batch classifier loss: 0.088132; batch adversarial loss: 0.467986\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063692; batch adversarial loss: 0.361930\n",
      "epoch 100; iter: 0; batch classifier loss: 0.106026; batch adversarial loss: 0.494058\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095923; batch adversarial loss: 0.407724\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070088; batch adversarial loss: 0.499821\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074145; batch adversarial loss: 0.511865\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090944; batch adversarial loss: 0.436975\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087156; batch adversarial loss: 0.395622\n",
      "epoch 106; iter: 0; batch classifier loss: 0.058630; batch adversarial loss: 0.571992\n",
      "epoch 107; iter: 0; batch classifier loss: 0.083198; batch adversarial loss: 0.545370\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067526; batch adversarial loss: 0.420271\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.451284\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055921; batch adversarial loss: 0.506840\n",
      "epoch 111; iter: 0; batch classifier loss: 0.087412; batch adversarial loss: 0.467862\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070550; batch adversarial loss: 0.468686\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086507; batch adversarial loss: 0.447798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030826; batch adversarial loss: 0.434594\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053382; batch adversarial loss: 0.530576\n",
      "epoch 116; iter: 0; batch classifier loss: 0.119850; batch adversarial loss: 0.395794\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060837; batch adversarial loss: 0.430112\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076451; batch adversarial loss: 0.355601\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041168; batch adversarial loss: 0.398625\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043223; batch adversarial loss: 0.459467\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052340; batch adversarial loss: 0.435312\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033740; batch adversarial loss: 0.421998\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041658; batch adversarial loss: 0.504205\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055797; batch adversarial loss: 0.428692\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089490; batch adversarial loss: 0.465916\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024165; batch adversarial loss: 0.508807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054945; batch adversarial loss: 0.482528\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023912; batch adversarial loss: 0.398966\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036836; batch adversarial loss: 0.471181\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071907; batch adversarial loss: 0.374090\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027755; batch adversarial loss: 0.491063\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032101; batch adversarial loss: 0.408818\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.517364\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043074; batch adversarial loss: 0.495835\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046171; batch adversarial loss: 0.565678\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052769; batch adversarial loss: 0.473195\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050723; batch adversarial loss: 0.407549\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034640; batch adversarial loss: 0.420770\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018006; batch adversarial loss: 0.526496\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032238; batch adversarial loss: 0.454832\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031592; batch adversarial loss: 0.374891\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018501; batch adversarial loss: 0.385790\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029598; batch adversarial loss: 0.476819\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023079; batch adversarial loss: 0.436740\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020612; batch adversarial loss: 0.565261\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016678; batch adversarial loss: 0.421050\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020015; batch adversarial loss: 0.484478\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023804; batch adversarial loss: 0.386962\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029827; batch adversarial loss: 0.516972\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012034; batch adversarial loss: 0.502020\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025894; batch adversarial loss: 0.533944\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052935; batch adversarial loss: 0.435489\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020929; batch adversarial loss: 0.358933\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045284; batch adversarial loss: 0.516221\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019770; batch adversarial loss: 0.403026\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018284; batch adversarial loss: 0.372102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019318; batch adversarial loss: 0.482384\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021105; batch adversarial loss: 0.383570\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022206; batch adversarial loss: 0.451187\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017498; batch adversarial loss: 0.406760\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011439; batch adversarial loss: 0.512309\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026884; batch adversarial loss: 0.508244\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018811; batch adversarial loss: 0.454081\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009724; batch adversarial loss: 0.482522\n",
      "epoch 165; iter: 0; batch classifier loss: 0.082427; batch adversarial loss: 0.418479\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020530; batch adversarial loss: 0.390212\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021400; batch adversarial loss: 0.437155\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012903; batch adversarial loss: 0.424331\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019514; batch adversarial loss: 0.537437\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034490; batch adversarial loss: 0.447354\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023293; batch adversarial loss: 0.501572\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026040; batch adversarial loss: 0.528191\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036105; batch adversarial loss: 0.403587\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008463; batch adversarial loss: 0.488706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175; iter: 0; batch classifier loss: 0.020926; batch adversarial loss: 0.429404\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030688; batch adversarial loss: 0.449636\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020149; batch adversarial loss: 0.463476\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012172; batch adversarial loss: 0.480808\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025327; batch adversarial loss: 0.448050\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016496; batch adversarial loss: 0.459183\n",
      "epoch 181; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.380225\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034981; batch adversarial loss: 0.406573\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014484; batch adversarial loss: 0.459081\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018280; batch adversarial loss: 0.468166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014094; batch adversarial loss: 0.385182\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020454; batch adversarial loss: 0.463656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013969; batch adversarial loss: 0.435572\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022094; batch adversarial loss: 0.435582\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063610; batch adversarial loss: 0.424217\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030443; batch adversarial loss: 0.392199\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016439; batch adversarial loss: 0.499100\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016205; batch adversarial loss: 0.459845\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014373; batch adversarial loss: 0.383556\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011829; batch adversarial loss: 0.421280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013021; batch adversarial loss: 0.516394\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012390; batch adversarial loss: 0.431340\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008690; batch adversarial loss: 0.457673\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011278; batch adversarial loss: 0.469412\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010752; batch adversarial loss: 0.427423\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686940; batch adversarial loss: 0.809175\n",
      "epoch 1; iter: 0; batch classifier loss: 0.491244; batch adversarial loss: 0.756461\n",
      "epoch 2; iter: 0; batch classifier loss: 0.444416; batch adversarial loss: 0.709314\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388941; batch adversarial loss: 0.672130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.397870; batch adversarial loss: 0.659555\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345266; batch adversarial loss: 0.638265\n",
      "epoch 6; iter: 0; batch classifier loss: 0.354782; batch adversarial loss: 0.635924\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362531; batch adversarial loss: 0.570961\n",
      "epoch 8; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.539019\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305982; batch adversarial loss: 0.496140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304678; batch adversarial loss: 0.445538\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253029; batch adversarial loss: 0.475533\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237112; batch adversarial loss: 0.496661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.263955; batch adversarial loss: 0.463203\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293971; batch adversarial loss: 0.496577\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361237; batch adversarial loss: 0.462985\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242569; batch adversarial loss: 0.514190\n",
      "epoch 17; iter: 0; batch classifier loss: 0.182877; batch adversarial loss: 0.394181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183986; batch adversarial loss: 0.396847\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191659; batch adversarial loss: 0.356659\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213700; batch adversarial loss: 0.413401\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257089; batch adversarial loss: 0.411160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.309192; batch adversarial loss: 0.418871\n",
      "epoch 23; iter: 0; batch classifier loss: 0.239043; batch adversarial loss: 0.403499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233471; batch adversarial loss: 0.373018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162690; batch adversarial loss: 0.416587\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208363; batch adversarial loss: 0.452058\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214493; batch adversarial loss: 0.374910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.181058; batch adversarial loss: 0.398167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191991; batch adversarial loss: 0.450327\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167211; batch adversarial loss: 0.412576\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123323; batch adversarial loss: 0.389554\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159643; batch adversarial loss: 0.474633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153395; batch adversarial loss: 0.382699\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171463; batch adversarial loss: 0.445335\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179172; batch adversarial loss: 0.391816\n",
      "epoch 36; iter: 0; batch classifier loss: 0.094235; batch adversarial loss: 0.363230\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105694; batch adversarial loss: 0.412883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139484; batch adversarial loss: 0.359480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140900; batch adversarial loss: 0.466714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126375; batch adversarial loss: 0.434107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112196; batch adversarial loss: 0.405919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102163; batch adversarial loss: 0.352912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110953; batch adversarial loss: 0.478046\n",
      "epoch 44; iter: 0; batch classifier loss: 0.188198; batch adversarial loss: 0.334613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097820; batch adversarial loss: 0.425274\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103448; batch adversarial loss: 0.409506\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192359; batch adversarial loss: 0.589190\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120228; batch adversarial loss: 0.363390\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089766; batch adversarial loss: 0.470156\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106181; batch adversarial loss: 0.368422\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097264; batch adversarial loss: 0.448481\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089245; batch adversarial loss: 0.439648\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113941; batch adversarial loss: 0.423905\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082531; batch adversarial loss: 0.385892\n",
      "epoch 55; iter: 0; batch classifier loss: 0.079614; batch adversarial loss: 0.433120\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069240; batch adversarial loss: 0.427557\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107039; batch adversarial loss: 0.380265\n",
      "epoch 58; iter: 0; batch classifier loss: 0.104225; batch adversarial loss: 0.369772\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133455; batch adversarial loss: 0.376172\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081623; batch adversarial loss: 0.432083\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068591; batch adversarial loss: 0.368826\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154042; batch adversarial loss: 0.480291\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115485; batch adversarial loss: 0.415925\n",
      "epoch 64; iter: 0; batch classifier loss: 0.114865; batch adversarial loss: 0.497936\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067196; batch adversarial loss: 0.346159\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070525; batch adversarial loss: 0.441142\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096777; batch adversarial loss: 0.398513\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097158; batch adversarial loss: 0.376067\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054357; batch adversarial loss: 0.339299\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074349; batch adversarial loss: 0.409496\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105341; batch adversarial loss: 0.499244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.085141; batch adversarial loss: 0.436492\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068955; batch adversarial loss: 0.411104\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064644; batch adversarial loss: 0.396679\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089455; batch adversarial loss: 0.377021\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101928; batch adversarial loss: 0.358021\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078064; batch adversarial loss: 0.434655\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059462; batch adversarial loss: 0.398235\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060898; batch adversarial loss: 0.359607\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048707; batch adversarial loss: 0.416241\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095321; batch adversarial loss: 0.494337\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083181; batch adversarial loss: 0.451096\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069137; batch adversarial loss: 0.439938\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062983; batch adversarial loss: 0.445057\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069754; batch adversarial loss: 0.469913\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057176; batch adversarial loss: 0.406037\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081440; batch adversarial loss: 0.393100\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080451; batch adversarial loss: 0.444852\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067158; batch adversarial loss: 0.418159\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099802; batch adversarial loss: 0.495916\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075222; batch adversarial loss: 0.394143\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084612; batch adversarial loss: 0.461090\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084129; batch adversarial loss: 0.425729\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085260; batch adversarial loss: 0.433202\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.466150\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067627; batch adversarial loss: 0.413523\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058293; batch adversarial loss: 0.408102\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046329; batch adversarial loss: 0.429777\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039630; batch adversarial loss: 0.439033\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069713; batch adversarial loss: 0.393557\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042667; batch adversarial loss: 0.468399\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052094; batch adversarial loss: 0.365231\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058531; batch adversarial loss: 0.338519\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035126; batch adversarial loss: 0.395919\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044870; batch adversarial loss: 0.447406\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036064; batch adversarial loss: 0.398091\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082647; batch adversarial loss: 0.321271\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025487; batch adversarial loss: 0.399397\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022529; batch adversarial loss: 0.417146\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026816; batch adversarial loss: 0.507173\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022488; batch adversarial loss: 0.450634\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045429; batch adversarial loss: 0.439430\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037688; batch adversarial loss: 0.355227\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036486; batch adversarial loss: 0.488663\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044362; batch adversarial loss: 0.449294\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037434; batch adversarial loss: 0.462191\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053076; batch adversarial loss: 0.468160\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030748; batch adversarial loss: 0.403616\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034531; batch adversarial loss: 0.398892\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028348; batch adversarial loss: 0.340701\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033818; batch adversarial loss: 0.432987\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037779; batch adversarial loss: 0.412976\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.354870\n",
      "epoch 124; iter: 0; batch classifier loss: 0.010833; batch adversarial loss: 0.514870\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019824; batch adversarial loss: 0.526198\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024565; batch adversarial loss: 0.361937\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018752; batch adversarial loss: 0.465890\n",
      "epoch 128; iter: 0; batch classifier loss: 0.033060; batch adversarial loss: 0.460833\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027184; batch adversarial loss: 0.382236\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020116; batch adversarial loss: 0.393295\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042959; batch adversarial loss: 0.397202\n",
      "epoch 132; iter: 0; batch classifier loss: 0.007935; batch adversarial loss: 0.394968\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019790; batch adversarial loss: 0.411291\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028922; batch adversarial loss: 0.492237\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023287; batch adversarial loss: 0.511050\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011358; batch adversarial loss: 0.512284\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057983; batch adversarial loss: 0.509097\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037960; batch adversarial loss: 0.657884\n",
      "epoch 139; iter: 0; batch classifier loss: 0.067998; batch adversarial loss: 0.505457\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073878; batch adversarial loss: 0.518467\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029237; batch adversarial loss: 0.431515\n",
      "epoch 142; iter: 0; batch classifier loss: 0.069244; batch adversarial loss: 0.608713\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051928; batch adversarial loss: 0.484044\n",
      "epoch 144; iter: 0; batch classifier loss: 0.089136; batch adversarial loss: 0.702169\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047401; batch adversarial loss: 0.555179\n",
      "epoch 146; iter: 0; batch classifier loss: 0.150821; batch adversarial loss: 0.694145\n",
      "epoch 147; iter: 0; batch classifier loss: 0.114920; batch adversarial loss: 0.564395\n",
      "epoch 148; iter: 0; batch classifier loss: 0.100771; batch adversarial loss: 0.604663\n",
      "epoch 149; iter: 0; batch classifier loss: 0.095160; batch adversarial loss: 0.618667\n",
      "epoch 150; iter: 0; batch classifier loss: 0.075510; batch adversarial loss: 0.547678\n",
      "epoch 151; iter: 0; batch classifier loss: 0.119557; batch adversarial loss: 0.593125\n",
      "epoch 152; iter: 0; batch classifier loss: 0.106480; batch adversarial loss: 0.644593\n",
      "epoch 153; iter: 0; batch classifier loss: 0.104610; batch adversarial loss: 0.515288\n",
      "epoch 154; iter: 0; batch classifier loss: 0.079749; batch adversarial loss: 0.522830\n",
      "epoch 155; iter: 0; batch classifier loss: 0.098287; batch adversarial loss: 0.500173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047569; batch adversarial loss: 0.468836\n",
      "epoch 157; iter: 0; batch classifier loss: 0.104198; batch adversarial loss: 0.596221\n",
      "epoch 158; iter: 0; batch classifier loss: 0.131899; batch adversarial loss: 0.553475\n",
      "epoch 159; iter: 0; batch classifier loss: 0.158959; batch adversarial loss: 0.596182\n",
      "epoch 160; iter: 0; batch classifier loss: 0.117413; batch adversarial loss: 0.430284\n",
      "epoch 161; iter: 0; batch classifier loss: 0.219084; batch adversarial loss: 0.693594\n",
      "epoch 162; iter: 0; batch classifier loss: 0.090115; batch adversarial loss: 0.475932\n",
      "epoch 163; iter: 0; batch classifier loss: 0.075159; batch adversarial loss: 0.523469\n",
      "epoch 164; iter: 0; batch classifier loss: 0.070030; batch adversarial loss: 0.423907\n",
      "epoch 165; iter: 0; batch classifier loss: 0.084556; batch adversarial loss: 0.554969\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060491; batch adversarial loss: 0.427707\n",
      "epoch 167; iter: 0; batch classifier loss: 0.127289; batch adversarial loss: 0.574737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.184603; batch adversarial loss: 0.689369\n",
      "epoch 169; iter: 0; batch classifier loss: 0.161567; batch adversarial loss: 0.559817\n",
      "epoch 170; iter: 0; batch classifier loss: 0.077413; batch adversarial loss: 0.475224\n",
      "epoch 171; iter: 0; batch classifier loss: 0.087391; batch adversarial loss: 0.423208\n",
      "epoch 172; iter: 0; batch classifier loss: 0.102945; batch adversarial loss: 0.534384\n",
      "epoch 173; iter: 0; batch classifier loss: 0.084094; batch adversarial loss: 0.494214\n",
      "epoch 174; iter: 0; batch classifier loss: 0.123685; batch adversarial loss: 0.547214\n",
      "epoch 175; iter: 0; batch classifier loss: 0.138340; batch adversarial loss: 0.476097\n",
      "epoch 176; iter: 0; batch classifier loss: 0.086310; batch adversarial loss: 0.530052\n",
      "epoch 177; iter: 0; batch classifier loss: 0.163326; batch adversarial loss: 0.559404\n",
      "epoch 178; iter: 0; batch classifier loss: 0.085150; batch adversarial loss: 0.427506\n",
      "epoch 179; iter: 0; batch classifier loss: 0.095169; batch adversarial loss: 0.469178\n",
      "epoch 180; iter: 0; batch classifier loss: 0.070556; batch adversarial loss: 0.435673\n",
      "epoch 181; iter: 0; batch classifier loss: 0.087639; batch adversarial loss: 0.485271\n",
      "epoch 182; iter: 0; batch classifier loss: 0.148389; batch adversarial loss: 0.543074\n",
      "epoch 183; iter: 0; batch classifier loss: 0.162552; batch adversarial loss: 0.455181\n",
      "epoch 184; iter: 0; batch classifier loss: 0.085542; batch adversarial loss: 0.469223\n",
      "epoch 185; iter: 0; batch classifier loss: 0.089728; batch adversarial loss: 0.475112\n",
      "epoch 186; iter: 0; batch classifier loss: 0.144382; batch adversarial loss: 0.580671\n",
      "epoch 187; iter: 0; batch classifier loss: 0.127969; batch adversarial loss: 0.463916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051402; batch adversarial loss: 0.415719\n",
      "epoch 189; iter: 0; batch classifier loss: 0.106932; batch adversarial loss: 0.454610\n",
      "epoch 190; iter: 0; batch classifier loss: 0.115503; batch adversarial loss: 0.481759\n",
      "epoch 191; iter: 0; batch classifier loss: 0.130150; batch adversarial loss: 0.514793\n",
      "epoch 192; iter: 0; batch classifier loss: 0.102578; batch adversarial loss: 0.475264\n",
      "epoch 193; iter: 0; batch classifier loss: 0.150486; batch adversarial loss: 0.443736\n",
      "epoch 194; iter: 0; batch classifier loss: 0.128372; batch adversarial loss: 0.444233\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037370; batch adversarial loss: 0.467989\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028227; batch adversarial loss: 0.485620\n",
      "epoch 197; iter: 0; batch classifier loss: 0.030469; batch adversarial loss: 0.330681\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025328; batch adversarial loss: 0.428647\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020385; batch adversarial loss: 0.479735\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675270; batch adversarial loss: 0.621321\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489023; batch adversarial loss: 0.630746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.404990; batch adversarial loss: 0.585691\n",
      "epoch 3; iter: 0; batch classifier loss: 0.440918; batch adversarial loss: 0.597384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.475265; batch adversarial loss: 0.619090\n",
      "epoch 5; iter: 0; batch classifier loss: 0.591280; batch adversarial loss: 0.637145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570974; batch adversarial loss: 0.628359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492409; batch adversarial loss: 0.578279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483732; batch adversarial loss: 0.537264\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373557; batch adversarial loss: 0.500730\n",
      "epoch 10; iter: 0; batch classifier loss: 0.412260; batch adversarial loss: 0.533973\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333648; batch adversarial loss: 0.505863\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356428; batch adversarial loss: 0.521356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.365907; batch adversarial loss: 0.491914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316628; batch adversarial loss: 0.513952\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307338; batch adversarial loss: 0.453668\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318774; batch adversarial loss: 0.484902\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357314; batch adversarial loss: 0.500642\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269467; batch adversarial loss: 0.444406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284512; batch adversarial loss: 0.500889\n",
      "epoch 20; iter: 0; batch classifier loss: 0.243711; batch adversarial loss: 0.432713\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306355; batch adversarial loss: 0.475691\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206486; batch adversarial loss: 0.418901\n",
      "epoch 23; iter: 0; batch classifier loss: 0.266720; batch adversarial loss: 0.406092\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267088; batch adversarial loss: 0.521616\n",
      "epoch 25; iter: 0; batch classifier loss: 0.247213; batch adversarial loss: 0.466844\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346280; batch adversarial loss: 0.443871\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294028; batch adversarial loss: 0.472107\n",
      "epoch 28; iter: 0; batch classifier loss: 0.279864; batch adversarial loss: 0.437846\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222316; batch adversarial loss: 0.451324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244209; batch adversarial loss: 0.519600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254819; batch adversarial loss: 0.441597\n",
      "epoch 32; iter: 0; batch classifier loss: 0.251037; batch adversarial loss: 0.441306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201893; batch adversarial loss: 0.508007\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279724; batch adversarial loss: 0.394734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.290768; batch adversarial loss: 0.444401\n",
      "epoch 36; iter: 0; batch classifier loss: 0.230214; batch adversarial loss: 0.483643\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250059; batch adversarial loss: 0.461341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225802; batch adversarial loss: 0.368024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.267744; batch adversarial loss: 0.481124\n",
      "epoch 40; iter: 0; batch classifier loss: 0.290534; batch adversarial loss: 0.356454\n",
      "epoch 41; iter: 0; batch classifier loss: 0.234357; batch adversarial loss: 0.482958\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169625; batch adversarial loss: 0.421945\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101636; batch adversarial loss: 0.483798\n",
      "epoch 44; iter: 0; batch classifier loss: 0.081807; batch adversarial loss: 0.432537\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102258; batch adversarial loss: 0.380449\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079080; batch adversarial loss: 0.433624\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091970; batch adversarial loss: 0.370255\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092635; batch adversarial loss: 0.499858\n",
      "epoch 49; iter: 0; batch classifier loss: 0.087554; batch adversarial loss: 0.401646\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160225; batch adversarial loss: 0.516552\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121504; batch adversarial loss: 0.450753\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141911; batch adversarial loss: 0.465427\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135889; batch adversarial loss: 0.423246\n",
      "epoch 54; iter: 0; batch classifier loss: 0.151878; batch adversarial loss: 0.458715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146331; batch adversarial loss: 0.502103\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159662; batch adversarial loss: 0.424393\n",
      "epoch 57; iter: 0; batch classifier loss: 0.150958; batch adversarial loss: 0.502253\n",
      "epoch 58; iter: 0; batch classifier loss: 0.192887; batch adversarial loss: 0.557545\n",
      "epoch 59; iter: 0; batch classifier loss: 0.163928; batch adversarial loss: 0.516224\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189699; batch adversarial loss: 0.422289\n",
      "epoch 61; iter: 0; batch classifier loss: 0.131157; batch adversarial loss: 0.374912\n",
      "epoch 62; iter: 0; batch classifier loss: 0.156284; batch adversarial loss: 0.483746\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175621; batch adversarial loss: 0.434481\n",
      "epoch 64; iter: 0; batch classifier loss: 0.168234; batch adversarial loss: 0.645247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.137287; batch adversarial loss: 0.493340\n",
      "epoch 66; iter: 0; batch classifier loss: 0.166888; batch adversarial loss: 0.457169\n",
      "epoch 67; iter: 0; batch classifier loss: 0.198597; batch adversarial loss: 0.484438\n",
      "epoch 68; iter: 0; batch classifier loss: 0.223260; batch adversarial loss: 0.484302\n",
      "epoch 69; iter: 0; batch classifier loss: 0.202695; batch adversarial loss: 0.508703\n",
      "epoch 70; iter: 0; batch classifier loss: 0.157820; batch adversarial loss: 0.470934\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169202; batch adversarial loss: 0.496516\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088715; batch adversarial loss: 0.446526\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123305; batch adversarial loss: 0.420599\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070452; batch adversarial loss: 0.484612\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091739; batch adversarial loss: 0.457336\n",
      "epoch 76; iter: 0; batch classifier loss: 0.134525; batch adversarial loss: 0.333503\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099927; batch adversarial loss: 0.496663\n",
      "epoch 78; iter: 0; batch classifier loss: 0.141120; batch adversarial loss: 0.457865\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132353; batch adversarial loss: 0.473271\n",
      "epoch 80; iter: 0; batch classifier loss: 0.171840; batch adversarial loss: 0.371195\n",
      "epoch 81; iter: 0; batch classifier loss: 0.166398; batch adversarial loss: 0.456866\n",
      "epoch 82; iter: 0; batch classifier loss: 0.133309; batch adversarial loss: 0.481693\n",
      "epoch 83; iter: 0; batch classifier loss: 0.155107; batch adversarial loss: 0.496533\n",
      "epoch 84; iter: 0; batch classifier loss: 0.194143; batch adversarial loss: 0.511823\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109815; batch adversarial loss: 0.470831\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118526; batch adversarial loss: 0.468200\n",
      "epoch 87; iter: 0; batch classifier loss: 0.159684; batch adversarial loss: 0.371145\n",
      "epoch 88; iter: 0; batch classifier loss: 0.164973; batch adversarial loss: 0.372759\n",
      "epoch 89; iter: 0; batch classifier loss: 0.150102; batch adversarial loss: 0.370855\n",
      "epoch 90; iter: 0; batch classifier loss: 0.149209; batch adversarial loss: 0.447505\n",
      "epoch 91; iter: 0; batch classifier loss: 0.222941; batch adversarial loss: 0.422080\n",
      "epoch 92; iter: 0; batch classifier loss: 0.191645; batch adversarial loss: 0.433218\n",
      "epoch 93; iter: 0; batch classifier loss: 0.135101; batch adversarial loss: 0.481499\n",
      "epoch 94; iter: 0; batch classifier loss: 0.136267; batch adversarial loss: 0.544367\n",
      "epoch 95; iter: 0; batch classifier loss: 0.134549; batch adversarial loss: 0.420651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.160948; batch adversarial loss: 0.481920\n",
      "epoch 97; iter: 0; batch classifier loss: 0.131588; batch adversarial loss: 0.496845\n",
      "epoch 98; iter: 0; batch classifier loss: 0.200884; batch adversarial loss: 0.432452\n",
      "epoch 99; iter: 0; batch classifier loss: 0.236369; batch adversarial loss: 0.409018\n",
      "epoch 100; iter: 0; batch classifier loss: 0.185871; batch adversarial loss: 0.432872\n",
      "epoch 101; iter: 0; batch classifier loss: 0.166533; batch adversarial loss: 0.433215\n",
      "epoch 102; iter: 0; batch classifier loss: 0.179398; batch adversarial loss: 0.421591\n",
      "epoch 103; iter: 0; batch classifier loss: 0.161579; batch adversarial loss: 0.372314\n",
      "epoch 104; iter: 0; batch classifier loss: 0.136460; batch adversarial loss: 0.432382\n",
      "epoch 105; iter: 0; batch classifier loss: 0.153289; batch adversarial loss: 0.396060\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105650; batch adversarial loss: 0.444420\n",
      "epoch 107; iter: 0; batch classifier loss: 0.178422; batch adversarial loss: 0.484106\n",
      "epoch 108; iter: 0; batch classifier loss: 0.146427; batch adversarial loss: 0.481690\n",
      "epoch 109; iter: 0; batch classifier loss: 0.106215; batch adversarial loss: 0.523010\n",
      "epoch 110; iter: 0; batch classifier loss: 0.127147; batch adversarial loss: 0.448863\n",
      "epoch 111; iter: 0; batch classifier loss: 0.121060; batch adversarial loss: 0.421230\n",
      "epoch 112; iter: 0; batch classifier loss: 0.122260; batch adversarial loss: 0.481844\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076364; batch adversarial loss: 0.494557\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076964; batch adversarial loss: 0.549519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068853; batch adversarial loss: 0.455695\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082843; batch adversarial loss: 0.421728\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061473; batch adversarial loss: 0.481629\n",
      "epoch 118; iter: 0; batch classifier loss: 0.065634; batch adversarial loss: 0.445453\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036360; batch adversarial loss: 0.506652\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056342; batch adversarial loss: 0.468594\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044867; batch adversarial loss: 0.485143\n",
      "epoch 122; iter: 0; batch classifier loss: 0.068006; batch adversarial loss: 0.455054\n",
      "epoch 123; iter: 0; batch classifier loss: 0.082231; batch adversarial loss: 0.436871\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038469; batch adversarial loss: 0.468993\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048139; batch adversarial loss: 0.473613\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044969; batch adversarial loss: 0.521551\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040541; batch adversarial loss: 0.385076\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021766; batch adversarial loss: 0.493433\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040902; batch adversarial loss: 0.505804\n",
      "epoch 130; iter: 0; batch classifier loss: 0.066874; batch adversarial loss: 0.426576\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027205; batch adversarial loss: 0.384866\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014958; batch adversarial loss: 0.408418\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032558; batch adversarial loss: 0.518475\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042980; batch adversarial loss: 0.436599\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023463; batch adversarial loss: 0.456760\n",
      "epoch 136; iter: 0; batch classifier loss: 0.021577; batch adversarial loss: 0.460896\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039423; batch adversarial loss: 0.339597\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024967; batch adversarial loss: 0.471589\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021828; batch adversarial loss: 0.440611\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034064; batch adversarial loss: 0.368102\n",
      "epoch 141; iter: 0; batch classifier loss: 0.009678; batch adversarial loss: 0.464813\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047851; batch adversarial loss: 0.505927\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015943; batch adversarial loss: 0.604439\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017068; batch adversarial loss: 0.368204\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043367; batch adversarial loss: 0.376039\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026567; batch adversarial loss: 0.483039\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034607; batch adversarial loss: 0.433415\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011032; batch adversarial loss: 0.449246\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020362; batch adversarial loss: 0.525846\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019563; batch adversarial loss: 0.473229\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020395; batch adversarial loss: 0.511095\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030366; batch adversarial loss: 0.421187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006167; batch adversarial loss: 0.494480\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013686; batch adversarial loss: 0.462230\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010299; batch adversarial loss: 0.447344\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021773; batch adversarial loss: 0.456720\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023721; batch adversarial loss: 0.349370\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029922; batch adversarial loss: 0.414577\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.420258\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023873; batch adversarial loss: 0.441296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.029437; batch adversarial loss: 0.511702\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027919; batch adversarial loss: 0.391511\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019444; batch adversarial loss: 0.483097\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017860; batch adversarial loss: 0.298869\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007241; batch adversarial loss: 0.439133\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029736; batch adversarial loss: 0.441547\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013888; batch adversarial loss: 0.457001\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015076; batch adversarial loss: 0.381540\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015586; batch adversarial loss: 0.522991\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009013; batch adversarial loss: 0.545225\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029326; batch adversarial loss: 0.493181\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017769; batch adversarial loss: 0.485491\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034288; batch adversarial loss: 0.441604\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017269; batch adversarial loss: 0.432703\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018187; batch adversarial loss: 0.396591\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005492; batch adversarial loss: 0.457844\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011477; batch adversarial loss: 0.445025\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008515; batch adversarial loss: 0.425274\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028078; batch adversarial loss: 0.405564\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015193; batch adversarial loss: 0.531294\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026164; batch adversarial loss: 0.453011\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004692; batch adversarial loss: 0.353693\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013443; batch adversarial loss: 0.488892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006992; batch adversarial loss: 0.519701\n",
      "epoch 185; iter: 0; batch classifier loss: 0.026663; batch adversarial loss: 0.372998\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010534; batch adversarial loss: 0.495311\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016640; batch adversarial loss: 0.477265\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018420; batch adversarial loss: 0.400588\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007825; batch adversarial loss: 0.486622\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022426; batch adversarial loss: 0.425854\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008131; batch adversarial loss: 0.435375\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018496; batch adversarial loss: 0.420968\n",
      "epoch 193; iter: 0; batch classifier loss: 0.033291; batch adversarial loss: 0.472478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009998; batch adversarial loss: 0.387949\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011023; batch adversarial loss: 0.528509\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031501; batch adversarial loss: 0.417623\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.437643\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038864; batch adversarial loss: 0.423150\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043448; batch adversarial loss: 0.329191\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703306; batch adversarial loss: 0.512654\n",
      "epoch 1; iter: 0; batch classifier loss: 0.340647; batch adversarial loss: 0.598968\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458683; batch adversarial loss: 0.618955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.345339; batch adversarial loss: 0.603922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379540; batch adversarial loss: 0.576642\n",
      "epoch 5; iter: 0; batch classifier loss: 0.385387; batch adversarial loss: 0.530975\n",
      "epoch 6; iter: 0; batch classifier loss: 0.360609; batch adversarial loss: 0.603497\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532968; batch adversarial loss: 0.581704\n",
      "epoch 8; iter: 0; batch classifier loss: 0.365656; batch adversarial loss: 0.507421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.423467; batch adversarial loss: 0.556571\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492420; batch adversarial loss: 0.508659\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492014; batch adversarial loss: 0.556449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353923; batch adversarial loss: 0.512577\n",
      "epoch 13; iter: 0; batch classifier loss: 0.244460; batch adversarial loss: 0.507686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338698; batch adversarial loss: 0.492268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.181750; batch adversarial loss: 0.454579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236906; batch adversarial loss: 0.428901\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234206; batch adversarial loss: 0.450336\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185944; batch adversarial loss: 0.572499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238081; batch adversarial loss: 0.498204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256020; batch adversarial loss: 0.433427\n",
      "epoch 21; iter: 0; batch classifier loss: 0.164869; batch adversarial loss: 0.437644\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195241; batch adversarial loss: 0.407557\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174525; batch adversarial loss: 0.482549\n",
      "epoch 24; iter: 0; batch classifier loss: 0.172758; batch adversarial loss: 0.386360\n",
      "epoch 25; iter: 0; batch classifier loss: 0.106053; batch adversarial loss: 0.471991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.123141; batch adversarial loss: 0.419209\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159233; batch adversarial loss: 0.483525\n",
      "epoch 28; iter: 0; batch classifier loss: 0.102914; batch adversarial loss: 0.393762\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170502; batch adversarial loss: 0.469529\n",
      "epoch 30; iter: 0; batch classifier loss: 0.120996; batch adversarial loss: 0.513741\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148056; batch adversarial loss: 0.372619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111629; batch adversarial loss: 0.422889\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203899; batch adversarial loss: 0.495394\n",
      "epoch 34; iter: 0; batch classifier loss: 0.115874; batch adversarial loss: 0.403345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140924; batch adversarial loss: 0.431968\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153186; batch adversarial loss: 0.449107\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154368; batch adversarial loss: 0.478662\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105995; batch adversarial loss: 0.452276\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124029; batch adversarial loss: 0.510978\n",
      "epoch 40; iter: 0; batch classifier loss: 0.175730; batch adversarial loss: 0.436794\n",
      "epoch 41; iter: 0; batch classifier loss: 0.099981; batch adversarial loss: 0.473253\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142914; batch adversarial loss: 0.464030\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122041; batch adversarial loss: 0.425340\n",
      "epoch 44; iter: 0; batch classifier loss: 0.138286; batch adversarial loss: 0.464186\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133116; batch adversarial loss: 0.556843\n",
      "epoch 46; iter: 0; batch classifier loss: 0.173100; batch adversarial loss: 0.438107\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111477; batch adversarial loss: 0.423471\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158890; batch adversarial loss: 0.444224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.129401; batch adversarial loss: 0.429423\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100160; batch adversarial loss: 0.556964\n",
      "epoch 51; iter: 0; batch classifier loss: 0.131947; batch adversarial loss: 0.529407\n",
      "epoch 52; iter: 0; batch classifier loss: 0.157840; batch adversarial loss: 0.465419\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204798; batch adversarial loss: 0.424329\n",
      "epoch 54; iter: 0; batch classifier loss: 0.104907; batch adversarial loss: 0.475846\n",
      "epoch 55; iter: 0; batch classifier loss: 0.142395; batch adversarial loss: 0.541519\n",
      "epoch 56; iter: 0; batch classifier loss: 0.171412; batch adversarial loss: 0.518219\n",
      "epoch 57; iter: 0; batch classifier loss: 0.177066; batch adversarial loss: 0.409089\n",
      "epoch 58; iter: 0; batch classifier loss: 0.129217; batch adversarial loss: 0.450087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.133583; batch adversarial loss: 0.471689\n",
      "epoch 60; iter: 0; batch classifier loss: 0.181183; batch adversarial loss: 0.397407\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115296; batch adversarial loss: 0.520223\n",
      "epoch 62; iter: 0; batch classifier loss: 0.139093; batch adversarial loss: 0.431101\n",
      "epoch 63; iter: 0; batch classifier loss: 0.132240; batch adversarial loss: 0.412316\n",
      "epoch 64; iter: 0; batch classifier loss: 0.143814; batch adversarial loss: 0.532284\n",
      "epoch 65; iter: 0; batch classifier loss: 0.135070; batch adversarial loss: 0.385152\n",
      "epoch 66; iter: 0; batch classifier loss: 0.184866; batch adversarial loss: 0.578751\n",
      "epoch 67; iter: 0; batch classifier loss: 0.144311; batch adversarial loss: 0.521385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.123774; batch adversarial loss: 0.420247\n",
      "epoch 69; iter: 0; batch classifier loss: 0.196226; batch adversarial loss: 0.428204\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115913; batch adversarial loss: 0.413110\n",
      "epoch 71; iter: 0; batch classifier loss: 0.190615; batch adversarial loss: 0.433203\n",
      "epoch 72; iter: 0; batch classifier loss: 0.194434; batch adversarial loss: 0.472180\n",
      "epoch 73; iter: 0; batch classifier loss: 0.153799; batch adversarial loss: 0.583078\n",
      "epoch 74; iter: 0; batch classifier loss: 0.129642; batch adversarial loss: 0.508127\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122844; batch adversarial loss: 0.428443\n",
      "epoch 76; iter: 0; batch classifier loss: 0.200326; batch adversarial loss: 0.370867\n",
      "epoch 77; iter: 0; batch classifier loss: 0.213250; batch adversarial loss: 0.356604\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113103; batch adversarial loss: 0.561414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115927; batch adversarial loss: 0.503650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.195475; batch adversarial loss: 0.471141\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193880; batch adversarial loss: 0.528691\n",
      "epoch 82; iter: 0; batch classifier loss: 0.186509; batch adversarial loss: 0.489732\n",
      "epoch 83; iter: 0; batch classifier loss: 0.169803; batch adversarial loss: 0.478305\n",
      "epoch 84; iter: 0; batch classifier loss: 0.151217; batch adversarial loss: 0.343460\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154153; batch adversarial loss: 0.418056\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112490; batch adversarial loss: 0.545487\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077220; batch adversarial loss: 0.512616\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078720; batch adversarial loss: 0.447315\n",
      "epoch 89; iter: 0; batch classifier loss: 0.104261; batch adversarial loss: 0.551816\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118966; batch adversarial loss: 0.360175\n",
      "epoch 91; iter: 0; batch classifier loss: 0.193258; batch adversarial loss: 0.458544\n",
      "epoch 92; iter: 0; batch classifier loss: 0.169479; batch adversarial loss: 0.429448\n",
      "epoch 93; iter: 0; batch classifier loss: 0.163450; batch adversarial loss: 0.458688\n",
      "epoch 94; iter: 0; batch classifier loss: 0.131863; batch adversarial loss: 0.518683\n",
      "epoch 95; iter: 0; batch classifier loss: 0.118776; batch adversarial loss: 0.468245\n",
      "epoch 96; iter: 0; batch classifier loss: 0.114389; batch adversarial loss: 0.562206\n",
      "epoch 97; iter: 0; batch classifier loss: 0.147743; batch adversarial loss: 0.391316\n",
      "epoch 98; iter: 0; batch classifier loss: 0.101978; batch adversarial loss: 0.346714\n",
      "epoch 99; iter: 0; batch classifier loss: 0.124744; batch adversarial loss: 0.443730\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097777; batch adversarial loss: 0.512899\n",
      "epoch 101; iter: 0; batch classifier loss: 0.103781; batch adversarial loss: 0.545230\n",
      "epoch 102; iter: 0; batch classifier loss: 0.131849; batch adversarial loss: 0.468941\n",
      "epoch 103; iter: 0; batch classifier loss: 0.138895; batch adversarial loss: 0.433315\n",
      "epoch 104; iter: 0; batch classifier loss: 0.129069; batch adversarial loss: 0.535849\n",
      "epoch 105; iter: 0; batch classifier loss: 0.164716; batch adversarial loss: 0.458800\n",
      "epoch 106; iter: 0; batch classifier loss: 0.146593; batch adversarial loss: 0.405688\n",
      "epoch 107; iter: 0; batch classifier loss: 0.120743; batch adversarial loss: 0.417324\n",
      "epoch 108; iter: 0; batch classifier loss: 0.133459; batch adversarial loss: 0.455696\n",
      "epoch 109; iter: 0; batch classifier loss: 0.143719; batch adversarial loss: 0.553910\n",
      "epoch 110; iter: 0; batch classifier loss: 0.124212; batch adversarial loss: 0.396432\n",
      "epoch 111; iter: 0; batch classifier loss: 0.112725; batch adversarial loss: 0.444829\n",
      "epoch 112; iter: 0; batch classifier loss: 0.126556; batch adversarial loss: 0.328917\n",
      "epoch 113; iter: 0; batch classifier loss: 0.178432; batch adversarial loss: 0.423740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.075660; batch adversarial loss: 0.409990\n",
      "epoch 115; iter: 0; batch classifier loss: 0.119947; batch adversarial loss: 0.498834\n",
      "epoch 116; iter: 0; batch classifier loss: 0.126444; batch adversarial loss: 0.342315\n",
      "epoch 117; iter: 0; batch classifier loss: 0.157690; batch adversarial loss: 0.391507\n",
      "epoch 118; iter: 0; batch classifier loss: 0.115468; batch adversarial loss: 0.518667\n",
      "epoch 119; iter: 0; batch classifier loss: 0.108084; batch adversarial loss: 0.359784\n",
      "epoch 120; iter: 0; batch classifier loss: 0.099220; batch adversarial loss: 0.464728\n",
      "epoch 121; iter: 0; batch classifier loss: 0.113903; batch adversarial loss: 0.510107\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057915; batch adversarial loss: 0.426241\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068824; batch adversarial loss: 0.361854\n",
      "epoch 124; iter: 0; batch classifier loss: 0.085801; batch adversarial loss: 0.494045\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065025; batch adversarial loss: 0.469929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060524; batch adversarial loss: 0.427121\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050540; batch adversarial loss: 0.406211\n",
      "epoch 128; iter: 0; batch classifier loss: 0.081581; batch adversarial loss: 0.431993\n",
      "epoch 129; iter: 0; batch classifier loss: 0.131745; batch adversarial loss: 0.495312\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051115; batch adversarial loss: 0.380622\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053189; batch adversarial loss: 0.404130\n",
      "epoch 132; iter: 0; batch classifier loss: 0.081401; batch adversarial loss: 0.464473\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036068; batch adversarial loss: 0.479988\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067985; batch adversarial loss: 0.531713\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040855; batch adversarial loss: 0.513440\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048976; batch adversarial loss: 0.444968\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067297; batch adversarial loss: 0.522997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.068233; batch adversarial loss: 0.429785\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058067; batch adversarial loss: 0.536631\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031253; batch adversarial loss: 0.429927\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037873; batch adversarial loss: 0.593332\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030954; batch adversarial loss: 0.490205\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047016; batch adversarial loss: 0.409822\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033382; batch adversarial loss: 0.383486\n",
      "epoch 145; iter: 0; batch classifier loss: 0.026214; batch adversarial loss: 0.414226\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012577; batch adversarial loss: 0.390077\n",
      "epoch 147; iter: 0; batch classifier loss: 0.073769; batch adversarial loss: 0.445724\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022963; batch adversarial loss: 0.423191\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025602; batch adversarial loss: 0.461114\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047551; batch adversarial loss: 0.544880\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019205; batch adversarial loss: 0.475068\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022351; batch adversarial loss: 0.442674\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045256; batch adversarial loss: 0.458968\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029851; batch adversarial loss: 0.496178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.025444; batch adversarial loss: 0.417297\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.476682\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016695; batch adversarial loss: 0.384666\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019730; batch adversarial loss: 0.401723\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040041; batch adversarial loss: 0.483448\n",
      "epoch 160; iter: 0; batch classifier loss: 0.061045; batch adversarial loss: 0.433077\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031585; batch adversarial loss: 0.365230\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033285; batch adversarial loss: 0.413937\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026359; batch adversarial loss: 0.377066\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.406909\n",
      "epoch 165; iter: 0; batch classifier loss: 0.051811; batch adversarial loss: 0.352024\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.564470\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038728; batch adversarial loss: 0.462091\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010565; batch adversarial loss: 0.473107\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029026; batch adversarial loss: 0.445842\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018058; batch adversarial loss: 0.506983\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031819; batch adversarial loss: 0.465523\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018741; batch adversarial loss: 0.503265\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034261; batch adversarial loss: 0.437364\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015566; batch adversarial loss: 0.376144\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016211; batch adversarial loss: 0.440078\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014082; batch adversarial loss: 0.466681\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027914; batch adversarial loss: 0.397130\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008336; batch adversarial loss: 0.466484\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034737; batch adversarial loss: 0.497411\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039784; batch adversarial loss: 0.484436\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025421; batch adversarial loss: 0.453605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011737; batch adversarial loss: 0.556495\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005938; batch adversarial loss: 0.416812\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045852; batch adversarial loss: 0.413875\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022534; batch adversarial loss: 0.439112\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039324; batch adversarial loss: 0.432102\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022356; batch adversarial loss: 0.563919\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038020; batch adversarial loss: 0.474357\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020412; batch adversarial loss: 0.391952\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011654; batch adversarial loss: 0.462866\n",
      "epoch 191; iter: 0; batch classifier loss: 0.055844; batch adversarial loss: 0.438268\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025426; batch adversarial loss: 0.457408\n",
      "epoch 193; iter: 0; batch classifier loss: 0.053385; batch adversarial loss: 0.474979\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012271; batch adversarial loss: 0.469296\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021707; batch adversarial loss: 0.485193\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010132; batch adversarial loss: 0.459949\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012859; batch adversarial loss: 0.357613\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009778; batch adversarial loss: 0.478370\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017566; batch adversarial loss: 0.442018\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685310; batch adversarial loss: 0.621067\n",
      "epoch 1; iter: 0; batch classifier loss: 0.428397; batch adversarial loss: 0.608789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380134; batch adversarial loss: 0.601830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379229; batch adversarial loss: 0.564445\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328824; batch adversarial loss: 0.577246\n",
      "epoch 5; iter: 0; batch classifier loss: 0.301103; batch adversarial loss: 0.550984\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271459; batch adversarial loss: 0.546080\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259087; batch adversarial loss: 0.560958\n",
      "epoch 8; iter: 0; batch classifier loss: 0.265896; batch adversarial loss: 0.456642\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287644; batch adversarial loss: 0.483940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.254596; batch adversarial loss: 0.458567\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273499; batch adversarial loss: 0.527670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284189; batch adversarial loss: 0.577035\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292867; batch adversarial loss: 0.530119\n",
      "epoch 14; iter: 0; batch classifier loss: 0.256656; batch adversarial loss: 0.607950\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226037; batch adversarial loss: 0.523942\n",
      "epoch 16; iter: 0; batch classifier loss: 0.277335; batch adversarial loss: 0.588760\n",
      "epoch 17; iter: 0; batch classifier loss: 0.197906; batch adversarial loss: 0.532001\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229718; batch adversarial loss: 0.502840\n",
      "epoch 19; iter: 0; batch classifier loss: 0.223463; batch adversarial loss: 0.546966\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291675; batch adversarial loss: 0.506436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370103; batch adversarial loss: 0.577135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329617; batch adversarial loss: 0.521372\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367502; batch adversarial loss: 0.515824\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466038; batch adversarial loss: 0.528048\n",
      "epoch 25; iter: 0; batch classifier loss: 0.258840; batch adversarial loss: 0.394092\n",
      "epoch 26; iter: 0; batch classifier loss: 0.136440; batch adversarial loss: 0.530212\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208683; batch adversarial loss: 0.480671\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163676; batch adversarial loss: 0.402416\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150414; batch adversarial loss: 0.433915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135225; batch adversarial loss: 0.379786\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150034; batch adversarial loss: 0.479463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144861; batch adversarial loss: 0.468118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.093289; batch adversarial loss: 0.496137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149947; batch adversarial loss: 0.464404\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122616; batch adversarial loss: 0.475061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148878; batch adversarial loss: 0.461969\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118996; batch adversarial loss: 0.429551\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118516; batch adversarial loss: 0.451297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112468; batch adversarial loss: 0.442838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114836; batch adversarial loss: 0.553726\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117013; batch adversarial loss: 0.395079\n",
      "epoch 42; iter: 0; batch classifier loss: 0.126701; batch adversarial loss: 0.514813\n",
      "epoch 43; iter: 0; batch classifier loss: 0.068578; batch adversarial loss: 0.497776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.056490; batch adversarial loss: 0.481249\n",
      "epoch 45; iter: 0; batch classifier loss: 0.068808; batch adversarial loss: 0.415650\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127438; batch adversarial loss: 0.465628\n",
      "epoch 47; iter: 0; batch classifier loss: 0.058325; batch adversarial loss: 0.363077\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124377; batch adversarial loss: 0.408219\n",
      "epoch 49; iter: 0; batch classifier loss: 0.139053; batch adversarial loss: 0.399360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079399; batch adversarial loss: 0.449864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.106404; batch adversarial loss: 0.400675\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099912; batch adversarial loss: 0.474526\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121512; batch adversarial loss: 0.464424\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099200; batch adversarial loss: 0.431119\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125523; batch adversarial loss: 0.371707\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099327; batch adversarial loss: 0.456076\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102264; batch adversarial loss: 0.447222\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084275; batch adversarial loss: 0.476622\n",
      "epoch 59; iter: 0; batch classifier loss: 0.134533; batch adversarial loss: 0.475726\n",
      "epoch 60; iter: 0; batch classifier loss: 0.123416; batch adversarial loss: 0.407392\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067748; batch adversarial loss: 0.404563\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089427; batch adversarial loss: 0.492764\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078950; batch adversarial loss: 0.492135\n",
      "epoch 64; iter: 0; batch classifier loss: 0.100546; batch adversarial loss: 0.517465\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147862; batch adversarial loss: 0.430959\n",
      "epoch 66; iter: 0; batch classifier loss: 0.132318; batch adversarial loss: 0.391025\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079298; batch adversarial loss: 0.402129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070472; batch adversarial loss: 0.451432\n",
      "epoch 69; iter: 0; batch classifier loss: 0.105948; batch adversarial loss: 0.565206\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080912; batch adversarial loss: 0.377013\n",
      "epoch 71; iter: 0; batch classifier loss: 0.147701; batch adversarial loss: 0.406245\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085918; batch adversarial loss: 0.486340\n",
      "epoch 73; iter: 0; batch classifier loss: 0.146129; batch adversarial loss: 0.426414\n",
      "epoch 74; iter: 0; batch classifier loss: 0.136742; batch adversarial loss: 0.473781\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116768; batch adversarial loss: 0.466424\n",
      "epoch 76; iter: 0; batch classifier loss: 0.099851; batch adversarial loss: 0.526591\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053660; batch adversarial loss: 0.508417\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087502; batch adversarial loss: 0.452936\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112501; batch adversarial loss: 0.492345\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095974; batch adversarial loss: 0.359470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105940; batch adversarial loss: 0.492104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.112187; batch adversarial loss: 0.468193\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069503; batch adversarial loss: 0.493641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.178601; batch adversarial loss: 0.364823\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086865; batch adversarial loss: 0.384981\n",
      "epoch 86; iter: 0; batch classifier loss: 0.093863; batch adversarial loss: 0.420521\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086652; batch adversarial loss: 0.490915\n",
      "epoch 88; iter: 0; batch classifier loss: 0.044123; batch adversarial loss: 0.552384\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085082; batch adversarial loss: 0.475452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.557724\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046313; batch adversarial loss: 0.502241\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097438; batch adversarial loss: 0.510351\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062395; batch adversarial loss: 0.522001\n",
      "epoch 94; iter: 0; batch classifier loss: 0.067897; batch adversarial loss: 0.409395\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085967; batch adversarial loss: 0.467746\n",
      "epoch 96; iter: 0; batch classifier loss: 0.103247; batch adversarial loss: 0.425435\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059050; batch adversarial loss: 0.420155\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067619; batch adversarial loss: 0.412302\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056032; batch adversarial loss: 0.543049\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058306; batch adversarial loss: 0.453368\n",
      "epoch 101; iter: 0; batch classifier loss: 0.167847; batch adversarial loss: 0.363521\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060346; batch adversarial loss: 0.489357\n",
      "epoch 103; iter: 0; batch classifier loss: 0.109234; batch adversarial loss: 0.468418\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074891; batch adversarial loss: 0.456851\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046630; batch adversarial loss: 0.379732\n",
      "epoch 106; iter: 0; batch classifier loss: 0.063106; batch adversarial loss: 0.489111\n",
      "epoch 107; iter: 0; batch classifier loss: 0.139093; batch adversarial loss: 0.468600\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059761; batch adversarial loss: 0.517890\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081297; batch adversarial loss: 0.435467\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067669; batch adversarial loss: 0.451776\n",
      "epoch 111; iter: 0; batch classifier loss: 0.102246; batch adversarial loss: 0.483786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050491; batch adversarial loss: 0.489973\n",
      "epoch 113; iter: 0; batch classifier loss: 0.111999; batch adversarial loss: 0.439830\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068761; batch adversarial loss: 0.386650\n",
      "epoch 115; iter: 0; batch classifier loss: 0.053197; batch adversarial loss: 0.446563\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079745; batch adversarial loss: 0.431368\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033649; batch adversarial loss: 0.516900\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030636; batch adversarial loss: 0.408109\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041190; batch adversarial loss: 0.442961\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035025; batch adversarial loss: 0.491448\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052203; batch adversarial loss: 0.415029\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031382; batch adversarial loss: 0.423306\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027547; batch adversarial loss: 0.509256\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013334; batch adversarial loss: 0.435379\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027680; batch adversarial loss: 0.471058\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032685; batch adversarial loss: 0.500370\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028144; batch adversarial loss: 0.410670\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044646; batch adversarial loss: 0.430008\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059117; batch adversarial loss: 0.425084\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036570; batch adversarial loss: 0.489965\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028401; batch adversarial loss: 0.424267\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047900; batch adversarial loss: 0.473200\n",
      "epoch 133; iter: 0; batch classifier loss: 0.075483; batch adversarial loss: 0.567636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028888; batch adversarial loss: 0.505244\n",
      "epoch 135; iter: 0; batch classifier loss: 0.056288; batch adversarial loss: 0.452129\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060820; batch adversarial loss: 0.488248\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017109; batch adversarial loss: 0.479454\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026734; batch adversarial loss: 0.411619\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035745; batch adversarial loss: 0.448951\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049185; batch adversarial loss: 0.451564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032910; batch adversarial loss: 0.436444\n",
      "epoch 142; iter: 0; batch classifier loss: 0.060654; batch adversarial loss: 0.470184\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027240; batch adversarial loss: 0.413926\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027039; batch adversarial loss: 0.478861\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028980; batch adversarial loss: 0.515858\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027530; batch adversarial loss: 0.538458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.388072\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012682; batch adversarial loss: 0.480333\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056963; batch adversarial loss: 0.484711\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058549; batch adversarial loss: 0.379674\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037851; batch adversarial loss: 0.483525\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051739; batch adversarial loss: 0.543587\n",
      "epoch 153; iter: 0; batch classifier loss: 0.053154; batch adversarial loss: 0.446928\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032932; batch adversarial loss: 0.515302\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016065; batch adversarial loss: 0.452751\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011098; batch adversarial loss: 0.502970\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.525541\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055343; batch adversarial loss: 0.413555\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037416; batch adversarial loss: 0.430886\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024434; batch adversarial loss: 0.530429\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053659; batch adversarial loss: 0.391127\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037857; batch adversarial loss: 0.513902\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016794; batch adversarial loss: 0.447830\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018328; batch adversarial loss: 0.452601\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029641; batch adversarial loss: 0.396955\n",
      "epoch 166; iter: 0; batch classifier loss: 0.056689; batch adversarial loss: 0.397135\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012947; batch adversarial loss: 0.382751\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022370; batch adversarial loss: 0.427111\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027848; batch adversarial loss: 0.465570\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.403080\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021727; batch adversarial loss: 0.493766\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009850; batch adversarial loss: 0.521809\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018946; batch adversarial loss: 0.531174\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016011; batch adversarial loss: 0.495481\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041590; batch adversarial loss: 0.420090\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028725; batch adversarial loss: 0.410071\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031848; batch adversarial loss: 0.413683\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011228; batch adversarial loss: 0.495817\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012212; batch adversarial loss: 0.474784\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023444; batch adversarial loss: 0.502489\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.411734\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018949; batch adversarial loss: 0.390364\n",
      "epoch 183; iter: 0; batch classifier loss: 0.044181; batch adversarial loss: 0.462146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022213; batch adversarial loss: 0.497055\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008474; batch adversarial loss: 0.469420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012853; batch adversarial loss: 0.557664\n",
      "epoch 187; iter: 0; batch classifier loss: 0.061791; batch adversarial loss: 0.401648\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044819; batch adversarial loss: 0.420093\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016137; batch adversarial loss: 0.622720\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031317; batch adversarial loss: 0.542116\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014331; batch adversarial loss: 0.479874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021831; batch adversarial loss: 0.483396\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006975; batch adversarial loss: 0.520622\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013942; batch adversarial loss: 0.480201\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008172; batch adversarial loss: 0.453335\n",
      "epoch 196; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.456315\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018355; batch adversarial loss: 0.463962\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033340; batch adversarial loss: 0.421251\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017044; batch adversarial loss: 0.409075\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716853; batch adversarial loss: 0.780639\n",
      "epoch 1; iter: 0; batch classifier loss: 0.693507; batch adversarial loss: 0.806939\n",
      "epoch 2; iter: 0; batch classifier loss: 0.769822; batch adversarial loss: 0.738195\n",
      "epoch 3; iter: 0; batch classifier loss: 0.691121; batch adversarial loss: 0.662279\n",
      "epoch 4; iter: 0; batch classifier loss: 0.490093; batch adversarial loss: 0.636576\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408553; batch adversarial loss: 0.581928\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345012; batch adversarial loss: 0.576737\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355846; batch adversarial loss: 0.543106\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298291; batch adversarial loss: 0.582232\n",
      "epoch 9; iter: 0; batch classifier loss: 0.355919; batch adversarial loss: 0.524103\n",
      "epoch 10; iter: 0; batch classifier loss: 0.283933; batch adversarial loss: 0.537643\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290012; batch adversarial loss: 0.505634\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280652; batch adversarial loss: 0.565581\n",
      "epoch 13; iter: 0; batch classifier loss: 0.268790; batch adversarial loss: 0.535800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239871; batch adversarial loss: 0.537986\n",
      "epoch 15; iter: 0; batch classifier loss: 0.295591; batch adversarial loss: 0.499179\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233878; batch adversarial loss: 0.530196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239916; batch adversarial loss: 0.465174\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216686; batch adversarial loss: 0.515269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207177; batch adversarial loss: 0.497319\n",
      "epoch 20; iter: 0; batch classifier loss: 0.203682; batch adversarial loss: 0.548513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213634; batch adversarial loss: 0.519170\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212720; batch adversarial loss: 0.482481\n",
      "epoch 23; iter: 0; batch classifier loss: 0.162317; batch adversarial loss: 0.504124\n",
      "epoch 24; iter: 0; batch classifier loss: 0.222902; batch adversarial loss: 0.524475\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215843; batch adversarial loss: 0.479029\n",
      "epoch 26; iter: 0; batch classifier loss: 0.212384; batch adversarial loss: 0.484123\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212489; batch adversarial loss: 0.456779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.246874; batch adversarial loss: 0.424306\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191453; batch adversarial loss: 0.500132\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202501; batch adversarial loss: 0.488221\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171645; batch adversarial loss: 0.432733\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139318; batch adversarial loss: 0.421269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.246050; batch adversarial loss: 0.475779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196020; batch adversarial loss: 0.372228\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171203; batch adversarial loss: 0.503442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109122; batch adversarial loss: 0.539955\n",
      "epoch 37; iter: 0; batch classifier loss: 0.147483; batch adversarial loss: 0.468662\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153425; batch adversarial loss: 0.402554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168957; batch adversarial loss: 0.423016\n",
      "epoch 40; iter: 0; batch classifier loss: 0.118970; batch adversarial loss: 0.484346\n",
      "epoch 41; iter: 0; batch classifier loss: 0.116764; batch adversarial loss: 0.401949\n",
      "epoch 42; iter: 0; batch classifier loss: 0.138119; batch adversarial loss: 0.435634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 0; batch classifier loss: 0.157913; batch adversarial loss: 0.477313\n",
      "epoch 44; iter: 0; batch classifier loss: 0.195390; batch adversarial loss: 0.429079\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132668; batch adversarial loss: 0.478861\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108587; batch adversarial loss: 0.453463\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125774; batch adversarial loss: 0.503939\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140960; batch adversarial loss: 0.420284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162416; batch adversarial loss: 0.365680\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135914; batch adversarial loss: 0.513549\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118880; batch adversarial loss: 0.487148\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106398; batch adversarial loss: 0.408616\n",
      "epoch 53; iter: 0; batch classifier loss: 0.140961; batch adversarial loss: 0.496992\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074921; batch adversarial loss: 0.442824\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098831; batch adversarial loss: 0.500654\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118097; batch adversarial loss: 0.433383\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105798; batch adversarial loss: 0.436922\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077143; batch adversarial loss: 0.472484\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090855; batch adversarial loss: 0.446748\n",
      "epoch 60; iter: 0; batch classifier loss: 0.108616; batch adversarial loss: 0.434613\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118608; batch adversarial loss: 0.464083\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071673; batch adversarial loss: 0.428264\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118825; batch adversarial loss: 0.426407\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140395; batch adversarial loss: 0.479946\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096808; batch adversarial loss: 0.386666\n",
      "epoch 66; iter: 0; batch classifier loss: 0.117662; batch adversarial loss: 0.458941\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123867; batch adversarial loss: 0.480899\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104982; batch adversarial loss: 0.442744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102957; batch adversarial loss: 0.552383\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065289; batch adversarial loss: 0.405520\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070514; batch adversarial loss: 0.388958\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092084; batch adversarial loss: 0.411423\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064264; batch adversarial loss: 0.462671\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093619; batch adversarial loss: 0.456618\n",
      "epoch 75; iter: 0; batch classifier loss: 0.089148; batch adversarial loss: 0.499915\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076136; batch adversarial loss: 0.465493\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063628; batch adversarial loss: 0.407727\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074366; batch adversarial loss: 0.517379\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092786; batch adversarial loss: 0.417736\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097550; batch adversarial loss: 0.382312\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102709; batch adversarial loss: 0.415611\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107413; batch adversarial loss: 0.389687\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087287; batch adversarial loss: 0.388569\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070274; batch adversarial loss: 0.442833\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073610; batch adversarial loss: 0.404301\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070768; batch adversarial loss: 0.533132\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080063; batch adversarial loss: 0.480625\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071294; batch adversarial loss: 0.540547\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046363; batch adversarial loss: 0.544851\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060492; batch adversarial loss: 0.472436\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070863; batch adversarial loss: 0.447737\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061702; batch adversarial loss: 0.468360\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058918; batch adversarial loss: 0.426925\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041514; batch adversarial loss: 0.414046\n",
      "epoch 95; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.428573\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058001; batch adversarial loss: 0.485914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048076; batch adversarial loss: 0.409160\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046338; batch adversarial loss: 0.577940\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075483; batch adversarial loss: 0.462170\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060048; batch adversarial loss: 0.427372\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062518; batch adversarial loss: 0.497277\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040217; batch adversarial loss: 0.455829\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043443; batch adversarial loss: 0.444538\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044842; batch adversarial loss: 0.401074\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029021; batch adversarial loss: 0.497175\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035391; batch adversarial loss: 0.411543\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.392979\n",
      "epoch 108; iter: 0; batch classifier loss: 0.038939; batch adversarial loss: 0.440150\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043948; batch adversarial loss: 0.450547\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057202; batch adversarial loss: 0.525581\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031165; batch adversarial loss: 0.458301\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052565; batch adversarial loss: 0.461753\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021662; batch adversarial loss: 0.486906\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065015; batch adversarial loss: 0.515982\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063301; batch adversarial loss: 0.513069\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040731; batch adversarial loss: 0.453997\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055223; batch adversarial loss: 0.549730\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048860; batch adversarial loss: 0.430853\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060936; batch adversarial loss: 0.440514\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023115; batch adversarial loss: 0.504115\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060055; batch adversarial loss: 0.469101\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043824; batch adversarial loss: 0.431265\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016209; batch adversarial loss: 0.401221\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055262; batch adversarial loss: 0.548200\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021668; batch adversarial loss: 0.425188\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022082; batch adversarial loss: 0.557997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055683; batch adversarial loss: 0.571362\n",
      "epoch 128; iter: 0; batch classifier loss: 0.008420; batch adversarial loss: 0.511208\n",
      "epoch 129; iter: 0; batch classifier loss: 0.039280; batch adversarial loss: 0.410818\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051670; batch adversarial loss: 0.464437\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038912; batch adversarial loss: 0.433507\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023578; batch adversarial loss: 0.528096\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044685; batch adversarial loss: 0.486492\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019416; batch adversarial loss: 0.430002\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046782; batch adversarial loss: 0.380877\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020255; batch adversarial loss: 0.526053\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019330; batch adversarial loss: 0.345997\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035969; batch adversarial loss: 0.397918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.015577; batch adversarial loss: 0.507786\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027122; batch adversarial loss: 0.447730\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015289; batch adversarial loss: 0.404881\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042413; batch adversarial loss: 0.426199\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011697; batch adversarial loss: 0.543121\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009291; batch adversarial loss: 0.465595\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027738; batch adversarial loss: 0.534207\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016020; batch adversarial loss: 0.460240\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052531; batch adversarial loss: 0.578956\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034757; batch adversarial loss: 0.456802\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037115; batch adversarial loss: 0.518191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028663; batch adversarial loss: 0.416953\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014213; batch adversarial loss: 0.519130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018201; batch adversarial loss: 0.537643\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009947; batch adversarial loss: 0.486825\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014510; batch adversarial loss: 0.464952\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018111; batch adversarial loss: 0.404622\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040361; batch adversarial loss: 0.488019\n",
      "epoch 157; iter: 0; batch classifier loss: 0.009033; batch adversarial loss: 0.487006\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021577; batch adversarial loss: 0.334546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008940; batch adversarial loss: 0.437693\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018808; batch adversarial loss: 0.444761\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013728; batch adversarial loss: 0.477856\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013434; batch adversarial loss: 0.482285\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019499; batch adversarial loss: 0.490185\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011096; batch adversarial loss: 0.450736\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048785; batch adversarial loss: 0.413508\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037538; batch adversarial loss: 0.431836\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027511; batch adversarial loss: 0.415814\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022403; batch adversarial loss: 0.520393\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028622; batch adversarial loss: 0.459630\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027972; batch adversarial loss: 0.563613\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031181; batch adversarial loss: 0.356702\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011145; batch adversarial loss: 0.372932\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036318; batch adversarial loss: 0.463700\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005877; batch adversarial loss: 0.516842\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039721; batch adversarial loss: 0.409488\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012906; batch adversarial loss: 0.447656\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018041; batch adversarial loss: 0.539373\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011261; batch adversarial loss: 0.522339\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012524; batch adversarial loss: 0.431249\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017544; batch adversarial loss: 0.397767\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021728; batch adversarial loss: 0.453435\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015005; batch adversarial loss: 0.411999\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021812; batch adversarial loss: 0.487926\n",
      "epoch 184; iter: 0; batch classifier loss: 0.002287; batch adversarial loss: 0.466418\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015991; batch adversarial loss: 0.429014\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029612; batch adversarial loss: 0.394565\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025938; batch adversarial loss: 0.373276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009702; batch adversarial loss: 0.401684\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013430; batch adversarial loss: 0.457981\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029231; batch adversarial loss: 0.405236\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008985; batch adversarial loss: 0.573554\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004663; batch adversarial loss: 0.418843\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015837; batch adversarial loss: 0.403178\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042169; batch adversarial loss: 0.408016\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011159; batch adversarial loss: 0.510347\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009616; batch adversarial loss: 0.409513\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019165; batch adversarial loss: 0.506547\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021707; batch adversarial loss: 0.428581\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.508815\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689093; batch adversarial loss: 0.924416\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553448; batch adversarial loss: 1.037134\n",
      "epoch 2; iter: 0; batch classifier loss: 0.868847; batch adversarial loss: 1.080225\n",
      "epoch 3; iter: 0; batch classifier loss: 0.944714; batch adversarial loss: 0.975333\n",
      "epoch 4; iter: 0; batch classifier loss: 1.081451; batch adversarial loss: 0.886963\n",
      "epoch 5; iter: 0; batch classifier loss: 0.825676; batch adversarial loss: 0.796987\n",
      "epoch 6; iter: 0; batch classifier loss: 0.972649; batch adversarial loss: 0.723458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.839694; batch adversarial loss: 0.658528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.959247; batch adversarial loss: 0.624790\n",
      "epoch 9; iter: 0; batch classifier loss: 0.787147; batch adversarial loss: 0.580525\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513635; batch adversarial loss: 0.529952\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387281; batch adversarial loss: 0.517817\n",
      "epoch 12; iter: 0; batch classifier loss: 0.245845; batch adversarial loss: 0.510639\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275555; batch adversarial loss: 0.484924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.263865; batch adversarial loss: 0.497846\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246407; batch adversarial loss: 0.444339\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235515; batch adversarial loss: 0.432287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.148997; batch adversarial loss: 0.443314\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184340; batch adversarial loss: 0.462697\n",
      "epoch 19; iter: 0; batch classifier loss: 0.204825; batch adversarial loss: 0.492262\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177445; batch adversarial loss: 0.430535\n",
      "epoch 21; iter: 0; batch classifier loss: 0.167472; batch adversarial loss: 0.519382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.156026; batch adversarial loss: 0.475558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.149633; batch adversarial loss: 0.540667\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202594; batch adversarial loss: 0.416203\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204260; batch adversarial loss: 0.418666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176756; batch adversarial loss: 0.470222\n",
      "epoch 27; iter: 0; batch classifier loss: 0.207870; batch adversarial loss: 0.479009\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200760; batch adversarial loss: 0.501278\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178708; batch adversarial loss: 0.475455\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239646; batch adversarial loss: 0.503495\n",
      "epoch 31; iter: 0; batch classifier loss: 0.171251; batch adversarial loss: 0.456208\n",
      "epoch 32; iter: 0; batch classifier loss: 0.221570; batch adversarial loss: 0.472822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187980; batch adversarial loss: 0.420547\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214590; batch adversarial loss: 0.396898\n",
      "epoch 35; iter: 0; batch classifier loss: 0.222555; batch adversarial loss: 0.467637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.198104; batch adversarial loss: 0.411289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132739; batch adversarial loss: 0.474957\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165055; batch adversarial loss: 0.459881\n",
      "epoch 39; iter: 0; batch classifier loss: 0.146389; batch adversarial loss: 0.495162\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155383; batch adversarial loss: 0.394389\n",
      "epoch 41; iter: 0; batch classifier loss: 0.146072; batch adversarial loss: 0.468001\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116933; batch adversarial loss: 0.458947\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094809; batch adversarial loss: 0.376079\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119602; batch adversarial loss: 0.539004\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122383; batch adversarial loss: 0.440081\n",
      "epoch 46; iter: 0; batch classifier loss: 0.111142; batch adversarial loss: 0.519129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095163; batch adversarial loss: 0.496274\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127348; batch adversarial loss: 0.434593\n",
      "epoch 49; iter: 0; batch classifier loss: 0.138605; batch adversarial loss: 0.408822\n",
      "epoch 50; iter: 0; batch classifier loss: 0.135186; batch adversarial loss: 0.375951\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094285; batch adversarial loss: 0.449478\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095729; batch adversarial loss: 0.447215\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106043; batch adversarial loss: 0.410391\n",
      "epoch 54; iter: 0; batch classifier loss: 0.109774; batch adversarial loss: 0.448588\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117546; batch adversarial loss: 0.392249\n",
      "epoch 56; iter: 0; batch classifier loss: 0.118736; batch adversarial loss: 0.420113\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074189; batch adversarial loss: 0.404497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094864; batch adversarial loss: 0.501994\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130039; batch adversarial loss: 0.424443\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114640; batch adversarial loss: 0.462205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083126; batch adversarial loss: 0.480241\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087208; batch adversarial loss: 0.452447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098427; batch adversarial loss: 0.456166\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063347; batch adversarial loss: 0.574995\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079370; batch adversarial loss: 0.364552\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078302; batch adversarial loss: 0.437797\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091243; batch adversarial loss: 0.400368\n",
      "epoch 68; iter: 0; batch classifier loss: 0.117320; batch adversarial loss: 0.466628\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083675; batch adversarial loss: 0.410572\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080313; batch adversarial loss: 0.448893\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105207; batch adversarial loss: 0.411834\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078790; batch adversarial loss: 0.444236\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102323; batch adversarial loss: 0.355937\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112565; batch adversarial loss: 0.456946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086111; batch adversarial loss: 0.480253\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080356; batch adversarial loss: 0.488091\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066690; batch adversarial loss: 0.405584\n",
      "epoch 78; iter: 0; batch classifier loss: 0.087195; batch adversarial loss: 0.328981\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054406; batch adversarial loss: 0.396891\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054413; batch adversarial loss: 0.380324\n",
      "epoch 81; iter: 0; batch classifier loss: 0.105773; batch adversarial loss: 0.464515\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050005; batch adversarial loss: 0.455524\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088028; batch adversarial loss: 0.554658\n",
      "epoch 84; iter: 0; batch classifier loss: 0.099809; batch adversarial loss: 0.424655\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085448; batch adversarial loss: 0.380196\n",
      "epoch 86; iter: 0; batch classifier loss: 0.095861; batch adversarial loss: 0.443701\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043997; batch adversarial loss: 0.487266\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081488; batch adversarial loss: 0.381876\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065194; batch adversarial loss: 0.434164\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050925; batch adversarial loss: 0.446073\n",
      "epoch 91; iter: 0; batch classifier loss: 0.048795; batch adversarial loss: 0.473608\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059823; batch adversarial loss: 0.421826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058305; batch adversarial loss: 0.464387\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080988; batch adversarial loss: 0.377321\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056855; batch adversarial loss: 0.482470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075854; batch adversarial loss: 0.417967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053129; batch adversarial loss: 0.542351\n",
      "epoch 98; iter: 0; batch classifier loss: 0.017738; batch adversarial loss: 0.456031\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086191; batch adversarial loss: 0.505767\n",
      "epoch 100; iter: 0; batch classifier loss: 0.026485; batch adversarial loss: 0.477355\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049747; batch adversarial loss: 0.404787\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038055; batch adversarial loss: 0.440169\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041258; batch adversarial loss: 0.400119\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066254; batch adversarial loss: 0.329330\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063290; batch adversarial loss: 0.472927\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032598; batch adversarial loss: 0.379609\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069306; batch adversarial loss: 0.454207\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048494; batch adversarial loss: 0.462837\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056644; batch adversarial loss: 0.419668\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045007; batch adversarial loss: 0.440678\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062421; batch adversarial loss: 0.416463\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039496; batch adversarial loss: 0.541112\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048280; batch adversarial loss: 0.406766\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056416; batch adversarial loss: 0.378109\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049664; batch adversarial loss: 0.506172\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050379; batch adversarial loss: 0.400660\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035606; batch adversarial loss: 0.399924\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037271; batch adversarial loss: 0.464859\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039063; batch adversarial loss: 0.327220\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047582; batch adversarial loss: 0.436726\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029725; batch adversarial loss: 0.449485\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031957; batch adversarial loss: 0.415895\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035185; batch adversarial loss: 0.632358\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050003; batch adversarial loss: 0.463962\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029317; batch adversarial loss: 0.390978\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.443147\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060634; batch adversarial loss: 0.525421\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014152; batch adversarial loss: 0.478156\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024624; batch adversarial loss: 0.626129\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021459; batch adversarial loss: 0.370937\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059758; batch adversarial loss: 0.541989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016172; batch adversarial loss: 0.439450\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029105; batch adversarial loss: 0.472675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.014830; batch adversarial loss: 0.489620\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031665; batch adversarial loss: 0.439616\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036610; batch adversarial loss: 0.361140\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041294; batch adversarial loss: 0.425156\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051307; batch adversarial loss: 0.414433\n",
      "epoch 139; iter: 0; batch classifier loss: 0.015761; batch adversarial loss: 0.622235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035292; batch adversarial loss: 0.421209\n",
      "epoch 141; iter: 0; batch classifier loss: 0.011297; batch adversarial loss: 0.419916\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027779; batch adversarial loss: 0.427912\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009094; batch adversarial loss: 0.448977\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027675; batch adversarial loss: 0.561214\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024968; batch adversarial loss: 0.495625\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042148; batch adversarial loss: 0.403403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018280; batch adversarial loss: 0.415560\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035561; batch adversarial loss: 0.435240\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015841; batch adversarial loss: 0.448654\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.526570\n",
      "epoch 151; iter: 0; batch classifier loss: 0.047009; batch adversarial loss: 0.510388\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031118; batch adversarial loss: 0.406152\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056252; batch adversarial loss: 0.389225\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019283; batch adversarial loss: 0.397117\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028773; batch adversarial loss: 0.408006\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015859; batch adversarial loss: 0.491901\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.519813\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025282; batch adversarial loss: 0.401021\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.367144\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033697; batch adversarial loss: 0.466905\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037882; batch adversarial loss: 0.479681\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030504; batch adversarial loss: 0.415785\n",
      "epoch 163; iter: 0; batch classifier loss: 0.002810; batch adversarial loss: 0.458685\n",
      "epoch 164; iter: 0; batch classifier loss: 0.051072; batch adversarial loss: 0.476297\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013785; batch adversarial loss: 0.393478\n",
      "epoch 166; iter: 0; batch classifier loss: 0.006787; batch adversarial loss: 0.402400\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011532; batch adversarial loss: 0.403504\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004100; batch adversarial loss: 0.518273\n",
      "epoch 169; iter: 0; batch classifier loss: 0.005643; batch adversarial loss: 0.383917\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013047; batch adversarial loss: 0.435771\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008138; batch adversarial loss: 0.475688\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009362; batch adversarial loss: 0.426094\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013188; batch adversarial loss: 0.413064\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008154; batch adversarial loss: 0.384199\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006641; batch adversarial loss: 0.452509\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032062; batch adversarial loss: 0.371933\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006693; batch adversarial loss: 0.475593\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008060; batch adversarial loss: 0.426410\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036306; batch adversarial loss: 0.379028\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022391; batch adversarial loss: 0.412436\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016009; batch adversarial loss: 0.430965\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027494; batch adversarial loss: 0.478206\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009672; batch adversarial loss: 0.429593\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011230; batch adversarial loss: 0.491185\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025279; batch adversarial loss: 0.460376\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012283; batch adversarial loss: 0.491127\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008555; batch adversarial loss: 0.470406\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033356; batch adversarial loss: 0.519858\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034165; batch adversarial loss: 0.429452\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007737; batch adversarial loss: 0.432976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007825; batch adversarial loss: 0.455386\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023418; batch adversarial loss: 0.407082\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020667; batch adversarial loss: 0.455478\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007408; batch adversarial loss: 0.440234\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024925; batch adversarial loss: 0.407819\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.478765\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018624; batch adversarial loss: 0.406887\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008190; batch adversarial loss: 0.414335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009560; batch adversarial loss: 0.494382\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700174; batch adversarial loss: 0.673690\n",
      "epoch 1; iter: 0; batch classifier loss: 0.556735; batch adversarial loss: 0.655548\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401927; batch adversarial loss: 0.622620\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537317; batch adversarial loss: 0.581110\n",
      "epoch 4; iter: 0; batch classifier loss: 0.514295; batch adversarial loss: 0.602564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563207; batch adversarial loss: 0.594031\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532687; batch adversarial loss: 0.577809\n",
      "epoch 7; iter: 0; batch classifier loss: 0.398209; batch adversarial loss: 0.550489\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402720; batch adversarial loss: 0.553212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509957; batch adversarial loss: 0.556436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388468; batch adversarial loss: 0.546785\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415440; batch adversarial loss: 0.554097\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418755; batch adversarial loss: 0.509637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442444; batch adversarial loss: 0.484973\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315404; batch adversarial loss: 0.506244\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363236; batch adversarial loss: 0.479421\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404313; batch adversarial loss: 0.518459\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347186; batch adversarial loss: 0.481327\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336855; batch adversarial loss: 0.501926\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287523; batch adversarial loss: 0.439246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.262754; batch adversarial loss: 0.493674\n",
      "epoch 21; iter: 0; batch classifier loss: 0.277340; batch adversarial loss: 0.448677\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243204; batch adversarial loss: 0.450419\n",
      "epoch 23; iter: 0; batch classifier loss: 0.249237; batch adversarial loss: 0.462034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346776; batch adversarial loss: 0.473452\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201727; batch adversarial loss: 0.497185\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223283; batch adversarial loss: 0.516352\n",
      "epoch 27; iter: 0; batch classifier loss: 0.267258; batch adversarial loss: 0.406104\n",
      "epoch 28; iter: 0; batch classifier loss: 0.244668; batch adversarial loss: 0.445341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.223863; batch adversarial loss: 0.505240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216453; batch adversarial loss: 0.459434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.190991; batch adversarial loss: 0.458005\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242512; batch adversarial loss: 0.431123\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239747; batch adversarial loss: 0.399140\n",
      "epoch 34; iter: 0; batch classifier loss: 0.178406; batch adversarial loss: 0.507422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257644; batch adversarial loss: 0.492754\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263546; batch adversarial loss: 0.473966\n",
      "epoch 37; iter: 0; batch classifier loss: 0.191051; batch adversarial loss: 0.462611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286310; batch adversarial loss: 0.447706\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167832; batch adversarial loss: 0.451648\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261685; batch adversarial loss: 0.400120\n",
      "epoch 41; iter: 0; batch classifier loss: 0.152492; batch adversarial loss: 0.463627\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184066; batch adversarial loss: 0.480654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.202110; batch adversarial loss: 0.389982\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220835; batch adversarial loss: 0.419068\n",
      "epoch 45; iter: 0; batch classifier loss: 0.184810; batch adversarial loss: 0.397712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166380; batch adversarial loss: 0.461899\n",
      "epoch 47; iter: 0; batch classifier loss: 0.243956; batch adversarial loss: 0.480894\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157823; batch adversarial loss: 0.468941\n",
      "epoch 49; iter: 0; batch classifier loss: 0.248483; batch adversarial loss: 0.478081\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157678; batch adversarial loss: 0.486746\n",
      "epoch 51; iter: 0; batch classifier loss: 0.242718; batch adversarial loss: 0.397962\n",
      "epoch 52; iter: 0; batch classifier loss: 0.213552; batch adversarial loss: 0.530732\n",
      "epoch 53; iter: 0; batch classifier loss: 0.188067; batch adversarial loss: 0.397021\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171758; batch adversarial loss: 0.546225\n",
      "epoch 55; iter: 0; batch classifier loss: 0.247669; batch adversarial loss: 0.371356\n",
      "epoch 56; iter: 0; batch classifier loss: 0.165274; batch adversarial loss: 0.282388\n",
      "epoch 57; iter: 0; batch classifier loss: 0.175169; batch adversarial loss: 0.458770\n",
      "epoch 58; iter: 0; batch classifier loss: 0.199558; batch adversarial loss: 0.525270\n",
      "epoch 59; iter: 0; batch classifier loss: 0.205819; batch adversarial loss: 0.449752\n",
      "epoch 60; iter: 0; batch classifier loss: 0.223469; batch adversarial loss: 0.400975\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163304; batch adversarial loss: 0.498984\n",
      "epoch 62; iter: 0; batch classifier loss: 0.186912; batch adversarial loss: 0.385593\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183754; batch adversarial loss: 0.433484\n",
      "epoch 64; iter: 0; batch classifier loss: 0.098253; batch adversarial loss: 0.552700\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218066; batch adversarial loss: 0.430257\n",
      "epoch 66; iter: 0; batch classifier loss: 0.166807; batch adversarial loss: 0.485787\n",
      "epoch 67; iter: 0; batch classifier loss: 0.175524; batch adversarial loss: 0.443442\n",
      "epoch 68; iter: 0; batch classifier loss: 0.141715; batch adversarial loss: 0.450744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141039; batch adversarial loss: 0.433865\n",
      "epoch 70; iter: 0; batch classifier loss: 0.133715; batch adversarial loss: 0.395417\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133696; batch adversarial loss: 0.432859\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150636; batch adversarial loss: 0.377628\n",
      "epoch 73; iter: 0; batch classifier loss: 0.140127; batch adversarial loss: 0.448320\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091406; batch adversarial loss: 0.417123\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099116; batch adversarial loss: 0.369124\n",
      "epoch 76; iter: 0; batch classifier loss: 0.128660; batch adversarial loss: 0.424696\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147446; batch adversarial loss: 0.514534\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058619; batch adversarial loss: 0.456948\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084355; batch adversarial loss: 0.376701\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099690; batch adversarial loss: 0.360976\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115713; batch adversarial loss: 0.493408\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099384; batch adversarial loss: 0.501243\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074117; batch adversarial loss: 0.373265\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082224; batch adversarial loss: 0.466910\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092096; batch adversarial loss: 0.451366\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040567; batch adversarial loss: 0.409217\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078564; batch adversarial loss: 0.410790\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045252; batch adversarial loss: 0.416740\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058783; batch adversarial loss: 0.536138\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075431; batch adversarial loss: 0.477490\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059381; batch adversarial loss: 0.418653\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052506; batch adversarial loss: 0.449165\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058856; batch adversarial loss: 0.345703\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053350; batch adversarial loss: 0.385748\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048895; batch adversarial loss: 0.418909\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048881; batch adversarial loss: 0.460030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054442; batch adversarial loss: 0.447546\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080480; batch adversarial loss: 0.450270\n",
      "epoch 99; iter: 0; batch classifier loss: 0.015494; batch adversarial loss: 0.501418\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036504; batch adversarial loss: 0.350237\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056500; batch adversarial loss: 0.404996\n",
      "epoch 102; iter: 0; batch classifier loss: 0.022978; batch adversarial loss: 0.391742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041706; batch adversarial loss: 0.404667\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.557733\n",
      "epoch 105; iter: 0; batch classifier loss: 0.020475; batch adversarial loss: 0.505698\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052919; batch adversarial loss: 0.419459\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028155; batch adversarial loss: 0.397159\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032095; batch adversarial loss: 0.431914\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033373; batch adversarial loss: 0.404026\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.381565\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022032; batch adversarial loss: 0.452626\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021031; batch adversarial loss: 0.388629\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031771; batch adversarial loss: 0.409152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.449624\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034580; batch adversarial loss: 0.415034\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036584; batch adversarial loss: 0.456975\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047059; batch adversarial loss: 0.454035\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021554; batch adversarial loss: 0.545738\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025449; batch adversarial loss: 0.457527\n",
      "epoch 120; iter: 0; batch classifier loss: 0.008385; batch adversarial loss: 0.410965\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.438401\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023125; batch adversarial loss: 0.519485\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039691; batch adversarial loss: 0.465767\n",
      "epoch 124; iter: 0; batch classifier loss: 0.007318; batch adversarial loss: 0.470442\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016257; batch adversarial loss: 0.414736\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052610; batch adversarial loss: 0.458610\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023168; batch adversarial loss: 0.501161\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014023; batch adversarial loss: 0.372808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.051403; batch adversarial loss: 0.383412\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043751; batch adversarial loss: 0.405947\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019857; batch adversarial loss: 0.406940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025628; batch adversarial loss: 0.459719\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018873; batch adversarial loss: 0.376451\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041577; batch adversarial loss: 0.417777\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032636; batch adversarial loss: 0.471604\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012036; batch adversarial loss: 0.563119\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.560231\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014136; batch adversarial loss: 0.460622\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021593; batch adversarial loss: 0.392547\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047883; batch adversarial loss: 0.343058\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022645; batch adversarial loss: 0.402338\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015833; batch adversarial loss: 0.459047\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027180; batch adversarial loss: 0.492778\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039147; batch adversarial loss: 0.452308\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018168; batch adversarial loss: 0.405015\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034724; batch adversarial loss: 0.403200\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018792; batch adversarial loss: 0.517682\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018929; batch adversarial loss: 0.513174\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026263; batch adversarial loss: 0.432836\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028548; batch adversarial loss: 0.432047\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030681; batch adversarial loss: 0.400154\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021842; batch adversarial loss: 0.528600\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020057; batch adversarial loss: 0.318573\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016752; batch adversarial loss: 0.413557\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026920; batch adversarial loss: 0.357985\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022588; batch adversarial loss: 0.400741\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028034; batch adversarial loss: 0.490925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016536; batch adversarial loss: 0.479421\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011032; batch adversarial loss: 0.465573\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.477273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008257; batch adversarial loss: 0.375740\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027233; batch adversarial loss: 0.436681\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012564; batch adversarial loss: 0.422680\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017443; batch adversarial loss: 0.437150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010728; batch adversarial loss: 0.374181\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040436; batch adversarial loss: 0.459241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013965; batch adversarial loss: 0.540030\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022400; batch adversarial loss: 0.350022\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025377; batch adversarial loss: 0.470221\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022838; batch adversarial loss: 0.352275\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007136; batch adversarial loss: 0.399965\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009244; batch adversarial loss: 0.463428\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014692; batch adversarial loss: 0.426502\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019949; batch adversarial loss: 0.479944\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011198; batch adversarial loss: 0.442107\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019328; batch adversarial loss: 0.421145\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023326; batch adversarial loss: 0.391584\n",
      "epoch 178; iter: 0; batch classifier loss: 0.042828; batch adversarial loss: 0.453171\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023191; batch adversarial loss: 0.474805\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036144; batch adversarial loss: 0.536497\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017260; batch adversarial loss: 0.403414\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026805; batch adversarial loss: 0.398853\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022935; batch adversarial loss: 0.377283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012053; batch adversarial loss: 0.430475\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009496; batch adversarial loss: 0.455640\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039842; batch adversarial loss: 0.464554\n",
      "epoch 187; iter: 0; batch classifier loss: 0.002258; batch adversarial loss: 0.492600\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007841; batch adversarial loss: 0.522816\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021874; batch adversarial loss: 0.470169\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013704; batch adversarial loss: 0.396132\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005559; batch adversarial loss: 0.436762\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015049; batch adversarial loss: 0.467656\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006041; batch adversarial loss: 0.534154\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022869; batch adversarial loss: 0.362733\n",
      "epoch 195; iter: 0; batch classifier loss: 0.003894; batch adversarial loss: 0.401924\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004455; batch adversarial loss: 0.477394\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027147; batch adversarial loss: 0.441248\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.345524\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009934; batch adversarial loss: 0.362163\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699657; batch adversarial loss: 0.732741\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477978; batch adversarial loss: 0.691153\n",
      "epoch 2; iter: 0; batch classifier loss: 0.401775; batch adversarial loss: 0.656117\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365933; batch adversarial loss: 0.625198\n",
      "epoch 4; iter: 0; batch classifier loss: 0.391178; batch adversarial loss: 0.551571\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334795; batch adversarial loss: 0.551994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.279981; batch adversarial loss: 0.530963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276083; batch adversarial loss: 0.527414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266726; batch adversarial loss: 0.541152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329748; batch adversarial loss: 0.480931\n",
      "epoch 10; iter: 0; batch classifier loss: 0.205900; batch adversarial loss: 0.513432\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224866; batch adversarial loss: 0.433312\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205083; batch adversarial loss: 0.452264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.220285; batch adversarial loss: 0.432435\n",
      "epoch 14; iter: 0; batch classifier loss: 0.178023; batch adversarial loss: 0.505531\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206304; batch adversarial loss: 0.443688\n",
      "epoch 16; iter: 0; batch classifier loss: 0.175968; batch adversarial loss: 0.429548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256320; batch adversarial loss: 0.456833\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164071; batch adversarial loss: 0.476949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.141104; batch adversarial loss: 0.427711\n",
      "epoch 20; iter: 0; batch classifier loss: 0.133308; batch adversarial loss: 0.436306\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168263; batch adversarial loss: 0.434871\n",
      "epoch 22; iter: 0; batch classifier loss: 0.126926; batch adversarial loss: 0.349049\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175994; batch adversarial loss: 0.397478\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185838; batch adversarial loss: 0.420526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.136249; batch adversarial loss: 0.444882\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141523; batch adversarial loss: 0.377572\n",
      "epoch 27; iter: 0; batch classifier loss: 0.135882; batch adversarial loss: 0.405699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221739; batch adversarial loss: 0.497948\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180523; batch adversarial loss: 0.543802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.157454; batch adversarial loss: 0.389159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.111880; batch adversarial loss: 0.446696\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111866; batch adversarial loss: 0.446702\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105530; batch adversarial loss: 0.373768\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186132; batch adversarial loss: 0.469227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.104982; batch adversarial loss: 0.345935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.138593; batch adversarial loss: 0.415709\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108895; batch adversarial loss: 0.397743\n",
      "epoch 38; iter: 0; batch classifier loss: 0.102259; batch adversarial loss: 0.364958\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095596; batch adversarial loss: 0.339882\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135101; batch adversarial loss: 0.382007\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112303; batch adversarial loss: 0.433681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130774; batch adversarial loss: 0.404237\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161082; batch adversarial loss: 0.420019\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107471; batch adversarial loss: 0.344513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098069; batch adversarial loss: 0.403810\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122307; batch adversarial loss: 0.404580\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113953; batch adversarial loss: 0.437927\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115550; batch adversarial loss: 0.449176\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110890; batch adversarial loss: 0.479020\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091908; batch adversarial loss: 0.346479\n",
      "epoch 51; iter: 0; batch classifier loss: 0.127932; batch adversarial loss: 0.477612\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093154; batch adversarial loss: 0.426370\n",
      "epoch 53; iter: 0; batch classifier loss: 0.112937; batch adversarial loss: 0.407395\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110306; batch adversarial loss: 0.444884\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122676; batch adversarial loss: 0.379599\n",
      "epoch 56; iter: 0; batch classifier loss: 0.079464; batch adversarial loss: 0.473594\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069075; batch adversarial loss: 0.382936\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095499; batch adversarial loss: 0.418049\n",
      "epoch 59; iter: 0; batch classifier loss: 0.118722; batch adversarial loss: 0.366163\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065498; batch adversarial loss: 0.438801\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158254; batch adversarial loss: 0.330979\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063975; batch adversarial loss: 0.368932\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061771; batch adversarial loss: 0.429840\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064316; batch adversarial loss: 0.376539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.080722; batch adversarial loss: 0.382050\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072443; batch adversarial loss: 0.431059\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101457; batch adversarial loss: 0.521380\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111963; batch adversarial loss: 0.383082\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061364; batch adversarial loss: 0.383533\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104109; batch adversarial loss: 0.430064\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095777; batch adversarial loss: 0.405400\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057032; batch adversarial loss: 0.406376\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.490240\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090995; batch adversarial loss: 0.394242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096623; batch adversarial loss: 0.451569\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069022; batch adversarial loss: 0.454654\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065808; batch adversarial loss: 0.367125\n",
      "epoch 78; iter: 0; batch classifier loss: 0.036857; batch adversarial loss: 0.369394\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054132; batch adversarial loss: 0.388965\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068529; batch adversarial loss: 0.421310\n",
      "epoch 81; iter: 0; batch classifier loss: 0.094843; batch adversarial loss: 0.370222\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059549; batch adversarial loss: 0.361440\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049454; batch adversarial loss: 0.363111\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072566; batch adversarial loss: 0.369322\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070456; batch adversarial loss: 0.501322\n",
      "epoch 86; iter: 0; batch classifier loss: 0.088425; batch adversarial loss: 0.447794\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062390; batch adversarial loss: 0.442235\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080164; batch adversarial loss: 0.446375\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078034; batch adversarial loss: 0.348397\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052383; batch adversarial loss: 0.493222\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062381; batch adversarial loss: 0.519211\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064816; batch adversarial loss: 0.444501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075540; batch adversarial loss: 0.493573\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094214; batch adversarial loss: 0.365641\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081077; batch adversarial loss: 0.422787\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055459; batch adversarial loss: 0.379241\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063522; batch adversarial loss: 0.477872\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068053; batch adversarial loss: 0.385023\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078995; batch adversarial loss: 0.467379\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090731; batch adversarial loss: 0.448192\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102312; batch adversarial loss: 0.469623\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052750; batch adversarial loss: 0.454200\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039210; batch adversarial loss: 0.373994\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083841; batch adversarial loss: 0.486199\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087710; batch adversarial loss: 0.423308\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043742; batch adversarial loss: 0.366269\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045665; batch adversarial loss: 0.527037\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065134; batch adversarial loss: 0.467516\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064402; batch adversarial loss: 0.346937\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080391; batch adversarial loss: 0.443002\n",
      "epoch 111; iter: 0; batch classifier loss: 0.071470; batch adversarial loss: 0.457818\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042053; batch adversarial loss: 0.425244\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052733; batch adversarial loss: 0.450882\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048561; batch adversarial loss: 0.487054\n",
      "epoch 115; iter: 0; batch classifier loss: 0.092082; batch adversarial loss: 0.501563\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061603; batch adversarial loss: 0.436039\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042002; batch adversarial loss: 0.433590\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031402; batch adversarial loss: 0.374527\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035063; batch adversarial loss: 0.401209\n",
      "epoch 120; iter: 0; batch classifier loss: 0.078572; batch adversarial loss: 0.557760\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050292; batch adversarial loss: 0.414068\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056906; batch adversarial loss: 0.421035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.082646; batch adversarial loss: 0.439896\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054261; batch adversarial loss: 0.419129\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047378; batch adversarial loss: 0.437063\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052333; batch adversarial loss: 0.389882\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044656; batch adversarial loss: 0.463468\n",
      "epoch 128; iter: 0; batch classifier loss: 0.073680; batch adversarial loss: 0.503576\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056044; batch adversarial loss: 0.434236\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026413; batch adversarial loss: 0.489900\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041007; batch adversarial loss: 0.448198\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036701; batch adversarial loss: 0.436595\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036365; batch adversarial loss: 0.337939\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038310; batch adversarial loss: 0.476057\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058920; batch adversarial loss: 0.368417\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028985; batch adversarial loss: 0.509617\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026325; batch adversarial loss: 0.379331\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072642; batch adversarial loss: 0.444696\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051099; batch adversarial loss: 0.483364\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038089; batch adversarial loss: 0.408145\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024938; batch adversarial loss: 0.403985\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042452; batch adversarial loss: 0.388377\n",
      "epoch 143; iter: 0; batch classifier loss: 0.045411; batch adversarial loss: 0.429010\n",
      "epoch 144; iter: 0; batch classifier loss: 0.023608; batch adversarial loss: 0.458131\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020203; batch adversarial loss: 0.497598\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040235; batch adversarial loss: 0.556254\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027137; batch adversarial loss: 0.449186\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037998; batch adversarial loss: 0.452571\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054823; batch adversarial loss: 0.564565\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036172; batch adversarial loss: 0.395415\n",
      "epoch 151; iter: 0; batch classifier loss: 0.085441; batch adversarial loss: 0.518674\n",
      "epoch 152; iter: 0; batch classifier loss: 0.076963; batch adversarial loss: 0.509477\n",
      "epoch 153; iter: 0; batch classifier loss: 0.074025; batch adversarial loss: 0.620641\n",
      "epoch 154; iter: 0; batch classifier loss: 0.073296; batch adversarial loss: 0.518737\n",
      "epoch 155; iter: 0; batch classifier loss: 0.079713; batch adversarial loss: 0.515772\n",
      "epoch 156; iter: 0; batch classifier loss: 0.131630; batch adversarial loss: 0.549375\n",
      "epoch 157; iter: 0; batch classifier loss: 0.126608; batch adversarial loss: 0.564261\n",
      "epoch 158; iter: 0; batch classifier loss: 0.105717; batch adversarial loss: 0.536763\n",
      "epoch 159; iter: 0; batch classifier loss: 0.110854; batch adversarial loss: 0.624225\n",
      "epoch 160; iter: 0; batch classifier loss: 0.147928; batch adversarial loss: 0.576938\n",
      "epoch 161; iter: 0; batch classifier loss: 0.214141; batch adversarial loss: 0.816145\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047045; batch adversarial loss: 0.539952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.167119; batch adversarial loss: 0.660736\n",
      "epoch 164; iter: 0; batch classifier loss: 0.169900; batch adversarial loss: 0.702097\n",
      "epoch 165; iter: 0; batch classifier loss: 0.155205; batch adversarial loss: 0.616321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.106349; batch adversarial loss: 0.570903\n",
      "epoch 167; iter: 0; batch classifier loss: 0.078979; batch adversarial loss: 0.454134\n",
      "epoch 168; iter: 0; batch classifier loss: 0.123927; batch adversarial loss: 0.574414\n",
      "epoch 169; iter: 0; batch classifier loss: 0.119799; batch adversarial loss: 0.527354\n",
      "epoch 170; iter: 0; batch classifier loss: 0.166500; batch adversarial loss: 0.712000\n",
      "epoch 171; iter: 0; batch classifier loss: 0.098450; batch adversarial loss: 0.526976\n",
      "epoch 172; iter: 0; batch classifier loss: 0.126969; batch adversarial loss: 0.576239\n",
      "epoch 173; iter: 0; batch classifier loss: 0.210984; batch adversarial loss: 0.693168\n",
      "epoch 174; iter: 0; batch classifier loss: 0.138954; batch adversarial loss: 0.587989\n",
      "epoch 175; iter: 0; batch classifier loss: 0.172106; batch adversarial loss: 0.722992\n",
      "epoch 176; iter: 0; batch classifier loss: 0.215246; batch adversarial loss: 0.669313\n",
      "epoch 177; iter: 0; batch classifier loss: 0.105671; batch adversarial loss: 0.531261\n",
      "epoch 178; iter: 0; batch classifier loss: 0.117742; batch adversarial loss: 0.482152\n",
      "epoch 179; iter: 0; batch classifier loss: 0.136794; batch adversarial loss: 0.579694\n",
      "epoch 180; iter: 0; batch classifier loss: 0.172320; batch adversarial loss: 0.566621\n",
      "epoch 181; iter: 0; batch classifier loss: 0.097984; batch adversarial loss: 0.525920\n",
      "epoch 182; iter: 0; batch classifier loss: 0.189824; batch adversarial loss: 0.632569\n",
      "epoch 183; iter: 0; batch classifier loss: 0.130175; batch adversarial loss: 0.549531\n",
      "epoch 184; iter: 0; batch classifier loss: 0.116484; batch adversarial loss: 0.542198\n",
      "epoch 185; iter: 0; batch classifier loss: 0.169032; batch adversarial loss: 0.576409\n",
      "epoch 186; iter: 0; batch classifier loss: 0.141917; batch adversarial loss: 0.468205\n",
      "epoch 187; iter: 0; batch classifier loss: 0.123008; batch adversarial loss: 0.563219\n",
      "epoch 188; iter: 0; batch classifier loss: 0.123763; batch adversarial loss: 0.544756\n",
      "epoch 189; iter: 0; batch classifier loss: 0.153319; batch adversarial loss: 0.484842\n",
      "epoch 190; iter: 0; batch classifier loss: 0.117361; batch adversarial loss: 0.505346\n",
      "epoch 191; iter: 0; batch classifier loss: 0.161681; batch adversarial loss: 0.524372\n",
      "epoch 192; iter: 0; batch classifier loss: 0.168699; batch adversarial loss: 0.499912\n",
      "epoch 193; iter: 0; batch classifier loss: 0.167499; batch adversarial loss: 0.659672\n",
      "epoch 194; iter: 0; batch classifier loss: 0.186974; batch adversarial loss: 0.617382\n",
      "epoch 195; iter: 0; batch classifier loss: 0.108971; batch adversarial loss: 0.555003\n",
      "epoch 196; iter: 0; batch classifier loss: 0.107343; batch adversarial loss: 0.514481\n",
      "epoch 197; iter: 0; batch classifier loss: 0.132896; batch adversarial loss: 0.474013\n",
      "epoch 198; iter: 0; batch classifier loss: 0.080664; batch adversarial loss: 0.429003\n",
      "epoch 199; iter: 0; batch classifier loss: 0.100663; batch adversarial loss: 0.565889\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701704; batch adversarial loss: 0.629946\n",
      "epoch 1; iter: 0; batch classifier loss: 0.342850; batch adversarial loss: 0.627010\n",
      "epoch 2; iter: 0; batch classifier loss: 0.501869; batch adversarial loss: 0.615688\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404677; batch adversarial loss: 0.596460\n",
      "epoch 4; iter: 0; batch classifier loss: 0.423194; batch adversarial loss: 0.587120\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559920; batch adversarial loss: 0.605007\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569516; batch adversarial loss: 0.555326\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618146; batch adversarial loss: 0.573863\n",
      "epoch 8; iter: 0; batch classifier loss: 0.637610; batch adversarial loss: 0.553841\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383974; batch adversarial loss: 0.551216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394467; batch adversarial loss: 0.489893\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397699; batch adversarial loss: 0.501941\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370206; batch adversarial loss: 0.537217\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374956; batch adversarial loss: 0.536420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310515; batch adversarial loss: 0.532842\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342250; batch adversarial loss: 0.437279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.424607; batch adversarial loss: 0.440959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367369; batch adversarial loss: 0.436710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.416015; batch adversarial loss: 0.458933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.299438; batch adversarial loss: 0.488250\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321150; batch adversarial loss: 0.496982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283689; batch adversarial loss: 0.481878\n",
      "epoch 22; iter: 0; batch classifier loss: 0.327515; batch adversarial loss: 0.523518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359571; batch adversarial loss: 0.500477\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341477; batch adversarial loss: 0.438147\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316175; batch adversarial loss: 0.431110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260845; batch adversarial loss: 0.535747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309941; batch adversarial loss: 0.399770\n",
      "epoch 28; iter: 0; batch classifier loss: 0.259779; batch adversarial loss: 0.450877\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210013; batch adversarial loss: 0.454880\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269517; batch adversarial loss: 0.453413\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266592; batch adversarial loss: 0.535302\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266601; batch adversarial loss: 0.487923\n",
      "epoch 33; iter: 0; batch classifier loss: 0.270976; batch adversarial loss: 0.432928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232439; batch adversarial loss: 0.526063\n",
      "epoch 35; iter: 0; batch classifier loss: 0.240070; batch adversarial loss: 0.403150\n",
      "epoch 36; iter: 0; batch classifier loss: 0.281719; batch adversarial loss: 0.457789\n",
      "epoch 37; iter: 0; batch classifier loss: 0.260944; batch adversarial loss: 0.437451\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207705; batch adversarial loss: 0.535232\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241940; batch adversarial loss: 0.487617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.237145; batch adversarial loss: 0.517990\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215920; batch adversarial loss: 0.476290\n",
      "epoch 42; iter: 0; batch classifier loss: 0.237384; batch adversarial loss: 0.446352\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400517; batch adversarial loss: 0.401106\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245973; batch adversarial loss: 0.483373\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203875; batch adversarial loss: 0.387542\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113992; batch adversarial loss: 0.470489\n",
      "epoch 47; iter: 0; batch classifier loss: 0.136135; batch adversarial loss: 0.392910\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080588; batch adversarial loss: 0.403780\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126969; batch adversarial loss: 0.416000\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136160; batch adversarial loss: 0.398055\n",
      "epoch 51; iter: 0; batch classifier loss: 0.183733; batch adversarial loss: 0.568457\n",
      "epoch 52; iter: 0; batch classifier loss: 0.265041; batch adversarial loss: 0.450099\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151084; batch adversarial loss: 0.542165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185286; batch adversarial loss: 0.419008\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221765; batch adversarial loss: 0.409415\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176072; batch adversarial loss: 0.385496\n",
      "epoch 57; iter: 0; batch classifier loss: 0.251252; batch adversarial loss: 0.383635\n",
      "epoch 58; iter: 0; batch classifier loss: 0.202005; batch adversarial loss: 0.394646\n",
      "epoch 59; iter: 0; batch classifier loss: 0.221307; batch adversarial loss: 0.482422\n",
      "epoch 60; iter: 0; batch classifier loss: 0.193264; batch adversarial loss: 0.445503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.210787; batch adversarial loss: 0.384081\n",
      "epoch 62; iter: 0; batch classifier loss: 0.170666; batch adversarial loss: 0.421056\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183304; batch adversarial loss: 0.408492\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134155; batch adversarial loss: 0.421543\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100399; batch adversarial loss: 0.456930\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083144; batch adversarial loss: 0.443582\n",
      "epoch 67; iter: 0; batch classifier loss: 0.047680; batch adversarial loss: 0.365770\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134272; batch adversarial loss: 0.377710\n",
      "epoch 69; iter: 0; batch classifier loss: 0.195666; batch adversarial loss: 0.341957\n",
      "epoch 70; iter: 0; batch classifier loss: 0.247728; batch adversarial loss: 0.455786\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206369; batch adversarial loss: 0.408031\n",
      "epoch 72; iter: 0; batch classifier loss: 0.199699; batch adversarial loss: 0.484992\n",
      "epoch 73; iter: 0; batch classifier loss: 0.152008; batch adversarial loss: 0.436496\n",
      "epoch 74; iter: 0; batch classifier loss: 0.251410; batch adversarial loss: 0.470712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134109; batch adversarial loss: 0.471253\n",
      "epoch 76; iter: 0; batch classifier loss: 0.268609; batch adversarial loss: 0.335092\n",
      "epoch 77; iter: 0; batch classifier loss: 0.244828; batch adversarial loss: 0.471625\n",
      "epoch 78; iter: 0; batch classifier loss: 0.166995; batch adversarial loss: 0.410311\n",
      "epoch 79; iter: 0; batch classifier loss: 0.230013; batch adversarial loss: 0.471787\n",
      "epoch 80; iter: 0; batch classifier loss: 0.249791; batch adversarial loss: 0.371469\n",
      "epoch 81; iter: 0; batch classifier loss: 0.221115; batch adversarial loss: 0.422104\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189657; batch adversarial loss: 0.446256\n",
      "epoch 83; iter: 0; batch classifier loss: 0.257189; batch adversarial loss: 0.483257\n",
      "epoch 84; iter: 0; batch classifier loss: 0.205883; batch adversarial loss: 0.483735\n",
      "epoch 85; iter: 0; batch classifier loss: 0.180804; batch adversarial loss: 0.483633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084296; batch adversarial loss: 0.382942\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051575; batch adversarial loss: 0.472170\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140980; batch adversarial loss: 0.406904\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117069; batch adversarial loss: 0.468255\n",
      "epoch 90; iter: 0; batch classifier loss: 0.167938; batch adversarial loss: 0.483596\n",
      "epoch 91; iter: 0; batch classifier loss: 0.166425; batch adversarial loss: 0.458304\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107867; batch adversarial loss: 0.431708\n",
      "epoch 93; iter: 0; batch classifier loss: 0.164350; batch adversarial loss: 0.470373\n",
      "epoch 94; iter: 0; batch classifier loss: 0.157278; batch adversarial loss: 0.292176\n",
      "epoch 95; iter: 0; batch classifier loss: 0.143961; batch adversarial loss: 0.430155\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073061; batch adversarial loss: 0.573914\n",
      "epoch 97; iter: 0; batch classifier loss: 0.121956; batch adversarial loss: 0.382681\n",
      "epoch 98; iter: 0; batch classifier loss: 0.171394; batch adversarial loss: 0.379722\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056858; batch adversarial loss: 0.365901\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075570; batch adversarial loss: 0.466484\n",
      "epoch 101; iter: 0; batch classifier loss: 0.121510; batch adversarial loss: 0.434499\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067447; batch adversarial loss: 0.405838\n",
      "epoch 103; iter: 0; batch classifier loss: 0.121220; batch adversarial loss: 0.391155\n",
      "epoch 104; iter: 0; batch classifier loss: 0.101682; batch adversarial loss: 0.409320\n",
      "epoch 105; iter: 0; batch classifier loss: 0.106469; batch adversarial loss: 0.432679\n",
      "epoch 106; iter: 0; batch classifier loss: 0.112287; batch adversarial loss: 0.386445\n",
      "epoch 107; iter: 0; batch classifier loss: 0.094102; batch adversarial loss: 0.372535\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046330; batch adversarial loss: 0.543320\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077161; batch adversarial loss: 0.442949\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068680; batch adversarial loss: 0.351256\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081876; batch adversarial loss: 0.479423\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057964; batch adversarial loss: 0.408054\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091195; batch adversarial loss: 0.466908\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057490; batch adversarial loss: 0.540889\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031372; batch adversarial loss: 0.459194\n",
      "epoch 116; iter: 0; batch classifier loss: 0.079283; batch adversarial loss: 0.398355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.441706\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042283; batch adversarial loss: 0.485378\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053775; batch adversarial loss: 0.437508\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077194; batch adversarial loss: 0.403055\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053311; batch adversarial loss: 0.420051\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047348; batch adversarial loss: 0.373226\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053377; batch adversarial loss: 0.407828\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047565; batch adversarial loss: 0.415294\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053847; batch adversarial loss: 0.417119\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026215; batch adversarial loss: 0.444743\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042424; batch adversarial loss: 0.356016\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055289; batch adversarial loss: 0.473998\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032460; batch adversarial loss: 0.496980\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036396; batch adversarial loss: 0.362995\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044252; batch adversarial loss: 0.436495\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019484; batch adversarial loss: 0.375491\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044163; batch adversarial loss: 0.497040\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046983; batch adversarial loss: 0.450762\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029823; batch adversarial loss: 0.497748\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031489; batch adversarial loss: 0.394763\n",
      "epoch 137; iter: 0; batch classifier loss: 0.010045; batch adversarial loss: 0.484040\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037490; batch adversarial loss: 0.497467\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010913; batch adversarial loss: 0.409161\n",
      "epoch 140; iter: 0; batch classifier loss: 0.020071; batch adversarial loss: 0.478558\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027147; batch adversarial loss: 0.443392\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.445079\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049986; batch adversarial loss: 0.415990\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032853; batch adversarial loss: 0.358357\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034962; batch adversarial loss: 0.460953\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042858; batch adversarial loss: 0.400674\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022653; batch adversarial loss: 0.428351\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043098; batch adversarial loss: 0.425223\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037244; batch adversarial loss: 0.412964\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019531; batch adversarial loss: 0.425357\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012982; batch adversarial loss: 0.480766\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008764; batch adversarial loss: 0.511262\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020624; batch adversarial loss: 0.418044\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019996; batch adversarial loss: 0.431542\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.407240\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046690; batch adversarial loss: 0.434498\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019125; batch adversarial loss: 0.399099\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022128; batch adversarial loss: 0.399028\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028320; batch adversarial loss: 0.470851\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031605; batch adversarial loss: 0.443890\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006553; batch adversarial loss: 0.439730\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010651; batch adversarial loss: 0.403001\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012588; batch adversarial loss: 0.473518\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026628; batch adversarial loss: 0.445918\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015695; batch adversarial loss: 0.452812\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021340; batch adversarial loss: 0.428184\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.434668\n",
      "epoch 168; iter: 0; batch classifier loss: 0.010843; batch adversarial loss: 0.402591\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013849; batch adversarial loss: 0.369142\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023504; batch adversarial loss: 0.427519\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012554; batch adversarial loss: 0.470051\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019096; batch adversarial loss: 0.502023\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015452; batch adversarial loss: 0.425358\n",
      "epoch 174; iter: 0; batch classifier loss: 0.005409; batch adversarial loss: 0.457163\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018125; batch adversarial loss: 0.415086\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037507; batch adversarial loss: 0.394532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011525; batch adversarial loss: 0.340080\n",
      "epoch 178; iter: 0; batch classifier loss: 0.003693; batch adversarial loss: 0.435249\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008631; batch adversarial loss: 0.512503\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005057; batch adversarial loss: 0.368092\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022225; batch adversarial loss: 0.399055\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040258; batch adversarial loss: 0.415710\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011969; batch adversarial loss: 0.482515\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025310; batch adversarial loss: 0.517609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005859; batch adversarial loss: 0.453707\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005726; batch adversarial loss: 0.452453\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007463; batch adversarial loss: 0.502593\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022840; batch adversarial loss: 0.459120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016745; batch adversarial loss: 0.425811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049987; batch adversarial loss: 0.433821\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005919; batch adversarial loss: 0.406695\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011478; batch adversarial loss: 0.401756\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007063; batch adversarial loss: 0.356573\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005790; batch adversarial loss: 0.427907\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017165; batch adversarial loss: 0.441614\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015083; batch adversarial loss: 0.609482\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018316; batch adversarial loss: 0.466833\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029517; batch adversarial loss: 0.455710\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014250; batch adversarial loss: 0.320694\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696786; batch adversarial loss: 0.561756\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552132; batch adversarial loss: 0.583270\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369594; batch adversarial loss: 0.551237\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326388; batch adversarial loss: 0.606278\n",
      "epoch 4; iter: 0; batch classifier loss: 0.415000; batch adversarial loss: 0.579595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457800; batch adversarial loss: 0.595016\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386015; batch adversarial loss: 0.565066\n",
      "epoch 7; iter: 0; batch classifier loss: 0.436052; batch adversarial loss: 0.586483\n",
      "epoch 8; iter: 0; batch classifier loss: 0.358003; batch adversarial loss: 0.519607\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353682; batch adversarial loss: 0.534116\n",
      "epoch 10; iter: 0; batch classifier loss: 0.666383; batch adversarial loss: 0.524221\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585894; batch adversarial loss: 0.560209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.660482; batch adversarial loss: 0.507279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 0; batch classifier loss: 0.452842; batch adversarial loss: 0.507048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373322; batch adversarial loss: 0.508195\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264999; batch adversarial loss: 0.506139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.245801; batch adversarial loss: 0.514416\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225167; batch adversarial loss: 0.456933\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285492; batch adversarial loss: 0.442128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225390; batch adversarial loss: 0.474439\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171407; batch adversarial loss: 0.455772\n",
      "epoch 21; iter: 0; batch classifier loss: 0.205917; batch adversarial loss: 0.471340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209373; batch adversarial loss: 0.398855\n",
      "epoch 23; iter: 0; batch classifier loss: 0.194579; batch adversarial loss: 0.453137\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162947; batch adversarial loss: 0.486260\n",
      "epoch 25; iter: 0; batch classifier loss: 0.177180; batch adversarial loss: 0.352019\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226302; batch adversarial loss: 0.493534\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166894; batch adversarial loss: 0.488781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153339; batch adversarial loss: 0.467092\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176317; batch adversarial loss: 0.496413\n",
      "epoch 30; iter: 0; batch classifier loss: 0.169181; batch adversarial loss: 0.465266\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137757; batch adversarial loss: 0.473556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093843; batch adversarial loss: 0.556530\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148664; batch adversarial loss: 0.528391\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103975; batch adversarial loss: 0.411024\n",
      "epoch 35; iter: 0; batch classifier loss: 0.119048; batch adversarial loss: 0.465978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120447; batch adversarial loss: 0.461848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074875; batch adversarial loss: 0.438883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.128599; batch adversarial loss: 0.356635\n",
      "epoch 39; iter: 0; batch classifier loss: 0.073907; batch adversarial loss: 0.416930\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129969; batch adversarial loss: 0.438869\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133261; batch adversarial loss: 0.414026\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120644; batch adversarial loss: 0.416356\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100482; batch adversarial loss: 0.502954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101926; batch adversarial loss: 0.418873\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103702; batch adversarial loss: 0.362798\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086166; batch adversarial loss: 0.395152\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108611; batch adversarial loss: 0.426761\n",
      "epoch 48; iter: 0; batch classifier loss: 0.100718; batch adversarial loss: 0.464243\n",
      "epoch 49; iter: 0; batch classifier loss: 0.075835; batch adversarial loss: 0.406490\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094036; batch adversarial loss: 0.442588\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109693; batch adversarial loss: 0.493317\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089900; batch adversarial loss: 0.456440\n",
      "epoch 53; iter: 0; batch classifier loss: 0.066551; batch adversarial loss: 0.560452\n",
      "epoch 54; iter: 0; batch classifier loss: 0.140497; batch adversarial loss: 0.365451\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186082; batch adversarial loss: 0.393339\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102423; batch adversarial loss: 0.484214\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125558; batch adversarial loss: 0.549669\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089324; batch adversarial loss: 0.426266\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115832; batch adversarial loss: 0.384936\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096383; batch adversarial loss: 0.432047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084604; batch adversarial loss: 0.493253\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089381; batch adversarial loss: 0.408334\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060357; batch adversarial loss: 0.487817\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083298; batch adversarial loss: 0.461866\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072948; batch adversarial loss: 0.577754\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069675; batch adversarial loss: 0.446224\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051761; batch adversarial loss: 0.469095\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109625; batch adversarial loss: 0.431514\n",
      "epoch 69; iter: 0; batch classifier loss: 0.088382; batch adversarial loss: 0.486768\n",
      "epoch 70; iter: 0; batch classifier loss: 0.042655; batch adversarial loss: 0.437293\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099849; batch adversarial loss: 0.429036\n",
      "epoch 72; iter: 0; batch classifier loss: 0.040534; batch adversarial loss: 0.407303\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062053; batch adversarial loss: 0.362562\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054484; batch adversarial loss: 0.449817\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083930; batch adversarial loss: 0.523907\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106462; batch adversarial loss: 0.453974\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088862; batch adversarial loss: 0.498378\n",
      "epoch 78; iter: 0; batch classifier loss: 0.110059; batch adversarial loss: 0.440683\n",
      "epoch 79; iter: 0; batch classifier loss: 0.104070; batch adversarial loss: 0.481883\n",
      "epoch 80; iter: 0; batch classifier loss: 0.029690; batch adversarial loss: 0.489319\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062328; batch adversarial loss: 0.413377\n",
      "epoch 82; iter: 0; batch classifier loss: 0.031866; batch adversarial loss: 0.443043\n",
      "epoch 83; iter: 0; batch classifier loss: 0.179511; batch adversarial loss: 0.400066\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078851; batch adversarial loss: 0.370612\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072472; batch adversarial loss: 0.440071\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103133; batch adversarial loss: 0.406052\n",
      "epoch 87; iter: 0; batch classifier loss: 0.113960; batch adversarial loss: 0.423631\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086412; batch adversarial loss: 0.497343\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065429; batch adversarial loss: 0.452930\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073405; batch adversarial loss: 0.436617\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100238; batch adversarial loss: 0.400391\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058085; batch adversarial loss: 0.460203\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053899; batch adversarial loss: 0.387610\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046844; batch adversarial loss: 0.461569\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050184; batch adversarial loss: 0.384818\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093556; batch adversarial loss: 0.460181\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042859; batch adversarial loss: 0.411675\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048501; batch adversarial loss: 0.429142\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053672; batch adversarial loss: 0.424271\n",
      "epoch 100; iter: 0; batch classifier loss: 0.030568; batch adversarial loss: 0.361890\n",
      "epoch 101; iter: 0; batch classifier loss: 0.060857; batch adversarial loss: 0.396002\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047813; batch adversarial loss: 0.551903\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075372; batch adversarial loss: 0.460678\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066479; batch adversarial loss: 0.367065\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048443; batch adversarial loss: 0.402237\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044825; batch adversarial loss: 0.476698\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028093; batch adversarial loss: 0.497614\n",
      "epoch 108; iter: 0; batch classifier loss: 0.124266; batch adversarial loss: 0.448463\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037040; batch adversarial loss: 0.439931\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033980; batch adversarial loss: 0.507922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111; iter: 0; batch classifier loss: 0.064360; batch adversarial loss: 0.475787\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058881; batch adversarial loss: 0.382162\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024502; batch adversarial loss: 0.527138\n",
      "epoch 114; iter: 0; batch classifier loss: 0.015269; batch adversarial loss: 0.459370\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066213; batch adversarial loss: 0.427510\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.537406\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047002; batch adversarial loss: 0.384314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023981; batch adversarial loss: 0.390018\n",
      "epoch 119; iter: 0; batch classifier loss: 0.096276; batch adversarial loss: 0.449244\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062853; batch adversarial loss: 0.400325\n",
      "epoch 121; iter: 0; batch classifier loss: 0.091114; batch adversarial loss: 0.379791\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030924; batch adversarial loss: 0.489950\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034188; batch adversarial loss: 0.523627\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058312; batch adversarial loss: 0.333131\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046388; batch adversarial loss: 0.418929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032453; batch adversarial loss: 0.418536\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027628; batch adversarial loss: 0.420208\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049577; batch adversarial loss: 0.429636\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050117; batch adversarial loss: 0.528129\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047796; batch adversarial loss: 0.515314\n",
      "epoch 131; iter: 0; batch classifier loss: 0.065467; batch adversarial loss: 0.441488\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073384; batch adversarial loss: 0.373730\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027067; batch adversarial loss: 0.513966\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028924; batch adversarial loss: 0.452672\n",
      "epoch 135; iter: 0; batch classifier loss: 0.066293; batch adversarial loss: 0.490017\n",
      "epoch 136; iter: 0; batch classifier loss: 0.062676; batch adversarial loss: 0.400821\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011492; batch adversarial loss: 0.401976\n",
      "epoch 138; iter: 0; batch classifier loss: 0.011554; batch adversarial loss: 0.429227\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046820; batch adversarial loss: 0.495951\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041227; batch adversarial loss: 0.377642\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038395; batch adversarial loss: 0.424714\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028280; batch adversarial loss: 0.425709\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053731; batch adversarial loss: 0.412312\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016343; batch adversarial loss: 0.397480\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022265; batch adversarial loss: 0.498931\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033768; batch adversarial loss: 0.396907\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037383; batch adversarial loss: 0.395463\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025948; batch adversarial loss: 0.406461\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032036; batch adversarial loss: 0.488833\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045595; batch adversarial loss: 0.439218\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025538; batch adversarial loss: 0.416449\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025918; batch adversarial loss: 0.529163\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.484043\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051822; batch adversarial loss: 0.426134\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026432; batch adversarial loss: 0.508609\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028811; batch adversarial loss: 0.384633\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033089; batch adversarial loss: 0.426704\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024853; batch adversarial loss: 0.471902\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.533664\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047508; batch adversarial loss: 0.517897\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022019; batch adversarial loss: 0.538432\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014284; batch adversarial loss: 0.509816\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016181; batch adversarial loss: 0.447188\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011259; batch adversarial loss: 0.466773\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034519; batch adversarial loss: 0.408298\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026996; batch adversarial loss: 0.433888\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026980; batch adversarial loss: 0.441372\n",
      "epoch 168; iter: 0; batch classifier loss: 0.043077; batch adversarial loss: 0.427453\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012169; batch adversarial loss: 0.388651\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017135; batch adversarial loss: 0.383098\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006291; batch adversarial loss: 0.565060\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022444; batch adversarial loss: 0.521889\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019036; batch adversarial loss: 0.437818\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015432; batch adversarial loss: 0.440413\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015862; batch adversarial loss: 0.504855\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.400654\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014921; batch adversarial loss: 0.418447\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017219; batch adversarial loss: 0.475588\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010483; batch adversarial loss: 0.420744\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023784; batch adversarial loss: 0.462339\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034441; batch adversarial loss: 0.485364\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028336; batch adversarial loss: 0.448574\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042160; batch adversarial loss: 0.485691\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042575; batch adversarial loss: 0.457420\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025125; batch adversarial loss: 0.467159\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017803; batch adversarial loss: 0.464609\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014801; batch adversarial loss: 0.467358\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017262; batch adversarial loss: 0.451342\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012024; batch adversarial loss: 0.399523\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029831; batch adversarial loss: 0.448789\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026603; batch adversarial loss: 0.464130\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015111; batch adversarial loss: 0.434984\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010774; batch adversarial loss: 0.429012\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046804; batch adversarial loss: 0.512385\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008780; batch adversarial loss: 0.516791\n",
      "epoch 196; iter: 0; batch classifier loss: 0.051340; batch adversarial loss: 0.430520\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016192; batch adversarial loss: 0.528365\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016736; batch adversarial loss: 0.438762\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006665; batch adversarial loss: 0.443790\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676681; batch adversarial loss: 0.594935\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511698; batch adversarial loss: 0.623217\n",
      "epoch 2; iter: 0; batch classifier loss: 0.434878; batch adversarial loss: 0.600341\n",
      "epoch 3; iter: 0; batch classifier loss: 0.358062; batch adversarial loss: 0.585571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407363; batch adversarial loss: 0.573155\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531100; batch adversarial loss: 0.594702\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480643; batch adversarial loss: 0.571354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7; iter: 0; batch classifier loss: 0.565500; batch adversarial loss: 0.586311\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423624; batch adversarial loss: 0.567236\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421475; batch adversarial loss: 0.547814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466379; batch adversarial loss: 0.513007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313771; batch adversarial loss: 0.483030\n",
      "epoch 12; iter: 0; batch classifier loss: 0.303904; batch adversarial loss: 0.532158\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328852; batch adversarial loss: 0.477675\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310971; batch adversarial loss: 0.517375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346806; batch adversarial loss: 0.506042\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323945; batch adversarial loss: 0.432950\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312195; batch adversarial loss: 0.489552\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285151; batch adversarial loss: 0.449396\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338472; batch adversarial loss: 0.507414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310774; batch adversarial loss: 0.461503\n",
      "epoch 21; iter: 0; batch classifier loss: 0.238288; batch adversarial loss: 0.480927\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339956; batch adversarial loss: 0.455340\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226226; batch adversarial loss: 0.452568\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353678; batch adversarial loss: 0.620928\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265735; batch adversarial loss: 0.415823\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217872; batch adversarial loss: 0.539766\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315875; batch adversarial loss: 0.402851\n",
      "epoch 28; iter: 0; batch classifier loss: 0.276004; batch adversarial loss: 0.455079\n",
      "epoch 29; iter: 0; batch classifier loss: 0.203877; batch adversarial loss: 0.432703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262254; batch adversarial loss: 0.536520\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275835; batch adversarial loss: 0.441590\n",
      "epoch 32; iter: 0; batch classifier loss: 0.274196; batch adversarial loss: 0.425115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.321202; batch adversarial loss: 0.403474\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196213; batch adversarial loss: 0.509383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.284486; batch adversarial loss: 0.433784\n",
      "epoch 36; iter: 0; batch classifier loss: 0.255002; batch adversarial loss: 0.466434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250227; batch adversarial loss: 0.490984\n",
      "epoch 38; iter: 0; batch classifier loss: 0.331564; batch adversarial loss: 0.465660\n",
      "epoch 39; iter: 0; batch classifier loss: 0.216439; batch adversarial loss: 0.503065\n",
      "epoch 40; iter: 0; batch classifier loss: 0.281372; batch adversarial loss: 0.413292\n",
      "epoch 41; iter: 0; batch classifier loss: 0.272210; batch adversarial loss: 0.402680\n",
      "epoch 42; iter: 0; batch classifier loss: 0.171970; batch adversarial loss: 0.451881\n",
      "epoch 43; iter: 0; batch classifier loss: 0.272485; batch adversarial loss: 0.471502\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179028; batch adversarial loss: 0.485216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205077; batch adversarial loss: 0.471130\n",
      "epoch 46; iter: 0; batch classifier loss: 0.198167; batch adversarial loss: 0.482151\n",
      "epoch 47; iter: 0; batch classifier loss: 0.132881; batch adversarial loss: 0.520630\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231754; batch adversarial loss: 0.459542\n",
      "epoch 49; iter: 0; batch classifier loss: 0.262006; batch adversarial loss: 0.447750\n",
      "epoch 50; iter: 0; batch classifier loss: 0.199600; batch adversarial loss: 0.458723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141036; batch adversarial loss: 0.397830\n",
      "epoch 52; iter: 0; batch classifier loss: 0.165936; batch adversarial loss: 0.448771\n",
      "epoch 53; iter: 0; batch classifier loss: 0.204084; batch adversarial loss: 0.618730\n",
      "epoch 54; iter: 0; batch classifier loss: 0.164537; batch adversarial loss: 0.496326\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173024; batch adversarial loss: 0.494365\n",
      "epoch 56; iter: 0; batch classifier loss: 0.256573; batch adversarial loss: 0.435021\n",
      "epoch 57; iter: 0; batch classifier loss: 0.182806; batch adversarial loss: 0.372197\n",
      "epoch 58; iter: 0; batch classifier loss: 0.277427; batch adversarial loss: 0.360717\n",
      "epoch 59; iter: 0; batch classifier loss: 0.193679; batch adversarial loss: 0.398004\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203600; batch adversarial loss: 0.422422\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128560; batch adversarial loss: 0.396435\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113990; batch adversarial loss: 0.445267\n",
      "epoch 63; iter: 0; batch classifier loss: 0.167315; batch adversarial loss: 0.445031\n",
      "epoch 64; iter: 0; batch classifier loss: 0.243771; batch adversarial loss: 0.471250\n",
      "epoch 65; iter: 0; batch classifier loss: 0.190835; batch adversarial loss: 0.433865\n",
      "epoch 66; iter: 0; batch classifier loss: 0.215555; batch adversarial loss: 0.420219\n",
      "epoch 67; iter: 0; batch classifier loss: 0.291411; batch adversarial loss: 0.400065\n",
      "epoch 68; iter: 0; batch classifier loss: 0.188290; batch adversarial loss: 0.447167\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164462; batch adversarial loss: 0.496028\n",
      "epoch 70; iter: 0; batch classifier loss: 0.275516; batch adversarial loss: 0.471509\n",
      "epoch 71; iter: 0; batch classifier loss: 0.152520; batch adversarial loss: 0.434508\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104651; batch adversarial loss: 0.482590\n",
      "epoch 73; iter: 0; batch classifier loss: 0.197267; batch adversarial loss: 0.383323\n",
      "epoch 74; iter: 0; batch classifier loss: 0.295966; batch adversarial loss: 0.346221\n",
      "epoch 75; iter: 0; batch classifier loss: 0.148515; batch adversarial loss: 0.446510\n",
      "epoch 76; iter: 0; batch classifier loss: 0.253655; batch adversarial loss: 0.358765\n",
      "epoch 77; iter: 0; batch classifier loss: 0.250957; batch adversarial loss: 0.397244\n",
      "epoch 78; iter: 0; batch classifier loss: 0.242467; batch adversarial loss: 0.421744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.203211; batch adversarial loss: 0.359702\n",
      "epoch 80; iter: 0; batch classifier loss: 0.179568; batch adversarial loss: 0.520717\n",
      "epoch 81; iter: 0; batch classifier loss: 0.140870; batch adversarial loss: 0.422172\n",
      "epoch 82; iter: 0; batch classifier loss: 0.191898; batch adversarial loss: 0.410067\n",
      "epoch 83; iter: 0; batch classifier loss: 0.317798; batch adversarial loss: 0.458837\n",
      "epoch 84; iter: 0; batch classifier loss: 0.240647; batch adversarial loss: 0.434036\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079025; batch adversarial loss: 0.534802\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102153; batch adversarial loss: 0.394704\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100129; batch adversarial loss: 0.411798\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104871; batch adversarial loss: 0.456911\n",
      "epoch 89; iter: 0; batch classifier loss: 0.187498; batch adversarial loss: 0.525605\n",
      "epoch 90; iter: 0; batch classifier loss: 0.204397; batch adversarial loss: 0.434602\n",
      "epoch 91; iter: 0; batch classifier loss: 0.147003; batch adversarial loss: 0.422208\n",
      "epoch 92; iter: 0; batch classifier loss: 0.158935; batch adversarial loss: 0.473392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.215524; batch adversarial loss: 0.507754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.190340; batch adversarial loss: 0.447110\n",
      "epoch 95; iter: 0; batch classifier loss: 0.191967; batch adversarial loss: 0.423651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.198515; batch adversarial loss: 0.458715\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199149; batch adversarial loss: 0.446231\n",
      "epoch 98; iter: 0; batch classifier loss: 0.185424; batch adversarial loss: 0.433867\n",
      "epoch 99; iter: 0; batch classifier loss: 0.193466; batch adversarial loss: 0.558328\n",
      "epoch 100; iter: 0; batch classifier loss: 0.191432; batch adversarial loss: 0.410139\n",
      "epoch 101; iter: 0; batch classifier loss: 0.200682; batch adversarial loss: 0.384833\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052794; batch adversarial loss: 0.396390\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068559; batch adversarial loss: 0.534740\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045067; batch adversarial loss: 0.421697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 105; iter: 0; batch classifier loss: 0.063283; batch adversarial loss: 0.443087\n",
      "epoch 106; iter: 0; batch classifier loss: 0.102844; batch adversarial loss: 0.432647\n",
      "epoch 107; iter: 0; batch classifier loss: 0.110883; batch adversarial loss: 0.445489\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065556; batch adversarial loss: 0.439546\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075212; batch adversarial loss: 0.443641\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088465; batch adversarial loss: 0.453119\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085812; batch adversarial loss: 0.547013\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092447; batch adversarial loss: 0.374012\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051192; batch adversarial loss: 0.485063\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054495; batch adversarial loss: 0.433434\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073181; batch adversarial loss: 0.488820\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062405; batch adversarial loss: 0.425612\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030429; batch adversarial loss: 0.390769\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035706; batch adversarial loss: 0.430130\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060347; batch adversarial loss: 0.346094\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051546; batch adversarial loss: 0.334768\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021493; batch adversarial loss: 0.477090\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052722; batch adversarial loss: 0.425242\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044042; batch adversarial loss: 0.359936\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035780; batch adversarial loss: 0.481967\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056074; batch adversarial loss: 0.409339\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031247; batch adversarial loss: 0.504614\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045782; batch adversarial loss: 0.403953\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047143; batch adversarial loss: 0.484136\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031782; batch adversarial loss: 0.465125\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073323; batch adversarial loss: 0.388335\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018247; batch adversarial loss: 0.357201\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025984; batch adversarial loss: 0.436277\n",
      "epoch 133; iter: 0; batch classifier loss: 0.016731; batch adversarial loss: 0.380555\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030006; batch adversarial loss: 0.569077\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050944; batch adversarial loss: 0.489785\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022236; batch adversarial loss: 0.485312\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017575; batch adversarial loss: 0.367392\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020553; batch adversarial loss: 0.485871\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050697; batch adversarial loss: 0.397167\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015389; batch adversarial loss: 0.441083\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019473; batch adversarial loss: 0.348332\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030653; batch adversarial loss: 0.489592\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022517; batch adversarial loss: 0.472079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025694; batch adversarial loss: 0.415858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024273; batch adversarial loss: 0.431766\n",
      "epoch 146; iter: 0; batch classifier loss: 0.009998; batch adversarial loss: 0.441227\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024257; batch adversarial loss: 0.497057\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025315; batch adversarial loss: 0.533768\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034753; batch adversarial loss: 0.447686\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018527; batch adversarial loss: 0.394572\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.475913\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036939; batch adversarial loss: 0.447033\n",
      "epoch 153; iter: 0; batch classifier loss: 0.023871; batch adversarial loss: 0.456146\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030733; batch adversarial loss: 0.436956\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025545; batch adversarial loss: 0.364286\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050778; batch adversarial loss: 0.408563\n",
      "epoch 157; iter: 0; batch classifier loss: 0.007280; batch adversarial loss: 0.471953\n",
      "epoch 158; iter: 0; batch classifier loss: 0.041722; batch adversarial loss: 0.418022\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034121; batch adversarial loss: 0.471148\n",
      "epoch 160; iter: 0; batch classifier loss: 0.005318; batch adversarial loss: 0.425879\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007078; batch adversarial loss: 0.455251\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028406; batch adversarial loss: 0.545125\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020054; batch adversarial loss: 0.466683\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028537; batch adversarial loss: 0.480380\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011585; batch adversarial loss: 0.417535\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015236; batch adversarial loss: 0.464529\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008446; batch adversarial loss: 0.476448\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028667; batch adversarial loss: 0.415033\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018788; batch adversarial loss: 0.410490\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016486; batch adversarial loss: 0.439561\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020224; batch adversarial loss: 0.423223\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011458; batch adversarial loss: 0.437530\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009233; batch adversarial loss: 0.458981\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009012; batch adversarial loss: 0.428559\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008182; batch adversarial loss: 0.484540\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014195; batch adversarial loss: 0.469183\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017271; batch adversarial loss: 0.462786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009785; batch adversarial loss: 0.369463\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019051; batch adversarial loss: 0.451908\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030310; batch adversarial loss: 0.486548\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029272; batch adversarial loss: 0.451228\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006080; batch adversarial loss: 0.437043\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016255; batch adversarial loss: 0.433107\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011848; batch adversarial loss: 0.440476\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012229; batch adversarial loss: 0.429545\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015669; batch adversarial loss: 0.407823\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003872; batch adversarial loss: 0.445857\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006581; batch adversarial loss: 0.494973\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009256; batch adversarial loss: 0.483378\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009796; batch adversarial loss: 0.514886\n",
      "epoch 191; iter: 0; batch classifier loss: 0.005923; batch adversarial loss: 0.379992\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034108; batch adversarial loss: 0.416085\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013819; batch adversarial loss: 0.499414\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020278; batch adversarial loss: 0.460149\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010177; batch adversarial loss: 0.406681\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016615; batch adversarial loss: 0.456948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008281; batch adversarial loss: 0.361581\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005671; batch adversarial loss: 0.475769\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014362; batch adversarial loss: 0.368401\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670001; batch adversarial loss: 0.848666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.378504; batch adversarial loss: 0.837344\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343913; batch adversarial loss: 0.792073\n",
      "epoch 3; iter: 0; batch classifier loss: 0.272674; batch adversarial loss: 0.714439\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460415; batch adversarial loss: 0.723586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302628; batch adversarial loss: 0.662404\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281502; batch adversarial loss: 0.641646\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350549; batch adversarial loss: 0.629883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270874; batch adversarial loss: 0.590246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282000; batch adversarial loss: 0.597932\n",
      "epoch 10; iter: 0; batch classifier loss: 0.277921; batch adversarial loss: 0.549819\n",
      "epoch 11; iter: 0; batch classifier loss: 0.244458; batch adversarial loss: 0.546685\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273671; batch adversarial loss: 0.461012\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312268; batch adversarial loss: 0.443072\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290217; batch adversarial loss: 0.488746\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270015; batch adversarial loss: 0.488829\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274024; batch adversarial loss: 0.497454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.325632; batch adversarial loss: 0.413634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261227; batch adversarial loss: 0.382005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272961; batch adversarial loss: 0.318512\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237722; batch adversarial loss: 0.394890\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259768; batch adversarial loss: 0.403376\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241644; batch adversarial loss: 0.408233\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248459; batch adversarial loss: 0.420445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189397; batch adversarial loss: 0.395642\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174876; batch adversarial loss: 0.376140\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149042; batch adversarial loss: 0.390676\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152005; batch adversarial loss: 0.406922\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193898; batch adversarial loss: 0.366405\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170063; batch adversarial loss: 0.397224\n",
      "epoch 30; iter: 0; batch classifier loss: 0.189953; batch adversarial loss: 0.399840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.194397; batch adversarial loss: 0.307060\n",
      "epoch 32; iter: 0; batch classifier loss: 0.185726; batch adversarial loss: 0.378240\n",
      "epoch 33; iter: 0; batch classifier loss: 0.175583; batch adversarial loss: 0.410994\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168108; batch adversarial loss: 0.369711\n",
      "epoch 35; iter: 0; batch classifier loss: 0.135129; batch adversarial loss: 0.358050\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154389; batch adversarial loss: 0.365450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137792; batch adversarial loss: 0.319955\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121684; batch adversarial loss: 0.374799\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167348; batch adversarial loss: 0.374389\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127422; batch adversarial loss: 0.412713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127500; batch adversarial loss: 0.418775\n",
      "epoch 42; iter: 0; batch classifier loss: 0.151552; batch adversarial loss: 0.415583\n",
      "epoch 43; iter: 0; batch classifier loss: 0.107737; batch adversarial loss: 0.457266\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103501; batch adversarial loss: 0.468199\n",
      "epoch 45; iter: 0; batch classifier loss: 0.100882; batch adversarial loss: 0.375996\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129286; batch adversarial loss: 0.422278\n",
      "epoch 47; iter: 0; batch classifier loss: 0.078272; batch adversarial loss: 0.374587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104555; batch adversarial loss: 0.419984\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082310; batch adversarial loss: 0.334457\n",
      "epoch 50; iter: 0; batch classifier loss: 0.116855; batch adversarial loss: 0.350922\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100943; batch adversarial loss: 0.418447\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085060; batch adversarial loss: 0.342521\n",
      "epoch 53; iter: 0; batch classifier loss: 0.071371; batch adversarial loss: 0.400817\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096608; batch adversarial loss: 0.453506\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107486; batch adversarial loss: 0.520216\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096700; batch adversarial loss: 0.365700\n",
      "epoch 57; iter: 0; batch classifier loss: 0.058599; batch adversarial loss: 0.426892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097466; batch adversarial loss: 0.437335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108351; batch adversarial loss: 0.474585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080856; batch adversarial loss: 0.411820\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081722; batch adversarial loss: 0.413640\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086836; batch adversarial loss: 0.479839\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080773; batch adversarial loss: 0.436634\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105457; batch adversarial loss: 0.407629\n",
      "epoch 65; iter: 0; batch classifier loss: 0.053606; batch adversarial loss: 0.516805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073645; batch adversarial loss: 0.462328\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078157; batch adversarial loss: 0.400048\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043624; batch adversarial loss: 0.404787\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089446; batch adversarial loss: 0.494307\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057107; batch adversarial loss: 0.399847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.053409; batch adversarial loss: 0.351496\n",
      "epoch 72; iter: 0; batch classifier loss: 0.079016; batch adversarial loss: 0.444364\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062519; batch adversarial loss: 0.439104\n",
      "epoch 74; iter: 0; batch classifier loss: 0.047787; batch adversarial loss: 0.331625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060035; batch adversarial loss: 0.418212\n",
      "epoch 76; iter: 0; batch classifier loss: 0.108767; batch adversarial loss: 0.473276\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086094; batch adversarial loss: 0.404460\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086033; batch adversarial loss: 0.378901\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056352; batch adversarial loss: 0.443070\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070797; batch adversarial loss: 0.395733\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064529; batch adversarial loss: 0.409001\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066781; batch adversarial loss: 0.404302\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071151; batch adversarial loss: 0.434457\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.510170\n",
      "epoch 85; iter: 0; batch classifier loss: 0.048956; batch adversarial loss: 0.411644\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055041; batch adversarial loss: 0.367429\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076742; batch adversarial loss: 0.410672\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080668; batch adversarial loss: 0.439069\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042044; batch adversarial loss: 0.416451\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052168; batch adversarial loss: 0.442615\n",
      "epoch 91; iter: 0; batch classifier loss: 0.053929; batch adversarial loss: 0.497536\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072083; batch adversarial loss: 0.440887\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091919; batch adversarial loss: 0.367724\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049803; batch adversarial loss: 0.404521\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050161; batch adversarial loss: 0.400954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045118; batch adversarial loss: 0.369296\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066454; batch adversarial loss: 0.387728\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052713; batch adversarial loss: 0.398677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99; iter: 0; batch classifier loss: 0.066424; batch adversarial loss: 0.493061\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060839; batch adversarial loss: 0.375153\n",
      "epoch 101; iter: 0; batch classifier loss: 0.021860; batch adversarial loss: 0.430451\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055814; batch adversarial loss: 0.438797\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023935; batch adversarial loss: 0.434046\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041628; batch adversarial loss: 0.486394\n",
      "epoch 105; iter: 0; batch classifier loss: 0.078397; batch adversarial loss: 0.435767\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076655; batch adversarial loss: 0.402912\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057378; batch adversarial loss: 0.492655\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039602; batch adversarial loss: 0.417321\n",
      "epoch 109; iter: 0; batch classifier loss: 0.019784; batch adversarial loss: 0.410833\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044007; batch adversarial loss: 0.541264\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039748; batch adversarial loss: 0.517444\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024708; batch adversarial loss: 0.446619\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045135; batch adversarial loss: 0.472322\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050635; batch adversarial loss: 0.503422\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023870; batch adversarial loss: 0.420283\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047727; batch adversarial loss: 0.445341\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038920; batch adversarial loss: 0.420962\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049732; batch adversarial loss: 0.571416\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027769; batch adversarial loss: 0.430203\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021997; batch adversarial loss: 0.460949\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018176; batch adversarial loss: 0.531578\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.480567\n",
      "epoch 123; iter: 0; batch classifier loss: 0.014087; batch adversarial loss: 0.384080\n",
      "epoch 124; iter: 0; batch classifier loss: 0.018065; batch adversarial loss: 0.476197\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061814; batch adversarial loss: 0.420501\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015759; batch adversarial loss: 0.435974\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035330; batch adversarial loss: 0.457158\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036849; batch adversarial loss: 0.551151\n",
      "epoch 129; iter: 0; batch classifier loss: 0.110429; batch adversarial loss: 0.625562\n",
      "epoch 130; iter: 0; batch classifier loss: 0.112213; batch adversarial loss: 0.663824\n",
      "epoch 131; iter: 0; batch classifier loss: 0.069699; batch adversarial loss: 0.522442\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072970; batch adversarial loss: 0.560556\n",
      "epoch 133; iter: 0; batch classifier loss: 0.129778; batch adversarial loss: 0.647991\n",
      "epoch 134; iter: 0; batch classifier loss: 0.138654; batch adversarial loss: 0.564448\n",
      "epoch 135; iter: 0; batch classifier loss: 0.089721; batch adversarial loss: 0.593269\n",
      "epoch 136; iter: 0; batch classifier loss: 0.209930; batch adversarial loss: 0.714643\n",
      "epoch 137; iter: 0; batch classifier loss: 0.109938; batch adversarial loss: 0.521406\n",
      "epoch 138; iter: 0; batch classifier loss: 0.097841; batch adversarial loss: 0.642400\n",
      "epoch 139; iter: 0; batch classifier loss: 0.089977; batch adversarial loss: 0.469327\n",
      "epoch 140; iter: 0; batch classifier loss: 0.128728; batch adversarial loss: 0.658971\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202770; batch adversarial loss: 0.753950\n",
      "epoch 142; iter: 0; batch classifier loss: 0.191055; batch adversarial loss: 0.639315\n",
      "epoch 143; iter: 0; batch classifier loss: 0.088264; batch adversarial loss: 0.529939\n",
      "epoch 144; iter: 0; batch classifier loss: 0.134953; batch adversarial loss: 0.547747\n",
      "epoch 145; iter: 0; batch classifier loss: 0.150028; batch adversarial loss: 0.582491\n",
      "epoch 146; iter: 0; batch classifier loss: 0.145304; batch adversarial loss: 0.647221\n",
      "epoch 147; iter: 0; batch classifier loss: 0.111021; batch adversarial loss: 0.481716\n",
      "epoch 148; iter: 0; batch classifier loss: 0.185300; batch adversarial loss: 0.752459\n",
      "epoch 149; iter: 0; batch classifier loss: 0.111598; batch adversarial loss: 0.520510\n",
      "epoch 150; iter: 0; batch classifier loss: 0.115405; batch adversarial loss: 0.558090\n",
      "epoch 151; iter: 0; batch classifier loss: 0.140815; batch adversarial loss: 0.598151\n",
      "epoch 152; iter: 0; batch classifier loss: 0.094189; batch adversarial loss: 0.525712\n",
      "epoch 153; iter: 0; batch classifier loss: 0.076227; batch adversarial loss: 0.462689\n",
      "epoch 154; iter: 0; batch classifier loss: 0.143135; batch adversarial loss: 0.566097\n",
      "epoch 155; iter: 0; batch classifier loss: 0.086219; batch adversarial loss: 0.518736\n",
      "epoch 156; iter: 0; batch classifier loss: 0.116412; batch adversarial loss: 0.441378\n",
      "epoch 157; iter: 0; batch classifier loss: 0.066104; batch adversarial loss: 0.439824\n",
      "epoch 158; iter: 0; batch classifier loss: 0.130035; batch adversarial loss: 0.548546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.143864; batch adversarial loss: 0.459983\n",
      "epoch 160; iter: 0; batch classifier loss: 0.097857; batch adversarial loss: 0.467635\n",
      "epoch 161; iter: 0; batch classifier loss: 0.093401; batch adversarial loss: 0.482778\n",
      "epoch 162; iter: 0; batch classifier loss: 0.097866; batch adversarial loss: 0.409131\n",
      "epoch 163; iter: 0; batch classifier loss: 0.110804; batch adversarial loss: 0.494689\n",
      "epoch 164; iter: 0; batch classifier loss: 0.083994; batch adversarial loss: 0.496823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.093721; batch adversarial loss: 0.472589\n",
      "epoch 166; iter: 0; batch classifier loss: 0.127975; batch adversarial loss: 0.492982\n",
      "epoch 167; iter: 0; batch classifier loss: 0.077809; batch adversarial loss: 0.478243\n",
      "epoch 168; iter: 0; batch classifier loss: 0.110235; batch adversarial loss: 0.461822\n",
      "epoch 169; iter: 0; batch classifier loss: 0.089382; batch adversarial loss: 0.519531\n",
      "epoch 170; iter: 0; batch classifier loss: 0.140064; batch adversarial loss: 0.394480\n",
      "epoch 171; iter: 0; batch classifier loss: 0.084335; batch adversarial loss: 0.422541\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047905; batch adversarial loss: 0.427824\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031182; batch adversarial loss: 0.397410\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035828; batch adversarial loss: 0.471705\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019350; batch adversarial loss: 0.455186\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031973; batch adversarial loss: 0.467634\n",
      "epoch 177; iter: 0; batch classifier loss: 0.059186; batch adversarial loss: 0.464324\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034192; batch adversarial loss: 0.423889\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029716; batch adversarial loss: 0.501931\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044482; batch adversarial loss: 0.559212\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020409; batch adversarial loss: 0.462704\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029896; batch adversarial loss: 0.359187\n",
      "epoch 183; iter: 0; batch classifier loss: 0.071627; batch adversarial loss: 0.355639\n",
      "epoch 184; iter: 0; batch classifier loss: 0.084385; batch adversarial loss: 0.387111\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029646; batch adversarial loss: 0.503587\n",
      "epoch 186; iter: 0; batch classifier loss: 0.089338; batch adversarial loss: 0.443755\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045325; batch adversarial loss: 0.424086\n",
      "epoch 188; iter: 0; batch classifier loss: 0.044253; batch adversarial loss: 0.562030\n",
      "epoch 189; iter: 0; batch classifier loss: 0.077801; batch adversarial loss: 0.392508\n",
      "epoch 190; iter: 0; batch classifier loss: 0.080104; batch adversarial loss: 0.428123\n",
      "epoch 191; iter: 0; batch classifier loss: 0.095258; batch adversarial loss: 0.552847\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041979; batch adversarial loss: 0.444806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.079311; batch adversarial loss: 0.459373\n",
      "epoch 194; iter: 0; batch classifier loss: 0.060201; batch adversarial loss: 0.430569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 195; iter: 0; batch classifier loss: 0.069462; batch adversarial loss: 0.447533\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.430443\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046063; batch adversarial loss: 0.484596\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041433; batch adversarial loss: 0.472473\n",
      "epoch 199; iter: 0; batch classifier loss: 0.108966; batch adversarial loss: 0.422483\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba3c48",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5bfa9a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbf8f6c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d7d982",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cf196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a15e577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982c7db",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21317cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9371f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b534568b14897b8686d22a9c79d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 20:15:17 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 20:15:17 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([331, 157, 559, 553, 580, 169, 561, 452, 180, 257, 160, 289, 197,\n",
      "             39, 290,  68,  56, 638,  54, 120],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 400, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42164aebf0d74a5992f0ca8075639200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a128a0a62f40fb9bd0b88e41d55103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6300cf6db9cc4bcf95389b1f6e9b8108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e75feb8b5c4e00a1fc551544462dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090775d7",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34860037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d17ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8359a8",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6c7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df04f9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb38f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
