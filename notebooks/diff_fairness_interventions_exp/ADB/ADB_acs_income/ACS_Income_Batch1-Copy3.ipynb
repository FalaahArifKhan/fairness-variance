{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e0dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0fe77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:55:54.052462Z",
     "start_time": "2024-01-06T10:55:54.038357Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall virny -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1967cc16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T10:56:09.679156Z",
     "start_time": "2024-01-06T10:56:09.668186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install using an HTTP link\n",
    "# !pip install git+https://github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors\n",
    "\n",
    "# Install using an SSH link\n",
    "# !pip install git+ssh://git@github.com/DataResponsibly/Virny.git@feature/prepare_experiments_for_inprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3f9af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.457257Z",
     "start_time": "2024-01-06T11:15:26.114625Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6d5921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.466361Z",
     "start_time": "2024-01-06T11:15:26.457627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0a91ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:26.478005Z",
     "start_time": "2024-01-06T11:15:26.467253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/dh3553/projects/fairness-variance\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"fairness-variance\":\n",
    "    os.chdir(\"../../../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab49c8",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d1b09b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.734704Z",
     "start_time": "2024-01-06T11:15:28.036691Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj\n",
    "from virny.datasets import ACSIncomeDataset\n",
    "\n",
    "from configs.constants import TEST_SET_FRACTION, EXPERIMENT_SEEDS\n",
    "\n",
    "from source.experiment_interface import run_exp_iter_with_inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa806c63",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9844be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.772286Z",
     "start_time": "2024-01-06T11:15:31.735883Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "EXPERIMENT_NAME = 'ADB_acs_income'\n",
    "DB_COLLECTION_NAME = 'one_repair_lvl_many_models'\n",
    "FAIRNESS_INTERVENTION_NAME = 'ADB'\n",
    "FAIR_INTERVENTION_PARAMS_LST = ['debiased_classifier']\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', 'diff_fairness_interventions_exp',\n",
    "                                     FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME)\n",
    "\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'notebooks', 'diff_fairness_interventions_exp',\n",
    "                                FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, 'folk_GA_2018_config.yaml')\n",
    "metrics_computation_config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee56fd",
   "metadata": {},
   "source": [
    "## Define a db writer and custom fields to insert into your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccb73a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:31.813421Z",
     "start_time": "2024-01-06T11:15:31.771935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairness_variance'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./configs/secrets.env')\n",
    "os.getenv(\"DB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73a52b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.096974Z",
     "start_time": "2024-01-06T11:15:31.811395Z"
    }
   },
   "outputs": [],
   "source": [
    "from source.utils.db_functions import connect_to_mongodb\n",
    "\n",
    "client, collection_obj, db_writer_func = connect_to_mongodb(DB_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8bca2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:32.138747Z",
     "start_time": "2024-01-06T11:15:32.097343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  bbba3cc4-760b-4e93-bb97-3a2077202cce\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "#     'session_uuid': str(uuid.uuid4()),\n",
    "    'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdff0b6",
   "metadata": {},
   "source": [
    "## Initialize custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d54e965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:33.528732Z",
     "start_time": "2024-01-06T11:15:33.475702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL</th>\n",
       "      <th>COW</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4110</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4130</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SCHL COW MAR  OCCP POBP RELP SEX RAC1P  AGEP  WKHP\n",
       "0   23   7   3   230   36    0   1     1    55  55.0\n",
       "1   16   1   5  4110   13    2   2     1    20  35.0\n",
       "2   16   4   3  4130   51    0   2     1    59  30.0\n",
       "3   18   4   1  4020   13    0   1     2    43  40.0\n",
       "4   14   1   1  8300   20    1   2     2    33  20.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = ACSIncomeDataset(state=['GA'], year=2018, with_nulls=False,\n",
    "                               subsample_size=15_000, subsample_seed=42)\n",
    "data_loader.X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0c8171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:34.580537Z",
     "start_time": "2024-01-06T11:15:34.538952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.X_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62dd25c",
   "metadata": {},
   "source": [
    "## Run experiment iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bf411",
   "metadata": {},
   "source": [
    "### Experiment iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dedecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:37.135031Z",
     "start_time": "2024-01-06T11:15:37.105079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 1\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-06T11:15:44.618835Z",
     "start_time": "2024-01-06T11:15:43.745040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 100,\n",
      " 'experiment_iteration': 'Exp_iter_1',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 100,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc38ee9c876469caefd18438ec5bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:04:06 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=724)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([10155, 11689, 12599, 12193,  8678,  8217,  4670, 12087,  5235,\n",
      "             4189,  7278, 10642,  5284,  7002, 14642, 10594,  7701,  8686,\n",
      "             8665,  6253],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0a941737a8417cb4f7946d88b35431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8c917d6c174359aff6c81106515faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.703511; batch adversarial loss: 0.868435\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433493; batch adversarial loss: 0.870017\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396227; batch adversarial loss: 0.863279\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393296; batch adversarial loss: 0.784595\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335170; batch adversarial loss: 0.729312\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302273; batch adversarial loss: 0.718420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340553; batch adversarial loss: 0.671042\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317702; batch adversarial loss: 0.662751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252170; batch adversarial loss: 0.648393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292380; batch adversarial loss: 0.613334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278500; batch adversarial loss: 0.582467\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315808; batch adversarial loss: 0.541661\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282857; batch adversarial loss: 0.547508\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245198; batch adversarial loss: 0.570313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295288; batch adversarial loss: 0.471533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.255773; batch adversarial loss: 0.471669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227866; batch adversarial loss: 0.459387\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265236; batch adversarial loss: 0.390383\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221451; batch adversarial loss: 0.492176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.235272; batch adversarial loss: 0.424545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.222551; batch adversarial loss: 0.393122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.149757; batch adversarial loss: 0.495092\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181218; batch adversarial loss: 0.386822\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139735; batch adversarial loss: 0.457702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153798; batch adversarial loss: 0.475582\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132027; batch adversarial loss: 0.444322\n",
      "epoch 26; iter: 0; batch classifier loss: 0.129947; batch adversarial loss: 0.370190\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140482; batch adversarial loss: 0.350910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166366; batch adversarial loss: 0.481889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178009; batch adversarial loss: 0.357132\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc859f",
   "metadata": {},
   "source": [
    "### Experiment iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c9de4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EXPERIMENT_SEEDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configs for an experiment iteration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m exp_iter_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m experiment_seed \u001b[38;5;241m=\u001b[39m \u001b[43mEXPERIMENT_SEEDS\u001b[49m[exp_iter_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m tuned_params_filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m ]\n\u001b[1;32m      6\u001b[0m tuned_params_df_paths \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_fairness_interventions_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                       FAIRNESS_INTERVENTION_NAME, EXPERIMENT_NAME, tuned_params_filename)\n\u001b[1;32m      8\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m tuned_params_filename \u001b[38;5;129;01min\u001b[39;00m tuned_params_filenames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EXPERIMENT_SEEDS' is not defined"
     ]
    }
   ],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 2\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a4cba0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:56.249510Z",
     "start_time": "2024-01-04T20:53:56.233525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 200,\n",
      " 'experiment_iteration': 'Exp_iter_2',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 200,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645c6009d3b48d29619a238bc476502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 17:15:39 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 17:15:39 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([322, 293, 576, 300, 391, 343, 294, 558, 560, 439, 355, 440, 277,\n",
      "            492, 644, 639, 589, 259, 313, 129],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 200, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c0277603884950a0c35cc9dcc3f539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7137564e8e0d4fcbbbfaaf03d73e170a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30ab3dbbfe4acb8557a8c1e2d6556b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a36e32d08b44c1b01ae496881c6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5eeec",
   "metadata": {},
   "source": [
    "### Experiment iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec85dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 3\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d39810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:46.750905Z",
     "start_time": "2024-01-04T20:53:46.744795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 300,\n",
      " 'experiment_iteration': 'Exp_iter_3',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 300,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48b0aa26f024ad1b1089190e134193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 19:29:01 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-04 19:29:01 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([250, 438, 479, 326,  46, 565, 534, 382, 377, 457,  97, 388, 123,\n",
      "            156, 430, 466,  38, 474, 167, 524],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 300, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddcae8f6fc4651885a3144088ae9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43ba8d965cc436a91f10cc39b3d5e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94495e7bec64c9ebf4c05cdd52e605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f7167dd20740a68f8f90158ec19560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f43f46",
   "metadata": {},
   "source": [
    "### Experiment iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989d5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 4\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79737200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:37.675129Z",
     "start_time": "2024-01-04T20:53:37.670178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:42 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 400,\n",
      " 'experiment_iteration': 'Exp_iter_4',\n",
      " 'fair_intervention_params_lst': \"['debiased_classifier']\",\n",
      " 'model_init_seed': 400,\n",
      " 'session_uuid': 'bbba3cc4-760b-4e93-bb97-3a2077202cce'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f15ca514c24250baae29947c011d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 22:05:42 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  debiased_classifier\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__SCHL_1', 'cat__SCHL_10', 'cat__SCHL_11', 'cat__SCHL_12',\n",
      "       'cat__SCHL_13', 'cat__SCHL_14', 'cat__SCHL_15', 'cat__SCHL_16',\n",
      "       'cat__SCHL_17', 'cat__SCHL_18',\n",
      "       ...\n",
      "       'cat__RELP_3', 'cat__RELP_4', 'cat__RELP_5', 'cat__RELP_6',\n",
      "       'cat__RELP_7', 'cat__RELP_8', 'cat__RELP_9', 'num__AGEP', 'num__WKHP',\n",
      "       'SEX&RAC1P_binary'],\n",
      "      dtype='object', length=719)\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 6425, 11811, 14319,  3284,  9129,  5763,  7549,  1393, 13879,\n",
      "            14802,  8634, 10336,  1486, 14287,  8890,  5961, 10137, 14550,\n",
      "            14981, 11017],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 6425, 11811, 14319,  3284,  9129,  5763,  7549,  1393, 13879,\n",
      "            14802,  8634, 10336,  1486, 14287,  8890,  5961, 10137, 14550,\n",
      "            14981, 11017],\n",
      "           dtype='int64')\n",
      "Using AdversarialDebiasing postprocessor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09041f878d241cea094ebf95e7b0263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98a3c2442b440ed86a0d1a747429081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dh3553/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.677585; batch adversarial loss: 0.597467\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494032; batch adversarial loss: 0.621915\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343630; batch adversarial loss: 0.612986\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444474; batch adversarial loss: 0.684488\n",
      "epoch 4; iter: 0; batch classifier loss: 0.480369; batch adversarial loss: 0.634319\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462111; batch adversarial loss: 0.651401\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520511; batch adversarial loss: 0.577156\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600537; batch adversarial loss: 0.549101\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512906; batch adversarial loss: 0.566630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478765; batch adversarial loss: 0.505048\n",
      "epoch 10; iter: 0; batch classifier loss: 0.452138; batch adversarial loss: 0.516545\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379780; batch adversarial loss: 0.516095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296681; batch adversarial loss: 0.553755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294567; batch adversarial loss: 0.495939\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290359; batch adversarial loss: 0.485542\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279763; batch adversarial loss: 0.468822\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328016; batch adversarial loss: 0.463370\n",
      "epoch 17; iter: 0; batch classifier loss: 0.175520; batch adversarial loss: 0.479446\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235636; batch adversarial loss: 0.418109\n",
      "epoch 19; iter: 0; batch classifier loss: 0.304983; batch adversarial loss: 0.430678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.290490; batch adversarial loss: 0.589192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.227882; batch adversarial loss: 0.500970\n",
      "epoch 22; iter: 0; batch classifier loss: 0.209464; batch adversarial loss: 0.533213\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202635; batch adversarial loss: 0.487425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266342; batch adversarial loss: 0.489860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207500; batch adversarial loss: 0.478546\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187412; batch adversarial loss: 0.486227\n",
      "epoch 27; iter: 0; batch classifier loss: 0.217744; batch adversarial loss: 0.440796\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155322; batch adversarial loss: 0.554118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178584; batch adversarial loss: 0.504525\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205027; batch adversarial loss: 0.468809\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169682; batch adversarial loss: 0.537480\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238010; batch adversarial loss: 0.398399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149759; batch adversarial loss: 0.563608\n",
      "epoch 34; iter: 0; batch classifier loss: 0.249391; batch adversarial loss: 0.475642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217722; batch adversarial loss: 0.396348\n",
      "epoch 36; iter: 0; batch classifier loss: 0.256043; batch adversarial loss: 0.465455\n",
      "epoch 37; iter: 0; batch classifier loss: 0.275169; batch adversarial loss: 0.397339\n",
      "epoch 38; iter: 0; batch classifier loss: 0.179900; batch adversarial loss: 0.469442\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164528; batch adversarial loss: 0.406609\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272439; batch adversarial loss: 0.439327\n",
      "epoch 41; iter: 0; batch classifier loss: 0.235621; batch adversarial loss: 0.403650\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163740; batch adversarial loss: 0.516382\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287203; batch adversarial loss: 0.470001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263721; batch adversarial loss: 0.470282\n",
      "epoch 45; iter: 0; batch classifier loss: 0.223470; batch adversarial loss: 0.449829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188920; batch adversarial loss: 0.445649\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238150; batch adversarial loss: 0.446623\n",
      "epoch 48; iter: 0; batch classifier loss: 0.243410; batch adversarial loss: 0.398549\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206664; batch adversarial loss: 0.409990\n",
      "epoch 50; iter: 0; batch classifier loss: 0.238673; batch adversarial loss: 0.543801\n",
      "epoch 51; iter: 0; batch classifier loss: 0.232303; batch adversarial loss: 0.471425\n",
      "epoch 52; iter: 0; batch classifier loss: 0.178592; batch adversarial loss: 0.506790\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169735; batch adversarial loss: 0.507016\n",
      "epoch 54; iter: 0; batch classifier loss: 0.145613; batch adversarial loss: 0.458901\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091042; batch adversarial loss: 0.382478\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081239; batch adversarial loss: 0.332024\n",
      "epoch 57; iter: 0; batch classifier loss: 0.064565; batch adversarial loss: 0.418316\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084135; batch adversarial loss: 0.438611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081728; batch adversarial loss: 0.501748\n",
      "epoch 60; iter: 0; batch classifier loss: 0.051519; batch adversarial loss: 0.476280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082260; batch adversarial loss: 0.483405\n",
      "epoch 62; iter: 0; batch classifier loss: 0.055671; batch adversarial loss: 0.500921\n",
      "epoch 63; iter: 0; batch classifier loss: 0.079861; batch adversarial loss: 0.400138\n",
      "epoch 64; iter: 0; batch classifier loss: 0.042044; batch adversarial loss: 0.456079\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075114; batch adversarial loss: 0.522836\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095858; batch adversarial loss: 0.431558\n",
      "epoch 67; iter: 0; batch classifier loss: 0.104784; batch adversarial loss: 0.358178\n",
      "epoch 68; iter: 0; batch classifier loss: 0.049774; batch adversarial loss: 0.479419\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074417; batch adversarial loss: 0.399703\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175533; batch adversarial loss: 0.482976\n",
      "epoch 71; iter: 0; batch classifier loss: 0.098303; batch adversarial loss: 0.426656\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072285; batch adversarial loss: 0.424910\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090912; batch adversarial loss: 0.493658\n",
      "epoch 74; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.447593\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062345; batch adversarial loss: 0.420400\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089332; batch adversarial loss: 0.515641\n",
      "epoch 77; iter: 0; batch classifier loss: 0.053263; batch adversarial loss: 0.467007\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075314; batch adversarial loss: 0.499013\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093429; batch adversarial loss: 0.475902\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073826; batch adversarial loss: 0.364081\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041186; batch adversarial loss: 0.448927\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085881; batch adversarial loss: 0.428351\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052667; batch adversarial loss: 0.439071\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085198; batch adversarial loss: 0.493060\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060204; batch adversarial loss: 0.465847\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058818; batch adversarial loss: 0.486078\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089025; batch adversarial loss: 0.373588\n",
      "epoch 88; iter: 0; batch classifier loss: 0.122275; batch adversarial loss: 0.473287\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056465; batch adversarial loss: 0.419336\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064235; batch adversarial loss: 0.387060\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095631; batch adversarial loss: 0.446659\n",
      "epoch 92; iter: 0; batch classifier loss: 0.073357; batch adversarial loss: 0.459973\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086467; batch adversarial loss: 0.433222\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053262; batch adversarial loss: 0.327575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049027; batch adversarial loss: 0.427224\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054600; batch adversarial loss: 0.335743\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043081; batch adversarial loss: 0.436787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.092907; batch adversarial loss: 0.474625\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059615; batch adversarial loss: 0.437229\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069312; batch adversarial loss: 0.438006\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067654; batch adversarial loss: 0.376961\n",
      "epoch 102; iter: 0; batch classifier loss: 0.115202; batch adversarial loss: 0.503067\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051429; batch adversarial loss: 0.540152\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082609; batch adversarial loss: 0.418987\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059490; batch adversarial loss: 0.410923\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041964; batch adversarial loss: 0.406170\n",
      "epoch 107; iter: 0; batch classifier loss: 0.087973; batch adversarial loss: 0.398447\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068366; batch adversarial loss: 0.353975\n",
      "epoch 109; iter: 0; batch classifier loss: 0.089199; batch adversarial loss: 0.363918\n",
      "epoch 110; iter: 0; batch classifier loss: 0.091749; batch adversarial loss: 0.520863\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044945; batch adversarial loss: 0.308539\n",
      "epoch 112; iter: 0; batch classifier loss: 0.082981; batch adversarial loss: 0.435149\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031508; batch adversarial loss: 0.372200\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043708; batch adversarial loss: 0.394490\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076513; batch adversarial loss: 0.397988\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052899; batch adversarial loss: 0.337791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047179; batch adversarial loss: 0.374484\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073339; batch adversarial loss: 0.418593\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069820; batch adversarial loss: 0.349832\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027665; batch adversarial loss: 0.452518\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046644; batch adversarial loss: 0.362976\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067825; batch adversarial loss: 0.436089\n",
      "epoch 123; iter: 0; batch classifier loss: 0.081402; batch adversarial loss: 0.445416\n",
      "epoch 124; iter: 0; batch classifier loss: 0.074252; batch adversarial loss: 0.331923\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061428; batch adversarial loss: 0.405274\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066500; batch adversarial loss: 0.438266\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057897; batch adversarial loss: 0.433534\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055456; batch adversarial loss: 0.437143\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057020; batch adversarial loss: 0.402228\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039973; batch adversarial loss: 0.617406\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031303; batch adversarial loss: 0.451034\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039692; batch adversarial loss: 0.312245\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036988; batch adversarial loss: 0.425950\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061961; batch adversarial loss: 0.498278\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045601; batch adversarial loss: 0.336057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043822; batch adversarial loss: 0.463227\n",
      "epoch 137; iter: 0; batch classifier loss: 0.062045; batch adversarial loss: 0.427228\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036203; batch adversarial loss: 0.411154\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.433250\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055640; batch adversarial loss: 0.465170\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043931; batch adversarial loss: 0.360165\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032369; batch adversarial loss: 0.515398\n",
      "epoch 143; iter: 0; batch classifier loss: 0.090800; batch adversarial loss: 0.357294\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052775; batch adversarial loss: 0.412289\n",
      "epoch 145; iter: 0; batch classifier loss: 0.077973; batch adversarial loss: 0.356442\n",
      "epoch 146; iter: 0; batch classifier loss: 0.066719; batch adversarial loss: 0.431802\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027593; batch adversarial loss: 0.452749\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036292; batch adversarial loss: 0.450940\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063413; batch adversarial loss: 0.494290\n",
      "epoch 150; iter: 0; batch classifier loss: 0.058019; batch adversarial loss: 0.393746\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043987; batch adversarial loss: 0.407169\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034434; batch adversarial loss: 0.417265\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032567; batch adversarial loss: 0.427204\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029734; batch adversarial loss: 0.427762\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055337; batch adversarial loss: 0.466948\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.405963\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029167; batch adversarial loss: 0.545996\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036884; batch adversarial loss: 0.503752\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021793; batch adversarial loss: 0.446099\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031465; batch adversarial loss: 0.383564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039948; batch adversarial loss: 0.422536\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021735; batch adversarial loss: 0.502069\n",
      "epoch 163; iter: 0; batch classifier loss: 0.054758; batch adversarial loss: 0.507334\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042307; batch adversarial loss: 0.520752\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036194; batch adversarial loss: 0.474382\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050389; batch adversarial loss: 0.448968\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068876; batch adversarial loss: 0.446868\n",
      "epoch 168; iter: 0; batch classifier loss: 0.054571; batch adversarial loss: 0.436152\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048713; batch adversarial loss: 0.453770\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035297; batch adversarial loss: 0.505699\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.456653\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011465; batch adversarial loss: 0.406177\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034700; batch adversarial loss: 0.493439\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039839; batch adversarial loss: 0.456324\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026427; batch adversarial loss: 0.444734\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023472; batch adversarial loss: 0.464828\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026017; batch adversarial loss: 0.464331\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031279; batch adversarial loss: 0.435661\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038529; batch adversarial loss: 0.404468\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018845; batch adversarial loss: 0.454727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036912; batch adversarial loss: 0.421497\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020753; batch adversarial loss: 0.414005\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017256; batch adversarial loss: 0.433008\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021275; batch adversarial loss: 0.391332\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013447; batch adversarial loss: 0.451468\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029607; batch adversarial loss: 0.380053\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045318; batch adversarial loss: 0.461566\n",
      "epoch 188; iter: 0; batch classifier loss: 0.036138; batch adversarial loss: 0.527901\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027750; batch adversarial loss: 0.391333\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032263; batch adversarial loss: 0.569522\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037699; batch adversarial loss: 0.413805\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020140; batch adversarial loss: 0.426685\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014637; batch adversarial loss: 0.563790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.026717; batch adversarial loss: 0.455519\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046704; batch adversarial loss: 0.397846\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021990; batch adversarial loss: 0.457392\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019459; batch adversarial loss: 0.434058\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023451; batch adversarial loss: 0.464300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029725; batch adversarial loss: 0.436588\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691162; batch adversarial loss: 0.775759\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517347; batch adversarial loss: 0.696251\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490119; batch adversarial loss: 0.697759\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363612; batch adversarial loss: 0.660582\n",
      "epoch 4; iter: 0; batch classifier loss: 0.332740; batch adversarial loss: 0.632286\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366495; batch adversarial loss: 0.559807\n",
      "epoch 6; iter: 0; batch classifier loss: 0.229602; batch adversarial loss: 0.574614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.252096; batch adversarial loss: 0.537885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277270; batch adversarial loss: 0.522472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291185; batch adversarial loss: 0.512775\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280167; batch adversarial loss: 0.463671\n",
      "epoch 11; iter: 0; batch classifier loss: 0.258253; batch adversarial loss: 0.507506\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250757; batch adversarial loss: 0.468068\n",
      "epoch 13; iter: 0; batch classifier loss: 0.258727; batch adversarial loss: 0.390608\n",
      "epoch 14; iter: 0; batch classifier loss: 0.204567; batch adversarial loss: 0.464537\n",
      "epoch 15; iter: 0; batch classifier loss: 0.155724; batch adversarial loss: 0.474565\n",
      "epoch 16; iter: 0; batch classifier loss: 0.164875; batch adversarial loss: 0.415533\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184222; batch adversarial loss: 0.377102\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183346; batch adversarial loss: 0.366186\n",
      "epoch 19; iter: 0; batch classifier loss: 0.163468; batch adversarial loss: 0.407510\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197089; batch adversarial loss: 0.439469\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183406; batch adversarial loss: 0.460342\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241156; batch adversarial loss: 0.335994\n",
      "epoch 23; iter: 0; batch classifier loss: 0.147847; batch adversarial loss: 0.369199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170292; batch adversarial loss: 0.337863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201042; batch adversarial loss: 0.435395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166770; batch adversarial loss: 0.415355\n",
      "epoch 27; iter: 0; batch classifier loss: 0.143110; batch adversarial loss: 0.421237\n",
      "epoch 28; iter: 0; batch classifier loss: 0.152994; batch adversarial loss: 0.385131\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157989; batch adversarial loss: 0.491603\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178567; batch adversarial loss: 0.412480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.128772; batch adversarial loss: 0.381873\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154258; batch adversarial loss: 0.431492\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139596; batch adversarial loss: 0.427363\n",
      "epoch 34; iter: 0; batch classifier loss: 0.108791; batch adversarial loss: 0.403625\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108030; batch adversarial loss: 0.371876\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169246; batch adversarial loss: 0.420265\n",
      "epoch 37; iter: 0; batch classifier loss: 0.108973; batch adversarial loss: 0.363932\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115199; batch adversarial loss: 0.377031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140049; batch adversarial loss: 0.378335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154180; batch adversarial loss: 0.544036\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096809; batch adversarial loss: 0.405895\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110830; batch adversarial loss: 0.348187\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083454; batch adversarial loss: 0.315450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116194; batch adversarial loss: 0.486267\n",
      "epoch 45; iter: 0; batch classifier loss: 0.137337; batch adversarial loss: 0.493410\n",
      "epoch 46; iter: 0; batch classifier loss: 0.076647; batch adversarial loss: 0.398924\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082548; batch adversarial loss: 0.375643\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077781; batch adversarial loss: 0.355509\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124597; batch adversarial loss: 0.407034\n",
      "epoch 50; iter: 0; batch classifier loss: 0.114000; batch adversarial loss: 0.425803\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091325; batch adversarial loss: 0.361810\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058186; batch adversarial loss: 0.429525\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097566; batch adversarial loss: 0.492446\n",
      "epoch 54; iter: 0; batch classifier loss: 0.058628; batch adversarial loss: 0.366248\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108280; batch adversarial loss: 0.460148\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102813; batch adversarial loss: 0.368761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084131; batch adversarial loss: 0.455645\n",
      "epoch 58; iter: 0; batch classifier loss: 0.089810; batch adversarial loss: 0.449239\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083831; batch adversarial loss: 0.362231\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068619; batch adversarial loss: 0.349615\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078398; batch adversarial loss: 0.363629\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082787; batch adversarial loss: 0.421350\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119930; batch adversarial loss: 0.411103\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082984; batch adversarial loss: 0.422400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072816; batch adversarial loss: 0.505001\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097017; batch adversarial loss: 0.496871\n",
      "epoch 67; iter: 0; batch classifier loss: 0.047490; batch adversarial loss: 0.428864\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070923; batch adversarial loss: 0.335550\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063551; batch adversarial loss: 0.488091\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078873; batch adversarial loss: 0.447155\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051087; batch adversarial loss: 0.431964\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082693; batch adversarial loss: 0.380059\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062782; batch adversarial loss: 0.316593\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081018; batch adversarial loss: 0.446309\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078450; batch adversarial loss: 0.436164\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082482; batch adversarial loss: 0.359083\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051024; batch adversarial loss: 0.378937\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056887; batch adversarial loss: 0.424862\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074636; batch adversarial loss: 0.390949\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102148; batch adversarial loss: 0.410961\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037364; batch adversarial loss: 0.419141\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032907; batch adversarial loss: 0.397393\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051945; batch adversarial loss: 0.424146\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070527; batch adversarial loss: 0.393121\n",
      "epoch 85; iter: 0; batch classifier loss: 0.031941; batch adversarial loss: 0.389920\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052061; batch adversarial loss: 0.386863\n",
      "epoch 87; iter: 0; batch classifier loss: 0.089203; batch adversarial loss: 0.339777\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038891; batch adversarial loss: 0.535455\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058671; batch adversarial loss: 0.471623\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047970; batch adversarial loss: 0.475135\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073979; batch adversarial loss: 0.449575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.035515; batch adversarial loss: 0.461024\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053993; batch adversarial loss: 0.469486\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043373; batch adversarial loss: 0.575634\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053282; batch adversarial loss: 0.398619\n",
      "epoch 96; iter: 0; batch classifier loss: 0.018305; batch adversarial loss: 0.474450\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.418197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.019587; batch adversarial loss: 0.462062\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054890; batch adversarial loss: 0.410374\n",
      "epoch 100; iter: 0; batch classifier loss: 0.027867; batch adversarial loss: 0.393113\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046659; batch adversarial loss: 0.464048\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034023; batch adversarial loss: 0.479258\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025303; batch adversarial loss: 0.400925\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036926; batch adversarial loss: 0.382679\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.407777\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052542; batch adversarial loss: 0.452106\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036360; batch adversarial loss: 0.459917\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039880; batch adversarial loss: 0.438484\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042743; batch adversarial loss: 0.390593\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060602; batch adversarial loss: 0.435999\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027801; batch adversarial loss: 0.512504\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044180; batch adversarial loss: 0.349737\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023575; batch adversarial loss: 0.575407\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054693; batch adversarial loss: 0.531336\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037968; batch adversarial loss: 0.441833\n",
      "epoch 116; iter: 0; batch classifier loss: 0.098225; batch adversarial loss: 0.572680\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062419; batch adversarial loss: 0.534766\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028143; batch adversarial loss: 0.496533\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082135; batch adversarial loss: 0.618915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.099917; batch adversarial loss: 0.543265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079451; batch adversarial loss: 0.568830\n",
      "epoch 122; iter: 0; batch classifier loss: 0.140470; batch adversarial loss: 0.594747\n",
      "epoch 123; iter: 0; batch classifier loss: 0.104038; batch adversarial loss: 0.537499\n",
      "epoch 124; iter: 0; batch classifier loss: 0.082087; batch adversarial loss: 0.526664\n",
      "epoch 125; iter: 0; batch classifier loss: 0.158086; batch adversarial loss: 0.621120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.120198; batch adversarial loss: 0.597249\n",
      "epoch 127; iter: 0; batch classifier loss: 0.117856; batch adversarial loss: 0.623167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.155081; batch adversarial loss: 0.603320\n",
      "epoch 129; iter: 0; batch classifier loss: 0.078353; batch adversarial loss: 0.545692\n",
      "epoch 130; iter: 0; batch classifier loss: 0.079063; batch adversarial loss: 0.540950\n",
      "epoch 131; iter: 0; batch classifier loss: 0.144832; batch adversarial loss: 0.593484\n",
      "epoch 132; iter: 0; batch classifier loss: 0.142970; batch adversarial loss: 0.662153\n",
      "epoch 133; iter: 0; batch classifier loss: 0.131696; batch adversarial loss: 0.535334\n",
      "epoch 134; iter: 0; batch classifier loss: 0.144076; batch adversarial loss: 0.583914\n",
      "epoch 135; iter: 0; batch classifier loss: 0.104597; batch adversarial loss: 0.539577\n",
      "epoch 136; iter: 0; batch classifier loss: 0.163441; batch adversarial loss: 0.623277\n",
      "epoch 137; iter: 0; batch classifier loss: 0.123658; batch adversarial loss: 0.563972\n",
      "epoch 138; iter: 0; batch classifier loss: 0.168697; batch adversarial loss: 0.523175\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060293; batch adversarial loss: 0.496710\n",
      "epoch 140; iter: 0; batch classifier loss: 0.118820; batch adversarial loss: 0.531965\n",
      "epoch 141; iter: 0; batch classifier loss: 0.078995; batch adversarial loss: 0.410272\n",
      "epoch 142; iter: 0; batch classifier loss: 0.120253; batch adversarial loss: 0.452023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.138506; batch adversarial loss: 0.475213\n",
      "epoch 144; iter: 0; batch classifier loss: 0.141540; batch adversarial loss: 0.532608\n",
      "epoch 145; iter: 0; batch classifier loss: 0.124829; batch adversarial loss: 0.511537\n",
      "epoch 146; iter: 0; batch classifier loss: 0.114418; batch adversarial loss: 0.507736\n",
      "epoch 147; iter: 0; batch classifier loss: 0.079369; batch adversarial loss: 0.414074\n",
      "epoch 148; iter: 0; batch classifier loss: 0.154488; batch adversarial loss: 0.531115\n",
      "epoch 149; iter: 0; batch classifier loss: 0.158179; batch adversarial loss: 0.608276\n",
      "epoch 150; iter: 0; batch classifier loss: 0.071313; batch adversarial loss: 0.396516\n",
      "epoch 151; iter: 0; batch classifier loss: 0.131009; batch adversarial loss: 0.521155\n",
      "epoch 152; iter: 0; batch classifier loss: 0.089920; batch adversarial loss: 0.420923\n",
      "epoch 153; iter: 0; batch classifier loss: 0.206399; batch adversarial loss: 0.638072\n",
      "epoch 154; iter: 0; batch classifier loss: 0.096728; batch adversarial loss: 0.471880\n",
      "epoch 155; iter: 0; batch classifier loss: 0.170096; batch adversarial loss: 0.570510\n",
      "epoch 156; iter: 0; batch classifier loss: 0.130407; batch adversarial loss: 0.541573\n",
      "epoch 157; iter: 0; batch classifier loss: 0.114088; batch adversarial loss: 0.451851\n",
      "epoch 158; iter: 0; batch classifier loss: 0.117335; batch adversarial loss: 0.530499\n",
      "epoch 159; iter: 0; batch classifier loss: 0.095386; batch adversarial loss: 0.528533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.096960; batch adversarial loss: 0.536452\n",
      "epoch 161; iter: 0; batch classifier loss: 0.080270; batch adversarial loss: 0.554396\n",
      "epoch 162; iter: 0; batch classifier loss: 0.119087; batch adversarial loss: 0.506855\n",
      "epoch 163; iter: 0; batch classifier loss: 0.123215; batch adversarial loss: 0.469098\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047546; batch adversarial loss: 0.407475\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026884; batch adversarial loss: 0.444052\n",
      "epoch 166; iter: 0; batch classifier loss: 0.063495; batch adversarial loss: 0.516099\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042377; batch adversarial loss: 0.440445\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048097; batch adversarial loss: 0.479732\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033310; batch adversarial loss: 0.413937\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033786; batch adversarial loss: 0.393027\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032692; batch adversarial loss: 0.475335\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030193; batch adversarial loss: 0.500654\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.402526\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032630; batch adversarial loss: 0.497939\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.434029\n",
      "epoch 176; iter: 0; batch classifier loss: 0.063029; batch adversarial loss: 0.464396\n",
      "epoch 177; iter: 0; batch classifier loss: 0.060732; batch adversarial loss: 0.394360\n",
      "epoch 178; iter: 0; batch classifier loss: 0.099883; batch adversarial loss: 0.434690\n",
      "epoch 179; iter: 0; batch classifier loss: 0.055391; batch adversarial loss: 0.517346\n",
      "epoch 180; iter: 0; batch classifier loss: 0.049329; batch adversarial loss: 0.405708\n",
      "epoch 181; iter: 0; batch classifier loss: 0.097883; batch adversarial loss: 0.460036\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051477; batch adversarial loss: 0.466017\n",
      "epoch 183; iter: 0; batch classifier loss: 0.062026; batch adversarial loss: 0.420560\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040326; batch adversarial loss: 0.530304\n",
      "epoch 185; iter: 0; batch classifier loss: 0.082285; batch adversarial loss: 0.439724\n",
      "epoch 186; iter: 0; batch classifier loss: 0.109168; batch adversarial loss: 0.507654\n",
      "epoch 187; iter: 0; batch classifier loss: 0.095936; batch adversarial loss: 0.383567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.092775; batch adversarial loss: 0.471160\n",
      "epoch 189; iter: 0; batch classifier loss: 0.089877; batch adversarial loss: 0.474139\n",
      "epoch 190; iter: 0; batch classifier loss: 0.062360; batch adversarial loss: 0.474472\n",
      "epoch 191; iter: 0; batch classifier loss: 0.057286; batch adversarial loss: 0.540327\n",
      "epoch 192; iter: 0; batch classifier loss: 0.063210; batch adversarial loss: 0.406073\n",
      "epoch 193; iter: 0; batch classifier loss: 0.120133; batch adversarial loss: 0.426558\n",
      "epoch 194; iter: 0; batch classifier loss: 0.065770; batch adversarial loss: 0.494092\n",
      "epoch 195; iter: 0; batch classifier loss: 0.053260; batch adversarial loss: 0.552893\n",
      "epoch 196; iter: 0; batch classifier loss: 0.100893; batch adversarial loss: 0.541806\n",
      "epoch 197; iter: 0; batch classifier loss: 0.072765; batch adversarial loss: 0.359674\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044716; batch adversarial loss: 0.478982\n",
      "epoch 199; iter: 0; batch classifier loss: 0.084155; batch adversarial loss: 0.499561\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690624; batch adversarial loss: 0.660932\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511508; batch adversarial loss: 0.642292\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433470; batch adversarial loss: 0.620321\n",
      "epoch 3; iter: 0; batch classifier loss: 0.417849; batch adversarial loss: 0.600048\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446603; batch adversarial loss: 0.590473\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462805; batch adversarial loss: 0.611942\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535414; batch adversarial loss: 0.561099\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463284; batch adversarial loss: 0.547630\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602596; batch adversarial loss: 0.562015\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404013; batch adversarial loss: 0.526928\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405217; batch adversarial loss: 0.522203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339124; batch adversarial loss: 0.515500\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345348; batch adversarial loss: 0.479063\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352288; batch adversarial loss: 0.544996\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356110; batch adversarial loss: 0.521913\n",
      "epoch 15; iter: 0; batch classifier loss: 0.431886; batch adversarial loss: 0.483198\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367560; batch adversarial loss: 0.508132\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278374; batch adversarial loss: 0.437789\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279151; batch adversarial loss: 0.498205\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277534; batch adversarial loss: 0.478707\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294017; batch adversarial loss: 0.487566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312607; batch adversarial loss: 0.476689\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226009; batch adversarial loss: 0.485494\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176260; batch adversarial loss: 0.502842\n",
      "epoch 24; iter: 0; batch classifier loss: 0.219298; batch adversarial loss: 0.506928\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256154; batch adversarial loss: 0.464799\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228003; batch adversarial loss: 0.451669\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169670; batch adversarial loss: 0.461368\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205066; batch adversarial loss: 0.396212\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167662; batch adversarial loss: 0.453677\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142309; batch adversarial loss: 0.492016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134079; batch adversarial loss: 0.464964\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208135; batch adversarial loss: 0.426700\n",
      "epoch 33; iter: 0; batch classifier loss: 0.170202; batch adversarial loss: 0.372416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161881; batch adversarial loss: 0.477645\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160822; batch adversarial loss: 0.431511\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143224; batch adversarial loss: 0.469123\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154773; batch adversarial loss: 0.495813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140504; batch adversarial loss: 0.467826\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143879; batch adversarial loss: 0.410653\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129930; batch adversarial loss: 0.444411\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110040; batch adversarial loss: 0.397523\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118242; batch adversarial loss: 0.516414\n",
      "epoch 43; iter: 0; batch classifier loss: 0.157100; batch adversarial loss: 0.425860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125750; batch adversarial loss: 0.498227\n",
      "epoch 45; iter: 0; batch classifier loss: 0.122437; batch adversarial loss: 0.476231\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144306; batch adversarial loss: 0.450240\n",
      "epoch 47; iter: 0; batch classifier loss: 0.064114; batch adversarial loss: 0.457273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106943; batch adversarial loss: 0.510151\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107838; batch adversarial loss: 0.417163\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127748; batch adversarial loss: 0.457361\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114263; batch adversarial loss: 0.462924\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071699; batch adversarial loss: 0.483943\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101000; batch adversarial loss: 0.436527\n",
      "epoch 54; iter: 0; batch classifier loss: 0.110910; batch adversarial loss: 0.416880\n",
      "epoch 55; iter: 0; batch classifier loss: 0.053240; batch adversarial loss: 0.437981\n",
      "epoch 56; iter: 0; batch classifier loss: 0.105653; batch adversarial loss: 0.484026\n",
      "epoch 57; iter: 0; batch classifier loss: 0.111249; batch adversarial loss: 0.457467\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118759; batch adversarial loss: 0.477021\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070330; batch adversarial loss: 0.407907\n",
      "epoch 60; iter: 0; batch classifier loss: 0.068490; batch adversarial loss: 0.514447\n",
      "epoch 61; iter: 0; batch classifier loss: 0.050037; batch adversarial loss: 0.498316\n",
      "epoch 62; iter: 0; batch classifier loss: 0.025568; batch adversarial loss: 0.420545\n",
      "epoch 63; iter: 0; batch classifier loss: 0.143751; batch adversarial loss: 0.439871\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075086; batch adversarial loss: 0.408826\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059237; batch adversarial loss: 0.391638\n",
      "epoch 66; iter: 0; batch classifier loss: 0.043694; batch adversarial loss: 0.512232\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057160; batch adversarial loss: 0.479127\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090060; batch adversarial loss: 0.481138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.038249; batch adversarial loss: 0.436854\n",
      "epoch 70; iter: 0; batch classifier loss: 0.039200; batch adversarial loss: 0.421003\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080592; batch adversarial loss: 0.455818\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057141; batch adversarial loss: 0.535452\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085266; batch adversarial loss: 0.441179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.149057; batch adversarial loss: 0.402579\n",
      "epoch 75; iter: 0; batch classifier loss: 0.045528; batch adversarial loss: 0.469902\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053801; batch adversarial loss: 0.425600\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106448; batch adversarial loss: 0.423214\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047898; batch adversarial loss: 0.465748\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099881; batch adversarial loss: 0.519440\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.476116\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047201; batch adversarial loss: 0.418475\n",
      "epoch 82; iter: 0; batch classifier loss: 0.073996; batch adversarial loss: 0.459916\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053710; batch adversarial loss: 0.495094\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068329; batch adversarial loss: 0.405736\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074478; batch adversarial loss: 0.356538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.024421; batch adversarial loss: 0.485896\n",
      "epoch 87; iter: 0; batch classifier loss: 0.043781; batch adversarial loss: 0.496965\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056679; batch adversarial loss: 0.481908\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095726; batch adversarial loss: 0.438418\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077794; batch adversarial loss: 0.568404\n",
      "epoch 91; iter: 0; batch classifier loss: 0.030707; batch adversarial loss: 0.462547\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043535; batch adversarial loss: 0.378637\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061954; batch adversarial loss: 0.503463\n",
      "epoch 94; iter: 0; batch classifier loss: 0.063644; batch adversarial loss: 0.402103\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066397; batch adversarial loss: 0.541272\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065964; batch adversarial loss: 0.379810\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035406; batch adversarial loss: 0.547794\n",
      "epoch 98; iter: 0; batch classifier loss: 0.027186; batch adversarial loss: 0.430177\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061819; batch adversarial loss: 0.500042\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048075; batch adversarial loss: 0.515349\n",
      "epoch 101; iter: 0; batch classifier loss: 0.133361; batch adversarial loss: 0.404285\n",
      "epoch 102; iter: 0; batch classifier loss: 0.011199; batch adversarial loss: 0.497332\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045885; batch adversarial loss: 0.435021\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037912; batch adversarial loss: 0.452997\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026195; batch adversarial loss: 0.474020\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062264; batch adversarial loss: 0.512485\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027966; batch adversarial loss: 0.414033\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019325; batch adversarial loss: 0.395934\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041738; batch adversarial loss: 0.426744\n",
      "epoch 110; iter: 0; batch classifier loss: 0.023183; batch adversarial loss: 0.542789\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018745; batch adversarial loss: 0.386242\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035445; batch adversarial loss: 0.406330\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025145; batch adversarial loss: 0.484592\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050151; batch adversarial loss: 0.413642\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032665; batch adversarial loss: 0.497133\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062949; batch adversarial loss: 0.496516\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025755; batch adversarial loss: 0.411920\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024972; batch adversarial loss: 0.396365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.455573\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038324; batch adversarial loss: 0.476732\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026115; batch adversarial loss: 0.378835\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040968; batch adversarial loss: 0.434967\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035262; batch adversarial loss: 0.427792\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064279; batch adversarial loss: 0.446234\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054456; batch adversarial loss: 0.401906\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065317; batch adversarial loss: 0.391048\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024088; batch adversarial loss: 0.373145\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026804; batch adversarial loss: 0.530950\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024448; batch adversarial loss: 0.392081\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045926; batch adversarial loss: 0.378627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024688; batch adversarial loss: 0.367005\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022242; batch adversarial loss: 0.516014\n",
      "epoch 133; iter: 0; batch classifier loss: 0.009033; batch adversarial loss: 0.473163\n",
      "epoch 134; iter: 0; batch classifier loss: 0.018058; batch adversarial loss: 0.537996\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054608; batch adversarial loss: 0.426580\n",
      "epoch 136; iter: 0; batch classifier loss: 0.008021; batch adversarial loss: 0.430877\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055158; batch adversarial loss: 0.415938\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035438; batch adversarial loss: 0.541541\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023043; batch adversarial loss: 0.474389\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037552; batch adversarial loss: 0.461705\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017560; batch adversarial loss: 0.472307\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015857; batch adversarial loss: 0.445788\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023636; batch adversarial loss: 0.385564\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030544; batch adversarial loss: 0.510289\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021306; batch adversarial loss: 0.481444\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041583; batch adversarial loss: 0.504365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057013; batch adversarial loss: 0.383076\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008486; batch adversarial loss: 0.380436\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.367503\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021469; batch adversarial loss: 0.411106\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021379; batch adversarial loss: 0.441489\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026912; batch adversarial loss: 0.419457\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019787; batch adversarial loss: 0.408709\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010147; batch adversarial loss: 0.386019\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015985; batch adversarial loss: 0.436558\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032874; batch adversarial loss: 0.456183\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021298; batch adversarial loss: 0.443916\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014587; batch adversarial loss: 0.478840\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018221; batch adversarial loss: 0.412684\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014571; batch adversarial loss: 0.601134\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035356; batch adversarial loss: 0.531586\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030457; batch adversarial loss: 0.443061\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014525; batch adversarial loss: 0.439814\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015678; batch adversarial loss: 0.455053\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029540; batch adversarial loss: 0.474554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.077907; batch adversarial loss: 0.390097\n",
      "epoch 167; iter: 0; batch classifier loss: 0.019099; batch adversarial loss: 0.424923\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019844; batch adversarial loss: 0.393711\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017374; batch adversarial loss: 0.471841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032796; batch adversarial loss: 0.417833\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029646; batch adversarial loss: 0.463512\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010676; batch adversarial loss: 0.523832\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013561; batch adversarial loss: 0.500827\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030309; batch adversarial loss: 0.425156\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011197; batch adversarial loss: 0.505401\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013380; batch adversarial loss: 0.490437\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052049; batch adversarial loss: 0.494354\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012411; batch adversarial loss: 0.402348\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036208; batch adversarial loss: 0.449642\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039931; batch adversarial loss: 0.512189\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005011; batch adversarial loss: 0.395075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.007312; batch adversarial loss: 0.417935\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042422; batch adversarial loss: 0.479892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.436517\n",
      "epoch 185; iter: 0; batch classifier loss: 0.003595; batch adversarial loss: 0.472004\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005912; batch adversarial loss: 0.552139\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041908; batch adversarial loss: 0.377948\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009638; batch adversarial loss: 0.548584\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014235; batch adversarial loss: 0.412675\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010063; batch adversarial loss: 0.481055\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020305; batch adversarial loss: 0.432207\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011233; batch adversarial loss: 0.389521\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022988; batch adversarial loss: 0.379903\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011780; batch adversarial loss: 0.612039\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024591; batch adversarial loss: 0.499304\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018746; batch adversarial loss: 0.538018\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.514490\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017684; batch adversarial loss: 0.486662\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022888; batch adversarial loss: 0.477758\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713172; batch adversarial loss: 0.566677\n",
      "epoch 1; iter: 0; batch classifier loss: 0.393895; batch adversarial loss: 0.583592\n",
      "epoch 2; iter: 0; batch classifier loss: 0.470532; batch adversarial loss: 0.599997\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369717; batch adversarial loss: 0.548512\n",
      "epoch 4; iter: 0; batch classifier loss: 0.324024; batch adversarial loss: 0.573882\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.544749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492406; batch adversarial loss: 0.686402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.395806; batch adversarial loss: 0.541818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446275; batch adversarial loss: 0.516366\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581340; batch adversarial loss: 0.544938\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519470; batch adversarial loss: 0.524481\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373608; batch adversarial loss: 0.507546\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503647; batch adversarial loss: 0.497258\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327152; batch adversarial loss: 0.482498\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308321; batch adversarial loss: 0.516326\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230233; batch adversarial loss: 0.507855\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332443; batch adversarial loss: 0.455393\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256716; batch adversarial loss: 0.560996\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244914; batch adversarial loss: 0.446363\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230487; batch adversarial loss: 0.498909\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302367; batch adversarial loss: 0.519507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261870; batch adversarial loss: 0.485610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284470; batch adversarial loss: 0.467217\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191217; batch adversarial loss: 0.432916\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194316; batch adversarial loss: 0.540883\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190817; batch adversarial loss: 0.410736\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191955; batch adversarial loss: 0.362890\n",
      "epoch 27; iter: 0; batch classifier loss: 0.183882; batch adversarial loss: 0.475782\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214209; batch adversarial loss: 0.412845\n",
      "epoch 29; iter: 0; batch classifier loss: 0.152216; batch adversarial loss: 0.442898\n",
      "epoch 30; iter: 0; batch classifier loss: 0.133817; batch adversarial loss: 0.444578\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152536; batch adversarial loss: 0.438467\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121086; batch adversarial loss: 0.316906\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111309; batch adversarial loss: 0.486163\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128426; batch adversarial loss: 0.391879\n",
      "epoch 35; iter: 0; batch classifier loss: 0.128227; batch adversarial loss: 0.451382\n",
      "epoch 36; iter: 0; batch classifier loss: 0.133648; batch adversarial loss: 0.464192\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114702; batch adversarial loss: 0.482603\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122657; batch adversarial loss: 0.448689\n",
      "epoch 39; iter: 0; batch classifier loss: 0.156340; batch adversarial loss: 0.424706\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129347; batch adversarial loss: 0.487028\n",
      "epoch 41; iter: 0; batch classifier loss: 0.151383; batch adversarial loss: 0.424502\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111911; batch adversarial loss: 0.431388\n",
      "epoch 43; iter: 0; batch classifier loss: 0.163307; batch adversarial loss: 0.361422\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111297; batch adversarial loss: 0.398024\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109216; batch adversarial loss: 0.373864\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098346; batch adversarial loss: 0.437777\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070913; batch adversarial loss: 0.449888\n",
      "epoch 48; iter: 0; batch classifier loss: 0.127982; batch adversarial loss: 0.384991\n",
      "epoch 49; iter: 0; batch classifier loss: 0.166103; batch adversarial loss: 0.498533\n",
      "epoch 50; iter: 0; batch classifier loss: 0.088962; batch adversarial loss: 0.445329\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093668; batch adversarial loss: 0.411486\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125210; batch adversarial loss: 0.459630\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105599; batch adversarial loss: 0.489834\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124857; batch adversarial loss: 0.451194\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089213; batch adversarial loss: 0.416170\n",
      "epoch 56; iter: 0; batch classifier loss: 0.145756; batch adversarial loss: 0.462768\n",
      "epoch 57; iter: 0; batch classifier loss: 0.127549; batch adversarial loss: 0.469161\n",
      "epoch 58; iter: 0; batch classifier loss: 0.120323; batch adversarial loss: 0.473014\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142629; batch adversarial loss: 0.455740\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129944; batch adversarial loss: 0.384694\n",
      "epoch 61; iter: 0; batch classifier loss: 0.103949; batch adversarial loss: 0.450328\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092905; batch adversarial loss: 0.476254\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120011; batch adversarial loss: 0.399368\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106177; batch adversarial loss: 0.536540\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082920; batch adversarial loss: 0.378169\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118720; batch adversarial loss: 0.509211\n",
      "epoch 67; iter: 0; batch classifier loss: 0.135947; batch adversarial loss: 0.527397\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085186; batch adversarial loss: 0.504236\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058190; batch adversarial loss: 0.480236\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076413; batch adversarial loss: 0.399192\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082134; batch adversarial loss: 0.417888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.151708; batch adversarial loss: 0.413983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087041; batch adversarial loss: 0.440736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.150007; batch adversarial loss: 0.451093\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054469; batch adversarial loss: 0.387815\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100914; batch adversarial loss: 0.483509\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099224; batch adversarial loss: 0.348980\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054919; batch adversarial loss: 0.438967\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088167; batch adversarial loss: 0.426385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.093932; batch adversarial loss: 0.438787\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074632; batch adversarial loss: 0.427280\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086657; batch adversarial loss: 0.445152\n",
      "epoch 83; iter: 0; batch classifier loss: 0.129437; batch adversarial loss: 0.355072\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059545; batch adversarial loss: 0.403906\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079176; batch adversarial loss: 0.395937\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083385; batch adversarial loss: 0.546249\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066603; batch adversarial loss: 0.420625\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064148; batch adversarial loss: 0.536502\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061969; batch adversarial loss: 0.418343\n",
      "epoch 90; iter: 0; batch classifier loss: 0.129671; batch adversarial loss: 0.409000\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113477; batch adversarial loss: 0.406319\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075055; batch adversarial loss: 0.467617\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041507; batch adversarial loss: 0.402219\n",
      "epoch 94; iter: 0; batch classifier loss: 0.138766; batch adversarial loss: 0.395692\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085416; batch adversarial loss: 0.541437\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033215; batch adversarial loss: 0.425576\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048860; batch adversarial loss: 0.468984\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080201; batch adversarial loss: 0.453859\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070757; batch adversarial loss: 0.389400\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094609; batch adversarial loss: 0.438050\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090216; batch adversarial loss: 0.384961\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047854; batch adversarial loss: 0.462926\n",
      "epoch 103; iter: 0; batch classifier loss: 0.029699; batch adversarial loss: 0.458220\n",
      "epoch 104; iter: 0; batch classifier loss: 0.049220; batch adversarial loss: 0.400629\n",
      "epoch 105; iter: 0; batch classifier loss: 0.104535; batch adversarial loss: 0.439460\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030135; batch adversarial loss: 0.483895\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048710; batch adversarial loss: 0.338930\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055697; batch adversarial loss: 0.464499\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041030; batch adversarial loss: 0.509293\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040469; batch adversarial loss: 0.371929\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049524; batch adversarial loss: 0.437865\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028337; batch adversarial loss: 0.443868\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041773; batch adversarial loss: 0.382612\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040979; batch adversarial loss: 0.403761\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078415; batch adversarial loss: 0.387272\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053284; batch adversarial loss: 0.465619\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033146; batch adversarial loss: 0.458765\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050611; batch adversarial loss: 0.451646\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054566; batch adversarial loss: 0.405936\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034568; batch adversarial loss: 0.461632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027642; batch adversarial loss: 0.444117\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028970; batch adversarial loss: 0.429964\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075381; batch adversarial loss: 0.346332\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032537; batch adversarial loss: 0.453851\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.394123\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055364; batch adversarial loss: 0.400791\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034635; batch adversarial loss: 0.366702\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035266; batch adversarial loss: 0.405396\n",
      "epoch 129; iter: 0; batch classifier loss: 0.067463; batch adversarial loss: 0.459696\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036603; batch adversarial loss: 0.425263\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049835; batch adversarial loss: 0.482846\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029415; batch adversarial loss: 0.414130\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037183; batch adversarial loss: 0.575586\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026327; batch adversarial loss: 0.425591\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062326; batch adversarial loss: 0.500509\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065296; batch adversarial loss: 0.381659\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047701; batch adversarial loss: 0.499706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032576; batch adversarial loss: 0.366438\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020933; batch adversarial loss: 0.399235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023729; batch adversarial loss: 0.486596\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021077; batch adversarial loss: 0.460341\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047507; batch adversarial loss: 0.386670\n",
      "epoch 143; iter: 0; batch classifier loss: 0.011532; batch adversarial loss: 0.412014\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034173; batch adversarial loss: 0.377275\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043038; batch adversarial loss: 0.496152\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029746; batch adversarial loss: 0.478876\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044574; batch adversarial loss: 0.447817\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022185; batch adversarial loss: 0.516196\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046693; batch adversarial loss: 0.300598\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.399623\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051728; batch adversarial loss: 0.412178\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026363; batch adversarial loss: 0.472664\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016555; batch adversarial loss: 0.483592\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047449; batch adversarial loss: 0.431731\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018321; batch adversarial loss: 0.373138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043215; batch adversarial loss: 0.388979\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019491; batch adversarial loss: 0.357871\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039369; batch adversarial loss: 0.401982\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032134; batch adversarial loss: 0.464313\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047474; batch adversarial loss: 0.494640\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029323; batch adversarial loss: 0.348047\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052114; batch adversarial loss: 0.533012\n",
      "epoch 163; iter: 0; batch classifier loss: 0.037443; batch adversarial loss: 0.445969\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038048; batch adversarial loss: 0.461942\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017859; batch adversarial loss: 0.472598\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011429; batch adversarial loss: 0.410325\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029516; batch adversarial loss: 0.392049\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025290; batch adversarial loss: 0.427448\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009375; batch adversarial loss: 0.487367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032201; batch adversarial loss: 0.447654\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015147; batch adversarial loss: 0.417599\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021546; batch adversarial loss: 0.557155\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008959; batch adversarial loss: 0.412864\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025325; batch adversarial loss: 0.490371\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013393; batch adversarial loss: 0.485016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.417600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008682; batch adversarial loss: 0.357621\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005969; batch adversarial loss: 0.357745\n",
      "epoch 179; iter: 0; batch classifier loss: 0.003934; batch adversarial loss: 0.504068\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029780; batch adversarial loss: 0.369916\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030841; batch adversarial loss: 0.358115\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012834; batch adversarial loss: 0.493780\n",
      "epoch 183; iter: 0; batch classifier loss: 0.004945; batch adversarial loss: 0.398160\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016377; batch adversarial loss: 0.416082\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008848; batch adversarial loss: 0.456246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030889; batch adversarial loss: 0.450854\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.497646\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010506; batch adversarial loss: 0.417146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.019566; batch adversarial loss: 0.340199\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015326; batch adversarial loss: 0.485822\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007759; batch adversarial loss: 0.396352\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009541; batch adversarial loss: 0.554865\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031349; batch adversarial loss: 0.524549\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017749; batch adversarial loss: 0.482715\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019512; batch adversarial loss: 0.433723\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010784; batch adversarial loss: 0.471888\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008675; batch adversarial loss: 0.459332\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025356; batch adversarial loss: 0.448609\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014716; batch adversarial loss: 0.435958\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669259; batch adversarial loss: 0.673750\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443809; batch adversarial loss: 0.641918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416502; batch adversarial loss: 0.598596\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355346; batch adversarial loss: 0.582515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290074; batch adversarial loss: 0.560860\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339640; batch adversarial loss: 0.559776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.311998; batch adversarial loss: 0.554660\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264558; batch adversarial loss: 0.530502\n",
      "epoch 8; iter: 0; batch classifier loss: 0.199348; batch adversarial loss: 0.502319\n",
      "epoch 9; iter: 0; batch classifier loss: 0.259413; batch adversarial loss: 0.514091\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257107; batch adversarial loss: 0.500112\n",
      "epoch 11; iter: 0; batch classifier loss: 0.221241; batch adversarial loss: 0.539790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.214157; batch adversarial loss: 0.479848\n",
      "epoch 13; iter: 0; batch classifier loss: 0.193611; batch adversarial loss: 0.475886\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209101; batch adversarial loss: 0.391505\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196655; batch adversarial loss: 0.506327\n",
      "epoch 16; iter: 0; batch classifier loss: 0.133718; batch adversarial loss: 0.458118\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164620; batch adversarial loss: 0.518034\n",
      "epoch 18; iter: 0; batch classifier loss: 0.175984; batch adversarial loss: 0.429562\n",
      "epoch 19; iter: 0; batch classifier loss: 0.148237; batch adversarial loss: 0.478281\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171602; batch adversarial loss: 0.419703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.191494; batch adversarial loss: 0.472567\n",
      "epoch 22; iter: 0; batch classifier loss: 0.109956; batch adversarial loss: 0.450690\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210636; batch adversarial loss: 0.586391\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176257; batch adversarial loss: 0.453363\n",
      "epoch 25; iter: 0; batch classifier loss: 0.168819; batch adversarial loss: 0.423583\n",
      "epoch 26; iter: 0; batch classifier loss: 0.232919; batch adversarial loss: 0.512555\n",
      "epoch 27; iter: 0; batch classifier loss: 0.169194; batch adversarial loss: 0.432394\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176543; batch adversarial loss: 0.407910\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160078; batch adversarial loss: 0.492800\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205558; batch adversarial loss: 0.449882\n",
      "epoch 31; iter: 0; batch classifier loss: 0.305963; batch adversarial loss: 0.527517\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311469; batch adversarial loss: 0.486957\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219831; batch adversarial loss: 0.486263\n",
      "epoch 34; iter: 0; batch classifier loss: 0.164193; batch adversarial loss: 0.434493\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140167; batch adversarial loss: 0.465623\n",
      "epoch 36; iter: 0; batch classifier loss: 0.106071; batch adversarial loss: 0.421279\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123045; batch adversarial loss: 0.564563\n",
      "epoch 38; iter: 0; batch classifier loss: 0.187089; batch adversarial loss: 0.439476\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113916; batch adversarial loss: 0.374907\n",
      "epoch 40; iter: 0; batch classifier loss: 0.121100; batch adversarial loss: 0.526321\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109832; batch adversarial loss: 0.437580\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097145; batch adversarial loss: 0.474494\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097497; batch adversarial loss: 0.375882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.116685; batch adversarial loss: 0.493752\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120823; batch adversarial loss: 0.422493\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107990; batch adversarial loss: 0.477342\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098382; batch adversarial loss: 0.481997\n",
      "epoch 48; iter: 0; batch classifier loss: 0.062816; batch adversarial loss: 0.441466\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095969; batch adversarial loss: 0.500183\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085010; batch adversarial loss: 0.514726\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080416; batch adversarial loss: 0.451749\n",
      "epoch 52; iter: 0; batch classifier loss: 0.078214; batch adversarial loss: 0.464426\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104493; batch adversarial loss: 0.463744\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114265; batch adversarial loss: 0.411601\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081832; batch adversarial loss: 0.374127\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129662; batch adversarial loss: 0.426893\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110800; batch adversarial loss: 0.459449\n",
      "epoch 58; iter: 0; batch classifier loss: 0.116644; batch adversarial loss: 0.494805\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087372; batch adversarial loss: 0.465872\n",
      "epoch 60; iter: 0; batch classifier loss: 0.126182; batch adversarial loss: 0.500399\n",
      "epoch 61; iter: 0; batch classifier loss: 0.123851; batch adversarial loss: 0.351881\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081618; batch adversarial loss: 0.442961\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083399; batch adversarial loss: 0.504105\n",
      "epoch 64; iter: 0; batch classifier loss: 0.136356; batch adversarial loss: 0.489595\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079773; batch adversarial loss: 0.339252\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054823; batch adversarial loss: 0.393290\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095502; batch adversarial loss: 0.479407\n",
      "epoch 68; iter: 0; batch classifier loss: 0.107329; batch adversarial loss: 0.455305\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110269; batch adversarial loss: 0.510243\n",
      "epoch 70; iter: 0; batch classifier loss: 0.093642; batch adversarial loss: 0.435197\n",
      "epoch 71; iter: 0; batch classifier loss: 0.120000; batch adversarial loss: 0.471095\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085294; batch adversarial loss: 0.473128\n",
      "epoch 73; iter: 0; batch classifier loss: 0.090900; batch adversarial loss: 0.433815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.103554; batch adversarial loss: 0.480220\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110848; batch adversarial loss: 0.530514\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116918; batch adversarial loss: 0.472606\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094256; batch adversarial loss: 0.411054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135344; batch adversarial loss: 0.455236\n",
      "epoch 79; iter: 0; batch classifier loss: 0.081345; batch adversarial loss: 0.518702\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.481106\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101109; batch adversarial loss: 0.406910\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056012; batch adversarial loss: 0.487920\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105254; batch adversarial loss: 0.463500\n",
      "epoch 84; iter: 0; batch classifier loss: 0.167252; batch adversarial loss: 0.469844\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082850; batch adversarial loss: 0.497564\n",
      "epoch 86; iter: 0; batch classifier loss: 0.123902; batch adversarial loss: 0.428367\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085329; batch adversarial loss: 0.409025\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116635; batch adversarial loss: 0.373719\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072345; batch adversarial loss: 0.478583\n",
      "epoch 90; iter: 0; batch classifier loss: 0.087864; batch adversarial loss: 0.385540\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064903; batch adversarial loss: 0.478245\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113839; batch adversarial loss: 0.375828\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058105; batch adversarial loss: 0.481618\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089002; batch adversarial loss: 0.573981\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072376; batch adversarial loss: 0.424934\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117097; batch adversarial loss: 0.397091\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048428; batch adversarial loss: 0.598992\n",
      "epoch 98; iter: 0; batch classifier loss: 0.085847; batch adversarial loss: 0.461308\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083345; batch adversarial loss: 0.484775\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075180; batch adversarial loss: 0.488522\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041972; batch adversarial loss: 0.555600\n",
      "epoch 102; iter: 0; batch classifier loss: 0.083954; batch adversarial loss: 0.514476\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059019; batch adversarial loss: 0.473089\n",
      "epoch 104; iter: 0; batch classifier loss: 0.124434; batch adversarial loss: 0.483613\n",
      "epoch 105; iter: 0; batch classifier loss: 0.039057; batch adversarial loss: 0.428835\n",
      "epoch 106; iter: 0; batch classifier loss: 0.074842; batch adversarial loss: 0.408376\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063875; batch adversarial loss: 0.406159\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070092; batch adversarial loss: 0.431292\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077008; batch adversarial loss: 0.519354\n",
      "epoch 110; iter: 0; batch classifier loss: 0.075910; batch adversarial loss: 0.452052\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073548; batch adversarial loss: 0.369254\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054686; batch adversarial loss: 0.561126\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057499; batch adversarial loss: 0.452947\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.470448\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054020; batch adversarial loss: 0.409161\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038498; batch adversarial loss: 0.454095\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040684; batch adversarial loss: 0.525917\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074183; batch adversarial loss: 0.427614\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050353; batch adversarial loss: 0.453384\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036762; batch adversarial loss: 0.481300\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060587; batch adversarial loss: 0.481749\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029146; batch adversarial loss: 0.495691\n",
      "epoch 123; iter: 0; batch classifier loss: 0.049000; batch adversarial loss: 0.567146\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049863; batch adversarial loss: 0.434058\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046177; batch adversarial loss: 0.499885\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040978; batch adversarial loss: 0.418816\n",
      "epoch 127; iter: 0; batch classifier loss: 0.072937; batch adversarial loss: 0.466262\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028098; batch adversarial loss: 0.527960\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.441833\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021690; batch adversarial loss: 0.436459\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053254; batch adversarial loss: 0.465191\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075668; batch adversarial loss: 0.426168\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026058; batch adversarial loss: 0.462132\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055334; batch adversarial loss: 0.414459\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039536; batch adversarial loss: 0.475301\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044733; batch adversarial loss: 0.523470\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.425059\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049427; batch adversarial loss: 0.530352\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029917; batch adversarial loss: 0.473018\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018568; batch adversarial loss: 0.359768\n",
      "epoch 141; iter: 0; batch classifier loss: 0.007832; batch adversarial loss: 0.454054\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028405; batch adversarial loss: 0.489691\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032468; batch adversarial loss: 0.415390\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024742; batch adversarial loss: 0.431217\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040990; batch adversarial loss: 0.597617\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018996; batch adversarial loss: 0.534254\n",
      "epoch 147; iter: 0; batch classifier loss: 0.094327; batch adversarial loss: 0.413725\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019960; batch adversarial loss: 0.448165\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034396; batch adversarial loss: 0.414078\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036315; batch adversarial loss: 0.447716\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031138; batch adversarial loss: 0.465585\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036955; batch adversarial loss: 0.417294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028008; batch adversarial loss: 0.465373\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031117; batch adversarial loss: 0.498352\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030256; batch adversarial loss: 0.417711\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037784; batch adversarial loss: 0.452219\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020895; batch adversarial loss: 0.433311\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022938; batch adversarial loss: 0.468769\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018853; batch adversarial loss: 0.512291\n",
      "epoch 160; iter: 0; batch classifier loss: 0.065396; batch adversarial loss: 0.399212\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013484; batch adversarial loss: 0.562572\n",
      "epoch 162; iter: 0; batch classifier loss: 0.055661; batch adversarial loss: 0.483115\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059838; batch adversarial loss: 0.421613\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007304; batch adversarial loss: 0.505541\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014339; batch adversarial loss: 0.409674\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011906; batch adversarial loss: 0.482518\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049274; batch adversarial loss: 0.439101\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011569; batch adversarial loss: 0.432072\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022902; batch adversarial loss: 0.479929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.049229; batch adversarial loss: 0.455354\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023448; batch adversarial loss: 0.522650\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015342; batch adversarial loss: 0.470156\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028148; batch adversarial loss: 0.491410\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028752; batch adversarial loss: 0.486266\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035532; batch adversarial loss: 0.463968\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015649; batch adversarial loss: 0.454832\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033373; batch adversarial loss: 0.480376\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012067; batch adversarial loss: 0.482497\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013674; batch adversarial loss: 0.495583\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.448281\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031624; batch adversarial loss: 0.496153\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038003; batch adversarial loss: 0.432639\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033867; batch adversarial loss: 0.415207\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006850; batch adversarial loss: 0.446920\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024155; batch adversarial loss: 0.325091\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038215; batch adversarial loss: 0.417680\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011076; batch adversarial loss: 0.447652\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038205; batch adversarial loss: 0.390775\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023533; batch adversarial loss: 0.453270\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017677; batch adversarial loss: 0.479065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.041254; batch adversarial loss: 0.387409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026583; batch adversarial loss: 0.363439\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027901; batch adversarial loss: 0.456815\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030344; batch adversarial loss: 0.475552\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031672; batch adversarial loss: 0.451349\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036920; batch adversarial loss: 0.483111\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021267; batch adversarial loss: 0.516742\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031683; batch adversarial loss: 0.460347\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024154; batch adversarial loss: 0.348812\n",
      "epoch 0; iter: 0; batch classifier loss: 0.662245; batch adversarial loss: 0.686526\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553022; batch adversarial loss: 0.663846\n",
      "epoch 2; iter: 0; batch classifier loss: 0.471670; batch adversarial loss: 0.631914\n",
      "epoch 3; iter: 0; batch classifier loss: 0.453807; batch adversarial loss: 0.641070\n",
      "epoch 4; iter: 0; batch classifier loss: 0.338720; batch adversarial loss: 0.600515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420411; batch adversarial loss: 0.599815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469745; batch adversarial loss: 0.577300\n",
      "epoch 7; iter: 0; batch classifier loss: 0.457416; batch adversarial loss: 0.595085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393018; batch adversarial loss: 0.537995\n",
      "epoch 9; iter: 0; batch classifier loss: 0.375242; batch adversarial loss: 0.546304\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331678; batch adversarial loss: 0.523380\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388860; batch adversarial loss: 0.493410\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346871; batch adversarial loss: 0.476237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321460; batch adversarial loss: 0.564802\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345906; batch adversarial loss: 0.496950\n",
      "epoch 15; iter: 0; batch classifier loss: 0.407291; batch adversarial loss: 0.462378\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379786; batch adversarial loss: 0.522890\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330312; batch adversarial loss: 0.425968\n",
      "epoch 18; iter: 0; batch classifier loss: 0.399997; batch adversarial loss: 0.477681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335374; batch adversarial loss: 0.454288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233121; batch adversarial loss: 0.498052\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341544; batch adversarial loss: 0.489439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365692; batch adversarial loss: 0.426958\n",
      "epoch 23; iter: 0; batch classifier loss: 0.376723; batch adversarial loss: 0.435547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227711; batch adversarial loss: 0.514592\n",
      "epoch 25; iter: 0; batch classifier loss: 0.253011; batch adversarial loss: 0.461557\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250909; batch adversarial loss: 0.466197\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246474; batch adversarial loss: 0.461790\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196386; batch adversarial loss: 0.447102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217489; batch adversarial loss: 0.431957\n",
      "epoch 30; iter: 0; batch classifier loss: 0.209868; batch adversarial loss: 0.522936\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249735; batch adversarial loss: 0.408037\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257146; batch adversarial loss: 0.494105\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261731; batch adversarial loss: 0.378537\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250831; batch adversarial loss: 0.455329\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205050; batch adversarial loss: 0.476134\n",
      "epoch 36; iter: 0; batch classifier loss: 0.213995; batch adversarial loss: 0.461791\n",
      "epoch 37; iter: 0; batch classifier loss: 0.199798; batch adversarial loss: 0.471117\n",
      "epoch 38; iter: 0; batch classifier loss: 0.255040; batch adversarial loss: 0.396302\n",
      "epoch 39; iter: 0; batch classifier loss: 0.260620; batch adversarial loss: 0.380741\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193366; batch adversarial loss: 0.456833\n",
      "epoch 41; iter: 0; batch classifier loss: 0.225925; batch adversarial loss: 0.504003\n",
      "epoch 42; iter: 0; batch classifier loss: 0.203789; batch adversarial loss: 0.447505\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231167; batch adversarial loss: 0.411935\n",
      "epoch 44; iter: 0; batch classifier loss: 0.286860; batch adversarial loss: 0.377650\n",
      "epoch 45; iter: 0; batch classifier loss: 0.180073; batch adversarial loss: 0.482506\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200566; batch adversarial loss: 0.422772\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153693; batch adversarial loss: 0.423526\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193824; batch adversarial loss: 0.445724\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125139; batch adversarial loss: 0.460350\n",
      "epoch 50; iter: 0; batch classifier loss: 0.172061; batch adversarial loss: 0.485406\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211449; batch adversarial loss: 0.434138\n",
      "epoch 52; iter: 0; batch classifier loss: 0.207729; batch adversarial loss: 0.324604\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175176; batch adversarial loss: 0.459472\n",
      "epoch 54; iter: 0; batch classifier loss: 0.232019; batch adversarial loss: 0.335605\n",
      "epoch 55; iter: 0; batch classifier loss: 0.151487; batch adversarial loss: 0.420051\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114215; batch adversarial loss: 0.483856\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168901; batch adversarial loss: 0.505175\n",
      "epoch 58; iter: 0; batch classifier loss: 0.230077; batch adversarial loss: 0.434424\n",
      "epoch 59; iter: 0; batch classifier loss: 0.149340; batch adversarial loss: 0.422266\n",
      "epoch 60; iter: 0; batch classifier loss: 0.186244; batch adversarial loss: 0.497092\n",
      "epoch 61; iter: 0; batch classifier loss: 0.183555; batch adversarial loss: 0.444199\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216973; batch adversarial loss: 0.409368\n",
      "epoch 63; iter: 0; batch classifier loss: 0.175732; batch adversarial loss: 0.483285\n",
      "epoch 64; iter: 0; batch classifier loss: 0.176354; batch adversarial loss: 0.446502\n",
      "epoch 65; iter: 0; batch classifier loss: 0.250464; batch adversarial loss: 0.272662\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125751; batch adversarial loss: 0.396876\n",
      "epoch 67; iter: 0; batch classifier loss: 0.049857; batch adversarial loss: 0.570609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.058503; batch adversarial loss: 0.431001\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070281; batch adversarial loss: 0.430311\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060998; batch adversarial loss: 0.383304\n",
      "epoch 71; iter: 0; batch classifier loss: 0.041191; batch adversarial loss: 0.321700\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058209; batch adversarial loss: 0.307315\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076800; batch adversarial loss: 0.506230\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053367; batch adversarial loss: 0.521749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.095593; batch adversarial loss: 0.406830\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069309; batch adversarial loss: 0.439787\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064167; batch adversarial loss: 0.398600\n",
      "epoch 78; iter: 0; batch classifier loss: 0.063619; batch adversarial loss: 0.419256\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071747; batch adversarial loss: 0.455239\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057046; batch adversarial loss: 0.453554\n",
      "epoch 81; iter: 0; batch classifier loss: 0.023254; batch adversarial loss: 0.467619\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058562; batch adversarial loss: 0.496651\n",
      "epoch 83; iter: 0; batch classifier loss: 0.042571; batch adversarial loss: 0.323627\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065471; batch adversarial loss: 0.433676\n",
      "epoch 85; iter: 0; batch classifier loss: 0.079956; batch adversarial loss: 0.529187\n",
      "epoch 86; iter: 0; batch classifier loss: 0.087354; batch adversarial loss: 0.386408\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048639; batch adversarial loss: 0.380852\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060463; batch adversarial loss: 0.489143\n",
      "epoch 89; iter: 0; batch classifier loss: 0.045906; batch adversarial loss: 0.394565\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059414; batch adversarial loss: 0.381130\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058712; batch adversarial loss: 0.437815\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035682; batch adversarial loss: 0.430662\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067970; batch adversarial loss: 0.338191\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046036; batch adversarial loss: 0.423346\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043683; batch adversarial loss: 0.391089\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051883; batch adversarial loss: 0.483632\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076628; batch adversarial loss: 0.472902\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084614; batch adversarial loss: 0.415767\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039724; batch adversarial loss: 0.453467\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064603; batch adversarial loss: 0.375620\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058875; batch adversarial loss: 0.366057\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066644; batch adversarial loss: 0.430335\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055279; batch adversarial loss: 0.408539\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044977; batch adversarial loss: 0.442724\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072437; batch adversarial loss: 0.359493\n",
      "epoch 106; iter: 0; batch classifier loss: 0.091714; batch adversarial loss: 0.441664\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054800; batch adversarial loss: 0.470783\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064558; batch adversarial loss: 0.469289\n",
      "epoch 109; iter: 0; batch classifier loss: 0.049454; batch adversarial loss: 0.394061\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074784; batch adversarial loss: 0.434166\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074282; batch adversarial loss: 0.406452\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069350; batch adversarial loss: 0.407944\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.452088\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045497; batch adversarial loss: 0.419403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027260; batch adversarial loss: 0.464644\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056208; batch adversarial loss: 0.453063\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043643; batch adversarial loss: 0.419647\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062232; batch adversarial loss: 0.423205\n",
      "epoch 119; iter: 0; batch classifier loss: 0.100610; batch adversarial loss: 0.446616\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046972; batch adversarial loss: 0.449981\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065777; batch adversarial loss: 0.425247\n",
      "epoch 122; iter: 0; batch classifier loss: 0.078072; batch adversarial loss: 0.349396\n",
      "epoch 123; iter: 0; batch classifier loss: 0.074842; batch adversarial loss: 0.415024\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060797; batch adversarial loss: 0.504460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051313; batch adversarial loss: 0.439009\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057796; batch adversarial loss: 0.378126\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067701; batch adversarial loss: 0.442252\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036896; batch adversarial loss: 0.417232\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062630; batch adversarial loss: 0.506203\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056388; batch adversarial loss: 0.411249\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056025; batch adversarial loss: 0.414024\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063500; batch adversarial loss: 0.361989\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047972; batch adversarial loss: 0.459751\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035633; batch adversarial loss: 0.447795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046548; batch adversarial loss: 0.539828\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060761; batch adversarial loss: 0.477445\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053299; batch adversarial loss: 0.357205\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045081; batch adversarial loss: 0.472901\n",
      "epoch 139; iter: 0; batch classifier loss: 0.073036; batch adversarial loss: 0.398934\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045240; batch adversarial loss: 0.414549\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051572; batch adversarial loss: 0.398412\n",
      "epoch 142; iter: 0; batch classifier loss: 0.063533; batch adversarial loss: 0.397367\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049982; batch adversarial loss: 0.505124\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062453; batch adversarial loss: 0.480970\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050153; batch adversarial loss: 0.458874\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059641; batch adversarial loss: 0.406913\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042862; batch adversarial loss: 0.442711\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057333; batch adversarial loss: 0.469970\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047427; batch adversarial loss: 0.480033\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039654; batch adversarial loss: 0.470211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028452; batch adversarial loss: 0.373487\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044400; batch adversarial loss: 0.393605\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052494; batch adversarial loss: 0.415598\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.354103\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051786; batch adversarial loss: 0.408086\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045826; batch adversarial loss: 0.355677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.522697\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055920; batch adversarial loss: 0.419096\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035243; batch adversarial loss: 0.515444\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036425; batch adversarial loss: 0.377245\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039182; batch adversarial loss: 0.502234\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038068; batch adversarial loss: 0.394384\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032968; batch adversarial loss: 0.361525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.044164; batch adversarial loss: 0.464388\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036106; batch adversarial loss: 0.450208\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042224; batch adversarial loss: 0.339874\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038209; batch adversarial loss: 0.480476\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049894; batch adversarial loss: 0.560855\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023497; batch adversarial loss: 0.372495\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025262; batch adversarial loss: 0.437540\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024250; batch adversarial loss: 0.382061\n",
      "epoch 172; iter: 0; batch classifier loss: 0.060326; batch adversarial loss: 0.406834\n",
      "epoch 173; iter: 0; batch classifier loss: 0.045567; batch adversarial loss: 0.386616\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016626; batch adversarial loss: 0.448118\n",
      "epoch 175; iter: 0; batch classifier loss: 0.031025; batch adversarial loss: 0.458221\n",
      "epoch 176; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.471922\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019661; batch adversarial loss: 0.387113\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013869; batch adversarial loss: 0.440023\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025748; batch adversarial loss: 0.454858\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029222; batch adversarial loss: 0.452373\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034565; batch adversarial loss: 0.438506\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030844; batch adversarial loss: 0.440019\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027648; batch adversarial loss: 0.357214\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040998; batch adversarial loss: 0.517217\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046377; batch adversarial loss: 0.423970\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022874; batch adversarial loss: 0.420101\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046194; batch adversarial loss: 0.498197\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027201; batch adversarial loss: 0.394897\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046661; batch adversarial loss: 0.387605\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049445; batch adversarial loss: 0.424270\n",
      "epoch 191; iter: 0; batch classifier loss: 0.049415; batch adversarial loss: 0.363416\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025544; batch adversarial loss: 0.432948\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017605; batch adversarial loss: 0.408812\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049812; batch adversarial loss: 0.386189\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026252; batch adversarial loss: 0.473412\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030205; batch adversarial loss: 0.407476\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026549; batch adversarial loss: 0.456749\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017575; batch adversarial loss: 0.451203\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027650; batch adversarial loss: 0.539069\n",
      "epoch 0; iter: 0; batch classifier loss: 0.649982; batch adversarial loss: 0.568020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432253; batch adversarial loss: 0.623266\n",
      "epoch 2; iter: 0; batch classifier loss: 0.325056; batch adversarial loss: 0.712451\n",
      "epoch 3; iter: 0; batch classifier loss: 0.478393; batch adversarial loss: 0.648398\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384917; batch adversarial loss: 0.682866\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526948; batch adversarial loss: 0.618554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630429; batch adversarial loss: 0.617622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506989; batch adversarial loss: 0.635245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558672; batch adversarial loss: 0.578382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461517; batch adversarial loss: 0.544614\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438802; batch adversarial loss: 0.493631\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384229; batch adversarial loss: 0.460156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361434; batch adversarial loss: 0.487715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290717; batch adversarial loss: 0.497842\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308971; batch adversarial loss: 0.471412\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274478; batch adversarial loss: 0.429980\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346356; batch adversarial loss: 0.400298\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259772; batch adversarial loss: 0.520334\n",
      "epoch 18; iter: 0; batch classifier loss: 0.297201; batch adversarial loss: 0.484036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200778; batch adversarial loss: 0.431941\n",
      "epoch 20; iter: 0; batch classifier loss: 0.218876; batch adversarial loss: 0.448018\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259326; batch adversarial loss: 0.415283\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249837; batch adversarial loss: 0.420560\n",
      "epoch 23; iter: 0; batch classifier loss: 0.155413; batch adversarial loss: 0.541251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.176435; batch adversarial loss: 0.483769\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194348; batch adversarial loss: 0.473425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.201062; batch adversarial loss: 0.449279\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170602; batch adversarial loss: 0.481649\n",
      "epoch 28; iter: 0; batch classifier loss: 0.196993; batch adversarial loss: 0.406644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163913; batch adversarial loss: 0.531773\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215491; batch adversarial loss: 0.480420\n",
      "epoch 31; iter: 0; batch classifier loss: 0.159286; batch adversarial loss: 0.521511\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168213; batch adversarial loss: 0.413142\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176344; batch adversarial loss: 0.514111\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165064; batch adversarial loss: 0.363179\n",
      "epoch 35; iter: 0; batch classifier loss: 0.179641; batch adversarial loss: 0.513122\n",
      "epoch 36; iter: 0; batch classifier loss: 0.157735; batch adversarial loss: 0.486598\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179046; batch adversarial loss: 0.446248\n",
      "epoch 38; iter: 0; batch classifier loss: 0.203827; batch adversarial loss: 0.545986\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149646; batch adversarial loss: 0.494004\n",
      "epoch 40; iter: 0; batch classifier loss: 0.166517; batch adversarial loss: 0.356386\n",
      "epoch 41; iter: 0; batch classifier loss: 0.220804; batch adversarial loss: 0.364109\n",
      "epoch 42; iter: 0; batch classifier loss: 0.186280; batch adversarial loss: 0.415853\n",
      "epoch 43; iter: 0; batch classifier loss: 0.189314; batch adversarial loss: 0.411410\n",
      "epoch 44; iter: 0; batch classifier loss: 0.176326; batch adversarial loss: 0.483210\n",
      "epoch 45; iter: 0; batch classifier loss: 0.213577; batch adversarial loss: 0.443772\n",
      "epoch 46; iter: 0; batch classifier loss: 0.157359; batch adversarial loss: 0.439113\n",
      "epoch 47; iter: 0; batch classifier loss: 0.211086; batch adversarial loss: 0.389028\n",
      "epoch 48; iter: 0; batch classifier loss: 0.197170; batch adversarial loss: 0.555845\n",
      "epoch 49; iter: 0; batch classifier loss: 0.177335; batch adversarial loss: 0.474843\n",
      "epoch 50; iter: 0; batch classifier loss: 0.277337; batch adversarial loss: 0.549272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.211752; batch adversarial loss: 0.499063\n",
      "epoch 52; iter: 0; batch classifier loss: 0.229439; batch adversarial loss: 0.398307\n",
      "epoch 53; iter: 0; batch classifier loss: 0.232047; batch adversarial loss: 0.460878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213764; batch adversarial loss: 0.552246\n",
      "epoch 55; iter: 0; batch classifier loss: 0.186504; batch adversarial loss: 0.506873\n",
      "epoch 56; iter: 0; batch classifier loss: 0.230844; batch adversarial loss: 0.433090\n",
      "epoch 57; iter: 0; batch classifier loss: 0.194807; batch adversarial loss: 0.388365\n",
      "epoch 58; iter: 0; batch classifier loss: 0.249694; batch adversarial loss: 0.505646\n",
      "epoch 59; iter: 0; batch classifier loss: 0.260857; batch adversarial loss: 0.470594\n",
      "epoch 60; iter: 0; batch classifier loss: 0.202849; batch adversarial loss: 0.363533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.269925; batch adversarial loss: 0.459070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.116100; batch adversarial loss: 0.517732\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085591; batch adversarial loss: 0.465553\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089609; batch adversarial loss: 0.479102\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076500; batch adversarial loss: 0.481971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068130; batch adversarial loss: 0.505530\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075488; batch adversarial loss: 0.432480\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087376; batch adversarial loss: 0.472959\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082771; batch adversarial loss: 0.480624\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081697; batch adversarial loss: 0.434301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083492; batch adversarial loss: 0.433143\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059242; batch adversarial loss: 0.414336\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088335; batch adversarial loss: 0.409576\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076179; batch adversarial loss: 0.386170\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070607; batch adversarial loss: 0.436220\n",
      "epoch 76; iter: 0; batch classifier loss: 0.131825; batch adversarial loss: 0.373955\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089596; batch adversarial loss: 0.450768\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085921; batch adversarial loss: 0.376051\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086201; batch adversarial loss: 0.419780\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084443; batch adversarial loss: 0.427126\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057618; batch adversarial loss: 0.469599\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082352; batch adversarial loss: 0.513816\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072287; batch adversarial loss: 0.462602\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091891; batch adversarial loss: 0.479728\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077133; batch adversarial loss: 0.369049\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069991; batch adversarial loss: 0.363622\n",
      "epoch 87; iter: 0; batch classifier loss: 0.124641; batch adversarial loss: 0.397983\n",
      "epoch 88; iter: 0; batch classifier loss: 0.042062; batch adversarial loss: 0.385147\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075881; batch adversarial loss: 0.459746\n",
      "epoch 90; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.433877\n",
      "epoch 91; iter: 0; batch classifier loss: 0.084101; batch adversarial loss: 0.510693\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065577; batch adversarial loss: 0.489118\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065009; batch adversarial loss: 0.441266\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092053; batch adversarial loss: 0.455643\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083631; batch adversarial loss: 0.404069\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068466; batch adversarial loss: 0.500182\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047454; batch adversarial loss: 0.423808\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038396; batch adversarial loss: 0.431214\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045995; batch adversarial loss: 0.489513\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067778; batch adversarial loss: 0.405885\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092500; batch adversarial loss: 0.440746\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055580; batch adversarial loss: 0.351310\n",
      "epoch 103; iter: 0; batch classifier loss: 0.079821; batch adversarial loss: 0.461677\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059284; batch adversarial loss: 0.499252\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040898; batch adversarial loss: 0.419738\n",
      "epoch 106; iter: 0; batch classifier loss: 0.097275; batch adversarial loss: 0.488713\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064337; batch adversarial loss: 0.449751\n",
      "epoch 108; iter: 0; batch classifier loss: 0.057015; batch adversarial loss: 0.371231\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035657; batch adversarial loss: 0.462905\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054054; batch adversarial loss: 0.496318\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060044; batch adversarial loss: 0.524988\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057105; batch adversarial loss: 0.506387\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061015; batch adversarial loss: 0.506044\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042358; batch adversarial loss: 0.360736\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058981; batch adversarial loss: 0.472772\n",
      "epoch 116; iter: 0; batch classifier loss: 0.086318; batch adversarial loss: 0.430005\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033590; batch adversarial loss: 0.458381\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059128; batch adversarial loss: 0.399577\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048784; batch adversarial loss: 0.350597\n",
      "epoch 120; iter: 0; batch classifier loss: 0.081199; batch adversarial loss: 0.437777\n",
      "epoch 121; iter: 0; batch classifier loss: 0.119886; batch adversarial loss: 0.418403\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048401; batch adversarial loss: 0.417304\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061446; batch adversarial loss: 0.504532\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041963; batch adversarial loss: 0.454496\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082806; batch adversarial loss: 0.460044\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066833; batch adversarial loss: 0.369072\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043352; batch adversarial loss: 0.382321\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067406; batch adversarial loss: 0.442455\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036289; batch adversarial loss: 0.432189\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048808; batch adversarial loss: 0.405856\n",
      "epoch 131; iter: 0; batch classifier loss: 0.066816; batch adversarial loss: 0.397909\n",
      "epoch 132; iter: 0; batch classifier loss: 0.067534; batch adversarial loss: 0.456358\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036950; batch adversarial loss: 0.466420\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078527; batch adversarial loss: 0.466431\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051863; batch adversarial loss: 0.411253\n",
      "epoch 136; iter: 0; batch classifier loss: 0.097761; batch adversarial loss: 0.468661\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075530; batch adversarial loss: 0.491253\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059668; batch adversarial loss: 0.406073\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045452; batch adversarial loss: 0.458491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056438; batch adversarial loss: 0.496294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.063868; batch adversarial loss: 0.505287\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028213; batch adversarial loss: 0.370479\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059421; batch adversarial loss: 0.512893\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052205; batch adversarial loss: 0.394373\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051405; batch adversarial loss: 0.320870\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040890; batch adversarial loss: 0.466298\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055141; batch adversarial loss: 0.435829\n",
      "epoch 148; iter: 0; batch classifier loss: 0.064292; batch adversarial loss: 0.370657\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064889; batch adversarial loss: 0.392378\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054782; batch adversarial loss: 0.349688\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033408; batch adversarial loss: 0.432272\n",
      "epoch 152; iter: 0; batch classifier loss: 0.087009; batch adversarial loss: 0.346884\n",
      "epoch 153; iter: 0; batch classifier loss: 0.064793; batch adversarial loss: 0.403606\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063201; batch adversarial loss: 0.391160\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051802; batch adversarial loss: 0.407007\n",
      "epoch 156; iter: 0; batch classifier loss: 0.077919; batch adversarial loss: 0.437587\n",
      "epoch 157; iter: 0; batch classifier loss: 0.066003; batch adversarial loss: 0.487744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.056607; batch adversarial loss: 0.386400\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031469; batch adversarial loss: 0.426782\n",
      "epoch 160; iter: 0; batch classifier loss: 0.050377; batch adversarial loss: 0.459991\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053671; batch adversarial loss: 0.383920\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028786; batch adversarial loss: 0.535762\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036831; batch adversarial loss: 0.431544\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031139; batch adversarial loss: 0.460566\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039641; batch adversarial loss: 0.479805\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035035; batch adversarial loss: 0.510241\n",
      "epoch 167; iter: 0; batch classifier loss: 0.109529; batch adversarial loss: 0.525629\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040350; batch adversarial loss: 0.492856\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020210; batch adversarial loss: 0.440686\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038041; batch adversarial loss: 0.360075\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033450; batch adversarial loss: 0.509079\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049345; batch adversarial loss: 0.484249\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033224; batch adversarial loss: 0.394777\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025610; batch adversarial loss: 0.466053\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011678; batch adversarial loss: 0.484801\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045450; batch adversarial loss: 0.445392\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029964; batch adversarial loss: 0.397987\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039261; batch adversarial loss: 0.509959\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035415; batch adversarial loss: 0.420700\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029051; batch adversarial loss: 0.538178\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019946; batch adversarial loss: 0.587096\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032251; batch adversarial loss: 0.435076\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028640; batch adversarial loss: 0.446880\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026472; batch adversarial loss: 0.462176\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023330; batch adversarial loss: 0.450645\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016007; batch adversarial loss: 0.378222\n",
      "epoch 187; iter: 0; batch classifier loss: 0.049685; batch adversarial loss: 0.403879\n",
      "epoch 188; iter: 0; batch classifier loss: 0.046108; batch adversarial loss: 0.428073\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043067; batch adversarial loss: 0.397959\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010710; batch adversarial loss: 0.466835\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021563; batch adversarial loss: 0.457189\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008480; batch adversarial loss: 0.490252\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013870; batch adversarial loss: 0.392302\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.511511\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037043; batch adversarial loss: 0.501783\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037967; batch adversarial loss: 0.435626\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022164; batch adversarial loss: 0.404620\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021994; batch adversarial loss: 0.503776\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036850; batch adversarial loss: 0.453089\n",
      "epoch 0; iter: 0; batch classifier loss: 0.666913; batch adversarial loss: 1.005033\n",
      "epoch 1; iter: 0; batch classifier loss: 0.725651; batch adversarial loss: 1.237127\n",
      "epoch 2; iter: 0; batch classifier loss: 0.919882; batch adversarial loss: 1.237900\n",
      "epoch 3; iter: 0; batch classifier loss: 1.112161; batch adversarial loss: 1.159677\n",
      "epoch 4; iter: 0; batch classifier loss: 1.232159; batch adversarial loss: 1.050720\n",
      "epoch 5; iter: 0; batch classifier loss: 1.282033; batch adversarial loss: 0.968664\n",
      "epoch 6; iter: 0; batch classifier loss: 1.215679; batch adversarial loss: 0.883940\n",
      "epoch 7; iter: 0; batch classifier loss: 1.377492; batch adversarial loss: 0.839360\n",
      "epoch 8; iter: 0; batch classifier loss: 1.111071; batch adversarial loss: 0.727844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.969703; batch adversarial loss: 0.703132\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654485; batch adversarial loss: 0.626816\n",
      "epoch 11; iter: 0; batch classifier loss: 0.726950; batch adversarial loss: 0.581548\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586887; batch adversarial loss: 0.556676\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389413; batch adversarial loss: 0.555918\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298183; batch adversarial loss: 0.471194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281117; batch adversarial loss: 0.536968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311326; batch adversarial loss: 0.460782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241337; batch adversarial loss: 0.494163\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265577; batch adversarial loss: 0.463816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.210112; batch adversarial loss: 0.532517\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197775; batch adversarial loss: 0.550168\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184526; batch adversarial loss: 0.481625\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214480; batch adversarial loss: 0.500526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234889; batch adversarial loss: 0.435983\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201417; batch adversarial loss: 0.477160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228930; batch adversarial loss: 0.505720\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223646; batch adversarial loss: 0.464772\n",
      "epoch 27; iter: 0; batch classifier loss: 0.156310; batch adversarial loss: 0.492174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235207; batch adversarial loss: 0.489882\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210267; batch adversarial loss: 0.385042\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191298; batch adversarial loss: 0.420697\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162854; batch adversarial loss: 0.440148\n",
      "epoch 32; iter: 0; batch classifier loss: 0.165382; batch adversarial loss: 0.469150\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194541; batch adversarial loss: 0.409547\n",
      "epoch 34; iter: 0; batch classifier loss: 0.190319; batch adversarial loss: 0.444670\n",
      "epoch 35; iter: 0; batch classifier loss: 0.182889; batch adversarial loss: 0.414849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186539; batch adversarial loss: 0.454803\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172327; batch adversarial loss: 0.452842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.168107; batch adversarial loss: 0.424020\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197210; batch adversarial loss: 0.483973\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192008; batch adversarial loss: 0.467382\n",
      "epoch 41; iter: 0; batch classifier loss: 0.171879; batch adversarial loss: 0.514366\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150453; batch adversarial loss: 0.522246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.226069; batch adversarial loss: 0.421119\n",
      "epoch 44; iter: 0; batch classifier loss: 0.170417; batch adversarial loss: 0.501630\n",
      "epoch 45; iter: 0; batch classifier loss: 0.175468; batch adversarial loss: 0.480353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.207396; batch adversarial loss: 0.376775\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201736; batch adversarial loss: 0.476325\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131279; batch adversarial loss: 0.487296\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214709; batch adversarial loss: 0.396865\n",
      "epoch 50; iter: 0; batch classifier loss: 0.186456; batch adversarial loss: 0.467005\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126773; batch adversarial loss: 0.461077\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148168; batch adversarial loss: 0.492678\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171103; batch adversarial loss: 0.414728\n",
      "epoch 54; iter: 0; batch classifier loss: 0.141664; batch adversarial loss: 0.427252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55; iter: 0; batch classifier loss: 0.111035; batch adversarial loss: 0.420756\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110752; batch adversarial loss: 0.357695\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132620; batch adversarial loss: 0.427518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.143789; batch adversarial loss: 0.536001\n",
      "epoch 59; iter: 0; batch classifier loss: 0.153923; batch adversarial loss: 0.412706\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115749; batch adversarial loss: 0.414062\n",
      "epoch 61; iter: 0; batch classifier loss: 0.140676; batch adversarial loss: 0.528012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.137979; batch adversarial loss: 0.551132\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117154; batch adversarial loss: 0.459319\n",
      "epoch 64; iter: 0; batch classifier loss: 0.143261; batch adversarial loss: 0.443942\n",
      "epoch 65; iter: 0; batch classifier loss: 0.147714; batch adversarial loss: 0.474001\n",
      "epoch 66; iter: 0; batch classifier loss: 0.152977; batch adversarial loss: 0.487190\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121660; batch adversarial loss: 0.427398\n",
      "epoch 68; iter: 0; batch classifier loss: 0.127296; batch adversarial loss: 0.432098\n",
      "epoch 69; iter: 0; batch classifier loss: 0.153710; batch adversarial loss: 0.406090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.134961; batch adversarial loss: 0.519474\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116072; batch adversarial loss: 0.451190\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116350; batch adversarial loss: 0.460020\n",
      "epoch 73; iter: 0; batch classifier loss: 0.133151; batch adversarial loss: 0.411837\n",
      "epoch 74; iter: 0; batch classifier loss: 0.125765; batch adversarial loss: 0.497519\n",
      "epoch 75; iter: 0; batch classifier loss: 0.162284; batch adversarial loss: 0.419629\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072936; batch adversarial loss: 0.410603\n",
      "epoch 77; iter: 0; batch classifier loss: 0.089617; batch adversarial loss: 0.459005\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126442; batch adversarial loss: 0.449946\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128154; batch adversarial loss: 0.483518\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107162; batch adversarial loss: 0.431856\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089528; batch adversarial loss: 0.460762\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175104; batch adversarial loss: 0.495579\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123819; batch adversarial loss: 0.487440\n",
      "epoch 84; iter: 0; batch classifier loss: 0.072573; batch adversarial loss: 0.534486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076774; batch adversarial loss: 0.532989\n",
      "epoch 86; iter: 0; batch classifier loss: 0.081741; batch adversarial loss: 0.457267\n",
      "epoch 87; iter: 0; batch classifier loss: 0.127537; batch adversarial loss: 0.427570\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100680; batch adversarial loss: 0.481069\n",
      "epoch 89; iter: 0; batch classifier loss: 0.105027; batch adversarial loss: 0.477868\n",
      "epoch 90; iter: 0; batch classifier loss: 0.122177; batch adversarial loss: 0.443893\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083438; batch adversarial loss: 0.493170\n",
      "epoch 92; iter: 0; batch classifier loss: 0.082185; batch adversarial loss: 0.382116\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102438; batch adversarial loss: 0.481595\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079901; batch adversarial loss: 0.364874\n",
      "epoch 95; iter: 0; batch classifier loss: 0.108221; batch adversarial loss: 0.475954\n",
      "epoch 96; iter: 0; batch classifier loss: 0.156292; batch adversarial loss: 0.525033\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099856; batch adversarial loss: 0.411768\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068490; batch adversarial loss: 0.382620\n",
      "epoch 99; iter: 0; batch classifier loss: 0.096649; batch adversarial loss: 0.403129\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092010; batch adversarial loss: 0.525905\n",
      "epoch 101; iter: 0; batch classifier loss: 0.108040; batch adversarial loss: 0.485058\n",
      "epoch 102; iter: 0; batch classifier loss: 0.139470; batch adversarial loss: 0.437032\n",
      "epoch 103; iter: 0; batch classifier loss: 0.126694; batch adversarial loss: 0.514851\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071455; batch adversarial loss: 0.489711\n",
      "epoch 105; iter: 0; batch classifier loss: 0.099507; batch adversarial loss: 0.424104\n",
      "epoch 106; iter: 0; batch classifier loss: 0.089349; batch adversarial loss: 0.509585\n",
      "epoch 107; iter: 0; batch classifier loss: 0.081773; batch adversarial loss: 0.478799\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045406; batch adversarial loss: 0.520576\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078762; batch adversarial loss: 0.479783\n",
      "epoch 110; iter: 0; batch classifier loss: 0.080779; batch adversarial loss: 0.424057\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055698; batch adversarial loss: 0.491679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073436; batch adversarial loss: 0.480122\n",
      "epoch 113; iter: 0; batch classifier loss: 0.082992; batch adversarial loss: 0.528534\n",
      "epoch 114; iter: 0; batch classifier loss: 0.097825; batch adversarial loss: 0.393996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.088960; batch adversarial loss: 0.465698\n",
      "epoch 116; iter: 0; batch classifier loss: 0.096878; batch adversarial loss: 0.472899\n",
      "epoch 117; iter: 0; batch classifier loss: 0.113132; batch adversarial loss: 0.462737\n",
      "epoch 118; iter: 0; batch classifier loss: 0.103763; batch adversarial loss: 0.432692\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067395; batch adversarial loss: 0.467206\n",
      "epoch 120; iter: 0; batch classifier loss: 0.085118; batch adversarial loss: 0.417288\n",
      "epoch 121; iter: 0; batch classifier loss: 0.099282; batch adversarial loss: 0.533007\n",
      "epoch 122; iter: 0; batch classifier loss: 0.105137; batch adversarial loss: 0.377607\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.533293\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033117; batch adversarial loss: 0.526271\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044474; batch adversarial loss: 0.473124\n",
      "epoch 126; iter: 0; batch classifier loss: 0.099426; batch adversarial loss: 0.431705\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063886; batch adversarial loss: 0.385289\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087652; batch adversarial loss: 0.526538\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072518; batch adversarial loss: 0.447266\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035146; batch adversarial loss: 0.490799\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043534; batch adversarial loss: 0.491717\n",
      "epoch 132; iter: 0; batch classifier loss: 0.097595; batch adversarial loss: 0.384824\n",
      "epoch 133; iter: 0; batch classifier loss: 0.072763; batch adversarial loss: 0.397951\n",
      "epoch 134; iter: 0; batch classifier loss: 0.076309; batch adversarial loss: 0.460726\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043898; batch adversarial loss: 0.453849\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035481; batch adversarial loss: 0.464293\n",
      "epoch 137; iter: 0; batch classifier loss: 0.085851; batch adversarial loss: 0.386730\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030327; batch adversarial loss: 0.435425\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040569; batch adversarial loss: 0.395412\n",
      "epoch 140; iter: 0; batch classifier loss: 0.081565; batch adversarial loss: 0.402266\n",
      "epoch 141; iter: 0; batch classifier loss: 0.090402; batch adversarial loss: 0.489552\n",
      "epoch 142; iter: 0; batch classifier loss: 0.051377; batch adversarial loss: 0.542233\n",
      "epoch 143; iter: 0; batch classifier loss: 0.075537; batch adversarial loss: 0.531633\n",
      "epoch 144; iter: 0; batch classifier loss: 0.067689; batch adversarial loss: 0.421863\n",
      "epoch 145; iter: 0; batch classifier loss: 0.069436; batch adversarial loss: 0.378745\n",
      "epoch 146; iter: 0; batch classifier loss: 0.110655; batch adversarial loss: 0.371861\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.382164\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043006; batch adversarial loss: 0.445209\n",
      "epoch 149; iter: 0; batch classifier loss: 0.077533; batch adversarial loss: 0.401059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024933; batch adversarial loss: 0.448597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.071899; batch adversarial loss: 0.427961\n",
      "epoch 152; iter: 0; batch classifier loss: 0.066245; batch adversarial loss: 0.419561\n",
      "epoch 153; iter: 0; batch classifier loss: 0.039209; batch adversarial loss: 0.463023\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.544073\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030908; batch adversarial loss: 0.472398\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050727; batch adversarial loss: 0.419861\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046930; batch adversarial loss: 0.378770\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044424; batch adversarial loss: 0.484404\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031533; batch adversarial loss: 0.363552\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024630; batch adversarial loss: 0.429166\n",
      "epoch 161; iter: 0; batch classifier loss: 0.020564; batch adversarial loss: 0.373652\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020680; batch adversarial loss: 0.442049\n",
      "epoch 163; iter: 0; batch classifier loss: 0.032028; batch adversarial loss: 0.515218\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013593; batch adversarial loss: 0.467556\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021032; batch adversarial loss: 0.420829\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026718; batch adversarial loss: 0.524940\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005862; batch adversarial loss: 0.411104\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019365; batch adversarial loss: 0.418994\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022953; batch adversarial loss: 0.545938\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034699; batch adversarial loss: 0.434257\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019838; batch adversarial loss: 0.410375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014886; batch adversarial loss: 0.489168\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.433402\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041821; batch adversarial loss: 0.425912\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027959; batch adversarial loss: 0.526028\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034924; batch adversarial loss: 0.533507\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036631; batch adversarial loss: 0.427263\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016783; batch adversarial loss: 0.382109\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016672; batch adversarial loss: 0.483022\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028672; batch adversarial loss: 0.381727\n",
      "epoch 181; iter: 0; batch classifier loss: 0.033345; batch adversarial loss: 0.421608\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014143; batch adversarial loss: 0.418550\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034431; batch adversarial loss: 0.375234\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030870; batch adversarial loss: 0.519072\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045316; batch adversarial loss: 0.446526\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016600; batch adversarial loss: 0.439798\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014453; batch adversarial loss: 0.418885\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017256; batch adversarial loss: 0.491475\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020385; batch adversarial loss: 0.457202\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.383213\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033755; batch adversarial loss: 0.467433\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040261; batch adversarial loss: 0.368479\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014042; batch adversarial loss: 0.565272\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020323; batch adversarial loss: 0.429894\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023293; batch adversarial loss: 0.451825\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017605; batch adversarial loss: 0.497310\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018977; batch adversarial loss: 0.458339\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019190; batch adversarial loss: 0.466010\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014927; batch adversarial loss: 0.485297\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685446; batch adversarial loss: 0.670188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.399518; batch adversarial loss: 0.643974\n",
      "epoch 2; iter: 0; batch classifier loss: 0.397650; batch adversarial loss: 0.587018\n",
      "epoch 3; iter: 0; batch classifier loss: 0.377600; batch adversarial loss: 0.568109\n",
      "epoch 4; iter: 0; batch classifier loss: 0.291857; batch adversarial loss: 0.576930\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286077; batch adversarial loss: 0.525495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.273559; batch adversarial loss: 0.518604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296358; batch adversarial loss: 0.518557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222952; batch adversarial loss: 0.509604\n",
      "epoch 9; iter: 0; batch classifier loss: 0.230793; batch adversarial loss: 0.511814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.230604; batch adversarial loss: 0.483706\n",
      "epoch 11; iter: 0; batch classifier loss: 0.194133; batch adversarial loss: 0.500354\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244228; batch adversarial loss: 0.533445\n",
      "epoch 13; iter: 0; batch classifier loss: 0.173592; batch adversarial loss: 0.564841\n",
      "epoch 14; iter: 0; batch classifier loss: 0.196388; batch adversarial loss: 0.457485\n",
      "epoch 15; iter: 0; batch classifier loss: 0.184160; batch adversarial loss: 0.535350\n",
      "epoch 16; iter: 0; batch classifier loss: 0.172478; batch adversarial loss: 0.494309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232511; batch adversarial loss: 0.562853\n",
      "epoch 18; iter: 0; batch classifier loss: 0.174696; batch adversarial loss: 0.505897\n",
      "epoch 19; iter: 0; batch classifier loss: 0.182274; batch adversarial loss: 0.409509\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211434; batch adversarial loss: 0.473631\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163962; batch adversarial loss: 0.507325\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201829; batch adversarial loss: 0.453789\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151849; batch adversarial loss: 0.454043\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173243; batch adversarial loss: 0.433066\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195257; batch adversarial loss: 0.448831\n",
      "epoch 26; iter: 0; batch classifier loss: 0.256931; batch adversarial loss: 0.627630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.181169; batch adversarial loss: 0.548592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.199844; batch adversarial loss: 0.510705\n",
      "epoch 29; iter: 0; batch classifier loss: 0.128784; batch adversarial loss: 0.457939\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237649; batch adversarial loss: 0.401750\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233700; batch adversarial loss: 0.503725\n",
      "epoch 32; iter: 0; batch classifier loss: 0.295833; batch adversarial loss: 0.402768\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392984; batch adversarial loss: 0.428063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160022; batch adversarial loss: 0.470085\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151411; batch adversarial loss: 0.500015\n",
      "epoch 36; iter: 0; batch classifier loss: 0.139311; batch adversarial loss: 0.429501\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124836; batch adversarial loss: 0.460323\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085729; batch adversarial loss: 0.471837\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116767; batch adversarial loss: 0.464915\n",
      "epoch 40; iter: 0; batch classifier loss: 0.100035; batch adversarial loss: 0.424216\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137303; batch adversarial loss: 0.451012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094828; batch adversarial loss: 0.468793\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081598; batch adversarial loss: 0.581763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083003; batch adversarial loss: 0.399838\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086637; batch adversarial loss: 0.493345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109109; batch adversarial loss: 0.423584\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100049; batch adversarial loss: 0.433381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.095726; batch adversarial loss: 0.479434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064517; batch adversarial loss: 0.488067\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076689; batch adversarial loss: 0.373013\n",
      "epoch 51; iter: 0; batch classifier loss: 0.091628; batch adversarial loss: 0.427881\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067728; batch adversarial loss: 0.395112\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077817; batch adversarial loss: 0.437374\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102141; batch adversarial loss: 0.519643\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083849; batch adversarial loss: 0.512822\n",
      "epoch 56; iter: 0; batch classifier loss: 0.054791; batch adversarial loss: 0.406410\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080887; batch adversarial loss: 0.419728\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093178; batch adversarial loss: 0.506862\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130093; batch adversarial loss: 0.434437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058414; batch adversarial loss: 0.448198\n",
      "epoch 61; iter: 0; batch classifier loss: 0.138419; batch adversarial loss: 0.388265\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075749; batch adversarial loss: 0.398518\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062427; batch adversarial loss: 0.517004\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096778; batch adversarial loss: 0.425228\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063497; batch adversarial loss: 0.453426\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045062; batch adversarial loss: 0.441455\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079990; batch adversarial loss: 0.512209\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119123; batch adversarial loss: 0.418500\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095354; batch adversarial loss: 0.447259\n",
      "epoch 70; iter: 0; batch classifier loss: 0.057381; batch adversarial loss: 0.436825\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078689; batch adversarial loss: 0.514777\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056352; batch adversarial loss: 0.524873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082584; batch adversarial loss: 0.505575\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065070; batch adversarial loss: 0.452163\n",
      "epoch 75; iter: 0; batch classifier loss: 0.048043; batch adversarial loss: 0.440088\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104055; batch adversarial loss: 0.455414\n",
      "epoch 77; iter: 0; batch classifier loss: 0.029246; batch adversarial loss: 0.498713\n",
      "epoch 78; iter: 0; batch classifier loss: 0.164092; batch adversarial loss: 0.420838\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039908; batch adversarial loss: 0.485879\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087009; batch adversarial loss: 0.423962\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044054; batch adversarial loss: 0.430123\n",
      "epoch 82; iter: 0; batch classifier loss: 0.094223; batch adversarial loss: 0.527895\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073578; batch adversarial loss: 0.417408\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085380; batch adversarial loss: 0.490285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.125979; batch adversarial loss: 0.437093\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104051; batch adversarial loss: 0.525442\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056814; batch adversarial loss: 0.427316\n",
      "epoch 88; iter: 0; batch classifier loss: 0.120388; batch adversarial loss: 0.476369\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095853; batch adversarial loss: 0.449164\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.403347\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041697; batch adversarial loss: 0.457850\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076882; batch adversarial loss: 0.458002\n",
      "epoch 93; iter: 0; batch classifier loss: 0.107350; batch adversarial loss: 0.524279\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051977; batch adversarial loss: 0.511193\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029295; batch adversarial loss: 0.443339\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082213; batch adversarial loss: 0.416993\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069740; batch adversarial loss: 0.501124\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030381; batch adversarial loss: 0.433889\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058983; batch adversarial loss: 0.501987\n",
      "epoch 100; iter: 0; batch classifier loss: 0.113010; batch adversarial loss: 0.459898\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065127; batch adversarial loss: 0.453292\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089282; batch adversarial loss: 0.515499\n",
      "epoch 103; iter: 0; batch classifier loss: 0.075144; batch adversarial loss: 0.354119\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044133; batch adversarial loss: 0.409505\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076479; batch adversarial loss: 0.519205\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027491; batch adversarial loss: 0.458039\n",
      "epoch 107; iter: 0; batch classifier loss: 0.095559; batch adversarial loss: 0.527344\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051556; batch adversarial loss: 0.441630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075348; batch adversarial loss: 0.484494\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086641; batch adversarial loss: 0.439998\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047302; batch adversarial loss: 0.472344\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074382; batch adversarial loss: 0.450057\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047176; batch adversarial loss: 0.518523\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057212; batch adversarial loss: 0.437337\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.493861\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033755; batch adversarial loss: 0.398638\n",
      "epoch 117; iter: 0; batch classifier loss: 0.040363; batch adversarial loss: 0.425260\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071485; batch adversarial loss: 0.476167\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083590; batch adversarial loss: 0.420177\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047903; batch adversarial loss: 0.410268\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070706; batch adversarial loss: 0.430631\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038401; batch adversarial loss: 0.402933\n",
      "epoch 123; iter: 0; batch classifier loss: 0.078380; batch adversarial loss: 0.462843\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067779; batch adversarial loss: 0.343815\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082421; batch adversarial loss: 0.451011\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070073; batch adversarial loss: 0.532968\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046430; batch adversarial loss: 0.439941\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063491; batch adversarial loss: 0.487647\n",
      "epoch 129; iter: 0; batch classifier loss: 0.084381; batch adversarial loss: 0.391107\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034581; batch adversarial loss: 0.465984\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027075; batch adversarial loss: 0.386642\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072620; batch adversarial loss: 0.451478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033697; batch adversarial loss: 0.459123\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024371; batch adversarial loss: 0.451274\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041506; batch adversarial loss: 0.537502\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040092; batch adversarial loss: 0.489160\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035844; batch adversarial loss: 0.485108\n",
      "epoch 138; iter: 0; batch classifier loss: 0.042962; batch adversarial loss: 0.438994\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032595; batch adversarial loss: 0.463369\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042392; batch adversarial loss: 0.459622\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056807; batch adversarial loss: 0.410650\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026375; batch adversarial loss: 0.412608\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062881; batch adversarial loss: 0.565189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.041977; batch adversarial loss: 0.469099\n",
      "epoch 145; iter: 0; batch classifier loss: 0.070580; batch adversarial loss: 0.469509\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031928; batch adversarial loss: 0.446916\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020122; batch adversarial loss: 0.458357\n",
      "epoch 148; iter: 0; batch classifier loss: 0.046987; batch adversarial loss: 0.536470\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023733; batch adversarial loss: 0.449677\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023006; batch adversarial loss: 0.483444\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025675; batch adversarial loss: 0.392280\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022810; batch adversarial loss: 0.477867\n",
      "epoch 153; iter: 0; batch classifier loss: 0.033025; batch adversarial loss: 0.425006\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046104; batch adversarial loss: 0.405250\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040999; batch adversarial loss: 0.399619\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053282; batch adversarial loss: 0.413877\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013652; batch adversarial loss: 0.460307\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036967; batch adversarial loss: 0.414011\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018639; batch adversarial loss: 0.456278\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008953; batch adversarial loss: 0.509484\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007196; batch adversarial loss: 0.402449\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026329; batch adversarial loss: 0.498022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.062541; batch adversarial loss: 0.381557\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021587; batch adversarial loss: 0.491440\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034714; batch adversarial loss: 0.374983\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039145; batch adversarial loss: 0.425776\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007597; batch adversarial loss: 0.380080\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036113; batch adversarial loss: 0.504502\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027416; batch adversarial loss: 0.486930\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008763; batch adversarial loss: 0.455454\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019245; batch adversarial loss: 0.460741\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009136; batch adversarial loss: 0.463809\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025776; batch adversarial loss: 0.521673\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022786; batch adversarial loss: 0.445572\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022271; batch adversarial loss: 0.410439\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023013; batch adversarial loss: 0.487133\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017310; batch adversarial loss: 0.556389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036392; batch adversarial loss: 0.416246\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027119; batch adversarial loss: 0.467121\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017281; batch adversarial loss: 0.471591\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020159; batch adversarial loss: 0.428340\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036633; batch adversarial loss: 0.454666\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027902; batch adversarial loss: 0.467862\n",
      "epoch 184; iter: 0; batch classifier loss: 0.023589; batch adversarial loss: 0.439469\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023903; batch adversarial loss: 0.428702\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040471; batch adversarial loss: 0.438943\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036123; batch adversarial loss: 0.457424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048562; batch adversarial loss: 0.471916\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.613581\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018700; batch adversarial loss: 0.371792\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024614; batch adversarial loss: 0.415409\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008409; batch adversarial loss: 0.517585\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024565; batch adversarial loss: 0.462092\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035235; batch adversarial loss: 0.418934\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037094; batch adversarial loss: 0.431511\n",
      "epoch 196; iter: 0; batch classifier loss: 0.039352; batch adversarial loss: 0.501561\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016075; batch adversarial loss: 0.465145\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040890; batch adversarial loss: 0.440573\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018151; batch adversarial loss: 0.489538\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678724; batch adversarial loss: 0.762335\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616403; batch adversarial loss: 0.763753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.707496; batch adversarial loss: 0.750095\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641003; batch adversarial loss: 0.669499\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439305; batch adversarial loss: 0.576415\n",
      "epoch 5; iter: 0; batch classifier loss: 0.445166; batch adversarial loss: 0.573458\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375944; batch adversarial loss: 0.578088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357374; batch adversarial loss: 0.498680\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281701; batch adversarial loss: 0.473384\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306131; batch adversarial loss: 0.578272\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296981; batch adversarial loss: 0.501681\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332555; batch adversarial loss: 0.473880\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238013; batch adversarial loss: 0.472641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232012; batch adversarial loss: 0.496425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210400; batch adversarial loss: 0.469847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268131; batch adversarial loss: 0.456800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218565; batch adversarial loss: 0.547531\n",
      "epoch 17; iter: 0; batch classifier loss: 0.242770; batch adversarial loss: 0.512218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.176815; batch adversarial loss: 0.487666\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249669; batch adversarial loss: 0.490660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219533; batch adversarial loss: 0.476628\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195737; batch adversarial loss: 0.477371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.230452; batch adversarial loss: 0.488108\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214466; batch adversarial loss: 0.505723\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147179; batch adversarial loss: 0.504238\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172051; batch adversarial loss: 0.486516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183040; batch adversarial loss: 0.459956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.150272; batch adversarial loss: 0.489081\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201229; batch adversarial loss: 0.402890\n",
      "epoch 29; iter: 0; batch classifier loss: 0.098448; batch adversarial loss: 0.419257\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137962; batch adversarial loss: 0.418118\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125585; batch adversarial loss: 0.462551\n",
      "epoch 32; iter: 0; batch classifier loss: 0.163419; batch adversarial loss: 0.513362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142842; batch adversarial loss: 0.463983\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157090; batch adversarial loss: 0.424622\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202877; batch adversarial loss: 0.444248\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191771; batch adversarial loss: 0.449860\n",
      "epoch 37; iter: 0; batch classifier loss: 0.151375; batch adversarial loss: 0.484152\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107547; batch adversarial loss: 0.474154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.140589; batch adversarial loss: 0.459177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.128023; batch adversarial loss: 0.420103\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112013; batch adversarial loss: 0.443777\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141614; batch adversarial loss: 0.530279\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121411; batch adversarial loss: 0.433329\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127526; batch adversarial loss: 0.349530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096087; batch adversarial loss: 0.420089\n",
      "epoch 46; iter: 0; batch classifier loss: 0.169458; batch adversarial loss: 0.441980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119499; batch adversarial loss: 0.432220\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132064; batch adversarial loss: 0.484802\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071848; batch adversarial loss: 0.385877\n",
      "epoch 50; iter: 0; batch classifier loss: 0.161841; batch adversarial loss: 0.425367\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076188; batch adversarial loss: 0.482556\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076591; batch adversarial loss: 0.402261\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088962; batch adversarial loss: 0.435735\n",
      "epoch 54; iter: 0; batch classifier loss: 0.123851; batch adversarial loss: 0.430141\n",
      "epoch 55; iter: 0; batch classifier loss: 0.151559; batch adversarial loss: 0.386386\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120165; batch adversarial loss: 0.416940\n",
      "epoch 57; iter: 0; batch classifier loss: 0.055156; batch adversarial loss: 0.450438\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064682; batch adversarial loss: 0.421998\n",
      "epoch 59; iter: 0; batch classifier loss: 0.083932; batch adversarial loss: 0.469350\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066201; batch adversarial loss: 0.457048\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080864; batch adversarial loss: 0.427590\n",
      "epoch 62; iter: 0; batch classifier loss: 0.086473; batch adversarial loss: 0.414271\n",
      "epoch 63; iter: 0; batch classifier loss: 0.047786; batch adversarial loss: 0.427704\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057343; batch adversarial loss: 0.470650\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090675; batch adversarial loss: 0.410805\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069509; batch adversarial loss: 0.447835\n",
      "epoch 67; iter: 0; batch classifier loss: 0.076713; batch adversarial loss: 0.447882\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111596; batch adversarial loss: 0.389726\n",
      "epoch 69; iter: 0; batch classifier loss: 0.047060; batch adversarial loss: 0.459035\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062849; batch adversarial loss: 0.551507\n",
      "epoch 71; iter: 0; batch classifier loss: 0.041414; batch adversarial loss: 0.438371\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083355; batch adversarial loss: 0.430676\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050343; batch adversarial loss: 0.373466\n",
      "epoch 74; iter: 0; batch classifier loss: 0.042413; batch adversarial loss: 0.431376\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047065; batch adversarial loss: 0.445783\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081649; batch adversarial loss: 0.456494\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054192; batch adversarial loss: 0.517748\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067285; batch adversarial loss: 0.422037\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048066; batch adversarial loss: 0.377721\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068332; batch adversarial loss: 0.358710\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058855; batch adversarial loss: 0.274352\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082687; batch adversarial loss: 0.444352\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060369; batch adversarial loss: 0.448129\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068927; batch adversarial loss: 0.390104\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041785; batch adversarial loss: 0.452800\n",
      "epoch 86; iter: 0; batch classifier loss: 0.028119; batch adversarial loss: 0.375484\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068712; batch adversarial loss: 0.483517\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048497; batch adversarial loss: 0.400207\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051270; batch adversarial loss: 0.433250\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056461; batch adversarial loss: 0.461722\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089533; batch adversarial loss: 0.442116\n",
      "epoch 92; iter: 0; batch classifier loss: 0.027183; batch adversarial loss: 0.495229\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045614; batch adversarial loss: 0.433052\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043927; batch adversarial loss: 0.449532\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056313; batch adversarial loss: 0.490729\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059266; batch adversarial loss: 0.510625\n",
      "epoch 97; iter: 0; batch classifier loss: 0.057860; batch adversarial loss: 0.401535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.049384; batch adversarial loss: 0.466816\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032465; batch adversarial loss: 0.388960\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022656; batch adversarial loss: 0.403339\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050238; batch adversarial loss: 0.416297\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067860; batch adversarial loss: 0.409760\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050495; batch adversarial loss: 0.519860\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057413; batch adversarial loss: 0.383244\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.499621\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069407; batch adversarial loss: 0.473389\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061067; batch adversarial loss: 0.459077\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033197; batch adversarial loss: 0.414420\n",
      "epoch 109; iter: 0; batch classifier loss: 0.065417; batch adversarial loss: 0.441378\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056257; batch adversarial loss: 0.495241\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035382; batch adversarial loss: 0.456528\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043605; batch adversarial loss: 0.385432\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051994; batch adversarial loss: 0.336637\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035607; batch adversarial loss: 0.467049\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031811; batch adversarial loss: 0.379526\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043920; batch adversarial loss: 0.492521\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.417620\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060599; batch adversarial loss: 0.457821\n",
      "epoch 119; iter: 0; batch classifier loss: 0.023168; batch adversarial loss: 0.435148\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023130; batch adversarial loss: 0.394652\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058380; batch adversarial loss: 0.417359\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076119; batch adversarial loss: 0.534650\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033964; batch adversarial loss: 0.450675\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034735; batch adversarial loss: 0.442897\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.450050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.399312\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038087; batch adversarial loss: 0.429168\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.397404\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023091; batch adversarial loss: 0.442899\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015419; batch adversarial loss: 0.381777\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062314; batch adversarial loss: 0.456228\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024481; batch adversarial loss: 0.393772\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047876; batch adversarial loss: 0.507658\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014360; batch adversarial loss: 0.422733\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031638; batch adversarial loss: 0.448921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.017687; batch adversarial loss: 0.478272\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019562; batch adversarial loss: 0.431832\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032615; batch adversarial loss: 0.428460\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034110; batch adversarial loss: 0.413583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027900; batch adversarial loss: 0.374676\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020082; batch adversarial loss: 0.405165\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040828; batch adversarial loss: 0.374475\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009449; batch adversarial loss: 0.518219\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014843; batch adversarial loss: 0.344604\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029706; batch adversarial loss: 0.436577\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.408520\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027758; batch adversarial loss: 0.393023\n",
      "epoch 148; iter: 0; batch classifier loss: 0.057317; batch adversarial loss: 0.401665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010161; batch adversarial loss: 0.433579\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018809; batch adversarial loss: 0.456202\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017574; batch adversarial loss: 0.470345\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014852; batch adversarial loss: 0.471457\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016522; batch adversarial loss: 0.533721\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018474; batch adversarial loss: 0.463380\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042862; batch adversarial loss: 0.397824\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028654; batch adversarial loss: 0.493629\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031960; batch adversarial loss: 0.402740\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007978; batch adversarial loss: 0.454550\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014323; batch adversarial loss: 0.440876\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024241; batch adversarial loss: 0.511400\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012006; batch adversarial loss: 0.452631\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019446; batch adversarial loss: 0.395589\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053643; batch adversarial loss: 0.396310\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020266; batch adversarial loss: 0.439311\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039421; batch adversarial loss: 0.414949\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012563; batch adversarial loss: 0.447022\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043081; batch adversarial loss: 0.583766\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025574; batch adversarial loss: 0.325175\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031920; batch adversarial loss: 0.352127\n",
      "epoch 170; iter: 0; batch classifier loss: 0.033438; batch adversarial loss: 0.460651\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011984; batch adversarial loss: 0.422602\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027672; batch adversarial loss: 0.384675\n",
      "epoch 173; iter: 0; batch classifier loss: 0.069798; batch adversarial loss: 0.502285\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030834; batch adversarial loss: 0.398886\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046685; batch adversarial loss: 0.431888\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013960; batch adversarial loss: 0.504144\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018550; batch adversarial loss: 0.377737\n",
      "epoch 178; iter: 0; batch classifier loss: 0.016230; batch adversarial loss: 0.418336\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041899; batch adversarial loss: 0.421201\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020317; batch adversarial loss: 0.419944\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024974; batch adversarial loss: 0.523766\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011687; batch adversarial loss: 0.437399\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012900; batch adversarial loss: 0.524369\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014010; batch adversarial loss: 0.494967\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010739; batch adversarial loss: 0.481877\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043613; batch adversarial loss: 0.451292\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029713; batch adversarial loss: 0.526541\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034495; batch adversarial loss: 0.338297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017391; batch adversarial loss: 0.446242\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035949; batch adversarial loss: 0.505019\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007144; batch adversarial loss: 0.412640\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018636; batch adversarial loss: 0.431005\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009115; batch adversarial loss: 0.503189\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009564; batch adversarial loss: 0.317353\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015600; batch adversarial loss: 0.466199\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019105; batch adversarial loss: 0.460042\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018764; batch adversarial loss: 0.385185\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020258; batch adversarial loss: 0.373305\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022793; batch adversarial loss: 0.388941\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700093; batch adversarial loss: 0.726178\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504874; batch adversarial loss: 0.662267\n",
      "epoch 2; iter: 0; batch classifier loss: 0.462686; batch adversarial loss: 0.642712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367671; batch adversarial loss: 0.610798\n",
      "epoch 4; iter: 0; batch classifier loss: 0.400566; batch adversarial loss: 0.568881\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336890; batch adversarial loss: 0.592450\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427357; batch adversarial loss: 0.570898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323169; batch adversarial loss: 0.582472\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342156; batch adversarial loss: 0.537524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363748; batch adversarial loss: 0.445699\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280187; batch adversarial loss: 0.478448\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351395; batch adversarial loss: 0.489433\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264502; batch adversarial loss: 0.472954\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335491; batch adversarial loss: 0.506796\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286848; batch adversarial loss: 0.520559\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355121; batch adversarial loss: 0.518634\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263440; batch adversarial loss: 0.482969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224924; batch adversarial loss: 0.544253\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196597; batch adversarial loss: 0.555218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234824; batch adversarial loss: 0.448549\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191009; batch adversarial loss: 0.478584\n",
      "epoch 21; iter: 0; batch classifier loss: 0.233797; batch adversarial loss: 0.478634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207513; batch adversarial loss: 0.475391\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251652; batch adversarial loss: 0.430443\n",
      "epoch 24; iter: 0; batch classifier loss: 0.191752; batch adversarial loss: 0.450015\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172770; batch adversarial loss: 0.539934\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191839; batch adversarial loss: 0.460025\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239925; batch adversarial loss: 0.460357\n",
      "epoch 28; iter: 0; batch classifier loss: 0.254457; batch adversarial loss: 0.452884\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212782; batch adversarial loss: 0.452982\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191806; batch adversarial loss: 0.477031\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260389; batch adversarial loss: 0.472237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.201281; batch adversarial loss: 0.450032\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179663; batch adversarial loss: 0.437236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201893; batch adversarial loss: 0.432018\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187227; batch adversarial loss: 0.484239\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163913; batch adversarial loss: 0.425781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.184699; batch adversarial loss: 0.390980\n",
      "epoch 38; iter: 0; batch classifier loss: 0.190177; batch adversarial loss: 0.423889\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134671; batch adversarial loss: 0.550585\n",
      "epoch 40; iter: 0; batch classifier loss: 0.200353; batch adversarial loss: 0.661115\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145117; batch adversarial loss: 0.497961\n",
      "epoch 42; iter: 0; batch classifier loss: 0.214285; batch adversarial loss: 0.514699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.185567; batch adversarial loss: 0.469853\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245329; batch adversarial loss: 0.462751\n",
      "epoch 45; iter: 0; batch classifier loss: 0.288140; batch adversarial loss: 0.434853\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223846; batch adversarial loss: 0.419416\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259917; batch adversarial loss: 0.467797\n",
      "epoch 48; iter: 0; batch classifier loss: 0.236222; batch adversarial loss: 0.385553\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118899; batch adversarial loss: 0.569934\n",
      "epoch 50; iter: 0; batch classifier loss: 0.249146; batch adversarial loss: 0.401039\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178978; batch adversarial loss: 0.510663\n",
      "epoch 52; iter: 0; batch classifier loss: 0.202241; batch adversarial loss: 0.532243\n",
      "epoch 53; iter: 0; batch classifier loss: 0.231338; batch adversarial loss: 0.592911\n",
      "epoch 54; iter: 0; batch classifier loss: 0.179963; batch adversarial loss: 0.397036\n",
      "epoch 55; iter: 0; batch classifier loss: 0.284805; batch adversarial loss: 0.423089\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250748; batch adversarial loss: 0.395564\n",
      "epoch 57; iter: 0; batch classifier loss: 0.174654; batch adversarial loss: 0.436238\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240447; batch adversarial loss: 0.433774\n",
      "epoch 59; iter: 0; batch classifier loss: 0.248677; batch adversarial loss: 0.409728\n",
      "epoch 60; iter: 0; batch classifier loss: 0.233466; batch adversarial loss: 0.434180\n",
      "epoch 61; iter: 0; batch classifier loss: 0.151493; batch adversarial loss: 0.434854\n",
      "epoch 62; iter: 0; batch classifier loss: 0.221675; batch adversarial loss: 0.422262\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091101; batch adversarial loss: 0.420365\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085402; batch adversarial loss: 0.370625\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079556; batch adversarial loss: 0.504806\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086082; batch adversarial loss: 0.391842\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080984; batch adversarial loss: 0.468165\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106632; batch adversarial loss: 0.440323\n",
      "epoch 69; iter: 0; batch classifier loss: 0.151888; batch adversarial loss: 0.385893\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115417; batch adversarial loss: 0.523595\n",
      "epoch 71; iter: 0; batch classifier loss: 0.097919; batch adversarial loss: 0.503715\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116990; batch adversarial loss: 0.479330\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114879; batch adversarial loss: 0.418465\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097563; batch adversarial loss: 0.446675\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086892; batch adversarial loss: 0.435245\n",
      "epoch 76; iter: 0; batch classifier loss: 0.087943; batch adversarial loss: 0.362592\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099254; batch adversarial loss: 0.418921\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112400; batch adversarial loss: 0.520770\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067297; batch adversarial loss: 0.511529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118650; batch adversarial loss: 0.441818\n",
      "epoch 81; iter: 0; batch classifier loss: 0.115804; batch adversarial loss: 0.515752\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113387; batch adversarial loss: 0.421461\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071687; batch adversarial loss: 0.566943\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043551; batch adversarial loss: 0.436093\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059449; batch adversarial loss: 0.465340\n",
      "epoch 86; iter: 0; batch classifier loss: 0.101628; batch adversarial loss: 0.435967\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036890; batch adversarial loss: 0.480632\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067471; batch adversarial loss: 0.439746\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081804; batch adversarial loss: 0.429108\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089642; batch adversarial loss: 0.510660\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096506; batch adversarial loss: 0.326808\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042203; batch adversarial loss: 0.420462\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046384; batch adversarial loss: 0.477648\n",
      "epoch 94; iter: 0; batch classifier loss: 0.068173; batch adversarial loss: 0.488551\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066393; batch adversarial loss: 0.403384\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050219; batch adversarial loss: 0.486818\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064441; batch adversarial loss: 0.495829\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054470; batch adversarial loss: 0.458130\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056393; batch adversarial loss: 0.444708\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059008; batch adversarial loss: 0.411144\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068285; batch adversarial loss: 0.466456\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040101; batch adversarial loss: 0.457870\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057676; batch adversarial loss: 0.437336\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079899; batch adversarial loss: 0.403372\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026008; batch adversarial loss: 0.502373\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044577; batch adversarial loss: 0.414026\n",
      "epoch 107; iter: 0; batch classifier loss: 0.023096; batch adversarial loss: 0.449568\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058255; batch adversarial loss: 0.382154\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045128; batch adversarial loss: 0.478566\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066922; batch adversarial loss: 0.361319\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043241; batch adversarial loss: 0.452512\n",
      "epoch 112; iter: 0; batch classifier loss: 0.074359; batch adversarial loss: 0.549845\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056108; batch adversarial loss: 0.447637\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040862; batch adversarial loss: 0.433389\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024375; batch adversarial loss: 0.411210\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042329; batch adversarial loss: 0.477171\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054455; batch adversarial loss: 0.431702\n",
      "epoch 118; iter: 0; batch classifier loss: 0.011483; batch adversarial loss: 0.488203\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028891; batch adversarial loss: 0.379306\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034127; batch adversarial loss: 0.412155\n",
      "epoch 121; iter: 0; batch classifier loss: 0.016940; batch adversarial loss: 0.416362\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042561; batch adversarial loss: 0.480212\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041904; batch adversarial loss: 0.384968\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016645; batch adversarial loss: 0.422607\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044103; batch adversarial loss: 0.346942\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.432123\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046783; batch adversarial loss: 0.561387\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024327; batch adversarial loss: 0.400086\n",
      "epoch 129; iter: 0; batch classifier loss: 0.060998; batch adversarial loss: 0.494900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.045699; batch adversarial loss: 0.287988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060855; batch adversarial loss: 0.449485\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015359; batch adversarial loss: 0.466217\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026667; batch adversarial loss: 0.545334\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017571; batch adversarial loss: 0.463786\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014410; batch adversarial loss: 0.436016\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024982; batch adversarial loss: 0.415417\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035987; batch adversarial loss: 0.399759\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013722; batch adversarial loss: 0.397684\n",
      "epoch 139; iter: 0; batch classifier loss: 0.041023; batch adversarial loss: 0.437648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038985; batch adversarial loss: 0.398943\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017098; batch adversarial loss: 0.430436\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031397; batch adversarial loss: 0.397300\n",
      "epoch 143; iter: 0; batch classifier loss: 0.005926; batch adversarial loss: 0.541602\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027040; batch adversarial loss: 0.389451\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023566; batch adversarial loss: 0.386188\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028439; batch adversarial loss: 0.406577\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025613; batch adversarial loss: 0.471029\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016413; batch adversarial loss: 0.411696\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015266; batch adversarial loss: 0.471743\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011114; batch adversarial loss: 0.468001\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.485310\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009703; batch adversarial loss: 0.431724\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011531; batch adversarial loss: 0.462604\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025672; batch adversarial loss: 0.412727\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015163; batch adversarial loss: 0.381637\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016963; batch adversarial loss: 0.466394\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016413; batch adversarial loss: 0.459252\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029133; batch adversarial loss: 0.434112\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008176; batch adversarial loss: 0.407152\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025227; batch adversarial loss: 0.449611\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016372; batch adversarial loss: 0.398085\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023147; batch adversarial loss: 0.455390\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020591; batch adversarial loss: 0.449886\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016313; batch adversarial loss: 0.417702\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016616; batch adversarial loss: 0.498695\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023741; batch adversarial loss: 0.424215\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031049; batch adversarial loss: 0.536440\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011769; batch adversarial loss: 0.476890\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015868; batch adversarial loss: 0.516722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010091; batch adversarial loss: 0.467317\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.466160\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047408; batch adversarial loss: 0.428105\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010900; batch adversarial loss: 0.483395\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026720; batch adversarial loss: 0.442420\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010625; batch adversarial loss: 0.549394\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015989; batch adversarial loss: 0.525161\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029265; batch adversarial loss: 0.482745\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019730; batch adversarial loss: 0.372158\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006410; batch adversarial loss: 0.394985\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021102; batch adversarial loss: 0.394905\n",
      "epoch 181; iter: 0; batch classifier loss: 0.002991; batch adversarial loss: 0.441772\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020782; batch adversarial loss: 0.461743\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.431772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006652; batch adversarial loss: 0.476123\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032222; batch adversarial loss: 0.456259\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012394; batch adversarial loss: 0.471595\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016075; batch adversarial loss: 0.544263\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005981; batch adversarial loss: 0.547603\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038328; batch adversarial loss: 0.411759\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009014; batch adversarial loss: 0.445970\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034259; batch adversarial loss: 0.444632\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019238; batch adversarial loss: 0.466402\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035524; batch adversarial loss: 0.474538\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030173; batch adversarial loss: 0.457129\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009161; batch adversarial loss: 0.423321\n",
      "epoch 196; iter: 0; batch classifier loss: 0.002867; batch adversarial loss: 0.341892\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025732; batch adversarial loss: 0.472937\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015831; batch adversarial loss: 0.380260\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009591; batch adversarial loss: 0.384507\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693598; batch adversarial loss: 1.001201\n",
      "epoch 1; iter: 0; batch classifier loss: 0.745716; batch adversarial loss: 1.172362\n",
      "epoch 2; iter: 0; batch classifier loss: 0.888812; batch adversarial loss: 1.159329\n",
      "epoch 3; iter: 0; batch classifier loss: 1.141048; batch adversarial loss: 1.112266\n",
      "epoch 4; iter: 0; batch classifier loss: 1.046336; batch adversarial loss: 0.970514\n",
      "epoch 5; iter: 0; batch classifier loss: 1.075727; batch adversarial loss: 0.873346\n",
      "epoch 6; iter: 0; batch classifier loss: 1.248942; batch adversarial loss: 0.834499\n",
      "epoch 7; iter: 0; batch classifier loss: 1.166154; batch adversarial loss: 0.740769\n",
      "epoch 8; iter: 0; batch classifier loss: 0.952160; batch adversarial loss: 0.690568\n",
      "epoch 9; iter: 0; batch classifier loss: 0.727633; batch adversarial loss: 0.619585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.655217; batch adversarial loss: 0.564314\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550139; batch adversarial loss: 0.572157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430689; batch adversarial loss: 0.505049\n",
      "epoch 13; iter: 0; batch classifier loss: 0.318498; batch adversarial loss: 0.508126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306766; batch adversarial loss: 0.498604\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218281; batch adversarial loss: 0.484210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.222897; batch adversarial loss: 0.535013\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314097; batch adversarial loss: 0.502743\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268373; batch adversarial loss: 0.478404\n",
      "epoch 19; iter: 0; batch classifier loss: 0.233209; batch adversarial loss: 0.510048\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272047; batch adversarial loss: 0.434635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195280; batch adversarial loss: 0.528290\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188813; batch adversarial loss: 0.476849\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263374; batch adversarial loss: 0.499997\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238063; batch adversarial loss: 0.454678\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204998; batch adversarial loss: 0.445904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.233675; batch adversarial loss: 0.469364\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131872; batch adversarial loss: 0.516760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149926; batch adversarial loss: 0.487349\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139139; batch adversarial loss: 0.532562\n",
      "epoch 30; iter: 0; batch classifier loss: 0.197331; batch adversarial loss: 0.463669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.218802; batch adversarial loss: 0.424378\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138781; batch adversarial loss: 0.415306\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167139; batch adversarial loss: 0.432372\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148082; batch adversarial loss: 0.503914\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138507; batch adversarial loss: 0.519349\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129842; batch adversarial loss: 0.467659\n",
      "epoch 37; iter: 0; batch classifier loss: 0.142704; batch adversarial loss: 0.513979\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209916; batch adversarial loss: 0.441247\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126262; batch adversarial loss: 0.434082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.149406; batch adversarial loss: 0.314139\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137746; batch adversarial loss: 0.449759\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096710; batch adversarial loss: 0.529678\n",
      "epoch 43; iter: 0; batch classifier loss: 0.111247; batch adversarial loss: 0.570353\n",
      "epoch 44; iter: 0; batch classifier loss: 0.114962; batch adversarial loss: 0.459552\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119308; batch adversarial loss: 0.463524\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108866; batch adversarial loss: 0.462542\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119963; batch adversarial loss: 0.497756\n",
      "epoch 48; iter: 0; batch classifier loss: 0.172427; batch adversarial loss: 0.404931\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116370; batch adversarial loss: 0.423996\n",
      "epoch 50; iter: 0; batch classifier loss: 0.141411; batch adversarial loss: 0.427648\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104415; batch adversarial loss: 0.471187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.084820; batch adversarial loss: 0.398034\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088442; batch adversarial loss: 0.446970\n",
      "epoch 54; iter: 0; batch classifier loss: 0.060503; batch adversarial loss: 0.456071\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115585; batch adversarial loss: 0.343388\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084831; batch adversarial loss: 0.553801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089092; batch adversarial loss: 0.518457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.126723; batch adversarial loss: 0.478461\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067533; batch adversarial loss: 0.467231\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114069; batch adversarial loss: 0.449243\n",
      "epoch 61; iter: 0; batch classifier loss: 0.081401; batch adversarial loss: 0.470343\n",
      "epoch 62; iter: 0; batch classifier loss: 0.092759; batch adversarial loss: 0.488957\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099616; batch adversarial loss: 0.343267\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112479; batch adversarial loss: 0.426587\n",
      "epoch 65; iter: 0; batch classifier loss: 0.093139; batch adversarial loss: 0.461934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094844; batch adversarial loss: 0.400024\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052248; batch adversarial loss: 0.558841\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101701; batch adversarial loss: 0.483550\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083677; batch adversarial loss: 0.376004\n",
      "epoch 70; iter: 0; batch classifier loss: 0.125528; batch adversarial loss: 0.327332\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070203; batch adversarial loss: 0.489346\n",
      "epoch 72; iter: 0; batch classifier loss: 0.101570; batch adversarial loss: 0.438915\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084352; batch adversarial loss: 0.560432\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081520; batch adversarial loss: 0.477994\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061115; batch adversarial loss: 0.432744\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096368; batch adversarial loss: 0.533722\n",
      "epoch 77; iter: 0; batch classifier loss: 0.036301; batch adversarial loss: 0.373468\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080356; batch adversarial loss: 0.457831\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114464; batch adversarial loss: 0.382399\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049314; batch adversarial loss: 0.539939\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071693; batch adversarial loss: 0.420180\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061990; batch adversarial loss: 0.508267\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073431; batch adversarial loss: 0.475934\n",
      "epoch 84; iter: 0; batch classifier loss: 0.101644; batch adversarial loss: 0.414308\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071991; batch adversarial loss: 0.395604\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092277; batch adversarial loss: 0.402714\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042236; batch adversarial loss: 0.507857\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127415; batch adversarial loss: 0.469660\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068772; batch adversarial loss: 0.455366\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065996; batch adversarial loss: 0.469312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086631; batch adversarial loss: 0.418043\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072187; batch adversarial loss: 0.466943\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061224; batch adversarial loss: 0.439583\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075836; batch adversarial loss: 0.483640\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048574; batch adversarial loss: 0.356022\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081844; batch adversarial loss: 0.503809\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040276; batch adversarial loss: 0.450669\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075693; batch adversarial loss: 0.464179\n",
      "epoch 99; iter: 0; batch classifier loss: 0.123899; batch adversarial loss: 0.293260\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076452; batch adversarial loss: 0.464621\n",
      "epoch 101; iter: 0; batch classifier loss: 0.126358; batch adversarial loss: 0.458554\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049394; batch adversarial loss: 0.464851\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036613; batch adversarial loss: 0.447927\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037657; batch adversarial loss: 0.465065\n",
      "epoch 105; iter: 0; batch classifier loss: 0.132785; batch adversarial loss: 0.448013\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050919; batch adversarial loss: 0.433680\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058666; batch adversarial loss: 0.508550\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065757; batch adversarial loss: 0.370729\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059034; batch adversarial loss: 0.420029\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089545; batch adversarial loss: 0.394516\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036127; batch adversarial loss: 0.471005\n",
      "epoch 112; iter: 0; batch classifier loss: 0.072148; batch adversarial loss: 0.422760\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049365; batch adversarial loss: 0.460917\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046279; batch adversarial loss: 0.407849\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071443; batch adversarial loss: 0.487598\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046539; batch adversarial loss: 0.532280\n",
      "epoch 117; iter: 0; batch classifier loss: 0.097481; batch adversarial loss: 0.494314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025798; batch adversarial loss: 0.450135\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036036; batch adversarial loss: 0.458089\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050390; batch adversarial loss: 0.472317\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034682; batch adversarial loss: 0.498273\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036038; batch adversarial loss: 0.377340\n",
      "epoch 123; iter: 0; batch classifier loss: 0.062396; batch adversarial loss: 0.381594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.044512; batch adversarial loss: 0.441167\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048678; batch adversarial loss: 0.416892\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045946; batch adversarial loss: 0.524414\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056722; batch adversarial loss: 0.465972\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018972; batch adversarial loss: 0.409714\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032731; batch adversarial loss: 0.430265\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037849; batch adversarial loss: 0.489465\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041150; batch adversarial loss: 0.444377\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021439; batch adversarial loss: 0.460783\n",
      "epoch 133; iter: 0; batch classifier loss: 0.078917; batch adversarial loss: 0.431177\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032972; batch adversarial loss: 0.447879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019874; batch adversarial loss: 0.374945\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035429; batch adversarial loss: 0.506784\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040965; batch adversarial loss: 0.421008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056640; batch adversarial loss: 0.509421\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042396; batch adversarial loss: 0.558632\n",
      "epoch 140; iter: 0; batch classifier loss: 0.063023; batch adversarial loss: 0.468813\n",
      "epoch 141; iter: 0; batch classifier loss: 0.077615; batch adversarial loss: 0.423751\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025215; batch adversarial loss: 0.500980\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042284; batch adversarial loss: 0.479294\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030379; batch adversarial loss: 0.519274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042785; batch adversarial loss: 0.497643\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015612; batch adversarial loss: 0.444752\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029807; batch adversarial loss: 0.500206\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017678; batch adversarial loss: 0.467212\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036718; batch adversarial loss: 0.501067\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030852; batch adversarial loss: 0.479296\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019588; batch adversarial loss: 0.590551\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036461; batch adversarial loss: 0.454004\n",
      "epoch 153; iter: 0; batch classifier loss: 0.051408; batch adversarial loss: 0.433986\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029691; batch adversarial loss: 0.465010\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052517; batch adversarial loss: 0.460785\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044971; batch adversarial loss: 0.464927\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035338; batch adversarial loss: 0.472157\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027738; batch adversarial loss: 0.394268\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032081; batch adversarial loss: 0.419927\n",
      "epoch 160; iter: 0; batch classifier loss: 0.054040; batch adversarial loss: 0.398328\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036247; batch adversarial loss: 0.436809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013231; batch adversarial loss: 0.393551\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044800; batch adversarial loss: 0.417197\n",
      "epoch 164; iter: 0; batch classifier loss: 0.053174; batch adversarial loss: 0.362259\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052068; batch adversarial loss: 0.441690\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023243; batch adversarial loss: 0.412281\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014962; batch adversarial loss: 0.410039\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040763; batch adversarial loss: 0.402047\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023000; batch adversarial loss: 0.427337\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037538; batch adversarial loss: 0.494382\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010854; batch adversarial loss: 0.482932\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044151; batch adversarial loss: 0.517563\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027281; batch adversarial loss: 0.426017\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021528; batch adversarial loss: 0.506078\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013857; batch adversarial loss: 0.488864\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014517; batch adversarial loss: 0.534028\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011927; batch adversarial loss: 0.474610\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018524; batch adversarial loss: 0.426847\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033214; batch adversarial loss: 0.499696\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.520940\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016291; batch adversarial loss: 0.536635\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024990; batch adversarial loss: 0.392646\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026102; batch adversarial loss: 0.491827\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045941; batch adversarial loss: 0.444215\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017170; batch adversarial loss: 0.456826\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042821; batch adversarial loss: 0.465060\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042189; batch adversarial loss: 0.366877\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019964; batch adversarial loss: 0.498533\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027513; batch adversarial loss: 0.422802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011096; batch adversarial loss: 0.368084\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019971; batch adversarial loss: 0.298368\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034652; batch adversarial loss: 0.407748\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012636; batch adversarial loss: 0.441736\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023997; batch adversarial loss: 0.526144\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013056; batch adversarial loss: 0.417574\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023797; batch adversarial loss: 0.424673\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018205; batch adversarial loss: 0.351417\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014157; batch adversarial loss: 0.404786\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.393417\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692182; batch adversarial loss: 0.642765\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455443; batch adversarial loss: 0.636646\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391889; batch adversarial loss: 0.630753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363971; batch adversarial loss: 0.599832\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327986; batch adversarial loss: 0.596901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.263038; batch adversarial loss: 0.561557\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271145; batch adversarial loss: 0.511283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.251102; batch adversarial loss: 0.525490\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280747; batch adversarial loss: 0.481548\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315652; batch adversarial loss: 0.453170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.209887; batch adversarial loss: 0.500244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.143142; batch adversarial loss: 0.549431\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274002; batch adversarial loss: 0.492063\n",
      "epoch 13; iter: 0; batch classifier loss: 0.182781; batch adversarial loss: 0.475181\n",
      "epoch 14; iter: 0; batch classifier loss: 0.159261; batch adversarial loss: 0.529604\n",
      "epoch 15; iter: 0; batch classifier loss: 0.143554; batch adversarial loss: 0.477681\n",
      "epoch 16; iter: 0; batch classifier loss: 0.188020; batch adversarial loss: 0.440458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.134119; batch adversarial loss: 0.473513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.143784; batch adversarial loss: 0.491442\n",
      "epoch 19; iter: 0; batch classifier loss: 0.097870; batch adversarial loss: 0.463663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.190765; batch adversarial loss: 0.429689\n",
      "epoch 21; iter: 0; batch classifier loss: 0.196703; batch adversarial loss: 0.418884\n",
      "epoch 22; iter: 0; batch classifier loss: 0.190109; batch adversarial loss: 0.530046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203603; batch adversarial loss: 0.582219\n",
      "epoch 24; iter: 0; batch classifier loss: 0.135964; batch adversarial loss: 0.557477\n",
      "epoch 25; iter: 0; batch classifier loss: 0.179677; batch adversarial loss: 0.453545\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176830; batch adversarial loss: 0.494632\n",
      "epoch 27; iter: 0; batch classifier loss: 0.240637; batch adversarial loss: 0.538464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.149554; batch adversarial loss: 0.500509\n",
      "epoch 29; iter: 0; batch classifier loss: 0.196609; batch adversarial loss: 0.500396\n",
      "epoch 30; iter: 0; batch classifier loss: 0.152266; batch adversarial loss: 0.556791\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168044; batch adversarial loss: 0.526354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194752; batch adversarial loss: 0.408805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237302; batch adversarial loss: 0.489189\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240148; batch adversarial loss: 0.444937\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317361; batch adversarial loss: 0.529826\n",
      "epoch 36; iter: 0; batch classifier loss: 0.174915; batch adversarial loss: 0.400802\n",
      "epoch 37; iter: 0; batch classifier loss: 0.073573; batch adversarial loss: 0.366340\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117669; batch adversarial loss: 0.398615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.070630; batch adversarial loss: 0.477818\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107720; batch adversarial loss: 0.410512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111481; batch adversarial loss: 0.416977\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103593; batch adversarial loss: 0.393228\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097846; batch adversarial loss: 0.443328\n",
      "epoch 44; iter: 0; batch classifier loss: 0.063918; batch adversarial loss: 0.413567\n",
      "epoch 45; iter: 0; batch classifier loss: 0.128768; batch adversarial loss: 0.473327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083001; batch adversarial loss: 0.390482\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087164; batch adversarial loss: 0.425284\n",
      "epoch 48; iter: 0; batch classifier loss: 0.052983; batch adversarial loss: 0.541233\n",
      "epoch 49; iter: 0; batch classifier loss: 0.062752; batch adversarial loss: 0.429209\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082890; batch adversarial loss: 0.338406\n",
      "epoch 51; iter: 0; batch classifier loss: 0.071457; batch adversarial loss: 0.453396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.065632; batch adversarial loss: 0.485348\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070691; batch adversarial loss: 0.405192\n",
      "epoch 54; iter: 0; batch classifier loss: 0.095694; batch adversarial loss: 0.440228\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072283; batch adversarial loss: 0.460605\n",
      "epoch 56; iter: 0; batch classifier loss: 0.059208; batch adversarial loss: 0.447341\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077645; batch adversarial loss: 0.432875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065158; batch adversarial loss: 0.534194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063534; batch adversarial loss: 0.480910\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090019; batch adversarial loss: 0.625260\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088819; batch adversarial loss: 0.419685\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065119; batch adversarial loss: 0.409805\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095070; batch adversarial loss: 0.478476\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086890; batch adversarial loss: 0.455155\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079932; batch adversarial loss: 0.376366\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058939; batch adversarial loss: 0.511342\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088441; batch adversarial loss: 0.514296\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075110; batch adversarial loss: 0.460260\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069791; batch adversarial loss: 0.465708\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078091; batch adversarial loss: 0.480279\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069344; batch adversarial loss: 0.489351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060756; batch adversarial loss: 0.491817\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066947; batch adversarial loss: 0.464970\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081054; batch adversarial loss: 0.418703\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081714; batch adversarial loss: 0.359410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055552; batch adversarial loss: 0.389955\n",
      "epoch 77; iter: 0; batch classifier loss: 0.128871; batch adversarial loss: 0.487647\n",
      "epoch 78; iter: 0; batch classifier loss: 0.111920; batch adversarial loss: 0.425379\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115970; batch adversarial loss: 0.517031\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126359; batch adversarial loss: 0.344623\n",
      "epoch 81; iter: 0; batch classifier loss: 0.102203; batch adversarial loss: 0.472175\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086237; batch adversarial loss: 0.554555\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074245; batch adversarial loss: 0.390394\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086497; batch adversarial loss: 0.449093\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077908; batch adversarial loss: 0.539073\n",
      "epoch 86; iter: 0; batch classifier loss: 0.103737; batch adversarial loss: 0.403757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088236; batch adversarial loss: 0.452628\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093198; batch adversarial loss: 0.501430\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064161; batch adversarial loss: 0.498673\n",
      "epoch 90; iter: 0; batch classifier loss: 0.121913; batch adversarial loss: 0.364680\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082186; batch adversarial loss: 0.452079\n",
      "epoch 92; iter: 0; batch classifier loss: 0.081164; batch adversarial loss: 0.504230\n",
      "epoch 93; iter: 0; batch classifier loss: 0.091041; batch adversarial loss: 0.387401\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058170; batch adversarial loss: 0.537444\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075247; batch adversarial loss: 0.471030\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080344; batch adversarial loss: 0.450529\n",
      "epoch 97; iter: 0; batch classifier loss: 0.076960; batch adversarial loss: 0.441394\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066354; batch adversarial loss: 0.370406\n",
      "epoch 99; iter: 0; batch classifier loss: 0.111431; batch adversarial loss: 0.419696\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090061; batch adversarial loss: 0.479256\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085259; batch adversarial loss: 0.366250\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042566; batch adversarial loss: 0.463029\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063323; batch adversarial loss: 0.414732\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047977; batch adversarial loss: 0.457561\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056154; batch adversarial loss: 0.480691\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052008; batch adversarial loss: 0.484860\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050297; batch adversarial loss: 0.432898\n",
      "epoch 108; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.382500\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068659; batch adversarial loss: 0.462886\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040515; batch adversarial loss: 0.429167\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039041; batch adversarial loss: 0.491494\n",
      "epoch 112; iter: 0; batch classifier loss: 0.109369; batch adversarial loss: 0.408811\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059502; batch adversarial loss: 0.433770\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041061; batch adversarial loss: 0.437214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.475747\n",
      "epoch 116; iter: 0; batch classifier loss: 0.062409; batch adversarial loss: 0.373383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.025809; batch adversarial loss: 0.439850\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021722; batch adversarial loss: 0.525854\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035225; batch adversarial loss: 0.446020\n",
      "epoch 120; iter: 0; batch classifier loss: 0.061462; batch adversarial loss: 0.515994\n",
      "epoch 121; iter: 0; batch classifier loss: 0.067174; batch adversarial loss: 0.472767\n",
      "epoch 122; iter: 0; batch classifier loss: 0.021605; batch adversarial loss: 0.478344\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084086; batch adversarial loss: 0.475467\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042143; batch adversarial loss: 0.341656\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067779; batch adversarial loss: 0.448391\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.421149\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044500; batch adversarial loss: 0.459272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030577; batch adversarial loss: 0.426125\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038728; batch adversarial loss: 0.333091\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023031; batch adversarial loss: 0.421964\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046713; batch adversarial loss: 0.439775\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057308; batch adversarial loss: 0.391582\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035038; batch adversarial loss: 0.437266\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024937; batch adversarial loss: 0.491119\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045883; batch adversarial loss: 0.499256\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.478214\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049271; batch adversarial loss: 0.503095\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056845; batch adversarial loss: 0.421129\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036378; batch adversarial loss: 0.402105\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050843; batch adversarial loss: 0.382303\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027418; batch adversarial loss: 0.449806\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029945; batch adversarial loss: 0.419541\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022263; batch adversarial loss: 0.416240\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052309; batch adversarial loss: 0.437142\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025835; batch adversarial loss: 0.489721\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038931; batch adversarial loss: 0.449078\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037171; batch adversarial loss: 0.377023\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020993; batch adversarial loss: 0.343761\n",
      "epoch 149; iter: 0; batch classifier loss: 0.068131; batch adversarial loss: 0.415978\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050055; batch adversarial loss: 0.454864\n",
      "epoch 151; iter: 0; batch classifier loss: 0.060327; batch adversarial loss: 0.410989\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034292; batch adversarial loss: 0.553753\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024532; batch adversarial loss: 0.473414\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.503948\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014892; batch adversarial loss: 0.499865\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035625; batch adversarial loss: 0.409100\n",
      "epoch 157; iter: 0; batch classifier loss: 0.014171; batch adversarial loss: 0.421631\n",
      "epoch 158; iter: 0; batch classifier loss: 0.053439; batch adversarial loss: 0.431000\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023290; batch adversarial loss: 0.524281\n",
      "epoch 160; iter: 0; batch classifier loss: 0.061823; batch adversarial loss: 0.451201\n",
      "epoch 161; iter: 0; batch classifier loss: 0.036776; batch adversarial loss: 0.452266\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031605; batch adversarial loss: 0.442490\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053928; batch adversarial loss: 0.431751\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025822; batch adversarial loss: 0.518743\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017771; batch adversarial loss: 0.458434\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035674; batch adversarial loss: 0.483695\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010835; batch adversarial loss: 0.468635\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023931; batch adversarial loss: 0.463697\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006297; batch adversarial loss: 0.554343\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021050; batch adversarial loss: 0.433485\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037739; batch adversarial loss: 0.379732\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007966; batch adversarial loss: 0.451295\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019187; batch adversarial loss: 0.480160\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013977; batch adversarial loss: 0.407683\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052957; batch adversarial loss: 0.444130\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013659; batch adversarial loss: 0.464416\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026227; batch adversarial loss: 0.352674\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055623; batch adversarial loss: 0.469028\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006571; batch adversarial loss: 0.430955\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029382; batch adversarial loss: 0.405910\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020719; batch adversarial loss: 0.502808\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041242; batch adversarial loss: 0.463740\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.416718\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024304; batch adversarial loss: 0.416027\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007126; batch adversarial loss: 0.501532\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023406; batch adversarial loss: 0.553651\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015332; batch adversarial loss: 0.485503\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020689; batch adversarial loss: 0.421241\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008456; batch adversarial loss: 0.477530\n",
      "epoch 190; iter: 0; batch classifier loss: 0.067888; batch adversarial loss: 0.437410\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017775; batch adversarial loss: 0.506280\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017658; batch adversarial loss: 0.465604\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035257; batch adversarial loss: 0.483592\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016668; batch adversarial loss: 0.372362\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028170; batch adversarial loss: 0.421389\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029140; batch adversarial loss: 0.534365\n",
      "epoch 197; iter: 0; batch classifier loss: 0.046529; batch adversarial loss: 0.483290\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016770; batch adversarial loss: 0.385987\n",
      "epoch 199; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.355638\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705753; batch adversarial loss: 0.744329\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426580; batch adversarial loss: 0.677702\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360308; batch adversarial loss: 0.639793\n",
      "epoch 3; iter: 0; batch classifier loss: 0.458468; batch adversarial loss: 0.615294\n",
      "epoch 4; iter: 0; batch classifier loss: 0.516780; batch adversarial loss: 0.599372\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344322; batch adversarial loss: 0.567899\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349238; batch adversarial loss: 0.567447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412616; batch adversarial loss: 0.575511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446577; batch adversarial loss: 0.548036\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384643; batch adversarial loss: 0.545862\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574601; batch adversarial loss: 0.564674\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447284; batch adversarial loss: 0.520034\n",
      "epoch 12; iter: 0; batch classifier loss: 0.486658; batch adversarial loss: 0.536340\n",
      "epoch 13; iter: 0; batch classifier loss: 0.409742; batch adversarial loss: 0.439080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.420885; batch adversarial loss: 0.489805\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373810; batch adversarial loss: 0.507963\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352630; batch adversarial loss: 0.491181\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388165; batch adversarial loss: 0.496747\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326628; batch adversarial loss: 0.490005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281085; batch adversarial loss: 0.462111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328037; batch adversarial loss: 0.421002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.378792; batch adversarial loss: 0.503109\n",
      "epoch 22; iter: 0; batch classifier loss: 0.296397; batch adversarial loss: 0.491823\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389787; batch adversarial loss: 0.484311\n",
      "epoch 24; iter: 0; batch classifier loss: 0.319755; batch adversarial loss: 0.479095\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275864; batch adversarial loss: 0.503964\n",
      "epoch 26; iter: 0; batch classifier loss: 0.344306; batch adversarial loss: 0.425297\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277299; batch adversarial loss: 0.495820\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195091; batch adversarial loss: 0.476365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199837; batch adversarial loss: 0.499969\n",
      "epoch 30; iter: 0; batch classifier loss: 0.263538; batch adversarial loss: 0.452496\n",
      "epoch 31; iter: 0; batch classifier loss: 0.230594; batch adversarial loss: 0.509470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265556; batch adversarial loss: 0.483622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267917; batch adversarial loss: 0.530893\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240880; batch adversarial loss: 0.465170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.234798; batch adversarial loss: 0.482851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211498; batch adversarial loss: 0.512368\n",
      "epoch 37; iter: 0; batch classifier loss: 0.202361; batch adversarial loss: 0.455379\n",
      "epoch 38; iter: 0; batch classifier loss: 0.231509; batch adversarial loss: 0.395822\n",
      "epoch 39; iter: 0; batch classifier loss: 0.228196; batch adversarial loss: 0.468047\n",
      "epoch 40; iter: 0; batch classifier loss: 0.215012; batch adversarial loss: 0.479035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.199128; batch adversarial loss: 0.471421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197775; batch adversarial loss: 0.490418\n",
      "epoch 43; iter: 0; batch classifier loss: 0.197760; batch adversarial loss: 0.547489\n",
      "epoch 44; iter: 0; batch classifier loss: 0.141110; batch adversarial loss: 0.530366\n",
      "epoch 45; iter: 0; batch classifier loss: 0.200894; batch adversarial loss: 0.437318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.229357; batch adversarial loss: 0.495519\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173861; batch adversarial loss: 0.491784\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196544; batch adversarial loss: 0.339546\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110640; batch adversarial loss: 0.451361\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207042; batch adversarial loss: 0.444207\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178071; batch adversarial loss: 0.528662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.206854; batch adversarial loss: 0.458476\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176039; batch adversarial loss: 0.457516\n",
      "epoch 54; iter: 0; batch classifier loss: 0.165416; batch adversarial loss: 0.397132\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158485; batch adversarial loss: 0.529541\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189989; batch adversarial loss: 0.482043\n",
      "epoch 57; iter: 0; batch classifier loss: 0.187908; batch adversarial loss: 0.480359\n",
      "epoch 58; iter: 0; batch classifier loss: 0.163028; batch adversarial loss: 0.481476\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148348; batch adversarial loss: 0.435258\n",
      "epoch 60; iter: 0; batch classifier loss: 0.142098; batch adversarial loss: 0.520080\n",
      "epoch 61; iter: 0; batch classifier loss: 0.149093; batch adversarial loss: 0.508471\n",
      "epoch 62; iter: 0; batch classifier loss: 0.212676; batch adversarial loss: 0.409478\n",
      "epoch 63; iter: 0; batch classifier loss: 0.142744; batch adversarial loss: 0.494758\n",
      "epoch 64; iter: 0; batch classifier loss: 0.213341; batch adversarial loss: 0.494634\n",
      "epoch 65; iter: 0; batch classifier loss: 0.178119; batch adversarial loss: 0.385502\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206332; batch adversarial loss: 0.458597\n",
      "epoch 67; iter: 0; batch classifier loss: 0.173527; batch adversarial loss: 0.448046\n",
      "epoch 68; iter: 0; batch classifier loss: 0.209289; batch adversarial loss: 0.384428\n",
      "epoch 69; iter: 0; batch classifier loss: 0.179995; batch adversarial loss: 0.420097\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113199; batch adversarial loss: 0.435812\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148283; batch adversarial loss: 0.498455\n",
      "epoch 72; iter: 0; batch classifier loss: 0.155242; batch adversarial loss: 0.477916\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129160; batch adversarial loss: 0.418278\n",
      "epoch 74; iter: 0; batch classifier loss: 0.128399; batch adversarial loss: 0.538753\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130535; batch adversarial loss: 0.441783\n",
      "epoch 76; iter: 0; batch classifier loss: 0.137165; batch adversarial loss: 0.482777\n",
      "epoch 77; iter: 0; batch classifier loss: 0.106583; batch adversarial loss: 0.494387\n",
      "epoch 78; iter: 0; batch classifier loss: 0.126277; batch adversarial loss: 0.448240\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091188; batch adversarial loss: 0.495538\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102961; batch adversarial loss: 0.500594\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083918; batch adversarial loss: 0.466660\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083425; batch adversarial loss: 0.461250\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090050; batch adversarial loss: 0.439874\n",
      "epoch 84; iter: 0; batch classifier loss: 0.115890; batch adversarial loss: 0.414159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.110778; batch adversarial loss: 0.458092\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099595; batch adversarial loss: 0.401641\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067616; batch adversarial loss: 0.410768\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066886; batch adversarial loss: 0.478178\n",
      "epoch 89; iter: 0; batch classifier loss: 0.099018; batch adversarial loss: 0.495421\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066539; batch adversarial loss: 0.379974\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063899; batch adversarial loss: 0.381641\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050044; batch adversarial loss: 0.432840\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059096; batch adversarial loss: 0.512558\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.463028\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057911; batch adversarial loss: 0.455922\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062894; batch adversarial loss: 0.468360\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071770; batch adversarial loss: 0.396894\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058909; batch adversarial loss: 0.466902\n",
      "epoch 99; iter: 0; batch classifier loss: 0.036533; batch adversarial loss: 0.440611\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050940; batch adversarial loss: 0.355741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057747; batch adversarial loss: 0.418247\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061945; batch adversarial loss: 0.428043\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025910; batch adversarial loss: 0.521311\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048023; batch adversarial loss: 0.436279\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048534; batch adversarial loss: 0.421524\n",
      "epoch 106; iter: 0; batch classifier loss: 0.023430; batch adversarial loss: 0.408307\n",
      "epoch 107; iter: 0; batch classifier loss: 0.009147; batch adversarial loss: 0.384916\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054506; batch adversarial loss: 0.453825\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039905; batch adversarial loss: 0.409728\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037475; batch adversarial loss: 0.425436\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060974; batch adversarial loss: 0.515883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.047968; batch adversarial loss: 0.442190\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.477811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049049; batch adversarial loss: 0.473327\n",
      "epoch 115; iter: 0; batch classifier loss: 0.017969; batch adversarial loss: 0.556606\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027979; batch adversarial loss: 0.518945\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034142; batch adversarial loss: 0.442661\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055512; batch adversarial loss: 0.430451\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017124; batch adversarial loss: 0.459318\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048144; batch adversarial loss: 0.392173\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025056; batch adversarial loss: 0.343632\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030986; batch adversarial loss: 0.518530\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037891; batch adversarial loss: 0.408521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035096; batch adversarial loss: 0.518007\n",
      "epoch 125; iter: 0; batch classifier loss: 0.007351; batch adversarial loss: 0.442500\n",
      "epoch 126; iter: 0; batch classifier loss: 0.019070; batch adversarial loss: 0.453149\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019043; batch adversarial loss: 0.441160\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.422846\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050068; batch adversarial loss: 0.459002\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.494866\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021180; batch adversarial loss: 0.432374\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030622; batch adversarial loss: 0.471377\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038701; batch adversarial loss: 0.459015\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015799; batch adversarial loss: 0.418341\n",
      "epoch 135; iter: 0; batch classifier loss: 0.016408; batch adversarial loss: 0.495360\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024249; batch adversarial loss: 0.373580\n",
      "epoch 137; iter: 0; batch classifier loss: 0.016070; batch adversarial loss: 0.565071\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054497; batch adversarial loss: 0.459443\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017792; batch adversarial loss: 0.511263\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023560; batch adversarial loss: 0.456888\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069273; batch adversarial loss: 0.485122\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028908; batch adversarial loss: 0.414091\n",
      "epoch 143; iter: 0; batch classifier loss: 0.006268; batch adversarial loss: 0.481502\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039142; batch adversarial loss: 0.473413\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.391119\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015273; batch adversarial loss: 0.467363\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042604; batch adversarial loss: 0.403999\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040781; batch adversarial loss: 0.458411\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021870; batch adversarial loss: 0.405828\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.471098\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015765; batch adversarial loss: 0.402930\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.482106\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018848; batch adversarial loss: 0.428002\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.368786\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017775; batch adversarial loss: 0.457955\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030156; batch adversarial loss: 0.434261\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046870; batch adversarial loss: 0.407718\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016437; batch adversarial loss: 0.422272\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019625; batch adversarial loss: 0.524660\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008501; batch adversarial loss: 0.468596\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008209; batch adversarial loss: 0.501544\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017262; batch adversarial loss: 0.456179\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042934; batch adversarial loss: 0.438461\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007594; batch adversarial loss: 0.550522\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007570; batch adversarial loss: 0.479507\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027018; batch adversarial loss: 0.450732\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012596; batch adversarial loss: 0.443295\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014277; batch adversarial loss: 0.442493\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030341; batch adversarial loss: 0.370154\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027072; batch adversarial loss: 0.483442\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.401091\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040812; batch adversarial loss: 0.396742\n",
      "epoch 173; iter: 0; batch classifier loss: 0.005717; batch adversarial loss: 0.409846\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016705; batch adversarial loss: 0.534238\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019065; batch adversarial loss: 0.481565\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010350; batch adversarial loss: 0.503300\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010197; batch adversarial loss: 0.528703\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008506; batch adversarial loss: 0.444394\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040196; batch adversarial loss: 0.450261\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007863; batch adversarial loss: 0.421939\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009985; batch adversarial loss: 0.521605\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023199; batch adversarial loss: 0.513447\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025665; batch adversarial loss: 0.455488\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031369; batch adversarial loss: 0.427676\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017233; batch adversarial loss: 0.578041\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019209; batch adversarial loss: 0.470618\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006565; batch adversarial loss: 0.444233\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042090; batch adversarial loss: 0.438305\n",
      "epoch 189; iter: 0; batch classifier loss: 0.053946; batch adversarial loss: 0.359824\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002464; batch adversarial loss: 0.488064\n",
      "epoch 191; iter: 0; batch classifier loss: 0.003947; batch adversarial loss: 0.465468\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012685; batch adversarial loss: 0.438066\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.486094\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010977; batch adversarial loss: 0.520568\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025114; batch adversarial loss: 0.431730\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010603; batch adversarial loss: 0.438693\n",
      "epoch 197; iter: 0; batch classifier loss: 0.005508; batch adversarial loss: 0.445755\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004188; batch adversarial loss: 0.441444\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008039; batch adversarial loss: 0.537923\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687689; batch adversarial loss: 0.682284\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474094; batch adversarial loss: 0.626374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.435173; batch adversarial loss: 0.622906\n",
      "epoch 3; iter: 0; batch classifier loss: 0.424422; batch adversarial loss: 0.574240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396244; batch adversarial loss: 0.564379\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321038; batch adversarial loss: 0.603358\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322622; batch adversarial loss: 0.543609\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379074; batch adversarial loss: 0.532765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.241090; batch adversarial loss: 0.576324\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367169; batch adversarial loss: 0.517572\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268908; batch adversarial loss: 0.501621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.285571; batch adversarial loss: 0.512561\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336441; batch adversarial loss: 0.543328\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302803; batch adversarial loss: 0.465528\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303343; batch adversarial loss: 0.462424\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344266; batch adversarial loss: 0.472790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.271027; batch adversarial loss: 0.467188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251267; batch adversarial loss: 0.455772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281817; batch adversarial loss: 0.454973\n",
      "epoch 19; iter: 0; batch classifier loss: 0.220221; batch adversarial loss: 0.447944\n",
      "epoch 20; iter: 0; batch classifier loss: 0.192223; batch adversarial loss: 0.516702\n",
      "epoch 21; iter: 0; batch classifier loss: 0.250271; batch adversarial loss: 0.404392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249476; batch adversarial loss: 0.445750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.253198; batch adversarial loss: 0.514657\n",
      "epoch 24; iter: 0; batch classifier loss: 0.200593; batch adversarial loss: 0.464793\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207108; batch adversarial loss: 0.441261\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204655; batch adversarial loss: 0.407615\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196810; batch adversarial loss: 0.452282\n",
      "epoch 28; iter: 0; batch classifier loss: 0.205579; batch adversarial loss: 0.423001\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185239; batch adversarial loss: 0.470140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.202347; batch adversarial loss: 0.490748\n",
      "epoch 31; iter: 0; batch classifier loss: 0.215254; batch adversarial loss: 0.426368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.199663; batch adversarial loss: 0.421952\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140306; batch adversarial loss: 0.580773\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196861; batch adversarial loss: 0.486770\n",
      "epoch 35; iter: 0; batch classifier loss: 0.190598; batch adversarial loss: 0.463329\n",
      "epoch 36; iter: 0; batch classifier loss: 0.190164; batch adversarial loss: 0.407597\n",
      "epoch 37; iter: 0; batch classifier loss: 0.254410; batch adversarial loss: 0.453328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247438; batch adversarial loss: 0.403809\n",
      "epoch 39; iter: 0; batch classifier loss: 0.244096; batch adversarial loss: 0.548394\n",
      "epoch 40; iter: 0; batch classifier loss: 0.187571; batch adversarial loss: 0.440087\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196211; batch adversarial loss: 0.506439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.176996; batch adversarial loss: 0.498291\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169641; batch adversarial loss: 0.449350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.236522; batch adversarial loss: 0.434384\n",
      "epoch 45; iter: 0; batch classifier loss: 0.249893; batch adversarial loss: 0.466981\n",
      "epoch 46; iter: 0; batch classifier loss: 0.163633; batch adversarial loss: 0.443434\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171793; batch adversarial loss: 0.375267\n",
      "epoch 48; iter: 0; batch classifier loss: 0.214724; batch adversarial loss: 0.516555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153483; batch adversarial loss: 0.431123\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178094; batch adversarial loss: 0.435779\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204086; batch adversarial loss: 0.479764\n",
      "epoch 52; iter: 0; batch classifier loss: 0.272936; batch adversarial loss: 0.471412\n",
      "epoch 53; iter: 0; batch classifier loss: 0.242668; batch adversarial loss: 0.521231\n",
      "epoch 54; iter: 0; batch classifier loss: 0.163849; batch adversarial loss: 0.578263\n",
      "epoch 55; iter: 0; batch classifier loss: 0.235821; batch adversarial loss: 0.480869\n",
      "epoch 56; iter: 0; batch classifier loss: 0.155177; batch adversarial loss: 0.508054\n",
      "epoch 57; iter: 0; batch classifier loss: 0.233828; batch adversarial loss: 0.384813\n",
      "epoch 58; iter: 0; batch classifier loss: 0.286746; batch adversarial loss: 0.361121\n",
      "epoch 59; iter: 0; batch classifier loss: 0.265731; batch adversarial loss: 0.348860\n",
      "epoch 60; iter: 0; batch classifier loss: 0.220092; batch adversarial loss: 0.582012\n",
      "epoch 61; iter: 0; batch classifier loss: 0.218150; batch adversarial loss: 0.470023\n",
      "epoch 62; iter: 0; batch classifier loss: 0.217908; batch adversarial loss: 0.434303\n",
      "epoch 63; iter: 0; batch classifier loss: 0.128051; batch adversarial loss: 0.433758\n",
      "epoch 64; iter: 0; batch classifier loss: 0.112717; batch adversarial loss: 0.471053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100415; batch adversarial loss: 0.379308\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097258; batch adversarial loss: 0.454548\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088384; batch adversarial loss: 0.414671\n",
      "epoch 68; iter: 0; batch classifier loss: 0.136512; batch adversarial loss: 0.385621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063937; batch adversarial loss: 0.416869\n",
      "epoch 70; iter: 0; batch classifier loss: 0.104189; batch adversarial loss: 0.395864\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133515; batch adversarial loss: 0.485031\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070207; batch adversarial loss: 0.365439\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089499; batch adversarial loss: 0.446605\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119149; batch adversarial loss: 0.460905\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063761; batch adversarial loss: 0.562443\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057741; batch adversarial loss: 0.489026\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099475; batch adversarial loss: 0.391076\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074644; batch adversarial loss: 0.453736\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077751; batch adversarial loss: 0.472976\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074882; batch adversarial loss: 0.389862\n",
      "epoch 81; iter: 0; batch classifier loss: 0.077358; batch adversarial loss: 0.433744\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051635; batch adversarial loss: 0.511680\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074225; batch adversarial loss: 0.420259\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053742; batch adversarial loss: 0.445820\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060534; batch adversarial loss: 0.413644\n",
      "epoch 86; iter: 0; batch classifier loss: 0.030541; batch adversarial loss: 0.512526\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065001; batch adversarial loss: 0.409251\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046893; batch adversarial loss: 0.513664\n",
      "epoch 89; iter: 0; batch classifier loss: 0.054409; batch adversarial loss: 0.394947\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039658; batch adversarial loss: 0.478465\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075763; batch adversarial loss: 0.398930\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064958; batch adversarial loss: 0.460993\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036167; batch adversarial loss: 0.506900\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050756; batch adversarial loss: 0.456736\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053258; batch adversarial loss: 0.491692\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.398416\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066134; batch adversarial loss: 0.366732\n",
      "epoch 98; iter: 0; batch classifier loss: 0.031161; batch adversarial loss: 0.413760\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032022; batch adversarial loss: 0.544846\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067941; batch adversarial loss: 0.339328\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056616; batch adversarial loss: 0.471929\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036222; batch adversarial loss: 0.458008\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033214; batch adversarial loss: 0.534558\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023585; batch adversarial loss: 0.431748\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035871; batch adversarial loss: 0.389023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.007941; batch adversarial loss: 0.465324\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028542; batch adversarial loss: 0.448940\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027510; batch adversarial loss: 0.476160\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027640; batch adversarial loss: 0.461222\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045687; batch adversarial loss: 0.368622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020120; batch adversarial loss: 0.526535\n",
      "epoch 112; iter: 0; batch classifier loss: 0.013699; batch adversarial loss: 0.477990\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020176; batch adversarial loss: 0.415204\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034038; batch adversarial loss: 0.534671\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035983; batch adversarial loss: 0.429114\n",
      "epoch 116; iter: 0; batch classifier loss: 0.018475; batch adversarial loss: 0.403495\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051761; batch adversarial loss: 0.590875\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031544; batch adversarial loss: 0.398983\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045750; batch adversarial loss: 0.489172\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051342; batch adversarial loss: 0.418390\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040725; batch adversarial loss: 0.509922\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034106; batch adversarial loss: 0.464031\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023410; batch adversarial loss: 0.460560\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032098; batch adversarial loss: 0.484675\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029838; batch adversarial loss: 0.499504\n",
      "epoch 126; iter: 0; batch classifier loss: 0.017353; batch adversarial loss: 0.439017\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015109; batch adversarial loss: 0.389007\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032935; batch adversarial loss: 0.538151\n",
      "epoch 129; iter: 0; batch classifier loss: 0.013912; batch adversarial loss: 0.481597\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046833; batch adversarial loss: 0.501294\n",
      "epoch 131; iter: 0; batch classifier loss: 0.014158; batch adversarial loss: 0.501230\n",
      "epoch 132; iter: 0; batch classifier loss: 0.010790; batch adversarial loss: 0.453380\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.447950\n",
      "epoch 134; iter: 0; batch classifier loss: 0.006627; batch adversarial loss: 0.510366\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032063; batch adversarial loss: 0.400497\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028168; batch adversarial loss: 0.495175\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032961; batch adversarial loss: 0.404356\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036290; batch adversarial loss: 0.441161\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030899; batch adversarial loss: 0.412282\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014188; batch adversarial loss: 0.569472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032599; batch adversarial loss: 0.487705\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041255; batch adversarial loss: 0.453525\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017636; batch adversarial loss: 0.453009\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020003; batch adversarial loss: 0.391998\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034979; batch adversarial loss: 0.521675\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041241; batch adversarial loss: 0.345873\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.434729\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008639; batch adversarial loss: 0.417878\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025300; batch adversarial loss: 0.546597\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032829; batch adversarial loss: 0.433998\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057559; batch adversarial loss: 0.481814\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029566; batch adversarial loss: 0.607682\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.364908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021535; batch adversarial loss: 0.463913\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036734; batch adversarial loss: 0.420280\n",
      "epoch 156; iter: 0; batch classifier loss: 0.005614; batch adversarial loss: 0.396643\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033423; batch adversarial loss: 0.484365\n",
      "epoch 158; iter: 0; batch classifier loss: 0.005943; batch adversarial loss: 0.409523\n",
      "epoch 159; iter: 0; batch classifier loss: 0.006841; batch adversarial loss: 0.465772\n",
      "epoch 160; iter: 0; batch classifier loss: 0.062078; batch adversarial loss: 0.435394\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014124; batch adversarial loss: 0.424510\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027724; batch adversarial loss: 0.440318\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017626; batch adversarial loss: 0.409913\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018886; batch adversarial loss: 0.427688\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041621; batch adversarial loss: 0.475253\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019527; batch adversarial loss: 0.423209\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044059; batch adversarial loss: 0.517885\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016392; batch adversarial loss: 0.360733\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023807; batch adversarial loss: 0.465619\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007770; batch adversarial loss: 0.360051\n",
      "epoch 171; iter: 0; batch classifier loss: 0.007278; batch adversarial loss: 0.469375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019191; batch adversarial loss: 0.407077\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010953; batch adversarial loss: 0.450741\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014054; batch adversarial loss: 0.426722\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017222; batch adversarial loss: 0.500500\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023614; batch adversarial loss: 0.330263\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027749; batch adversarial loss: 0.392202\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005291; batch adversarial loss: 0.474101\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009803; batch adversarial loss: 0.530357\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004563; batch adversarial loss: 0.379948\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008558; batch adversarial loss: 0.579850\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020540; batch adversarial loss: 0.542072\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015860; batch adversarial loss: 0.363556\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013423; batch adversarial loss: 0.365391\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008286; batch adversarial loss: 0.439499\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.457533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006683; batch adversarial loss: 0.420022\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013504; batch adversarial loss: 0.405520\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023095; batch adversarial loss: 0.405052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040272; batch adversarial loss: 0.499862\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026210; batch adversarial loss: 0.413953\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011967; batch adversarial loss: 0.367660\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010192; batch adversarial loss: 0.468794\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017146; batch adversarial loss: 0.514530\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015833; batch adversarial loss: 0.474867\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012554; batch adversarial loss: 0.391903\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003738; batch adversarial loss: 0.486102\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010198; batch adversarial loss: 0.411316\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009804; batch adversarial loss: 0.485572\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698722; batch adversarial loss: 0.668867\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441521; batch adversarial loss: 0.637634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.431394; batch adversarial loss: 0.622047\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390526; batch adversarial loss: 0.573268\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331906; batch adversarial loss: 0.572356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.350880; batch adversarial loss: 0.544785\n",
      "epoch 6; iter: 0; batch classifier loss: 0.355170; batch adversarial loss: 0.533262\n",
      "epoch 7; iter: 0; batch classifier loss: 0.257286; batch adversarial loss: 0.493977\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246254; batch adversarial loss: 0.511080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.225395; batch adversarial loss: 0.505289\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218379; batch adversarial loss: 0.503306\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214054; batch adversarial loss: 0.442665\n",
      "epoch 12; iter: 0; batch classifier loss: 0.252005; batch adversarial loss: 0.513141\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198082; batch adversarial loss: 0.430529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166293; batch adversarial loss: 0.490906\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174944; batch adversarial loss: 0.385884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.125514; batch adversarial loss: 0.507419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.141227; batch adversarial loss: 0.526528\n",
      "epoch 18; iter: 0; batch classifier loss: 0.113292; batch adversarial loss: 0.434950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.121629; batch adversarial loss: 0.467335\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171953; batch adversarial loss: 0.461933\n",
      "epoch 21; iter: 0; batch classifier loss: 0.134379; batch adversarial loss: 0.389791\n",
      "epoch 22; iter: 0; batch classifier loss: 0.123549; batch adversarial loss: 0.438783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.118416; batch adversarial loss: 0.506018\n",
      "epoch 24; iter: 0; batch classifier loss: 0.131444; batch adversarial loss: 0.435203\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163846; batch adversarial loss: 0.474112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141892; batch adversarial loss: 0.532723\n",
      "epoch 27; iter: 0; batch classifier loss: 0.111362; batch adversarial loss: 0.453549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.105216; batch adversarial loss: 0.560875\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156837; batch adversarial loss: 0.486998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111650; batch adversarial loss: 0.418138\n",
      "epoch 31; iter: 0; batch classifier loss: 0.116316; batch adversarial loss: 0.415834\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138397; batch adversarial loss: 0.490139\n",
      "epoch 33; iter: 0; batch classifier loss: 0.151983; batch adversarial loss: 0.507424\n",
      "epoch 34; iter: 0; batch classifier loss: 0.187613; batch adversarial loss: 0.527181\n",
      "epoch 35; iter: 0; batch classifier loss: 0.166145; batch adversarial loss: 0.471832\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095194; batch adversarial loss: 0.380199\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170785; batch adversarial loss: 0.526943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139226; batch adversarial loss: 0.462045\n",
      "epoch 39; iter: 0; batch classifier loss: 0.161346; batch adversarial loss: 0.401444\n",
      "epoch 40; iter: 0; batch classifier loss: 0.236002; batch adversarial loss: 0.518465\n",
      "epoch 41; iter: 0; batch classifier loss: 0.209252; batch adversarial loss: 0.472885\n",
      "epoch 42; iter: 0; batch classifier loss: 0.198449; batch adversarial loss: 0.491257\n",
      "epoch 43; iter: 0; batch classifier loss: 0.166007; batch adversarial loss: 0.417536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149168; batch adversarial loss: 0.460404\n",
      "epoch 45; iter: 0; batch classifier loss: 0.072129; batch adversarial loss: 0.447661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120520; batch adversarial loss: 0.480594\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101015; batch adversarial loss: 0.488136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088372; batch adversarial loss: 0.474476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.061634; batch adversarial loss: 0.574196\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066138; batch adversarial loss: 0.453528\n",
      "epoch 51; iter: 0; batch classifier loss: 0.106371; batch adversarial loss: 0.546614\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077116; batch adversarial loss: 0.420665\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081462; batch adversarial loss: 0.430914\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114129; batch adversarial loss: 0.390422\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081803; batch adversarial loss: 0.486125\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094765; batch adversarial loss: 0.465405\n",
      "epoch 57; iter: 0; batch classifier loss: 0.166540; batch adversarial loss: 0.443412\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082000; batch adversarial loss: 0.444391\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088373; batch adversarial loss: 0.425210\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062350; batch adversarial loss: 0.509133\n",
      "epoch 61; iter: 0; batch classifier loss: 0.043983; batch adversarial loss: 0.432166\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105505; batch adversarial loss: 0.436295\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076747; batch adversarial loss: 0.512909\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067557; batch adversarial loss: 0.398423\n",
      "epoch 65; iter: 0; batch classifier loss: 0.046578; batch adversarial loss: 0.450035\n",
      "epoch 66; iter: 0; batch classifier loss: 0.045463; batch adversarial loss: 0.504321\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059044; batch adversarial loss: 0.412924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072626; batch adversarial loss: 0.392163\n",
      "epoch 69; iter: 0; batch classifier loss: 0.048537; batch adversarial loss: 0.460910\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055439; batch adversarial loss: 0.463144\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051170; batch adversarial loss: 0.548968\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072376; batch adversarial loss: 0.449423\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049918; batch adversarial loss: 0.540977\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103254; batch adversarial loss: 0.488224\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079649; batch adversarial loss: 0.450992\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122223; batch adversarial loss: 0.400492\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081410; batch adversarial loss: 0.522645\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099429; batch adversarial loss: 0.499743\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054418; batch adversarial loss: 0.462551\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099535; batch adversarial loss: 0.540721\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075375; batch adversarial loss: 0.467111\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063474; batch adversarial loss: 0.428460\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069847; batch adversarial loss: 0.395301\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066785; batch adversarial loss: 0.416177\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061229; batch adversarial loss: 0.573906\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120758; batch adversarial loss: 0.423543\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081822; batch adversarial loss: 0.413639\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050984; batch adversarial loss: 0.430118\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065086; batch adversarial loss: 0.436406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.103764; batch adversarial loss: 0.400014\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075760; batch adversarial loss: 0.460390\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053745; batch adversarial loss: 0.422806\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056161; batch adversarial loss: 0.462799\n",
      "epoch 94; iter: 0; batch classifier loss: 0.032793; batch adversarial loss: 0.457153\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077556; batch adversarial loss: 0.474593\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071816; batch adversarial loss: 0.453224\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074840; batch adversarial loss: 0.499680\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059494; batch adversarial loss: 0.445954\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028161; batch adversarial loss: 0.534938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.049403; batch adversarial loss: 0.434334\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053771; batch adversarial loss: 0.473181\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044259; batch adversarial loss: 0.398087\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038232; batch adversarial loss: 0.496744\n",
      "epoch 104; iter: 0; batch classifier loss: 0.101339; batch adversarial loss: 0.436517\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050422; batch adversarial loss: 0.448439\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.501363\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038274; batch adversarial loss: 0.414063\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055253; batch adversarial loss: 0.473158\n",
      "epoch 109; iter: 0; batch classifier loss: 0.085706; batch adversarial loss: 0.402749\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061700; batch adversarial loss: 0.502661\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037984; batch adversarial loss: 0.440366\n",
      "epoch 112; iter: 0; batch classifier loss: 0.079097; batch adversarial loss: 0.443411\n",
      "epoch 113; iter: 0; batch classifier loss: 0.062653; batch adversarial loss: 0.523811\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048999; batch adversarial loss: 0.430050\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057697; batch adversarial loss: 0.408450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037020; batch adversarial loss: 0.469400\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042073; batch adversarial loss: 0.429318\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041782; batch adversarial loss: 0.423738\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029186; batch adversarial loss: 0.456175\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057586; batch adversarial loss: 0.399292\n",
      "epoch 121; iter: 0; batch classifier loss: 0.089179; batch adversarial loss: 0.400817\n",
      "epoch 122; iter: 0; batch classifier loss: 0.012263; batch adversarial loss: 0.482850\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045670; batch adversarial loss: 0.419496\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063680; batch adversarial loss: 0.451983\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045134; batch adversarial loss: 0.527074\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032193; batch adversarial loss: 0.415236\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022710; batch adversarial loss: 0.475669\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054437; batch adversarial loss: 0.470673\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014233; batch adversarial loss: 0.511350\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021413; batch adversarial loss: 0.471445\n",
      "epoch 131; iter: 0; batch classifier loss: 0.057137; batch adversarial loss: 0.420522\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034275; batch adversarial loss: 0.377998\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043292; batch adversarial loss: 0.491232\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033232; batch adversarial loss: 0.374230\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033438; batch adversarial loss: 0.434849\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025840; batch adversarial loss: 0.422765\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019692; batch adversarial loss: 0.477409\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060107; batch adversarial loss: 0.442178\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026164; batch adversarial loss: 0.531702\n",
      "epoch 140; iter: 0; batch classifier loss: 0.031409; batch adversarial loss: 0.382330\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030262; batch adversarial loss: 0.410864\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025725; batch adversarial loss: 0.503186\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038453; batch adversarial loss: 0.518375\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012058; batch adversarial loss: 0.489488\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034683; batch adversarial loss: 0.475869\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031995; batch adversarial loss: 0.455871\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034785; batch adversarial loss: 0.540799\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021117; batch adversarial loss: 0.455260\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038348; batch adversarial loss: 0.551270\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054219; batch adversarial loss: 0.484670\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052513; batch adversarial loss: 0.419754\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025683; batch adversarial loss: 0.478880\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018449; batch adversarial loss: 0.559851\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021983; batch adversarial loss: 0.423550\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034894; batch adversarial loss: 0.386251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011092; batch adversarial loss: 0.414909\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031431; batch adversarial loss: 0.404861\n",
      "epoch 158; iter: 0; batch classifier loss: 0.059431; batch adversarial loss: 0.411340\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012973; batch adversarial loss: 0.427532\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035060; batch adversarial loss: 0.378261\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024707; batch adversarial loss: 0.557310\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031713; batch adversarial loss: 0.470254\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023576; batch adversarial loss: 0.405179\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008247; batch adversarial loss: 0.475088\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023810; batch adversarial loss: 0.448492\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024995; batch adversarial loss: 0.366801\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013357; batch adversarial loss: 0.524784\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062374; batch adversarial loss: 0.468076\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038220; batch adversarial loss: 0.470987\n",
      "epoch 170; iter: 0; batch classifier loss: 0.034868; batch adversarial loss: 0.446263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033153; batch adversarial loss: 0.435860\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020021; batch adversarial loss: 0.381609\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026653; batch adversarial loss: 0.438197\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.451727\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028762; batch adversarial loss: 0.492851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055120; batch adversarial loss: 0.458087\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052189; batch adversarial loss: 0.611616\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013272; batch adversarial loss: 0.384182\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.405493\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028890; batch adversarial loss: 0.465729\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024254; batch adversarial loss: 0.443793\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041315; batch adversarial loss: 0.435614\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010631; batch adversarial loss: 0.384774\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008677; batch adversarial loss: 0.477661\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033593; batch adversarial loss: 0.369569\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014021; batch adversarial loss: 0.492668\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017846; batch adversarial loss: 0.411872\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016414; batch adversarial loss: 0.360179\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028053; batch adversarial loss: 0.413873\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016003; batch adversarial loss: 0.549936\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042408; batch adversarial loss: 0.449055\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016904; batch adversarial loss: 0.377424\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027657; batch adversarial loss: 0.439353\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033088; batch adversarial loss: 0.485108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.064367; batch adversarial loss: 0.496731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.434789\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025997; batch adversarial loss: 0.382853\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015473; batch adversarial loss: 0.556439\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026717; batch adversarial loss: 0.492536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714551; batch adversarial loss: 0.637786\n",
      "epoch 1; iter: 0; batch classifier loss: 0.498488; batch adversarial loss: 0.656626\n",
      "epoch 2; iter: 0; batch classifier loss: 0.470752; batch adversarial loss: 0.637306\n",
      "epoch 3; iter: 0; batch classifier loss: 0.364961; batch adversarial loss: 0.620096\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369709; batch adversarial loss: 0.601311\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379983; batch adversarial loss: 0.589829\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383051; batch adversarial loss: 0.555401\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379789; batch adversarial loss: 0.567813\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432858; batch adversarial loss: 0.507111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329242; batch adversarial loss: 0.592178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294004; batch adversarial loss: 0.520122\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290872; batch adversarial loss: 0.505299\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282777; batch adversarial loss: 0.486619\n",
      "epoch 13; iter: 0; batch classifier loss: 0.196902; batch adversarial loss: 0.458051\n",
      "epoch 14; iter: 0; batch classifier loss: 0.254239; batch adversarial loss: 0.542373\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217999; batch adversarial loss: 0.471660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322145; batch adversarial loss: 0.470548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259854; batch adversarial loss: 0.522906\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246312; batch adversarial loss: 0.575014\n",
      "epoch 19; iter: 0; batch classifier loss: 0.232107; batch adversarial loss: 0.421731\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237878; batch adversarial loss: 0.396648\n",
      "epoch 21; iter: 0; batch classifier loss: 0.135967; batch adversarial loss: 0.452633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.156429; batch adversarial loss: 0.552493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.212506; batch adversarial loss: 0.492810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.212524; batch adversarial loss: 0.448684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171969; batch adversarial loss: 0.459470\n",
      "epoch 26; iter: 0; batch classifier loss: 0.159090; batch adversarial loss: 0.466286\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147661; batch adversarial loss: 0.413252\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142926; batch adversarial loss: 0.445568\n",
      "epoch 29; iter: 0; batch classifier loss: 0.130203; batch adversarial loss: 0.459059\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153141; batch adversarial loss: 0.599866\n",
      "epoch 31; iter: 0; batch classifier loss: 0.228298; batch adversarial loss: 0.491278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134746; batch adversarial loss: 0.403744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.088720; batch adversarial loss: 0.537266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.185370; batch adversarial loss: 0.431482\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132686; batch adversarial loss: 0.436043\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140946; batch adversarial loss: 0.494848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130180; batch adversarial loss: 0.437298\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147809; batch adversarial loss: 0.461540\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092882; batch adversarial loss: 0.470405\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152801; batch adversarial loss: 0.377048\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113898; batch adversarial loss: 0.463765\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111473; batch adversarial loss: 0.514434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.173720; batch adversarial loss: 0.518930\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136494; batch adversarial loss: 0.429125\n",
      "epoch 45; iter: 0; batch classifier loss: 0.117144; batch adversarial loss: 0.397817\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133526; batch adversarial loss: 0.447812\n",
      "epoch 47; iter: 0; batch classifier loss: 0.131304; batch adversarial loss: 0.479042\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128970; batch adversarial loss: 0.407590\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116240; batch adversarial loss: 0.358631\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112940; batch adversarial loss: 0.337729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084646; batch adversarial loss: 0.545723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089336; batch adversarial loss: 0.579722\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114783; batch adversarial loss: 0.434188\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062331; batch adversarial loss: 0.582157\n",
      "epoch 55; iter: 0; batch classifier loss: 0.066908; batch adversarial loss: 0.497752\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082667; batch adversarial loss: 0.469979\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121046; batch adversarial loss: 0.485504\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118464; batch adversarial loss: 0.374326\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109863; batch adversarial loss: 0.479611\n",
      "epoch 60; iter: 0; batch classifier loss: 0.133882; batch adversarial loss: 0.505887\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095352; batch adversarial loss: 0.469986\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079175; batch adversarial loss: 0.399095\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074473; batch adversarial loss: 0.451564\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106938; batch adversarial loss: 0.407509\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064531; batch adversarial loss: 0.408190\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066795; batch adversarial loss: 0.527755\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081918; batch adversarial loss: 0.510952\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077931; batch adversarial loss: 0.422539\n",
      "epoch 69; iter: 0; batch classifier loss: 0.091427; batch adversarial loss: 0.434416\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070265; batch adversarial loss: 0.485458\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071362; batch adversarial loss: 0.444336\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084950; batch adversarial loss: 0.441640\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095864; batch adversarial loss: 0.454547\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079654; batch adversarial loss: 0.449946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068532; batch adversarial loss: 0.423694\n",
      "epoch 76; iter: 0; batch classifier loss: 0.025815; batch adversarial loss: 0.574481\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110136; batch adversarial loss: 0.425178\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079319; batch adversarial loss: 0.409398\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.408359\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053046; batch adversarial loss: 0.481027\n",
      "epoch 81; iter: 0; batch classifier loss: 0.099299; batch adversarial loss: 0.488413\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043255; batch adversarial loss: 0.458112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105152; batch adversarial loss: 0.512875\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079261; batch adversarial loss: 0.398079\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073203; batch adversarial loss: 0.519520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089940; batch adversarial loss: 0.432534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068597; batch adversarial loss: 0.457952\n",
      "epoch 88; iter: 0; batch classifier loss: 0.132785; batch adversarial loss: 0.465722\n",
      "epoch 89; iter: 0; batch classifier loss: 0.117790; batch adversarial loss: 0.457016\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067318; batch adversarial loss: 0.555700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046265; batch adversarial loss: 0.399886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102651; batch adversarial loss: 0.463740\n",
      "epoch 93; iter: 0; batch classifier loss: 0.081853; batch adversarial loss: 0.485781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.586189\n",
      "epoch 95; iter: 0; batch classifier loss: 0.029275; batch adversarial loss: 0.494809\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079070; batch adversarial loss: 0.420920\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088589; batch adversarial loss: 0.465939\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039946; batch adversarial loss: 0.519217\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058098; batch adversarial loss: 0.509631\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050526; batch adversarial loss: 0.465461\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058110; batch adversarial loss: 0.457118\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069283; batch adversarial loss: 0.599437\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.536679\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050983; batch adversarial loss: 0.443513\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055896; batch adversarial loss: 0.408461\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036827; batch adversarial loss: 0.460643\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060019; batch adversarial loss: 0.478350\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055303; batch adversarial loss: 0.465463\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069762; batch adversarial loss: 0.444192\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033735; batch adversarial loss: 0.425105\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065827; batch adversarial loss: 0.446931\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026906; batch adversarial loss: 0.513036\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060600; batch adversarial loss: 0.402674\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068320; batch adversarial loss: 0.495451\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049457; batch adversarial loss: 0.439514\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035708; batch adversarial loss: 0.480803\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049610; batch adversarial loss: 0.446555\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039325; batch adversarial loss: 0.483348\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041820; batch adversarial loss: 0.345157\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025322; batch adversarial loss: 0.490347\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019191; batch adversarial loss: 0.573117\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032210; batch adversarial loss: 0.454852\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029846; batch adversarial loss: 0.589556\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030880; batch adversarial loss: 0.448283\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055477; batch adversarial loss: 0.489895\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047272; batch adversarial loss: 0.588152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020264; batch adversarial loss: 0.461167\n",
      "epoch 128; iter: 0; batch classifier loss: 0.077882; batch adversarial loss: 0.442933\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016004; batch adversarial loss: 0.551495\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034567; batch adversarial loss: 0.496733\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022670; batch adversarial loss: 0.478299\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024912; batch adversarial loss: 0.462701\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020701; batch adversarial loss: 0.437821\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020210; batch adversarial loss: 0.506272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.041874; batch adversarial loss: 0.451902\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023629; batch adversarial loss: 0.500064\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066174; batch adversarial loss: 0.409752\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030005; batch adversarial loss: 0.498436\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034530; batch adversarial loss: 0.419181\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055437; batch adversarial loss: 0.521335\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020135; batch adversarial loss: 0.413683\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034036; batch adversarial loss: 0.483586\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053801; batch adversarial loss: 0.282697\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057584; batch adversarial loss: 0.458274\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043336; batch adversarial loss: 0.428738\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037752; batch adversarial loss: 0.418680\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034299; batch adversarial loss: 0.378564\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023902; batch adversarial loss: 0.472105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064355; batch adversarial loss: 0.481083\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039827; batch adversarial loss: 0.460656\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008716; batch adversarial loss: 0.507915\n",
      "epoch 152; iter: 0; batch classifier loss: 0.049093; batch adversarial loss: 0.383979\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038962; batch adversarial loss: 0.489229\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012936; batch adversarial loss: 0.453952\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036149; batch adversarial loss: 0.523043\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015331; batch adversarial loss: 0.512782\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025093; batch adversarial loss: 0.353845\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025889; batch adversarial loss: 0.426227\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011143; batch adversarial loss: 0.485364\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039206; batch adversarial loss: 0.493307\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029016; batch adversarial loss: 0.571297\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031290; batch adversarial loss: 0.440733\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030761; batch adversarial loss: 0.496988\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029849; batch adversarial loss: 0.541109\n",
      "epoch 165; iter: 0; batch classifier loss: 0.047313; batch adversarial loss: 0.426133\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032673; batch adversarial loss: 0.461886\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022086; batch adversarial loss: 0.474830\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025931; batch adversarial loss: 0.479467\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017673; batch adversarial loss: 0.432968\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027608; batch adversarial loss: 0.390004\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015308; batch adversarial loss: 0.437225\n",
      "epoch 172; iter: 0; batch classifier loss: 0.052837; batch adversarial loss: 0.464083\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025764; batch adversarial loss: 0.572267\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019511; batch adversarial loss: 0.423030\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021759; batch adversarial loss: 0.550729\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032246; batch adversarial loss: 0.525578\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032532; batch adversarial loss: 0.388929\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050422; batch adversarial loss: 0.518831\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038481; batch adversarial loss: 0.566023\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009378; batch adversarial loss: 0.456923\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020499; batch adversarial loss: 0.531213\n",
      "epoch 182; iter: 0; batch classifier loss: 0.057453; batch adversarial loss: 0.453197\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039689; batch adversarial loss: 0.545956\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010496; batch adversarial loss: 0.395405\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029279; batch adversarial loss: 0.463723\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017217; batch adversarial loss: 0.403358\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032778; batch adversarial loss: 0.425575\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016406; batch adversarial loss: 0.512874\n",
      "epoch 189; iter: 0; batch classifier loss: 0.065392; batch adversarial loss: 0.424793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.023070; batch adversarial loss: 0.487198\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009719; batch adversarial loss: 0.363055\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.448576\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027514; batch adversarial loss: 0.457089\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025220; batch adversarial loss: 0.420662\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030827; batch adversarial loss: 0.451191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.050724; batch adversarial loss: 0.509181\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028511; batch adversarial loss: 0.497989\n",
      "epoch 198; iter: 0; batch classifier loss: 0.003716; batch adversarial loss: 0.524172\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018436; batch adversarial loss: 0.485636\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691161; batch adversarial loss: 0.753936\n",
      "epoch 1; iter: 0; batch classifier loss: 0.511197; batch adversarial loss: 0.712228\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531983; batch adversarial loss: 0.670214\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369287; batch adversarial loss: 0.636395\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382113; batch adversarial loss: 0.619108\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373873; batch adversarial loss: 0.573047\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371099; batch adversarial loss: 0.560771\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359806; batch adversarial loss: 0.597308\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274516; batch adversarial loss: 0.512174\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364050; batch adversarial loss: 0.542159\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341115; batch adversarial loss: 0.528722\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424534; batch adversarial loss: 0.503377\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334109; batch adversarial loss: 0.503137\n",
      "epoch 13; iter: 0; batch classifier loss: 0.403689; batch adversarial loss: 0.500893\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379078; batch adversarial loss: 0.493166\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428076; batch adversarial loss: 0.473838\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355326; batch adversarial loss: 0.496912\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357442; batch adversarial loss: 0.486768\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337321; batch adversarial loss: 0.450494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298125; batch adversarial loss: 0.518116\n",
      "epoch 20; iter: 0; batch classifier loss: 0.354524; batch adversarial loss: 0.450169\n",
      "epoch 21; iter: 0; batch classifier loss: 0.378601; batch adversarial loss: 0.447230\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213585; batch adversarial loss: 0.447045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.300420; batch adversarial loss: 0.414871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.247996; batch adversarial loss: 0.498194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275275; batch adversarial loss: 0.425998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214345; batch adversarial loss: 0.465350\n",
      "epoch 27; iter: 0; batch classifier loss: 0.246537; batch adversarial loss: 0.386107\n",
      "epoch 28; iter: 0; batch classifier loss: 0.235377; batch adversarial loss: 0.414574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213386; batch adversarial loss: 0.441846\n",
      "epoch 30; iter: 0; batch classifier loss: 0.255185; batch adversarial loss: 0.411627\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177095; batch adversarial loss: 0.429728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.297371; batch adversarial loss: 0.387993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226893; batch adversarial loss: 0.499782\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225925; batch adversarial loss: 0.476891\n",
      "epoch 35; iter: 0; batch classifier loss: 0.226947; batch adversarial loss: 0.505530\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175451; batch adversarial loss: 0.516722\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235353; batch adversarial loss: 0.426070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192234; batch adversarial loss: 0.506953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129633; batch adversarial loss: 0.404676\n",
      "epoch 40; iter: 0; batch classifier loss: 0.224826; batch adversarial loss: 0.492293\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240646; batch adversarial loss: 0.523049\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197284; batch adversarial loss: 0.420867\n",
      "epoch 43; iter: 0; batch classifier loss: 0.172731; batch adversarial loss: 0.504272\n",
      "epoch 44; iter: 0; batch classifier loss: 0.218151; batch adversarial loss: 0.460148\n",
      "epoch 45; iter: 0; batch classifier loss: 0.205908; batch adversarial loss: 0.418092\n",
      "epoch 46; iter: 0; batch classifier loss: 0.206083; batch adversarial loss: 0.480653\n",
      "epoch 47; iter: 0; batch classifier loss: 0.153812; batch adversarial loss: 0.493560\n",
      "epoch 48; iter: 0; batch classifier loss: 0.177092; batch adversarial loss: 0.463666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.150441; batch adversarial loss: 0.423088\n",
      "epoch 50; iter: 0; batch classifier loss: 0.173045; batch adversarial loss: 0.468938\n",
      "epoch 51; iter: 0; batch classifier loss: 0.227163; batch adversarial loss: 0.434350\n",
      "epoch 52; iter: 0; batch classifier loss: 0.209465; batch adversarial loss: 0.458552\n",
      "epoch 53; iter: 0; batch classifier loss: 0.127338; batch adversarial loss: 0.511502\n",
      "epoch 54; iter: 0; batch classifier loss: 0.158712; batch adversarial loss: 0.533233\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154607; batch adversarial loss: 0.471016\n",
      "epoch 56; iter: 0; batch classifier loss: 0.167893; batch adversarial loss: 0.448318\n",
      "epoch 57; iter: 0; batch classifier loss: 0.198491; batch adversarial loss: 0.461508\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098152; batch adversarial loss: 0.545335\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130264; batch adversarial loss: 0.537845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.133566; batch adversarial loss: 0.468861\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186138; batch adversarial loss: 0.470690\n",
      "epoch 62; iter: 0; batch classifier loss: 0.156514; batch adversarial loss: 0.422011\n",
      "epoch 63; iter: 0; batch classifier loss: 0.149139; batch adversarial loss: 0.344187\n",
      "epoch 64; iter: 0; batch classifier loss: 0.141616; batch adversarial loss: 0.447032\n",
      "epoch 65; iter: 0; batch classifier loss: 0.124297; batch adversarial loss: 0.457681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.164089; batch adversarial loss: 0.410033\n",
      "epoch 67; iter: 0; batch classifier loss: 0.102067; batch adversarial loss: 0.429575\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102205; batch adversarial loss: 0.483309\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174214; batch adversarial loss: 0.371996\n",
      "epoch 70; iter: 0; batch classifier loss: 0.142646; batch adversarial loss: 0.459785\n",
      "epoch 71; iter: 0; batch classifier loss: 0.130494; batch adversarial loss: 0.421386\n",
      "epoch 72; iter: 0; batch classifier loss: 0.105250; batch adversarial loss: 0.466862\n",
      "epoch 73; iter: 0; batch classifier loss: 0.127943; batch adversarial loss: 0.486756\n",
      "epoch 74; iter: 0; batch classifier loss: 0.110945; batch adversarial loss: 0.382967\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107135; batch adversarial loss: 0.431519\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157366; batch adversarial loss: 0.434134\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147299; batch adversarial loss: 0.392271\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076726; batch adversarial loss: 0.445783\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062534; batch adversarial loss: 0.501002\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084887; batch adversarial loss: 0.441032\n",
      "epoch 81; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.400517\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119638; batch adversarial loss: 0.406331\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078255; batch adversarial loss: 0.454231\n",
      "epoch 84; iter: 0; batch classifier loss: 0.074413; batch adversarial loss: 0.450512\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053278; batch adversarial loss: 0.420692\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047249; batch adversarial loss: 0.374557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095250; batch adversarial loss: 0.432187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.096620; batch adversarial loss: 0.453991\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087125; batch adversarial loss: 0.519360\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067952; batch adversarial loss: 0.485415\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086746; batch adversarial loss: 0.453239\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068997; batch adversarial loss: 0.468220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056832; batch adversarial loss: 0.530328\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080348; batch adversarial loss: 0.396551\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073671; batch adversarial loss: 0.418233\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058257; batch adversarial loss: 0.411330\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064024; batch adversarial loss: 0.418925\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074259; batch adversarial loss: 0.447888\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053072; batch adversarial loss: 0.384472\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054539; batch adversarial loss: 0.506521\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063564; batch adversarial loss: 0.435909\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042974; batch adversarial loss: 0.383333\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070569; batch adversarial loss: 0.402360\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045440; batch adversarial loss: 0.414241\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040202; batch adversarial loss: 0.408222\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033806; batch adversarial loss: 0.397155\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062188; batch adversarial loss: 0.503793\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.515267\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024778; batch adversarial loss: 0.414477\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027509; batch adversarial loss: 0.458050\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063274; batch adversarial loss: 0.437350\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.535736\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031794; batch adversarial loss: 0.459618\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029800; batch adversarial loss: 0.391719\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042083; batch adversarial loss: 0.476709\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045422; batch adversarial loss: 0.545220\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042193; batch adversarial loss: 0.443393\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024098; batch adversarial loss: 0.420434\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022394; batch adversarial loss: 0.386417\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059899; batch adversarial loss: 0.312221\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037863; batch adversarial loss: 0.486142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035387; batch adversarial loss: 0.358900\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026632; batch adversarial loss: 0.390115\n",
      "epoch 124; iter: 0; batch classifier loss: 0.079246; batch adversarial loss: 0.438721\n",
      "epoch 125; iter: 0; batch classifier loss: 0.064643; batch adversarial loss: 0.430357\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045990; batch adversarial loss: 0.441757\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019454; batch adversarial loss: 0.377338\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060095; batch adversarial loss: 0.445955\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022820; batch adversarial loss: 0.358432\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034416; batch adversarial loss: 0.441333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044171; batch adversarial loss: 0.503363\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020833; batch adversarial loss: 0.437495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046869; batch adversarial loss: 0.447184\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028799; batch adversarial loss: 0.414664\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054035; batch adversarial loss: 0.392119\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022798; batch adversarial loss: 0.487375\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.461066\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030917; batch adversarial loss: 0.403346\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030469; batch adversarial loss: 0.434895\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044657; batch adversarial loss: 0.428993\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020883; batch adversarial loss: 0.538352\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021137; batch adversarial loss: 0.469582\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027176; batch adversarial loss: 0.467602\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026053; batch adversarial loss: 0.449159\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013147; batch adversarial loss: 0.416397\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012088; batch adversarial loss: 0.461502\n",
      "epoch 147; iter: 0; batch classifier loss: 0.049633; batch adversarial loss: 0.497109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044689; batch adversarial loss: 0.410149\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014779; batch adversarial loss: 0.385257\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022731; batch adversarial loss: 0.452189\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032407; batch adversarial loss: 0.544871\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031889; batch adversarial loss: 0.406188\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022547; batch adversarial loss: 0.536296\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031616; batch adversarial loss: 0.500191\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017193; batch adversarial loss: 0.387016\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011326; batch adversarial loss: 0.333793\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011287; batch adversarial loss: 0.408165\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018937; batch adversarial loss: 0.472137\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037117; batch adversarial loss: 0.486764\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017164; batch adversarial loss: 0.489854\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022100; batch adversarial loss: 0.465016\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016080; batch adversarial loss: 0.455187\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029555; batch adversarial loss: 0.448932\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024445; batch adversarial loss: 0.335933\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031042; batch adversarial loss: 0.375520\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020382; batch adversarial loss: 0.421713\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016901; batch adversarial loss: 0.442782\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028832; batch adversarial loss: 0.300473\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021277; batch adversarial loss: 0.480051\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023693; batch adversarial loss: 0.493793\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010013; batch adversarial loss: 0.541578\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.386145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031721; batch adversarial loss: 0.423021\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013172; batch adversarial loss: 0.292713\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043946; batch adversarial loss: 0.463163\n",
      "epoch 176; iter: 0; batch classifier loss: 0.049217; batch adversarial loss: 0.465115\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020470; batch adversarial loss: 0.416203\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031596; batch adversarial loss: 0.445369\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041693; batch adversarial loss: 0.538764\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015832; batch adversarial loss: 0.564180\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014574; batch adversarial loss: 0.435807\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022879; batch adversarial loss: 0.527342\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033603; batch adversarial loss: 0.529736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.005415; batch adversarial loss: 0.450729\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046229; batch adversarial loss: 0.326003\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011691; batch adversarial loss: 0.459014\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019656; batch adversarial loss: 0.410247\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019807; batch adversarial loss: 0.483066\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025302; batch adversarial loss: 0.479672\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030842; batch adversarial loss: 0.423631\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016953; batch adversarial loss: 0.423071\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037909; batch adversarial loss: 0.397061\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007822; batch adversarial loss: 0.476607\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020860; batch adversarial loss: 0.472773\n",
      "epoch 195; iter: 0; batch classifier loss: 0.048898; batch adversarial loss: 0.559896\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022578; batch adversarial loss: 0.424627\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022059; batch adversarial loss: 0.462882\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023612; batch adversarial loss: 0.354541\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028932; batch adversarial loss: 0.431272\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699471; batch adversarial loss: 0.898055\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555715; batch adversarial loss: 0.895718\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647627; batch adversarial loss: 0.885910\n",
      "epoch 3; iter: 0; batch classifier loss: 1.009027; batch adversarial loss: 0.836013\n",
      "epoch 4; iter: 0; batch classifier loss: 0.913469; batch adversarial loss: 0.744953\n",
      "epoch 5; iter: 0; batch classifier loss: 1.073165; batch adversarial loss: 0.673879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.931532; batch adversarial loss: 0.621504\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513678; batch adversarial loss: 0.553701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345140; batch adversarial loss: 0.566226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341215; batch adversarial loss: 0.570702\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268281; batch adversarial loss: 0.500602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.394257; batch adversarial loss: 0.537132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.370342; batch adversarial loss: 0.538980\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292023; batch adversarial loss: 0.495249\n",
      "epoch 14; iter: 0; batch classifier loss: 0.295758; batch adversarial loss: 0.503947\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337475; batch adversarial loss: 0.522903\n",
      "epoch 16; iter: 0; batch classifier loss: 0.329051; batch adversarial loss: 0.527133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333048; batch adversarial loss: 0.555505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320033; batch adversarial loss: 0.429921\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241208; batch adversarial loss: 0.496671\n",
      "epoch 20; iter: 0; batch classifier loss: 0.383493; batch adversarial loss: 0.498120\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303395; batch adversarial loss: 0.453058\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253566; batch adversarial loss: 0.439156\n",
      "epoch 23; iter: 0; batch classifier loss: 0.277113; batch adversarial loss: 0.523990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201624; batch adversarial loss: 0.480781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297261; batch adversarial loss: 0.394397\n",
      "epoch 26; iter: 0; batch classifier loss: 0.251501; batch adversarial loss: 0.461366\n",
      "epoch 27; iter: 0; batch classifier loss: 0.191336; batch adversarial loss: 0.487385\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285748; batch adversarial loss: 0.421457\n",
      "epoch 29; iter: 0; batch classifier loss: 0.243512; batch adversarial loss: 0.352156\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229338; batch adversarial loss: 0.516510\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149273; batch adversarial loss: 0.605428\n",
      "epoch 32; iter: 0; batch classifier loss: 0.188962; batch adversarial loss: 0.482861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162996; batch adversarial loss: 0.427929\n",
      "epoch 34; iter: 0; batch classifier loss: 0.188049; batch adversarial loss: 0.390408\n",
      "epoch 35; iter: 0; batch classifier loss: 0.173132; batch adversarial loss: 0.422661\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113542; batch adversarial loss: 0.449703\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166254; batch adversarial loss: 0.576093\n",
      "epoch 38; iter: 0; batch classifier loss: 0.155737; batch adversarial loss: 0.460868\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116944; batch adversarial loss: 0.435929\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113832; batch adversarial loss: 0.398027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.121620; batch adversarial loss: 0.458184\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105444; batch adversarial loss: 0.543462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122067; batch adversarial loss: 0.419167\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213056; batch adversarial loss: 0.471009\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105563; batch adversarial loss: 0.431009\n",
      "epoch 46; iter: 0; batch classifier loss: 0.083601; batch adversarial loss: 0.467611\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073247; batch adversarial loss: 0.496970\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094913; batch adversarial loss: 0.504609\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059118; batch adversarial loss: 0.475772\n",
      "epoch 50; iter: 0; batch classifier loss: 0.095601; batch adversarial loss: 0.408198\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083689; batch adversarial loss: 0.456730\n",
      "epoch 52; iter: 0; batch classifier loss: 0.046622; batch adversarial loss: 0.498415\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108782; batch adversarial loss: 0.421286\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112406; batch adversarial loss: 0.367573\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123846; batch adversarial loss: 0.412510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073735; batch adversarial loss: 0.471982\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065062; batch adversarial loss: 0.402281\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067994; batch adversarial loss: 0.435053\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074732; batch adversarial loss: 0.498023\n",
      "epoch 60; iter: 0; batch classifier loss: 0.061267; batch adversarial loss: 0.436396\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055965; batch adversarial loss: 0.389221\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069160; batch adversarial loss: 0.493440\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050641; batch adversarial loss: 0.523942\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067161; batch adversarial loss: 0.447838\n",
      "epoch 65; iter: 0; batch classifier loss: 0.038932; batch adversarial loss: 0.523817\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072043; batch adversarial loss: 0.410933\n",
      "epoch 67; iter: 0; batch classifier loss: 0.051817; batch adversarial loss: 0.440701\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054563; batch adversarial loss: 0.402821\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064012; batch adversarial loss: 0.319026\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048449; batch adversarial loss: 0.389749\n",
      "epoch 71; iter: 0; batch classifier loss: 0.074873; batch adversarial loss: 0.560106\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065090; batch adversarial loss: 0.383448\n",
      "epoch 73; iter: 0; batch classifier loss: 0.093374; batch adversarial loss: 0.353386\n",
      "epoch 74; iter: 0; batch classifier loss: 0.051614; batch adversarial loss: 0.537804\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051403; batch adversarial loss: 0.378591\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047318; batch adversarial loss: 0.435142\n",
      "epoch 77; iter: 0; batch classifier loss: 0.041011; batch adversarial loss: 0.439654\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076242; batch adversarial loss: 0.366657\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061935; batch adversarial loss: 0.542965\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060038; batch adversarial loss: 0.440737\n",
      "epoch 81; iter: 0; batch classifier loss: 0.025036; batch adversarial loss: 0.474392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.051616; batch adversarial loss: 0.436743\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.442273\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060010; batch adversarial loss: 0.436361\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051847; batch adversarial loss: 0.408500\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074058; batch adversarial loss: 0.472090\n",
      "epoch 87; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.512174\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059858; batch adversarial loss: 0.446387\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036324; batch adversarial loss: 0.483366\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058785; batch adversarial loss: 0.472560\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042431; batch adversarial loss: 0.441896\n",
      "epoch 92; iter: 0; batch classifier loss: 0.027942; batch adversarial loss: 0.456644\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033507; batch adversarial loss: 0.461406\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065624; batch adversarial loss: 0.480392\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032324; batch adversarial loss: 0.478523\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051149; batch adversarial loss: 0.565130\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051918; batch adversarial loss: 0.497783\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053601; batch adversarial loss: 0.512409\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040737; batch adversarial loss: 0.311410\n",
      "epoch 100; iter: 0; batch classifier loss: 0.040806; batch adversarial loss: 0.409139\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066218; batch adversarial loss: 0.375561\n",
      "epoch 102; iter: 0; batch classifier loss: 0.020484; batch adversarial loss: 0.512959\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053550; batch adversarial loss: 0.383093\n",
      "epoch 104; iter: 0; batch classifier loss: 0.011134; batch adversarial loss: 0.485014\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033582; batch adversarial loss: 0.463431\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050248; batch adversarial loss: 0.452468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027523; batch adversarial loss: 0.443439\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076943; batch adversarial loss: 0.425707\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056125; batch adversarial loss: 0.454190\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057341; batch adversarial loss: 0.497770\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021946; batch adversarial loss: 0.400854\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059303; batch adversarial loss: 0.407761\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024518; batch adversarial loss: 0.440831\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034478; batch adversarial loss: 0.451977\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.496267\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066365; batch adversarial loss: 0.474138\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050511; batch adversarial loss: 0.454028\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046112; batch adversarial loss: 0.442494\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031448; batch adversarial loss: 0.476408\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037462; batch adversarial loss: 0.380152\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024612; batch adversarial loss: 0.511089\n",
      "epoch 122; iter: 0; batch classifier loss: 0.045451; batch adversarial loss: 0.410071\n",
      "epoch 123; iter: 0; batch classifier loss: 0.010643; batch adversarial loss: 0.543713\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034464; batch adversarial loss: 0.489222\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025497; batch adversarial loss: 0.458588\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030032; batch adversarial loss: 0.422735\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045202; batch adversarial loss: 0.463464\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031133; batch adversarial loss: 0.457917\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030563; batch adversarial loss: 0.514969\n",
      "epoch 130; iter: 0; batch classifier loss: 0.011516; batch adversarial loss: 0.466372\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018120; batch adversarial loss: 0.416914\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014632; batch adversarial loss: 0.400945\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015478; batch adversarial loss: 0.522999\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048527; batch adversarial loss: 0.471270\n",
      "epoch 135; iter: 0; batch classifier loss: 0.005553; batch adversarial loss: 0.432947\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040932; batch adversarial loss: 0.368143\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011138; batch adversarial loss: 0.358704\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.407973\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044557; batch adversarial loss: 0.416264\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023365; batch adversarial loss: 0.485013\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044358; batch adversarial loss: 0.479401\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039454; batch adversarial loss: 0.422703\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018628; batch adversarial loss: 0.506321\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009068; batch adversarial loss: 0.347708\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011602; batch adversarial loss: 0.362837\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034480; batch adversarial loss: 0.395085\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018635; batch adversarial loss: 0.537157\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056565; batch adversarial loss: 0.433501\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034684; batch adversarial loss: 0.346734\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029208; batch adversarial loss: 0.420337\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024827; batch adversarial loss: 0.483697\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012915; batch adversarial loss: 0.424220\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025599; batch adversarial loss: 0.464197\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013210; batch adversarial loss: 0.453444\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028683; batch adversarial loss: 0.507153\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048860; batch adversarial loss: 0.461590\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025114; batch adversarial loss: 0.488965\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015599; batch adversarial loss: 0.386454\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022211; batch adversarial loss: 0.507000\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012655; batch adversarial loss: 0.564087\n",
      "epoch 161; iter: 0; batch classifier loss: 0.043202; batch adversarial loss: 0.497711\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042093; batch adversarial loss: 0.473266\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021618; batch adversarial loss: 0.480556\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014582; batch adversarial loss: 0.441824\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023125; batch adversarial loss: 0.432759\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020678; batch adversarial loss: 0.545251\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.494553\n",
      "epoch 168; iter: 0; batch classifier loss: 0.003439; batch adversarial loss: 0.442179\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034150; batch adversarial loss: 0.518347\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013428; batch adversarial loss: 0.436994\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013118; batch adversarial loss: 0.464649\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005642; batch adversarial loss: 0.448397\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.432273\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020691; batch adversarial loss: 0.434428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.374621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.004272; batch adversarial loss: 0.544673\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018042; batch adversarial loss: 0.417989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.004463; batch adversarial loss: 0.501487\n",
      "epoch 179; iter: 0; batch classifier loss: 0.002846; batch adversarial loss: 0.388902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.005640; batch adversarial loss: 0.418033\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021519; batch adversarial loss: 0.504484\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013241; batch adversarial loss: 0.493256\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034882; batch adversarial loss: 0.483958\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012911; batch adversarial loss: 0.369861\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033638; batch adversarial loss: 0.464131\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022443; batch adversarial loss: 0.438463\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017690; batch adversarial loss: 0.431942\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005073; batch adversarial loss: 0.445903\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010357; batch adversarial loss: 0.416390\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016587; batch adversarial loss: 0.450105\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010782; batch adversarial loss: 0.482384\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031446; batch adversarial loss: 0.445210\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005013; batch adversarial loss: 0.591806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009823; batch adversarial loss: 0.426471\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024827; batch adversarial loss: 0.403501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017133; batch adversarial loss: 0.457564\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014100; batch adversarial loss: 0.473562\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008451; batch adversarial loss: 0.439613\n",
      "epoch 199; iter: 0; batch classifier loss: 0.071244; batch adversarial loss: 0.332097\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665439; batch adversarial loss: 0.705108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504994; batch adversarial loss: 0.701773\n",
      "epoch 2; iter: 0; batch classifier loss: 0.394583; batch adversarial loss: 0.678145\n",
      "epoch 3; iter: 0; batch classifier loss: 0.414884; batch adversarial loss: 0.608629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363625; batch adversarial loss: 0.586142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.312954; batch adversarial loss: 0.590548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362299; batch adversarial loss: 0.514743\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321425; batch adversarial loss: 0.513278\n",
      "epoch 8; iter: 0; batch classifier loss: 0.243222; batch adversarial loss: 0.507755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.221949; batch adversarial loss: 0.521693\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268987; batch adversarial loss: 0.521251\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264804; batch adversarial loss: 0.507223\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285111; batch adversarial loss: 0.427869\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261331; batch adversarial loss: 0.461294\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236396; batch adversarial loss: 0.465270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.129712; batch adversarial loss: 0.483814\n",
      "epoch 16; iter: 0; batch classifier loss: 0.197573; batch adversarial loss: 0.488730\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164134; batch adversarial loss: 0.425823\n",
      "epoch 18; iter: 0; batch classifier loss: 0.198061; batch adversarial loss: 0.482277\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203808; batch adversarial loss: 0.497119\n",
      "epoch 20; iter: 0; batch classifier loss: 0.138789; batch adversarial loss: 0.473396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.183621; batch adversarial loss: 0.449228\n",
      "epoch 22; iter: 0; batch classifier loss: 0.099476; batch adversarial loss: 0.497265\n",
      "epoch 23; iter: 0; batch classifier loss: 0.119155; batch adversarial loss: 0.435411\n",
      "epoch 24; iter: 0; batch classifier loss: 0.137740; batch adversarial loss: 0.486323\n",
      "epoch 25; iter: 0; batch classifier loss: 0.088487; batch adversarial loss: 0.463596\n",
      "epoch 26; iter: 0; batch classifier loss: 0.145338; batch adversarial loss: 0.464155\n",
      "epoch 27; iter: 0; batch classifier loss: 0.148962; batch adversarial loss: 0.484582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.146085; batch adversarial loss: 0.519136\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218150; batch adversarial loss: 0.490993\n",
      "epoch 30; iter: 0; batch classifier loss: 0.234888; batch adversarial loss: 0.544380\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268375; batch adversarial loss: 0.608112\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176905; batch adversarial loss: 0.483079\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219697; batch adversarial loss: 0.527997\n",
      "epoch 34; iter: 0; batch classifier loss: 0.185243; batch adversarial loss: 0.561311\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203239; batch adversarial loss: 0.450873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192088; batch adversarial loss: 0.489996\n",
      "epoch 37; iter: 0; batch classifier loss: 0.161028; batch adversarial loss: 0.497367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149166; batch adversarial loss: 0.453684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.185574; batch adversarial loss: 0.498379\n",
      "epoch 40; iter: 0; batch classifier loss: 0.184504; batch adversarial loss: 0.505929\n",
      "epoch 41; iter: 0; batch classifier loss: 0.228002; batch adversarial loss: 0.629616\n",
      "epoch 42; iter: 0; batch classifier loss: 0.160257; batch adversarial loss: 0.386069\n",
      "epoch 43; iter: 0; batch classifier loss: 0.197113; batch adversarial loss: 0.605715\n",
      "epoch 44; iter: 0; batch classifier loss: 0.248078; batch adversarial loss: 0.459223\n",
      "epoch 45; iter: 0; batch classifier loss: 0.175141; batch adversarial loss: 0.525087\n",
      "epoch 46; iter: 0; batch classifier loss: 0.047802; batch adversarial loss: 0.405492\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085257; batch adversarial loss: 0.410466\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081274; batch adversarial loss: 0.442315\n",
      "epoch 49; iter: 0; batch classifier loss: 0.056803; batch adversarial loss: 0.433148\n",
      "epoch 50; iter: 0; batch classifier loss: 0.060012; batch adversarial loss: 0.512764\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079895; batch adversarial loss: 0.496848\n",
      "epoch 52; iter: 0; batch classifier loss: 0.059553; batch adversarial loss: 0.515205\n",
      "epoch 53; iter: 0; batch classifier loss: 0.078853; batch adversarial loss: 0.395533\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098307; batch adversarial loss: 0.424974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061745; batch adversarial loss: 0.570402\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083765; batch adversarial loss: 0.438428\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069687; batch adversarial loss: 0.452211\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069367; batch adversarial loss: 0.475159\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066615; batch adversarial loss: 0.413960\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072012; batch adversarial loss: 0.503014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078695; batch adversarial loss: 0.367439\n",
      "epoch 62; iter: 0; batch classifier loss: 0.044231; batch adversarial loss: 0.443621\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072411; batch adversarial loss: 0.464554\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090012; batch adversarial loss: 0.486129\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074912; batch adversarial loss: 0.423736\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054471; batch adversarial loss: 0.508024\n",
      "epoch 67; iter: 0; batch classifier loss: 0.046807; batch adversarial loss: 0.394563\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076943; batch adversarial loss: 0.531941\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084903; batch adversarial loss: 0.480991\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079927; batch adversarial loss: 0.445024\n",
      "epoch 71; iter: 0; batch classifier loss: 0.027678; batch adversarial loss: 0.482072\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109700; batch adversarial loss: 0.442780\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052533; batch adversarial loss: 0.492827\n",
      "epoch 74; iter: 0; batch classifier loss: 0.135316; batch adversarial loss: 0.388729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052778; batch adversarial loss: 0.434221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.059370; batch adversarial loss: 0.413052\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083023; batch adversarial loss: 0.450792\n",
      "epoch 78; iter: 0; batch classifier loss: 0.035734; batch adversarial loss: 0.490360\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044492; batch adversarial loss: 0.513272\n",
      "epoch 80; iter: 0; batch classifier loss: 0.034586; batch adversarial loss: 0.507206\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097594; batch adversarial loss: 0.436415\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079324; batch adversarial loss: 0.456032\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081703; batch adversarial loss: 0.544546\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063805; batch adversarial loss: 0.407374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041947; batch adversarial loss: 0.440514\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060240; batch adversarial loss: 0.504839\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054710; batch adversarial loss: 0.443883\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037673; batch adversarial loss: 0.547421\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051051; batch adversarial loss: 0.533888\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035722; batch adversarial loss: 0.493510\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099411; batch adversarial loss: 0.445267\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057621; batch adversarial loss: 0.535359\n",
      "epoch 93; iter: 0; batch classifier loss: 0.019025; batch adversarial loss: 0.588061\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075760; batch adversarial loss: 0.540832\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055688; batch adversarial loss: 0.515766\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061080; batch adversarial loss: 0.415060\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060202; batch adversarial loss: 0.469421\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054826; batch adversarial loss: 0.466327\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035456; batch adversarial loss: 0.441298\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028397; batch adversarial loss: 0.385306\n",
      "epoch 101; iter: 0; batch classifier loss: 0.099031; batch adversarial loss: 0.490432\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054665; batch adversarial loss: 0.563820\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053580; batch adversarial loss: 0.463307\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043262; batch adversarial loss: 0.557957\n",
      "epoch 105; iter: 0; batch classifier loss: 0.020039; batch adversarial loss: 0.555663\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062366; batch adversarial loss: 0.461973\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039117; batch adversarial loss: 0.502859\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060092; batch adversarial loss: 0.383729\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077340; batch adversarial loss: 0.428091\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036766; batch adversarial loss: 0.511533\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030206; batch adversarial loss: 0.417199\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.426194\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039655; batch adversarial loss: 0.429895\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033909; batch adversarial loss: 0.546214\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052646; batch adversarial loss: 0.462360\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038135; batch adversarial loss: 0.464156\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052525; batch adversarial loss: 0.507035\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045429; batch adversarial loss: 0.459635\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050129; batch adversarial loss: 0.446363\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031059; batch adversarial loss: 0.551403\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054552; batch adversarial loss: 0.477186\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031667; batch adversarial loss: 0.480783\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032051; batch adversarial loss: 0.455863\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055491; batch adversarial loss: 0.524950\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044141; batch adversarial loss: 0.357860\n",
      "epoch 126; iter: 0; batch classifier loss: 0.068542; batch adversarial loss: 0.419352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028580; batch adversarial loss: 0.460170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.082184; batch adversarial loss: 0.407807\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040180; batch adversarial loss: 0.520002\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015337; batch adversarial loss: 0.414152\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034167; batch adversarial loss: 0.473029\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040839; batch adversarial loss: 0.409148\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050031; batch adversarial loss: 0.457963\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053196; batch adversarial loss: 0.475361\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047898; batch adversarial loss: 0.471170\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018165; batch adversarial loss: 0.487506\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041145; batch adversarial loss: 0.422931\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010504; batch adversarial loss: 0.570627\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.427620\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040659; batch adversarial loss: 0.416853\n",
      "epoch 141; iter: 0; batch classifier loss: 0.020847; batch adversarial loss: 0.416004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020950; batch adversarial loss: 0.480112\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033886; batch adversarial loss: 0.472805\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035793; batch adversarial loss: 0.526335\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021873; batch adversarial loss: 0.475484\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026449; batch adversarial loss: 0.456945\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026580; batch adversarial loss: 0.420150\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030397; batch adversarial loss: 0.528945\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015504; batch adversarial loss: 0.405880\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026308; batch adversarial loss: 0.511772\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030468; batch adversarial loss: 0.395683\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026943; batch adversarial loss: 0.546916\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032141; batch adversarial loss: 0.398956\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022110; batch adversarial loss: 0.407842\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032623; batch adversarial loss: 0.411364\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052707; batch adversarial loss: 0.503308\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.475490\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016262; batch adversarial loss: 0.552172\n",
      "epoch 159; iter: 0; batch classifier loss: 0.004505; batch adversarial loss: 0.366224\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041901; batch adversarial loss: 0.477331\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024844; batch adversarial loss: 0.383315\n",
      "epoch 162; iter: 0; batch classifier loss: 0.060830; batch adversarial loss: 0.383953\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040224; batch adversarial loss: 0.442140\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042999; batch adversarial loss: 0.591973\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010212; batch adversarial loss: 0.461741\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018704; batch adversarial loss: 0.441720\n",
      "epoch 167; iter: 0; batch classifier loss: 0.059853; batch adversarial loss: 0.501595\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037310; batch adversarial loss: 0.460842\n",
      "epoch 169; iter: 0; batch classifier loss: 0.010139; batch adversarial loss: 0.408203\n",
      "epoch 170; iter: 0; batch classifier loss: 0.005532; batch adversarial loss: 0.403889\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019056; batch adversarial loss: 0.516186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.027931; batch adversarial loss: 0.481174\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014178; batch adversarial loss: 0.490437\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029979; batch adversarial loss: 0.331431\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024374; batch adversarial loss: 0.434206\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005873; batch adversarial loss: 0.537403\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039466; batch adversarial loss: 0.355715\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010275; batch adversarial loss: 0.480466\n",
      "epoch 179; iter: 0; batch classifier loss: 0.063934; batch adversarial loss: 0.502339\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030743; batch adversarial loss: 0.366706\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028502; batch adversarial loss: 0.433971\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015888; batch adversarial loss: 0.397015\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005919; batch adversarial loss: 0.477129\n",
      "epoch 184; iter: 0; batch classifier loss: 0.052032; batch adversarial loss: 0.467366\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013601; batch adversarial loss: 0.473749\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033127; batch adversarial loss: 0.502484\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009457; batch adversarial loss: 0.383866\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017380; batch adversarial loss: 0.425988\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010305; batch adversarial loss: 0.446574\n",
      "epoch 190; iter: 0; batch classifier loss: 0.047784; batch adversarial loss: 0.412893\n",
      "epoch 191; iter: 0; batch classifier loss: 0.050094; batch adversarial loss: 0.407618\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009324; batch adversarial loss: 0.445233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026398; batch adversarial loss: 0.532492\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007845; batch adversarial loss: 0.515360\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040706; batch adversarial loss: 0.517969\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022392; batch adversarial loss: 0.602172\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026611; batch adversarial loss: 0.468888\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038303; batch adversarial loss: 0.428362\n",
      "epoch 199; iter: 0; batch classifier loss: 0.050287; batch adversarial loss: 0.436535\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689209; batch adversarial loss: 0.628153\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471507; batch adversarial loss: 0.628098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.359375; batch adversarial loss: 0.615149\n",
      "epoch 3; iter: 0; batch classifier loss: 0.307326; batch adversarial loss: 0.583504\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335562; batch adversarial loss: 0.560943\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349664; batch adversarial loss: 0.525583\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296425; batch adversarial loss: 0.505953\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382104; batch adversarial loss: 0.521738\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262774; batch adversarial loss: 0.501138\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242983; batch adversarial loss: 0.586654\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264726; batch adversarial loss: 0.512284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251627; batch adversarial loss: 0.408218\n",
      "epoch 12; iter: 0; batch classifier loss: 0.183636; batch adversarial loss: 0.477364\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266621; batch adversarial loss: 0.479529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290322; batch adversarial loss: 0.436934\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279017; batch adversarial loss: 0.535949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296345; batch adversarial loss: 0.537339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372403; batch adversarial loss: 0.510887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429382; batch adversarial loss: 0.421779\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523524; batch adversarial loss: 0.491539\n",
      "epoch 20; iter: 0; batch classifier loss: 0.384793; batch adversarial loss: 0.542578\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221282; batch adversarial loss: 0.472591\n",
      "epoch 22; iter: 0; batch classifier loss: 0.187185; batch adversarial loss: 0.469380\n",
      "epoch 23; iter: 0; batch classifier loss: 0.197198; batch adversarial loss: 0.526850\n",
      "epoch 24; iter: 0; batch classifier loss: 0.192103; batch adversarial loss: 0.444001\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216493; batch adversarial loss: 0.527527\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194883; batch adversarial loss: 0.321188\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163630; batch adversarial loss: 0.495752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157904; batch adversarial loss: 0.443057\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146758; batch adversarial loss: 0.498116\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149592; batch adversarial loss: 0.497595\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157367; batch adversarial loss: 0.467581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.104009; batch adversarial loss: 0.441081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121766; batch adversarial loss: 0.458214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.112128; batch adversarial loss: 0.491073\n",
      "epoch 35; iter: 0; batch classifier loss: 0.104570; batch adversarial loss: 0.520931\n",
      "epoch 36; iter: 0; batch classifier loss: 0.132954; batch adversarial loss: 0.434305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177019; batch adversarial loss: 0.351181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096715; batch adversarial loss: 0.515296\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138389; batch adversarial loss: 0.474845\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095891; batch adversarial loss: 0.454971\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100847; batch adversarial loss: 0.443833\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148247; batch adversarial loss: 0.518584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117218; batch adversarial loss: 0.489492\n",
      "epoch 44; iter: 0; batch classifier loss: 0.172133; batch adversarial loss: 0.464446\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105076; batch adversarial loss: 0.469213\n",
      "epoch 46; iter: 0; batch classifier loss: 0.155594; batch adversarial loss: 0.432337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105225; batch adversarial loss: 0.419205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110251; batch adversarial loss: 0.371879\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074840; batch adversarial loss: 0.557040\n",
      "epoch 50; iter: 0; batch classifier loss: 0.080757; batch adversarial loss: 0.491452\n",
      "epoch 51; iter: 0; batch classifier loss: 0.081778; batch adversarial loss: 0.538424\n",
      "epoch 52; iter: 0; batch classifier loss: 0.073761; batch adversarial loss: 0.487671\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103166; batch adversarial loss: 0.541406\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081934; batch adversarial loss: 0.501680\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093016; batch adversarial loss: 0.394532\n",
      "epoch 56; iter: 0; batch classifier loss: 0.129555; batch adversarial loss: 0.408970\n",
      "epoch 57; iter: 0; batch classifier loss: 0.100815; batch adversarial loss: 0.380156\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074065; batch adversarial loss: 0.391138\n",
      "epoch 59; iter: 0; batch classifier loss: 0.133661; batch adversarial loss: 0.496785\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097867; batch adversarial loss: 0.540313\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051812; batch adversarial loss: 0.496819\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106465; batch adversarial loss: 0.530394\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102140; batch adversarial loss: 0.385576\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104840; batch adversarial loss: 0.479321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.060577; batch adversarial loss: 0.404385\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096333; batch adversarial loss: 0.463282\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087961; batch adversarial loss: 0.487755\n",
      "epoch 68; iter: 0; batch classifier loss: 0.080638; batch adversarial loss: 0.426324\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115701; batch adversarial loss: 0.399711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.076245; batch adversarial loss: 0.352845\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080301; batch adversarial loss: 0.452919\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126922; batch adversarial loss: 0.440240\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068736; batch adversarial loss: 0.456464\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077072; batch adversarial loss: 0.513560\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096788; batch adversarial loss: 0.533107\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042712; batch adversarial loss: 0.393961\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074974; batch adversarial loss: 0.527180\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079088; batch adversarial loss: 0.464298\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067143; batch adversarial loss: 0.409783\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083989; batch adversarial loss: 0.404699\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066949; batch adversarial loss: 0.448137\n",
      "epoch 82; iter: 0; batch classifier loss: 0.099297; batch adversarial loss: 0.463037\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062714; batch adversarial loss: 0.365430\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066452; batch adversarial loss: 0.523566\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051981; batch adversarial loss: 0.470764\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063499; batch adversarial loss: 0.465169\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080957; batch adversarial loss: 0.459190\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074700; batch adversarial loss: 0.462382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102746; batch adversarial loss: 0.487079\n",
      "epoch 90; iter: 0; batch classifier loss: 0.045589; batch adversarial loss: 0.482414\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060311; batch adversarial loss: 0.499526\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078978; batch adversarial loss: 0.401330\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074995; batch adversarial loss: 0.427190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103695; batch adversarial loss: 0.489804\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071623; batch adversarial loss: 0.418618\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052559; batch adversarial loss: 0.512263\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087723; batch adversarial loss: 0.513712\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048298; batch adversarial loss: 0.408338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070165; batch adversarial loss: 0.378335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049476; batch adversarial loss: 0.449535\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062312; batch adversarial loss: 0.509510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062379; batch adversarial loss: 0.398893\n",
      "epoch 103; iter: 0; batch classifier loss: 0.076167; batch adversarial loss: 0.375199\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060547; batch adversarial loss: 0.427949\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038670; batch adversarial loss: 0.489014\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068984; batch adversarial loss: 0.383798\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055323; batch adversarial loss: 0.400526\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051775; batch adversarial loss: 0.539799\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076794; batch adversarial loss: 0.421979\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055140; batch adversarial loss: 0.455357\n",
      "epoch 111; iter: 0; batch classifier loss: 0.089868; batch adversarial loss: 0.418719\n",
      "epoch 112; iter: 0; batch classifier loss: 0.057223; batch adversarial loss: 0.514197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050937; batch adversarial loss: 0.453798\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092006; batch adversarial loss: 0.511383\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081735; batch adversarial loss: 0.436521\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.397753\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089291; batch adversarial loss: 0.478068\n",
      "epoch 118; iter: 0; batch classifier loss: 0.051076; batch adversarial loss: 0.457905\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025729; batch adversarial loss: 0.328698\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052958; batch adversarial loss: 0.509049\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059576; batch adversarial loss: 0.433518\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031085; batch adversarial loss: 0.472326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045548; batch adversarial loss: 0.438707\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031459; batch adversarial loss: 0.359922\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048127; batch adversarial loss: 0.412900\n",
      "epoch 126; iter: 0; batch classifier loss: 0.011301; batch adversarial loss: 0.493120\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060250; batch adversarial loss: 0.434483\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049901; batch adversarial loss: 0.428463\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071538; batch adversarial loss: 0.548989\n",
      "epoch 130; iter: 0; batch classifier loss: 0.010551; batch adversarial loss: 0.433518\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046842; batch adversarial loss: 0.547645\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019253; batch adversarial loss: 0.389350\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050147; batch adversarial loss: 0.439954\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038929; batch adversarial loss: 0.443951\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047069; batch adversarial loss: 0.480244\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034704; batch adversarial loss: 0.493037\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024855; batch adversarial loss: 0.453464\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030745; batch adversarial loss: 0.481427\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045975; batch adversarial loss: 0.488495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018268; batch adversarial loss: 0.488508\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029076; batch adversarial loss: 0.415561\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027545; batch adversarial loss: 0.417620\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020400; batch adversarial loss: 0.410020\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020582; batch adversarial loss: 0.391038\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040265; batch adversarial loss: 0.454638\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027695; batch adversarial loss: 0.524260\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019960; batch adversarial loss: 0.516058\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021868; batch adversarial loss: 0.469222\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023636; batch adversarial loss: 0.478969\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035265; batch adversarial loss: 0.508328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030899; batch adversarial loss: 0.450795\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042970; batch adversarial loss: 0.405086\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044868; batch adversarial loss: 0.388978\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023195; batch adversarial loss: 0.548117\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010439; batch adversarial loss: 0.464918\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024093; batch adversarial loss: 0.458961\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.424730\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019748; batch adversarial loss: 0.502827\n",
      "epoch 159; iter: 0; batch classifier loss: 0.032128; batch adversarial loss: 0.469037\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025218; batch adversarial loss: 0.527128\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021046; batch adversarial loss: 0.445747\n",
      "epoch 162; iter: 0; batch classifier loss: 0.032999; batch adversarial loss: 0.435988\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035195; batch adversarial loss: 0.421911\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015020; batch adversarial loss: 0.421304\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046230; batch adversarial loss: 0.464811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.025591; batch adversarial loss: 0.463960\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026009; batch adversarial loss: 0.386160\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019988; batch adversarial loss: 0.341841\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040017; batch adversarial loss: 0.480167\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026960; batch adversarial loss: 0.415686\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028663; batch adversarial loss: 0.452665\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040137; batch adversarial loss: 0.440924\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033388; batch adversarial loss: 0.324586\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013780; batch adversarial loss: 0.404164\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014579; batch adversarial loss: 0.404387\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014808; batch adversarial loss: 0.409945\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031649; batch adversarial loss: 0.482818\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015436; batch adversarial loss: 0.386373\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019997; batch adversarial loss: 0.463847\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034440; batch adversarial loss: 0.392489\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023495; batch adversarial loss: 0.433859\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014723; batch adversarial loss: 0.546161\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021312; batch adversarial loss: 0.425550\n",
      "epoch 184; iter: 0; batch classifier loss: 0.052238; batch adversarial loss: 0.471145\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012457; batch adversarial loss: 0.509890\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.390535\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045600; batch adversarial loss: 0.426732\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016962; batch adversarial loss: 0.369168\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018064; batch adversarial loss: 0.514943\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012554; batch adversarial loss: 0.480419\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017393; batch adversarial loss: 0.376790\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017586; batch adversarial loss: 0.494000\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027481; batch adversarial loss: 0.387562\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037873; batch adversarial loss: 0.387897\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016520; batch adversarial loss: 0.421704\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004744; batch adversarial loss: 0.403742\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014047; batch adversarial loss: 0.480189\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025122; batch adversarial loss: 0.394699\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020125; batch adversarial loss: 0.485747\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736627; batch adversarial loss: 0.773520\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461770; batch adversarial loss: 0.714710\n",
      "epoch 2; iter: 0; batch classifier loss: 0.324982; batch adversarial loss: 0.697111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359209; batch adversarial loss: 0.673966\n",
      "epoch 4; iter: 0; batch classifier loss: 0.348381; batch adversarial loss: 0.644029\n",
      "epoch 5; iter: 0; batch classifier loss: 0.416378; batch adversarial loss: 0.603174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309563; batch adversarial loss: 0.559026\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310020; batch adversarial loss: 0.511960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327983; batch adversarial loss: 0.505073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.271943; batch adversarial loss: 0.459963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306785; batch adversarial loss: 0.508776\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273571; batch adversarial loss: 0.404668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.250560; batch adversarial loss: 0.417958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.217395; batch adversarial loss: 0.487529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241403; batch adversarial loss: 0.410287\n",
      "epoch 15; iter: 0; batch classifier loss: 0.263371; batch adversarial loss: 0.429619\n",
      "epoch 16; iter: 0; batch classifier loss: 0.237334; batch adversarial loss: 0.390936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240948; batch adversarial loss: 0.428592\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209291; batch adversarial loss: 0.353531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248174; batch adversarial loss: 0.366825\n",
      "epoch 20; iter: 0; batch classifier loss: 0.143626; batch adversarial loss: 0.366119\n",
      "epoch 21; iter: 0; batch classifier loss: 0.200511; batch adversarial loss: 0.389074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192587; batch adversarial loss: 0.441087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238812; batch adversarial loss: 0.442038\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253032; batch adversarial loss: 0.397566\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207860; batch adversarial loss: 0.433233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.178105; batch adversarial loss: 0.368428\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175898; batch adversarial loss: 0.405980\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148620; batch adversarial loss: 0.401108\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177971; batch adversarial loss: 0.476219\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139309; batch adversarial loss: 0.321880\n",
      "epoch 31; iter: 0; batch classifier loss: 0.201100; batch adversarial loss: 0.420972\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146359; batch adversarial loss: 0.434478\n",
      "epoch 33; iter: 0; batch classifier loss: 0.140770; batch adversarial loss: 0.439417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145113; batch adversarial loss: 0.397365\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156532; batch adversarial loss: 0.463410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152328; batch adversarial loss: 0.439597\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116019; batch adversarial loss: 0.461274\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181658; batch adversarial loss: 0.395816\n",
      "epoch 39; iter: 0; batch classifier loss: 0.118269; batch adversarial loss: 0.350793\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108470; batch adversarial loss: 0.488700\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107603; batch adversarial loss: 0.421124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120966; batch adversarial loss: 0.422213\n",
      "epoch 43; iter: 0; batch classifier loss: 0.102920; batch adversarial loss: 0.413913\n",
      "epoch 44; iter: 0; batch classifier loss: 0.137036; batch adversarial loss: 0.421895\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163821; batch adversarial loss: 0.469551\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153572; batch adversarial loss: 0.499539\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119297; batch adversarial loss: 0.451465\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072235; batch adversarial loss: 0.369341\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069266; batch adversarial loss: 0.318159\n",
      "epoch 50; iter: 0; batch classifier loss: 0.093200; batch adversarial loss: 0.351007\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093134; batch adversarial loss: 0.376221\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074316; batch adversarial loss: 0.395133\n",
      "epoch 53; iter: 0; batch classifier loss: 0.108144; batch adversarial loss: 0.443968\n",
      "epoch 54; iter: 0; batch classifier loss: 0.119451; batch adversarial loss: 0.396052\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082605; batch adversarial loss: 0.449070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113909; batch adversarial loss: 0.440295\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068520; batch adversarial loss: 0.439457\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056476; batch adversarial loss: 0.428226\n",
      "epoch 59; iter: 0; batch classifier loss: 0.059809; batch adversarial loss: 0.456269\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105752; batch adversarial loss: 0.366424\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074279; batch adversarial loss: 0.325270\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094434; batch adversarial loss: 0.438369\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104477; batch adversarial loss: 0.389037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.104071; batch adversarial loss: 0.423244\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067859; batch adversarial loss: 0.507203\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090189; batch adversarial loss: 0.316686\n",
      "epoch 67; iter: 0; batch classifier loss: 0.047566; batch adversarial loss: 0.408647\n",
      "epoch 68; iter: 0; batch classifier loss: 0.093737; batch adversarial loss: 0.416171\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049810; batch adversarial loss: 0.424929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084080; batch adversarial loss: 0.484669\n",
      "epoch 71; iter: 0; batch classifier loss: 0.102643; batch adversarial loss: 0.366721\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066044; batch adversarial loss: 0.434810\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081352; batch adversarial loss: 0.420413\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082013; batch adversarial loss: 0.446501\n",
      "epoch 75; iter: 0; batch classifier loss: 0.117349; batch adversarial loss: 0.422812\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083820; batch adversarial loss: 0.387856\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087725; batch adversarial loss: 0.483378\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062726; batch adversarial loss: 0.426485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069672; batch adversarial loss: 0.395685\n",
      "epoch 80; iter: 0; batch classifier loss: 0.106153; batch adversarial loss: 0.427971\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051067; batch adversarial loss: 0.419745\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085246; batch adversarial loss: 0.304391\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056907; batch adversarial loss: 0.396949\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056288; batch adversarial loss: 0.359823\n",
      "epoch 85; iter: 0; batch classifier loss: 0.108288; batch adversarial loss: 0.368481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066530; batch adversarial loss: 0.367118\n",
      "epoch 87; iter: 0; batch classifier loss: 0.085582; batch adversarial loss: 0.486804\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.403557\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068915; batch adversarial loss: 0.381330\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035155; batch adversarial loss: 0.398640\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072688; batch adversarial loss: 0.415479\n",
      "epoch 92; iter: 0; batch classifier loss: 0.042247; batch adversarial loss: 0.374663\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073119; batch adversarial loss: 0.397615\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070637; batch adversarial loss: 0.342066\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051006; batch adversarial loss: 0.399870\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042509; batch adversarial loss: 0.372466\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052270; batch adversarial loss: 0.414502\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064793; batch adversarial loss: 0.419170\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047854; batch adversarial loss: 0.422549\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075815; batch adversarial loss: 0.435199\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041210; batch adversarial loss: 0.428074\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048281; batch adversarial loss: 0.357976\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045933; batch adversarial loss: 0.498788\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057465; batch adversarial loss: 0.465806\n",
      "epoch 105; iter: 0; batch classifier loss: 0.066797; batch adversarial loss: 0.346407\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033604; batch adversarial loss: 0.452695\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043087; batch adversarial loss: 0.471992\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044929; batch adversarial loss: 0.355002\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045012; batch adversarial loss: 0.527395\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053701; batch adversarial loss: 0.444705\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062706; batch adversarial loss: 0.452247\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062959; batch adversarial loss: 0.480021\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048635; batch adversarial loss: 0.388823\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050462; batch adversarial loss: 0.435748\n",
      "epoch 115; iter: 0; batch classifier loss: 0.059562; batch adversarial loss: 0.430285\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029154; batch adversarial loss: 0.347604\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037473; batch adversarial loss: 0.395228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.058045; batch adversarial loss: 0.451020\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050658; batch adversarial loss: 0.436901\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051198; batch adversarial loss: 0.384740\n",
      "epoch 121; iter: 0; batch classifier loss: 0.061391; batch adversarial loss: 0.481289\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039866; batch adversarial loss: 0.321118\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034967; batch adversarial loss: 0.500774\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019687; batch adversarial loss: 0.490727\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028775; batch adversarial loss: 0.428450\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036811; batch adversarial loss: 0.431942\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018520; batch adversarial loss: 0.409918\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044850; batch adversarial loss: 0.417518\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046911; batch adversarial loss: 0.431215\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029632; batch adversarial loss: 0.482674\n",
      "epoch 131; iter: 0; batch classifier loss: 0.064793; batch adversarial loss: 0.503470\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014376; batch adversarial loss: 0.606787\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024749; batch adversarial loss: 0.559039\n",
      "epoch 134; iter: 0; batch classifier loss: 0.012581; batch adversarial loss: 0.455392\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020476; batch adversarial loss: 0.456445\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041183; batch adversarial loss: 0.450739\n",
      "epoch 137; iter: 0; batch classifier loss: 0.072240; batch adversarial loss: 0.435176\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026698; batch adversarial loss: 0.522802\n",
      "epoch 139; iter: 0; batch classifier loss: 0.060336; batch adversarial loss: 0.563047\n",
      "epoch 140; iter: 0; batch classifier loss: 0.049775; batch adversarial loss: 0.507222\n",
      "epoch 141; iter: 0; batch classifier loss: 0.064855; batch adversarial loss: 0.491307\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056887; batch adversarial loss: 0.538196\n",
      "epoch 143; iter: 0; batch classifier loss: 0.106720; batch adversarial loss: 0.713366\n",
      "epoch 144; iter: 0; batch classifier loss: 0.069703; batch adversarial loss: 0.493031\n",
      "epoch 145; iter: 0; batch classifier loss: 0.254182; batch adversarial loss: 1.000581\n",
      "epoch 146; iter: 0; batch classifier loss: 0.134911; batch adversarial loss: 0.481251\n",
      "epoch 147; iter: 0; batch classifier loss: 0.097595; batch adversarial loss: 0.414584\n",
      "epoch 148; iter: 0; batch classifier loss: 0.168333; batch adversarial loss: 0.733834\n",
      "epoch 149; iter: 0; batch classifier loss: 0.166741; batch adversarial loss: 0.629839\n",
      "epoch 150; iter: 0; batch classifier loss: 0.174012; batch adversarial loss: 0.763505\n",
      "epoch 151; iter: 0; batch classifier loss: 0.145458; batch adversarial loss: 0.646402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.239928; batch adversarial loss: 0.888319\n",
      "epoch 153; iter: 0; batch classifier loss: 0.228380; batch adversarial loss: 0.811224\n",
      "epoch 154; iter: 0; batch classifier loss: 0.218551; batch adversarial loss: 0.734153\n",
      "epoch 155; iter: 0; batch classifier loss: 0.180279; batch adversarial loss: 0.534776\n",
      "epoch 156; iter: 0; batch classifier loss: 0.220636; batch adversarial loss: 0.761143\n",
      "epoch 157; iter: 0; batch classifier loss: 0.143935; batch adversarial loss: 0.684831\n",
      "epoch 158; iter: 0; batch classifier loss: 0.150062; batch adversarial loss: 0.713097\n",
      "epoch 159; iter: 0; batch classifier loss: 0.222190; batch adversarial loss: 0.665019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.136239; batch adversarial loss: 0.619071\n",
      "epoch 161; iter: 0; batch classifier loss: 0.137222; batch adversarial loss: 0.546825\n",
      "epoch 162; iter: 0; batch classifier loss: 0.178231; batch adversarial loss: 0.611419\n",
      "epoch 163; iter: 0; batch classifier loss: 0.178069; batch adversarial loss: 0.612371\n",
      "epoch 164; iter: 0; batch classifier loss: 0.111929; batch adversarial loss: 0.517443\n",
      "epoch 165; iter: 0; batch classifier loss: 0.171454; batch adversarial loss: 0.625114\n",
      "epoch 166; iter: 0; batch classifier loss: 0.186106; batch adversarial loss: 0.615900\n",
      "epoch 167; iter: 0; batch classifier loss: 0.193433; batch adversarial loss: 0.672022\n",
      "epoch 168; iter: 0; batch classifier loss: 0.244485; batch adversarial loss: 0.685458\n",
      "epoch 169; iter: 0; batch classifier loss: 0.167652; batch adversarial loss: 0.589025\n",
      "epoch 170; iter: 0; batch classifier loss: 0.141221; batch adversarial loss: 0.568224\n",
      "epoch 171; iter: 0; batch classifier loss: 0.155133; batch adversarial loss: 0.529435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.140649; batch adversarial loss: 0.494474\n",
      "epoch 173; iter: 0; batch classifier loss: 0.093658; batch adversarial loss: 0.456359\n",
      "epoch 174; iter: 0; batch classifier loss: 0.157162; batch adversarial loss: 0.511502\n",
      "epoch 175; iter: 0; batch classifier loss: 0.144530; batch adversarial loss: 0.544949\n",
      "epoch 176; iter: 0; batch classifier loss: 0.243861; batch adversarial loss: 0.606592\n",
      "epoch 177; iter: 0; batch classifier loss: 0.109507; batch adversarial loss: 0.433110\n",
      "epoch 178; iter: 0; batch classifier loss: 0.153928; batch adversarial loss: 0.579774\n",
      "epoch 179; iter: 0; batch classifier loss: 0.159535; batch adversarial loss: 0.642704\n",
      "epoch 180; iter: 0; batch classifier loss: 0.126277; batch adversarial loss: 0.452997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.179280; batch adversarial loss: 0.506256\n",
      "epoch 182; iter: 0; batch classifier loss: 0.153319; batch adversarial loss: 0.472258\n",
      "epoch 183; iter: 0; batch classifier loss: 0.107924; batch adversarial loss: 0.476179\n",
      "epoch 184; iter: 0; batch classifier loss: 0.104328; batch adversarial loss: 0.366919\n",
      "epoch 185; iter: 0; batch classifier loss: 0.127977; batch adversarial loss: 0.596350\n",
      "epoch 186; iter: 0; batch classifier loss: 0.130922; batch adversarial loss: 0.412378\n",
      "epoch 187; iter: 0; batch classifier loss: 0.150081; batch adversarial loss: 0.427134\n",
      "epoch 188; iter: 0; batch classifier loss: 0.128829; batch adversarial loss: 0.484042\n",
      "epoch 189; iter: 0; batch classifier loss: 0.137760; batch adversarial loss: 0.470641\n",
      "epoch 190; iter: 0; batch classifier loss: 0.175254; batch adversarial loss: 0.565409\n",
      "epoch 191; iter: 0; batch classifier loss: 0.102179; batch adversarial loss: 0.436421\n",
      "epoch 192; iter: 0; batch classifier loss: 0.087102; batch adversarial loss: 0.411566\n",
      "epoch 193; iter: 0; batch classifier loss: 0.064795; batch adversarial loss: 0.432482\n",
      "epoch 194; iter: 0; batch classifier loss: 0.043583; batch adversarial loss: 0.419037\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029929; batch adversarial loss: 0.360158\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034187; batch adversarial loss: 0.393415\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.463340\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017684; batch adversarial loss: 0.489300\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020163; batch adversarial loss: 0.528902\n",
      "epoch 0; iter: 0; batch classifier loss: 0.654701; batch adversarial loss: 0.776204\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628170; batch adversarial loss: 0.777325\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647208; batch adversarial loss: 0.699197\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630748; batch adversarial loss: 0.671114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.487439; batch adversarial loss: 0.640359\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330705; batch adversarial loss: 0.564544\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308776; batch adversarial loss: 0.523550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319595; batch adversarial loss: 0.523316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.254518; batch adversarial loss: 0.528851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282165; batch adversarial loss: 0.497254\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276294; batch adversarial loss: 0.574271\n",
      "epoch 11; iter: 0; batch classifier loss: 0.208956; batch adversarial loss: 0.484814\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273411; batch adversarial loss: 0.537327\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242703; batch adversarial loss: 0.458863\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229324; batch adversarial loss: 0.559712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.177654; batch adversarial loss: 0.519707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213486; batch adversarial loss: 0.511724\n",
      "epoch 17; iter: 0; batch classifier loss: 0.178868; batch adversarial loss: 0.453234\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261589; batch adversarial loss: 0.491259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197961; batch adversarial loss: 0.514896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205941; batch adversarial loss: 0.438575\n",
      "epoch 21; iter: 0; batch classifier loss: 0.124032; batch adversarial loss: 0.448350\n",
      "epoch 22; iter: 0; batch classifier loss: 0.199484; batch adversarial loss: 0.514694\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187020; batch adversarial loss: 0.401943\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169574; batch adversarial loss: 0.550157\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158387; batch adversarial loss: 0.581947\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140351; batch adversarial loss: 0.481091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.129668; batch adversarial loss: 0.523717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148523; batch adversarial loss: 0.391367\n",
      "epoch 29; iter: 0; batch classifier loss: 0.146961; batch adversarial loss: 0.514500\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141835; batch adversarial loss: 0.504969\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172910; batch adversarial loss: 0.382552\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127708; batch adversarial loss: 0.455888\n",
      "epoch 33; iter: 0; batch classifier loss: 0.097881; batch adversarial loss: 0.456381\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104696; batch adversarial loss: 0.477646\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140860; batch adversarial loss: 0.436026\n",
      "epoch 36; iter: 0; batch classifier loss: 0.129203; batch adversarial loss: 0.449504\n",
      "epoch 37; iter: 0; batch classifier loss: 0.145648; batch adversarial loss: 0.393893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117644; batch adversarial loss: 0.480599\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088780; batch adversarial loss: 0.446877\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116166; batch adversarial loss: 0.328473\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104687; batch adversarial loss: 0.405562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122588; batch adversarial loss: 0.460098\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135386; batch adversarial loss: 0.546378\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106533; batch adversarial loss: 0.483236\n",
      "epoch 45; iter: 0; batch classifier loss: 0.044189; batch adversarial loss: 0.440244\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127468; batch adversarial loss: 0.484517\n",
      "epoch 47; iter: 0; batch classifier loss: 0.077859; batch adversarial loss: 0.526393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.085332; batch adversarial loss: 0.543689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119336; batch adversarial loss: 0.445327\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089962; batch adversarial loss: 0.563775\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159505; batch adversarial loss: 0.458413\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072097; batch adversarial loss: 0.461983\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117128; batch adversarial loss: 0.338600\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077521; batch adversarial loss: 0.524452\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107154; batch adversarial loss: 0.402925\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068896; batch adversarial loss: 0.539725\n",
      "epoch 57; iter: 0; batch classifier loss: 0.145729; batch adversarial loss: 0.373670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.095003; batch adversarial loss: 0.354430\n",
      "epoch 59; iter: 0; batch classifier loss: 0.087863; batch adversarial loss: 0.556608\n",
      "epoch 60; iter: 0; batch classifier loss: 0.090053; batch adversarial loss: 0.373685\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108789; batch adversarial loss: 0.564603\n",
      "epoch 62; iter: 0; batch classifier loss: 0.054478; batch adversarial loss: 0.493694\n",
      "epoch 63; iter: 0; batch classifier loss: 0.078267; batch adversarial loss: 0.395197\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083230; batch adversarial loss: 0.510240\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064463; batch adversarial loss: 0.467791\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068230; batch adversarial loss: 0.441083\n",
      "epoch 67; iter: 0; batch classifier loss: 0.038634; batch adversarial loss: 0.375324\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095050; batch adversarial loss: 0.466405\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060081; batch adversarial loss: 0.325086\n",
      "epoch 70; iter: 0; batch classifier loss: 0.054065; batch adversarial loss: 0.490892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054662; batch adversarial loss: 0.382273\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072246; batch adversarial loss: 0.380547\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038997; batch adversarial loss: 0.475198\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086678; batch adversarial loss: 0.363423\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099890; batch adversarial loss: 0.449937\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061891; batch adversarial loss: 0.406421\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042981; batch adversarial loss: 0.471604\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073085; batch adversarial loss: 0.393005\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058615; batch adversarial loss: 0.435174\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096962; batch adversarial loss: 0.546645\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080869; batch adversarial loss: 0.539955\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037248; batch adversarial loss: 0.572727\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064112; batch adversarial loss: 0.475292\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066258; batch adversarial loss: 0.522325\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078593; batch adversarial loss: 0.449376\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063435; batch adversarial loss: 0.389550\n",
      "epoch 87; iter: 0; batch classifier loss: 0.023118; batch adversarial loss: 0.477311\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066214; batch adversarial loss: 0.453131\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065039; batch adversarial loss: 0.516163\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074296; batch adversarial loss: 0.380718\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041667; batch adversarial loss: 0.462655\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044294; batch adversarial loss: 0.388955\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.383990\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036651; batch adversarial loss: 0.405167\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.424253\n",
      "epoch 96; iter: 0; batch classifier loss: 0.052185; batch adversarial loss: 0.380089\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042342; batch adversarial loss: 0.454185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030684; batch adversarial loss: 0.459699\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050648; batch adversarial loss: 0.448006\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057077; batch adversarial loss: 0.439194\n",
      "epoch 101; iter: 0; batch classifier loss: 0.033953; batch adversarial loss: 0.479372\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074441; batch adversarial loss: 0.565534\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036173; batch adversarial loss: 0.507189\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061848; batch adversarial loss: 0.405450\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040713; batch adversarial loss: 0.412888\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043105; batch adversarial loss: 0.432428\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046708; batch adversarial loss: 0.411224\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046312; batch adversarial loss: 0.415582\n",
      "epoch 109; iter: 0; batch classifier loss: 0.050803; batch adversarial loss: 0.396900\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022878; batch adversarial loss: 0.404154\n",
      "epoch 111; iter: 0; batch classifier loss: 0.013907; batch adversarial loss: 0.365090\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033268; batch adversarial loss: 0.516642\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027780; batch adversarial loss: 0.445427\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049005; batch adversarial loss: 0.456449\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032135; batch adversarial loss: 0.374571\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027467; batch adversarial loss: 0.466140\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062526; batch adversarial loss: 0.417077\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040208; batch adversarial loss: 0.486788\n",
      "epoch 119; iter: 0; batch classifier loss: 0.015753; batch adversarial loss: 0.410301\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040690; batch adversarial loss: 0.422924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038617; batch adversarial loss: 0.426501\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050481; batch adversarial loss: 0.615137\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020296; batch adversarial loss: 0.519417\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021660; batch adversarial loss: 0.440320\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012471; batch adversarial loss: 0.520996\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033094; batch adversarial loss: 0.471561\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021016; batch adversarial loss: 0.351296\n",
      "epoch 128; iter: 0; batch classifier loss: 0.067797; batch adversarial loss: 0.486233\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041287; batch adversarial loss: 0.376238\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044135; batch adversarial loss: 0.560492\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037392; batch adversarial loss: 0.456602\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030384; batch adversarial loss: 0.482083\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033846; batch adversarial loss: 0.618424\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039228; batch adversarial loss: 0.554954\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030675; batch adversarial loss: 0.427662\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035551; batch adversarial loss: 0.430778\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029945; batch adversarial loss: 0.382819\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022770; batch adversarial loss: 0.450550\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011036; batch adversarial loss: 0.499826\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014488; batch adversarial loss: 0.441121\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030256; batch adversarial loss: 0.442848\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046914; batch adversarial loss: 0.460256\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014802; batch adversarial loss: 0.418938\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018948; batch adversarial loss: 0.453915\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030066; batch adversarial loss: 0.497871\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042871; batch adversarial loss: 0.471193\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024202; batch adversarial loss: 0.393696\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026875; batch adversarial loss: 0.482619\n",
      "epoch 149; iter: 0; batch classifier loss: 0.037109; batch adversarial loss: 0.380668\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025586; batch adversarial loss: 0.484405\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043879; batch adversarial loss: 0.477130\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034381; batch adversarial loss: 0.431302\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014311; batch adversarial loss: 0.398738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.463100\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009716; batch adversarial loss: 0.461598\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029551; batch adversarial loss: 0.418397\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028293; batch adversarial loss: 0.512535\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016301; batch adversarial loss: 0.449663\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025715; batch adversarial loss: 0.458735\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016656; batch adversarial loss: 0.464703\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021258; batch adversarial loss: 0.456515\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050797; batch adversarial loss: 0.351701\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023267; batch adversarial loss: 0.463995\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028919; batch adversarial loss: 0.406261\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038273; batch adversarial loss: 0.431531\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021082; batch adversarial loss: 0.479936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049219; batch adversarial loss: 0.607331\n",
      "epoch 168; iter: 0; batch classifier loss: 0.054430; batch adversarial loss: 0.471574\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036015; batch adversarial loss: 0.432841\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027409; batch adversarial loss: 0.490682\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045394; batch adversarial loss: 0.424752\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026256; batch adversarial loss: 0.496052\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029872; batch adversarial loss: 0.455865\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020948; batch adversarial loss: 0.403426\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013205; batch adversarial loss: 0.455891\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016485; batch adversarial loss: 0.431469\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.433305\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020712; batch adversarial loss: 0.415593\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010553; batch adversarial loss: 0.397566\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022123; batch adversarial loss: 0.421234\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028525; batch adversarial loss: 0.480756\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010788; batch adversarial loss: 0.540283\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.452846\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036081; batch adversarial loss: 0.420032\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024136; batch adversarial loss: 0.482428\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012692; batch adversarial loss: 0.498477\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027979; batch adversarial loss: 0.355917\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012019; batch adversarial loss: 0.436312\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007226; batch adversarial loss: 0.516733\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038762; batch adversarial loss: 0.347136\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022000; batch adversarial loss: 0.414790\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008889; batch adversarial loss: 0.369576\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020881; batch adversarial loss: 0.453163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025624; batch adversarial loss: 0.458237\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035718; batch adversarial loss: 0.475484\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026731; batch adversarial loss: 0.498947\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.416919\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040059; batch adversarial loss: 0.416609\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017130; batch adversarial loss: 0.369616\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683188; batch adversarial loss: 0.780512\n",
      "epoch 1; iter: 0; batch classifier loss: 0.458551; batch adversarial loss: 0.727571\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421346; batch adversarial loss: 0.687473\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348597; batch adversarial loss: 0.652565\n",
      "epoch 4; iter: 0; batch classifier loss: 0.338798; batch adversarial loss: 0.615880\n",
      "epoch 5; iter: 0; batch classifier loss: 0.371789; batch adversarial loss: 0.591586\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338626; batch adversarial loss: 0.588105\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311779; batch adversarial loss: 0.568219\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255731; batch adversarial loss: 0.523405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270176; batch adversarial loss: 0.512864\n",
      "epoch 10; iter: 0; batch classifier loss: 0.227805; batch adversarial loss: 0.535721\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207342; batch adversarial loss: 0.519373\n",
      "epoch 12; iter: 0; batch classifier loss: 0.232532; batch adversarial loss: 0.481958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.240152; batch adversarial loss: 0.507758\n",
      "epoch 14; iter: 0; batch classifier loss: 0.208928; batch adversarial loss: 0.507606\n",
      "epoch 15; iter: 0; batch classifier loss: 0.204791; batch adversarial loss: 0.530954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192230; batch adversarial loss: 0.479213\n",
      "epoch 17; iter: 0; batch classifier loss: 0.283334; batch adversarial loss: 0.479151\n",
      "epoch 18; iter: 0; batch classifier loss: 0.201840; batch adversarial loss: 0.584023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316580; batch adversarial loss: 0.519273\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250608; batch adversarial loss: 0.439056\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355043; batch adversarial loss: 0.526574\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264022; batch adversarial loss: 0.526752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225151; batch adversarial loss: 0.490917\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184329; batch adversarial loss: 0.509444\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172411; batch adversarial loss: 0.490154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.168524; batch adversarial loss: 0.468417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.113842; batch adversarial loss: 0.458942\n",
      "epoch 28; iter: 0; batch classifier loss: 0.113548; batch adversarial loss: 0.515067\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176655; batch adversarial loss: 0.473311\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134513; batch adversarial loss: 0.396219\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160132; batch adversarial loss: 0.399414\n",
      "epoch 32; iter: 0; batch classifier loss: 0.106436; batch adversarial loss: 0.488016\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128502; batch adversarial loss: 0.420808\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132868; batch adversarial loss: 0.422411\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117067; batch adversarial loss: 0.446157\n",
      "epoch 36; iter: 0; batch classifier loss: 0.077354; batch adversarial loss: 0.443319\n",
      "epoch 37; iter: 0; batch classifier loss: 0.124418; batch adversarial loss: 0.555495\n",
      "epoch 38; iter: 0; batch classifier loss: 0.132629; batch adversarial loss: 0.501033\n",
      "epoch 39; iter: 0; batch classifier loss: 0.130510; batch adversarial loss: 0.396992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.466678\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112711; batch adversarial loss: 0.547131\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097048; batch adversarial loss: 0.445918\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113647; batch adversarial loss: 0.453860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110438; batch adversarial loss: 0.371069\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108365; batch adversarial loss: 0.378113\n",
      "epoch 46; iter: 0; batch classifier loss: 0.051641; batch adversarial loss: 0.570023\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129998; batch adversarial loss: 0.374455\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086579; batch adversarial loss: 0.345879\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088469; batch adversarial loss: 0.427715\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098760; batch adversarial loss: 0.437545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.062770; batch adversarial loss: 0.468356\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107795; batch adversarial loss: 0.393274\n",
      "epoch 53; iter: 0; batch classifier loss: 0.115400; batch adversarial loss: 0.404538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.055566; batch adversarial loss: 0.492164\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084730; batch adversarial loss: 0.507716\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087492; batch adversarial loss: 0.398765\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090304; batch adversarial loss: 0.413284\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066111; batch adversarial loss: 0.518547\n",
      "epoch 59; iter: 0; batch classifier loss: 0.102053; batch adversarial loss: 0.482089\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099980; batch adversarial loss: 0.474453\n",
      "epoch 61; iter: 0; batch classifier loss: 0.092257; batch adversarial loss: 0.434911\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082608; batch adversarial loss: 0.344171\n",
      "epoch 63; iter: 0; batch classifier loss: 0.028697; batch adversarial loss: 0.459837\n",
      "epoch 64; iter: 0; batch classifier loss: 0.130358; batch adversarial loss: 0.364503\n",
      "epoch 65; iter: 0; batch classifier loss: 0.099952; batch adversarial loss: 0.420704\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058489; batch adversarial loss: 0.473442\n",
      "epoch 67; iter: 0; batch classifier loss: 0.075997; batch adversarial loss: 0.469926\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065534; batch adversarial loss: 0.441796\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073523; batch adversarial loss: 0.474764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.044236; batch adversarial loss: 0.509112\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073437; batch adversarial loss: 0.441038\n",
      "epoch 72; iter: 0; batch classifier loss: 0.033854; batch adversarial loss: 0.360320\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052668; batch adversarial loss: 0.525049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072760; batch adversarial loss: 0.455056\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060317; batch adversarial loss: 0.388390\n",
      "epoch 76; iter: 0; batch classifier loss: 0.047247; batch adversarial loss: 0.510225\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034570; batch adversarial loss: 0.347127\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046850; batch adversarial loss: 0.346910\n",
      "epoch 79; iter: 0; batch classifier loss: 0.048455; batch adversarial loss: 0.571319\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064942; batch adversarial loss: 0.449779\n",
      "epoch 81; iter: 0; batch classifier loss: 0.033170; batch adversarial loss: 0.553594\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060138; batch adversarial loss: 0.481811\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065619; batch adversarial loss: 0.547993\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089989; batch adversarial loss: 0.465664\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070470; batch adversarial loss: 0.460553\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040506; batch adversarial loss: 0.450049\n",
      "epoch 87; iter: 0; batch classifier loss: 0.040717; batch adversarial loss: 0.481248\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034028; batch adversarial loss: 0.535420\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092209; batch adversarial loss: 0.396884\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047973; batch adversarial loss: 0.433421\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056665; batch adversarial loss: 0.338556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048853; batch adversarial loss: 0.436949\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038598; batch adversarial loss: 0.464646\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064533; batch adversarial loss: 0.461664\n",
      "epoch 95; iter: 0; batch classifier loss: 0.054915; batch adversarial loss: 0.411218\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051273; batch adversarial loss: 0.444119\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038450; batch adversarial loss: 0.378322\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030507; batch adversarial loss: 0.488298\n",
      "epoch 99; iter: 0; batch classifier loss: 0.027709; batch adversarial loss: 0.416516\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041603; batch adversarial loss: 0.425693\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042031; batch adversarial loss: 0.471019\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.451154\n",
      "epoch 103; iter: 0; batch classifier loss: 0.056797; batch adversarial loss: 0.515987\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041130; batch adversarial loss: 0.435107\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027575; batch adversarial loss: 0.513427\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060868; batch adversarial loss: 0.379347\n",
      "epoch 107; iter: 0; batch classifier loss: 0.017483; batch adversarial loss: 0.581025\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077045; batch adversarial loss: 0.415822\n",
      "epoch 109; iter: 0; batch classifier loss: 0.018548; batch adversarial loss: 0.421211\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045870; batch adversarial loss: 0.417953\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034750; batch adversarial loss: 0.428517\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052358; batch adversarial loss: 0.418512\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049741; batch adversarial loss: 0.419942\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060562; batch adversarial loss: 0.429442\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047709; batch adversarial loss: 0.357932\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034182; batch adversarial loss: 0.554373\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076175; batch adversarial loss: 0.450368\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031494; batch adversarial loss: 0.433264\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036013; batch adversarial loss: 0.467088\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077861; batch adversarial loss: 0.569739\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053849; batch adversarial loss: 0.527840\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032632; batch adversarial loss: 0.431069\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043597; batch adversarial loss: 0.420085\n",
      "epoch 124; iter: 0; batch classifier loss: 0.013419; batch adversarial loss: 0.453768\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056409; batch adversarial loss: 0.591548\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054004; batch adversarial loss: 0.440411\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035162; batch adversarial loss: 0.436199\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036346; batch adversarial loss: 0.567862\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024066; batch adversarial loss: 0.431591\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028433; batch adversarial loss: 0.421597\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022154; batch adversarial loss: 0.458108\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028467; batch adversarial loss: 0.436028\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.513300\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034119; batch adversarial loss: 0.451361\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042591; batch adversarial loss: 0.434199\n",
      "epoch 136; iter: 0; batch classifier loss: 0.012860; batch adversarial loss: 0.416649\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050446; batch adversarial loss: 0.348334\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031583; batch adversarial loss: 0.534167\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048379; batch adversarial loss: 0.540881\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052298; batch adversarial loss: 0.462698\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044411; batch adversarial loss: 0.348127\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011682; batch adversarial loss: 0.404233\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023541; batch adversarial loss: 0.436446\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014882; batch adversarial loss: 0.481563\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028565; batch adversarial loss: 0.403665\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021462; batch adversarial loss: 0.451048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.023830; batch adversarial loss: 0.394382\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013913; batch adversarial loss: 0.402038\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011834; batch adversarial loss: 0.432438\n",
      "epoch 150; iter: 0; batch classifier loss: 0.051211; batch adversarial loss: 0.484230\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037815; batch adversarial loss: 0.369461\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027337; batch adversarial loss: 0.452096\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011886; batch adversarial loss: 0.549762\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036536; batch adversarial loss: 0.439866\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012099; batch adversarial loss: 0.499714\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033533; batch adversarial loss: 0.521407\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033075; batch adversarial loss: 0.377116\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009110; batch adversarial loss: 0.442260\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019763; batch adversarial loss: 0.525301\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018146; batch adversarial loss: 0.426932\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016693; batch adversarial loss: 0.444871\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033146; batch adversarial loss: 0.456670\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014599; batch adversarial loss: 0.452843\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029832; batch adversarial loss: 0.499263\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014558; batch adversarial loss: 0.490993\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015138; batch adversarial loss: 0.505767\n",
      "epoch 167; iter: 0; batch classifier loss: 0.048036; batch adversarial loss: 0.369147\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023336; batch adversarial loss: 0.444469\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023734; batch adversarial loss: 0.396298\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009136; batch adversarial loss: 0.434364\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013362; batch adversarial loss: 0.395488\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018367; batch adversarial loss: 0.439569\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037396; batch adversarial loss: 0.456367\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030939; batch adversarial loss: 0.523974\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038950; batch adversarial loss: 0.426437\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023248; batch adversarial loss: 0.430443\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018763; batch adversarial loss: 0.476206\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033636; batch adversarial loss: 0.491562\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022833; batch adversarial loss: 0.388325\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024216; batch adversarial loss: 0.415788\n",
      "epoch 181; iter: 0; batch classifier loss: 0.054189; batch adversarial loss: 0.429111\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020170; batch adversarial loss: 0.431295\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019458; batch adversarial loss: 0.407323\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026517; batch adversarial loss: 0.436540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019357; batch adversarial loss: 0.399414\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016101; batch adversarial loss: 0.511016\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.451685\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033511; batch adversarial loss: 0.458714\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012695; batch adversarial loss: 0.554934\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041133; batch adversarial loss: 0.409252\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020107; batch adversarial loss: 0.471446\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016502; batch adversarial loss: 0.500484\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032099; batch adversarial loss: 0.473325\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020497; batch adversarial loss: 0.420055\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035068; batch adversarial loss: 0.452913\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012848; batch adversarial loss: 0.505592\n",
      "epoch 197; iter: 0; batch classifier loss: 0.011634; batch adversarial loss: 0.454762\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007834; batch adversarial loss: 0.456063\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041333; batch adversarial loss: 0.549205\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680443; batch adversarial loss: 0.602450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.404060; batch adversarial loss: 0.617932\n",
      "epoch 2; iter: 0; batch classifier loss: 0.436594; batch adversarial loss: 0.599930\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415861; batch adversarial loss: 0.584975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344757; batch adversarial loss: 0.616437\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368498; batch adversarial loss: 0.566789\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414397; batch adversarial loss: 0.578926\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493007; batch adversarial loss: 0.581906\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492522; batch adversarial loss: 0.592146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610611; batch adversarial loss: 0.577611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.622491; batch adversarial loss: 0.571072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519537; batch adversarial loss: 0.504285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.444650; batch adversarial loss: 0.481245\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373256; batch adversarial loss: 0.499829\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389152; batch adversarial loss: 0.483365\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283654; batch adversarial loss: 0.495666\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327122; batch adversarial loss: 0.465829\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356521; batch adversarial loss: 0.503176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251460; batch adversarial loss: 0.452386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280746; batch adversarial loss: 0.455259\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272462; batch adversarial loss: 0.494558\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228028; batch adversarial loss: 0.440846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.273355; batch adversarial loss: 0.475815\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241772; batch adversarial loss: 0.547570\n",
      "epoch 24; iter: 0; batch classifier loss: 0.244506; batch adversarial loss: 0.468185\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223772; batch adversarial loss: 0.466872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.242899; batch adversarial loss: 0.466261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256335; batch adversarial loss: 0.422473\n",
      "epoch 28; iter: 0; batch classifier loss: 0.223536; batch adversarial loss: 0.375234\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199159; batch adversarial loss: 0.507213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.224241; batch adversarial loss: 0.431960\n",
      "epoch 31; iter: 0; batch classifier loss: 0.245761; batch adversarial loss: 0.524632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.217938; batch adversarial loss: 0.398742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239833; batch adversarial loss: 0.508928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171657; batch adversarial loss: 0.421323\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257033; batch adversarial loss: 0.390967\n",
      "epoch 36; iter: 0; batch classifier loss: 0.167588; batch adversarial loss: 0.501063\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215305; batch adversarial loss: 0.525043\n",
      "epoch 38; iter: 0; batch classifier loss: 0.195646; batch adversarial loss: 0.512880\n",
      "epoch 39; iter: 0; batch classifier loss: 0.199193; batch adversarial loss: 0.533665\n",
      "epoch 40; iter: 0; batch classifier loss: 0.192217; batch adversarial loss: 0.438993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.255475; batch adversarial loss: 0.449840\n",
      "epoch 42; iter: 0; batch classifier loss: 0.183163; batch adversarial loss: 0.482696\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251234; batch adversarial loss: 0.482208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.199853; batch adversarial loss: 0.483990\n",
      "epoch 45; iter: 0; batch classifier loss: 0.143466; batch adversarial loss: 0.486831\n",
      "epoch 46; iter: 0; batch classifier loss: 0.215429; batch adversarial loss: 0.483511\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238161; batch adversarial loss: 0.580895\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231627; batch adversarial loss: 0.436042\n",
      "epoch 49; iter: 0; batch classifier loss: 0.191044; batch adversarial loss: 0.436966\n",
      "epoch 50; iter: 0; batch classifier loss: 0.214003; batch adversarial loss: 0.435037\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156712; batch adversarial loss: 0.373171\n",
      "epoch 52; iter: 0; batch classifier loss: 0.274370; batch adversarial loss: 0.422439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.247324; batch adversarial loss: 0.421577\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200932; batch adversarial loss: 0.370800\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156362; batch adversarial loss: 0.447011\n",
      "epoch 56; iter: 0; batch classifier loss: 0.262425; batch adversarial loss: 0.433624\n",
      "epoch 57; iter: 0; batch classifier loss: 0.111984; batch adversarial loss: 0.521870\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194991; batch adversarial loss: 0.510732\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200902; batch adversarial loss: 0.458931\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203087; batch adversarial loss: 0.509697\n",
      "epoch 61; iter: 0; batch classifier loss: 0.150845; batch adversarial loss: 0.421457\n",
      "epoch 62; iter: 0; batch classifier loss: 0.124193; batch adversarial loss: 0.420335\n",
      "epoch 63; iter: 0; batch classifier loss: 0.188632; batch adversarial loss: 0.471505\n",
      "epoch 64; iter: 0; batch classifier loss: 0.277677; batch adversarial loss: 0.446202\n",
      "epoch 65; iter: 0; batch classifier loss: 0.154200; batch adversarial loss: 0.433590\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097338; batch adversarial loss: 0.482880\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105497; batch adversarial loss: 0.406028\n",
      "epoch 68; iter: 0; batch classifier loss: 0.179639; batch adversarial loss: 0.481816\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200935; batch adversarial loss: 0.443640\n",
      "epoch 70; iter: 0; batch classifier loss: 0.134394; batch adversarial loss: 0.471413\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086983; batch adversarial loss: 0.447682\n",
      "epoch 72; iter: 0; batch classifier loss: 0.179838; batch adversarial loss: 0.445878\n",
      "epoch 73; iter: 0; batch classifier loss: 0.239270; batch adversarial loss: 0.366195\n",
      "epoch 74; iter: 0; batch classifier loss: 0.145010; batch adversarial loss: 0.445448\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177273; batch adversarial loss: 0.458552\n",
      "epoch 76; iter: 0; batch classifier loss: 0.170006; batch adversarial loss: 0.498466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.176718; batch adversarial loss: 0.408715\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192578; batch adversarial loss: 0.459311\n",
      "epoch 79; iter: 0; batch classifier loss: 0.192765; batch adversarial loss: 0.395940\n",
      "epoch 80; iter: 0; batch classifier loss: 0.283393; batch adversarial loss: 0.458614\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152279; batch adversarial loss: 0.459135\n",
      "epoch 82; iter: 0; batch classifier loss: 0.235602; batch adversarial loss: 0.408047\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091311; batch adversarial loss: 0.445973\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090384; batch adversarial loss: 0.459211\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.445012\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069076; batch adversarial loss: 0.404322\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057289; batch adversarial loss: 0.415568\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073121; batch adversarial loss: 0.416623\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080578; batch adversarial loss: 0.410340\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061516; batch adversarial loss: 0.469546\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056993; batch adversarial loss: 0.515813\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038464; batch adversarial loss: 0.458222\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053085; batch adversarial loss: 0.378033\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043263; batch adversarial loss: 0.457782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046385; batch adversarial loss: 0.442644\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059253; batch adversarial loss: 0.477769\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063609; batch adversarial loss: 0.422540\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054562; batch adversarial loss: 0.527349\n",
      "epoch 99; iter: 0; batch classifier loss: 0.081479; batch adversarial loss: 0.395288\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059263; batch adversarial loss: 0.518570\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073696; batch adversarial loss: 0.397722\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062201; batch adversarial loss: 0.457576\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064454; batch adversarial loss: 0.477121\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061119; batch adversarial loss: 0.398398\n",
      "epoch 105; iter: 0; batch classifier loss: 0.065371; batch adversarial loss: 0.336673\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056973; batch adversarial loss: 0.413468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065411; batch adversarial loss: 0.372760\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078903; batch adversarial loss: 0.410353\n",
      "epoch 109; iter: 0; batch classifier loss: 0.115857; batch adversarial loss: 0.479803\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041278; batch adversarial loss: 0.472481\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042051; batch adversarial loss: 0.463209\n",
      "epoch 112; iter: 0; batch classifier loss: 0.068209; batch adversarial loss: 0.429003\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038422; batch adversarial loss: 0.356242\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053963; batch adversarial loss: 0.393096\n",
      "epoch 115; iter: 0; batch classifier loss: 0.095439; batch adversarial loss: 0.458703\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027790; batch adversarial loss: 0.423837\n",
      "epoch 117; iter: 0; batch classifier loss: 0.087537; batch adversarial loss: 0.428237\n",
      "epoch 118; iter: 0; batch classifier loss: 0.121036; batch adversarial loss: 0.429252\n",
      "epoch 119; iter: 0; batch classifier loss: 0.077610; batch adversarial loss: 0.457273\n",
      "epoch 120; iter: 0; batch classifier loss: 0.060152; batch adversarial loss: 0.474924\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072102; batch adversarial loss: 0.350762\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.436758\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057305; batch adversarial loss: 0.390705\n",
      "epoch 124; iter: 0; batch classifier loss: 0.104049; batch adversarial loss: 0.445944\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037420; batch adversarial loss: 0.508813\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042817; batch adversarial loss: 0.389619\n",
      "epoch 127; iter: 0; batch classifier loss: 0.101996; batch adversarial loss: 0.455342\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070439; batch adversarial loss: 0.335182\n",
      "epoch 129; iter: 0; batch classifier loss: 0.092052; batch adversarial loss: 0.387437\n",
      "epoch 130; iter: 0; batch classifier loss: 0.116365; batch adversarial loss: 0.432479\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038881; batch adversarial loss: 0.384791\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.384761\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047262; batch adversarial loss: 0.474209\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041547; batch adversarial loss: 0.456346\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046628; batch adversarial loss: 0.315277\n",
      "epoch 136; iter: 0; batch classifier loss: 0.041397; batch adversarial loss: 0.416053\n",
      "epoch 137; iter: 0; batch classifier loss: 0.074836; batch adversarial loss: 0.349699\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063049; batch adversarial loss: 0.453120\n",
      "epoch 139; iter: 0; batch classifier loss: 0.123854; batch adversarial loss: 0.356549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.028568; batch adversarial loss: 0.349946\n",
      "epoch 141; iter: 0; batch classifier loss: 0.063088; batch adversarial loss: 0.367650\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038308; batch adversarial loss: 0.341227\n",
      "epoch 143; iter: 0; batch classifier loss: 0.080372; batch adversarial loss: 0.425137\n",
      "epoch 144; iter: 0; batch classifier loss: 0.070257; batch adversarial loss: 0.395081\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057945; batch adversarial loss: 0.436672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041657; batch adversarial loss: 0.400158\n",
      "epoch 147; iter: 0; batch classifier loss: 0.132979; batch adversarial loss: 0.464162\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049504; batch adversarial loss: 0.400538\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053691; batch adversarial loss: 0.367938\n",
      "epoch 150; iter: 0; batch classifier loss: 0.076808; batch adversarial loss: 0.410785\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053180; batch adversarial loss: 0.359601\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056931; batch adversarial loss: 0.416920\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054919; batch adversarial loss: 0.318744\n",
      "epoch 154; iter: 0; batch classifier loss: 0.052216; batch adversarial loss: 0.416066\n",
      "epoch 155; iter: 0; batch classifier loss: 0.063752; batch adversarial loss: 0.473578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053818; batch adversarial loss: 0.420813\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043339; batch adversarial loss: 0.399839\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054493; batch adversarial loss: 0.329223\n",
      "epoch 159; iter: 0; batch classifier loss: 0.068052; batch adversarial loss: 0.451205\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034523; batch adversarial loss: 0.471385\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042408; batch adversarial loss: 0.391827\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044332; batch adversarial loss: 0.384401\n",
      "epoch 163; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.447551\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054262; batch adversarial loss: 0.415450\n",
      "epoch 165; iter: 0; batch classifier loss: 0.058287; batch adversarial loss: 0.393197\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054896; batch adversarial loss: 0.291031\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046089; batch adversarial loss: 0.435872\n",
      "epoch 168; iter: 0; batch classifier loss: 0.071585; batch adversarial loss: 0.418121\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049043; batch adversarial loss: 0.439606\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043861; batch adversarial loss: 0.383263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041729; batch adversarial loss: 0.506540\n",
      "epoch 172; iter: 0; batch classifier loss: 0.049912; batch adversarial loss: 0.462652\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042064; batch adversarial loss: 0.512927\n",
      "epoch 174; iter: 0; batch classifier loss: 0.087326; batch adversarial loss: 0.464730\n",
      "epoch 175; iter: 0; batch classifier loss: 0.055733; batch adversarial loss: 0.409027\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041251; batch adversarial loss: 0.314074\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052575; batch adversarial loss: 0.414421\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017599; batch adversarial loss: 0.356004\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038457; batch adversarial loss: 0.405284\n",
      "epoch 180; iter: 0; batch classifier loss: 0.044854; batch adversarial loss: 0.403785\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029009; batch adversarial loss: 0.476085\n",
      "epoch 182; iter: 0; batch classifier loss: 0.050522; batch adversarial loss: 0.291626\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033238; batch adversarial loss: 0.378834\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057793; batch adversarial loss: 0.513142\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041619; batch adversarial loss: 0.367406\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.421361\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042088; batch adversarial loss: 0.451253\n",
      "epoch 188; iter: 0; batch classifier loss: 0.054195; batch adversarial loss: 0.389290\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.471526\n",
      "epoch 190; iter: 0; batch classifier loss: 0.072301; batch adversarial loss: 0.366915\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027794; batch adversarial loss: 0.416982\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033822; batch adversarial loss: 0.399153\n",
      "epoch 193; iter: 0; batch classifier loss: 0.045942; batch adversarial loss: 0.400691\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041381; batch adversarial loss: 0.491632\n",
      "epoch 195; iter: 0; batch classifier loss: 0.032988; batch adversarial loss: 0.409312\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024949; batch adversarial loss: 0.422102\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034056; batch adversarial loss: 0.376237\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033192; batch adversarial loss: 0.478692\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056334; batch adversarial loss: 0.422928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691897; batch adversarial loss: 0.724468\n",
      "epoch 1; iter: 0; batch classifier loss: 0.502931; batch adversarial loss: 0.687391\n",
      "epoch 2; iter: 0; batch classifier loss: 0.427210; batch adversarial loss: 0.657148\n",
      "epoch 3; iter: 0; batch classifier loss: 0.342419; batch adversarial loss: 0.636514\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356041; batch adversarial loss: 0.606747\n",
      "epoch 5; iter: 0; batch classifier loss: 0.395443; batch adversarial loss: 0.553136\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383063; batch adversarial loss: 0.501322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324864; batch adversarial loss: 0.494325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335561; batch adversarial loss: 0.500965\n",
      "epoch 9; iter: 0; batch classifier loss: 0.229539; batch adversarial loss: 0.498715\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218057; batch adversarial loss: 0.488450\n",
      "epoch 11; iter: 0; batch classifier loss: 0.225165; batch adversarial loss: 0.458374\n",
      "epoch 12; iter: 0; batch classifier loss: 0.216413; batch adversarial loss: 0.437419\n",
      "epoch 13; iter: 0; batch classifier loss: 0.152620; batch adversarial loss: 0.515125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.182362; batch adversarial loss: 0.459656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.193227; batch adversarial loss: 0.456945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.172381; batch adversarial loss: 0.471526\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185489; batch adversarial loss: 0.418997\n",
      "epoch 18; iter: 0; batch classifier loss: 0.123545; batch adversarial loss: 0.445630\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219535; batch adversarial loss: 0.490945\n",
      "epoch 20; iter: 0; batch classifier loss: 0.138502; batch adversarial loss: 0.465116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.127514; batch adversarial loss: 0.443889\n",
      "epoch 22; iter: 0; batch classifier loss: 0.111057; batch adversarial loss: 0.407979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.126814; batch adversarial loss: 0.394044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.156509; batch adversarial loss: 0.465798\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196924; batch adversarial loss: 0.458330\n",
      "epoch 26; iter: 0; batch classifier loss: 0.149727; batch adversarial loss: 0.431792\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144890; batch adversarial loss: 0.381754\n",
      "epoch 28; iter: 0; batch classifier loss: 0.143980; batch adversarial loss: 0.405601\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120483; batch adversarial loss: 0.444676\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139658; batch adversarial loss: 0.429473\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149508; batch adversarial loss: 0.337990\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127048; batch adversarial loss: 0.362613\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116671; batch adversarial loss: 0.427735\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106687; batch adversarial loss: 0.460836\n",
      "epoch 35; iter: 0; batch classifier loss: 0.147768; batch adversarial loss: 0.474262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.170760; batch adversarial loss: 0.436667\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134829; batch adversarial loss: 0.432008\n",
      "epoch 38; iter: 0; batch classifier loss: 0.094548; batch adversarial loss: 0.346794\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135439; batch adversarial loss: 0.444778\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095415; batch adversarial loss: 0.386068\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140204; batch adversarial loss: 0.342975\n",
      "epoch 42; iter: 0; batch classifier loss: 0.118206; batch adversarial loss: 0.470299\n",
      "epoch 43; iter: 0; batch classifier loss: 0.063842; batch adversarial loss: 0.371117\n",
      "epoch 44; iter: 0; batch classifier loss: 0.164498; batch adversarial loss: 0.530438\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099048; batch adversarial loss: 0.446627\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150404; batch adversarial loss: 0.491257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114333; batch adversarial loss: 0.365822\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109791; batch adversarial loss: 0.404792\n",
      "epoch 49; iter: 0; batch classifier loss: 0.155998; batch adversarial loss: 0.392123\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098388; batch adversarial loss: 0.374605\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104659; batch adversarial loss: 0.506071\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092278; batch adversarial loss: 0.398452\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097649; batch adversarial loss: 0.446892\n",
      "epoch 54; iter: 0; batch classifier loss: 0.078613; batch adversarial loss: 0.398611\n",
      "epoch 55; iter: 0; batch classifier loss: 0.095304; batch adversarial loss: 0.396553\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112202; batch adversarial loss: 0.345108\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102332; batch adversarial loss: 0.473938\n",
      "epoch 58; iter: 0; batch classifier loss: 0.118052; batch adversarial loss: 0.381169\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101093; batch adversarial loss: 0.453259\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130287; batch adversarial loss: 0.475695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076602; batch adversarial loss: 0.412825\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080071; batch adversarial loss: 0.405236\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073503; batch adversarial loss: 0.461225\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085995; batch adversarial loss: 0.520599\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083282; batch adversarial loss: 0.358497\n",
      "epoch 66; iter: 0; batch classifier loss: 0.117271; batch adversarial loss: 0.375081\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111038; batch adversarial loss: 0.449537\n",
      "epoch 68; iter: 0; batch classifier loss: 0.055730; batch adversarial loss: 0.469261\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100367; batch adversarial loss: 0.427763\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062919; batch adversarial loss: 0.465510\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093344; batch adversarial loss: 0.460753\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068671; batch adversarial loss: 0.436188\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062722; batch adversarial loss: 0.432538\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059926; batch adversarial loss: 0.438472\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081747; batch adversarial loss: 0.444883\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058671; batch adversarial loss: 0.411052\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065351; batch adversarial loss: 0.399802\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091115; batch adversarial loss: 0.428610\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084582; batch adversarial loss: 0.431770\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076456; batch adversarial loss: 0.412305\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065694; batch adversarial loss: 0.456428\n",
      "epoch 82; iter: 0; batch classifier loss: 0.029878; batch adversarial loss: 0.470849\n",
      "epoch 83; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.425016\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071001; batch adversarial loss: 0.427356\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085726; batch adversarial loss: 0.568292\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062500; batch adversarial loss: 0.404786\n",
      "epoch 87; iter: 0; batch classifier loss: 0.051350; batch adversarial loss: 0.365766\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047837; batch adversarial loss: 0.434308\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043694; batch adversarial loss: 0.361950\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067475; batch adversarial loss: 0.497667\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.384646\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068739; batch adversarial loss: 0.376458\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080171; batch adversarial loss: 0.413535\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047523; batch adversarial loss: 0.491751\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.349434\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059807; batch adversarial loss: 0.438303\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065742; batch adversarial loss: 0.271633\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059195; batch adversarial loss: 0.456776\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057626; batch adversarial loss: 0.424026\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060303; batch adversarial loss: 0.453898\n",
      "epoch 101; iter: 0; batch classifier loss: 0.071095; batch adversarial loss: 0.477768\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056910; batch adversarial loss: 0.404292\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063622; batch adversarial loss: 0.434208\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079946; batch adversarial loss: 0.313042\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048983; batch adversarial loss: 0.426999\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043932; batch adversarial loss: 0.405120\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050352; batch adversarial loss: 0.454829\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046871; batch adversarial loss: 0.436005\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062461; batch adversarial loss: 0.467566\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069313; batch adversarial loss: 0.297736\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038213; batch adversarial loss: 0.461202\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046377; batch adversarial loss: 0.385145\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050301; batch adversarial loss: 0.432814\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037056; batch adversarial loss: 0.423239\n",
      "epoch 115; iter: 0; batch classifier loss: 0.085536; batch adversarial loss: 0.375386\n",
      "epoch 116; iter: 0; batch classifier loss: 0.047770; batch adversarial loss: 0.435469\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035320; batch adversarial loss: 0.421896\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044358; batch adversarial loss: 0.333542\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036617; batch adversarial loss: 0.492791\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047320; batch adversarial loss: 0.442248\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049637; batch adversarial loss: 0.360602\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028771; batch adversarial loss: 0.490629\n",
      "epoch 123; iter: 0; batch classifier loss: 0.058043; batch adversarial loss: 0.377960\n",
      "epoch 124; iter: 0; batch classifier loss: 0.069491; batch adversarial loss: 0.370355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046249; batch adversarial loss: 0.407144\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060176; batch adversarial loss: 0.442388\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043952; batch adversarial loss: 0.480675\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056185; batch adversarial loss: 0.393989\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033859; batch adversarial loss: 0.360771\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073651; batch adversarial loss: 0.545215\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026250; batch adversarial loss: 0.508773\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036201; batch adversarial loss: 0.424574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029973; batch adversarial loss: 0.402157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.025784; batch adversarial loss: 0.453541\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031721; batch adversarial loss: 0.491552\n",
      "epoch 136; iter: 0; batch classifier loss: 0.038225; batch adversarial loss: 0.384119\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043659; batch adversarial loss: 0.431395\n",
      "epoch 138; iter: 0; batch classifier loss: 0.028114; batch adversarial loss: 0.475415\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017324; batch adversarial loss: 0.364649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018281; batch adversarial loss: 0.514960\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044932; batch adversarial loss: 0.433667\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033157; batch adversarial loss: 0.440551\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020110; batch adversarial loss: 0.475892\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046892; batch adversarial loss: 0.482457\n",
      "epoch 145; iter: 0; batch classifier loss: 0.080215; batch adversarial loss: 0.415260\n",
      "epoch 146; iter: 0; batch classifier loss: 0.078932; batch adversarial loss: 0.492924\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043065; batch adversarial loss: 0.529914\n",
      "epoch 148; iter: 0; batch classifier loss: 0.110391; batch adversarial loss: 0.560662\n",
      "epoch 149; iter: 0; batch classifier loss: 0.092578; batch adversarial loss: 0.633511\n",
      "epoch 150; iter: 0; batch classifier loss: 0.132170; batch adversarial loss: 0.754775\n",
      "epoch 151; iter: 0; batch classifier loss: 0.107747; batch adversarial loss: 0.572863\n",
      "epoch 152; iter: 0; batch classifier loss: 0.169853; batch adversarial loss: 0.647896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073938; batch adversarial loss: 0.410238\n",
      "epoch 154; iter: 0; batch classifier loss: 0.135935; batch adversarial loss: 0.599751\n",
      "epoch 155; iter: 0; batch classifier loss: 0.210849; batch adversarial loss: 0.560389\n",
      "epoch 156; iter: 0; batch classifier loss: 0.148257; batch adversarial loss: 0.692693\n",
      "epoch 157; iter: 0; batch classifier loss: 0.095241; batch adversarial loss: 0.531874\n",
      "epoch 158; iter: 0; batch classifier loss: 0.227734; batch adversarial loss: 0.754670\n",
      "epoch 159; iter: 0; batch classifier loss: 0.128519; batch adversarial loss: 0.646301\n",
      "epoch 160; iter: 0; batch classifier loss: 0.192131; batch adversarial loss: 0.716780\n",
      "epoch 161; iter: 0; batch classifier loss: 0.111934; batch adversarial loss: 0.509242\n",
      "epoch 162; iter: 0; batch classifier loss: 0.193972; batch adversarial loss: 0.591946\n",
      "epoch 163; iter: 0; batch classifier loss: 0.163086; batch adversarial loss: 0.710393\n",
      "epoch 164; iter: 0; batch classifier loss: 0.136912; batch adversarial loss: 0.501523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.159740; batch adversarial loss: 0.643851\n",
      "epoch 166; iter: 0; batch classifier loss: 0.152543; batch adversarial loss: 0.539001\n",
      "epoch 167; iter: 0; batch classifier loss: 0.168504; batch adversarial loss: 0.582548\n",
      "epoch 168; iter: 0; batch classifier loss: 0.094082; batch adversarial loss: 0.490945\n",
      "epoch 169; iter: 0; batch classifier loss: 0.180146; batch adversarial loss: 0.598099\n",
      "epoch 170; iter: 0; batch classifier loss: 0.138304; batch adversarial loss: 0.576724\n",
      "epoch 171; iter: 0; batch classifier loss: 0.075710; batch adversarial loss: 0.433819\n",
      "epoch 172; iter: 0; batch classifier loss: 0.136115; batch adversarial loss: 0.503467\n",
      "epoch 173; iter: 0; batch classifier loss: 0.181978; batch adversarial loss: 0.625595\n",
      "epoch 174; iter: 0; batch classifier loss: 0.102475; batch adversarial loss: 0.552949\n",
      "epoch 175; iter: 0; batch classifier loss: 0.104343; batch adversarial loss: 0.503841\n",
      "epoch 176; iter: 0; batch classifier loss: 0.140405; batch adversarial loss: 0.600366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.175047; batch adversarial loss: 0.479227\n",
      "epoch 178; iter: 0; batch classifier loss: 0.104452; batch adversarial loss: 0.471494\n",
      "epoch 179; iter: 0; batch classifier loss: 0.096030; batch adversarial loss: 0.467241\n",
      "epoch 180; iter: 0; batch classifier loss: 0.097737; batch adversarial loss: 0.393516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.134781; batch adversarial loss: 0.534114\n",
      "epoch 182; iter: 0; batch classifier loss: 0.074633; batch adversarial loss: 0.486718\n",
      "epoch 183; iter: 0; batch classifier loss: 0.120356; batch adversarial loss: 0.487433\n",
      "epoch 184; iter: 0; batch classifier loss: 0.119885; batch adversarial loss: 0.405775\n",
      "epoch 185; iter: 0; batch classifier loss: 0.138687; batch adversarial loss: 0.629683\n",
      "epoch 186; iter: 0; batch classifier loss: 0.125743; batch adversarial loss: 0.468596\n",
      "epoch 187; iter: 0; batch classifier loss: 0.125316; batch adversarial loss: 0.420151\n",
      "epoch 188; iter: 0; batch classifier loss: 0.130722; batch adversarial loss: 0.510567\n",
      "epoch 189; iter: 0; batch classifier loss: 0.105822; batch adversarial loss: 0.416927\n",
      "epoch 190; iter: 0; batch classifier loss: 0.135808; batch adversarial loss: 0.516039\n",
      "epoch 191; iter: 0; batch classifier loss: 0.089404; batch adversarial loss: 0.409529\n",
      "epoch 192; iter: 0; batch classifier loss: 0.090977; batch adversarial loss: 0.395288\n",
      "epoch 193; iter: 0; batch classifier loss: 0.100133; batch adversarial loss: 0.492323\n",
      "epoch 194; iter: 0; batch classifier loss: 0.099379; batch adversarial loss: 0.438853\n",
      "epoch 195; iter: 0; batch classifier loss: 0.082772; batch adversarial loss: 0.424560\n",
      "epoch 196; iter: 0; batch classifier loss: 0.078267; batch adversarial loss: 0.385245\n",
      "epoch 197; iter: 0; batch classifier loss: 0.083639; batch adversarial loss: 0.457218\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019090; batch adversarial loss: 0.483666\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018047; batch adversarial loss: 0.471644\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690469; batch adversarial loss: 0.610094\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441640; batch adversarial loss: 0.620797\n",
      "epoch 2; iter: 0; batch classifier loss: 0.332826; batch adversarial loss: 0.589351\n",
      "epoch 3; iter: 0; batch classifier loss: 0.301225; batch adversarial loss: 0.632794\n",
      "epoch 4; iter: 0; batch classifier loss: 0.331793; batch adversarial loss: 0.543567\n",
      "epoch 5; iter: 0; batch classifier loss: 0.333785; batch adversarial loss: 0.556141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.367036; batch adversarial loss: 0.499744\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297590; batch adversarial loss: 0.541809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322698; batch adversarial loss: 0.525194\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275210; batch adversarial loss: 0.501783\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280315; batch adversarial loss: 0.492786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.230745; batch adversarial loss: 0.510920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302024; batch adversarial loss: 0.546183\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335558; batch adversarial loss: 0.526755\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302258; batch adversarial loss: 0.497389\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310422; batch adversarial loss: 0.536470\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356416; batch adversarial loss: 0.529854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.591043; batch adversarial loss: 0.466324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553629; batch adversarial loss: 0.480839\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432580; batch adversarial loss: 0.488518\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252528; batch adversarial loss: 0.432343\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187352; batch adversarial loss: 0.453430\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183350; batch adversarial loss: 0.445573\n",
      "epoch 23; iter: 0; batch classifier loss: 0.158157; batch adversarial loss: 0.423145\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140944; batch adversarial loss: 0.463754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192529; batch adversarial loss: 0.412612\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207983; batch adversarial loss: 0.533710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176013; batch adversarial loss: 0.381523\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171130; batch adversarial loss: 0.447302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154535; batch adversarial loss: 0.540305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.166085; batch adversarial loss: 0.485048\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166636; batch adversarial loss: 0.506972\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117739; batch adversarial loss: 0.334584\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126335; batch adversarial loss: 0.474741\n",
      "epoch 34; iter: 0; batch classifier loss: 0.099392; batch adversarial loss: 0.393238\n",
      "epoch 35; iter: 0; batch classifier loss: 0.094905; batch adversarial loss: 0.520918\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111917; batch adversarial loss: 0.332070\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110552; batch adversarial loss: 0.439839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.161261; batch adversarial loss: 0.379902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093865; batch adversarial loss: 0.433152\n",
      "epoch 40; iter: 0; batch classifier loss: 0.077352; batch adversarial loss: 0.574150\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089762; batch adversarial loss: 0.439180\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106995; batch adversarial loss: 0.340006\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101782; batch adversarial loss: 0.402194\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107472; batch adversarial loss: 0.404911\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099628; batch adversarial loss: 0.408202\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129459; batch adversarial loss: 0.478780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.064570; batch adversarial loss: 0.409749\n",
      "epoch 48; iter: 0; batch classifier loss: 0.117302; batch adversarial loss: 0.424477\n",
      "epoch 49; iter: 0; batch classifier loss: 0.126084; batch adversarial loss: 0.413172\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098294; batch adversarial loss: 0.375301\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096745; batch adversarial loss: 0.509154\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114694; batch adversarial loss: 0.456102\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125303; batch adversarial loss: 0.513727\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088544; batch adversarial loss: 0.446123\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077528; batch adversarial loss: 0.414096\n",
      "epoch 56; iter: 0; batch classifier loss: 0.058427; batch adversarial loss: 0.460199\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082807; batch adversarial loss: 0.529809\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093285; batch adversarial loss: 0.376962\n",
      "epoch 59; iter: 0; batch classifier loss: 0.148664; batch adversarial loss: 0.452195\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091779; batch adversarial loss: 0.427125\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059455; batch adversarial loss: 0.498224\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089001; batch adversarial loss: 0.380920\n",
      "epoch 63; iter: 0; batch classifier loss: 0.098807; batch adversarial loss: 0.384690\n",
      "epoch 64; iter: 0; batch classifier loss: 0.075250; batch adversarial loss: 0.457554\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092745; batch adversarial loss: 0.456323\n",
      "epoch 66; iter: 0; batch classifier loss: 0.041350; batch adversarial loss: 0.396651\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145767; batch adversarial loss: 0.434129\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082061; batch adversarial loss: 0.550761\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076416; batch adversarial loss: 0.549940\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087649; batch adversarial loss: 0.442613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.150824; batch adversarial loss: 0.478192\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094523; batch adversarial loss: 0.408927\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092430; batch adversarial loss: 0.501219\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067472; batch adversarial loss: 0.375491\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087635; batch adversarial loss: 0.365146\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086009; batch adversarial loss: 0.450269\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068617; batch adversarial loss: 0.476319\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064966; batch adversarial loss: 0.428384\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099344; batch adversarial loss: 0.466951\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108780; batch adversarial loss: 0.340456\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062478; batch adversarial loss: 0.437938\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042882; batch adversarial loss: 0.478142\n",
      "epoch 83; iter: 0; batch classifier loss: 0.142972; batch adversarial loss: 0.396066\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048235; batch adversarial loss: 0.462000\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065124; batch adversarial loss: 0.513504\n",
      "epoch 86; iter: 0; batch classifier loss: 0.063665; batch adversarial loss: 0.566378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039129; batch adversarial loss: 0.391411\n",
      "epoch 88; iter: 0; batch classifier loss: 0.083592; batch adversarial loss: 0.392247\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040552; batch adversarial loss: 0.488567\n",
      "epoch 90; iter: 0; batch classifier loss: 0.139993; batch adversarial loss: 0.430999\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062854; batch adversarial loss: 0.518734\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055323; batch adversarial loss: 0.483127\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078696; batch adversarial loss: 0.349045\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069520; batch adversarial loss: 0.460774\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074375; batch adversarial loss: 0.497471\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066573; batch adversarial loss: 0.406358\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072856; batch adversarial loss: 0.500166\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050535; batch adversarial loss: 0.439987\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066828; batch adversarial loss: 0.514680\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076386; batch adversarial loss: 0.388955\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039812; batch adversarial loss: 0.363607\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053065; batch adversarial loss: 0.447183\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066248; batch adversarial loss: 0.475929\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042315; batch adversarial loss: 0.467014\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040345; batch adversarial loss: 0.556798\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054137; batch adversarial loss: 0.469710\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052822; batch adversarial loss: 0.548318\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049520; batch adversarial loss: 0.471067\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054226; batch adversarial loss: 0.421764\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024171; batch adversarial loss: 0.389221\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051296; batch adversarial loss: 0.436276\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075219; batch adversarial loss: 0.411985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025815; batch adversarial loss: 0.447799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062982; batch adversarial loss: 0.455325\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040944; batch adversarial loss: 0.503127\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049168; batch adversarial loss: 0.412777\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033223; batch adversarial loss: 0.461183\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043538; batch adversarial loss: 0.489980\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034820; batch adversarial loss: 0.475111\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035449; batch adversarial loss: 0.454134\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036533; batch adversarial loss: 0.450334\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028633; batch adversarial loss: 0.481657\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.442506\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031164; batch adversarial loss: 0.459237\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025547; batch adversarial loss: 0.498790\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064238; batch adversarial loss: 0.476363\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044968; batch adversarial loss: 0.457542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.031410; batch adversarial loss: 0.472335\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037262; batch adversarial loss: 0.469809\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043873; batch adversarial loss: 0.514146\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041300; batch adversarial loss: 0.401420\n",
      "epoch 132; iter: 0; batch classifier loss: 0.075809; batch adversarial loss: 0.338211\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047090; batch adversarial loss: 0.441064\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032428; batch adversarial loss: 0.498124\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067617; batch adversarial loss: 0.416426\n",
      "epoch 136; iter: 0; batch classifier loss: 0.060446; batch adversarial loss: 0.543310\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.374106\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031230; batch adversarial loss: 0.388916\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050547; batch adversarial loss: 0.414610\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035136; batch adversarial loss: 0.461373\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021304; batch adversarial loss: 0.414054\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036572; batch adversarial loss: 0.455070\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021680; batch adversarial loss: 0.450470\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056117; batch adversarial loss: 0.454962\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013055; batch adversarial loss: 0.545876\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047588; batch adversarial loss: 0.550062\n",
      "epoch 147; iter: 0; batch classifier loss: 0.040176; batch adversarial loss: 0.476091\n",
      "epoch 148; iter: 0; batch classifier loss: 0.007797; batch adversarial loss: 0.495357\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013556; batch adversarial loss: 0.386191\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027945; batch adversarial loss: 0.422320\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055827; batch adversarial loss: 0.443165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025723; batch adversarial loss: 0.448838\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049629; batch adversarial loss: 0.383815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.484907\n",
      "epoch 155; iter: 0; batch classifier loss: 0.020811; batch adversarial loss: 0.407238\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021990; batch adversarial loss: 0.476947\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056544; batch adversarial loss: 0.446919\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012846; batch adversarial loss: 0.532239\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026680; batch adversarial loss: 0.451064\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030742; batch adversarial loss: 0.429760\n",
      "epoch 161; iter: 0; batch classifier loss: 0.044439; batch adversarial loss: 0.415813\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012525; batch adversarial loss: 0.427238\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034551; batch adversarial loss: 0.391215\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014377; batch adversarial loss: 0.353307\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037938; batch adversarial loss: 0.366581\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029010; batch adversarial loss: 0.463272\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033268; batch adversarial loss: 0.421707\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031759; batch adversarial loss: 0.491991\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035793; batch adversarial loss: 0.490802\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015049; batch adversarial loss: 0.464157\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019021; batch adversarial loss: 0.455636\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013749; batch adversarial loss: 0.483995\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029912; batch adversarial loss: 0.508343\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020043; batch adversarial loss: 0.493209\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019533; batch adversarial loss: 0.409101\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011305; batch adversarial loss: 0.457919\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017229; batch adversarial loss: 0.512426\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045630; batch adversarial loss: 0.447123\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017744; batch adversarial loss: 0.515310\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021851; batch adversarial loss: 0.425442\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021200; batch adversarial loss: 0.429517\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033462; batch adversarial loss: 0.403990\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010894; batch adversarial loss: 0.444823\n",
      "epoch 184; iter: 0; batch classifier loss: 0.079316; batch adversarial loss: 0.403501\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018420; batch adversarial loss: 0.462074\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021682; batch adversarial loss: 0.456406\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017772; batch adversarial loss: 0.507022\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052410; batch adversarial loss: 0.589167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.482553\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032035; batch adversarial loss: 0.379860\n",
      "epoch 191; iter: 0; batch classifier loss: 0.034373; batch adversarial loss: 0.465481\n",
      "epoch 192; iter: 0; batch classifier loss: 0.042422; batch adversarial loss: 0.434591\n",
      "epoch 193; iter: 0; batch classifier loss: 0.059150; batch adversarial loss: 0.460553\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016105; batch adversarial loss: 0.404932\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015044; batch adversarial loss: 0.411483\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017357; batch adversarial loss: 0.365246\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020591; batch adversarial loss: 0.542703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.045038; batch adversarial loss: 0.350446\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014134; batch adversarial loss: 0.347804\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682068; batch adversarial loss: 0.542438\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375911; batch adversarial loss: 0.623783\n",
      "epoch 2; iter: 0; batch classifier loss: 0.363277; batch adversarial loss: 0.563312\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374369; batch adversarial loss: 0.580654\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298911; batch adversarial loss: 0.488013\n",
      "epoch 5; iter: 0; batch classifier loss: 0.280018; batch adversarial loss: 0.537517\n",
      "epoch 6; iter: 0; batch classifier loss: 0.284151; batch adversarial loss: 0.536275\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300670; batch adversarial loss: 0.523091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276528; batch adversarial loss: 0.511032\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315649; batch adversarial loss: 0.492005\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319948; batch adversarial loss: 0.463767\n",
      "epoch 11; iter: 0; batch classifier loss: 0.217434; batch adversarial loss: 0.531683\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273152; batch adversarial loss: 0.596661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356106; batch adversarial loss: 0.517498\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222907; batch adversarial loss: 0.446376\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230637; batch adversarial loss: 0.483726\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279033; batch adversarial loss: 0.542497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273178; batch adversarial loss: 0.510058\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217190; batch adversarial loss: 0.521782\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317670; batch adversarial loss: 0.557345\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249601; batch adversarial loss: 0.467497\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298503; batch adversarial loss: 0.522210\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406424; batch adversarial loss: 0.522063\n",
      "epoch 23; iter: 0; batch classifier loss: 0.376452; batch adversarial loss: 0.477208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.372382; batch adversarial loss: 0.445236\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169245; batch adversarial loss: 0.483785\n",
      "epoch 26; iter: 0; batch classifier loss: 0.190635; batch adversarial loss: 0.375613\n",
      "epoch 27; iter: 0; batch classifier loss: 0.107210; batch adversarial loss: 0.488359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144291; batch adversarial loss: 0.396783\n",
      "epoch 29; iter: 0; batch classifier loss: 0.148099; batch adversarial loss: 0.491241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151140; batch adversarial loss: 0.546992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146173; batch adversarial loss: 0.353935\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112324; batch adversarial loss: 0.464468\n",
      "epoch 33; iter: 0; batch classifier loss: 0.102731; batch adversarial loss: 0.496150\n",
      "epoch 34; iter: 0; batch classifier loss: 0.144703; batch adversarial loss: 0.455985\n",
      "epoch 35; iter: 0; batch classifier loss: 0.111903; batch adversarial loss: 0.487958\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098933; batch adversarial loss: 0.497467\n",
      "epoch 37; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.511635\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099471; batch adversarial loss: 0.495463\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113076; batch adversarial loss: 0.471593\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094385; batch adversarial loss: 0.433498\n",
      "epoch 41; iter: 0; batch classifier loss: 0.094097; batch adversarial loss: 0.446041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.063264; batch adversarial loss: 0.568296\n",
      "epoch 43; iter: 0; batch classifier loss: 0.065477; batch adversarial loss: 0.508631\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085819; batch adversarial loss: 0.400811\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093823; batch adversarial loss: 0.493687\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098588; batch adversarial loss: 0.458619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.068301; batch adversarial loss: 0.319470\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112692; batch adversarial loss: 0.440814\n",
      "epoch 49; iter: 0; batch classifier loss: 0.057105; batch adversarial loss: 0.460695\n",
      "epoch 50; iter: 0; batch classifier loss: 0.074657; batch adversarial loss: 0.470728\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070881; batch adversarial loss: 0.440177\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096467; batch adversarial loss: 0.558248\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077390; batch adversarial loss: 0.422174\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096826; batch adversarial loss: 0.497247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077240; batch adversarial loss: 0.324249\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086096; batch adversarial loss: 0.364879\n",
      "epoch 57; iter: 0; batch classifier loss: 0.114940; batch adversarial loss: 0.525817\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059586; batch adversarial loss: 0.422193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117575; batch adversarial loss: 0.484055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.125813; batch adversarial loss: 0.437131\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055958; batch adversarial loss: 0.406098\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125372; batch adversarial loss: 0.408094\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088594; batch adversarial loss: 0.462080\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108459; batch adversarial loss: 0.533384\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061440; batch adversarial loss: 0.582187\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072277; batch adversarial loss: 0.406820\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067748; batch adversarial loss: 0.501019\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088749; batch adversarial loss: 0.467120\n",
      "epoch 69; iter: 0; batch classifier loss: 0.042182; batch adversarial loss: 0.479848\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078964; batch adversarial loss: 0.442268\n",
      "epoch 71; iter: 0; batch classifier loss: 0.132257; batch adversarial loss: 0.361857\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055909; batch adversarial loss: 0.426852\n",
      "epoch 73; iter: 0; batch classifier loss: 0.045001; batch adversarial loss: 0.419931\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096345; batch adversarial loss: 0.336411\n",
      "epoch 75; iter: 0; batch classifier loss: 0.074030; batch adversarial loss: 0.424670\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133696; batch adversarial loss: 0.437077\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083898; batch adversarial loss: 0.454916\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059451; batch adversarial loss: 0.409455\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084766; batch adversarial loss: 0.436816\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084024; batch adversarial loss: 0.443292\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082931; batch adversarial loss: 0.507660\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096663; batch adversarial loss: 0.496740\n",
      "epoch 83; iter: 0; batch classifier loss: 0.028621; batch adversarial loss: 0.432248\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062160; batch adversarial loss: 0.495274\n",
      "epoch 85; iter: 0; batch classifier loss: 0.051456; batch adversarial loss: 0.387243\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046020; batch adversarial loss: 0.403569\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066534; batch adversarial loss: 0.524117\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088896; batch adversarial loss: 0.454307\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084232; batch adversarial loss: 0.524534\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065177; batch adversarial loss: 0.374651\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039108; batch adversarial loss: 0.471937\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039202; batch adversarial loss: 0.496633\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056066; batch adversarial loss: 0.412547\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065352; batch adversarial loss: 0.468297\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085600; batch adversarial loss: 0.501833\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073771; batch adversarial loss: 0.505538\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050467; batch adversarial loss: 0.475979\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084152; batch adversarial loss: 0.387070\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054432; batch adversarial loss: 0.416688\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024006; batch adversarial loss: 0.439011\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046142; batch adversarial loss: 0.342329\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034528; batch adversarial loss: 0.425582\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078904; batch adversarial loss: 0.541646\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050636; batch adversarial loss: 0.521276\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022642; batch adversarial loss: 0.426861\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034664; batch adversarial loss: 0.391939\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032771; batch adversarial loss: 0.532590\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070884; batch adversarial loss: 0.406060\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061377; batch adversarial loss: 0.423391\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045339; batch adversarial loss: 0.418345\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053486; batch adversarial loss: 0.484637\n",
      "epoch 112; iter: 0; batch classifier loss: 0.083798; batch adversarial loss: 0.464466\n",
      "epoch 113; iter: 0; batch classifier loss: 0.090919; batch adversarial loss: 0.444582\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.446019\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076587; batch adversarial loss: 0.444085\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056434; batch adversarial loss: 0.422080\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052176; batch adversarial loss: 0.481002\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073331; batch adversarial loss: 0.479060\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069459; batch adversarial loss: 0.494226\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036135; batch adversarial loss: 0.478498\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035588; batch adversarial loss: 0.434449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.048907; batch adversarial loss: 0.450787\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041433; batch adversarial loss: 0.432925\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054556; batch adversarial loss: 0.460013\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035561; batch adversarial loss: 0.466331\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038426; batch adversarial loss: 0.435639\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030821; batch adversarial loss: 0.470204\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063137; batch adversarial loss: 0.373560\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049650; batch adversarial loss: 0.393867\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018951; batch adversarial loss: 0.492315\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019819; batch adversarial loss: 0.462524\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048922; batch adversarial loss: 0.443577\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044061; batch adversarial loss: 0.385662\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043653; batch adversarial loss: 0.443770\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062219; batch adversarial loss: 0.394477\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047611; batch adversarial loss: 0.422547\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028904; batch adversarial loss: 0.477936\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.454115\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024277; batch adversarial loss: 0.500120\n",
      "epoch 140; iter: 0; batch classifier loss: 0.019283; batch adversarial loss: 0.473347\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045748; batch adversarial loss: 0.551172\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032789; batch adversarial loss: 0.458347\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017485; batch adversarial loss: 0.478486\n",
      "epoch 144; iter: 0; batch classifier loss: 0.005315; batch adversarial loss: 0.467152\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029985; batch adversarial loss: 0.361353\n",
      "epoch 146; iter: 0; batch classifier loss: 0.061328; batch adversarial loss: 0.458466\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036869; batch adversarial loss: 0.502675\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.402030\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032075; batch adversarial loss: 0.407507\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.445558\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036682; batch adversarial loss: 0.407421\n",
      "epoch 152; iter: 0; batch classifier loss: 0.058503; batch adversarial loss: 0.454912\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007722; batch adversarial loss: 0.514653\n",
      "epoch 154; iter: 0; batch classifier loss: 0.085527; batch adversarial loss: 0.451255\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049142; batch adversarial loss: 0.501268\n",
      "epoch 156; iter: 0; batch classifier loss: 0.078584; batch adversarial loss: 0.437747\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034308; batch adversarial loss: 0.443423\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023758; batch adversarial loss: 0.508246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026911; batch adversarial loss: 0.439855\n",
      "epoch 160; iter: 0; batch classifier loss: 0.090689; batch adversarial loss: 0.504086\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034385; batch adversarial loss: 0.461353\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025538; batch adversarial loss: 0.369718\n",
      "epoch 163; iter: 0; batch classifier loss: 0.054753; batch adversarial loss: 0.409521\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.495802\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030010; batch adversarial loss: 0.341422\n",
      "epoch 166; iter: 0; batch classifier loss: 0.031653; batch adversarial loss: 0.369799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.051555; batch adversarial loss: 0.455599\n",
      "epoch 168; iter: 0; batch classifier loss: 0.071421; batch adversarial loss: 0.345453\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037849; batch adversarial loss: 0.411423\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027546; batch adversarial loss: 0.420435\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037107; batch adversarial loss: 0.520519\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.495564\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021741; batch adversarial loss: 0.372278\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009467; batch adversarial loss: 0.494763\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014633; batch adversarial loss: 0.471420\n",
      "epoch 176; iter: 0; batch classifier loss: 0.085708; batch adversarial loss: 0.393777\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036725; batch adversarial loss: 0.435509\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025904; batch adversarial loss: 0.422190\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037957; batch adversarial loss: 0.444564\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019658; batch adversarial loss: 0.412754\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011915; batch adversarial loss: 0.408988\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039225; batch adversarial loss: 0.518265\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042186; batch adversarial loss: 0.410814\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034774; batch adversarial loss: 0.393748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016041; batch adversarial loss: 0.406880\n",
      "epoch 186; iter: 0; batch classifier loss: 0.038691; batch adversarial loss: 0.417873\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019768; batch adversarial loss: 0.415069\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023278; batch adversarial loss: 0.386580\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035527; batch adversarial loss: 0.511372\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022888; batch adversarial loss: 0.420083\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042506; batch adversarial loss: 0.391720\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044304; batch adversarial loss: 0.492745\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010477; batch adversarial loss: 0.502619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025303; batch adversarial loss: 0.381107\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013029; batch adversarial loss: 0.506179\n",
      "epoch 196; iter: 0; batch classifier loss: 0.052402; batch adversarial loss: 0.481859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010360; batch adversarial loss: 0.443461\n",
      "epoch 198; iter: 0; batch classifier loss: 0.036634; batch adversarial loss: 0.398283\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020614; batch adversarial loss: 0.514562\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685827; batch adversarial loss: 0.938706\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447459; batch adversarial loss: 1.019673\n",
      "epoch 2; iter: 0; batch classifier loss: 0.385246; batch adversarial loss: 0.924706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.338275; batch adversarial loss: 0.883169\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345703; batch adversarial loss: 0.883354\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287109; batch adversarial loss: 0.716913\n",
      "epoch 6; iter: 0; batch classifier loss: 0.302462; batch adversarial loss: 0.729764\n",
      "epoch 7; iter: 0; batch classifier loss: 0.282209; batch adversarial loss: 0.677262\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298566; batch adversarial loss: 0.660493\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242718; batch adversarial loss: 0.646658\n",
      "epoch 10; iter: 0; batch classifier loss: 0.285743; batch adversarial loss: 0.627600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.289047; batch adversarial loss: 0.574980\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205644; batch adversarial loss: 0.566441\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267551; batch adversarial loss: 0.574039\n",
      "epoch 14; iter: 0; batch classifier loss: 0.178207; batch adversarial loss: 0.544148\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215275; batch adversarial loss: 0.552535\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212504; batch adversarial loss: 0.558070\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180315; batch adversarial loss: 0.481477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 0; batch classifier loss: 0.186768; batch adversarial loss: 0.503285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181694; batch adversarial loss: 0.493477\n",
      "epoch 20; iter: 0; batch classifier loss: 0.221611; batch adversarial loss: 0.450894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204463; batch adversarial loss: 0.504319\n",
      "epoch 22; iter: 0; batch classifier loss: 0.165681; batch adversarial loss: 0.476729\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191532; batch adversarial loss: 0.438506\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170919; batch adversarial loss: 0.422033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175962; batch adversarial loss: 0.409449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.173109; batch adversarial loss: 0.407373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167569; batch adversarial loss: 0.450756\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183777; batch adversarial loss: 0.473798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.193100; batch adversarial loss: 0.360213\n",
      "epoch 30; iter: 0; batch classifier loss: 0.158171; batch adversarial loss: 0.456436\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164797; batch adversarial loss: 0.547035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.193861; batch adversarial loss: 0.419957\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192678; batch adversarial loss: 0.445052\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154247; batch adversarial loss: 0.369255\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152019; batch adversarial loss: 0.464455\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161947; batch adversarial loss: 0.365896\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177542; batch adversarial loss: 0.430593\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172901; batch adversarial loss: 0.372902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175407; batch adversarial loss: 0.427050\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157919; batch adversarial loss: 0.328770\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110960; batch adversarial loss: 0.361305\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122565; batch adversarial loss: 0.377142\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123319; batch adversarial loss: 0.285838\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128718; batch adversarial loss: 0.388776\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109470; batch adversarial loss: 0.442141\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148274; batch adversarial loss: 0.424079\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117147; batch adversarial loss: 0.396030\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141816; batch adversarial loss: 0.411755\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115847; batch adversarial loss: 0.380457\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132593; batch adversarial loss: 0.375780\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109130; batch adversarial loss: 0.335939\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102030; batch adversarial loss: 0.442114\n",
      "epoch 53; iter: 0; batch classifier loss: 0.131794; batch adversarial loss: 0.374062\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106299; batch adversarial loss: 0.379753\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089649; batch adversarial loss: 0.337735\n",
      "epoch 56; iter: 0; batch classifier loss: 0.090633; batch adversarial loss: 0.372146\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104238; batch adversarial loss: 0.421420\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105869; batch adversarial loss: 0.374855\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086184; batch adversarial loss: 0.348437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.104796; batch adversarial loss: 0.392438\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093458; batch adversarial loss: 0.438089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073578; batch adversarial loss: 0.318851\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110558; batch adversarial loss: 0.451050\n",
      "epoch 64; iter: 0; batch classifier loss: 0.065267; batch adversarial loss: 0.355024\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104904; batch adversarial loss: 0.401955\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081559; batch adversarial loss: 0.431772\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110214; batch adversarial loss: 0.350346\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054367; batch adversarial loss: 0.349620\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073451; batch adversarial loss: 0.392293\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058269; batch adversarial loss: 0.414242\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064489; batch adversarial loss: 0.392714\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053977; batch adversarial loss: 0.458323\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076444; batch adversarial loss: 0.367356\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046000; batch adversarial loss: 0.321914\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070263; batch adversarial loss: 0.404820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085842; batch adversarial loss: 0.430375\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082893; batch adversarial loss: 0.291911\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071961; batch adversarial loss: 0.443655\n",
      "epoch 79; iter: 0; batch classifier loss: 0.054421; batch adversarial loss: 0.412252\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059834; batch adversarial loss: 0.420685\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068531; batch adversarial loss: 0.402720\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052469; batch adversarial loss: 0.406472\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061311; batch adversarial loss: 0.403702\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079658; batch adversarial loss: 0.440632\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056592; batch adversarial loss: 0.404389\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045184; batch adversarial loss: 0.471838\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042262; batch adversarial loss: 0.464618\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052298; batch adversarial loss: 0.455028\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044469; batch adversarial loss: 0.463003\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044222; batch adversarial loss: 0.385342\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032970; batch adversarial loss: 0.480316\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053526; batch adversarial loss: 0.385990\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053925; batch adversarial loss: 0.435583\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058225; batch adversarial loss: 0.426926\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055534; batch adversarial loss: 0.430971\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072735; batch adversarial loss: 0.324513\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068200; batch adversarial loss: 0.411947\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070616; batch adversarial loss: 0.327075\n",
      "epoch 99; iter: 0; batch classifier loss: 0.073359; batch adversarial loss: 0.495049\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059167; batch adversarial loss: 0.445774\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039230; batch adversarial loss: 0.470204\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056706; batch adversarial loss: 0.384803\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036455; batch adversarial loss: 0.463450\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040097; batch adversarial loss: 0.413821\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030238; batch adversarial loss: 0.387142\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059529; batch adversarial loss: 0.550757\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040939; batch adversarial loss: 0.376569\n",
      "epoch 108; iter: 0; batch classifier loss: 0.015821; batch adversarial loss: 0.445149\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031623; batch adversarial loss: 0.414436\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027685; batch adversarial loss: 0.450195\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062111; batch adversarial loss: 0.475151\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017964; batch adversarial loss: 0.362955\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040863; batch adversarial loss: 0.471839\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059987; batch adversarial loss: 0.418549\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045779; batch adversarial loss: 0.485953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 116; iter: 0; batch classifier loss: 0.033842; batch adversarial loss: 0.425221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046908; batch adversarial loss: 0.412405\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.421784\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022274; batch adversarial loss: 0.426409\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025351; batch adversarial loss: 0.468681\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033238; batch adversarial loss: 0.477386\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044013; batch adversarial loss: 0.370992\n",
      "epoch 123; iter: 0; batch classifier loss: 0.019032; batch adversarial loss: 0.438439\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057390; batch adversarial loss: 0.511525\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045308; batch adversarial loss: 0.471059\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038798; batch adversarial loss: 0.470716\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052976; batch adversarial loss: 0.553094\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056574; batch adversarial loss: 0.548168\n",
      "epoch 129; iter: 0; batch classifier loss: 0.080921; batch adversarial loss: 0.396501\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024458; batch adversarial loss: 0.508950\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046752; batch adversarial loss: 0.511264\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057042; batch adversarial loss: 0.504212\n",
      "epoch 133; iter: 0; batch classifier loss: 0.093192; batch adversarial loss: 0.608330\n",
      "epoch 134; iter: 0; batch classifier loss: 0.156052; batch adversarial loss: 0.634437\n",
      "epoch 135; iter: 0; batch classifier loss: 0.085730; batch adversarial loss: 0.494198\n",
      "epoch 136; iter: 0; batch classifier loss: 0.104331; batch adversarial loss: 0.480356\n",
      "epoch 137; iter: 0; batch classifier loss: 0.114747; batch adversarial loss: 0.598796\n",
      "epoch 138; iter: 0; batch classifier loss: 0.147136; batch adversarial loss: 0.602438\n",
      "epoch 139; iter: 0; batch classifier loss: 0.068509; batch adversarial loss: 0.494738\n",
      "epoch 140; iter: 0; batch classifier loss: 0.082336; batch adversarial loss: 0.522140\n",
      "epoch 141; iter: 0; batch classifier loss: 0.071456; batch adversarial loss: 0.426256\n",
      "epoch 142; iter: 0; batch classifier loss: 0.125994; batch adversarial loss: 0.524274\n",
      "epoch 143; iter: 0; batch classifier loss: 0.090932; batch adversarial loss: 0.438886\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042293; batch adversarial loss: 0.511074\n",
      "epoch 145; iter: 0; batch classifier loss: 0.114682; batch adversarial loss: 0.516630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.130438; batch adversarial loss: 0.561258\n",
      "epoch 147; iter: 0; batch classifier loss: 0.101230; batch adversarial loss: 0.535652\n",
      "epoch 148; iter: 0; batch classifier loss: 0.082535; batch adversarial loss: 0.486385\n",
      "epoch 149; iter: 0; batch classifier loss: 0.124761; batch adversarial loss: 0.516802\n",
      "epoch 150; iter: 0; batch classifier loss: 0.163934; batch adversarial loss: 0.560162\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062468; batch adversarial loss: 0.440959\n",
      "epoch 152; iter: 0; batch classifier loss: 0.080598; batch adversarial loss: 0.475712\n",
      "epoch 153; iter: 0; batch classifier loss: 0.100957; batch adversarial loss: 0.543957\n",
      "epoch 154; iter: 0; batch classifier loss: 0.070357; batch adversarial loss: 0.501360\n",
      "epoch 155; iter: 0; batch classifier loss: 0.072156; batch adversarial loss: 0.414567\n",
      "epoch 156; iter: 0; batch classifier loss: 0.108804; batch adversarial loss: 0.570285\n",
      "epoch 157; iter: 0; batch classifier loss: 0.065047; batch adversarial loss: 0.453557\n",
      "epoch 158; iter: 0; batch classifier loss: 0.110335; batch adversarial loss: 0.534868\n",
      "epoch 159; iter: 0; batch classifier loss: 0.096007; batch adversarial loss: 0.517828\n",
      "epoch 160; iter: 0; batch classifier loss: 0.085823; batch adversarial loss: 0.448550\n",
      "epoch 161; iter: 0; batch classifier loss: 0.069182; batch adversarial loss: 0.463722\n",
      "epoch 162; iter: 0; batch classifier loss: 0.090239; batch adversarial loss: 0.544247\n",
      "epoch 163; iter: 0; batch classifier loss: 0.069093; batch adversarial loss: 0.564598\n",
      "epoch 164; iter: 0; batch classifier loss: 0.097001; batch adversarial loss: 0.437652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.073059; batch adversarial loss: 0.479631\n",
      "epoch 166; iter: 0; batch classifier loss: 0.102926; batch adversarial loss: 0.518406\n",
      "epoch 167; iter: 0; batch classifier loss: 0.064394; batch adversarial loss: 0.372810\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069712; batch adversarial loss: 0.495506\n",
      "epoch 169; iter: 0; batch classifier loss: 0.107967; batch adversarial loss: 0.489573\n",
      "epoch 170; iter: 0; batch classifier loss: 0.101677; batch adversarial loss: 0.450826\n",
      "epoch 171; iter: 0; batch classifier loss: 0.078280; batch adversarial loss: 0.431983\n",
      "epoch 172; iter: 0; batch classifier loss: 0.097861; batch adversarial loss: 0.468723\n",
      "epoch 173; iter: 0; batch classifier loss: 0.066924; batch adversarial loss: 0.450529\n",
      "epoch 174; iter: 0; batch classifier loss: 0.095129; batch adversarial loss: 0.423974\n",
      "epoch 175; iter: 0; batch classifier loss: 0.066606; batch adversarial loss: 0.446437\n",
      "epoch 176; iter: 0; batch classifier loss: 0.107376; batch adversarial loss: 0.447430\n",
      "epoch 177; iter: 0; batch classifier loss: 0.062217; batch adversarial loss: 0.431949\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043253; batch adversarial loss: 0.395086\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040080; batch adversarial loss: 0.382598\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031385; batch adversarial loss: 0.405917\n",
      "epoch 181; iter: 0; batch classifier loss: 0.048503; batch adversarial loss: 0.446086\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023916; batch adversarial loss: 0.515751\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046469; batch adversarial loss: 0.496237\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057623; batch adversarial loss: 0.453404\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049563; batch adversarial loss: 0.467371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017350; batch adversarial loss: 0.407946\n",
      "epoch 187; iter: 0; batch classifier loss: 0.057540; batch adversarial loss: 0.378283\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045744; batch adversarial loss: 0.493663\n",
      "epoch 189; iter: 0; batch classifier loss: 0.065836; batch adversarial loss: 0.400376\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046487; batch adversarial loss: 0.532887\n",
      "epoch 191; iter: 0; batch classifier loss: 0.068558; batch adversarial loss: 0.361282\n",
      "epoch 192; iter: 0; batch classifier loss: 0.046340; batch adversarial loss: 0.419437\n",
      "epoch 193; iter: 0; batch classifier loss: 0.052760; batch adversarial loss: 0.390068\n",
      "epoch 194; iter: 0; batch classifier loss: 0.054504; batch adversarial loss: 0.399943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.087629; batch adversarial loss: 0.436694\n",
      "epoch 196; iter: 0; batch classifier loss: 0.069604; batch adversarial loss: 0.437796\n",
      "epoch 197; iter: 0; batch classifier loss: 0.075461; batch adversarial loss: 0.369194\n",
      "epoch 198; iter: 0; batch classifier loss: 0.063113; batch adversarial loss: 0.508798\n",
      "epoch 199; iter: 0; batch classifier loss: 0.048317; batch adversarial loss: 0.464707\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724420; batch adversarial loss: 0.889330\n",
      "epoch 1; iter: 0; batch classifier loss: 0.337691; batch adversarial loss: 0.911395\n",
      "epoch 2; iter: 0; batch classifier loss: 0.369336; batch adversarial loss: 0.930485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.329108; batch adversarial loss: 0.768311\n",
      "epoch 4; iter: 0; batch classifier loss: 0.285492; batch adversarial loss: 0.770418\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311076; batch adversarial loss: 0.700099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.334233; batch adversarial loss: 0.719077\n",
      "epoch 7; iter: 0; batch classifier loss: 0.270721; batch adversarial loss: 0.662140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307743; batch adversarial loss: 0.665040\n",
      "epoch 9; iter: 0; batch classifier loss: 0.239019; batch adversarial loss: 0.662822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302245; batch adversarial loss: 0.559794\n",
      "epoch 11; iter: 0; batch classifier loss: 0.290539; batch adversarial loss: 0.612147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 0; batch classifier loss: 0.256173; batch adversarial loss: 0.549742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248560; batch adversarial loss: 0.489387\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282275; batch adversarial loss: 0.538507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.265798; batch adversarial loss: 0.495588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195091; batch adversarial loss: 0.548070\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213612; batch adversarial loss: 0.471963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.204691; batch adversarial loss: 0.457559\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172697; batch adversarial loss: 0.438009\n",
      "epoch 20; iter: 0; batch classifier loss: 0.177919; batch adversarial loss: 0.439127\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197510; batch adversarial loss: 0.469167\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167842; batch adversarial loss: 0.447997\n",
      "epoch 23; iter: 0; batch classifier loss: 0.208956; batch adversarial loss: 0.459794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.235943; batch adversarial loss: 0.379217\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204326; batch adversarial loss: 0.448726\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204069; batch adversarial loss: 0.347780\n",
      "epoch 27; iter: 0; batch classifier loss: 0.140386; batch adversarial loss: 0.450932\n",
      "epoch 28; iter: 0; batch classifier loss: 0.154850; batch adversarial loss: 0.344926\n",
      "epoch 29; iter: 0; batch classifier loss: 0.158687; batch adversarial loss: 0.445884\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172604; batch adversarial loss: 0.423509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182072; batch adversarial loss: 0.482902\n",
      "epoch 32; iter: 0; batch classifier loss: 0.190994; batch adversarial loss: 0.423532\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142196; batch adversarial loss: 0.450082\n",
      "epoch 34; iter: 0; batch classifier loss: 0.141955; batch adversarial loss: 0.407140\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132738; batch adversarial loss: 0.467138\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095669; batch adversarial loss: 0.415796\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141778; batch adversarial loss: 0.443883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.171043; batch adversarial loss: 0.372060\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174016; batch adversarial loss: 0.360850\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105160; batch adversarial loss: 0.450883\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129107; batch adversarial loss: 0.337549\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106335; batch adversarial loss: 0.356737\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087603; batch adversarial loss: 0.350249\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105970; batch adversarial loss: 0.430423\n",
      "epoch 45; iter: 0; batch classifier loss: 0.161723; batch adversarial loss: 0.352544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.136497; batch adversarial loss: 0.440530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100691; batch adversarial loss: 0.372578\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099358; batch adversarial loss: 0.438740\n",
      "epoch 49; iter: 0; batch classifier loss: 0.085280; batch adversarial loss: 0.444341\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069547; batch adversarial loss: 0.460307\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099929; batch adversarial loss: 0.373681\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115185; batch adversarial loss: 0.449597\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106108; batch adversarial loss: 0.311340\n",
      "epoch 54; iter: 0; batch classifier loss: 0.093600; batch adversarial loss: 0.430239\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091809; batch adversarial loss: 0.413937\n",
      "epoch 56; iter: 0; batch classifier loss: 0.099801; batch adversarial loss: 0.445049\n",
      "epoch 57; iter: 0; batch classifier loss: 0.074793; batch adversarial loss: 0.441300\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097618; batch adversarial loss: 0.458488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105037; batch adversarial loss: 0.444093\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106402; batch adversarial loss: 0.488290\n",
      "epoch 61; iter: 0; batch classifier loss: 0.123886; batch adversarial loss: 0.348278\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078050; batch adversarial loss: 0.342489\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083579; batch adversarial loss: 0.367006\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096948; batch adversarial loss: 0.331122\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110770; batch adversarial loss: 0.376314\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087756; batch adversarial loss: 0.433712\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080130; batch adversarial loss: 0.444843\n",
      "epoch 68; iter: 0; batch classifier loss: 0.051398; batch adversarial loss: 0.467592\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096094; batch adversarial loss: 0.387668\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066399; batch adversarial loss: 0.519881\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049807; batch adversarial loss: 0.423802\n",
      "epoch 72; iter: 0; batch classifier loss: 0.039724; batch adversarial loss: 0.469580\n",
      "epoch 73; iter: 0; batch classifier loss: 0.054785; batch adversarial loss: 0.424223\n",
      "epoch 74; iter: 0; batch classifier loss: 0.044982; batch adversarial loss: 0.369903\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085842; batch adversarial loss: 0.414128\n",
      "epoch 76; iter: 0; batch classifier loss: 0.118531; batch adversarial loss: 0.397081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067037; batch adversarial loss: 0.382283\n",
      "epoch 78; iter: 0; batch classifier loss: 0.051172; batch adversarial loss: 0.415497\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070376; batch adversarial loss: 0.442349\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065400; batch adversarial loss: 0.535433\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081740; batch adversarial loss: 0.438995\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075868; batch adversarial loss: 0.388621\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054750; batch adversarial loss: 0.487104\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046108; batch adversarial loss: 0.468664\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074324; batch adversarial loss: 0.494169\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064134; batch adversarial loss: 0.429654\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056847; batch adversarial loss: 0.398232\n",
      "epoch 88; iter: 0; batch classifier loss: 0.032000; batch adversarial loss: 0.354833\n",
      "epoch 89; iter: 0; batch classifier loss: 0.044836; batch adversarial loss: 0.440686\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037779; batch adversarial loss: 0.521499\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083059; batch adversarial loss: 0.526589\n",
      "epoch 92; iter: 0; batch classifier loss: 0.038704; batch adversarial loss: 0.517719\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037654; batch adversarial loss: 0.529724\n",
      "epoch 94; iter: 0; batch classifier loss: 0.030539; batch adversarial loss: 0.459922\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056362; batch adversarial loss: 0.403128\n",
      "epoch 96; iter: 0; batch classifier loss: 0.017584; batch adversarial loss: 0.372886\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041838; batch adversarial loss: 0.386057\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.380936\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076453; batch adversarial loss: 0.435771\n",
      "epoch 100; iter: 0; batch classifier loss: 0.029644; batch adversarial loss: 0.391474\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039670; batch adversarial loss: 0.582088\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069152; batch adversarial loss: 0.428171\n",
      "epoch 103; iter: 0; batch classifier loss: 0.031752; batch adversarial loss: 0.461284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.027553; batch adversarial loss: 0.407844\n",
      "epoch 105; iter: 0; batch classifier loss: 0.101405; batch adversarial loss: 0.451924\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041628; batch adversarial loss: 0.419676\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080134; batch adversarial loss: 0.593919\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028776; batch adversarial loss: 0.527144\n",
      "epoch 109; iter: 0; batch classifier loss: 0.086321; batch adversarial loss: 0.554171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110; iter: 0; batch classifier loss: 0.114726; batch adversarial loss: 0.588251\n",
      "epoch 111; iter: 0; batch classifier loss: 0.119024; batch adversarial loss: 0.566162\n",
      "epoch 112; iter: 0; batch classifier loss: 0.153297; batch adversarial loss: 0.630312\n",
      "epoch 113; iter: 0; batch classifier loss: 0.103375; batch adversarial loss: 0.590519\n",
      "epoch 114; iter: 0; batch classifier loss: 0.120852; batch adversarial loss: 0.598472\n",
      "epoch 115; iter: 0; batch classifier loss: 0.198511; batch adversarial loss: 0.730958\n",
      "epoch 116; iter: 0; batch classifier loss: 0.184068; batch adversarial loss: 0.635433\n",
      "epoch 117; iter: 0; batch classifier loss: 0.149709; batch adversarial loss: 0.575435\n",
      "epoch 118; iter: 0; batch classifier loss: 0.088542; batch adversarial loss: 0.384678\n",
      "epoch 119; iter: 0; batch classifier loss: 0.117390; batch adversarial loss: 0.568107\n",
      "epoch 120; iter: 0; batch classifier loss: 0.141975; batch adversarial loss: 0.592183\n",
      "epoch 121; iter: 0; batch classifier loss: 0.140716; batch adversarial loss: 0.590864\n",
      "epoch 122; iter: 0; batch classifier loss: 0.137237; batch adversarial loss: 0.582555\n",
      "epoch 123; iter: 0; batch classifier loss: 0.161102; batch adversarial loss: 0.651289\n",
      "epoch 124; iter: 0; batch classifier loss: 0.147435; batch adversarial loss: 0.633670\n",
      "epoch 125; iter: 0; batch classifier loss: 0.093732; batch adversarial loss: 0.448908\n",
      "epoch 126; iter: 0; batch classifier loss: 0.125336; batch adversarial loss: 0.597434\n",
      "epoch 127; iter: 0; batch classifier loss: 0.166952; batch adversarial loss: 0.623634\n",
      "epoch 128; iter: 0; batch classifier loss: 0.185783; batch adversarial loss: 0.692029\n",
      "epoch 129; iter: 0; batch classifier loss: 0.130986; batch adversarial loss: 0.492788\n",
      "epoch 130; iter: 0; batch classifier loss: 0.111187; batch adversarial loss: 0.518618\n",
      "epoch 131; iter: 0; batch classifier loss: 0.139206; batch adversarial loss: 0.492682\n",
      "epoch 132; iter: 0; batch classifier loss: 0.090465; batch adversarial loss: 0.543131\n",
      "epoch 133; iter: 0; batch classifier loss: 0.093698; batch adversarial loss: 0.452139\n",
      "epoch 134; iter: 0; batch classifier loss: 0.142974; batch adversarial loss: 0.493261\n",
      "epoch 135; iter: 0; batch classifier loss: 0.121836; batch adversarial loss: 0.508710\n",
      "epoch 136; iter: 0; batch classifier loss: 0.114310; batch adversarial loss: 0.550491\n",
      "epoch 137; iter: 0; batch classifier loss: 0.127616; batch adversarial loss: 0.515211\n",
      "epoch 138; iter: 0; batch classifier loss: 0.138009; batch adversarial loss: 0.501114\n",
      "epoch 139; iter: 0; batch classifier loss: 0.106830; batch adversarial loss: 0.511833\n",
      "epoch 140; iter: 0; batch classifier loss: 0.160354; batch adversarial loss: 0.445015\n",
      "epoch 141; iter: 0; batch classifier loss: 0.135323; batch adversarial loss: 0.556132\n",
      "epoch 142; iter: 0; batch classifier loss: 0.119672; batch adversarial loss: 0.547081\n",
      "epoch 143; iter: 0; batch classifier loss: 0.109586; batch adversarial loss: 0.446394\n",
      "epoch 144; iter: 0; batch classifier loss: 0.091180; batch adversarial loss: 0.442709\n",
      "epoch 145; iter: 0; batch classifier loss: 0.125787; batch adversarial loss: 0.501274\n",
      "epoch 146; iter: 0; batch classifier loss: 0.105655; batch adversarial loss: 0.524513\n",
      "epoch 147; iter: 0; batch classifier loss: 0.121389; batch adversarial loss: 0.493220\n",
      "epoch 148; iter: 0; batch classifier loss: 0.109966; batch adversarial loss: 0.457749\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040331; batch adversarial loss: 0.396943\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.386290\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042781; batch adversarial loss: 0.503735\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025159; batch adversarial loss: 0.495676\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027463; batch adversarial loss: 0.462527\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030045; batch adversarial loss: 0.419403\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049647; batch adversarial loss: 0.476075\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035041; batch adversarial loss: 0.505250\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019407; batch adversarial loss: 0.500065\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048583; batch adversarial loss: 0.498454\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039730; batch adversarial loss: 0.401125\n",
      "epoch 160; iter: 0; batch classifier loss: 0.034487; batch adversarial loss: 0.341512\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030375; batch adversarial loss: 0.367303\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043243; batch adversarial loss: 0.511209\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025060; batch adversarial loss: 0.395718\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044311; batch adversarial loss: 0.430787\n",
      "epoch 165; iter: 0; batch classifier loss: 0.082264; batch adversarial loss: 0.413431\n",
      "epoch 166; iter: 0; batch classifier loss: 0.083332; batch adversarial loss: 0.492489\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031001; batch adversarial loss: 0.472911\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049637; batch adversarial loss: 0.455232\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035755; batch adversarial loss: 0.356223\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048615; batch adversarial loss: 0.512263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.067725; batch adversarial loss: 0.438093\n",
      "epoch 172; iter: 0; batch classifier loss: 0.070192; batch adversarial loss: 0.423377\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065010; batch adversarial loss: 0.332426\n",
      "epoch 174; iter: 0; batch classifier loss: 0.049249; batch adversarial loss: 0.450842\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058364; batch adversarial loss: 0.421277\n",
      "epoch 176; iter: 0; batch classifier loss: 0.056907; batch adversarial loss: 0.472972\n",
      "epoch 177; iter: 0; batch classifier loss: 0.045661; batch adversarial loss: 0.507685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048938; batch adversarial loss: 0.596876\n",
      "epoch 179; iter: 0; batch classifier loss: 0.110084; batch adversarial loss: 0.337826\n",
      "epoch 180; iter: 0; batch classifier loss: 0.071165; batch adversarial loss: 0.557681\n",
      "epoch 181; iter: 0; batch classifier loss: 0.079771; batch adversarial loss: 0.374855\n",
      "epoch 182; iter: 0; batch classifier loss: 0.095697; batch adversarial loss: 0.462811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041386; batch adversarial loss: 0.406532\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057895; batch adversarial loss: 0.459241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037211; batch adversarial loss: 0.428903\n",
      "epoch 186; iter: 0; batch classifier loss: 0.050232; batch adversarial loss: 0.431598\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029002; batch adversarial loss: 0.424423\n",
      "epoch 188; iter: 0; batch classifier loss: 0.057456; batch adversarial loss: 0.451716\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031020; batch adversarial loss: 0.498020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.060087; batch adversarial loss: 0.416577\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038448; batch adversarial loss: 0.545874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051438; batch adversarial loss: 0.560258\n",
      "epoch 193; iter: 0; batch classifier loss: 0.056731; batch adversarial loss: 0.471644\n",
      "epoch 194; iter: 0; batch classifier loss: 0.038745; batch adversarial loss: 0.438811\n",
      "epoch 195; iter: 0; batch classifier loss: 0.130903; batch adversarial loss: 0.474309\n",
      "epoch 196; iter: 0; batch classifier loss: 0.084454; batch adversarial loss: 0.488030\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010093; batch adversarial loss: 0.475540\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038644; batch adversarial loss: 0.402145\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052604; batch adversarial loss: 0.416021\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706247; batch adversarial loss: 0.715798\n",
      "epoch 1; iter: 0; batch classifier loss: 0.457974; batch adversarial loss: 0.666130\n",
      "epoch 2; iter: 0; batch classifier loss: 0.435737; batch adversarial loss: 0.643815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.407286; batch adversarial loss: 0.609765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382646; batch adversarial loss: 0.582536\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460875; batch adversarial loss: 0.595719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.445573; batch adversarial loss: 0.565569\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460539; batch adversarial loss: 0.550352\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483066; batch adversarial loss: 0.568187\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426352; batch adversarial loss: 0.544097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415733; batch adversarial loss: 0.537657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.433837; batch adversarial loss: 0.569852\n",
      "epoch 12; iter: 0; batch classifier loss: 0.443885; batch adversarial loss: 0.499099\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420505; batch adversarial loss: 0.507753\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302437; batch adversarial loss: 0.496394\n",
      "epoch 15; iter: 0; batch classifier loss: 0.352943; batch adversarial loss: 0.487418\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319878; batch adversarial loss: 0.462475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369508; batch adversarial loss: 0.518089\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274086; batch adversarial loss: 0.535421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308470; batch adversarial loss: 0.482481\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269395; batch adversarial loss: 0.485520\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263856; batch adversarial loss: 0.494006\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277235; batch adversarial loss: 0.476342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318733; batch adversarial loss: 0.445774\n",
      "epoch 24; iter: 0; batch classifier loss: 0.238684; batch adversarial loss: 0.462950\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187841; batch adversarial loss: 0.497158\n",
      "epoch 26; iter: 0; batch classifier loss: 0.203894; batch adversarial loss: 0.480519\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247947; batch adversarial loss: 0.424335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221934; batch adversarial loss: 0.398559\n",
      "epoch 29; iter: 0; batch classifier loss: 0.219402; batch adversarial loss: 0.480480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195445; batch adversarial loss: 0.430556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169742; batch adversarial loss: 0.525084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201778; batch adversarial loss: 0.395070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.177925; batch adversarial loss: 0.415199\n",
      "epoch 34; iter: 0; batch classifier loss: 0.114332; batch adversarial loss: 0.480041\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171541; batch adversarial loss: 0.482811\n",
      "epoch 36; iter: 0; batch classifier loss: 0.189161; batch adversarial loss: 0.468926\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198559; batch adversarial loss: 0.386025\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219784; batch adversarial loss: 0.503684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187522; batch adversarial loss: 0.463441\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169491; batch adversarial loss: 0.526502\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156231; batch adversarial loss: 0.435166\n",
      "epoch 42; iter: 0; batch classifier loss: 0.133813; batch adversarial loss: 0.469480\n",
      "epoch 43; iter: 0; batch classifier loss: 0.141746; batch adversarial loss: 0.448725\n",
      "epoch 44; iter: 0; batch classifier loss: 0.105212; batch adversarial loss: 0.422950\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086947; batch adversarial loss: 0.528955\n",
      "epoch 46; iter: 0; batch classifier loss: 0.141208; batch adversarial loss: 0.438821\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113061; batch adversarial loss: 0.387929\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119184; batch adversarial loss: 0.388005\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136537; batch adversarial loss: 0.478761\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123128; batch adversarial loss: 0.338870\n",
      "epoch 51; iter: 0; batch classifier loss: 0.111501; batch adversarial loss: 0.451490\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088897; batch adversarial loss: 0.441122\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086278; batch adversarial loss: 0.451339\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063169; batch adversarial loss: 0.433289\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098346; batch adversarial loss: 0.451454\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142712; batch adversarial loss: 0.436963\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093243; batch adversarial loss: 0.468109\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070166; batch adversarial loss: 0.465850\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060581; batch adversarial loss: 0.508178\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074693; batch adversarial loss: 0.378968\n",
      "epoch 61; iter: 0; batch classifier loss: 0.088081; batch adversarial loss: 0.496616\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075952; batch adversarial loss: 0.393477\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051834; batch adversarial loss: 0.586698\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076353; batch adversarial loss: 0.505830\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118525; batch adversarial loss: 0.402247\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073371; batch adversarial loss: 0.388285\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110588; batch adversarial loss: 0.441339\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064985; batch adversarial loss: 0.550978\n",
      "epoch 69; iter: 0; batch classifier loss: 0.054767; batch adversarial loss: 0.394602\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065282; batch adversarial loss: 0.392446\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089553; batch adversarial loss: 0.461332\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064528; batch adversarial loss: 0.520408\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069349; batch adversarial loss: 0.375290\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063096; batch adversarial loss: 0.425967\n",
      "epoch 75; iter: 0; batch classifier loss: 0.032563; batch adversarial loss: 0.441457\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067782; batch adversarial loss: 0.557716\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077733; batch adversarial loss: 0.501032\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067142; batch adversarial loss: 0.469695\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049174; batch adversarial loss: 0.547256\n",
      "epoch 80; iter: 0; batch classifier loss: 0.037637; batch adversarial loss: 0.430758\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067800; batch adversarial loss: 0.438319\n",
      "epoch 82; iter: 0; batch classifier loss: 0.032360; batch adversarial loss: 0.461076\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079718; batch adversarial loss: 0.377358\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055103; batch adversarial loss: 0.415625\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.404857\n",
      "epoch 86; iter: 0; batch classifier loss: 0.023640; batch adversarial loss: 0.556881\n",
      "epoch 87; iter: 0; batch classifier loss: 0.038858; batch adversarial loss: 0.427841\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038187; batch adversarial loss: 0.399929\n",
      "epoch 89; iter: 0; batch classifier loss: 0.029229; batch adversarial loss: 0.425119\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056225; batch adversarial loss: 0.349952\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078572; batch adversarial loss: 0.457471\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079601; batch adversarial loss: 0.394503\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094346; batch adversarial loss: 0.472149\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043874; batch adversarial loss: 0.317165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043277; batch adversarial loss: 0.379335\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043593; batch adversarial loss: 0.478812\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069858; batch adversarial loss: 0.448792\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040663; batch adversarial loss: 0.496325\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057004; batch adversarial loss: 0.485255\n",
      "epoch 100; iter: 0; batch classifier loss: 0.027459; batch adversarial loss: 0.477252\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031119; batch adversarial loss: 0.345745\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035112; batch adversarial loss: 0.438542\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057921; batch adversarial loss: 0.424255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.045554; batch adversarial loss: 0.421115\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045021; batch adversarial loss: 0.489960\n",
      "epoch 106; iter: 0; batch classifier loss: 0.038583; batch adversarial loss: 0.415280\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075144; batch adversarial loss: 0.511334\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043909; batch adversarial loss: 0.459920\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077389; batch adversarial loss: 0.552402\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026347; batch adversarial loss: 0.534958\n",
      "epoch 111; iter: 0; batch classifier loss: 0.017385; batch adversarial loss: 0.495566\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027412; batch adversarial loss: 0.420501\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031532; batch adversarial loss: 0.526589\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023696; batch adversarial loss: 0.389538\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047735; batch adversarial loss: 0.367922\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021870; batch adversarial loss: 0.362829\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055143; batch adversarial loss: 0.395411\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061673; batch adversarial loss: 0.488234\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026972; batch adversarial loss: 0.424403\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053134; batch adversarial loss: 0.520173\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043842; batch adversarial loss: 0.406145\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054705; batch adversarial loss: 0.546436\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046956; batch adversarial loss: 0.490184\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041176; batch adversarial loss: 0.490397\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054538; batch adversarial loss: 0.451880\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057102; batch adversarial loss: 0.493896\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022291; batch adversarial loss: 0.422369\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023904; batch adversarial loss: 0.512709\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044983; batch adversarial loss: 0.372575\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019392; batch adversarial loss: 0.370222\n",
      "epoch 131; iter: 0; batch classifier loss: 0.016645; batch adversarial loss: 0.363694\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058996; batch adversarial loss: 0.460660\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021590; batch adversarial loss: 0.467736\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.366765\n",
      "epoch 135; iter: 0; batch classifier loss: 0.062832; batch adversarial loss: 0.393705\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032403; batch adversarial loss: 0.496850\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047668; batch adversarial loss: 0.463446\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040205; batch adversarial loss: 0.507918\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056561; batch adversarial loss: 0.448649\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025676; batch adversarial loss: 0.452044\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031798; batch adversarial loss: 0.423884\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035994; batch adversarial loss: 0.488352\n",
      "epoch 143; iter: 0; batch classifier loss: 0.007398; batch adversarial loss: 0.458839\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022302; batch adversarial loss: 0.505390\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021508; batch adversarial loss: 0.394969\n",
      "epoch 146; iter: 0; batch classifier loss: 0.041332; batch adversarial loss: 0.534104\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039513; batch adversarial loss: 0.380697\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041989; batch adversarial loss: 0.380730\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005021; batch adversarial loss: 0.463073\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023597; batch adversarial loss: 0.468601\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027791; batch adversarial loss: 0.460566\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031328; batch adversarial loss: 0.395909\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042312; batch adversarial loss: 0.381580\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038999; batch adversarial loss: 0.443756\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037058; batch adversarial loss: 0.580908\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016710; batch adversarial loss: 0.386012\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023463; batch adversarial loss: 0.506377\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016146; batch adversarial loss: 0.489373\n",
      "epoch 159; iter: 0; batch classifier loss: 0.015143; batch adversarial loss: 0.490387\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009005; batch adversarial loss: 0.545105\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026842; batch adversarial loss: 0.398575\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039210; batch adversarial loss: 0.386512\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046788; batch adversarial loss: 0.432239\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020880; batch adversarial loss: 0.455605\n",
      "epoch 165; iter: 0; batch classifier loss: 0.035711; batch adversarial loss: 0.442084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014867; batch adversarial loss: 0.463050\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013986; batch adversarial loss: 0.396065\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014360; batch adversarial loss: 0.413795\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015978; batch adversarial loss: 0.450235\n",
      "epoch 170; iter: 0; batch classifier loss: 0.010400; batch adversarial loss: 0.410457\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015577; batch adversarial loss: 0.400582\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012765; batch adversarial loss: 0.415761\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007145; batch adversarial loss: 0.475594\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044451; batch adversarial loss: 0.393870\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017060; batch adversarial loss: 0.412502\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013860; batch adversarial loss: 0.510059\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011996; batch adversarial loss: 0.507363\n",
      "epoch 178; iter: 0; batch classifier loss: 0.048482; batch adversarial loss: 0.376159\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017745; batch adversarial loss: 0.430771\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032278; batch adversarial loss: 0.423567\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023177; batch adversarial loss: 0.423349\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005560; batch adversarial loss: 0.428564\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009643; batch adversarial loss: 0.411879\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042161; batch adversarial loss: 0.596003\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031419; batch adversarial loss: 0.450974\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033413; batch adversarial loss: 0.409814\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010294; batch adversarial loss: 0.511276\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025160; batch adversarial loss: 0.434018\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007133; batch adversarial loss: 0.486697\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025080; batch adversarial loss: 0.521534\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009650; batch adversarial loss: 0.452880\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029780; batch adversarial loss: 0.353778\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019862; batch adversarial loss: 0.440068\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016750; batch adversarial loss: 0.410425\n",
      "epoch 195; iter: 0; batch classifier loss: 0.040549; batch adversarial loss: 0.398216\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014049; batch adversarial loss: 0.408037\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009123; batch adversarial loss: 0.350579\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018153; batch adversarial loss: 0.538936\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019278; batch adversarial loss: 0.476272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.687677; batch adversarial loss: 0.702482\n",
      "epoch 1; iter: 0; batch classifier loss: 0.394553; batch adversarial loss: 0.665859\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.623069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339148; batch adversarial loss: 0.603236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351402; batch adversarial loss: 0.570380\n",
      "epoch 5; iter: 0; batch classifier loss: 0.401899; batch adversarial loss: 0.596210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.415229; batch adversarial loss: 0.579847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377081; batch adversarial loss: 0.551406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474274; batch adversarial loss: 0.567496\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524189; batch adversarial loss: 0.513819\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555808; batch adversarial loss: 0.493551\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413850; batch adversarial loss: 0.520274\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457741; batch adversarial loss: 0.492937\n",
      "epoch 13; iter: 0; batch classifier loss: 0.332043; batch adversarial loss: 0.451243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410643; batch adversarial loss: 0.516321\n",
      "epoch 15; iter: 0; batch classifier loss: 0.423321; batch adversarial loss: 0.470139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414918; batch adversarial loss: 0.474922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.305167; batch adversarial loss: 0.500379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332044; batch adversarial loss: 0.499092\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328459; batch adversarial loss: 0.428016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305824; batch adversarial loss: 0.472737\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285759; batch adversarial loss: 0.534034\n",
      "epoch 22; iter: 0; batch classifier loss: 0.247505; batch adversarial loss: 0.518558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275605; batch adversarial loss: 0.448027\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302777; batch adversarial loss: 0.466189\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262592; batch adversarial loss: 0.512967\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187244; batch adversarial loss: 0.459845\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315773; batch adversarial loss: 0.421757\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211218; batch adversarial loss: 0.431045\n",
      "epoch 29; iter: 0; batch classifier loss: 0.317952; batch adversarial loss: 0.490963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285421; batch adversarial loss: 0.484696\n",
      "epoch 31; iter: 0; batch classifier loss: 0.211259; batch adversarial loss: 0.480827\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222446; batch adversarial loss: 0.449386\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332855; batch adversarial loss: 0.372765\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241370; batch adversarial loss: 0.424672\n",
      "epoch 35; iter: 0; batch classifier loss: 0.223640; batch adversarial loss: 0.520968\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283578; batch adversarial loss: 0.435435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.249312; batch adversarial loss: 0.489871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262769; batch adversarial loss: 0.523171\n",
      "epoch 39; iter: 0; batch classifier loss: 0.205032; batch adversarial loss: 0.478877\n",
      "epoch 40; iter: 0; batch classifier loss: 0.313071; batch adversarial loss: 0.544424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293901; batch adversarial loss: 0.388937\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196284; batch adversarial loss: 0.520728\n",
      "epoch 43; iter: 0; batch classifier loss: 0.271722; batch adversarial loss: 0.506070\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259730; batch adversarial loss: 0.398770\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194425; batch adversarial loss: 0.508770\n",
      "epoch 46; iter: 0; batch classifier loss: 0.235942; batch adversarial loss: 0.551980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.292284; batch adversarial loss: 0.492838\n",
      "epoch 48; iter: 0; batch classifier loss: 0.212266; batch adversarial loss: 0.492954\n",
      "epoch 49; iter: 0; batch classifier loss: 0.223974; batch adversarial loss: 0.409731\n",
      "epoch 50; iter: 0; batch classifier loss: 0.207000; batch adversarial loss: 0.494535\n",
      "epoch 51; iter: 0; batch classifier loss: 0.288393; batch adversarial loss: 0.472723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195443; batch adversarial loss: 0.519053\n",
      "epoch 53; iter: 0; batch classifier loss: 0.242995; batch adversarial loss: 0.447992\n",
      "epoch 54; iter: 0; batch classifier loss: 0.185081; batch adversarial loss: 0.530715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.183934; batch adversarial loss: 0.434602\n",
      "epoch 56; iter: 0; batch classifier loss: 0.182135; batch adversarial loss: 0.445665\n",
      "epoch 57; iter: 0; batch classifier loss: 0.208018; batch adversarial loss: 0.505758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.259391; batch adversarial loss: 0.398400\n",
      "epoch 59; iter: 0; batch classifier loss: 0.120121; batch adversarial loss: 0.606965\n",
      "epoch 60; iter: 0; batch classifier loss: 0.145646; batch adversarial loss: 0.422519\n",
      "epoch 61; iter: 0; batch classifier loss: 0.230874; batch adversarial loss: 0.410383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.211874; batch adversarial loss: 0.372823\n",
      "epoch 63; iter: 0; batch classifier loss: 0.237341; batch adversarial loss: 0.409553\n",
      "epoch 64; iter: 0; batch classifier loss: 0.255065; batch adversarial loss: 0.507902\n",
      "epoch 65; iter: 0; batch classifier loss: 0.168129; batch adversarial loss: 0.422267\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133313; batch adversarial loss: 0.420049\n",
      "epoch 67; iter: 0; batch classifier loss: 0.152053; batch adversarial loss: 0.471515\n",
      "epoch 68; iter: 0; batch classifier loss: 0.238192; batch adversarial loss: 0.485702\n",
      "epoch 69; iter: 0; batch classifier loss: 0.174600; batch adversarial loss: 0.497343\n",
      "epoch 70; iter: 0; batch classifier loss: 0.215773; batch adversarial loss: 0.432153\n",
      "epoch 71; iter: 0; batch classifier loss: 0.256584; batch adversarial loss: 0.407525\n",
      "epoch 72; iter: 0; batch classifier loss: 0.209905; batch adversarial loss: 0.435743\n",
      "epoch 73; iter: 0; batch classifier loss: 0.253999; batch adversarial loss: 0.410107\n",
      "epoch 74; iter: 0; batch classifier loss: 0.196985; batch adversarial loss: 0.519946\n",
      "epoch 75; iter: 0; batch classifier loss: 0.284122; batch adversarial loss: 0.387013\n",
      "epoch 76; iter: 0; batch classifier loss: 0.130452; batch adversarial loss: 0.507630\n",
      "epoch 77; iter: 0; batch classifier loss: 0.147833; batch adversarial loss: 0.482878\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158136; batch adversarial loss: 0.556344\n",
      "epoch 79; iter: 0; batch classifier loss: 0.220699; batch adversarial loss: 0.520827\n",
      "epoch 80; iter: 0; batch classifier loss: 0.202584; batch adversarial loss: 0.470467\n",
      "epoch 81; iter: 0; batch classifier loss: 0.222601; batch adversarial loss: 0.508275\n",
      "epoch 82; iter: 0; batch classifier loss: 0.216373; batch adversarial loss: 0.531412\n",
      "epoch 83; iter: 0; batch classifier loss: 0.240146; batch adversarial loss: 0.336066\n",
      "epoch 84; iter: 0; batch classifier loss: 0.150205; batch adversarial loss: 0.459413\n",
      "epoch 85; iter: 0; batch classifier loss: 0.224372; batch adversarial loss: 0.485024\n",
      "epoch 86; iter: 0; batch classifier loss: 0.241616; batch adversarial loss: 0.458649\n",
      "epoch 87; iter: 0; batch classifier loss: 0.194602; batch adversarial loss: 0.408733\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078031; batch adversarial loss: 0.508543\n",
      "epoch 89; iter: 0; batch classifier loss: 0.270415; batch adversarial loss: 0.384915\n",
      "epoch 90; iter: 0; batch classifier loss: 0.292066; batch adversarial loss: 0.410266\n",
      "epoch 91; iter: 0; batch classifier loss: 0.113716; batch adversarial loss: 0.508232\n",
      "epoch 92; iter: 0; batch classifier loss: 0.221330; batch adversarial loss: 0.445866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.229544; batch adversarial loss: 0.472209\n",
      "epoch 94; iter: 0; batch classifier loss: 0.293886; batch adversarial loss: 0.434470\n",
      "epoch 95; iter: 0; batch classifier loss: 0.195248; batch adversarial loss: 0.533326\n",
      "epoch 96; iter: 0; batch classifier loss: 0.186037; batch adversarial loss: 0.422514\n",
      "epoch 97; iter: 0; batch classifier loss: 0.182973; batch adversarial loss: 0.470378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.173877; batch adversarial loss: 0.446109\n",
      "epoch 99; iter: 0; batch classifier loss: 0.172294; batch adversarial loss: 0.508454\n",
      "epoch 100; iter: 0; batch classifier loss: 0.192020; batch adversarial loss: 0.520308\n",
      "epoch 101; iter: 0; batch classifier loss: 0.256836; batch adversarial loss: 0.458795\n",
      "epoch 102; iter: 0; batch classifier loss: 0.262721; batch adversarial loss: 0.409201\n",
      "epoch 103; iter: 0; batch classifier loss: 0.228399; batch adversarial loss: 0.422515\n",
      "epoch 104; iter: 0; batch classifier loss: 0.166785; batch adversarial loss: 0.433878\n",
      "epoch 105; iter: 0; batch classifier loss: 0.224423; batch adversarial loss: 0.409672\n",
      "epoch 106; iter: 0; batch classifier loss: 0.252446; batch adversarial loss: 0.507684\n",
      "epoch 107; iter: 0; batch classifier loss: 0.236212; batch adversarial loss: 0.495906\n",
      "epoch 108; iter: 0; batch classifier loss: 0.225032; batch adversarial loss: 0.471231\n",
      "epoch 109; iter: 0; batch classifier loss: 0.197920; batch adversarial loss: 0.372920\n",
      "epoch 110; iter: 0; batch classifier loss: 0.222206; batch adversarial loss: 0.385097\n",
      "epoch 111; iter: 0; batch classifier loss: 0.242849; batch adversarial loss: 0.507848\n",
      "epoch 112; iter: 0; batch classifier loss: 0.202178; batch adversarial loss: 0.471306\n",
      "epoch 113; iter: 0; batch classifier loss: 0.120326; batch adversarial loss: 0.372549\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068798; batch adversarial loss: 0.419760\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050782; batch adversarial loss: 0.480690\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052407; batch adversarial loss: 0.468477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061957; batch adversarial loss: 0.410231\n",
      "epoch 118; iter: 0; batch classifier loss: 0.038620; batch adversarial loss: 0.460201\n",
      "epoch 119; iter: 0; batch classifier loss: 0.067056; batch adversarial loss: 0.518020\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039024; batch adversarial loss: 0.433977\n",
      "epoch 121; iter: 0; batch classifier loss: 0.081335; batch adversarial loss: 0.450882\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052038; batch adversarial loss: 0.477035\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035286; batch adversarial loss: 0.474913\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033764; batch adversarial loss: 0.475454\n",
      "epoch 125; iter: 0; batch classifier loss: 0.070590; batch adversarial loss: 0.484879\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042702; batch adversarial loss: 0.398203\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058443; batch adversarial loss: 0.581120\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052694; batch adversarial loss: 0.361092\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062307; batch adversarial loss: 0.517568\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042995; batch adversarial loss: 0.414777\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038151; batch adversarial loss: 0.299145\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070642; batch adversarial loss: 0.443368\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049484; batch adversarial loss: 0.376260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.089926; batch adversarial loss: 0.411340\n",
      "epoch 135; iter: 0; batch classifier loss: 0.113587; batch adversarial loss: 0.508060\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046912; batch adversarial loss: 0.434292\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056726; batch adversarial loss: 0.311876\n",
      "epoch 138; iter: 0; batch classifier loss: 0.140227; batch adversarial loss: 0.454743\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049237; batch adversarial loss: 0.462869\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038223; batch adversarial loss: 0.400063\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049084; batch adversarial loss: 0.408727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.065745; batch adversarial loss: 0.408931\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038238; batch adversarial loss: 0.505998\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062795; batch adversarial loss: 0.469057\n",
      "epoch 145; iter: 0; batch classifier loss: 0.076689; batch adversarial loss: 0.429854\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060879; batch adversarial loss: 0.450382\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043336; batch adversarial loss: 0.426862\n",
      "epoch 148; iter: 0; batch classifier loss: 0.060809; batch adversarial loss: 0.396613\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035969; batch adversarial loss: 0.414799\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062360; batch adversarial loss: 0.382302\n",
      "epoch 151; iter: 0; batch classifier loss: 0.062618; batch adversarial loss: 0.420158\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.396515\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029068; batch adversarial loss: 0.408270\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046775; batch adversarial loss: 0.397372\n",
      "epoch 155; iter: 0; batch classifier loss: 0.063828; batch adversarial loss: 0.384765\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058786; batch adversarial loss: 0.348970\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.414639\n",
      "epoch 158; iter: 0; batch classifier loss: 0.055005; batch adversarial loss: 0.433734\n",
      "epoch 159; iter: 0; batch classifier loss: 0.051999; batch adversarial loss: 0.424968\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041272; batch adversarial loss: 0.383136\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054693; batch adversarial loss: 0.466860\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042548; batch adversarial loss: 0.507981\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059267; batch adversarial loss: 0.479704\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054201; batch adversarial loss: 0.368886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048315; batch adversarial loss: 0.387444\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052678; batch adversarial loss: 0.452408\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026315; batch adversarial loss: 0.452045\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059195; batch adversarial loss: 0.495744\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047043; batch adversarial loss: 0.392722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041878; batch adversarial loss: 0.310101\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026599; batch adversarial loss: 0.434879\n",
      "epoch 172; iter: 0; batch classifier loss: 0.040824; batch adversarial loss: 0.408956\n",
      "epoch 173; iter: 0; batch classifier loss: 0.049095; batch adversarial loss: 0.356844\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059599; batch adversarial loss: 0.413935\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052533; batch adversarial loss: 0.311700\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032562; batch adversarial loss: 0.397917\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043582; batch adversarial loss: 0.319685\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035589; batch adversarial loss: 0.432259\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024798; batch adversarial loss: 0.491698\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040946; batch adversarial loss: 0.326682\n",
      "epoch 181; iter: 0; batch classifier loss: 0.052285; batch adversarial loss: 0.500647\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040449; batch adversarial loss: 0.354957\n",
      "epoch 183; iter: 0; batch classifier loss: 0.080420; batch adversarial loss: 0.471229\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056670; batch adversarial loss: 0.408010\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052902; batch adversarial loss: 0.477407\n",
      "epoch 186; iter: 0; batch classifier loss: 0.057868; batch adversarial loss: 0.517510\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040074; batch adversarial loss: 0.391947\n",
      "epoch 188; iter: 0; batch classifier loss: 0.066965; batch adversarial loss: 0.388670\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036877; batch adversarial loss: 0.380507\n",
      "epoch 190; iter: 0; batch classifier loss: 0.054775; batch adversarial loss: 0.474039\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027855; batch adversarial loss: 0.473818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.063730; batch adversarial loss: 0.462306\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042440; batch adversarial loss: 0.427034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.048168; batch adversarial loss: 0.372298\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056098; batch adversarial loss: 0.464933\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029064; batch adversarial loss: 0.368007\n",
      "epoch 197; iter: 0; batch classifier loss: 0.049871; batch adversarial loss: 0.448131\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039283; batch adversarial loss: 0.468963\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027756; batch adversarial loss: 0.386979\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707460; batch adversarial loss: 0.569327\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451813; batch adversarial loss: 0.608361\n",
      "epoch 2; iter: 0; batch classifier loss: 0.331395; batch adversarial loss: 0.569524\n",
      "epoch 3; iter: 0; batch classifier loss: 0.379575; batch adversarial loss: 0.556909\n",
      "epoch 4; iter: 0; batch classifier loss: 0.300043; batch adversarial loss: 0.604600\n",
      "epoch 5; iter: 0; batch classifier loss: 0.426754; batch adversarial loss: 0.631279\n",
      "epoch 6; iter: 0; batch classifier loss: 0.366850; batch adversarial loss: 0.593296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328499; batch adversarial loss: 0.531153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327651; batch adversarial loss: 0.552337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348578; batch adversarial loss: 0.546713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269113; batch adversarial loss: 0.500987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327714; batch adversarial loss: 0.563509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.278086; batch adversarial loss: 0.545981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328729; batch adversarial loss: 0.430207\n",
      "epoch 14; iter: 0; batch classifier loss: 0.257627; batch adversarial loss: 0.534694\n",
      "epoch 15; iter: 0; batch classifier loss: 0.187819; batch adversarial loss: 0.550946\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260104; batch adversarial loss: 0.530789\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233777; batch adversarial loss: 0.548130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236290; batch adversarial loss: 0.469578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256520; batch adversarial loss: 0.459642\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331032; batch adversarial loss: 0.483076\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267332; batch adversarial loss: 0.501741\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224013; batch adversarial loss: 0.446712\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236543; batch adversarial loss: 0.488888\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185952; batch adversarial loss: 0.471923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.195840; batch adversarial loss: 0.503560\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179999; batch adversarial loss: 0.447476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200487; batch adversarial loss: 0.375936\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172824; batch adversarial loss: 0.481302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166761; batch adversarial loss: 0.457923\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176269; batch adversarial loss: 0.468635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182699; batch adversarial loss: 0.448911\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184457; batch adversarial loss: 0.473602\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229599; batch adversarial loss: 0.527284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.196760; batch adversarial loss: 0.408978\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205744; batch adversarial loss: 0.437259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241208; batch adversarial loss: 0.484905\n",
      "epoch 37; iter: 0; batch classifier loss: 0.178836; batch adversarial loss: 0.511830\n",
      "epoch 38; iter: 0; batch classifier loss: 0.182574; batch adversarial loss: 0.429847\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163305; batch adversarial loss: 0.539260\n",
      "epoch 40; iter: 0; batch classifier loss: 0.217186; batch adversarial loss: 0.429564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206396; batch adversarial loss: 0.462509\n",
      "epoch 42; iter: 0; batch classifier loss: 0.219102; batch adversarial loss: 0.431897\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209458; batch adversarial loss: 0.467829\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259802; batch adversarial loss: 0.479738\n",
      "epoch 45; iter: 0; batch classifier loss: 0.163804; batch adversarial loss: 0.496966\n",
      "epoch 46; iter: 0; batch classifier loss: 0.163225; batch adversarial loss: 0.469367\n",
      "epoch 47; iter: 0; batch classifier loss: 0.272837; batch adversarial loss: 0.453221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210373; batch adversarial loss: 0.421061\n",
      "epoch 49; iter: 0; batch classifier loss: 0.291124; batch adversarial loss: 0.413984\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188749; batch adversarial loss: 0.497071\n",
      "epoch 51; iter: 0; batch classifier loss: 0.182013; batch adversarial loss: 0.544286\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225796; batch adversarial loss: 0.484083\n",
      "epoch 53; iter: 0; batch classifier loss: 0.168711; batch adversarial loss: 0.399070\n",
      "epoch 54; iter: 0; batch classifier loss: 0.260769; batch adversarial loss: 0.386211\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237776; batch adversarial loss: 0.459550\n",
      "epoch 56; iter: 0; batch classifier loss: 0.202157; batch adversarial loss: 0.470677\n",
      "epoch 57; iter: 0; batch classifier loss: 0.216151; batch adversarial loss: 0.446997\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117685; batch adversarial loss: 0.434512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.104756; batch adversarial loss: 0.457272\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119396; batch adversarial loss: 0.454983\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106279; batch adversarial loss: 0.530946\n",
      "epoch 62; iter: 0; batch classifier loss: 0.078152; batch adversarial loss: 0.425030\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094512; batch adversarial loss: 0.524273\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081969; batch adversarial loss: 0.468062\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056540; batch adversarial loss: 0.464919\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070494; batch adversarial loss: 0.460027\n",
      "epoch 67; iter: 0; batch classifier loss: 0.108235; batch adversarial loss: 0.494898\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061185; batch adversarial loss: 0.354192\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055409; batch adversarial loss: 0.430764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074828; batch adversarial loss: 0.528901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093126; batch adversarial loss: 0.422829\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073481; batch adversarial loss: 0.407238\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101260; batch adversarial loss: 0.459770\n",
      "epoch 74; iter: 0; batch classifier loss: 0.118174; batch adversarial loss: 0.470514\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119251; batch adversarial loss: 0.432784\n",
      "epoch 76; iter: 0; batch classifier loss: 0.054988; batch adversarial loss: 0.501628\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123999; batch adversarial loss: 0.442373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072261; batch adversarial loss: 0.428425\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101608; batch adversarial loss: 0.526164\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089091; batch adversarial loss: 0.332938\n",
      "epoch 81; iter: 0; batch classifier loss: 0.036376; batch adversarial loss: 0.436917\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075930; batch adversarial loss: 0.479726\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071728; batch adversarial loss: 0.413424\n",
      "epoch 84; iter: 0; batch classifier loss: 0.130862; batch adversarial loss: 0.549398\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043666; batch adversarial loss: 0.440651\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067279; batch adversarial loss: 0.367774\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087456; batch adversarial loss: 0.410897\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073043; batch adversarial loss: 0.331689\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053737; batch adversarial loss: 0.387985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049905; batch adversarial loss: 0.425812\n",
      "epoch 91; iter: 0; batch classifier loss: 0.052860; batch adversarial loss: 0.480596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.058404; batch adversarial loss: 0.371150\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041992; batch adversarial loss: 0.359227\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070388; batch adversarial loss: 0.366624\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090100; batch adversarial loss: 0.446127\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066239; batch adversarial loss: 0.340966\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077061; batch adversarial loss: 0.402714\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065070; batch adversarial loss: 0.457693\n",
      "epoch 99; iter: 0; batch classifier loss: 0.078443; batch adversarial loss: 0.430700\n",
      "epoch 100; iter: 0; batch classifier loss: 0.102764; batch adversarial loss: 0.397885\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045298; batch adversarial loss: 0.430226\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079828; batch adversarial loss: 0.441142\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074717; batch adversarial loss: 0.398535\n",
      "epoch 104; iter: 0; batch classifier loss: 0.091251; batch adversarial loss: 0.408448\n",
      "epoch 105; iter: 0; batch classifier loss: 0.110852; batch adversarial loss: 0.403748\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034604; batch adversarial loss: 0.460622\n",
      "epoch 107; iter: 0; batch classifier loss: 0.097323; batch adversarial loss: 0.403648\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064697; batch adversarial loss: 0.510744\n",
      "epoch 109; iter: 0; batch classifier loss: 0.100425; batch adversarial loss: 0.413903\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083711; batch adversarial loss: 0.459679\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076320; batch adversarial loss: 0.455313\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092084; batch adversarial loss: 0.344420\n",
      "epoch 113; iter: 0; batch classifier loss: 0.095398; batch adversarial loss: 0.425733\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063259; batch adversarial loss: 0.407306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050406; batch adversarial loss: 0.442978\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071137; batch adversarial loss: 0.368430\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044985; batch adversarial loss: 0.356752\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066815; batch adversarial loss: 0.464772\n",
      "epoch 119; iter: 0; batch classifier loss: 0.069434; batch adversarial loss: 0.411946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068597; batch adversarial loss: 0.368683\n",
      "epoch 121; iter: 0; batch classifier loss: 0.095658; batch adversarial loss: 0.421773\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034012; batch adversarial loss: 0.477805\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044614; batch adversarial loss: 0.391377\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064727; batch adversarial loss: 0.378737\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057324; batch adversarial loss: 0.372110\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061221; batch adversarial loss: 0.352020\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070284; batch adversarial loss: 0.432958\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061730; batch adversarial loss: 0.346126\n",
      "epoch 129; iter: 0; batch classifier loss: 0.070322; batch adversarial loss: 0.475934\n",
      "epoch 130; iter: 0; batch classifier loss: 0.076989; batch adversarial loss: 0.326683\n",
      "epoch 131; iter: 0; batch classifier loss: 0.068772; batch adversarial loss: 0.349351\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047518; batch adversarial loss: 0.512495\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042936; batch adversarial loss: 0.431333\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064436; batch adversarial loss: 0.413498\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044000; batch adversarial loss: 0.495679\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056596; batch adversarial loss: 0.492411\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063464; batch adversarial loss: 0.363802\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060372; batch adversarial loss: 0.535702\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043888; batch adversarial loss: 0.440971\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.432068\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037352; batch adversarial loss: 0.478439\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050916; batch adversarial loss: 0.459463\n",
      "epoch 143; iter: 0; batch classifier loss: 0.064822; batch adversarial loss: 0.411954\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044115; batch adversarial loss: 0.317627\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045923; batch adversarial loss: 0.460872\n",
      "epoch 146; iter: 0; batch classifier loss: 0.056061; batch adversarial loss: 0.413449\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025049; batch adversarial loss: 0.509098\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049124; batch adversarial loss: 0.454168\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025891; batch adversarial loss: 0.486048\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036174; batch adversarial loss: 0.518581\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042387; batch adversarial loss: 0.416566\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.453329\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044120; batch adversarial loss: 0.529305\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030233; batch adversarial loss: 0.450499\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021440; batch adversarial loss: 0.455523\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036282; batch adversarial loss: 0.378229\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037486; batch adversarial loss: 0.482526\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032064; batch adversarial loss: 0.404824\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041600; batch adversarial loss: 0.382681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030669; batch adversarial loss: 0.498250\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048783; batch adversarial loss: 0.359701\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051937; batch adversarial loss: 0.361914\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036501; batch adversarial loss: 0.406017\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029373; batch adversarial loss: 0.461236\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017801; batch adversarial loss: 0.499455\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016307; batch adversarial loss: 0.439005\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011020; batch adversarial loss: 0.473275\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038836; batch adversarial loss: 0.411748\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021340; batch adversarial loss: 0.491359\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029441; batch adversarial loss: 0.452465\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025942; batch adversarial loss: 0.495085\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009103; batch adversarial loss: 0.449159\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032302; batch adversarial loss: 0.493191\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028241; batch adversarial loss: 0.406245\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.397846\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048815; batch adversarial loss: 0.520914\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016398; batch adversarial loss: 0.422876\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034884; batch adversarial loss: 0.415031\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020242; batch adversarial loss: 0.385216\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020237; batch adversarial loss: 0.457147\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024340; batch adversarial loss: 0.415980\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009452; batch adversarial loss: 0.441404\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015944; batch adversarial loss: 0.502146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013811; batch adversarial loss: 0.466031\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011517; batch adversarial loss: 0.539371\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027451; batch adversarial loss: 0.349111\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.472569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.039516; batch adversarial loss: 0.402136\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020526; batch adversarial loss: 0.526914\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028118; batch adversarial loss: 0.425334\n",
      "epoch 191; iter: 0; batch classifier loss: 0.066352; batch adversarial loss: 0.483743\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014301; batch adversarial loss: 0.418317\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027083; batch adversarial loss: 0.406158\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022207; batch adversarial loss: 0.411785\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008740; batch adversarial loss: 0.491276\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020024; batch adversarial loss: 0.506766\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034381; batch adversarial loss: 0.379330\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026654; batch adversarial loss: 0.447954\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025422; batch adversarial loss: 0.451173\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705733; batch adversarial loss: 0.944074\n",
      "epoch 1; iter: 0; batch classifier loss: 0.702547; batch adversarial loss: 1.015607\n",
      "epoch 2; iter: 0; batch classifier loss: 0.781388; batch adversarial loss: 0.934287\n",
      "epoch 3; iter: 0; batch classifier loss: 0.919947; batch adversarial loss: 0.948546\n",
      "epoch 4; iter: 0; batch classifier loss: 0.927763; batch adversarial loss: 0.881817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.859303; batch adversarial loss: 0.823302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.805931; batch adversarial loss: 0.692474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.691903; batch adversarial loss: 0.668834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531337; batch adversarial loss: 0.568578\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584102; batch adversarial loss: 0.599563\n",
      "epoch 10; iter: 0; batch classifier loss: 0.376020; batch adversarial loss: 0.520107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309724; batch adversarial loss: 0.520428\n",
      "epoch 12; iter: 0; batch classifier loss: 0.340582; batch adversarial loss: 0.549641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261419; batch adversarial loss: 0.533551\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262665; batch adversarial loss: 0.533197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266239; batch adversarial loss: 0.468002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270397; batch adversarial loss: 0.551347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.266515; batch adversarial loss: 0.465224\n",
      "epoch 18; iter: 0; batch classifier loss: 0.249296; batch adversarial loss: 0.517093\n",
      "epoch 19; iter: 0; batch classifier loss: 0.187215; batch adversarial loss: 0.439333\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229060; batch adversarial loss: 0.446303\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212988; batch adversarial loss: 0.511787\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216237; batch adversarial loss: 0.419451\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265589; batch adversarial loss: 0.455352\n",
      "epoch 24; iter: 0; batch classifier loss: 0.223257; batch adversarial loss: 0.470216\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184577; batch adversarial loss: 0.451867\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165888; batch adversarial loss: 0.469000\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152898; batch adversarial loss: 0.483187\n",
      "epoch 28; iter: 0; batch classifier loss: 0.209798; batch adversarial loss: 0.439323\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142978; batch adversarial loss: 0.446456\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151491; batch adversarial loss: 0.497509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145217; batch adversarial loss: 0.527176\n",
      "epoch 32; iter: 0; batch classifier loss: 0.194287; batch adversarial loss: 0.397363\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105855; batch adversarial loss: 0.433212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.146338; batch adversarial loss: 0.417726\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118490; batch adversarial loss: 0.409682\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158711; batch adversarial loss: 0.520651\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134703; batch adversarial loss: 0.538144\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172918; batch adversarial loss: 0.464379\n",
      "epoch 39; iter: 0; batch classifier loss: 0.129318; batch adversarial loss: 0.395779\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140868; batch adversarial loss: 0.463572\n",
      "epoch 41; iter: 0; batch classifier loss: 0.117338; batch adversarial loss: 0.431868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.121204; batch adversarial loss: 0.479262\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071785; batch adversarial loss: 0.536955\n",
      "epoch 44; iter: 0; batch classifier loss: 0.109799; batch adversarial loss: 0.448453\n",
      "epoch 45; iter: 0; batch classifier loss: 0.065311; batch adversarial loss: 0.400801\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088021; batch adversarial loss: 0.488794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083843; batch adversarial loss: 0.484256\n",
      "epoch 48; iter: 0; batch classifier loss: 0.094590; batch adversarial loss: 0.442876\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115629; batch adversarial loss: 0.463056\n",
      "epoch 50; iter: 0; batch classifier loss: 0.057862; batch adversarial loss: 0.499000\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077900; batch adversarial loss: 0.359124\n",
      "epoch 52; iter: 0; batch classifier loss: 0.135772; batch adversarial loss: 0.465753\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110610; batch adversarial loss: 0.391224\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097392; batch adversarial loss: 0.371151\n",
      "epoch 55; iter: 0; batch classifier loss: 0.043169; batch adversarial loss: 0.501718\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075653; batch adversarial loss: 0.473775\n",
      "epoch 57; iter: 0; batch classifier loss: 0.094005; batch adversarial loss: 0.474542\n",
      "epoch 58; iter: 0; batch classifier loss: 0.056432; batch adversarial loss: 0.469957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098372; batch adversarial loss: 0.454096\n",
      "epoch 60; iter: 0; batch classifier loss: 0.058878; batch adversarial loss: 0.523322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075019; batch adversarial loss: 0.504314\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097037; batch adversarial loss: 0.486351\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096801; batch adversarial loss: 0.492245\n",
      "epoch 64; iter: 0; batch classifier loss: 0.053121; batch adversarial loss: 0.442980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086969; batch adversarial loss: 0.422129\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066568; batch adversarial loss: 0.496737\n",
      "epoch 67; iter: 0; batch classifier loss: 0.052652; batch adversarial loss: 0.473360\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052920; batch adversarial loss: 0.478752\n",
      "epoch 69; iter: 0; batch classifier loss: 0.075765; batch adversarial loss: 0.448893\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063974; batch adversarial loss: 0.476628\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049789; batch adversarial loss: 0.569802\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056779; batch adversarial loss: 0.380903\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098335; batch adversarial loss: 0.378358\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049625; batch adversarial loss: 0.464007\n",
      "epoch 75; iter: 0; batch classifier loss: 0.049332; batch adversarial loss: 0.473888\n",
      "epoch 76; iter: 0; batch classifier loss: 0.066835; batch adversarial loss: 0.515847\n",
      "epoch 77; iter: 0; batch classifier loss: 0.031967; batch adversarial loss: 0.458080\n",
      "epoch 78; iter: 0; batch classifier loss: 0.046228; batch adversarial loss: 0.463649\n",
      "epoch 79; iter: 0; batch classifier loss: 0.039932; batch adversarial loss: 0.533467\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068609; batch adversarial loss: 0.459708\n",
      "epoch 81; iter: 0; batch classifier loss: 0.045491; batch adversarial loss: 0.454663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055504; batch adversarial loss: 0.561033\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052098; batch adversarial loss: 0.456408\n",
      "epoch 84; iter: 0; batch classifier loss: 0.031603; batch adversarial loss: 0.494416\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065426; batch adversarial loss: 0.520129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86; iter: 0; batch classifier loss: 0.056618; batch adversarial loss: 0.547279\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081135; batch adversarial loss: 0.417601\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041747; batch adversarial loss: 0.508205\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050986; batch adversarial loss: 0.333803\n",
      "epoch 90; iter: 0; batch classifier loss: 0.030920; batch adversarial loss: 0.387332\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036528; batch adversarial loss: 0.425286\n",
      "epoch 92; iter: 0; batch classifier loss: 0.037146; batch adversarial loss: 0.458612\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053210; batch adversarial loss: 0.446167\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042818; batch adversarial loss: 0.393396\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038958; batch adversarial loss: 0.524913\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037900; batch adversarial loss: 0.442031\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044739; batch adversarial loss: 0.475561\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077015; batch adversarial loss: 0.480239\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048264; batch adversarial loss: 0.510481\n",
      "epoch 100; iter: 0; batch classifier loss: 0.015176; batch adversarial loss: 0.359250\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027767; batch adversarial loss: 0.482869\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034640; batch adversarial loss: 0.326612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038110; batch adversarial loss: 0.501992\n",
      "epoch 104; iter: 0; batch classifier loss: 0.018930; batch adversarial loss: 0.345016\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030365; batch adversarial loss: 0.413286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032536; batch adversarial loss: 0.400257\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069876; batch adversarial loss: 0.521177\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024599; batch adversarial loss: 0.516059\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032264; batch adversarial loss: 0.445504\n",
      "epoch 110; iter: 0; batch classifier loss: 0.016858; batch adversarial loss: 0.477547\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037192; batch adversarial loss: 0.434402\n",
      "epoch 112; iter: 0; batch classifier loss: 0.013147; batch adversarial loss: 0.490539\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042279; batch adversarial loss: 0.465590\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024582; batch adversarial loss: 0.353079\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037089; batch adversarial loss: 0.404166\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032755; batch adversarial loss: 0.440342\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067570; batch adversarial loss: 0.404786\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026516; batch adversarial loss: 0.453433\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013819; batch adversarial loss: 0.377087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.500542\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035036; batch adversarial loss: 0.537944\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044778; batch adversarial loss: 0.447942\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031178; batch adversarial loss: 0.485324\n",
      "epoch 124; iter: 0; batch classifier loss: 0.064700; batch adversarial loss: 0.552460\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045529; batch adversarial loss: 0.487370\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023740; batch adversarial loss: 0.425167\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023969; batch adversarial loss: 0.412706\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050292; batch adversarial loss: 0.442225\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029336; batch adversarial loss: 0.516659\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040969; batch adversarial loss: 0.458387\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033099; batch adversarial loss: 0.466704\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047752; batch adversarial loss: 0.535894\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037654; batch adversarial loss: 0.439716\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050612; batch adversarial loss: 0.451804\n",
      "epoch 135; iter: 0; batch classifier loss: 0.049377; batch adversarial loss: 0.431637\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011024; batch adversarial loss: 0.443156\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015332; batch adversarial loss: 0.523577\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032321; batch adversarial loss: 0.545414\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034244; batch adversarial loss: 0.570648\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046278; batch adversarial loss: 0.488366\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028237; batch adversarial loss: 0.487964\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025631; batch adversarial loss: 0.455601\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034254; batch adversarial loss: 0.472335\n",
      "epoch 144; iter: 0; batch classifier loss: 0.007787; batch adversarial loss: 0.475577\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062337; batch adversarial loss: 0.433383\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031245; batch adversarial loss: 0.398216\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051678; batch adversarial loss: 0.483849\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015489; batch adversarial loss: 0.432987\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021231; batch adversarial loss: 0.460147\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022194; batch adversarial loss: 0.509069\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027306; batch adversarial loss: 0.413831\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008001; batch adversarial loss: 0.466943\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019997; batch adversarial loss: 0.490463\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018477; batch adversarial loss: 0.441818\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028091; batch adversarial loss: 0.498827\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028733; batch adversarial loss: 0.447510\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034726; batch adversarial loss: 0.496448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045871; batch adversarial loss: 0.448246\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027971; batch adversarial loss: 0.483301\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009699; batch adversarial loss: 0.533668\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045614; batch adversarial loss: 0.413165\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012095; batch adversarial loss: 0.385039\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018127; batch adversarial loss: 0.573015\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008591; batch adversarial loss: 0.477198\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011746; batch adversarial loss: 0.456263\n",
      "epoch 166; iter: 0; batch classifier loss: 0.003251; batch adversarial loss: 0.439353\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023074; batch adversarial loss: 0.434376\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030398; batch adversarial loss: 0.555484\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031090; batch adversarial loss: 0.471162\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021151; batch adversarial loss: 0.458327\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028864; batch adversarial loss: 0.449140\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018111; batch adversarial loss: 0.404593\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012313; batch adversarial loss: 0.392599\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023674; batch adversarial loss: 0.467949\n",
      "epoch 175; iter: 0; batch classifier loss: 0.006767; batch adversarial loss: 0.530790\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041161; batch adversarial loss: 0.397667\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018255; batch adversarial loss: 0.366389\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029823; batch adversarial loss: 0.603195\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010888; batch adversarial loss: 0.484945\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025491; batch adversarial loss: 0.454289\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007373; batch adversarial loss: 0.479041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182; iter: 0; batch classifier loss: 0.030194; batch adversarial loss: 0.472144\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012357; batch adversarial loss: 0.435685\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014898; batch adversarial loss: 0.524389\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010750; batch adversarial loss: 0.430936\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005470; batch adversarial loss: 0.438223\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018490; batch adversarial loss: 0.467889\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005826; batch adversarial loss: 0.333456\n",
      "epoch 189; iter: 0; batch classifier loss: 0.016961; batch adversarial loss: 0.445371\n",
      "epoch 190; iter: 0; batch classifier loss: 0.001845; batch adversarial loss: 0.558471\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016694; batch adversarial loss: 0.465181\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038094; batch adversarial loss: 0.447243\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005442; batch adversarial loss: 0.491554\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005863; batch adversarial loss: 0.549931\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038403; batch adversarial loss: 0.519105\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008489; batch adversarial loss: 0.512847\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009558; batch adversarial loss: 0.487560\n",
      "epoch 198; iter: 0; batch classifier loss: 0.006426; batch adversarial loss: 0.463617\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027749; batch adversarial loss: 0.508083\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707187; batch adversarial loss: 0.530105\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470438; batch adversarial loss: 0.557048\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417213; batch adversarial loss: 0.582285\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403371; batch adversarial loss: 0.572173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439618; batch adversarial loss: 0.522802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380790; batch adversarial loss: 0.579110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421006; batch adversarial loss: 0.631761\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465206; batch adversarial loss: 0.572909\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474299; batch adversarial loss: 0.556246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622409; batch adversarial loss: 0.558470\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555603; batch adversarial loss: 0.533827\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491097; batch adversarial loss: 0.504087\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427479; batch adversarial loss: 0.490595\n",
      "epoch 13; iter: 0; batch classifier loss: 0.311261; batch adversarial loss: 0.509589\n",
      "epoch 14; iter: 0; batch classifier loss: 0.327254; batch adversarial loss: 0.480587\n",
      "epoch 15; iter: 0; batch classifier loss: 0.213240; batch adversarial loss: 0.466903\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253101; batch adversarial loss: 0.448848\n",
      "epoch 17; iter: 0; batch classifier loss: 0.263117; batch adversarial loss: 0.483922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.190632; batch adversarial loss: 0.415344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249896; batch adversarial loss: 0.502029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304332; batch adversarial loss: 0.409823\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175800; batch adversarial loss: 0.442200\n",
      "epoch 22; iter: 0; batch classifier loss: 0.213304; batch adversarial loss: 0.413857\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191316; batch adversarial loss: 0.568279\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210207; batch adversarial loss: 0.383290\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201485; batch adversarial loss: 0.487415\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191863; batch adversarial loss: 0.484148\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171540; batch adversarial loss: 0.463103\n",
      "epoch 28; iter: 0; batch classifier loss: 0.096316; batch adversarial loss: 0.438418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171568; batch adversarial loss: 0.522984\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173726; batch adversarial loss: 0.502753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151581; batch adversarial loss: 0.493829\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159320; batch adversarial loss: 0.478358\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130399; batch adversarial loss: 0.478271\n",
      "epoch 34; iter: 0; batch classifier loss: 0.165775; batch adversarial loss: 0.462223\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184645; batch adversarial loss: 0.440381\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151747; batch adversarial loss: 0.439157\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121754; batch adversarial loss: 0.433693\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124319; batch adversarial loss: 0.519307\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120895; batch adversarial loss: 0.450235\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152208; batch adversarial loss: 0.400909\n",
      "epoch 41; iter: 0; batch classifier loss: 0.149267; batch adversarial loss: 0.441172\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111744; batch adversarial loss: 0.445214\n",
      "epoch 43; iter: 0; batch classifier loss: 0.118376; batch adversarial loss: 0.486042\n",
      "epoch 44; iter: 0; batch classifier loss: 0.174839; batch adversarial loss: 0.522619\n",
      "epoch 45; iter: 0; batch classifier loss: 0.160766; batch adversarial loss: 0.445287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.162882; batch adversarial loss: 0.467407\n",
      "epoch 47; iter: 0; batch classifier loss: 0.147509; batch adversarial loss: 0.458691\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155928; batch adversarial loss: 0.440805\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148503; batch adversarial loss: 0.436961\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177080; batch adversarial loss: 0.523328\n",
      "epoch 51; iter: 0; batch classifier loss: 0.152935; batch adversarial loss: 0.444857\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134956; batch adversarial loss: 0.409873\n",
      "epoch 53; iter: 0; batch classifier loss: 0.150934; batch adversarial loss: 0.459325\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132490; batch adversarial loss: 0.593964\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131501; batch adversarial loss: 0.411699\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161068; batch adversarial loss: 0.426130\n",
      "epoch 57; iter: 0; batch classifier loss: 0.144177; batch adversarial loss: 0.443515\n",
      "epoch 58; iter: 0; batch classifier loss: 0.185053; batch adversarial loss: 0.525230\n",
      "epoch 59; iter: 0; batch classifier loss: 0.175510; batch adversarial loss: 0.423295\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189728; batch adversarial loss: 0.446379\n",
      "epoch 61; iter: 0; batch classifier loss: 0.181600; batch adversarial loss: 0.432734\n",
      "epoch 62; iter: 0; batch classifier loss: 0.178233; batch adversarial loss: 0.433709\n",
      "epoch 63; iter: 0; batch classifier loss: 0.116890; batch adversarial loss: 0.496766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.130655; batch adversarial loss: 0.486253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.189936; batch adversarial loss: 0.469588\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125811; batch adversarial loss: 0.485714\n",
      "epoch 67; iter: 0; batch classifier loss: 0.170804; batch adversarial loss: 0.511198\n",
      "epoch 68; iter: 0; batch classifier loss: 0.171932; batch adversarial loss: 0.484054\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123124; batch adversarial loss: 0.437954\n",
      "epoch 70; iter: 0; batch classifier loss: 0.228507; batch adversarial loss: 0.436243\n",
      "epoch 71; iter: 0; batch classifier loss: 0.170509; batch adversarial loss: 0.444689\n",
      "epoch 72; iter: 0; batch classifier loss: 0.167463; batch adversarial loss: 0.409647\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198033; batch adversarial loss: 0.432641\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119743; batch adversarial loss: 0.433674\n",
      "epoch 75; iter: 0; batch classifier loss: 0.183273; batch adversarial loss: 0.509853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.176445; batch adversarial loss: 0.425049\n",
      "epoch 77; iter: 0; batch classifier loss: 0.189417; batch adversarial loss: 0.385031\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119749; batch adversarial loss: 0.485233\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135579; batch adversarial loss: 0.409277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80; iter: 0; batch classifier loss: 0.168894; batch adversarial loss: 0.522231\n",
      "epoch 81; iter: 0; batch classifier loss: 0.152655; batch adversarial loss: 0.534386\n",
      "epoch 82; iter: 0; batch classifier loss: 0.221309; batch adversarial loss: 0.544671\n",
      "epoch 83; iter: 0; batch classifier loss: 0.168100; batch adversarial loss: 0.482493\n",
      "epoch 84; iter: 0; batch classifier loss: 0.177167; batch adversarial loss: 0.471094\n",
      "epoch 85; iter: 0; batch classifier loss: 0.235554; batch adversarial loss: 0.471814\n",
      "epoch 86; iter: 0; batch classifier loss: 0.153732; batch adversarial loss: 0.421993\n",
      "epoch 87; iter: 0; batch classifier loss: 0.165601; batch adversarial loss: 0.359416\n",
      "epoch 88; iter: 0; batch classifier loss: 0.192764; batch adversarial loss: 0.433707\n",
      "epoch 89; iter: 0; batch classifier loss: 0.148360; batch adversarial loss: 0.484372\n",
      "epoch 90; iter: 0; batch classifier loss: 0.117015; batch adversarial loss: 0.359964\n",
      "epoch 91; iter: 0; batch classifier loss: 0.161989; batch adversarial loss: 0.495817\n",
      "epoch 92; iter: 0; batch classifier loss: 0.137127; batch adversarial loss: 0.459443\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169313; batch adversarial loss: 0.434848\n",
      "epoch 94; iter: 0; batch classifier loss: 0.184815; batch adversarial loss: 0.446531\n",
      "epoch 95; iter: 0; batch classifier loss: 0.121492; batch adversarial loss: 0.458986\n",
      "epoch 96; iter: 0; batch classifier loss: 0.125946; batch adversarial loss: 0.421948\n",
      "epoch 97; iter: 0; batch classifier loss: 0.121022; batch adversarial loss: 0.433582\n",
      "epoch 98; iter: 0; batch classifier loss: 0.097380; batch adversarial loss: 0.596082\n",
      "epoch 99; iter: 0; batch classifier loss: 0.151311; batch adversarial loss: 0.386739\n",
      "epoch 100; iter: 0; batch classifier loss: 0.133018; batch adversarial loss: 0.495766\n",
      "epoch 101; iter: 0; batch classifier loss: 0.111586; batch adversarial loss: 0.506507\n",
      "epoch 102; iter: 0; batch classifier loss: 0.159993; batch adversarial loss: 0.446640\n",
      "epoch 103; iter: 0; batch classifier loss: 0.177330; batch adversarial loss: 0.434881\n",
      "epoch 104; iter: 0; batch classifier loss: 0.102894; batch adversarial loss: 0.393259\n",
      "epoch 105; iter: 0; batch classifier loss: 0.148064; batch adversarial loss: 0.458095\n",
      "epoch 106; iter: 0; batch classifier loss: 0.131252; batch adversarial loss: 0.457812\n",
      "epoch 107; iter: 0; batch classifier loss: 0.114439; batch adversarial loss: 0.505428\n",
      "epoch 108; iter: 0; batch classifier loss: 0.142299; batch adversarial loss: 0.484482\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090831; batch adversarial loss: 0.434578\n",
      "epoch 110; iter: 0; batch classifier loss: 0.133838; batch adversarial loss: 0.398835\n",
      "epoch 111; iter: 0; batch classifier loss: 0.191852; batch adversarial loss: 0.458912\n",
      "epoch 112; iter: 0; batch classifier loss: 0.155427; batch adversarial loss: 0.458851\n",
      "epoch 113; iter: 0; batch classifier loss: 0.119171; batch adversarial loss: 0.558877\n",
      "epoch 114; iter: 0; batch classifier loss: 0.131285; batch adversarial loss: 0.545219\n",
      "epoch 115; iter: 0; batch classifier loss: 0.114922; batch adversarial loss: 0.423230\n",
      "epoch 116; iter: 0; batch classifier loss: 0.131503; batch adversarial loss: 0.423176\n",
      "epoch 117; iter: 0; batch classifier loss: 0.161384; batch adversarial loss: 0.407414\n",
      "epoch 118; iter: 0; batch classifier loss: 0.167418; batch adversarial loss: 0.346731\n",
      "epoch 119; iter: 0; batch classifier loss: 0.088472; batch adversarial loss: 0.556255\n",
      "epoch 120; iter: 0; batch classifier loss: 0.104677; batch adversarial loss: 0.525671\n",
      "epoch 121; iter: 0; batch classifier loss: 0.099528; batch adversarial loss: 0.408815\n",
      "epoch 122; iter: 0; batch classifier loss: 0.122487; batch adversarial loss: 0.521117\n",
      "epoch 123; iter: 0; batch classifier loss: 0.108115; batch adversarial loss: 0.433573\n",
      "epoch 124; iter: 0; batch classifier loss: 0.101026; batch adversarial loss: 0.482390\n",
      "epoch 125; iter: 0; batch classifier loss: 0.092557; batch adversarial loss: 0.550483\n",
      "epoch 126; iter: 0; batch classifier loss: 0.079397; batch adversarial loss: 0.492030\n",
      "epoch 127; iter: 0; batch classifier loss: 0.090812; batch adversarial loss: 0.447072\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071687; batch adversarial loss: 0.434671\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059914; batch adversarial loss: 0.526822\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053278; batch adversarial loss: 0.409396\n",
      "epoch 131; iter: 0; batch classifier loss: 0.085841; batch adversarial loss: 0.498345\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061484; batch adversarial loss: 0.486250\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062272; batch adversarial loss: 0.473451\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062207; batch adversarial loss: 0.457365\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040842; batch adversarial loss: 0.447007\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065367; batch adversarial loss: 0.471867\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045165; batch adversarial loss: 0.413687\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030302; batch adversarial loss: 0.442758\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040379; batch adversarial loss: 0.477915\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045032; batch adversarial loss: 0.458207\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029635; batch adversarial loss: 0.456723\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025508; batch adversarial loss: 0.470514\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025947; batch adversarial loss: 0.414363\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050110; batch adversarial loss: 0.524953\n",
      "epoch 145; iter: 0; batch classifier loss: 0.029121; batch adversarial loss: 0.559193\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026897; batch adversarial loss: 0.455044\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019261; batch adversarial loss: 0.479180\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028809; batch adversarial loss: 0.504938\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023611; batch adversarial loss: 0.434626\n",
      "epoch 150; iter: 0; batch classifier loss: 0.065494; batch adversarial loss: 0.438867\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046909; batch adversarial loss: 0.462194\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033653; batch adversarial loss: 0.374128\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034162; batch adversarial loss: 0.429084\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031908; batch adversarial loss: 0.395330\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017294; batch adversarial loss: 0.443978\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067012; batch adversarial loss: 0.381615\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052546; batch adversarial loss: 0.396955\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011445; batch adversarial loss: 0.447170\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012284; batch adversarial loss: 0.487243\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022805; batch adversarial loss: 0.483060\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030729; batch adversarial loss: 0.420588\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010870; batch adversarial loss: 0.553419\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.444697\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016933; batch adversarial loss: 0.489736\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028161; batch adversarial loss: 0.555692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024007; batch adversarial loss: 0.428321\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025367; batch adversarial loss: 0.490030\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016800; batch adversarial loss: 0.512411\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009021; batch adversarial loss: 0.464398\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032017; batch adversarial loss: 0.399320\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014075; batch adversarial loss: 0.475873\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023966; batch adversarial loss: 0.493865\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018982; batch adversarial loss: 0.504617\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018112; batch adversarial loss: 0.425795\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010844; batch adversarial loss: 0.413262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 176; iter: 0; batch classifier loss: 0.026566; batch adversarial loss: 0.486986\n",
      "epoch 177; iter: 0; batch classifier loss: 0.028082; batch adversarial loss: 0.460222\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031084; batch adversarial loss: 0.487869\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043207; batch adversarial loss: 0.492829\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026451; batch adversarial loss: 0.353456\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016218; batch adversarial loss: 0.422664\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014694; batch adversarial loss: 0.457779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022399; batch adversarial loss: 0.377084\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045848; batch adversarial loss: 0.479372\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011579; batch adversarial loss: 0.526839\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019788; batch adversarial loss: 0.430130\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006208; batch adversarial loss: 0.493467\n",
      "epoch 188; iter: 0; batch classifier loss: 0.050116; batch adversarial loss: 0.424879\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013929; batch adversarial loss: 0.479008\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014217; batch adversarial loss: 0.486381\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017131; batch adversarial loss: 0.488499\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050506; batch adversarial loss: 0.430381\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020646; batch adversarial loss: 0.444720\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030136; batch adversarial loss: 0.453330\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013510; batch adversarial loss: 0.534656\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009681; batch adversarial loss: 0.447139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026401; batch adversarial loss: 0.389321\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024228; batch adversarial loss: 0.551543\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021257; batch adversarial loss: 0.506465\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716645; batch adversarial loss: 0.694445\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518041; batch adversarial loss: 0.644096\n",
      "epoch 2; iter: 0; batch classifier loss: 0.460754; batch adversarial loss: 0.603986\n",
      "epoch 3; iter: 0; batch classifier loss: 0.439018; batch adversarial loss: 0.602565\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409049; batch adversarial loss: 0.582606\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418119; batch adversarial loss: 0.596533\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432526; batch adversarial loss: 0.570753\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377438; batch adversarial loss: 0.572104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519557; batch adversarial loss: 0.531911\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511656; batch adversarial loss: 0.512319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389950; batch adversarial loss: 0.537104\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387588; batch adversarial loss: 0.590423\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369973; batch adversarial loss: 0.495615\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401274; batch adversarial loss: 0.499134\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402607; batch adversarial loss: 0.481357\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271655; batch adversarial loss: 0.510136\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418160; batch adversarial loss: 0.425941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333349; batch adversarial loss: 0.445377\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346940; batch adversarial loss: 0.482012\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298874; batch adversarial loss: 0.444723\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327013; batch adversarial loss: 0.517229\n",
      "epoch 21; iter: 0; batch classifier loss: 0.302010; batch adversarial loss: 0.472355\n",
      "epoch 22; iter: 0; batch classifier loss: 0.292435; batch adversarial loss: 0.550196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301762; batch adversarial loss: 0.461203\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341802; batch adversarial loss: 0.456003\n",
      "epoch 25; iter: 0; batch classifier loss: 0.370799; batch adversarial loss: 0.398691\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424499; batch adversarial loss: 0.511163\n",
      "epoch 27; iter: 0; batch classifier loss: 0.261841; batch adversarial loss: 0.450364\n",
      "epoch 28; iter: 0; batch classifier loss: 0.339391; batch adversarial loss: 0.418363\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301739; batch adversarial loss: 0.441504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272394; batch adversarial loss: 0.458296\n",
      "epoch 31; iter: 0; batch classifier loss: 0.312203; batch adversarial loss: 0.431957\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373749; batch adversarial loss: 0.412514\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261729; batch adversarial loss: 0.444889\n",
      "epoch 34; iter: 0; batch classifier loss: 0.287645; batch adversarial loss: 0.433471\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288295; batch adversarial loss: 0.462395\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293231; batch adversarial loss: 0.385936\n",
      "epoch 37; iter: 0; batch classifier loss: 0.294490; batch adversarial loss: 0.462711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.257993; batch adversarial loss: 0.481719\n",
      "epoch 39; iter: 0; batch classifier loss: 0.272983; batch adversarial loss: 0.462895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.290376; batch adversarial loss: 0.471766\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230554; batch adversarial loss: 0.539638\n",
      "epoch 42; iter: 0; batch classifier loss: 0.146752; batch adversarial loss: 0.529543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219437; batch adversarial loss: 0.461500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.193557; batch adversarial loss: 0.424566\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225498; batch adversarial loss: 0.436143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.215315; batch adversarial loss: 0.423644\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175672; batch adversarial loss: 0.457850\n",
      "epoch 48; iter: 0; batch classifier loss: 0.183761; batch adversarial loss: 0.483598\n",
      "epoch 49; iter: 0; batch classifier loss: 0.174887; batch adversarial loss: 0.434602\n",
      "epoch 50; iter: 0; batch classifier loss: 0.140938; batch adversarial loss: 0.518281\n",
      "epoch 51; iter: 0; batch classifier loss: 0.243063; batch adversarial loss: 0.531845\n",
      "epoch 52; iter: 0; batch classifier loss: 0.163373; batch adversarial loss: 0.494620\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119311; batch adversarial loss: 0.434685\n",
      "epoch 54; iter: 0; batch classifier loss: 0.111939; batch adversarial loss: 0.498261\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237235; batch adversarial loss: 0.422798\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221977; batch adversarial loss: 0.396789\n",
      "epoch 57; iter: 0; batch classifier loss: 0.152948; batch adversarial loss: 0.457227\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170063; batch adversarial loss: 0.446245\n",
      "epoch 59; iter: 0; batch classifier loss: 0.279723; batch adversarial loss: 0.520855\n",
      "epoch 60; iter: 0; batch classifier loss: 0.199429; batch adversarial loss: 0.446887\n",
      "epoch 61; iter: 0; batch classifier loss: 0.236485; batch adversarial loss: 0.422089\n",
      "epoch 62; iter: 0; batch classifier loss: 0.199674; batch adversarial loss: 0.458268\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105076; batch adversarial loss: 0.519859\n",
      "epoch 64; iter: 0; batch classifier loss: 0.158293; batch adversarial loss: 0.408242\n",
      "epoch 65; iter: 0; batch classifier loss: 0.136484; batch adversarial loss: 0.520412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.257675; batch adversarial loss: 0.446755\n",
      "epoch 67; iter: 0; batch classifier loss: 0.178751; batch adversarial loss: 0.495938\n",
      "epoch 68; iter: 0; batch classifier loss: 0.189154; batch adversarial loss: 0.496326\n",
      "epoch 69; iter: 0; batch classifier loss: 0.224778; batch adversarial loss: 0.433916\n",
      "epoch 70; iter: 0; batch classifier loss: 0.114563; batch adversarial loss: 0.422067\n",
      "epoch 71; iter: 0; batch classifier loss: 0.194459; batch adversarial loss: 0.483391\n",
      "epoch 72; iter: 0; batch classifier loss: 0.219904; batch adversarial loss: 0.520099\n",
      "epoch 73; iter: 0; batch classifier loss: 0.171599; batch adversarial loss: 0.397451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.083638; batch adversarial loss: 0.543351\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069367; batch adversarial loss: 0.455897\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059972; batch adversarial loss: 0.427573\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084635; batch adversarial loss: 0.431665\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167604; batch adversarial loss: 0.445127\n",
      "epoch 79; iter: 0; batch classifier loss: 0.214194; batch adversarial loss: 0.488072\n",
      "epoch 80; iter: 0; batch classifier loss: 0.206452; batch adversarial loss: 0.432267\n",
      "epoch 81; iter: 0; batch classifier loss: 0.143251; batch adversarial loss: 0.409110\n",
      "epoch 82; iter: 0; batch classifier loss: 0.174228; batch adversarial loss: 0.449385\n",
      "epoch 83; iter: 0; batch classifier loss: 0.185485; batch adversarial loss: 0.458473\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184177; batch adversarial loss: 0.495617\n",
      "epoch 85; iter: 0; batch classifier loss: 0.182365; batch adversarial loss: 0.607300\n",
      "epoch 86; iter: 0; batch classifier loss: 0.241374; batch adversarial loss: 0.458126\n",
      "epoch 87; iter: 0; batch classifier loss: 0.134723; batch adversarial loss: 0.445982\n",
      "epoch 88; iter: 0; batch classifier loss: 0.194529; batch adversarial loss: 0.472365\n",
      "epoch 89; iter: 0; batch classifier loss: 0.287632; batch adversarial loss: 0.409479\n",
      "epoch 90; iter: 0; batch classifier loss: 0.190112; batch adversarial loss: 0.483498\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085475; batch adversarial loss: 0.444917\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034092; batch adversarial loss: 0.547274\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052813; batch adversarial loss: 0.443372\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038629; batch adversarial loss: 0.460906\n",
      "epoch 95; iter: 0; batch classifier loss: 0.059514; batch adversarial loss: 0.386463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026432; batch adversarial loss: 0.453488\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035330; batch adversarial loss: 0.403433\n",
      "epoch 98; iter: 0; batch classifier loss: 0.071396; batch adversarial loss: 0.443923\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043373; batch adversarial loss: 0.463038\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036133; batch adversarial loss: 0.385290\n",
      "epoch 101; iter: 0; batch classifier loss: 0.029653; batch adversarial loss: 0.406905\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032563; batch adversarial loss: 0.382996\n",
      "epoch 103; iter: 0; batch classifier loss: 0.027513; batch adversarial loss: 0.543503\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035489; batch adversarial loss: 0.357719\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028278; batch adversarial loss: 0.460688\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034984; batch adversarial loss: 0.509563\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028689; batch adversarial loss: 0.431980\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037118; batch adversarial loss: 0.518453\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024276; batch adversarial loss: 0.459375\n",
      "epoch 110; iter: 0; batch classifier loss: 0.021053; batch adversarial loss: 0.446332\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042647; batch adversarial loss: 0.472262\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031304; batch adversarial loss: 0.474388\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025948; batch adversarial loss: 0.477756\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027845; batch adversarial loss: 0.451920\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038240; batch adversarial loss: 0.399638\n",
      "epoch 116; iter: 0; batch classifier loss: 0.014971; batch adversarial loss: 0.441687\n",
      "epoch 117; iter: 0; batch classifier loss: 0.019145; batch adversarial loss: 0.466024\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043446; batch adversarial loss: 0.428036\n",
      "epoch 119; iter: 0; batch classifier loss: 0.020604; batch adversarial loss: 0.413395\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027828; batch adversarial loss: 0.445384\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041695; batch adversarial loss: 0.495351\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034731; batch adversarial loss: 0.449061\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067319; batch adversarial loss: 0.410034\n",
      "epoch 124; iter: 0; batch classifier loss: 0.025841; batch adversarial loss: 0.444176\n",
      "epoch 125; iter: 0; batch classifier loss: 0.059084; batch adversarial loss: 0.429693\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037379; batch adversarial loss: 0.533361\n",
      "epoch 127; iter: 0; batch classifier loss: 0.025151; batch adversarial loss: 0.418735\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050485; batch adversarial loss: 0.355561\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036915; batch adversarial loss: 0.379361\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051690; batch adversarial loss: 0.442400\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051606; batch adversarial loss: 0.423256\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039917; batch adversarial loss: 0.526685\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017946; batch adversarial loss: 0.414698\n",
      "epoch 134; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.395588\n",
      "epoch 135; iter: 0; batch classifier loss: 0.073121; batch adversarial loss: 0.413025\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055317; batch adversarial loss: 0.408473\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036755; batch adversarial loss: 0.411391\n",
      "epoch 138; iter: 0; batch classifier loss: 0.070374; batch adversarial loss: 0.536929\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039766; batch adversarial loss: 0.485307\n",
      "epoch 140; iter: 0; batch classifier loss: 0.075170; batch adversarial loss: 0.386342\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037737; batch adversarial loss: 0.373511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044545; batch adversarial loss: 0.376252\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050020; batch adversarial loss: 0.488001\n",
      "epoch 144; iter: 0; batch classifier loss: 0.058925; batch adversarial loss: 0.427337\n",
      "epoch 145; iter: 0; batch classifier loss: 0.070682; batch adversarial loss: 0.401432\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038927; batch adversarial loss: 0.375951\n",
      "epoch 147; iter: 0; batch classifier loss: 0.058898; batch adversarial loss: 0.449865\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044332; batch adversarial loss: 0.426097\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050756; batch adversarial loss: 0.480429\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048841; batch adversarial loss: 0.363143\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037534; batch adversarial loss: 0.441246\n",
      "epoch 152; iter: 0; batch classifier loss: 0.077075; batch adversarial loss: 0.455113\n",
      "epoch 153; iter: 0; batch classifier loss: 0.102893; batch adversarial loss: 0.485658\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025631; batch adversarial loss: 0.419512\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043244; batch adversarial loss: 0.482173\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037767; batch adversarial loss: 0.468236\n",
      "epoch 157; iter: 0; batch classifier loss: 0.076553; batch adversarial loss: 0.485766\n",
      "epoch 158; iter: 0; batch classifier loss: 0.076430; batch adversarial loss: 0.489406\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036245; batch adversarial loss: 0.388052\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024477; batch adversarial loss: 0.440426\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045758; batch adversarial loss: 0.498121\n",
      "epoch 162; iter: 0; batch classifier loss: 0.069476; batch adversarial loss: 0.375170\n",
      "epoch 163; iter: 0; batch classifier loss: 0.053672; batch adversarial loss: 0.458995\n",
      "epoch 164; iter: 0; batch classifier loss: 0.075155; batch adversarial loss: 0.442487\n",
      "epoch 165; iter: 0; batch classifier loss: 0.056110; batch adversarial loss: 0.430640\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037340; batch adversarial loss: 0.503765\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027917; batch adversarial loss: 0.416046\n",
      "epoch 168; iter: 0; batch classifier loss: 0.045682; batch adversarial loss: 0.433650\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032729; batch adversarial loss: 0.462832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.046222; batch adversarial loss: 0.439218\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033831; batch adversarial loss: 0.562591\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047096; batch adversarial loss: 0.474056\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058078; batch adversarial loss: 0.490565\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047099; batch adversarial loss: 0.454718\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048202; batch adversarial loss: 0.399757\n",
      "epoch 176; iter: 0; batch classifier loss: 0.062394; batch adversarial loss: 0.474545\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049812; batch adversarial loss: 0.495630\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036939; batch adversarial loss: 0.480595\n",
      "epoch 179; iter: 0; batch classifier loss: 0.041553; batch adversarial loss: 0.441581\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032215; batch adversarial loss: 0.433174\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036673; batch adversarial loss: 0.381263\n",
      "epoch 182; iter: 0; batch classifier loss: 0.056945; batch adversarial loss: 0.349527\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034267; batch adversarial loss: 0.433597\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045518; batch adversarial loss: 0.435612\n",
      "epoch 185; iter: 0; batch classifier loss: 0.058504; batch adversarial loss: 0.404456\n",
      "epoch 186; iter: 0; batch classifier loss: 0.047086; batch adversarial loss: 0.499431\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030563; batch adversarial loss: 0.455925\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048968; batch adversarial loss: 0.467367\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024581; batch adversarial loss: 0.452490\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022196; batch adversarial loss: 0.416118\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036033; batch adversarial loss: 0.446012\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051931; batch adversarial loss: 0.383955\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032628; batch adversarial loss: 0.374455\n",
      "epoch 194; iter: 0; batch classifier loss: 0.060958; batch adversarial loss: 0.370459\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023686; batch adversarial loss: 0.431017\n",
      "epoch 196; iter: 0; batch classifier loss: 0.057303; batch adversarial loss: 0.463672\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041271; batch adversarial loss: 0.450071\n",
      "epoch 198; iter: 0; batch classifier loss: 0.046523; batch adversarial loss: 0.369276\n",
      "epoch 199; iter: 0; batch classifier loss: 0.079066; batch adversarial loss: 0.467036\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704178; batch adversarial loss: 0.545963\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487183; batch adversarial loss: 0.568069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.318011; batch adversarial loss: 0.614612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.364542; batch adversarial loss: 0.520123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387995; batch adversarial loss: 0.513072\n",
      "epoch 5; iter: 0; batch classifier loss: 0.471390; batch adversarial loss: 0.557010\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320012; batch adversarial loss: 0.612545\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368110; batch adversarial loss: 0.628776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399212; batch adversarial loss: 0.558993\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548506; batch adversarial loss: 0.586118\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503249; batch adversarial loss: 0.550182\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562226; batch adversarial loss: 0.554494\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307703; batch adversarial loss: 0.486083\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309606; batch adversarial loss: 0.478617\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245242; batch adversarial loss: 0.442479\n",
      "epoch 15; iter: 0; batch classifier loss: 0.238494; batch adversarial loss: 0.435062\n",
      "epoch 16; iter: 0; batch classifier loss: 0.203497; batch adversarial loss: 0.419757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.224548; batch adversarial loss: 0.441451\n",
      "epoch 18; iter: 0; batch classifier loss: 0.184223; batch adversarial loss: 0.487137\n",
      "epoch 19; iter: 0; batch classifier loss: 0.214827; batch adversarial loss: 0.463620\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199027; batch adversarial loss: 0.457830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186138; batch adversarial loss: 0.480903\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168075; batch adversarial loss: 0.431439\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193994; batch adversarial loss: 0.441334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.105011; batch adversarial loss: 0.410218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.162836; batch adversarial loss: 0.500302\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180879; batch adversarial loss: 0.454390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154998; batch adversarial loss: 0.454638\n",
      "epoch 28; iter: 0; batch classifier loss: 0.097484; batch adversarial loss: 0.435055\n",
      "epoch 29; iter: 0; batch classifier loss: 0.094360; batch adversarial loss: 0.456360\n",
      "epoch 30; iter: 0; batch classifier loss: 0.101605; batch adversarial loss: 0.402843\n",
      "epoch 31; iter: 0; batch classifier loss: 0.090160; batch adversarial loss: 0.436790\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108371; batch adversarial loss: 0.461832\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098423; batch adversarial loss: 0.443506\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104497; batch adversarial loss: 0.449544\n",
      "epoch 35; iter: 0; batch classifier loss: 0.106870; batch adversarial loss: 0.449560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095631; batch adversarial loss: 0.497496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122253; batch adversarial loss: 0.451951\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099248; batch adversarial loss: 0.512819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123082; batch adversarial loss: 0.352184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.085030; batch adversarial loss: 0.425169\n",
      "epoch 41; iter: 0; batch classifier loss: 0.088539; batch adversarial loss: 0.416520\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077655; batch adversarial loss: 0.579584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.083462; batch adversarial loss: 0.482052\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095638; batch adversarial loss: 0.375559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112930; batch adversarial loss: 0.377519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.055322; batch adversarial loss: 0.436204\n",
      "epoch 47; iter: 0; batch classifier loss: 0.084795; batch adversarial loss: 0.384106\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089733; batch adversarial loss: 0.502631\n",
      "epoch 49; iter: 0; batch classifier loss: 0.088850; batch adversarial loss: 0.434701\n",
      "epoch 50; iter: 0; batch classifier loss: 0.128190; batch adversarial loss: 0.490663\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095942; batch adversarial loss: 0.440658\n",
      "epoch 52; iter: 0; batch classifier loss: 0.119074; batch adversarial loss: 0.383125\n",
      "epoch 53; iter: 0; batch classifier loss: 0.104911; batch adversarial loss: 0.423081\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073278; batch adversarial loss: 0.553861\n",
      "epoch 55; iter: 0; batch classifier loss: 0.060776; batch adversarial loss: 0.546289\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108615; batch adversarial loss: 0.449191\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096971; batch adversarial loss: 0.427789\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079415; batch adversarial loss: 0.462950\n",
      "epoch 59; iter: 0; batch classifier loss: 0.045244; batch adversarial loss: 0.386252\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101001; batch adversarial loss: 0.484059\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079064; batch adversarial loss: 0.485515\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066695; batch adversarial loss: 0.450688\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083825; batch adversarial loss: 0.473766\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061459; batch adversarial loss: 0.484749\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076223; batch adversarial loss: 0.437699\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075254; batch adversarial loss: 0.485283\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079247; batch adversarial loss: 0.437798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.120589; batch adversarial loss: 0.477237\n",
      "epoch 69; iter: 0; batch classifier loss: 0.111311; batch adversarial loss: 0.366169\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082150; batch adversarial loss: 0.395799\n",
      "epoch 71; iter: 0; batch classifier loss: 0.089935; batch adversarial loss: 0.532223\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113259; batch adversarial loss: 0.482719\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128620; batch adversarial loss: 0.394500\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097355; batch adversarial loss: 0.460608\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067478; batch adversarial loss: 0.356910\n",
      "epoch 76; iter: 0; batch classifier loss: 0.041481; batch adversarial loss: 0.545397\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070365; batch adversarial loss: 0.388579\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089492; batch adversarial loss: 0.485232\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088746; batch adversarial loss: 0.426743\n",
      "epoch 80; iter: 0; batch classifier loss: 0.057487; batch adversarial loss: 0.496319\n",
      "epoch 81; iter: 0; batch classifier loss: 0.046480; batch adversarial loss: 0.488449\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067028; batch adversarial loss: 0.476550\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049208; batch adversarial loss: 0.473286\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089394; batch adversarial loss: 0.421687\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056026; batch adversarial loss: 0.421939\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084913; batch adversarial loss: 0.491433\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066830; batch adversarial loss: 0.512147\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080548; batch adversarial loss: 0.434490\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061201; batch adversarial loss: 0.402749\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037376; batch adversarial loss: 0.484131\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041390; batch adversarial loss: 0.436915\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056463; batch adversarial loss: 0.441292\n",
      "epoch 93; iter: 0; batch classifier loss: 0.092415; batch adversarial loss: 0.395915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053854; batch adversarial loss: 0.441265\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071457; batch adversarial loss: 0.390934\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026567; batch adversarial loss: 0.525140\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049602; batch adversarial loss: 0.485472\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062006; batch adversarial loss: 0.381022\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052028; batch adversarial loss: 0.384712\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062438; batch adversarial loss: 0.412425\n",
      "epoch 101; iter: 0; batch classifier loss: 0.104004; batch adversarial loss: 0.411576\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027931; batch adversarial loss: 0.423713\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070027; batch adversarial loss: 0.408007\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047091; batch adversarial loss: 0.386987\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057473; batch adversarial loss: 0.405401\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064091; batch adversarial loss: 0.357277\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082503; batch adversarial loss: 0.457195\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061003; batch adversarial loss: 0.358422\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048920; batch adversarial loss: 0.437946\n",
      "epoch 110; iter: 0; batch classifier loss: 0.101632; batch adversarial loss: 0.359824\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042606; batch adversarial loss: 0.407377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026262; batch adversarial loss: 0.415227\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054760; batch adversarial loss: 0.477545\n",
      "epoch 114; iter: 0; batch classifier loss: 0.076269; batch adversarial loss: 0.429043\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049831; batch adversarial loss: 0.313915\n",
      "epoch 116; iter: 0; batch classifier loss: 0.020580; batch adversarial loss: 0.521272\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055139; batch adversarial loss: 0.345488\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059450; batch adversarial loss: 0.498356\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053936; batch adversarial loss: 0.422924\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056130; batch adversarial loss: 0.540647\n",
      "epoch 121; iter: 0; batch classifier loss: 0.033003; batch adversarial loss: 0.419422\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059440; batch adversarial loss: 0.383780\n",
      "epoch 123; iter: 0; batch classifier loss: 0.086594; batch adversarial loss: 0.388714\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054427; batch adversarial loss: 0.484566\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018791; batch adversarial loss: 0.373757\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025841; batch adversarial loss: 0.508352\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.454970\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037757; batch adversarial loss: 0.449373\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035606; batch adversarial loss: 0.414246\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047668; batch adversarial loss: 0.425643\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063708; batch adversarial loss: 0.447059\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031097; batch adversarial loss: 0.435129\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014398; batch adversarial loss: 0.421798\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034083; batch adversarial loss: 0.473377\n",
      "epoch 135; iter: 0; batch classifier loss: 0.053769; batch adversarial loss: 0.413204\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061778; batch adversarial loss: 0.407716\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025627; batch adversarial loss: 0.394875\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056093; batch adversarial loss: 0.404908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024300; batch adversarial loss: 0.359710\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028704; batch adversarial loss: 0.393727\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022183; batch adversarial loss: 0.442354\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023610; batch adversarial loss: 0.545720\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015125; batch adversarial loss: 0.469934\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033440; batch adversarial loss: 0.378133\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017419; batch adversarial loss: 0.529340\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026106; batch adversarial loss: 0.437576\n",
      "epoch 147; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.432157\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015705; batch adversarial loss: 0.481087\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062127; batch adversarial loss: 0.458659\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012672; batch adversarial loss: 0.473195\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039658; batch adversarial loss: 0.508535\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042701; batch adversarial loss: 0.414093\n",
      "epoch 153; iter: 0; batch classifier loss: 0.059974; batch adversarial loss: 0.405338\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058011; batch adversarial loss: 0.464518\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009761; batch adversarial loss: 0.353270\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023987; batch adversarial loss: 0.410281\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017944; batch adversarial loss: 0.367673\n",
      "epoch 158; iter: 0; batch classifier loss: 0.011131; batch adversarial loss: 0.511312\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023903; batch adversarial loss: 0.464625\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021762; batch adversarial loss: 0.431252\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022683; batch adversarial loss: 0.456513\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020739; batch adversarial loss: 0.535011\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040078; batch adversarial loss: 0.377077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.070177; batch adversarial loss: 0.396960\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011422; batch adversarial loss: 0.519572\n",
      "epoch 166; iter: 0; batch classifier loss: 0.065408; batch adversarial loss: 0.422070\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027437; batch adversarial loss: 0.519224\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021786; batch adversarial loss: 0.436686\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015147; batch adversarial loss: 0.269906\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019991; batch adversarial loss: 0.367906\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005958; batch adversarial loss: 0.334127\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018988; batch adversarial loss: 0.452142\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021709; batch adversarial loss: 0.379298\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.471353\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038720; batch adversarial loss: 0.379252\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013776; batch adversarial loss: 0.507618\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.473696\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030685; batch adversarial loss: 0.447960\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023626; batch adversarial loss: 0.474451\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.427496\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009025; batch adversarial loss: 0.437770\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025278; batch adversarial loss: 0.393636\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026136; batch adversarial loss: 0.429498\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037316; batch adversarial loss: 0.488743\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018779; batch adversarial loss: 0.370246\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010617; batch adversarial loss: 0.539411\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009186; batch adversarial loss: 0.511634\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014824; batch adversarial loss: 0.409586\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009485; batch adversarial loss: 0.447931\n",
      "epoch 190; iter: 0; batch classifier loss: 0.009433; batch adversarial loss: 0.436158\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015202; batch adversarial loss: 0.475066\n",
      "epoch 192; iter: 0; batch classifier loss: 0.062743; batch adversarial loss: 0.431601\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012663; batch adversarial loss: 0.493870\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036929; batch adversarial loss: 0.426115\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035405; batch adversarial loss: 0.451165\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018342; batch adversarial loss: 0.484339\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017684; batch adversarial loss: 0.381608\n",
      "epoch 198; iter: 0; batch classifier loss: 0.041292; batch adversarial loss: 0.400545\n",
      "epoch 199; iter: 0; batch classifier loss: 0.072581; batch adversarial loss: 0.444791\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710079; batch adversarial loss: 0.758359\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461010; batch adversarial loss: 0.710351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.453477; batch adversarial loss: 0.656721\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343092; batch adversarial loss: 0.617961\n",
      "epoch 4; iter: 0; batch classifier loss: 0.391533; batch adversarial loss: 0.603668\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349879; batch adversarial loss: 0.608656\n",
      "epoch 6; iter: 0; batch classifier loss: 0.467567; batch adversarial loss: 0.585271\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351624; batch adversarial loss: 0.570836\n",
      "epoch 8; iter: 0; batch classifier loss: 0.328733; batch adversarial loss: 0.551314\n",
      "epoch 9; iter: 0; batch classifier loss: 0.469096; batch adversarial loss: 0.566068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467717; batch adversarial loss: 0.583350\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553230; batch adversarial loss: 0.504857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470864; batch adversarial loss: 0.561288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407480; batch adversarial loss: 0.564516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506071; batch adversarial loss: 0.507592\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363124; batch adversarial loss: 0.471422\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282445; batch adversarial loss: 0.483152\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310579; batch adversarial loss: 0.470775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.270307; batch adversarial loss: 0.457647\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325212; batch adversarial loss: 0.476568\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311209; batch adversarial loss: 0.479811\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294713; batch adversarial loss: 0.507011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304855; batch adversarial loss: 0.543067\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306850; batch adversarial loss: 0.407269\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303788; batch adversarial loss: 0.487239\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242785; batch adversarial loss: 0.528841\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296901; batch adversarial loss: 0.456690\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281111; batch adversarial loss: 0.465660\n",
      "epoch 28; iter: 0; batch classifier loss: 0.220306; batch adversarial loss: 0.471729\n",
      "epoch 29; iter: 0; batch classifier loss: 0.256441; batch adversarial loss: 0.447764\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257828; batch adversarial loss: 0.496551\n",
      "epoch 31; iter: 0; batch classifier loss: 0.185850; batch adversarial loss: 0.538298\n",
      "epoch 32; iter: 0; batch classifier loss: 0.313102; batch adversarial loss: 0.456762\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209807; batch adversarial loss: 0.443374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233510; batch adversarial loss: 0.445295\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210898; batch adversarial loss: 0.463166\n",
      "epoch 36; iter: 0; batch classifier loss: 0.224616; batch adversarial loss: 0.509495\n",
      "epoch 37; iter: 0; batch classifier loss: 0.228042; batch adversarial loss: 0.386916\n",
      "epoch 38; iter: 0; batch classifier loss: 0.266829; batch adversarial loss: 0.477481\n",
      "epoch 39; iter: 0; batch classifier loss: 0.223946; batch adversarial loss: 0.562922\n",
      "epoch 40; iter: 0; batch classifier loss: 0.172062; batch adversarial loss: 0.520383\n",
      "epoch 41; iter: 0; batch classifier loss: 0.228292; batch adversarial loss: 0.504823\n",
      "epoch 42; iter: 0; batch classifier loss: 0.227832; batch adversarial loss: 0.452476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.201015; batch adversarial loss: 0.469207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.231494; batch adversarial loss: 0.527049\n",
      "epoch 45; iter: 0; batch classifier loss: 0.297343; batch adversarial loss: 0.451408\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317866; batch adversarial loss: 0.460607\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201738; batch adversarial loss: 0.447959\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224654; batch adversarial loss: 0.541550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.237655; batch adversarial loss: 0.483909\n",
      "epoch 50; iter: 0; batch classifier loss: 0.182629; batch adversarial loss: 0.484813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.218059; batch adversarial loss: 0.382622\n",
      "epoch 52; iter: 0; batch classifier loss: 0.194558; batch adversarial loss: 0.459963\n",
      "epoch 53; iter: 0; batch classifier loss: 0.351956; batch adversarial loss: 0.434256\n",
      "epoch 54; iter: 0; batch classifier loss: 0.206830; batch adversarial loss: 0.362334\n",
      "epoch 55; iter: 0; batch classifier loss: 0.236881; batch adversarial loss: 0.324119\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187931; batch adversarial loss: 0.472510\n",
      "epoch 57; iter: 0; batch classifier loss: 0.171766; batch adversarial loss: 0.470612\n",
      "epoch 58; iter: 0; batch classifier loss: 0.228247; batch adversarial loss: 0.434567\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176721; batch adversarial loss: 0.568455\n",
      "epoch 60; iter: 0; batch classifier loss: 0.206436; batch adversarial loss: 0.556957\n",
      "epoch 61; iter: 0; batch classifier loss: 0.206177; batch adversarial loss: 0.482319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.186920; batch adversarial loss: 0.373165\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111301; batch adversarial loss: 0.519156\n",
      "epoch 64; iter: 0; batch classifier loss: 0.093126; batch adversarial loss: 0.531130\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098245; batch adversarial loss: 0.371042\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096489; batch adversarial loss: 0.407321\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065997; batch adversarial loss: 0.485435\n",
      "epoch 68; iter: 0; batch classifier loss: 0.130337; batch adversarial loss: 0.475167\n",
      "epoch 69; iter: 0; batch classifier loss: 0.163561; batch adversarial loss: 0.373975\n",
      "epoch 70; iter: 0; batch classifier loss: 0.137294; batch adversarial loss: 0.333431\n",
      "epoch 71; iter: 0; batch classifier loss: 0.133858; batch adversarial loss: 0.447430\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083532; batch adversarial loss: 0.445908\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087661; batch adversarial loss: 0.380920\n",
      "epoch 74; iter: 0; batch classifier loss: 0.129845; batch adversarial loss: 0.462113\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098290; batch adversarial loss: 0.422801\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061659; batch adversarial loss: 0.475526\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087660; batch adversarial loss: 0.416868\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074267; batch adversarial loss: 0.415806\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075469; batch adversarial loss: 0.453939\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102648; batch adversarial loss: 0.522981\n",
      "epoch 81; iter: 0; batch classifier loss: 0.071517; batch adversarial loss: 0.504059\n",
      "epoch 82; iter: 0; batch classifier loss: 0.135083; batch adversarial loss: 0.466626\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079604; batch adversarial loss: 0.413472\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075325; batch adversarial loss: 0.388549\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068113; batch adversarial loss: 0.382895\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072031; batch adversarial loss: 0.436618\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064451; batch adversarial loss: 0.486715\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040549; batch adversarial loss: 0.399359\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073324; batch adversarial loss: 0.462607\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061961; batch adversarial loss: 0.416318\n",
      "epoch 91; iter: 0; batch classifier loss: 0.044592; batch adversarial loss: 0.355197\n",
      "epoch 92; iter: 0; batch classifier loss: 0.110522; batch adversarial loss: 0.531719\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032871; batch adversarial loss: 0.360754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.044382; batch adversarial loss: 0.404213\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042240; batch adversarial loss: 0.441743\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044543; batch adversarial loss: 0.452169\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042225; batch adversarial loss: 0.393473\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042363; batch adversarial loss: 0.539297\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025236; batch adversarial loss: 0.467235\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043265; batch adversarial loss: 0.491334\n",
      "epoch 101; iter: 0; batch classifier loss: 0.042595; batch adversarial loss: 0.430073\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048280; batch adversarial loss: 0.439664\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045723; batch adversarial loss: 0.426974\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044154; batch adversarial loss: 0.444852\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048259; batch adversarial loss: 0.477412\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043812; batch adversarial loss: 0.412020\n",
      "epoch 107; iter: 0; batch classifier loss: 0.041514; batch adversarial loss: 0.458482\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016483; batch adversarial loss: 0.407234\n",
      "epoch 109; iter: 0; batch classifier loss: 0.012870; batch adversarial loss: 0.575307\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054854; batch adversarial loss: 0.478473\n",
      "epoch 111; iter: 0; batch classifier loss: 0.035416; batch adversarial loss: 0.463919\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036197; batch adversarial loss: 0.501157\n",
      "epoch 113; iter: 0; batch classifier loss: 0.010752; batch adversarial loss: 0.507452\n",
      "epoch 114; iter: 0; batch classifier loss: 0.030642; batch adversarial loss: 0.519319\n",
      "epoch 115; iter: 0; batch classifier loss: 0.052775; batch adversarial loss: 0.438471\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065496; batch adversarial loss: 0.470084\n",
      "epoch 117; iter: 0; batch classifier loss: 0.045159; batch adversarial loss: 0.453987\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026570; batch adversarial loss: 0.540333\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016823; batch adversarial loss: 0.475165\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037054; batch adversarial loss: 0.508292\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024367; batch adversarial loss: 0.375001\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039394; batch adversarial loss: 0.411556\n",
      "epoch 123; iter: 0; batch classifier loss: 0.020135; batch adversarial loss: 0.549760\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040023; batch adversarial loss: 0.587327\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019905; batch adversarial loss: 0.413519\n",
      "epoch 126; iter: 0; batch classifier loss: 0.015138; batch adversarial loss: 0.473095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.046385; batch adversarial loss: 0.461437\n",
      "epoch 128; iter: 0; batch classifier loss: 0.005783; batch adversarial loss: 0.461912\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054742; batch adversarial loss: 0.464664\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020073; batch adversarial loss: 0.528627\n",
      "epoch 131; iter: 0; batch classifier loss: 0.067817; batch adversarial loss: 0.328008\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043163; batch adversarial loss: 0.569855\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025133; batch adversarial loss: 0.591161\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051778; batch adversarial loss: 0.543955\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021622; batch adversarial loss: 0.515601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010605; batch adversarial loss: 0.539016\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018089; batch adversarial loss: 0.394117\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052054; batch adversarial loss: 0.461325\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034548; batch adversarial loss: 0.348657\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024647; batch adversarial loss: 0.441681\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.388661\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023424; batch adversarial loss: 0.475620\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020583; batch adversarial loss: 0.391835\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017537; batch adversarial loss: 0.384239\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037032; batch adversarial loss: 0.435647\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035810; batch adversarial loss: 0.409731\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023076; batch adversarial loss: 0.444598\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034467; batch adversarial loss: 0.461678\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005338; batch adversarial loss: 0.438359\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027393; batch adversarial loss: 0.443432\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029098; batch adversarial loss: 0.363043\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018890; batch adversarial loss: 0.451021\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007890; batch adversarial loss: 0.429186\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038472; batch adversarial loss: 0.400417\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028103; batch adversarial loss: 0.421109\n",
      "epoch 156; iter: 0; batch classifier loss: 0.059014; batch adversarial loss: 0.511972\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029511; batch adversarial loss: 0.426334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.012843; batch adversarial loss: 0.478127\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019248; batch adversarial loss: 0.344550\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016882; batch adversarial loss: 0.432501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010365; batch adversarial loss: 0.416896\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047283; batch adversarial loss: 0.431703\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009669; batch adversarial loss: 0.463885\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015632; batch adversarial loss: 0.368934\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014710; batch adversarial loss: 0.331490\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011670; batch adversarial loss: 0.419742\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008984; batch adversarial loss: 0.379747\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013072; batch adversarial loss: 0.471349\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040110; batch adversarial loss: 0.459862\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027511; batch adversarial loss: 0.397744\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009831; batch adversarial loss: 0.499332\n",
      "epoch 172; iter: 0; batch classifier loss: 0.002808; batch adversarial loss: 0.512076\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013832; batch adversarial loss: 0.439935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012659; batch adversarial loss: 0.500817\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020094; batch adversarial loss: 0.453165\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018350; batch adversarial loss: 0.488114\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010389; batch adversarial loss: 0.454949\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013558; batch adversarial loss: 0.439504\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009988; batch adversarial loss: 0.535801\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010448; batch adversarial loss: 0.351056\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007188; batch adversarial loss: 0.459817\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019520; batch adversarial loss: 0.403897\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034733; batch adversarial loss: 0.424278\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006034; batch adversarial loss: 0.449028\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009026; batch adversarial loss: 0.394271\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023568; batch adversarial loss: 0.416261\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025558; batch adversarial loss: 0.444926\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023742; batch adversarial loss: 0.529800\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006329; batch adversarial loss: 0.486272\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020321; batch adversarial loss: 0.522057\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021446; batch adversarial loss: 0.501006\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007244; batch adversarial loss: 0.416316\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011267; batch adversarial loss: 0.440917\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004131; batch adversarial loss: 0.491099\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012050; batch adversarial loss: 0.385868\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016321; batch adversarial loss: 0.517425\n",
      "epoch 197; iter: 0; batch classifier loss: 0.002736; batch adversarial loss: 0.351566\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025082; batch adversarial loss: 0.487046\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025330; batch adversarial loss: 0.488164\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682716; batch adversarial loss: 0.644765\n",
      "epoch 1; iter: 0; batch classifier loss: 0.425979; batch adversarial loss: 0.640241\n",
      "epoch 2; iter: 0; batch classifier loss: 0.367400; batch adversarial loss: 0.622237\n",
      "epoch 3; iter: 0; batch classifier loss: 0.333002; batch adversarial loss: 0.593865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.323434; batch adversarial loss: 0.573938\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375057; batch adversarial loss: 0.572605\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340750; batch adversarial loss: 0.498114\n",
      "epoch 7; iter: 0; batch classifier loss: 0.218416; batch adversarial loss: 0.501194\n",
      "epoch 8; iter: 0; batch classifier loss: 0.229710; batch adversarial loss: 0.524718\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384760; batch adversarial loss: 0.470998\n",
      "epoch 10; iter: 0; batch classifier loss: 0.207152; batch adversarial loss: 0.490322\n",
      "epoch 11; iter: 0; batch classifier loss: 0.192550; batch adversarial loss: 0.478883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255219; batch adversarial loss: 0.426459\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273931; batch adversarial loss: 0.454512\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223465; batch adversarial loss: 0.456095\n",
      "epoch 15; iter: 0; batch classifier loss: 0.206927; batch adversarial loss: 0.434299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.201649; batch adversarial loss: 0.485389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.126592; batch adversarial loss: 0.431587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.167045; batch adversarial loss: 0.494021\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155157; batch adversarial loss: 0.543917\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219354; batch adversarial loss: 0.642606\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203292; batch adversarial loss: 0.523323\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194632; batch adversarial loss: 0.435033\n",
      "epoch 23; iter: 0; batch classifier loss: 0.188283; batch adversarial loss: 0.481342\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188444; batch adversarial loss: 0.492157\n",
      "epoch 25; iter: 0; batch classifier loss: 0.160808; batch adversarial loss: 0.484244\n",
      "epoch 26; iter: 0; batch classifier loss: 0.153618; batch adversarial loss: 0.470576\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162517; batch adversarial loss: 0.436285\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197389; batch adversarial loss: 0.529843\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179015; batch adversarial loss: 0.459980\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162822; batch adversarial loss: 0.479682\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172132; batch adversarial loss: 0.495951\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189693; batch adversarial loss: 0.506820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164283; batch adversarial loss: 0.443790\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148985; batch adversarial loss: 0.430604\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270317; batch adversarial loss: 0.506534\n",
      "epoch 36; iter: 0; batch classifier loss: 0.246134; batch adversarial loss: 0.537225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232471; batch adversarial loss: 0.396483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.111436; batch adversarial loss: 0.406713\n",
      "epoch 39; iter: 0; batch classifier loss: 0.093920; batch adversarial loss: 0.373081\n",
      "epoch 40; iter: 0; batch classifier loss: 0.094522; batch adversarial loss: 0.392176\n",
      "epoch 41; iter: 0; batch classifier loss: 0.075738; batch adversarial loss: 0.445449\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125971; batch adversarial loss: 0.409359\n",
      "epoch 43; iter: 0; batch classifier loss: 0.075358; batch adversarial loss: 0.481901\n",
      "epoch 44; iter: 0; batch classifier loss: 0.068858; batch adversarial loss: 0.395496\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094092; batch adversarial loss: 0.353122\n",
      "epoch 46; iter: 0; batch classifier loss: 0.164969; batch adversarial loss: 0.442626\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095259; batch adversarial loss: 0.494249\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095484; batch adversarial loss: 0.405952\n",
      "epoch 49; iter: 0; batch classifier loss: 0.071961; batch adversarial loss: 0.459958\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065997; batch adversarial loss: 0.451662\n",
      "epoch 51; iter: 0; batch classifier loss: 0.068547; batch adversarial loss: 0.442255\n",
      "epoch 52; iter: 0; batch classifier loss: 0.090908; batch adversarial loss: 0.511488\n",
      "epoch 53; iter: 0; batch classifier loss: 0.064082; batch adversarial loss: 0.458110\n",
      "epoch 54; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.317638\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089840; batch adversarial loss: 0.372453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.105124; batch adversarial loss: 0.445115\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051814; batch adversarial loss: 0.347005\n",
      "epoch 58; iter: 0; batch classifier loss: 0.048660; batch adversarial loss: 0.500061\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096922; batch adversarial loss: 0.472031\n",
      "epoch 60; iter: 0; batch classifier loss: 0.046397; batch adversarial loss: 0.447280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.056273; batch adversarial loss: 0.460016\n",
      "epoch 62; iter: 0; batch classifier loss: 0.025169; batch adversarial loss: 0.450377\n",
      "epoch 63; iter: 0; batch classifier loss: 0.046731; batch adversarial loss: 0.436992\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081308; batch adversarial loss: 0.425468\n",
      "epoch 65; iter: 0; batch classifier loss: 0.045035; batch adversarial loss: 0.353018\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061739; batch adversarial loss: 0.480959\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057369; batch adversarial loss: 0.423318\n",
      "epoch 68; iter: 0; batch classifier loss: 0.053043; batch adversarial loss: 0.395457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056401; batch adversarial loss: 0.462164\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088043; batch adversarial loss: 0.454134\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076553; batch adversarial loss: 0.408898\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060908; batch adversarial loss: 0.357157\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087705; batch adversarial loss: 0.405635\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122950; batch adversarial loss: 0.447469\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077206; batch adversarial loss: 0.548273\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055588; batch adversarial loss: 0.415760\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067554; batch adversarial loss: 0.486867\n",
      "epoch 78; iter: 0; batch classifier loss: 0.062897; batch adversarial loss: 0.424508\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067260; batch adversarial loss: 0.426957\n",
      "epoch 80; iter: 0; batch classifier loss: 0.032517; batch adversarial loss: 0.459850\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053473; batch adversarial loss: 0.446999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056372; batch adversarial loss: 0.408233\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092328; batch adversarial loss: 0.389526\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042280; batch adversarial loss: 0.377054\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066441; batch adversarial loss: 0.542485\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056327; batch adversarial loss: 0.449912\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082286; batch adversarial loss: 0.368147\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063025; batch adversarial loss: 0.380880\n",
      "epoch 89; iter: 0; batch classifier loss: 0.095538; batch adversarial loss: 0.482059\n",
      "epoch 90; iter: 0; batch classifier loss: 0.064792; batch adversarial loss: 0.434784\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067516; batch adversarial loss: 0.499319\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062146; batch adversarial loss: 0.513923\n",
      "epoch 93; iter: 0; batch classifier loss: 0.073119; batch adversarial loss: 0.424282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084331; batch adversarial loss: 0.532326\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042705; batch adversarial loss: 0.395848\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046422; batch adversarial loss: 0.435811\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051096; batch adversarial loss: 0.411051\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059450; batch adversarial loss: 0.579656\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040888; batch adversarial loss: 0.431729\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056964; batch adversarial loss: 0.515106\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046792; batch adversarial loss: 0.439421\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037147; batch adversarial loss: 0.463307\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094142; batch adversarial loss: 0.458143\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033744; batch adversarial loss: 0.413108\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084901; batch adversarial loss: 0.423769\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025023; batch adversarial loss: 0.491407\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060846; batch adversarial loss: 0.482741\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055725; batch adversarial loss: 0.548864\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035629; batch adversarial loss: 0.527299\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022906; batch adversarial loss: 0.524871\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066208; batch adversarial loss: 0.441663\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041359; batch adversarial loss: 0.502634\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054798; batch adversarial loss: 0.375306\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036519; batch adversarial loss: 0.529665\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054676; batch adversarial loss: 0.411180\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040007; batch adversarial loss: 0.368310\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039775; batch adversarial loss: 0.514451\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025728; batch adversarial loss: 0.445065\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021985; batch adversarial loss: 0.394637\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037246; batch adversarial loss: 0.506036\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027051; batch adversarial loss: 0.489678\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042028; batch adversarial loss: 0.474957\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046661; batch adversarial loss: 0.420472\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039950; batch adversarial loss: 0.398893\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051383; batch adversarial loss: 0.432374\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030149; batch adversarial loss: 0.558707\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037330; batch adversarial loss: 0.443521\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032647; batch adversarial loss: 0.335176\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021413; batch adversarial loss: 0.440780\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045415; batch adversarial loss: 0.400988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040686; batch adversarial loss: 0.404279\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020426; batch adversarial loss: 0.376766\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031002; batch adversarial loss: 0.434038\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033512; batch adversarial loss: 0.470486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017611; batch adversarial loss: 0.505193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050263; batch adversarial loss: 0.433816\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033168; batch adversarial loss: 0.552562\n",
      "epoch 138; iter: 0; batch classifier loss: 0.049034; batch adversarial loss: 0.510266\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038871; batch adversarial loss: 0.409863\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032995; batch adversarial loss: 0.449454\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035323; batch adversarial loss: 0.381282\n",
      "epoch 142; iter: 0; batch classifier loss: 0.092691; batch adversarial loss: 0.438678\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051332; batch adversarial loss: 0.505226\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022553; batch adversarial loss: 0.519509\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034643; batch adversarial loss: 0.452672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040280; batch adversarial loss: 0.437538\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021908; batch adversarial loss: 0.515219\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023071; batch adversarial loss: 0.440166\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045881; batch adversarial loss: 0.357084\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016317; batch adversarial loss: 0.513521\n",
      "epoch 151; iter: 0; batch classifier loss: 0.010191; batch adversarial loss: 0.351142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.025179; batch adversarial loss: 0.450028\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021340; batch adversarial loss: 0.353251\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023623; batch adversarial loss: 0.423951\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010034; batch adversarial loss: 0.453542\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040752; batch adversarial loss: 0.498630\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057578; batch adversarial loss: 0.399556\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037468; batch adversarial loss: 0.435551\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049489; batch adversarial loss: 0.389286\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049824; batch adversarial loss: 0.467786\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053645; batch adversarial loss: 0.450616\n",
      "epoch 162; iter: 0; batch classifier loss: 0.048869; batch adversarial loss: 0.379921\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034336; batch adversarial loss: 0.467033\n",
      "epoch 164; iter: 0; batch classifier loss: 0.039527; batch adversarial loss: 0.434886\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026389; batch adversarial loss: 0.429505\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024425; batch adversarial loss: 0.454909\n",
      "epoch 167; iter: 0; batch classifier loss: 0.043006; batch adversarial loss: 0.394197\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022572; batch adversarial loss: 0.438642\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024909; batch adversarial loss: 0.341751\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058124; batch adversarial loss: 0.475834\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021487; batch adversarial loss: 0.399835\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039698; batch adversarial loss: 0.462838\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027123; batch adversarial loss: 0.500953\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013976; batch adversarial loss: 0.446880\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010988; batch adversarial loss: 0.492072\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035039; batch adversarial loss: 0.394031\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023953; batch adversarial loss: 0.412987\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022208; batch adversarial loss: 0.506222\n",
      "epoch 179; iter: 0; batch classifier loss: 0.066847; batch adversarial loss: 0.405217\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030215; batch adversarial loss: 0.467219\n",
      "epoch 181; iter: 0; batch classifier loss: 0.060737; batch adversarial loss: 0.518519\n",
      "epoch 182; iter: 0; batch classifier loss: 0.061319; batch adversarial loss: 0.448009\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021699; batch adversarial loss: 0.531876\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014770; batch adversarial loss: 0.495072\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012938; batch adversarial loss: 0.400522\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046984; batch adversarial loss: 0.451676\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010738; batch adversarial loss: 0.440419\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034522; batch adversarial loss: 0.518120\n",
      "epoch 189; iter: 0; batch classifier loss: 0.057632; batch adversarial loss: 0.354935\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010478; batch adversarial loss: 0.391254\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023305; batch adversarial loss: 0.413811\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005061; batch adversarial loss: 0.355911\n",
      "epoch 193; iter: 0; batch classifier loss: 0.003402; batch adversarial loss: 0.516047\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.486514\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006434; batch adversarial loss: 0.387719\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033164; batch adversarial loss: 0.500516\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024097; batch adversarial loss: 0.370379\n",
      "epoch 198; iter: 0; batch classifier loss: 0.043275; batch adversarial loss: 0.462816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026537; batch adversarial loss: 0.378720\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691243; batch adversarial loss: 0.563959\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403646; batch adversarial loss: 0.595115\n",
      "epoch 2; iter: 0; batch classifier loss: 0.503760; batch adversarial loss: 0.567947\n",
      "epoch 3; iter: 0; batch classifier loss: 0.424950; batch adversarial loss: 0.599151\n",
      "epoch 4; iter: 0; batch classifier loss: 0.459595; batch adversarial loss: 0.534308\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489801; batch adversarial loss: 0.651454\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512797; batch adversarial loss: 0.588954\n",
      "epoch 7; iter: 0; batch classifier loss: 0.470559; batch adversarial loss: 0.530418\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586118; batch adversarial loss: 0.563482\n",
      "epoch 9; iter: 0; batch classifier loss: 0.609019; batch adversarial loss: 0.536042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488244; batch adversarial loss: 0.532580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.427833; batch adversarial loss: 0.506916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356052; batch adversarial loss: 0.505784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361118; batch adversarial loss: 0.450126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357146; batch adversarial loss: 0.529309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290268; batch adversarial loss: 0.473038\n",
      "epoch 16; iter: 0; batch classifier loss: 0.267178; batch adversarial loss: 0.470550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331837; batch adversarial loss: 0.468389\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290315; batch adversarial loss: 0.491532\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259646; batch adversarial loss: 0.455079\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248210; batch adversarial loss: 0.474429\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312636; batch adversarial loss: 0.527924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.231089; batch adversarial loss: 0.490501\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245286; batch adversarial loss: 0.480794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.119802; batch adversarial loss: 0.478153\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215559; batch adversarial loss: 0.489026\n",
      "epoch 26; iter: 0; batch classifier loss: 0.186607; batch adversarial loss: 0.461753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157234; batch adversarial loss: 0.438524\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188345; batch adversarial loss: 0.433684\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170526; batch adversarial loss: 0.429169\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167994; batch adversarial loss: 0.445373\n",
      "epoch 31; iter: 0; batch classifier loss: 0.149233; batch adversarial loss: 0.479963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189449; batch adversarial loss: 0.536780\n",
      "epoch 33; iter: 0; batch classifier loss: 0.120286; batch adversarial loss: 0.447624\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149706; batch adversarial loss: 0.498093\n",
      "epoch 35; iter: 0; batch classifier loss: 0.152361; batch adversarial loss: 0.447480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162255; batch adversarial loss: 0.453797\n",
      "epoch 37; iter: 0; batch classifier loss: 0.166753; batch adversarial loss: 0.469903\n",
      "epoch 38; iter: 0; batch classifier loss: 0.188039; batch adversarial loss: 0.409507\n",
      "epoch 39; iter: 0; batch classifier loss: 0.154602; batch adversarial loss: 0.482824\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202344; batch adversarial loss: 0.483687\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143013; batch adversarial loss: 0.478600\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115002; batch adversarial loss: 0.467067\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135814; batch adversarial loss: 0.502283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.079529; batch adversarial loss: 0.473782\n",
      "epoch 45; iter: 0; batch classifier loss: 0.171693; batch adversarial loss: 0.477486\n",
      "epoch 46; iter: 0; batch classifier loss: 0.118754; batch adversarial loss: 0.494398\n",
      "epoch 47; iter: 0; batch classifier loss: 0.129005; batch adversarial loss: 0.443819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.105299; batch adversarial loss: 0.423308\n",
      "epoch 49; iter: 0; batch classifier loss: 0.167204; batch adversarial loss: 0.362577\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100595; batch adversarial loss: 0.420358\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134620; batch adversarial loss: 0.449198\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109341; batch adversarial loss: 0.430037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165913; batch adversarial loss: 0.380675\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099041; batch adversarial loss: 0.498931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.135966; batch adversarial loss: 0.509494\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134107; batch adversarial loss: 0.422572\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116092; batch adversarial loss: 0.440931\n",
      "epoch 58; iter: 0; batch classifier loss: 0.093834; batch adversarial loss: 0.381698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160498; batch adversarial loss: 0.506804\n",
      "epoch 60; iter: 0; batch classifier loss: 0.105536; batch adversarial loss: 0.559832\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075630; batch adversarial loss: 0.484221\n",
      "epoch 62; iter: 0; batch classifier loss: 0.120779; batch adversarial loss: 0.488569\n",
      "epoch 63; iter: 0; batch classifier loss: 0.146275; batch adversarial loss: 0.496657\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091083; batch adversarial loss: 0.395796\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078252; batch adversarial loss: 0.428380\n",
      "epoch 66; iter: 0; batch classifier loss: 0.146324; batch adversarial loss: 0.375757\n",
      "epoch 67; iter: 0; batch classifier loss: 0.125379; batch adversarial loss: 0.445356\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070927; batch adversarial loss: 0.384325\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108852; batch adversarial loss: 0.409274\n",
      "epoch 70; iter: 0; batch classifier loss: 0.156480; batch adversarial loss: 0.389798\n",
      "epoch 71; iter: 0; batch classifier loss: 0.123614; batch adversarial loss: 0.424200\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110576; batch adversarial loss: 0.518093\n",
      "epoch 73; iter: 0; batch classifier loss: 0.095579; batch adversarial loss: 0.447712\n",
      "epoch 74; iter: 0; batch classifier loss: 0.117958; batch adversarial loss: 0.398021\n",
      "epoch 75; iter: 0; batch classifier loss: 0.087289; batch adversarial loss: 0.456485\n",
      "epoch 76; iter: 0; batch classifier loss: 0.106877; batch adversarial loss: 0.440565\n",
      "epoch 77; iter: 0; batch classifier loss: 0.108471; batch adversarial loss: 0.421330\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128804; batch adversarial loss: 0.477489\n",
      "epoch 79; iter: 0; batch classifier loss: 0.131351; batch adversarial loss: 0.359559\n",
      "epoch 80; iter: 0; batch classifier loss: 0.095536; batch adversarial loss: 0.428583\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047592; batch adversarial loss: 0.453662\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067750; batch adversarial loss: 0.500562\n",
      "epoch 83; iter: 0; batch classifier loss: 0.084092; batch adversarial loss: 0.392925\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092464; batch adversarial loss: 0.409181\n",
      "epoch 85; iter: 0; batch classifier loss: 0.114345; batch adversarial loss: 0.415093\n",
      "epoch 86; iter: 0; batch classifier loss: 0.105410; batch adversarial loss: 0.460223\n",
      "epoch 87; iter: 0; batch classifier loss: 0.141358; batch adversarial loss: 0.402003\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102493; batch adversarial loss: 0.419261\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056624; batch adversarial loss: 0.434590\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062772; batch adversarial loss: 0.409047\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063920; batch adversarial loss: 0.498569\n",
      "epoch 92; iter: 0; batch classifier loss: 0.091046; batch adversarial loss: 0.444743\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046370; batch adversarial loss: 0.507384\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066632; batch adversarial loss: 0.418469\n",
      "epoch 95; iter: 0; batch classifier loss: 0.119842; batch adversarial loss: 0.535805\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051077; batch adversarial loss: 0.485146\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060058; batch adversarial loss: 0.573211\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082241; batch adversarial loss: 0.488201\n",
      "epoch 99; iter: 0; batch classifier loss: 0.056813; batch adversarial loss: 0.479921\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058195; batch adversarial loss: 0.378113\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049620; batch adversarial loss: 0.483623\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041874; batch adversarial loss: 0.490614\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054836; batch adversarial loss: 0.428850\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080858; batch adversarial loss: 0.544249\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026008; batch adversarial loss: 0.359509\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060335; batch adversarial loss: 0.537651\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057530; batch adversarial loss: 0.478583\n",
      "epoch 108; iter: 0; batch classifier loss: 0.087693; batch adversarial loss: 0.446146\n",
      "epoch 109; iter: 0; batch classifier loss: 0.089207; batch adversarial loss: 0.439534\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060728; batch adversarial loss: 0.496586\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062337; batch adversarial loss: 0.347016\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061355; batch adversarial loss: 0.434583\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034115; batch adversarial loss: 0.457486\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.460013\n",
      "epoch 115; iter: 0; batch classifier loss: 0.085291; batch adversarial loss: 0.311190\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051379; batch adversarial loss: 0.406333\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044454; batch adversarial loss: 0.473221\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037103; batch adversarial loss: 0.422664\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053295; batch adversarial loss: 0.440456\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069510; batch adversarial loss: 0.406879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050116; batch adversarial loss: 0.418557\n",
      "epoch 122; iter: 0; batch classifier loss: 0.050952; batch adversarial loss: 0.464598\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041911; batch adversarial loss: 0.399356\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019283; batch adversarial loss: 0.490884\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021071; batch adversarial loss: 0.376961\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035141; batch adversarial loss: 0.465946\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032843; batch adversarial loss: 0.453512\n",
      "epoch 128; iter: 0; batch classifier loss: 0.012437; batch adversarial loss: 0.489401\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051602; batch adversarial loss: 0.444290\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046612; batch adversarial loss: 0.566732\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052730; batch adversarial loss: 0.401342\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033629; batch adversarial loss: 0.423267\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043996; batch adversarial loss: 0.364889\n",
      "epoch 134; iter: 0; batch classifier loss: 0.059172; batch adversarial loss: 0.476708\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036900; batch adversarial loss: 0.438803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039906; batch adversarial loss: 0.464952\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036007; batch adversarial loss: 0.411695\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025973; batch adversarial loss: 0.488268\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029283; batch adversarial loss: 0.455630\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057108; batch adversarial loss: 0.419818\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016210; batch adversarial loss: 0.326631\n",
      "epoch 142; iter: 0; batch classifier loss: 0.066016; batch adversarial loss: 0.390936\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037269; batch adversarial loss: 0.499243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.032795; batch adversarial loss: 0.432363\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024447; batch adversarial loss: 0.483992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045264; batch adversarial loss: 0.407501\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050770; batch adversarial loss: 0.412989\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013863; batch adversarial loss: 0.459116\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029319; batch adversarial loss: 0.451169\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031975; batch adversarial loss: 0.417117\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011152; batch adversarial loss: 0.462146\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019059; batch adversarial loss: 0.360363\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036951; batch adversarial loss: 0.537490\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006604; batch adversarial loss: 0.511366\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019047; batch adversarial loss: 0.375530\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047868; batch adversarial loss: 0.444798\n",
      "epoch 157; iter: 0; batch classifier loss: 0.025639; batch adversarial loss: 0.394533\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019814; batch adversarial loss: 0.377683\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013419; batch adversarial loss: 0.399774\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013258; batch adversarial loss: 0.466369\n",
      "epoch 161; iter: 0; batch classifier loss: 0.010490; batch adversarial loss: 0.407458\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029303; batch adversarial loss: 0.403648\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039854; batch adversarial loss: 0.417150\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027064; batch adversarial loss: 0.409810\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026241; batch adversarial loss: 0.461617\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024774; batch adversarial loss: 0.453746\n",
      "epoch 167; iter: 0; batch classifier loss: 0.070402; batch adversarial loss: 0.446851\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062470; batch adversarial loss: 0.463622\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012119; batch adversarial loss: 0.450597\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039341; batch adversarial loss: 0.433855\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032623; batch adversarial loss: 0.409919\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026728; batch adversarial loss: 0.434918\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013946; batch adversarial loss: 0.489297\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016623; batch adversarial loss: 0.408386\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026267; batch adversarial loss: 0.441499\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031290; batch adversarial loss: 0.347185\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018594; batch adversarial loss: 0.517928\n",
      "epoch 178; iter: 0; batch classifier loss: 0.045823; batch adversarial loss: 0.558287\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034928; batch adversarial loss: 0.467496\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019914; batch adversarial loss: 0.499997\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017982; batch adversarial loss: 0.339196\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023396; batch adversarial loss: 0.360702\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013609; batch adversarial loss: 0.352805\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019427; batch adversarial loss: 0.486804\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041880; batch adversarial loss: 0.400318\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013457; batch adversarial loss: 0.462429\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008352; batch adversarial loss: 0.535535\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012978; batch adversarial loss: 0.547868\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007994; batch adversarial loss: 0.421183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026160; batch adversarial loss: 0.379319\n",
      "epoch 191; iter: 0; batch classifier loss: 0.042362; batch adversarial loss: 0.534212\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021464; batch adversarial loss: 0.389196\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025128; batch adversarial loss: 0.440054\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008799; batch adversarial loss: 0.367411\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016500; batch adversarial loss: 0.491967\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011127; batch adversarial loss: 0.420888\n",
      "epoch 197; iter: 0; batch classifier loss: 0.016047; batch adversarial loss: 0.404639\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022760; batch adversarial loss: 0.516121\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026774; batch adversarial loss: 0.497239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687409; batch adversarial loss: 0.569765\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420536; batch adversarial loss: 0.604657\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400539; batch adversarial loss: 0.559717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403416; batch adversarial loss: 0.554333\n",
      "epoch 4; iter: 0; batch classifier loss: 0.330167; batch adversarial loss: 0.553724\n",
      "epoch 5; iter: 0; batch classifier loss: 0.284591; batch adversarial loss: 0.571944\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381104; batch adversarial loss: 0.531329\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283637; batch adversarial loss: 0.486073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288595; batch adversarial loss: 0.525615\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315112; batch adversarial loss: 0.513328\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284463; batch adversarial loss: 0.490096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.200656; batch adversarial loss: 0.498642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.242688; batch adversarial loss: 0.521996\n",
      "epoch 13; iter: 0; batch classifier loss: 0.213149; batch adversarial loss: 0.498015\n",
      "epoch 14; iter: 0; batch classifier loss: 0.291533; batch adversarial loss: 0.578323\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373899; batch adversarial loss: 0.567551\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418932; batch adversarial loss: 0.608053\n",
      "epoch 17; iter: 0; batch classifier loss: 0.448959; batch adversarial loss: 0.470726\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549484; batch adversarial loss: 0.509715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462241; batch adversarial loss: 0.574057\n",
      "epoch 20; iter: 0; batch classifier loss: 0.305190; batch adversarial loss: 0.516431\n",
      "epoch 21; iter: 0; batch classifier loss: 0.231736; batch adversarial loss: 0.510577\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246954; batch adversarial loss: 0.458839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174755; batch adversarial loss: 0.448192\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230265; batch adversarial loss: 0.506083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171653; batch adversarial loss: 0.486811\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204356; batch adversarial loss: 0.440622\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142353; batch adversarial loss: 0.490517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.157622; batch adversarial loss: 0.531081\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111936; batch adversarial loss: 0.439385\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126413; batch adversarial loss: 0.426902\n",
      "epoch 31; iter: 0; batch classifier loss: 0.129164; batch adversarial loss: 0.531932\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159923; batch adversarial loss: 0.372303\n",
      "epoch 33; iter: 0; batch classifier loss: 0.193568; batch adversarial loss: 0.613246\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123541; batch adversarial loss: 0.366358\n",
      "epoch 35; iter: 0; batch classifier loss: 0.107905; batch adversarial loss: 0.470648\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134255; batch adversarial loss: 0.469769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.118672; batch adversarial loss: 0.388529\n",
      "epoch 38; iter: 0; batch classifier loss: 0.114963; batch adversarial loss: 0.419192\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148403; batch adversarial loss: 0.511762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.205893; batch adversarial loss: 0.425955\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129886; batch adversarial loss: 0.476546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147341; batch adversarial loss: 0.459716\n",
      "epoch 43; iter: 0; batch classifier loss: 0.113689; batch adversarial loss: 0.555618\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085870; batch adversarial loss: 0.399594\n",
      "epoch 45; iter: 0; batch classifier loss: 0.074416; batch adversarial loss: 0.510659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123504; batch adversarial loss: 0.435271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.119802; batch adversarial loss: 0.465338\n",
      "epoch 48; iter: 0; batch classifier loss: 0.141264; batch adversarial loss: 0.387578\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118782; batch adversarial loss: 0.483425\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124221; batch adversarial loss: 0.442747\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093978; batch adversarial loss: 0.501248\n",
      "epoch 52; iter: 0; batch classifier loss: 0.122673; batch adversarial loss: 0.442997\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085681; batch adversarial loss: 0.393131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122456; batch adversarial loss: 0.493074\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106500; batch adversarial loss: 0.494773\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142832; batch adversarial loss: 0.429262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.135694; batch adversarial loss: 0.479178\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109945; batch adversarial loss: 0.445812\n",
      "epoch 59; iter: 0; batch classifier loss: 0.138983; batch adversarial loss: 0.357644\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155236; batch adversarial loss: 0.461470\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099202; batch adversarial loss: 0.496646\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097326; batch adversarial loss: 0.434382\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115712; batch adversarial loss: 0.454388\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086217; batch adversarial loss: 0.380991\n",
      "epoch 65; iter: 0; batch classifier loss: 0.076818; batch adversarial loss: 0.535967\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110510; batch adversarial loss: 0.416580\n",
      "epoch 67; iter: 0; batch classifier loss: 0.097361; batch adversarial loss: 0.441815\n",
      "epoch 68; iter: 0; batch classifier loss: 0.104694; batch adversarial loss: 0.460138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.164200; batch adversarial loss: 0.393310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091951; batch adversarial loss: 0.449358\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116476; batch adversarial loss: 0.442593\n",
      "epoch 72; iter: 0; batch classifier loss: 0.117909; batch adversarial loss: 0.505079\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120396; batch adversarial loss: 0.501765\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102366; batch adversarial loss: 0.418705\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129421; batch adversarial loss: 0.505632\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076920; batch adversarial loss: 0.447544\n",
      "epoch 77; iter: 0; batch classifier loss: 0.036642; batch adversarial loss: 0.456907\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109797; batch adversarial loss: 0.487183\n",
      "epoch 79; iter: 0; batch classifier loss: 0.160930; batch adversarial loss: 0.521056\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072204; batch adversarial loss: 0.459521\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083914; batch adversarial loss: 0.483557\n",
      "epoch 82; iter: 0; batch classifier loss: 0.132070; batch adversarial loss: 0.376042\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073554; batch adversarial loss: 0.530833\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047868; batch adversarial loss: 0.454727\n",
      "epoch 85; iter: 0; batch classifier loss: 0.107776; batch adversarial loss: 0.467221\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107323; batch adversarial loss: 0.453207\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058252; batch adversarial loss: 0.561265\n",
      "epoch 88; iter: 0; batch classifier loss: 0.104850; batch adversarial loss: 0.377473\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049557; batch adversarial loss: 0.494185\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051020; batch adversarial loss: 0.456575\n",
      "epoch 91; iter: 0; batch classifier loss: 0.119531; batch adversarial loss: 0.350416\n",
      "epoch 92; iter: 0; batch classifier loss: 0.089586; batch adversarial loss: 0.457732\n",
      "epoch 93; iter: 0; batch classifier loss: 0.083717; batch adversarial loss: 0.508862\n",
      "epoch 94; iter: 0; batch classifier loss: 0.086989; batch adversarial loss: 0.413437\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056106; batch adversarial loss: 0.437708\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084013; batch adversarial loss: 0.482579\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070402; batch adversarial loss: 0.484635\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050846; batch adversarial loss: 0.463100\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046601; batch adversarial loss: 0.412361\n",
      "epoch 100; iter: 0; batch classifier loss: 0.059048; batch adversarial loss: 0.433240\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073257; batch adversarial loss: 0.453761\n",
      "epoch 102; iter: 0; batch classifier loss: 0.078728; batch adversarial loss: 0.485523\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035018; batch adversarial loss: 0.505527\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033500; batch adversarial loss: 0.444007\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049464; batch adversarial loss: 0.496734\n",
      "epoch 106; iter: 0; batch classifier loss: 0.084259; batch adversarial loss: 0.427239\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052834; batch adversarial loss: 0.483277\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072235; batch adversarial loss: 0.382979\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088130; batch adversarial loss: 0.408175\n",
      "epoch 110; iter: 0; batch classifier loss: 0.086592; batch adversarial loss: 0.413675\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069525; batch adversarial loss: 0.502143\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060184; batch adversarial loss: 0.485080\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064785; batch adversarial loss: 0.387657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.420786\n",
      "epoch 115; iter: 0; batch classifier loss: 0.027844; batch adversarial loss: 0.510928\n",
      "epoch 116; iter: 0; batch classifier loss: 0.070142; batch adversarial loss: 0.483098\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055021; batch adversarial loss: 0.542134\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068280; batch adversarial loss: 0.503293\n",
      "epoch 119; iter: 0; batch classifier loss: 0.083650; batch adversarial loss: 0.444827\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044881; batch adversarial loss: 0.480819\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059142; batch adversarial loss: 0.441228\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046309; batch adversarial loss: 0.455175\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063938; batch adversarial loss: 0.482266\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041454; batch adversarial loss: 0.473495\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020260; batch adversarial loss: 0.447138\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060160; batch adversarial loss: 0.476233\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034460; batch adversarial loss: 0.384168\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051706; batch adversarial loss: 0.428456\n",
      "epoch 129; iter: 0; batch classifier loss: 0.023450; batch adversarial loss: 0.396723\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017963; batch adversarial loss: 0.449575\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039869; batch adversarial loss: 0.444221\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054753; batch adversarial loss: 0.382820\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052874; batch adversarial loss: 0.471638\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038716; batch adversarial loss: 0.405393\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069964; batch adversarial loss: 0.444541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.039775; batch adversarial loss: 0.417252\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033708; batch adversarial loss: 0.439875\n",
      "epoch 138; iter: 0; batch classifier loss: 0.059834; batch adversarial loss: 0.393822\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031334; batch adversarial loss: 0.528874\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036673; batch adversarial loss: 0.454122\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028133; batch adversarial loss: 0.384414\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052149; batch adversarial loss: 0.495097\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047663; batch adversarial loss: 0.485044\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040425; batch adversarial loss: 0.366358\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025279; batch adversarial loss: 0.485212\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044306; batch adversarial loss: 0.368251\n",
      "epoch 147; iter: 0; batch classifier loss: 0.065070; batch adversarial loss: 0.391904\n",
      "epoch 148; iter: 0; batch classifier loss: 0.023692; batch adversarial loss: 0.400077\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035766; batch adversarial loss: 0.421187\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026778; batch adversarial loss: 0.416242\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026274; batch adversarial loss: 0.493253\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053287; batch adversarial loss: 0.463634\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043693; batch adversarial loss: 0.417442\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017634; batch adversarial loss: 0.407246\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023870; batch adversarial loss: 0.502352\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020847; batch adversarial loss: 0.420178\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.503815\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019595; batch adversarial loss: 0.416060\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031543; batch adversarial loss: 0.423836\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037109; batch adversarial loss: 0.428593\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.500471\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027638; batch adversarial loss: 0.489434\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021502; batch adversarial loss: 0.473797\n",
      "epoch 164; iter: 0; batch classifier loss: 0.062391; batch adversarial loss: 0.452842\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016199; batch adversarial loss: 0.431791\n",
      "epoch 166; iter: 0; batch classifier loss: 0.004836; batch adversarial loss: 0.540565\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018004; batch adversarial loss: 0.437637\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022864; batch adversarial loss: 0.475545\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036492; batch adversarial loss: 0.407929\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029364; batch adversarial loss: 0.498985\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025028; batch adversarial loss: 0.429787\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.541823\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027735; batch adversarial loss: 0.415434\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017673; batch adversarial loss: 0.500017\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035788; batch adversarial loss: 0.457694\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041592; batch adversarial loss: 0.503347\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027446; batch adversarial loss: 0.394497\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026319; batch adversarial loss: 0.468183\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012440; batch adversarial loss: 0.433130\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039395; batch adversarial loss: 0.535075\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026311; batch adversarial loss: 0.436211\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017318; batch adversarial loss: 0.439905\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.522185\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038529; batch adversarial loss: 0.387684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020056; batch adversarial loss: 0.429416\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040198; batch adversarial loss: 0.498222\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021751; batch adversarial loss: 0.372987\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034560; batch adversarial loss: 0.440108\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.448930\n",
      "epoch 190; iter: 0; batch classifier loss: 0.066822; batch adversarial loss: 0.458285\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018015; batch adversarial loss: 0.401015\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031377; batch adversarial loss: 0.441918\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018033; batch adversarial loss: 0.553519\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007910; batch adversarial loss: 0.426623\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015161; batch adversarial loss: 0.527659\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.436442\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012416; batch adversarial loss: 0.336505\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028556; batch adversarial loss: 0.567343\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016093; batch adversarial loss: 0.447821\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689371; batch adversarial loss: 0.815122\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480893; batch adversarial loss: 0.766262\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625649; batch adversarial loss: 0.740217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.807611; batch adversarial loss: 0.688693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.622331; batch adversarial loss: 0.620726\n",
      "epoch 5; iter: 0; batch classifier loss: 0.439577; batch adversarial loss: 0.597663\n",
      "epoch 6; iter: 0; batch classifier loss: 0.420008; batch adversarial loss: 0.541104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.397754; batch adversarial loss: 0.549197\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356277; batch adversarial loss: 0.547571\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322726; batch adversarial loss: 0.576238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.356435; batch adversarial loss: 0.525509\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331034; batch adversarial loss: 0.538497\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332807; batch adversarial loss: 0.567739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357782; batch adversarial loss: 0.493503\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333086; batch adversarial loss: 0.479200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311122; batch adversarial loss: 0.515163\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292924; batch adversarial loss: 0.491862\n",
      "epoch 17; iter: 0; batch classifier loss: 0.213262; batch adversarial loss: 0.509469\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284377; batch adversarial loss: 0.505073\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303319; batch adversarial loss: 0.476924\n",
      "epoch 20; iter: 0; batch classifier loss: 0.308557; batch adversarial loss: 0.442528\n",
      "epoch 21; iter: 0; batch classifier loss: 0.262013; batch adversarial loss: 0.474521\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279708; batch adversarial loss: 0.485405\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219963; batch adversarial loss: 0.481711\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274186; batch adversarial loss: 0.400149\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232969; batch adversarial loss: 0.470133\n",
      "epoch 26; iter: 0; batch classifier loss: 0.300128; batch adversarial loss: 0.432903\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245693; batch adversarial loss: 0.498161\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208360; batch adversarial loss: 0.455252\n",
      "epoch 29; iter: 0; batch classifier loss: 0.280553; batch adversarial loss: 0.479240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272497; batch adversarial loss: 0.490998\n",
      "epoch 31; iter: 0; batch classifier loss: 0.214338; batch adversarial loss: 0.485780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.180668; batch adversarial loss: 0.502243\n",
      "epoch 33; iter: 0; batch classifier loss: 0.203438; batch adversarial loss: 0.495387\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225735; batch adversarial loss: 0.433762\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232876; batch adversarial loss: 0.372415\n",
      "epoch 36; iter: 0; batch classifier loss: 0.205608; batch adversarial loss: 0.404226\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175166; batch adversarial loss: 0.435437\n",
      "epoch 38; iter: 0; batch classifier loss: 0.206817; batch adversarial loss: 0.425625\n",
      "epoch 39; iter: 0; batch classifier loss: 0.224587; batch adversarial loss: 0.413100\n",
      "epoch 40; iter: 0; batch classifier loss: 0.272756; batch adversarial loss: 0.529808\n",
      "epoch 41; iter: 0; batch classifier loss: 0.254542; batch adversarial loss: 0.472051\n",
      "epoch 42; iter: 0; batch classifier loss: 0.184145; batch adversarial loss: 0.495897\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158822; batch adversarial loss: 0.402368\n",
      "epoch 44; iter: 0; batch classifier loss: 0.195370; batch adversarial loss: 0.547688\n",
      "epoch 45; iter: 0; batch classifier loss: 0.151459; batch adversarial loss: 0.421015\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200882; batch adversarial loss: 0.373466\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175916; batch adversarial loss: 0.468828\n",
      "epoch 48; iter: 0; batch classifier loss: 0.209811; batch adversarial loss: 0.378677\n",
      "epoch 49; iter: 0; batch classifier loss: 0.165838; batch adversarial loss: 0.417657\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202753; batch adversarial loss: 0.413718\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189435; batch adversarial loss: 0.486723\n",
      "epoch 52; iter: 0; batch classifier loss: 0.175791; batch adversarial loss: 0.407507\n",
      "epoch 53; iter: 0; batch classifier loss: 0.163547; batch adversarial loss: 0.470125\n",
      "epoch 54; iter: 0; batch classifier loss: 0.173192; batch adversarial loss: 0.415814\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125041; batch adversarial loss: 0.397353\n",
      "epoch 56; iter: 0; batch classifier loss: 0.124649; batch adversarial loss: 0.453918\n",
      "epoch 57; iter: 0; batch classifier loss: 0.167480; batch adversarial loss: 0.496759\n",
      "epoch 58; iter: 0; batch classifier loss: 0.128183; batch adversarial loss: 0.512746\n",
      "epoch 59; iter: 0; batch classifier loss: 0.159443; batch adversarial loss: 0.385650\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137265; batch adversarial loss: 0.349544\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115571; batch adversarial loss: 0.466441\n",
      "epoch 62; iter: 0; batch classifier loss: 0.158551; batch adversarial loss: 0.545700\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104482; batch adversarial loss: 0.444463\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090476; batch adversarial loss: 0.422778\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105249; batch adversarial loss: 0.433589\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126140; batch adversarial loss: 0.342618\n",
      "epoch 67; iter: 0; batch classifier loss: 0.129989; batch adversarial loss: 0.422997\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118964; batch adversarial loss: 0.441982\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074370; batch adversarial loss: 0.402920\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066838; batch adversarial loss: 0.419500\n",
      "epoch 71; iter: 0; batch classifier loss: 0.098024; batch adversarial loss: 0.397529\n",
      "epoch 72; iter: 0; batch classifier loss: 0.143982; batch adversarial loss: 0.414912\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078374; batch adversarial loss: 0.427251\n",
      "epoch 74; iter: 0; batch classifier loss: 0.078512; batch adversarial loss: 0.542590\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142785; batch adversarial loss: 0.367765\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086732; batch adversarial loss: 0.333284\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072724; batch adversarial loss: 0.499421\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070396; batch adversarial loss: 0.436825\n",
      "epoch 79; iter: 0; batch classifier loss: 0.097379; batch adversarial loss: 0.446175\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053784; batch adversarial loss: 0.451847\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052060; batch adversarial loss: 0.477426\n",
      "epoch 82; iter: 0; batch classifier loss: 0.056344; batch adversarial loss: 0.427813\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043707; batch adversarial loss: 0.465600\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076981; batch adversarial loss: 0.384911\n",
      "epoch 85; iter: 0; batch classifier loss: 0.121913; batch adversarial loss: 0.485585\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045240; batch adversarial loss: 0.501381\n",
      "epoch 87; iter: 0; batch classifier loss: 0.067088; batch adversarial loss: 0.390036\n",
      "epoch 88; iter: 0; batch classifier loss: 0.108570; batch adversarial loss: 0.392919\n",
      "epoch 89; iter: 0; batch classifier loss: 0.027507; batch adversarial loss: 0.498948\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038790; batch adversarial loss: 0.531047\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083554; batch adversarial loss: 0.338648\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068707; batch adversarial loss: 0.482929\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068214; batch adversarial loss: 0.440708\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059248; batch adversarial loss: 0.426081\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046770; batch adversarial loss: 0.369701\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031344; batch adversarial loss: 0.507594\n",
      "epoch 97; iter: 0; batch classifier loss: 0.029071; batch adversarial loss: 0.522230\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055842; batch adversarial loss: 0.479828\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040413; batch adversarial loss: 0.493885\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065141; batch adversarial loss: 0.464276\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034344; batch adversarial loss: 0.360512\n",
      "epoch 102; iter: 0; batch classifier loss: 0.022162; batch adversarial loss: 0.447591\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050898; batch adversarial loss: 0.468482\n",
      "epoch 104; iter: 0; batch classifier loss: 0.044724; batch adversarial loss: 0.396055\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032085; batch adversarial loss: 0.351109\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028394; batch adversarial loss: 0.426232\n",
      "epoch 107; iter: 0; batch classifier loss: 0.075392; batch adversarial loss: 0.434813\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053554; batch adversarial loss: 0.508788\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024201; batch adversarial loss: 0.490445\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019890; batch adversarial loss: 0.479250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044128; batch adversarial loss: 0.536126\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043800; batch adversarial loss: 0.415578\n",
      "epoch 113; iter: 0; batch classifier loss: 0.014951; batch adversarial loss: 0.450317\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032507; batch adversarial loss: 0.378234\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019973; batch adversarial loss: 0.456130\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055352; batch adversarial loss: 0.476520\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033498; batch adversarial loss: 0.390228\n",
      "epoch 118; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.469030\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031840; batch adversarial loss: 0.424971\n",
      "epoch 120; iter: 0; batch classifier loss: 0.010208; batch adversarial loss: 0.410293\n",
      "epoch 121; iter: 0; batch classifier loss: 0.020457; batch adversarial loss: 0.492061\n",
      "epoch 122; iter: 0; batch classifier loss: 0.039190; batch adversarial loss: 0.480134\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024620; batch adversarial loss: 0.416449\n",
      "epoch 124; iter: 0; batch classifier loss: 0.014059; batch adversarial loss: 0.405978\n",
      "epoch 125; iter: 0; batch classifier loss: 0.011306; batch adversarial loss: 0.404929\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033365; batch adversarial loss: 0.420253\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022815; batch adversarial loss: 0.482890\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017505; batch adversarial loss: 0.411728\n",
      "epoch 129; iter: 0; batch classifier loss: 0.018344; batch adversarial loss: 0.451666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.054787; batch adversarial loss: 0.421898\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019293; batch adversarial loss: 0.461715\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019662; batch adversarial loss: 0.387075\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014672; batch adversarial loss: 0.367969\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010920; batch adversarial loss: 0.452637\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023740; batch adversarial loss: 0.458685\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025081; batch adversarial loss: 0.486794\n",
      "epoch 137; iter: 0; batch classifier loss: 0.059537; batch adversarial loss: 0.492143\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014032; batch adversarial loss: 0.487900\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018973; batch adversarial loss: 0.457140\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021162; batch adversarial loss: 0.432593\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021828; batch adversarial loss: 0.527937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.010177; batch adversarial loss: 0.479892\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015727; batch adversarial loss: 0.419670\n",
      "epoch 144; iter: 0; batch classifier loss: 0.012412; batch adversarial loss: 0.469263\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028217; batch adversarial loss: 0.421101\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024721; batch adversarial loss: 0.419477\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028555; batch adversarial loss: 0.468891\n",
      "epoch 148; iter: 0; batch classifier loss: 0.004813; batch adversarial loss: 0.414147\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008467; batch adversarial loss: 0.474678\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023353; batch adversarial loss: 0.465229\n",
      "epoch 151; iter: 0; batch classifier loss: 0.005659; batch adversarial loss: 0.425542\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018880; batch adversarial loss: 0.388369\n",
      "epoch 153; iter: 0; batch classifier loss: 0.013485; batch adversarial loss: 0.410187\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026169; batch adversarial loss: 0.399904\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017512; batch adversarial loss: 0.384759\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014066; batch adversarial loss: 0.504509\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016116; batch adversarial loss: 0.431397\n",
      "epoch 158; iter: 0; batch classifier loss: 0.030390; batch adversarial loss: 0.429413\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037263; batch adversarial loss: 0.511555\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008647; batch adversarial loss: 0.439520\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014269; batch adversarial loss: 0.473708\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012237; batch adversarial loss: 0.372175\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006168; batch adversarial loss: 0.431712\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010627; batch adversarial loss: 0.472817\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025345; batch adversarial loss: 0.449526\n",
      "epoch 166; iter: 0; batch classifier loss: 0.017123; batch adversarial loss: 0.327050\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.525003\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006538; batch adversarial loss: 0.522116\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016255; batch adversarial loss: 0.404006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011432; batch adversarial loss: 0.389603\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004797; batch adversarial loss: 0.531551\n",
      "epoch 172; iter: 0; batch classifier loss: 0.018644; batch adversarial loss: 0.369424\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014530; batch adversarial loss: 0.419793\n",
      "epoch 174; iter: 0; batch classifier loss: 0.008253; batch adversarial loss: 0.430001\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024921; batch adversarial loss: 0.437829\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009580; batch adversarial loss: 0.352651\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.429277\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020568; batch adversarial loss: 0.455888\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015336; batch adversarial loss: 0.455810\n",
      "epoch 180; iter: 0; batch classifier loss: 0.003181; batch adversarial loss: 0.534580\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005495; batch adversarial loss: 0.459638\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014013; batch adversarial loss: 0.482773\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021434; batch adversarial loss: 0.487723\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018675; batch adversarial loss: 0.489768\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015441; batch adversarial loss: 0.337403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003565; batch adversarial loss: 0.517512\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005608; batch adversarial loss: 0.517259\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012765; batch adversarial loss: 0.429187\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051996; batch adversarial loss: 0.439993\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017066; batch adversarial loss: 0.431129\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009877; batch adversarial loss: 0.395675\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033413; batch adversarial loss: 0.377285\n",
      "epoch 193; iter: 0; batch classifier loss: 0.005588; batch adversarial loss: 0.469338\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010380; batch adversarial loss: 0.564828\n",
      "epoch 195; iter: 0; batch classifier loss: 0.004906; batch adversarial loss: 0.441286\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.405139\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029496; batch adversarial loss: 0.462888\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005939; batch adversarial loss: 0.453073\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026716; batch adversarial loss: 0.445764\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704673; batch adversarial loss: 0.565693\n",
      "epoch 1; iter: 0; batch classifier loss: 0.482668; batch adversarial loss: 0.598230\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433130; batch adversarial loss: 0.565800\n",
      "epoch 3; iter: 0; batch classifier loss: 0.391484; batch adversarial loss: 0.561919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402045; batch adversarial loss: 0.572847\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529208; batch adversarial loss: 0.555608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.444661; batch adversarial loss: 0.615023\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646534; batch adversarial loss: 0.591928\n",
      "epoch 8; iter: 0; batch classifier loss: 0.635849; batch adversarial loss: 0.523267\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500726; batch adversarial loss: 0.573568\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480512; batch adversarial loss: 0.520472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.382131; batch adversarial loss: 0.493211\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337946; batch adversarial loss: 0.563120\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274945; batch adversarial loss: 0.503092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297393; batch adversarial loss: 0.473544\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267606; batch adversarial loss: 0.490361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311768; batch adversarial loss: 0.486700\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234202; batch adversarial loss: 0.491436\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256650; batch adversarial loss: 0.415043\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193317; batch adversarial loss: 0.395292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.190800; batch adversarial loss: 0.486537\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268946; batch adversarial loss: 0.430011\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228066; batch adversarial loss: 0.467963\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184773; batch adversarial loss: 0.545321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.196584; batch adversarial loss: 0.515631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.118643; batch adversarial loss: 0.476280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.137368; batch adversarial loss: 0.454309\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165445; batch adversarial loss: 0.431495\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129796; batch adversarial loss: 0.456722\n",
      "epoch 29; iter: 0; batch classifier loss: 0.134213; batch adversarial loss: 0.408427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160110; batch adversarial loss: 0.446125\n",
      "epoch 31; iter: 0; batch classifier loss: 0.161513; batch adversarial loss: 0.531871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177751; batch adversarial loss: 0.407009\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154928; batch adversarial loss: 0.373805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.105750; batch adversarial loss: 0.506521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142456; batch adversarial loss: 0.527230\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108711; batch adversarial loss: 0.419482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.165234; batch adversarial loss: 0.492496\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112778; batch adversarial loss: 0.436626\n",
      "epoch 39; iter: 0; batch classifier loss: 0.126250; batch adversarial loss: 0.419170\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095349; batch adversarial loss: 0.365255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122296; batch adversarial loss: 0.448499\n",
      "epoch 42; iter: 0; batch classifier loss: 0.177952; batch adversarial loss: 0.503347\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078359; batch adversarial loss: 0.479086\n",
      "epoch 44; iter: 0; batch classifier loss: 0.090863; batch adversarial loss: 0.458706\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158461; batch adversarial loss: 0.424135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.160739; batch adversarial loss: 0.529383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.139778; batch adversarial loss: 0.477329\n",
      "epoch 48; iter: 0; batch classifier loss: 0.216957; batch adversarial loss: 0.404939\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119538; batch adversarial loss: 0.405421\n",
      "epoch 50; iter: 0; batch classifier loss: 0.185255; batch adversarial loss: 0.406247\n",
      "epoch 51; iter: 0; batch classifier loss: 0.137649; batch adversarial loss: 0.520195\n",
      "epoch 52; iter: 0; batch classifier loss: 0.097381; batch adversarial loss: 0.446531\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129699; batch adversarial loss: 0.431921\n",
      "epoch 54; iter: 0; batch classifier loss: 0.118314; batch adversarial loss: 0.418981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.147876; batch adversarial loss: 0.414431\n",
      "epoch 56; iter: 0; batch classifier loss: 0.121922; batch adversarial loss: 0.343486\n",
      "epoch 57; iter: 0; batch classifier loss: 0.153282; batch adversarial loss: 0.531219\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099217; batch adversarial loss: 0.520888\n",
      "epoch 59; iter: 0; batch classifier loss: 0.101464; batch adversarial loss: 0.448044\n",
      "epoch 60; iter: 0; batch classifier loss: 0.087604; batch adversarial loss: 0.413472\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133185; batch adversarial loss: 0.436382\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104554; batch adversarial loss: 0.511369\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087154; batch adversarial loss: 0.386389\n",
      "epoch 64; iter: 0; batch classifier loss: 0.127150; batch adversarial loss: 0.495601\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133024; batch adversarial loss: 0.495195\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110705; batch adversarial loss: 0.430674\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099232; batch adversarial loss: 0.463349\n",
      "epoch 68; iter: 0; batch classifier loss: 0.098313; batch adversarial loss: 0.407744\n",
      "epoch 69; iter: 0; batch classifier loss: 0.122450; batch adversarial loss: 0.479244\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086851; batch adversarial loss: 0.431056\n",
      "epoch 71; iter: 0; batch classifier loss: 0.141655; batch adversarial loss: 0.490662\n",
      "epoch 72; iter: 0; batch classifier loss: 0.103175; batch adversarial loss: 0.441523\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110817; batch adversarial loss: 0.513891\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114375; batch adversarial loss: 0.410865\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110121; batch adversarial loss: 0.331657\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120863; batch adversarial loss: 0.339707\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149378; batch adversarial loss: 0.475159\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102339; batch adversarial loss: 0.412433\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107292; batch adversarial loss: 0.413635\n",
      "epoch 80; iter: 0; batch classifier loss: 0.124105; batch adversarial loss: 0.457232\n",
      "epoch 81; iter: 0; batch classifier loss: 0.150993; batch adversarial loss: 0.385375\n",
      "epoch 82; iter: 0; batch classifier loss: 0.142221; batch adversarial loss: 0.415329\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105477; batch adversarial loss: 0.436267\n",
      "epoch 84; iter: 0; batch classifier loss: 0.109125; batch adversarial loss: 0.399672\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076447; batch adversarial loss: 0.395314\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112683; batch adversarial loss: 0.417566\n",
      "epoch 87; iter: 0; batch classifier loss: 0.093033; batch adversarial loss: 0.459863\n",
      "epoch 88; iter: 0; batch classifier loss: 0.136113; batch adversarial loss: 0.445977\n",
      "epoch 89; iter: 0; batch classifier loss: 0.146342; batch adversarial loss: 0.451966\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080075; batch adversarial loss: 0.488217\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099568; batch adversarial loss: 0.435130\n",
      "epoch 92; iter: 0; batch classifier loss: 0.123827; batch adversarial loss: 0.489818\n",
      "epoch 93; iter: 0; batch classifier loss: 0.175444; batch adversarial loss: 0.385385\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079146; batch adversarial loss: 0.471950\n",
      "epoch 95; iter: 0; batch classifier loss: 0.074052; batch adversarial loss: 0.513316\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088209; batch adversarial loss: 0.425030\n",
      "epoch 97; iter: 0; batch classifier loss: 0.092066; batch adversarial loss: 0.432778\n",
      "epoch 98; iter: 0; batch classifier loss: 0.104193; batch adversarial loss: 0.555159\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088106; batch adversarial loss: 0.459772\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074227; batch adversarial loss: 0.530296\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077356; batch adversarial loss: 0.416484\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060221; batch adversarial loss: 0.537497\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080233; batch adversarial loss: 0.445384\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090728; batch adversarial loss: 0.478543\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053865; batch adversarial loss: 0.589534\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055749; batch adversarial loss: 0.427782\n",
      "epoch 107; iter: 0; batch classifier loss: 0.080857; batch adversarial loss: 0.490433\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086391; batch adversarial loss: 0.527698\n",
      "epoch 109; iter: 0; batch classifier loss: 0.092342; batch adversarial loss: 0.460182\n",
      "epoch 110; iter: 0; batch classifier loss: 0.084708; batch adversarial loss: 0.347240\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048439; batch adversarial loss: 0.489543\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044305; batch adversarial loss: 0.435965\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055737; batch adversarial loss: 0.425853\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036926; batch adversarial loss: 0.434514\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068658; batch adversarial loss: 0.463219\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060161; batch adversarial loss: 0.355188\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067690; batch adversarial loss: 0.456415\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057778; batch adversarial loss: 0.440296\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051786; batch adversarial loss: 0.486917\n",
      "epoch 120; iter: 0; batch classifier loss: 0.017617; batch adversarial loss: 0.485176\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055632; batch adversarial loss: 0.426937\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042976; batch adversarial loss: 0.507329\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063866; batch adversarial loss: 0.438657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.039583; batch adversarial loss: 0.596468\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041071; batch adversarial loss: 0.435997\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048169; batch adversarial loss: 0.340008\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029875; batch adversarial loss: 0.294145\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034270; batch adversarial loss: 0.510974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040640; batch adversarial loss: 0.480209\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045032; batch adversarial loss: 0.504267\n",
      "epoch 131; iter: 0; batch classifier loss: 0.077225; batch adversarial loss: 0.458900\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045668; batch adversarial loss: 0.454850\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017643; batch adversarial loss: 0.498676\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042793; batch adversarial loss: 0.439669\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034275; batch adversarial loss: 0.502803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026185; batch adversarial loss: 0.404419\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025220; batch adversarial loss: 0.437030\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053914; batch adversarial loss: 0.451028\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.403812\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037440; batch adversarial loss: 0.401734\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031878; batch adversarial loss: 0.351010\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017258; batch adversarial loss: 0.434649\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033180; batch adversarial loss: 0.365902\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018395; batch adversarial loss: 0.459788\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027532; batch adversarial loss: 0.430151\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.439514\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025810; batch adversarial loss: 0.425531\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036097; batch adversarial loss: 0.447467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.042409; batch adversarial loss: 0.547656\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030418; batch adversarial loss: 0.480125\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041376; batch adversarial loss: 0.373002\n",
      "epoch 152; iter: 0; batch classifier loss: 0.073312; batch adversarial loss: 0.463200\n",
      "epoch 153; iter: 0; batch classifier loss: 0.010545; batch adversarial loss: 0.428135\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.417179\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034854; batch adversarial loss: 0.401993\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030861; batch adversarial loss: 0.532681\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041153; batch adversarial loss: 0.447828\n",
      "epoch 158; iter: 0; batch classifier loss: 0.006668; batch adversarial loss: 0.450010\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007882; batch adversarial loss: 0.459694\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031540; batch adversarial loss: 0.454068\n",
      "epoch 161; iter: 0; batch classifier loss: 0.076988; batch adversarial loss: 0.428336\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036511; batch adversarial loss: 0.471683\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036213; batch adversarial loss: 0.470991\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017260; batch adversarial loss: 0.446979\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032140; batch adversarial loss: 0.458797\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045604; batch adversarial loss: 0.393569\n",
      "epoch 167; iter: 0; batch classifier loss: 0.044718; batch adversarial loss: 0.451695\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026444; batch adversarial loss: 0.409515\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014800; batch adversarial loss: 0.387274\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040462; batch adversarial loss: 0.443806\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024062; batch adversarial loss: 0.426110\n",
      "epoch 172; iter: 0; batch classifier loss: 0.034033; batch adversarial loss: 0.568177\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019315; batch adversarial loss: 0.412414\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022365; batch adversarial loss: 0.444805\n",
      "epoch 175; iter: 0; batch classifier loss: 0.005833; batch adversarial loss: 0.455439\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044116; batch adversarial loss: 0.409521\n",
      "epoch 177; iter: 0; batch classifier loss: 0.067907; batch adversarial loss: 0.490858\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022213; batch adversarial loss: 0.614987\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022932; batch adversarial loss: 0.418674\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018303; batch adversarial loss: 0.518966\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027041; batch adversarial loss: 0.455822\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016094; batch adversarial loss: 0.469123\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036313; batch adversarial loss: 0.554547\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022213; batch adversarial loss: 0.488147\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023998; batch adversarial loss: 0.463712\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017598; batch adversarial loss: 0.498866\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028056; batch adversarial loss: 0.382498\n",
      "epoch 188; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.435232\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021406; batch adversarial loss: 0.420075\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021476; batch adversarial loss: 0.450698\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021971; batch adversarial loss: 0.454512\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.369569\n",
      "epoch 193; iter: 0; batch classifier loss: 0.044731; batch adversarial loss: 0.443493\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017570; batch adversarial loss: 0.585003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018838; batch adversarial loss: 0.414410\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016939; batch adversarial loss: 0.446727\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047333; batch adversarial loss: 0.496173\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026861; batch adversarial loss: 0.402451\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004092; batch adversarial loss: 0.465428\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671640; batch adversarial loss: 0.605106\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424599; batch adversarial loss: 0.638479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.291154; batch adversarial loss: 0.610979\n",
      "epoch 3; iter: 0; batch classifier loss: 0.346858; batch adversarial loss: 0.575790\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384166; batch adversarial loss: 0.516264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.270550; batch adversarial loss: 0.551999\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345834; batch adversarial loss: 0.570054\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338340; batch adversarial loss: 0.534842\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286232; batch adversarial loss: 0.544289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.302130; batch adversarial loss: 0.515038\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246719; batch adversarial loss: 0.496745\n",
      "epoch 11; iter: 0; batch classifier loss: 0.239782; batch adversarial loss: 0.527736\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302333; batch adversarial loss: 0.477036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.211407; batch adversarial loss: 0.546088\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245182; batch adversarial loss: 0.452479\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167397; batch adversarial loss: 0.522301\n",
      "epoch 16; iter: 0; batch classifier loss: 0.251806; batch adversarial loss: 0.478885\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298313; batch adversarial loss: 0.511535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269018; batch adversarial loss: 0.556829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427810; batch adversarial loss: 0.564103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.378728; batch adversarial loss: 0.501038\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385734; batch adversarial loss: 0.460552\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432999; batch adversarial loss: 0.444663\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224241; batch adversarial loss: 0.449425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215839; batch adversarial loss: 0.433478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148579; batch adversarial loss: 0.440730\n",
      "epoch 26; iter: 0; batch classifier loss: 0.148721; batch adversarial loss: 0.366076\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154397; batch adversarial loss: 0.423518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125315; batch adversarial loss: 0.474719\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176285; batch adversarial loss: 0.466287\n",
      "epoch 30; iter: 0; batch classifier loss: 0.110465; batch adversarial loss: 0.443001\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120464; batch adversarial loss: 0.427502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.133947; batch adversarial loss: 0.417151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133597; batch adversarial loss: 0.361839\n",
      "epoch 34; iter: 0; batch classifier loss: 0.080789; batch adversarial loss: 0.404925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129268; batch adversarial loss: 0.450269\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141606; batch adversarial loss: 0.502722\n",
      "epoch 37; iter: 0; batch classifier loss: 0.086554; batch adversarial loss: 0.569474\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123267; batch adversarial loss: 0.462331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102382; batch adversarial loss: 0.478378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129129; batch adversarial loss: 0.505831\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122761; batch adversarial loss: 0.511638\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113990; batch adversarial loss: 0.451677\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109291; batch adversarial loss: 0.482970\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121525; batch adversarial loss: 0.367523\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126364; batch adversarial loss: 0.477585\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077721; batch adversarial loss: 0.527030\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105770; batch adversarial loss: 0.473467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109717; batch adversarial loss: 0.520945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.116433; batch adversarial loss: 0.498167\n",
      "epoch 50; iter: 0; batch classifier loss: 0.045484; batch adversarial loss: 0.502228\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098375; batch adversarial loss: 0.483886\n",
      "epoch 52; iter: 0; batch classifier loss: 0.070699; batch adversarial loss: 0.568952\n",
      "epoch 53; iter: 0; batch classifier loss: 0.105980; batch adversarial loss: 0.526241\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062014; batch adversarial loss: 0.484153\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110856; batch adversarial loss: 0.552844\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110117; batch adversarial loss: 0.457442\n",
      "epoch 57; iter: 0; batch classifier loss: 0.091721; batch adversarial loss: 0.463253\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115319; batch adversarial loss: 0.485585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086424; batch adversarial loss: 0.454155\n",
      "epoch 60; iter: 0; batch classifier loss: 0.056252; batch adversarial loss: 0.525146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073432; batch adversarial loss: 0.423573\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085902; batch adversarial loss: 0.438480\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089456; batch adversarial loss: 0.583231\n",
      "epoch 64; iter: 0; batch classifier loss: 0.106791; batch adversarial loss: 0.368007\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068081; batch adversarial loss: 0.463604\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085131; batch adversarial loss: 0.458572\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056087; batch adversarial loss: 0.477609\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109812; batch adversarial loss: 0.393358\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094190; batch adversarial loss: 0.467130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101333; batch adversarial loss: 0.426478\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075839; batch adversarial loss: 0.501317\n",
      "epoch 72; iter: 0; batch classifier loss: 0.095897; batch adversarial loss: 0.554565\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068067; batch adversarial loss: 0.480072\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086183; batch adversarial loss: 0.458228\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107719; batch adversarial loss: 0.462667\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073242; batch adversarial loss: 0.451812\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048481; batch adversarial loss: 0.537118\n",
      "epoch 78; iter: 0; batch classifier loss: 0.098948; batch adversarial loss: 0.362411\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062276; batch adversarial loss: 0.444504\n",
      "epoch 80; iter: 0; batch classifier loss: 0.091508; batch adversarial loss: 0.408880\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107178; batch adversarial loss: 0.469694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060115; batch adversarial loss: 0.455714\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063093; batch adversarial loss: 0.507953\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114933; batch adversarial loss: 0.543010\n",
      "epoch 85; iter: 0; batch classifier loss: 0.027865; batch adversarial loss: 0.526984\n",
      "epoch 86; iter: 0; batch classifier loss: 0.088577; batch adversarial loss: 0.435998\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086949; batch adversarial loss: 0.461065\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071562; batch adversarial loss: 0.480674\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081035; batch adversarial loss: 0.371578\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046295; batch adversarial loss: 0.403108\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083035; batch adversarial loss: 0.381326\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070467; batch adversarial loss: 0.475815\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102584; batch adversarial loss: 0.476492\n",
      "epoch 94; iter: 0; batch classifier loss: 0.112974; batch adversarial loss: 0.531946\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103638; batch adversarial loss: 0.483005\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080208; batch adversarial loss: 0.342392\n",
      "epoch 97; iter: 0; batch classifier loss: 0.108127; batch adversarial loss: 0.363536\n",
      "epoch 98; iter: 0; batch classifier loss: 0.039238; batch adversarial loss: 0.457589\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.474777\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076419; batch adversarial loss: 0.352175\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054848; batch adversarial loss: 0.411632\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049907; batch adversarial loss: 0.484685\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053126; batch adversarial loss: 0.402416\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069484; batch adversarial loss: 0.407298\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038043; batch adversarial loss: 0.517875\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042454; batch adversarial loss: 0.300503\n",
      "epoch 107; iter: 0; batch classifier loss: 0.105327; batch adversarial loss: 0.427752\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020932; batch adversarial loss: 0.508062\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048125; batch adversarial loss: 0.349093\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051349; batch adversarial loss: 0.421885\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066499; batch adversarial loss: 0.449532\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059475; batch adversarial loss: 0.438901\n",
      "epoch 113; iter: 0; batch classifier loss: 0.091116; batch adversarial loss: 0.449801\n",
      "epoch 114; iter: 0; batch classifier loss: 0.070503; batch adversarial loss: 0.395023\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064106; batch adversarial loss: 0.394970\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036774; batch adversarial loss: 0.424163\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044691; batch adversarial loss: 0.447616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.062652; batch adversarial loss: 0.421528\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038982; batch adversarial loss: 0.467024\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032031; batch adversarial loss: 0.417705\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049373; batch adversarial loss: 0.406772\n",
      "epoch 122; iter: 0; batch classifier loss: 0.103761; batch adversarial loss: 0.373814\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033055; batch adversarial loss: 0.435108\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026445; batch adversarial loss: 0.496471\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035957; batch adversarial loss: 0.399716\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042007; batch adversarial loss: 0.495364\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048225; batch adversarial loss: 0.468338\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032395; batch adversarial loss: 0.517311\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025467; batch adversarial loss: 0.488276\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042221; batch adversarial loss: 0.386665\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018545; batch adversarial loss: 0.467227\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022295; batch adversarial loss: 0.451968\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054207; batch adversarial loss: 0.406469\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052430; batch adversarial loss: 0.427331\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025912; batch adversarial loss: 0.414102\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042648; batch adversarial loss: 0.548056\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036127; batch adversarial loss: 0.426436\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031929; batch adversarial loss: 0.457435\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024011; batch adversarial loss: 0.545223\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055841; batch adversarial loss: 0.425563\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035124; batch adversarial loss: 0.477587\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048349; batch adversarial loss: 0.421600\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016085; batch adversarial loss: 0.385079\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041027; batch adversarial loss: 0.497313\n",
      "epoch 145; iter: 0; batch classifier loss: 0.040748; batch adversarial loss: 0.577516\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037007; batch adversarial loss: 0.426349\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033833; batch adversarial loss: 0.531547\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034917; batch adversarial loss: 0.448941\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040586; batch adversarial loss: 0.400771\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038062; batch adversarial loss: 0.364629\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022408; batch adversarial loss: 0.525952\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040967; batch adversarial loss: 0.481897\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017283; batch adversarial loss: 0.438814\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038270; batch adversarial loss: 0.432067\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022310; batch adversarial loss: 0.502305\n",
      "epoch 156; iter: 0; batch classifier loss: 0.038522; batch adversarial loss: 0.456437\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030708; batch adversarial loss: 0.388427\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010970; batch adversarial loss: 0.463999\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038659; batch adversarial loss: 0.458819\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008060; batch adversarial loss: 0.437229\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030441; batch adversarial loss: 0.424262\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052882; batch adversarial loss: 0.582598\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039853; batch adversarial loss: 0.399014\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021021; batch adversarial loss: 0.415060\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028328; batch adversarial loss: 0.408397\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052588; batch adversarial loss: 0.412163\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015022; batch adversarial loss: 0.520423\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026433; batch adversarial loss: 0.374190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033947; batch adversarial loss: 0.379269\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018032; batch adversarial loss: 0.461423\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030478; batch adversarial loss: 0.428921\n",
      "epoch 172; iter: 0; batch classifier loss: 0.053501; batch adversarial loss: 0.309938\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065301; batch adversarial loss: 0.477088\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040438; batch adversarial loss: 0.484235\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021320; batch adversarial loss: 0.505409\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016605; batch adversarial loss: 0.516631\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042970; batch adversarial loss: 0.448178\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010182; batch adversarial loss: 0.420158\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014875; batch adversarial loss: 0.444909\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014899; batch adversarial loss: 0.516250\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012975; batch adversarial loss: 0.473266\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031573; batch adversarial loss: 0.445984\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021364; batch adversarial loss: 0.453866\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027230; batch adversarial loss: 0.438260\n",
      "epoch 185; iter: 0; batch classifier loss: 0.020450; batch adversarial loss: 0.495321\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018516; batch adversarial loss: 0.356765\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041522; batch adversarial loss: 0.418922\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005678; batch adversarial loss: 0.543384\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014397; batch adversarial loss: 0.355433\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017679; batch adversarial loss: 0.416602\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017126; batch adversarial loss: 0.452003\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024878; batch adversarial loss: 0.514199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010200; batch adversarial loss: 0.504023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019495; batch adversarial loss: 0.423637\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054179; batch adversarial loss: 0.444761\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004799; batch adversarial loss: 0.502155\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015673; batch adversarial loss: 0.432085\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017202; batch adversarial loss: 0.416064\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013375; batch adversarial loss: 0.515157\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708120; batch adversarial loss: 0.785349\n",
      "epoch 1; iter: 0; batch classifier loss: 0.397619; batch adversarial loss: 0.739236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393025; batch adversarial loss: 0.685524\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339682; batch adversarial loss: 0.661003\n",
      "epoch 4; iter: 0; batch classifier loss: 0.316111; batch adversarial loss: 0.625374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.347075; batch adversarial loss: 0.613382\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404017; batch adversarial loss: 0.579521\n",
      "epoch 7; iter: 0; batch classifier loss: 0.322928; batch adversarial loss: 0.530887\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270729; batch adversarial loss: 0.538776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386408; batch adversarial loss: 0.480246\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284111; batch adversarial loss: 0.536052\n",
      "epoch 11; iter: 0; batch classifier loss: 0.203869; batch adversarial loss: 0.454422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.171076; batch adversarial loss: 0.522743\n",
      "epoch 13; iter: 0; batch classifier loss: 0.182190; batch adversarial loss: 0.470854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.201829; batch adversarial loss: 0.462547\n",
      "epoch 15; iter: 0; batch classifier loss: 0.194079; batch adversarial loss: 0.492273\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218749; batch adversarial loss: 0.490322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.204977; batch adversarial loss: 0.431468\n",
      "epoch 18; iter: 0; batch classifier loss: 0.162634; batch adversarial loss: 0.473522\n",
      "epoch 19; iter: 0; batch classifier loss: 0.151986; batch adversarial loss: 0.442238\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157966; batch adversarial loss: 0.405324\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212009; batch adversarial loss: 0.437878\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181203; batch adversarial loss: 0.482597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172472; batch adversarial loss: 0.396626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181440; batch adversarial loss: 0.425052\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158670; batch adversarial loss: 0.391266\n",
      "epoch 26; iter: 0; batch classifier loss: 0.167314; batch adversarial loss: 0.479380\n",
      "epoch 27; iter: 0; batch classifier loss: 0.130526; batch adversarial loss: 0.452201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169233; batch adversarial loss: 0.415670\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125682; batch adversarial loss: 0.438402\n",
      "epoch 30; iter: 0; batch classifier loss: 0.146490; batch adversarial loss: 0.403764\n",
      "epoch 31; iter: 0; batch classifier loss: 0.113640; batch adversarial loss: 0.395027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.172398; batch adversarial loss: 0.377591\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131694; batch adversarial loss: 0.396184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171349; batch adversarial loss: 0.349169\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162180; batch adversarial loss: 0.507696\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154120; batch adversarial loss: 0.448182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.107493; batch adversarial loss: 0.392191\n",
      "epoch 38; iter: 0; batch classifier loss: 0.185217; batch adversarial loss: 0.393010\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123737; batch adversarial loss: 0.404909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.102724; batch adversarial loss: 0.352725\n",
      "epoch 41; iter: 0; batch classifier loss: 0.083459; batch adversarial loss: 0.428380\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125358; batch adversarial loss: 0.451239\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101051; batch adversarial loss: 0.412538\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132590; batch adversarial loss: 0.400670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120446; batch adversarial loss: 0.415616\n",
      "epoch 46; iter: 0; batch classifier loss: 0.121928; batch adversarial loss: 0.423396\n",
      "epoch 47; iter: 0; batch classifier loss: 0.094891; batch adversarial loss: 0.396679\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081688; batch adversarial loss: 0.447856\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110587; batch adversarial loss: 0.502022\n",
      "epoch 50; iter: 0; batch classifier loss: 0.092289; batch adversarial loss: 0.428520\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109216; batch adversarial loss: 0.455606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072049; batch adversarial loss: 0.407530\n",
      "epoch 53; iter: 0; batch classifier loss: 0.152053; batch adversarial loss: 0.440236\n",
      "epoch 54; iter: 0; batch classifier loss: 0.071557; batch adversarial loss: 0.414142\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093968; batch adversarial loss: 0.348725\n",
      "epoch 56; iter: 0; batch classifier loss: 0.083875; batch adversarial loss: 0.376785\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079682; batch adversarial loss: 0.453316\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081774; batch adversarial loss: 0.393510\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068828; batch adversarial loss: 0.363476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.099208; batch adversarial loss: 0.458113\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055041; batch adversarial loss: 0.372970\n",
      "epoch 62; iter: 0; batch classifier loss: 0.068729; batch adversarial loss: 0.461892\n",
      "epoch 63; iter: 0; batch classifier loss: 0.051272; batch adversarial loss: 0.389904\n",
      "epoch 64; iter: 0; batch classifier loss: 0.045036; batch adversarial loss: 0.441119\n",
      "epoch 65; iter: 0; batch classifier loss: 0.050128; batch adversarial loss: 0.472336\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092689; batch adversarial loss: 0.432351\n",
      "epoch 67; iter: 0; batch classifier loss: 0.044111; batch adversarial loss: 0.398884\n",
      "epoch 68; iter: 0; batch classifier loss: 0.044305; batch adversarial loss: 0.442637\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102211; batch adversarial loss: 0.469987\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048792; batch adversarial loss: 0.435696\n",
      "epoch 71; iter: 0; batch classifier loss: 0.065480; batch adversarial loss: 0.433895\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080205; batch adversarial loss: 0.453227\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092432; batch adversarial loss: 0.451083\n",
      "epoch 74; iter: 0; batch classifier loss: 0.104341; batch adversarial loss: 0.451525\n",
      "epoch 75; iter: 0; batch classifier loss: 0.088757; batch adversarial loss: 0.435991\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072648; batch adversarial loss: 0.494977\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062468; batch adversarial loss: 0.438707\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073616; batch adversarial loss: 0.385289\n",
      "epoch 79; iter: 0; batch classifier loss: 0.089207; batch adversarial loss: 0.413593\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069745; batch adversarial loss: 0.423649\n",
      "epoch 81; iter: 0; batch classifier loss: 0.098894; batch adversarial loss: 0.379872\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084319; batch adversarial loss: 0.457732\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071913; batch adversarial loss: 0.375282\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082730; batch adversarial loss: 0.429256\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058854; batch adversarial loss: 0.476860\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054399; batch adversarial loss: 0.463770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101569; batch adversarial loss: 0.414355\n",
      "epoch 88; iter: 0; batch classifier loss: 0.097373; batch adversarial loss: 0.362203\n",
      "epoch 89; iter: 0; batch classifier loss: 0.069316; batch adversarial loss: 0.339825\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083542; batch adversarial loss: 0.381079\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061373; batch adversarial loss: 0.464522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.064062; batch adversarial loss: 0.362277\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075779; batch adversarial loss: 0.351479\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062507; batch adversarial loss: 0.412970\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044893; batch adversarial loss: 0.488505\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087344; batch adversarial loss: 0.386674\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041333; batch adversarial loss: 0.441954\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074275; batch adversarial loss: 0.484238\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098290; batch adversarial loss: 0.491729\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075106; batch adversarial loss: 0.436587\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048600; batch adversarial loss: 0.399186\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043935; batch adversarial loss: 0.356452\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060591; batch adversarial loss: 0.467111\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054557; batch adversarial loss: 0.470865\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040373; batch adversarial loss: 0.540569\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062633; batch adversarial loss: 0.410945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055294; batch adversarial loss: 0.428685\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068012; batch adversarial loss: 0.481926\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053963; batch adversarial loss: 0.439659\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048941; batch adversarial loss: 0.451354\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081681; batch adversarial loss: 0.415065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.062809; batch adversarial loss: 0.347037\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061252; batch adversarial loss: 0.404488\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060953; batch adversarial loss: 0.374161\n",
      "epoch 115; iter: 0; batch classifier loss: 0.026153; batch adversarial loss: 0.365653\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038219; batch adversarial loss: 0.485627\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060267; batch adversarial loss: 0.536610\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050822; batch adversarial loss: 0.467746\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044833; batch adversarial loss: 0.489857\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068134; batch adversarial loss: 0.412932\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030158; batch adversarial loss: 0.409880\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043418; batch adversarial loss: 0.366563\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061958; batch adversarial loss: 0.492125\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026044; batch adversarial loss: 0.468090\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038792; batch adversarial loss: 0.423601\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047645; batch adversarial loss: 0.394660\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042262; batch adversarial loss: 0.438141\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029905; batch adversarial loss: 0.456105\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041503; batch adversarial loss: 0.534394\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053463; batch adversarial loss: 0.471851\n",
      "epoch 131; iter: 0; batch classifier loss: 0.063150; batch adversarial loss: 0.460743\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040145; batch adversarial loss: 0.446486\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046334; batch adversarial loss: 0.492044\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045583; batch adversarial loss: 0.597162\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018020; batch adversarial loss: 0.403516\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030549; batch adversarial loss: 0.429868\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032563; batch adversarial loss: 0.402822\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029474; batch adversarial loss: 0.408361\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034682; batch adversarial loss: 0.493744\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038514; batch adversarial loss: 0.445198\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047938; batch adversarial loss: 0.510023\n",
      "epoch 142; iter: 0; batch classifier loss: 0.033612; batch adversarial loss: 0.429332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062157; batch adversarial loss: 0.444316\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021734; batch adversarial loss: 0.484495\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017804; batch adversarial loss: 0.415624\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054733; batch adversarial loss: 0.508927\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027840; batch adversarial loss: 0.480012\n",
      "epoch 148; iter: 0; batch classifier loss: 0.044581; batch adversarial loss: 0.406811\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063054; batch adversarial loss: 0.491843\n",
      "epoch 150; iter: 0; batch classifier loss: 0.078739; batch adversarial loss: 0.565887\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035046; batch adversarial loss: 0.418472\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062184; batch adversarial loss: 0.599313\n",
      "epoch 153; iter: 0; batch classifier loss: 0.120183; batch adversarial loss: 0.718636\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059000; batch adversarial loss: 0.532817\n",
      "epoch 155; iter: 0; batch classifier loss: 0.138883; batch adversarial loss: 0.586276\n",
      "epoch 156; iter: 0; batch classifier loss: 0.195774; batch adversarial loss: 0.719126\n",
      "epoch 157; iter: 0; batch classifier loss: 0.166038; batch adversarial loss: 0.792903\n",
      "epoch 158; iter: 0; batch classifier loss: 0.125380; batch adversarial loss: 0.580477\n",
      "epoch 159; iter: 0; batch classifier loss: 0.205727; batch adversarial loss: 0.770986\n",
      "epoch 160; iter: 0; batch classifier loss: 0.148279; batch adversarial loss: 0.725082\n",
      "epoch 161; iter: 0; batch classifier loss: 0.175558; batch adversarial loss: 0.671316\n",
      "epoch 162; iter: 0; batch classifier loss: 0.174022; batch adversarial loss: 0.762612\n",
      "epoch 163; iter: 0; batch classifier loss: 0.201451; batch adversarial loss: 0.639554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.138529; batch adversarial loss: 0.655063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.192480; batch adversarial loss: 0.706692\n",
      "epoch 166; iter: 0; batch classifier loss: 0.142016; batch adversarial loss: 0.620868\n",
      "epoch 167; iter: 0; batch classifier loss: 0.211995; batch adversarial loss: 0.684190\n",
      "epoch 168; iter: 0; batch classifier loss: 0.261564; batch adversarial loss: 0.795155\n",
      "epoch 169; iter: 0; batch classifier loss: 0.152679; batch adversarial loss: 0.596734\n",
      "epoch 170; iter: 0; batch classifier loss: 0.250079; batch adversarial loss: 0.780124\n",
      "epoch 171; iter: 0; batch classifier loss: 0.165738; batch adversarial loss: 0.527249\n",
      "epoch 172; iter: 0; batch classifier loss: 0.141277; batch adversarial loss: 0.570134\n",
      "epoch 173; iter: 0; batch classifier loss: 0.158984; batch adversarial loss: 0.568604\n",
      "epoch 174; iter: 0; batch classifier loss: 0.193071; batch adversarial loss: 0.641184\n",
      "epoch 175; iter: 0; batch classifier loss: 0.173265; batch adversarial loss: 0.499427\n",
      "epoch 176; iter: 0; batch classifier loss: 0.117368; batch adversarial loss: 0.523230\n",
      "epoch 177; iter: 0; batch classifier loss: 0.138541; batch adversarial loss: 0.522833\n",
      "epoch 178; iter: 0; batch classifier loss: 0.183523; batch adversarial loss: 0.694035\n",
      "epoch 179; iter: 0; batch classifier loss: 0.128186; batch adversarial loss: 0.520983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.171670; batch adversarial loss: 0.585697\n",
      "epoch 181; iter: 0; batch classifier loss: 0.239856; batch adversarial loss: 0.612641\n",
      "epoch 182; iter: 0; batch classifier loss: 0.145855; batch adversarial loss: 0.547001\n",
      "epoch 183; iter: 0; batch classifier loss: 0.161224; batch adversarial loss: 0.644280\n",
      "epoch 184; iter: 0; batch classifier loss: 0.126182; batch adversarial loss: 0.479857\n",
      "epoch 185; iter: 0; batch classifier loss: 0.185361; batch adversarial loss: 0.602025\n",
      "epoch 186; iter: 0; batch classifier loss: 0.199770; batch adversarial loss: 0.596878\n",
      "epoch 187; iter: 0; batch classifier loss: 0.154945; batch adversarial loss: 0.514684\n",
      "epoch 188; iter: 0; batch classifier loss: 0.119653; batch adversarial loss: 0.464614\n",
      "epoch 189; iter: 0; batch classifier loss: 0.152644; batch adversarial loss: 0.529894\n",
      "epoch 190; iter: 0; batch classifier loss: 0.210830; batch adversarial loss: 0.598444\n",
      "epoch 191; iter: 0; batch classifier loss: 0.172761; batch adversarial loss: 0.611596\n",
      "epoch 192; iter: 0; batch classifier loss: 0.104343; batch adversarial loss: 0.467442\n",
      "epoch 193; iter: 0; batch classifier loss: 0.143342; batch adversarial loss: 0.474384\n",
      "epoch 194; iter: 0; batch classifier loss: 0.130185; batch adversarial loss: 0.480125\n",
      "epoch 195; iter: 0; batch classifier loss: 0.114716; batch adversarial loss: 0.437356\n",
      "epoch 196; iter: 0; batch classifier loss: 0.107647; batch adversarial loss: 0.432523\n",
      "epoch 197; iter: 0; batch classifier loss: 0.158909; batch adversarial loss: 0.467271\n",
      "epoch 198; iter: 0; batch classifier loss: 0.091637; batch adversarial loss: 0.373426\n",
      "epoch 199; iter: 0; batch classifier loss: 0.083639; batch adversarial loss: 0.456252\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697246; batch adversarial loss: 1.331262\n",
      "epoch 1; iter: 0; batch classifier loss: 0.891818; batch adversarial loss: 1.745366\n",
      "epoch 2; iter: 0; batch classifier loss: 0.987507; batch adversarial loss: 1.693864\n",
      "epoch 3; iter: 0; batch classifier loss: 1.325744; batch adversarial loss: 1.619036\n",
      "epoch 4; iter: 0; batch classifier loss: 1.377810; batch adversarial loss: 1.503805\n",
      "epoch 5; iter: 0; batch classifier loss: 1.141888; batch adversarial loss: 1.316171\n",
      "epoch 6; iter: 0; batch classifier loss: 1.300266; batch adversarial loss: 1.228448\n",
      "epoch 7; iter: 0; batch classifier loss: 1.420826; batch adversarial loss: 1.126304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 1.504642; batch adversarial loss: 1.040375\n",
      "epoch 9; iter: 0; batch classifier loss: 1.249084; batch adversarial loss: 0.941500\n",
      "epoch 10; iter: 0; batch classifier loss: 1.415203; batch adversarial loss: 0.863256\n",
      "epoch 11; iter: 0; batch classifier loss: 1.315709; batch adversarial loss: 0.802109\n",
      "epoch 12; iter: 0; batch classifier loss: 1.216863; batch adversarial loss: 0.741569\n",
      "epoch 13; iter: 0; batch classifier loss: 1.153992; batch adversarial loss: 0.668981\n",
      "epoch 14; iter: 0; batch classifier loss: 1.319363; batch adversarial loss: 0.625530\n",
      "epoch 15; iter: 0; batch classifier loss: 1.229222; batch adversarial loss: 0.598103\n",
      "epoch 16; iter: 0; batch classifier loss: 1.010186; batch adversarial loss: 0.607697\n",
      "epoch 17; iter: 0; batch classifier loss: 1.150806; batch adversarial loss: 0.561954\n",
      "epoch 18; iter: 0; batch classifier loss: 1.175445; batch adversarial loss: 0.523574\n",
      "epoch 19; iter: 0; batch classifier loss: 0.837118; batch adversarial loss: 0.556168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483405; batch adversarial loss: 0.511102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365836; batch adversarial loss: 0.478563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275804; batch adversarial loss: 0.499370\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258918; batch adversarial loss: 0.422150\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239436; batch adversarial loss: 0.486781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199207; batch adversarial loss: 0.408930\n",
      "epoch 26; iter: 0; batch classifier loss: 0.273702; batch adversarial loss: 0.558694\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212455; batch adversarial loss: 0.502833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211616; batch adversarial loss: 0.464769\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174584; batch adversarial loss: 0.471228\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216998; batch adversarial loss: 0.447472\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151304; batch adversarial loss: 0.537337\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206185; batch adversarial loss: 0.506130\n",
      "epoch 33; iter: 0; batch classifier loss: 0.192100; batch adversarial loss: 0.425703\n",
      "epoch 34; iter: 0; batch classifier loss: 0.211964; batch adversarial loss: 0.483951\n",
      "epoch 35; iter: 0; batch classifier loss: 0.273733; batch adversarial loss: 0.465704\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241946; batch adversarial loss: 0.481240\n",
      "epoch 37; iter: 0; batch classifier loss: 0.183352; batch adversarial loss: 0.466843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.173335; batch adversarial loss: 0.472567\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174261; batch adversarial loss: 0.511436\n",
      "epoch 40; iter: 0; batch classifier loss: 0.308015; batch adversarial loss: 0.445363\n",
      "epoch 41; iter: 0; batch classifier loss: 0.181988; batch adversarial loss: 0.474234\n",
      "epoch 42; iter: 0; batch classifier loss: 0.250238; batch adversarial loss: 0.481151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.259646; batch adversarial loss: 0.437364\n",
      "epoch 44; iter: 0; batch classifier loss: 0.249765; batch adversarial loss: 0.441740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.220720; batch adversarial loss: 0.506977\n",
      "epoch 46; iter: 0; batch classifier loss: 0.186938; batch adversarial loss: 0.442365\n",
      "epoch 47; iter: 0; batch classifier loss: 0.262907; batch adversarial loss: 0.377565\n",
      "epoch 48; iter: 0; batch classifier loss: 0.190860; batch adversarial loss: 0.480788\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206752; batch adversarial loss: 0.413623\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226967; batch adversarial loss: 0.487698\n",
      "epoch 51; iter: 0; batch classifier loss: 0.196265; batch adversarial loss: 0.503016\n",
      "epoch 52; iter: 0; batch classifier loss: 0.212382; batch adversarial loss: 0.474807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.181860; batch adversarial loss: 0.513716\n",
      "epoch 54; iter: 0; batch classifier loss: 0.214260; batch adversarial loss: 0.496558\n",
      "epoch 55; iter: 0; batch classifier loss: 0.176012; batch adversarial loss: 0.412745\n",
      "epoch 56; iter: 0; batch classifier loss: 0.151418; batch adversarial loss: 0.477238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210886; batch adversarial loss: 0.415354\n",
      "epoch 58; iter: 0; batch classifier loss: 0.225465; batch adversarial loss: 0.421978\n",
      "epoch 59; iter: 0; batch classifier loss: 0.240595; batch adversarial loss: 0.412919\n",
      "epoch 60; iter: 0; batch classifier loss: 0.207200; batch adversarial loss: 0.478487\n",
      "epoch 61; iter: 0; batch classifier loss: 0.192239; batch adversarial loss: 0.533327\n",
      "epoch 62; iter: 0; batch classifier loss: 0.146192; batch adversarial loss: 0.437147\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196200; batch adversarial loss: 0.445704\n",
      "epoch 64; iter: 0; batch classifier loss: 0.151558; batch adversarial loss: 0.569515\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.383864\n",
      "epoch 66; iter: 0; batch classifier loss: 0.147685; batch adversarial loss: 0.503994\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171597; batch adversarial loss: 0.460162\n",
      "epoch 68; iter: 0; batch classifier loss: 0.178131; batch adversarial loss: 0.398089\n",
      "epoch 69; iter: 0; batch classifier loss: 0.199809; batch adversarial loss: 0.437553\n",
      "epoch 70; iter: 0; batch classifier loss: 0.170284; batch adversarial loss: 0.482673\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222877; batch adversarial loss: 0.372791\n",
      "epoch 72; iter: 0; batch classifier loss: 0.171397; batch adversarial loss: 0.375591\n",
      "epoch 73; iter: 0; batch classifier loss: 0.133331; batch adversarial loss: 0.450118\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166100; batch adversarial loss: 0.469749\n",
      "epoch 75; iter: 0; batch classifier loss: 0.185133; batch adversarial loss: 0.443926\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138272; batch adversarial loss: 0.485097\n",
      "epoch 77; iter: 0; batch classifier loss: 0.184309; batch adversarial loss: 0.436424\n",
      "epoch 78; iter: 0; batch classifier loss: 0.217617; batch adversarial loss: 0.374250\n",
      "epoch 79; iter: 0; batch classifier loss: 0.141664; batch adversarial loss: 0.482160\n",
      "epoch 80; iter: 0; batch classifier loss: 0.197977; batch adversarial loss: 0.398633\n",
      "epoch 81; iter: 0; batch classifier loss: 0.228792; batch adversarial loss: 0.385148\n",
      "epoch 82; iter: 0; batch classifier loss: 0.182235; batch adversarial loss: 0.510881\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154370; batch adversarial loss: 0.457620\n",
      "epoch 84; iter: 0; batch classifier loss: 0.172131; batch adversarial loss: 0.561592\n",
      "epoch 85; iter: 0; batch classifier loss: 0.188891; batch adversarial loss: 0.360973\n",
      "epoch 86; iter: 0; batch classifier loss: 0.145753; batch adversarial loss: 0.593870\n",
      "epoch 87; iter: 0; batch classifier loss: 0.186964; batch adversarial loss: 0.421277\n",
      "epoch 88; iter: 0; batch classifier loss: 0.162692; batch adversarial loss: 0.506194\n",
      "epoch 89; iter: 0; batch classifier loss: 0.167946; batch adversarial loss: 0.431753\n",
      "epoch 90; iter: 0; batch classifier loss: 0.151914; batch adversarial loss: 0.385826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.200302; batch adversarial loss: 0.457554\n",
      "epoch 92; iter: 0; batch classifier loss: 0.160238; batch adversarial loss: 0.459060\n",
      "epoch 93; iter: 0; batch classifier loss: 0.237433; batch adversarial loss: 0.448196\n",
      "epoch 94; iter: 0; batch classifier loss: 0.203907; batch adversarial loss: 0.471042\n",
      "epoch 95; iter: 0; batch classifier loss: 0.151916; batch adversarial loss: 0.383985\n",
      "epoch 96; iter: 0; batch classifier loss: 0.170599; batch adversarial loss: 0.508765\n",
      "epoch 97; iter: 0; batch classifier loss: 0.156632; batch adversarial loss: 0.411741\n",
      "epoch 98; iter: 0; batch classifier loss: 0.241762; batch adversarial loss: 0.470953\n",
      "epoch 99; iter: 0; batch classifier loss: 0.154615; batch adversarial loss: 0.472476\n",
      "epoch 100; iter: 0; batch classifier loss: 0.234315; batch adversarial loss: 0.484120\n",
      "epoch 101; iter: 0; batch classifier loss: 0.180399; batch adversarial loss: 0.421738\n",
      "epoch 102; iter: 0; batch classifier loss: 0.189570; batch adversarial loss: 0.593460\n",
      "epoch 103; iter: 0; batch classifier loss: 0.207823; batch adversarial loss: 0.348253\n",
      "epoch 104; iter: 0; batch classifier loss: 0.158563; batch adversarial loss: 0.396526\n",
      "epoch 105; iter: 0; batch classifier loss: 0.173244; batch adversarial loss: 0.447017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.170397; batch adversarial loss: 0.520784\n",
      "epoch 107; iter: 0; batch classifier loss: 0.172554; batch adversarial loss: 0.533087\n",
      "epoch 108; iter: 0; batch classifier loss: 0.195375; batch adversarial loss: 0.483589\n",
      "epoch 109; iter: 0; batch classifier loss: 0.242952; batch adversarial loss: 0.471148\n",
      "epoch 110; iter: 0; batch classifier loss: 0.162679; batch adversarial loss: 0.520643\n",
      "epoch 111; iter: 0; batch classifier loss: 0.118781; batch adversarial loss: 0.421855\n",
      "epoch 112; iter: 0; batch classifier loss: 0.146092; batch adversarial loss: 0.459295\n",
      "epoch 113; iter: 0; batch classifier loss: 0.105664; batch adversarial loss: 0.446983\n",
      "epoch 114; iter: 0; batch classifier loss: 0.143034; batch adversarial loss: 0.482748\n",
      "epoch 115; iter: 0; batch classifier loss: 0.182353; batch adversarial loss: 0.472422\n",
      "epoch 116; iter: 0; batch classifier loss: 0.175449; batch adversarial loss: 0.480245\n",
      "epoch 117; iter: 0; batch classifier loss: 0.235239; batch adversarial loss: 0.435506\n",
      "epoch 118; iter: 0; batch classifier loss: 0.196330; batch adversarial loss: 0.434564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.156033; batch adversarial loss: 0.558470\n",
      "epoch 120; iter: 0; batch classifier loss: 0.151206; batch adversarial loss: 0.398043\n",
      "epoch 121; iter: 0; batch classifier loss: 0.173024; batch adversarial loss: 0.520446\n",
      "epoch 122; iter: 0; batch classifier loss: 0.221482; batch adversarial loss: 0.445819\n",
      "epoch 123; iter: 0; batch classifier loss: 0.189413; batch adversarial loss: 0.358572\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144659; batch adversarial loss: 0.459359\n",
      "epoch 125; iter: 0; batch classifier loss: 0.188624; batch adversarial loss: 0.470957\n",
      "epoch 126; iter: 0; batch classifier loss: 0.186646; batch adversarial loss: 0.446973\n",
      "epoch 127; iter: 0; batch classifier loss: 0.101591; batch adversarial loss: 0.507859\n",
      "epoch 128; iter: 0; batch classifier loss: 0.125670; batch adversarial loss: 0.532430\n",
      "epoch 129; iter: 0; batch classifier loss: 0.212589; batch adversarial loss: 0.471931\n",
      "epoch 130; iter: 0; batch classifier loss: 0.176260; batch adversarial loss: 0.422026\n",
      "epoch 131; iter: 0; batch classifier loss: 0.213875; batch adversarial loss: 0.421289\n",
      "epoch 132; iter: 0; batch classifier loss: 0.174843; batch adversarial loss: 0.420972\n",
      "epoch 133; iter: 0; batch classifier loss: 0.205645; batch adversarial loss: 0.483448\n",
      "epoch 134; iter: 0; batch classifier loss: 0.104507; batch adversarial loss: 0.545370\n",
      "epoch 135; iter: 0; batch classifier loss: 0.133562; batch adversarial loss: 0.521064\n",
      "epoch 136; iter: 0; batch classifier loss: 0.237042; batch adversarial loss: 0.471006\n",
      "epoch 137; iter: 0; batch classifier loss: 0.152228; batch adversarial loss: 0.532865\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072263; batch adversarial loss: 0.482340\n",
      "epoch 139; iter: 0; batch classifier loss: 0.066094; batch adversarial loss: 0.471450\n",
      "epoch 140; iter: 0; batch classifier loss: 0.107307; batch adversarial loss: 0.444097\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051400; batch adversarial loss: 0.405180\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048135; batch adversarial loss: 0.472628\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062496; batch adversarial loss: 0.431129\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036407; batch adversarial loss: 0.481115\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035352; batch adversarial loss: 0.456409\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040927; batch adversarial loss: 0.393324\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041636; batch adversarial loss: 0.452410\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072899; batch adversarial loss: 0.374469\n",
      "epoch 149; iter: 0; batch classifier loss: 0.055766; batch adversarial loss: 0.443918\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023206; batch adversarial loss: 0.449859\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026307; batch adversarial loss: 0.436344\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023747; batch adversarial loss: 0.459457\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031706; batch adversarial loss: 0.519517\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037935; batch adversarial loss: 0.499155\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035815; batch adversarial loss: 0.365414\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036066; batch adversarial loss: 0.517122\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030308; batch adversarial loss: 0.472863\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021757; batch adversarial loss: 0.455030\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044396; batch adversarial loss: 0.390894\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028692; batch adversarial loss: 0.418140\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053941; batch adversarial loss: 0.499291\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019986; batch adversarial loss: 0.432328\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028926; batch adversarial loss: 0.449370\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027871; batch adversarial loss: 0.447659\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028218; batch adversarial loss: 0.408841\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027987; batch adversarial loss: 0.481895\n",
      "epoch 167; iter: 0; batch classifier loss: 0.075195; batch adversarial loss: 0.455530\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033136; batch adversarial loss: 0.392864\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039865; batch adversarial loss: 0.381048\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023046; batch adversarial loss: 0.432006\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030343; batch adversarial loss: 0.401596\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036887; batch adversarial loss: 0.510259\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038700; batch adversarial loss: 0.497175\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009886; batch adversarial loss: 0.589661\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024099; batch adversarial loss: 0.379397\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035581; batch adversarial loss: 0.467822\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014943; batch adversarial loss: 0.479247\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025555; batch adversarial loss: 0.381972\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035309; batch adversarial loss: 0.494732\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036708; batch adversarial loss: 0.431776\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018670; batch adversarial loss: 0.437676\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025646; batch adversarial loss: 0.399654\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019283; batch adversarial loss: 0.488897\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024294; batch adversarial loss: 0.502005\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032958; batch adversarial loss: 0.488865\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028775; batch adversarial loss: 0.492615\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029767; batch adversarial loss: 0.456388\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037875; batch adversarial loss: 0.472066\n",
      "epoch 189; iter: 0; batch classifier loss: 0.082439; batch adversarial loss: 0.443173\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006915; batch adversarial loss: 0.513433\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021998; batch adversarial loss: 0.417838\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028961; batch adversarial loss: 0.371157\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.540502\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011511; batch adversarial loss: 0.450332\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023465; batch adversarial loss: 0.552128\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023177; batch adversarial loss: 0.513408\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021388; batch adversarial loss: 0.432206\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037070; batch adversarial loss: 0.347569\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003664; batch adversarial loss: 0.544368\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693283; batch adversarial loss: 0.636277\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463337; batch adversarial loss: 0.640175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.419954; batch adversarial loss: 0.613963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.498297; batch adversarial loss: 0.592448\n",
      "epoch 4; iter: 0; batch classifier loss: 0.449352; batch adversarial loss: 0.620578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422856; batch adversarial loss: 0.608819\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476313; batch adversarial loss: 0.562122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530362; batch adversarial loss: 0.594617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519569; batch adversarial loss: 0.531497\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479077; batch adversarial loss: 0.589399\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394453; batch adversarial loss: 0.528696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341213; batch adversarial loss: 0.504309\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284256; batch adversarial loss: 0.529226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374142; batch adversarial loss: 0.426975\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304905; batch adversarial loss: 0.503234\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360273; batch adversarial loss: 0.501339\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322051; batch adversarial loss: 0.540592\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395556; batch adversarial loss: 0.505841\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362555; batch adversarial loss: 0.461331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266259; batch adversarial loss: 0.484799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295786; batch adversarial loss: 0.530379\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275202; batch adversarial loss: 0.514246\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354683; batch adversarial loss: 0.459705\n",
      "epoch 23; iter: 0; batch classifier loss: 0.350229; batch adversarial loss: 0.415000\n",
      "epoch 24; iter: 0; batch classifier loss: 0.310611; batch adversarial loss: 0.420373\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331288; batch adversarial loss: 0.472611\n",
      "epoch 26; iter: 0; batch classifier loss: 0.301103; batch adversarial loss: 0.471150\n",
      "epoch 27; iter: 0; batch classifier loss: 0.314142; batch adversarial loss: 0.412725\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335826; batch adversarial loss: 0.428048\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266278; batch adversarial loss: 0.478847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279206; batch adversarial loss: 0.482252\n",
      "epoch 31; iter: 0; batch classifier loss: 0.263820; batch adversarial loss: 0.511135\n",
      "epoch 32; iter: 0; batch classifier loss: 0.218597; batch adversarial loss: 0.467644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.237680; batch adversarial loss: 0.452225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.264113; batch adversarial loss: 0.485113\n",
      "epoch 35; iter: 0; batch classifier loss: 0.250491; batch adversarial loss: 0.411516\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305049; batch adversarial loss: 0.434332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273143; batch adversarial loss: 0.428217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.298192; batch adversarial loss: 0.473789\n",
      "epoch 39; iter: 0; batch classifier loss: 0.286052; batch adversarial loss: 0.462602\n",
      "epoch 40; iter: 0; batch classifier loss: 0.280565; batch adversarial loss: 0.482410\n",
      "epoch 41; iter: 0; batch classifier loss: 0.281058; batch adversarial loss: 0.366718\n",
      "epoch 42; iter: 0; batch classifier loss: 0.257646; batch adversarial loss: 0.459773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247004; batch adversarial loss: 0.435871\n",
      "epoch 44; iter: 0; batch classifier loss: 0.123980; batch adversarial loss: 0.375221\n",
      "epoch 45; iter: 0; batch classifier loss: 0.132727; batch adversarial loss: 0.543647\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266132; batch adversarial loss: 0.473054\n",
      "epoch 47; iter: 0; batch classifier loss: 0.155961; batch adversarial loss: 0.385835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.213121; batch adversarial loss: 0.444101\n",
      "epoch 49; iter: 0; batch classifier loss: 0.262590; batch adversarial loss: 0.411308\n",
      "epoch 50; iter: 0; batch classifier loss: 0.153220; batch adversarial loss: 0.323927\n",
      "epoch 51; iter: 0; batch classifier loss: 0.139265; batch adversarial loss: 0.493715\n",
      "epoch 52; iter: 0; batch classifier loss: 0.237391; batch adversarial loss: 0.519416\n",
      "epoch 53; iter: 0; batch classifier loss: 0.164875; batch adversarial loss: 0.457701\n",
      "epoch 54; iter: 0; batch classifier loss: 0.193211; batch adversarial loss: 0.521606\n",
      "epoch 55; iter: 0; batch classifier loss: 0.166924; batch adversarial loss: 0.409842\n",
      "epoch 56; iter: 0; batch classifier loss: 0.101704; batch adversarial loss: 0.532840\n",
      "epoch 57; iter: 0; batch classifier loss: 0.255071; batch adversarial loss: 0.334646\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178809; batch adversarial loss: 0.546194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.165645; batch adversarial loss: 0.533552\n",
      "epoch 60; iter: 0; batch classifier loss: 0.214153; batch adversarial loss: 0.421679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111189; batch adversarial loss: 0.532297\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064089; batch adversarial loss: 0.359579\n",
      "epoch 63; iter: 0; batch classifier loss: 0.111147; batch adversarial loss: 0.433181\n",
      "epoch 64; iter: 0; batch classifier loss: 0.160922; batch adversarial loss: 0.397241\n",
      "epoch 65; iter: 0; batch classifier loss: 0.251329; batch adversarial loss: 0.484862\n",
      "epoch 66; iter: 0; batch classifier loss: 0.206084; batch adversarial loss: 0.397117\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133887; batch adversarial loss: 0.560990\n",
      "epoch 68; iter: 0; batch classifier loss: 0.243667; batch adversarial loss: 0.469755\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152155; batch adversarial loss: 0.496989\n",
      "epoch 70; iter: 0; batch classifier loss: 0.279294; batch adversarial loss: 0.446748\n",
      "epoch 71; iter: 0; batch classifier loss: 0.212924; batch adversarial loss: 0.422010\n",
      "epoch 72; iter: 0; batch classifier loss: 0.213185; batch adversarial loss: 0.434352\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089362; batch adversarial loss: 0.383707\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084061; batch adversarial loss: 0.432367\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067058; batch adversarial loss: 0.365046\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073652; batch adversarial loss: 0.388555\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055661; batch adversarial loss: 0.457538\n",
      "epoch 78; iter: 0; batch classifier loss: 0.040104; batch adversarial loss: 0.447949\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056680; batch adversarial loss: 0.347372\n",
      "epoch 80; iter: 0; batch classifier loss: 0.088506; batch adversarial loss: 0.520631\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090133; batch adversarial loss: 0.466661\n",
      "epoch 82; iter: 0; batch classifier loss: 0.041694; batch adversarial loss: 0.500736\n",
      "epoch 83; iter: 0; batch classifier loss: 0.058491; batch adversarial loss: 0.421585\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060328; batch adversarial loss: 0.463489\n",
      "epoch 85; iter: 0; batch classifier loss: 0.106015; batch adversarial loss: 0.559452\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102598; batch adversarial loss: 0.604669\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054975; batch adversarial loss: 0.387877\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064725; batch adversarial loss: 0.407345\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040967; batch adversarial loss: 0.443303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.068633; batch adversarial loss: 0.437385\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073766; batch adversarial loss: 0.434870\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060670; batch adversarial loss: 0.521578\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058282; batch adversarial loss: 0.295314\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066261; batch adversarial loss: 0.441575\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092172; batch adversarial loss: 0.438079\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072314; batch adversarial loss: 0.411715\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055921; batch adversarial loss: 0.485797\n",
      "epoch 98; iter: 0; batch classifier loss: 0.052784; batch adversarial loss: 0.428684\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051248; batch adversarial loss: 0.384356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.048813; batch adversarial loss: 0.378291\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062856; batch adversarial loss: 0.442974\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057376; batch adversarial loss: 0.472653\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035316; batch adversarial loss: 0.434982\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061686; batch adversarial loss: 0.382612\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055076; batch adversarial loss: 0.483814\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067490; batch adversarial loss: 0.407858\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065122; batch adversarial loss: 0.391550\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071643; batch adversarial loss: 0.385321\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055259; batch adversarial loss: 0.407983\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049093; batch adversarial loss: 0.418186\n",
      "epoch 111; iter: 0; batch classifier loss: 0.086950; batch adversarial loss: 0.468884\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092956; batch adversarial loss: 0.337948\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068667; batch adversarial loss: 0.504093\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071860; batch adversarial loss: 0.353152\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063356; batch adversarial loss: 0.343361\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056465; batch adversarial loss: 0.499405\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085548; batch adversarial loss: 0.425883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.074993; batch adversarial loss: 0.450208\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054552; batch adversarial loss: 0.423354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.107460; batch adversarial loss: 0.447232\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068183; batch adversarial loss: 0.454208\n",
      "epoch 122; iter: 0; batch classifier loss: 0.113821; batch adversarial loss: 0.392379\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044779; batch adversarial loss: 0.337754\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042073; batch adversarial loss: 0.436586\n",
      "epoch 125; iter: 0; batch classifier loss: 0.094073; batch adversarial loss: 0.437857\n",
      "epoch 126; iter: 0; batch classifier loss: 0.052774; batch adversarial loss: 0.348010\n",
      "epoch 127; iter: 0; batch classifier loss: 0.055546; batch adversarial loss: 0.400555\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047710; batch adversarial loss: 0.465861\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052571; batch adversarial loss: 0.444855\n",
      "epoch 130; iter: 0; batch classifier loss: 0.065779; batch adversarial loss: 0.400961\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071760; batch adversarial loss: 0.394044\n",
      "epoch 132; iter: 0; batch classifier loss: 0.099624; batch adversarial loss: 0.533426\n",
      "epoch 133; iter: 0; batch classifier loss: 0.084009; batch adversarial loss: 0.445548\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062887; batch adversarial loss: 0.526809\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045742; batch adversarial loss: 0.456327\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074660; batch adversarial loss: 0.397601\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.341932\n",
      "epoch 138; iter: 0; batch classifier loss: 0.054328; batch adversarial loss: 0.370236\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054196; batch adversarial loss: 0.427831\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047596; batch adversarial loss: 0.440096\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040548; batch adversarial loss: 0.376613\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045314; batch adversarial loss: 0.333876\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053992; batch adversarial loss: 0.432320\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056702; batch adversarial loss: 0.436094\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046090; batch adversarial loss: 0.388309\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054011; batch adversarial loss: 0.351540\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062754; batch adversarial loss: 0.418360\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049724; batch adversarial loss: 0.499074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.066961; batch adversarial loss: 0.450538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.050754; batch adversarial loss: 0.439371\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059107; batch adversarial loss: 0.459229\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061005; batch adversarial loss: 0.488346\n",
      "epoch 153; iter: 0; batch classifier loss: 0.078383; batch adversarial loss: 0.428790\n",
      "epoch 154; iter: 0; batch classifier loss: 0.058189; batch adversarial loss: 0.440364\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049804; batch adversarial loss: 0.520891\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043669; batch adversarial loss: 0.435478\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051687; batch adversarial loss: 0.387176\n",
      "epoch 158; iter: 0; batch classifier loss: 0.049062; batch adversarial loss: 0.405029\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022692; batch adversarial loss: 0.391049\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036014; batch adversarial loss: 0.541042\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037387; batch adversarial loss: 0.448735\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018592; batch adversarial loss: 0.394625\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039419; batch adversarial loss: 0.494819\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046918; batch adversarial loss: 0.409378\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037637; batch adversarial loss: 0.488523\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036127; batch adversarial loss: 0.436012\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026403; batch adversarial loss: 0.416865\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042935; batch adversarial loss: 0.526834\n",
      "epoch 169; iter: 0; batch classifier loss: 0.062343; batch adversarial loss: 0.426668\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029802; batch adversarial loss: 0.511215\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029406; batch adversarial loss: 0.391341\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022286; batch adversarial loss: 0.381411\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027579; batch adversarial loss: 0.473117\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027169; batch adversarial loss: 0.420509\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024488; batch adversarial loss: 0.481876\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035506; batch adversarial loss: 0.459000\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046388; batch adversarial loss: 0.465708\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037730; batch adversarial loss: 0.455980\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031278; batch adversarial loss: 0.477227\n",
      "epoch 180; iter: 0; batch classifier loss: 0.018238; batch adversarial loss: 0.394079\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039530; batch adversarial loss: 0.437218\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040473; batch adversarial loss: 0.410249\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021758; batch adversarial loss: 0.309232\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020629; batch adversarial loss: 0.456939\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022952; batch adversarial loss: 0.350567\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011640; batch adversarial loss: 0.532409\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033265; batch adversarial loss: 0.525795\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019612; batch adversarial loss: 0.504036\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036818; batch adversarial loss: 0.445864\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023565; batch adversarial loss: 0.443348\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037728; batch adversarial loss: 0.464655\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041886; batch adversarial loss: 0.442087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028726; batch adversarial loss: 0.402682\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010435; batch adversarial loss: 0.376065\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034716; batch adversarial loss: 0.391934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.032064; batch adversarial loss: 0.424092\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015998; batch adversarial loss: 0.452891\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012962; batch adversarial loss: 0.489834\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010693; batch adversarial loss: 0.419056\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694158; batch adversarial loss: 0.787502\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384265; batch adversarial loss: 0.761956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.386932; batch adversarial loss: 0.740819\n",
      "epoch 3; iter: 0; batch classifier loss: 0.357774; batch adversarial loss: 0.678472\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335111; batch adversarial loss: 0.647845\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327242; batch adversarial loss: 0.602366\n",
      "epoch 6; iter: 0; batch classifier loss: 0.268574; batch adversarial loss: 0.600687\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296516; batch adversarial loss: 0.567458\n",
      "epoch 8; iter: 0; batch classifier loss: 0.363564; batch adversarial loss: 0.570209\n",
      "epoch 9; iter: 0; batch classifier loss: 0.285206; batch adversarial loss: 0.524824\n",
      "epoch 10; iter: 0; batch classifier loss: 0.318882; batch adversarial loss: 0.524010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347885; batch adversarial loss: 0.489701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.259166; batch adversarial loss: 0.503949\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265992; batch adversarial loss: 0.439414\n",
      "epoch 14; iter: 0; batch classifier loss: 0.156532; batch adversarial loss: 0.387893\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224135; batch adversarial loss: 0.438218\n",
      "epoch 16; iter: 0; batch classifier loss: 0.163836; batch adversarial loss: 0.447129\n",
      "epoch 17; iter: 0; batch classifier loss: 0.205967; batch adversarial loss: 0.456962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.161587; batch adversarial loss: 0.495524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.203699; batch adversarial loss: 0.407281\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201855; batch adversarial loss: 0.376242\n",
      "epoch 21; iter: 0; batch classifier loss: 0.136263; batch adversarial loss: 0.455837\n",
      "epoch 22; iter: 0; batch classifier loss: 0.144533; batch adversarial loss: 0.447274\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164221; batch adversarial loss: 0.545533\n",
      "epoch 24; iter: 0; batch classifier loss: 0.135569; batch adversarial loss: 0.401506\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148438; batch adversarial loss: 0.507238\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140099; batch adversarial loss: 0.383179\n",
      "epoch 27; iter: 0; batch classifier loss: 0.083582; batch adversarial loss: 0.398282\n",
      "epoch 28; iter: 0; batch classifier loss: 0.139410; batch adversarial loss: 0.428255\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179763; batch adversarial loss: 0.379697\n",
      "epoch 30; iter: 0; batch classifier loss: 0.171374; batch adversarial loss: 0.397059\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179192; batch adversarial loss: 0.407734\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184329; batch adversarial loss: 0.471491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.135189; batch adversarial loss: 0.356334\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148639; batch adversarial loss: 0.422590\n",
      "epoch 35; iter: 0; batch classifier loss: 0.126698; batch adversarial loss: 0.333414\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117417; batch adversarial loss: 0.337283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157928; batch adversarial loss: 0.402821\n",
      "epoch 38; iter: 0; batch classifier loss: 0.142335; batch adversarial loss: 0.399907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098248; batch adversarial loss: 0.350588\n",
      "epoch 40; iter: 0; batch classifier loss: 0.126364; batch adversarial loss: 0.408620\n",
      "epoch 41; iter: 0; batch classifier loss: 0.132583; batch adversarial loss: 0.385074\n",
      "epoch 42; iter: 0; batch classifier loss: 0.164548; batch adversarial loss: 0.439314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.067797; batch adversarial loss: 0.368299\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118257; batch adversarial loss: 0.557577\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099529; batch adversarial loss: 0.380755\n",
      "epoch 46; iter: 0; batch classifier loss: 0.123814; batch adversarial loss: 0.410838\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118340; batch adversarial loss: 0.506908\n",
      "epoch 48; iter: 0; batch classifier loss: 0.138132; batch adversarial loss: 0.455681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.061268; batch adversarial loss: 0.375715\n",
      "epoch 50; iter: 0; batch classifier loss: 0.126064; batch adversarial loss: 0.473983\n",
      "epoch 51; iter: 0; batch classifier loss: 0.073390; batch adversarial loss: 0.384479\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115214; batch adversarial loss: 0.426531\n",
      "epoch 53; iter: 0; batch classifier loss: 0.057124; batch adversarial loss: 0.377614\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112971; batch adversarial loss: 0.419876\n",
      "epoch 55; iter: 0; batch classifier loss: 0.088183; batch adversarial loss: 0.338613\n",
      "epoch 56; iter: 0; batch classifier loss: 0.060629; batch adversarial loss: 0.363308\n",
      "epoch 57; iter: 0; batch classifier loss: 0.095789; batch adversarial loss: 0.380400\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082575; batch adversarial loss: 0.389644\n",
      "epoch 59; iter: 0; batch classifier loss: 0.064250; batch adversarial loss: 0.439750\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088525; batch adversarial loss: 0.397201\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134427; batch adversarial loss: 0.532467\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101219; batch adversarial loss: 0.369969\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076205; batch adversarial loss: 0.401709\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084280; batch adversarial loss: 0.429783\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086409; batch adversarial loss: 0.384679\n",
      "epoch 66; iter: 0; batch classifier loss: 0.073098; batch adversarial loss: 0.373996\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066032; batch adversarial loss: 0.419025\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065719; batch adversarial loss: 0.396844\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058885; batch adversarial loss: 0.354561\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109584; batch adversarial loss: 0.510720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062474; batch adversarial loss: 0.422310\n",
      "epoch 72; iter: 0; batch classifier loss: 0.089217; batch adversarial loss: 0.454692\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103009; batch adversarial loss: 0.464219\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046501; batch adversarial loss: 0.357028\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075545; batch adversarial loss: 0.434374\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068555; batch adversarial loss: 0.403186\n",
      "epoch 77; iter: 0; batch classifier loss: 0.073140; batch adversarial loss: 0.395620\n",
      "epoch 78; iter: 0; batch classifier loss: 0.070718; batch adversarial loss: 0.462013\n",
      "epoch 79; iter: 0; batch classifier loss: 0.103849; batch adversarial loss: 0.364838\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074447; batch adversarial loss: 0.510438\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074310; batch adversarial loss: 0.362266\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.368778\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075749; batch adversarial loss: 0.483779\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061977; batch adversarial loss: 0.444569\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050577; batch adversarial loss: 0.342075\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078174; batch adversarial loss: 0.424484\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118312; batch adversarial loss: 0.433907\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103267; batch adversarial loss: 0.376313\n",
      "epoch 89; iter: 0; batch classifier loss: 0.101575; batch adversarial loss: 0.441263\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058118; batch adversarial loss: 0.371118\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101779; batch adversarial loss: 0.461153\n",
      "epoch 92; iter: 0; batch classifier loss: 0.043646; batch adversarial loss: 0.367362\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063718; batch adversarial loss: 0.352284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.116000; batch adversarial loss: 0.423805\n",
      "epoch 95; iter: 0; batch classifier loss: 0.056484; batch adversarial loss: 0.424807\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074548; batch adversarial loss: 0.401031\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041898; batch adversarial loss: 0.431387\n",
      "epoch 98; iter: 0; batch classifier loss: 0.066774; batch adversarial loss: 0.432951\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050041; batch adversarial loss: 0.410365\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048585; batch adversarial loss: 0.473439\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095033; batch adversarial loss: 0.449637\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052527; batch adversarial loss: 0.390757\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057337; batch adversarial loss: 0.435455\n",
      "epoch 104; iter: 0; batch classifier loss: 0.059180; batch adversarial loss: 0.413870\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053870; batch adversarial loss: 0.393719\n",
      "epoch 106; iter: 0; batch classifier loss: 0.096185; batch adversarial loss: 0.458907\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059583; batch adversarial loss: 0.420913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076844; batch adversarial loss: 0.390471\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062504; batch adversarial loss: 0.484310\n",
      "epoch 110; iter: 0; batch classifier loss: 0.076176; batch adversarial loss: 0.434591\n",
      "epoch 111; iter: 0; batch classifier loss: 0.045965; batch adversarial loss: 0.404685\n",
      "epoch 112; iter: 0; batch classifier loss: 0.103306; batch adversarial loss: 0.456675\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069639; batch adversarial loss: 0.459348\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042653; batch adversarial loss: 0.357792\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071380; batch adversarial loss: 0.545681\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060002; batch adversarial loss: 0.432225\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060989; batch adversarial loss: 0.385612\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062368; batch adversarial loss: 0.418875\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.358940\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051721; batch adversarial loss: 0.417414\n",
      "epoch 121; iter: 0; batch classifier loss: 0.111547; batch adversarial loss: 0.439717\n",
      "epoch 122; iter: 0; batch classifier loss: 0.059402; batch adversarial loss: 0.446442\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061652; batch adversarial loss: 0.424725\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053611; batch adversarial loss: 0.422278\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057498; batch adversarial loss: 0.404824\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047656; batch adversarial loss: 0.440945\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059358; batch adversarial loss: 0.487402\n",
      "epoch 128; iter: 0; batch classifier loss: 0.069039; batch adversarial loss: 0.379504\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058162; batch adversarial loss: 0.358152\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031895; batch adversarial loss: 0.432283\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045992; batch adversarial loss: 0.383161\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042545; batch adversarial loss: 0.508314\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040027; batch adversarial loss: 0.425449\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034355; batch adversarial loss: 0.520337\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039245; batch adversarial loss: 0.443320\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050784; batch adversarial loss: 0.491733\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023100; batch adversarial loss: 0.452773\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040607; batch adversarial loss: 0.506944\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050244; batch adversarial loss: 0.442313\n",
      "epoch 140; iter: 0; batch classifier loss: 0.058588; batch adversarial loss: 0.400732\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029486; batch adversarial loss: 0.388446\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021352; batch adversarial loss: 0.399287\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032157; batch adversarial loss: 0.536138\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041851; batch adversarial loss: 0.319828\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.416823\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052093; batch adversarial loss: 0.455401\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009166; batch adversarial loss: 0.399726\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017701; batch adversarial loss: 0.489045\n",
      "epoch 149; iter: 0; batch classifier loss: 0.068266; batch adversarial loss: 0.360664\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015669; batch adversarial loss: 0.543301\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.361771\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029332; batch adversarial loss: 0.473977\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031009; batch adversarial loss: 0.430068\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036697; batch adversarial loss: 0.432303\n",
      "epoch 155; iter: 0; batch classifier loss: 0.058928; batch adversarial loss: 0.518356\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031124; batch adversarial loss: 0.489927\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053943; batch adversarial loss: 0.542881\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037187; batch adversarial loss: 0.457475\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026649; batch adversarial loss: 0.512608\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035732; batch adversarial loss: 0.545253\n",
      "epoch 161; iter: 0; batch classifier loss: 0.048821; batch adversarial loss: 0.395368\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013938; batch adversarial loss: 0.420223\n",
      "epoch 163; iter: 0; batch classifier loss: 0.139052; batch adversarial loss: 0.720381\n",
      "epoch 164; iter: 0; batch classifier loss: 0.109853; batch adversarial loss: 0.647152\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060346; batch adversarial loss: 0.452964\n",
      "epoch 166; iter: 0; batch classifier loss: 0.090556; batch adversarial loss: 0.610586\n",
      "epoch 167; iter: 0; batch classifier loss: 0.122259; batch adversarial loss: 0.664168\n",
      "epoch 168; iter: 0; batch classifier loss: 0.104920; batch adversarial loss: 0.551495\n",
      "epoch 169; iter: 0; batch classifier loss: 0.137080; batch adversarial loss: 0.655243\n",
      "epoch 170; iter: 0; batch classifier loss: 0.116004; batch adversarial loss: 0.569818\n",
      "epoch 171; iter: 0; batch classifier loss: 0.117762; batch adversarial loss: 0.565713\n",
      "epoch 172; iter: 0; batch classifier loss: 0.137719; batch adversarial loss: 0.673914\n",
      "epoch 173; iter: 0; batch classifier loss: 0.100178; batch adversarial loss: 0.509403\n",
      "epoch 174; iter: 0; batch classifier loss: 0.173803; batch adversarial loss: 0.699780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.233137; batch adversarial loss: 0.791753\n",
      "epoch 176; iter: 0; batch classifier loss: 0.193117; batch adversarial loss: 0.678027\n",
      "epoch 177; iter: 0; batch classifier loss: 0.198614; batch adversarial loss: 0.648388\n",
      "epoch 178; iter: 0; batch classifier loss: 0.157625; batch adversarial loss: 0.651657\n",
      "epoch 179; iter: 0; batch classifier loss: 0.186983; batch adversarial loss: 0.670692\n",
      "epoch 180; iter: 0; batch classifier loss: 0.194243; batch adversarial loss: 0.668883\n",
      "epoch 181; iter: 0; batch classifier loss: 0.222060; batch adversarial loss: 0.742836\n",
      "epoch 182; iter: 0; batch classifier loss: 0.199058; batch adversarial loss: 0.720925\n",
      "epoch 183; iter: 0; batch classifier loss: 0.107982; batch adversarial loss: 0.538839\n",
      "epoch 184; iter: 0; batch classifier loss: 0.138686; batch adversarial loss: 0.553595\n",
      "epoch 185; iter: 0; batch classifier loss: 0.145939; batch adversarial loss: 0.588070\n",
      "epoch 186; iter: 0; batch classifier loss: 0.180125; batch adversarial loss: 0.691257\n",
      "epoch 187; iter: 0; batch classifier loss: 0.149968; batch adversarial loss: 0.500896\n",
      "epoch 188; iter: 0; batch classifier loss: 0.117389; batch adversarial loss: 0.512126\n",
      "epoch 189; iter: 0; batch classifier loss: 0.199992; batch adversarial loss: 0.596756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.077685; batch adversarial loss: 0.401256\n",
      "epoch 191; iter: 0; batch classifier loss: 0.212114; batch adversarial loss: 0.658541\n",
      "epoch 192; iter: 0; batch classifier loss: 0.205551; batch adversarial loss: 0.664951\n",
      "epoch 193; iter: 0; batch classifier loss: 0.117584; batch adversarial loss: 0.537945\n",
      "epoch 194; iter: 0; batch classifier loss: 0.098244; batch adversarial loss: 0.482668\n",
      "epoch 195; iter: 0; batch classifier loss: 0.121590; batch adversarial loss: 0.486812\n",
      "epoch 196; iter: 0; batch classifier loss: 0.141176; batch adversarial loss: 0.579292\n",
      "epoch 197; iter: 0; batch classifier loss: 0.102636; batch adversarial loss: 0.489390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.136181; batch adversarial loss: 0.470273\n",
      "epoch 199; iter: 0; batch classifier loss: 0.137102; batch adversarial loss: 0.475122\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725607; batch adversarial loss: 0.632357\n",
      "epoch 1; iter: 0; batch classifier loss: 0.529106; batch adversarial loss: 0.640338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.420302; batch adversarial loss: 0.597409\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451451; batch adversarial loss: 0.610338\n",
      "epoch 4; iter: 0; batch classifier loss: 0.526729; batch adversarial loss: 0.599050\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440161; batch adversarial loss: 0.592673\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476064; batch adversarial loss: 0.620609\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466359; batch adversarial loss: 0.591660\n",
      "epoch 8; iter: 0; batch classifier loss: 0.454625; batch adversarial loss: 0.520755\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354340; batch adversarial loss: 0.549154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449421; batch adversarial loss: 0.510221\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459046; batch adversarial loss: 0.515018\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355697; batch adversarial loss: 0.522890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347670; batch adversarial loss: 0.502609\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316272; batch adversarial loss: 0.474878\n",
      "epoch 15; iter: 0; batch classifier loss: 0.410934; batch adversarial loss: 0.494152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366095; batch adversarial loss: 0.461016\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340125; batch adversarial loss: 0.497966\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384784; batch adversarial loss: 0.472486\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265564; batch adversarial loss: 0.522611\n",
      "epoch 20; iter: 0; batch classifier loss: 0.365220; batch adversarial loss: 0.507594\n",
      "epoch 21; iter: 0; batch classifier loss: 0.402972; batch adversarial loss: 0.418190\n",
      "epoch 22; iter: 0; batch classifier loss: 0.256840; batch adversarial loss: 0.519875\n",
      "epoch 23; iter: 0; batch classifier loss: 0.312810; batch adversarial loss: 0.464721\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240123; batch adversarial loss: 0.578581\n",
      "epoch 25; iter: 0; batch classifier loss: 0.315733; batch adversarial loss: 0.589143\n",
      "epoch 26; iter: 0; batch classifier loss: 0.362547; batch adversarial loss: 0.400221\n",
      "epoch 27; iter: 0; batch classifier loss: 0.206530; batch adversarial loss: 0.442510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375748; batch adversarial loss: 0.409876\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259200; batch adversarial loss: 0.461828\n",
      "epoch 30; iter: 0; batch classifier loss: 0.214852; batch adversarial loss: 0.480147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268780; batch adversarial loss: 0.484312\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374644; batch adversarial loss: 0.321953\n",
      "epoch 33; iter: 0; batch classifier loss: 0.296287; batch adversarial loss: 0.492551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208188; batch adversarial loss: 0.439981\n",
      "epoch 35; iter: 0; batch classifier loss: 0.245483; batch adversarial loss: 0.521318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.319714; batch adversarial loss: 0.404491\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222244; batch adversarial loss: 0.466690\n",
      "epoch 38; iter: 0; batch classifier loss: 0.273925; batch adversarial loss: 0.487877\n",
      "epoch 39; iter: 0; batch classifier loss: 0.202233; batch adversarial loss: 0.402315\n",
      "epoch 40; iter: 0; batch classifier loss: 0.341866; batch adversarial loss: 0.428957\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236315; batch adversarial loss: 0.447178\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213029; batch adversarial loss: 0.518687\n",
      "epoch 43; iter: 0; batch classifier loss: 0.244961; batch adversarial loss: 0.412851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171868; batch adversarial loss: 0.482072\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098934; batch adversarial loss: 0.422047\n",
      "epoch 46; iter: 0; batch classifier loss: 0.137708; batch adversarial loss: 0.346825\n",
      "epoch 47; iter: 0; batch classifier loss: 0.203049; batch adversarial loss: 0.511917\n",
      "epoch 48; iter: 0; batch classifier loss: 0.180244; batch adversarial loss: 0.335731\n",
      "epoch 49; iter: 0; batch classifier loss: 0.267596; batch adversarial loss: 0.470910\n",
      "epoch 50; iter: 0; batch classifier loss: 0.253250; batch adversarial loss: 0.398232\n",
      "epoch 51; iter: 0; batch classifier loss: 0.207076; batch adversarial loss: 0.471027\n",
      "epoch 52; iter: 0; batch classifier loss: 0.199118; batch adversarial loss: 0.422360\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133279; batch adversarial loss: 0.409797\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077863; batch adversarial loss: 0.396999\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072145; batch adversarial loss: 0.532390\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087319; batch adversarial loss: 0.393043\n",
      "epoch 57; iter: 0; batch classifier loss: 0.085094; batch adversarial loss: 0.532080\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086250; batch adversarial loss: 0.352553\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108114; batch adversarial loss: 0.569666\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065240; batch adversarial loss: 0.503972\n",
      "epoch 61; iter: 0; batch classifier loss: 0.220317; batch adversarial loss: 0.391897\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160750; batch adversarial loss: 0.412190\n",
      "epoch 63; iter: 0; batch classifier loss: 0.120992; batch adversarial loss: 0.419924\n",
      "epoch 64; iter: 0; batch classifier loss: 0.125821; batch adversarial loss: 0.402795\n",
      "epoch 65; iter: 0; batch classifier loss: 0.132015; batch adversarial loss: 0.434859\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125319; batch adversarial loss: 0.565423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.230826; batch adversarial loss: 0.395992\n",
      "epoch 68; iter: 0; batch classifier loss: 0.163421; batch adversarial loss: 0.505537\n",
      "epoch 69; iter: 0; batch classifier loss: 0.245424; batch adversarial loss: 0.407823\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128870; batch adversarial loss: 0.561182\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206595; batch adversarial loss: 0.297161\n",
      "epoch 72; iter: 0; batch classifier loss: 0.191184; batch adversarial loss: 0.422959\n",
      "epoch 73; iter: 0; batch classifier loss: 0.220153; batch adversarial loss: 0.308577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.301843; batch adversarial loss: 0.361347\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195622; batch adversarial loss: 0.482904\n",
      "epoch 76; iter: 0; batch classifier loss: 0.191125; batch adversarial loss: 0.446549\n",
      "epoch 77; iter: 0; batch classifier loss: 0.212013; batch adversarial loss: 0.446305\n",
      "epoch 78; iter: 0; batch classifier loss: 0.133435; batch adversarial loss: 0.458336\n",
      "epoch 79; iter: 0; batch classifier loss: 0.185960; batch adversarial loss: 0.484543\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108066; batch adversarial loss: 0.419475\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113847; batch adversarial loss: 0.497204\n",
      "epoch 82; iter: 0; batch classifier loss: 0.277120; batch adversarial loss: 0.419595\n",
      "epoch 83; iter: 0; batch classifier loss: 0.192683; batch adversarial loss: 0.385169\n",
      "epoch 84; iter: 0; batch classifier loss: 0.206199; batch adversarial loss: 0.372012\n",
      "epoch 85; iter: 0; batch classifier loss: 0.163013; batch adversarial loss: 0.421420\n",
      "epoch 86; iter: 0; batch classifier loss: 0.204915; batch adversarial loss: 0.507392\n",
      "epoch 87; iter: 0; batch classifier loss: 0.169148; batch adversarial loss: 0.471167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.184558; batch adversarial loss: 0.521251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.200392; batch adversarial loss: 0.359361\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118996; batch adversarial loss: 0.533755\n",
      "epoch 91; iter: 0; batch classifier loss: 0.204108; batch adversarial loss: 0.421848\n",
      "epoch 92; iter: 0; batch classifier loss: 0.214037; batch adversarial loss: 0.433955\n",
      "epoch 93; iter: 0; batch classifier loss: 0.216020; batch adversarial loss: 0.521520\n",
      "epoch 94; iter: 0; batch classifier loss: 0.179400; batch adversarial loss: 0.583685\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090982; batch adversarial loss: 0.495667\n",
      "epoch 96; iter: 0; batch classifier loss: 0.130702; batch adversarial loss: 0.470322\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094381; batch adversarial loss: 0.535246\n",
      "epoch 98; iter: 0; batch classifier loss: 0.172608; batch adversarial loss: 0.483624\n",
      "epoch 99; iter: 0; batch classifier loss: 0.148226; batch adversarial loss: 0.462145\n",
      "epoch 100; iter: 0; batch classifier loss: 0.154697; batch adversarial loss: 0.405404\n",
      "epoch 101; iter: 0; batch classifier loss: 0.181457; batch adversarial loss: 0.394676\n",
      "epoch 102; iter: 0; batch classifier loss: 0.188546; batch adversarial loss: 0.470285\n",
      "epoch 103; iter: 0; batch classifier loss: 0.178837; batch adversarial loss: 0.395924\n",
      "epoch 104; iter: 0; batch classifier loss: 0.152237; batch adversarial loss: 0.356664\n",
      "epoch 105; iter: 0; batch classifier loss: 0.121810; batch adversarial loss: 0.547351\n",
      "epoch 106; iter: 0; batch classifier loss: 0.139013; batch adversarial loss: 0.369026\n",
      "epoch 107; iter: 0; batch classifier loss: 0.145159; batch adversarial loss: 0.473388\n",
      "epoch 108; iter: 0; batch classifier loss: 0.154077; batch adversarial loss: 0.381823\n",
      "epoch 109; iter: 0; batch classifier loss: 0.149421; batch adversarial loss: 0.435160\n",
      "epoch 110; iter: 0; batch classifier loss: 0.159458; batch adversarial loss: 0.429719\n",
      "epoch 111; iter: 0; batch classifier loss: 0.123335; batch adversarial loss: 0.452886\n",
      "epoch 112; iter: 0; batch classifier loss: 0.095130; batch adversarial loss: 0.503260\n",
      "epoch 113; iter: 0; batch classifier loss: 0.100185; batch adversarial loss: 0.387052\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082161; batch adversarial loss: 0.614126\n",
      "epoch 115; iter: 0; batch classifier loss: 0.078418; batch adversarial loss: 0.396301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.116658; batch adversarial loss: 0.483904\n",
      "epoch 117; iter: 0; batch classifier loss: 0.107872; batch adversarial loss: 0.379285\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032771; batch adversarial loss: 0.485963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.079751; batch adversarial loss: 0.387231\n",
      "epoch 120; iter: 0; batch classifier loss: 0.122681; batch adversarial loss: 0.318553\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049537; batch adversarial loss: 0.422650\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032517; batch adversarial loss: 0.477093\n",
      "epoch 123; iter: 0; batch classifier loss: 0.074608; batch adversarial loss: 0.449919\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050588; batch adversarial loss: 0.544106\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044251; batch adversarial loss: 0.467161\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037766; batch adversarial loss: 0.408688\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067102; batch adversarial loss: 0.401746\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053283; batch adversarial loss: 0.553012\n",
      "epoch 129; iter: 0; batch classifier loss: 0.058249; batch adversarial loss: 0.491279\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056199; batch adversarial loss: 0.437597\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033638; batch adversarial loss: 0.437182\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046456; batch adversarial loss: 0.442868\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036252; batch adversarial loss: 0.444677\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031154; batch adversarial loss: 0.396564\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043513; batch adversarial loss: 0.513314\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072389; batch adversarial loss: 0.480119\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057611; batch adversarial loss: 0.500565\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031620; batch adversarial loss: 0.278254\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023854; batch adversarial loss: 0.354663\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040900; batch adversarial loss: 0.423633\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028689; batch adversarial loss: 0.407044\n",
      "epoch 142; iter: 0; batch classifier loss: 0.069405; batch adversarial loss: 0.416647\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024069; batch adversarial loss: 0.472185\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034406; batch adversarial loss: 0.482135\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060765; batch adversarial loss: 0.477990\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052795; batch adversarial loss: 0.451973\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046107; batch adversarial loss: 0.408016\n",
      "epoch 148; iter: 0; batch classifier loss: 0.048981; batch adversarial loss: 0.326702\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026377; batch adversarial loss: 0.394260\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025235; batch adversarial loss: 0.441133\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031404; batch adversarial loss: 0.395548\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014963; batch adversarial loss: 0.436081\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020062; batch adversarial loss: 0.553888\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023124; batch adversarial loss: 0.431390\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028455; batch adversarial loss: 0.465132\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037071; batch adversarial loss: 0.474822\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028812; batch adversarial loss: 0.465286\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023050; batch adversarial loss: 0.463886\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049559; batch adversarial loss: 0.442237\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013737; batch adversarial loss: 0.423898\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047238; batch adversarial loss: 0.444872\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021493; batch adversarial loss: 0.467712\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025337; batch adversarial loss: 0.391307\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011896; batch adversarial loss: 0.426859\n",
      "epoch 165; iter: 0; batch classifier loss: 0.047233; batch adversarial loss: 0.372855\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023961; batch adversarial loss: 0.528389\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014331; batch adversarial loss: 0.479095\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022463; batch adversarial loss: 0.484272\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007446; batch adversarial loss: 0.393111\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009081; batch adversarial loss: 0.462342\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008465; batch adversarial loss: 0.399971\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045745; batch adversarial loss: 0.384252\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026952; batch adversarial loss: 0.416630\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050108; batch adversarial loss: 0.393824\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015932; batch adversarial loss: 0.422663\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034778; batch adversarial loss: 0.557150\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020938; batch adversarial loss: 0.538386\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017858; batch adversarial loss: 0.489408\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011001; batch adversarial loss: 0.380095\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026443; batch adversarial loss: 0.495258\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027897; batch adversarial loss: 0.430210\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019108; batch adversarial loss: 0.402619\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016901; batch adversarial loss: 0.375699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.012711; batch adversarial loss: 0.493769\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012329; batch adversarial loss: 0.392210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016257; batch adversarial loss: 0.399617\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020757; batch adversarial loss: 0.473363\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013517; batch adversarial loss: 0.503687\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023550; batch adversarial loss: 0.402317\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011463; batch adversarial loss: 0.381101\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028724; batch adversarial loss: 0.455576\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008091; batch adversarial loss: 0.446223\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013732; batch adversarial loss: 0.369277\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036660; batch adversarial loss: 0.499231\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019788; batch adversarial loss: 0.442745\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019431; batch adversarial loss: 0.497398\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027423; batch adversarial loss: 0.474813\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005514; batch adversarial loss: 0.424870\n",
      "epoch 199; iter: 0; batch classifier loss: 0.003599; batch adversarial loss: 0.416277\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689625; batch adversarial loss: 0.716060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.465066; batch adversarial loss: 0.668759\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447127; batch adversarial loss: 0.625215\n",
      "epoch 3; iter: 0; batch classifier loss: 0.479908; batch adversarial loss: 0.625220\n",
      "epoch 4; iter: 0; batch classifier loss: 0.413874; batch adversarial loss: 0.606441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380529; batch adversarial loss: 0.594074\n",
      "epoch 6; iter: 0; batch classifier loss: 0.431472; batch adversarial loss: 0.567973\n",
      "epoch 7; iter: 0; batch classifier loss: 0.467462; batch adversarial loss: 0.598164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494260; batch adversarial loss: 0.574245\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489619; batch adversarial loss: 0.514249\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493360; batch adversarial loss: 0.531111\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541096; batch adversarial loss: 0.507198\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462370; batch adversarial loss: 0.532637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382720; batch adversarial loss: 0.486643\n",
      "epoch 14; iter: 0; batch classifier loss: 0.386540; batch adversarial loss: 0.438533\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314390; batch adversarial loss: 0.476573\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343202; batch adversarial loss: 0.509938\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331124; batch adversarial loss: 0.535851\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326960; batch adversarial loss: 0.494191\n",
      "epoch 19; iter: 0; batch classifier loss: 0.393882; batch adversarial loss: 0.485857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.317908; batch adversarial loss: 0.442064\n",
      "epoch 21; iter: 0; batch classifier loss: 0.327319; batch adversarial loss: 0.488329\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284894; batch adversarial loss: 0.510800\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280457; batch adversarial loss: 0.506846\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270556; batch adversarial loss: 0.536133\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243234; batch adversarial loss: 0.437057\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275067; batch adversarial loss: 0.460878\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224166; batch adversarial loss: 0.427626\n",
      "epoch 28; iter: 0; batch classifier loss: 0.237565; batch adversarial loss: 0.492205\n",
      "epoch 29; iter: 0; batch classifier loss: 0.208945; batch adversarial loss: 0.441113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.218568; batch adversarial loss: 0.496797\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173758; batch adversarial loss: 0.539091\n",
      "epoch 32; iter: 0; batch classifier loss: 0.264184; batch adversarial loss: 0.379689\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249639; batch adversarial loss: 0.433297\n",
      "epoch 34; iter: 0; batch classifier loss: 0.214658; batch adversarial loss: 0.469468\n",
      "epoch 35; iter: 0; batch classifier loss: 0.199728; batch adversarial loss: 0.512555\n",
      "epoch 36; iter: 0; batch classifier loss: 0.225282; batch adversarial loss: 0.383145\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186548; batch adversarial loss: 0.423991\n",
      "epoch 38; iter: 0; batch classifier loss: 0.209074; batch adversarial loss: 0.371243\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176147; batch adversarial loss: 0.414162\n",
      "epoch 40; iter: 0; batch classifier loss: 0.196737; batch adversarial loss: 0.440207\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206115; batch adversarial loss: 0.452868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197859; batch adversarial loss: 0.469383\n",
      "epoch 43; iter: 0; batch classifier loss: 0.190669; batch adversarial loss: 0.390024\n",
      "epoch 44; iter: 0; batch classifier loss: 0.207373; batch adversarial loss: 0.483623\n",
      "epoch 45; iter: 0; batch classifier loss: 0.251224; batch adversarial loss: 0.554723\n",
      "epoch 46; iter: 0; batch classifier loss: 0.139131; batch adversarial loss: 0.517618\n",
      "epoch 47; iter: 0; batch classifier loss: 0.230692; batch adversarial loss: 0.497070\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187667; batch adversarial loss: 0.448142\n",
      "epoch 49; iter: 0; batch classifier loss: 0.233799; batch adversarial loss: 0.470759\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130301; batch adversarial loss: 0.470901\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109027; batch adversarial loss: 0.447396\n",
      "epoch 52; iter: 0; batch classifier loss: 0.146540; batch adversarial loss: 0.536343\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191906; batch adversarial loss: 0.507131\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142856; batch adversarial loss: 0.423770\n",
      "epoch 55; iter: 0; batch classifier loss: 0.234820; batch adversarial loss: 0.471812\n",
      "epoch 56; iter: 0; batch classifier loss: 0.173505; batch adversarial loss: 0.446068\n",
      "epoch 57; iter: 0; batch classifier loss: 0.159199; batch adversarial loss: 0.422052\n",
      "epoch 58; iter: 0; batch classifier loss: 0.183359; batch adversarial loss: 0.471299\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088194; batch adversarial loss: 0.532330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119178; batch adversarial loss: 0.545777\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078805; batch adversarial loss: 0.482651\n",
      "epoch 62; iter: 0; batch classifier loss: 0.159795; batch adversarial loss: 0.457362\n",
      "epoch 63; iter: 0; batch classifier loss: 0.165863; batch adversarial loss: 0.434656\n",
      "epoch 64; iter: 0; batch classifier loss: 0.133499; batch adversarial loss: 0.520916\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081011; batch adversarial loss: 0.407382\n",
      "epoch 66; iter: 0; batch classifier loss: 0.096617; batch adversarial loss: 0.459426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.133861; batch adversarial loss: 0.396267\n",
      "epoch 68; iter: 0; batch classifier loss: 0.192133; batch adversarial loss: 0.546669\n",
      "epoch 69; iter: 0; batch classifier loss: 0.140608; batch adversarial loss: 0.413495\n",
      "epoch 70; iter: 0; batch classifier loss: 0.160724; batch adversarial loss: 0.457115\n",
      "epoch 71; iter: 0; batch classifier loss: 0.152375; batch adversarial loss: 0.457630\n",
      "epoch 72; iter: 0; batch classifier loss: 0.114089; batch adversarial loss: 0.505876\n",
      "epoch 73; iter: 0; batch classifier loss: 0.089200; batch adversarial loss: 0.556613\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090352; batch adversarial loss: 0.390045\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134101; batch adversarial loss: 0.485020\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075546; batch adversarial loss: 0.408874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062501; batch adversarial loss: 0.546030\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076324; batch adversarial loss: 0.368253\n",
      "epoch 79; iter: 0; batch classifier loss: 0.128851; batch adversarial loss: 0.444529\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084967; batch adversarial loss: 0.415764\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095219; batch adversarial loss: 0.542557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.062032; batch adversarial loss: 0.464527\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089378; batch adversarial loss: 0.543947\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066642; batch adversarial loss: 0.499420\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072418; batch adversarial loss: 0.463734\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102905; batch adversarial loss: 0.407528\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048010; batch adversarial loss: 0.411352\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054191; batch adversarial loss: 0.423294\n",
      "epoch 89; iter: 0; batch classifier loss: 0.118836; batch adversarial loss: 0.437586\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073267; batch adversarial loss: 0.439203\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093952; batch adversarial loss: 0.421367\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085825; batch adversarial loss: 0.414910\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052415; batch adversarial loss: 0.496591\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038202; batch adversarial loss: 0.540808\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069098; batch adversarial loss: 0.374008\n",
      "epoch 96; iter: 0; batch classifier loss: 0.024829; batch adversarial loss: 0.481261\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072099; batch adversarial loss: 0.473108\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053986; batch adversarial loss: 0.484568\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037526; batch adversarial loss: 0.452078\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048652; batch adversarial loss: 0.364257\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070522; batch adversarial loss: 0.435713\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057697; batch adversarial loss: 0.452627\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068733; batch adversarial loss: 0.479843\n",
      "epoch 104; iter: 0; batch classifier loss: 0.015781; batch adversarial loss: 0.434444\n",
      "epoch 105; iter: 0; batch classifier loss: 0.029331; batch adversarial loss: 0.543263\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044351; batch adversarial loss: 0.527666\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056625; batch adversarial loss: 0.386933\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.472448\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042622; batch adversarial loss: 0.499419\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042816; batch adversarial loss: 0.401469\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036435; batch adversarial loss: 0.398123\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075681; batch adversarial loss: 0.522334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031935; batch adversarial loss: 0.479071\n",
      "epoch 114; iter: 0; batch classifier loss: 0.009286; batch adversarial loss: 0.535458\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062850; batch adversarial loss: 0.391903\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028824; batch adversarial loss: 0.493405\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029829; batch adversarial loss: 0.408447\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043819; batch adversarial loss: 0.507258\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040678; batch adversarial loss: 0.476464\n",
      "epoch 120; iter: 0; batch classifier loss: 0.038442; batch adversarial loss: 0.482755\n",
      "epoch 121; iter: 0; batch classifier loss: 0.081151; batch adversarial loss: 0.400978\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025144; batch adversarial loss: 0.378627\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053460; batch adversarial loss: 0.400855\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041358; batch adversarial loss: 0.486192\n",
      "epoch 125; iter: 0; batch classifier loss: 0.025641; batch adversarial loss: 0.481057\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.471095\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021920; batch adversarial loss: 0.416498\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019664; batch adversarial loss: 0.436933\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035732; batch adversarial loss: 0.368630\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036230; batch adversarial loss: 0.394802\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051120; batch adversarial loss: 0.413418\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029679; batch adversarial loss: 0.443772\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011037; batch adversarial loss: 0.467510\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028640; batch adversarial loss: 0.407674\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022795; batch adversarial loss: 0.463946\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042172; batch adversarial loss: 0.447269\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032482; batch adversarial loss: 0.368417\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022677; batch adversarial loss: 0.387773\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046448; batch adversarial loss: 0.432718\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025360; batch adversarial loss: 0.403085\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021905; batch adversarial loss: 0.399935\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022831; batch adversarial loss: 0.399158\n",
      "epoch 143; iter: 0; batch classifier loss: 0.053381; batch adversarial loss: 0.434338\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011037; batch adversarial loss: 0.532051\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017401; batch adversarial loss: 0.441825\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011433; batch adversarial loss: 0.487875\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045984; batch adversarial loss: 0.434599\n",
      "epoch 148; iter: 0; batch classifier loss: 0.006958; batch adversarial loss: 0.457005\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028042; batch adversarial loss: 0.483050\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027482; batch adversarial loss: 0.375125\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.483757\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011711; batch adversarial loss: 0.439534\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017367; batch adversarial loss: 0.450514\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027395; batch adversarial loss: 0.408508\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031800; batch adversarial loss: 0.341603\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024103; batch adversarial loss: 0.399102\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024977; batch adversarial loss: 0.482326\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028501; batch adversarial loss: 0.555305\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012383; batch adversarial loss: 0.506696\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016971; batch adversarial loss: 0.478445\n",
      "epoch 161; iter: 0; batch classifier loss: 0.054977; batch adversarial loss: 0.443392\n",
      "epoch 162; iter: 0; batch classifier loss: 0.033615; batch adversarial loss: 0.425542\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015545; batch adversarial loss: 0.490364\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026472; batch adversarial loss: 0.370570\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021092; batch adversarial loss: 0.456823\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015328; batch adversarial loss: 0.427849\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008784; batch adversarial loss: 0.424779\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011710; batch adversarial loss: 0.456491\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023639; batch adversarial loss: 0.421839\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037861; batch adversarial loss: 0.438723\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016222; batch adversarial loss: 0.355345\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021800; batch adversarial loss: 0.433254\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015867; batch adversarial loss: 0.553666\n",
      "epoch 174; iter: 0; batch classifier loss: 0.063517; batch adversarial loss: 0.468338\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041019; batch adversarial loss: 0.413431\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025383; batch adversarial loss: 0.387634\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025210; batch adversarial loss: 0.429256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.017141; batch adversarial loss: 0.445282\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045245; batch adversarial loss: 0.458938\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019181; batch adversarial loss: 0.486226\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015629; batch adversarial loss: 0.470963\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015901; batch adversarial loss: 0.402955\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013051; batch adversarial loss: 0.391687\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008100; batch adversarial loss: 0.452009\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011218; batch adversarial loss: 0.442861\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033457; batch adversarial loss: 0.438700\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048484; batch adversarial loss: 0.413125\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028002; batch adversarial loss: 0.504568\n",
      "epoch 189; iter: 0; batch classifier loss: 0.022626; batch adversarial loss: 0.493075\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012034; batch adversarial loss: 0.386342\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045053; batch adversarial loss: 0.375841\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020484; batch adversarial loss: 0.413042\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018652; batch adversarial loss: 0.498679\n",
      "epoch 194; iter: 0; batch classifier loss: 0.007451; batch adversarial loss: 0.412515\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014931; batch adversarial loss: 0.500691\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008256; batch adversarial loss: 0.417795\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017579; batch adversarial loss: 0.468442\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023840; batch adversarial loss: 0.431196\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004227; batch adversarial loss: 0.460576\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698845; batch adversarial loss: 0.563076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.430501; batch adversarial loss: 0.654451\n",
      "epoch 2; iter: 0; batch classifier loss: 0.374658; batch adversarial loss: 0.567304\n",
      "epoch 3; iter: 0; batch classifier loss: 0.334837; batch adversarial loss: 0.557022\n",
      "epoch 4; iter: 0; batch classifier loss: 0.317945; batch adversarial loss: 0.532176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.269852; batch adversarial loss: 0.514182\n",
      "epoch 6; iter: 0; batch classifier loss: 0.341929; batch adversarial loss: 0.565348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.272016; batch adversarial loss: 0.547711\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303046; batch adversarial loss: 0.495241\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238220; batch adversarial loss: 0.504835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244481; batch adversarial loss: 0.520107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295465; batch adversarial loss: 0.472610\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211577; batch adversarial loss: 0.555279\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251503; batch adversarial loss: 0.479581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.217977; batch adversarial loss: 0.470696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199897; batch adversarial loss: 0.545491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225435; batch adversarial loss: 0.487379\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252417; batch adversarial loss: 0.504317\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316633; batch adversarial loss: 0.610607\n",
      "epoch 19; iter: 0; batch classifier loss: 0.266633; batch adversarial loss: 0.557324\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255419; batch adversarial loss: 0.562959\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330232; batch adversarial loss: 0.476742\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225776; batch adversarial loss: 0.495591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316931; batch adversarial loss: 0.530418\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442098; batch adversarial loss: 0.460412\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277963; batch adversarial loss: 0.445437\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264564; batch adversarial loss: 0.598124\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178501; batch adversarial loss: 0.534627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.193979; batch adversarial loss: 0.439921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.194266; batch adversarial loss: 0.437324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.126213; batch adversarial loss: 0.482808\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140401; batch adversarial loss: 0.417030\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135703; batch adversarial loss: 0.514057\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112319; batch adversarial loss: 0.421136\n",
      "epoch 34; iter: 0; batch classifier loss: 0.167475; batch adversarial loss: 0.455067\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125425; batch adversarial loss: 0.506835\n",
      "epoch 36; iter: 0; batch classifier loss: 0.082036; batch adversarial loss: 0.406370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102514; batch adversarial loss: 0.473221\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126631; batch adversarial loss: 0.460328\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114846; batch adversarial loss: 0.395966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098965; batch adversarial loss: 0.449117\n",
      "epoch 41; iter: 0; batch classifier loss: 0.127332; batch adversarial loss: 0.473822\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113432; batch adversarial loss: 0.425163\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183798; batch adversarial loss: 0.459746\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124308; batch adversarial loss: 0.455592\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113256; batch adversarial loss: 0.502822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120800; batch adversarial loss: 0.452257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108040; batch adversarial loss: 0.457805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095880; batch adversarial loss: 0.484337\n",
      "epoch 49; iter: 0; batch classifier loss: 0.135445; batch adversarial loss: 0.464748\n",
      "epoch 50; iter: 0; batch classifier loss: 0.124341; batch adversarial loss: 0.454417\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100105; batch adversarial loss: 0.442899\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164841; batch adversarial loss: 0.354498\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123534; batch adversarial loss: 0.444654\n",
      "epoch 54; iter: 0; batch classifier loss: 0.155683; batch adversarial loss: 0.427220\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123622; batch adversarial loss: 0.514295\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091683; batch adversarial loss: 0.499855\n",
      "epoch 57; iter: 0; batch classifier loss: 0.101609; batch adversarial loss: 0.427299\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115752; batch adversarial loss: 0.460365\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079380; batch adversarial loss: 0.476157\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069102; batch adversarial loss: 0.511510\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109998; batch adversarial loss: 0.361753\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090045; batch adversarial loss: 0.396415\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105731; batch adversarial loss: 0.451881\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092983; batch adversarial loss: 0.395061\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142174; batch adversarial loss: 0.433203\n",
      "epoch 66; iter: 0; batch classifier loss: 0.155173; batch adversarial loss: 0.422273\n",
      "epoch 67; iter: 0; batch classifier loss: 0.180587; batch adversarial loss: 0.522414\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122650; batch adversarial loss: 0.409339\n",
      "epoch 69; iter: 0; batch classifier loss: 0.131205; batch adversarial loss: 0.489584\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089339; batch adversarial loss: 0.439229\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084297; batch adversarial loss: 0.455745\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091149; batch adversarial loss: 0.476299\n",
      "epoch 73; iter: 0; batch classifier loss: 0.131158; batch adversarial loss: 0.440967\n",
      "epoch 74; iter: 0; batch classifier loss: 0.133754; batch adversarial loss: 0.358439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.142912; batch adversarial loss: 0.411298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.162795; batch adversarial loss: 0.375370\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101317; batch adversarial loss: 0.477112\n",
      "epoch 78; iter: 0; batch classifier loss: 0.135536; batch adversarial loss: 0.433260\n",
      "epoch 79; iter: 0; batch classifier loss: 0.138217; batch adversarial loss: 0.462440\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089326; batch adversarial loss: 0.392801\n",
      "epoch 81; iter: 0; batch classifier loss: 0.095513; batch adversarial loss: 0.547804\n",
      "epoch 82; iter: 0; batch classifier loss: 0.154032; batch adversarial loss: 0.502936\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082192; batch adversarial loss: 0.454023\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086318; batch adversarial loss: 0.489510\n",
      "epoch 85; iter: 0; batch classifier loss: 0.128168; batch adversarial loss: 0.423401\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120396; batch adversarial loss: 0.472463\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073945; batch adversarial loss: 0.426729\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086833; batch adversarial loss: 0.427127\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065399; batch adversarial loss: 0.531303\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093068; batch adversarial loss: 0.447493\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131354; batch adversarial loss: 0.461680\n",
      "epoch 92; iter: 0; batch classifier loss: 0.107048; batch adversarial loss: 0.373311\n",
      "epoch 93; iter: 0; batch classifier loss: 0.111895; batch adversarial loss: 0.446002\n",
      "epoch 94; iter: 0; batch classifier loss: 0.059532; batch adversarial loss: 0.496458\n",
      "epoch 95; iter: 0; batch classifier loss: 0.092922; batch adversarial loss: 0.366538\n",
      "epoch 96; iter: 0; batch classifier loss: 0.111191; batch adversarial loss: 0.457166\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099540; batch adversarial loss: 0.508022\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070532; batch adversarial loss: 0.429338\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110140; batch adversarial loss: 0.514604\n",
      "epoch 100; iter: 0; batch classifier loss: 0.073649; batch adversarial loss: 0.516415\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075593; batch adversarial loss: 0.413980\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073738; batch adversarial loss: 0.525021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.141418; batch adversarial loss: 0.456348\n",
      "epoch 104; iter: 0; batch classifier loss: 0.103710; batch adversarial loss: 0.530148\n",
      "epoch 105; iter: 0; batch classifier loss: 0.112141; batch adversarial loss: 0.475569\n",
      "epoch 106; iter: 0; batch classifier loss: 0.080059; batch adversarial loss: 0.437964\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063265; batch adversarial loss: 0.386663\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071591; batch adversarial loss: 0.470309\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068993; batch adversarial loss: 0.464151\n",
      "epoch 110; iter: 0; batch classifier loss: 0.110354; batch adversarial loss: 0.425185\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057675; batch adversarial loss: 0.452295\n",
      "epoch 112; iter: 0; batch classifier loss: 0.114358; batch adversarial loss: 0.470101\n",
      "epoch 113; iter: 0; batch classifier loss: 0.061919; batch adversarial loss: 0.559562\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082746; batch adversarial loss: 0.371064\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062689; batch adversarial loss: 0.390404\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.395769\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080837; batch adversarial loss: 0.446424\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043142; batch adversarial loss: 0.430505\n",
      "epoch 119; iter: 0; batch classifier loss: 0.055756; batch adversarial loss: 0.414518\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068476; batch adversarial loss: 0.467711\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048559; batch adversarial loss: 0.469773\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066162; batch adversarial loss: 0.493368\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066167; batch adversarial loss: 0.454375\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051766; batch adversarial loss: 0.452669\n",
      "epoch 125; iter: 0; batch classifier loss: 0.083956; batch adversarial loss: 0.476624\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062237; batch adversarial loss: 0.356689\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042814; batch adversarial loss: 0.539985\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056218; batch adversarial loss: 0.437436\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028438; batch adversarial loss: 0.417727\n",
      "epoch 130; iter: 0; batch classifier loss: 0.078326; batch adversarial loss: 0.460420\n",
      "epoch 131; iter: 0; batch classifier loss: 0.054540; batch adversarial loss: 0.435504\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045498; batch adversarial loss: 0.474508\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042035; batch adversarial loss: 0.405757\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056913; batch adversarial loss: 0.376136\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052231; batch adversarial loss: 0.484351\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046763; batch adversarial loss: 0.519607\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023738; batch adversarial loss: 0.442582\n",
      "epoch 138; iter: 0; batch classifier loss: 0.066339; batch adversarial loss: 0.487659\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025309; batch adversarial loss: 0.499368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037274; batch adversarial loss: 0.454902\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053230; batch adversarial loss: 0.459931\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031099; batch adversarial loss: 0.334254\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034326; batch adversarial loss: 0.446383\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016408; batch adversarial loss: 0.434723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038939; batch adversarial loss: 0.496672\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047566; batch adversarial loss: 0.557085\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034909; batch adversarial loss: 0.486587\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020984; batch adversarial loss: 0.431631\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019529; batch adversarial loss: 0.503503\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044294; batch adversarial loss: 0.477222\n",
      "epoch 151; iter: 0; batch classifier loss: 0.059627; batch adversarial loss: 0.408336\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021630; batch adversarial loss: 0.421433\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020773; batch adversarial loss: 0.343911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.037375; batch adversarial loss: 0.497522\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057916; batch adversarial loss: 0.466113\n",
      "epoch 156; iter: 0; batch classifier loss: 0.058297; batch adversarial loss: 0.395571\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012791; batch adversarial loss: 0.478850\n",
      "epoch 158; iter: 0; batch classifier loss: 0.063997; batch adversarial loss: 0.447437\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023369; batch adversarial loss: 0.476957\n",
      "epoch 160; iter: 0; batch classifier loss: 0.049340; batch adversarial loss: 0.399564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039475; batch adversarial loss: 0.420216\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031038; batch adversarial loss: 0.436502\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027623; batch adversarial loss: 0.446483\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021872; batch adversarial loss: 0.500843\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015502; batch adversarial loss: 0.473407\n",
      "epoch 166; iter: 0; batch classifier loss: 0.043472; batch adversarial loss: 0.407269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026184; batch adversarial loss: 0.516845\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.465338\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033687; batch adversarial loss: 0.450716\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018056; batch adversarial loss: 0.516929\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024820; batch adversarial loss: 0.402079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.049133; batch adversarial loss: 0.527895\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021258; batch adversarial loss: 0.464768\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025356; batch adversarial loss: 0.433050\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042850; batch adversarial loss: 0.490745\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014786; batch adversarial loss: 0.498428\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014891; batch adversarial loss: 0.440891\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027508; batch adversarial loss: 0.399074\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020366; batch adversarial loss: 0.438604\n",
      "epoch 180; iter: 0; batch classifier loss: 0.027271; batch adversarial loss: 0.482410\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020634; batch adversarial loss: 0.424596\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013862; batch adversarial loss: 0.474431\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018961; batch adversarial loss: 0.467697\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034898; batch adversarial loss: 0.446459\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029681; batch adversarial loss: 0.511935\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021956; batch adversarial loss: 0.412912\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.418552\n",
      "epoch 188; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.394391\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028979; batch adversarial loss: 0.541165\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010720; batch adversarial loss: 0.526087\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023678; batch adversarial loss: 0.381797\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036009; batch adversarial loss: 0.429337\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004515; batch adversarial loss: 0.441699\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018323; batch adversarial loss: 0.428459\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021159; batch adversarial loss: 0.395649\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011917; batch adversarial loss: 0.379405\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031222; batch adversarial loss: 0.522168\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022425; batch adversarial loss: 0.418655\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027649; batch adversarial loss: 0.496651\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699744; batch adversarial loss: 0.773329\n",
      "epoch 1; iter: 0; batch classifier loss: 0.426954; batch adversarial loss: 0.730930\n",
      "epoch 2; iter: 0; batch classifier loss: 0.388217; batch adversarial loss: 0.681717\n",
      "epoch 3; iter: 0; batch classifier loss: 0.385120; batch adversarial loss: 0.641416\n",
      "epoch 4; iter: 0; batch classifier loss: 0.273724; batch adversarial loss: 0.637157\n",
      "epoch 5; iter: 0; batch classifier loss: 0.320026; batch adversarial loss: 0.597830\n",
      "epoch 6; iter: 0; batch classifier loss: 0.369655; batch adversarial loss: 0.574986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239936; batch adversarial loss: 0.544765\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286461; batch adversarial loss: 0.556487\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267014; batch adversarial loss: 0.493609\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242021; batch adversarial loss: 0.499029\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224081; batch adversarial loss: 0.508370\n",
      "epoch 12; iter: 0; batch classifier loss: 0.191352; batch adversarial loss: 0.466435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239697; batch adversarial loss: 0.525497\n",
      "epoch 14; iter: 0; batch classifier loss: 0.142414; batch adversarial loss: 0.450868\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246066; batch adversarial loss: 0.488243\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207439; batch adversarial loss: 0.466822\n",
      "epoch 17; iter: 0; batch classifier loss: 0.160631; batch adversarial loss: 0.581292\n",
      "epoch 18; iter: 0; batch classifier loss: 0.165138; batch adversarial loss: 0.496666\n",
      "epoch 19; iter: 0; batch classifier loss: 0.127906; batch adversarial loss: 0.465329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.126444; batch adversarial loss: 0.474535\n",
      "epoch 21; iter: 0; batch classifier loss: 0.118288; batch adversarial loss: 0.477615\n",
      "epoch 22; iter: 0; batch classifier loss: 0.141035; batch adversarial loss: 0.416319\n",
      "epoch 23; iter: 0; batch classifier loss: 0.130817; batch adversarial loss: 0.578490\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138503; batch adversarial loss: 0.449087\n",
      "epoch 25; iter: 0; batch classifier loss: 0.121643; batch adversarial loss: 0.494036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.105002; batch adversarial loss: 0.480753\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118299; batch adversarial loss: 0.535230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.118978; batch adversarial loss: 0.533772\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142983; batch adversarial loss: 0.413933\n",
      "epoch 30; iter: 0; batch classifier loss: 0.096287; batch adversarial loss: 0.505962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104633; batch adversarial loss: 0.388423\n",
      "epoch 32; iter: 0; batch classifier loss: 0.130158; batch adversarial loss: 0.564554\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160768; batch adversarial loss: 0.423731\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155694; batch adversarial loss: 0.420927\n",
      "epoch 35; iter: 0; batch classifier loss: 0.143375; batch adversarial loss: 0.444868\n",
      "epoch 36; iter: 0; batch classifier loss: 0.265843; batch adversarial loss: 0.478237\n",
      "epoch 37; iter: 0; batch classifier loss: 0.261081; batch adversarial loss: 0.464682\n",
      "epoch 38; iter: 0; batch classifier loss: 0.114385; batch adversarial loss: 0.557437\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110330; batch adversarial loss: 0.478135\n",
      "epoch 40; iter: 0; batch classifier loss: 0.072376; batch adversarial loss: 0.463190\n",
      "epoch 41; iter: 0; batch classifier loss: 0.094578; batch adversarial loss: 0.386848\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087631; batch adversarial loss: 0.442447\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089135; batch adversarial loss: 0.464472\n",
      "epoch 44; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.389401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.059470; batch adversarial loss: 0.543184\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114634; batch adversarial loss: 0.383271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.050595; batch adversarial loss: 0.423569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.054688; batch adversarial loss: 0.475248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074798; batch adversarial loss: 0.431984\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075411; batch adversarial loss: 0.405616\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086893; batch adversarial loss: 0.492427\n",
      "epoch 52; iter: 0; batch classifier loss: 0.107057; batch adversarial loss: 0.343957\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070851; batch adversarial loss: 0.439164\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077536; batch adversarial loss: 0.446751\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072031; batch adversarial loss: 0.425160\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065563; batch adversarial loss: 0.502810\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077056; batch adversarial loss: 0.438875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052128; batch adversarial loss: 0.440620\n",
      "epoch 59; iter: 0; batch classifier loss: 0.040335; batch adversarial loss: 0.476747\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060640; batch adversarial loss: 0.560497\n",
      "epoch 61; iter: 0; batch classifier loss: 0.055782; batch adversarial loss: 0.458485\n",
      "epoch 62; iter: 0; batch classifier loss: 0.052149; batch adversarial loss: 0.401503\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057624; batch adversarial loss: 0.529933\n",
      "epoch 64; iter: 0; batch classifier loss: 0.058225; batch adversarial loss: 0.530971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.034267; batch adversarial loss: 0.530394\n",
      "epoch 66; iter: 0; batch classifier loss: 0.047637; batch adversarial loss: 0.567524\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062127; batch adversarial loss: 0.498205\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108141; batch adversarial loss: 0.507886\n",
      "epoch 69; iter: 0; batch classifier loss: 0.036869; batch adversarial loss: 0.442049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.069184; batch adversarial loss: 0.462259\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075903; batch adversarial loss: 0.368620\n",
      "epoch 72; iter: 0; batch classifier loss: 0.070133; batch adversarial loss: 0.462308\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061342; batch adversarial loss: 0.449051\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068260; batch adversarial loss: 0.440913\n",
      "epoch 75; iter: 0; batch classifier loss: 0.034392; batch adversarial loss: 0.392155\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062616; batch adversarial loss: 0.443656\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047775; batch adversarial loss: 0.501012\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055765; batch adversarial loss: 0.435731\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049426; batch adversarial loss: 0.414294\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055092; batch adversarial loss: 0.470702\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073730; batch adversarial loss: 0.498080\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047883; batch adversarial loss: 0.460625\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065086; batch adversarial loss: 0.480986\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039450; batch adversarial loss: 0.422394\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078468; batch adversarial loss: 0.421007\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066814; batch adversarial loss: 0.423612\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059413; batch adversarial loss: 0.509705\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058594; batch adversarial loss: 0.483513\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034389; batch adversarial loss: 0.501904\n",
      "epoch 90; iter: 0; batch classifier loss: 0.044151; batch adversarial loss: 0.389673\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073469; batch adversarial loss: 0.447776\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068188; batch adversarial loss: 0.533947\n",
      "epoch 93; iter: 0; batch classifier loss: 0.074002; batch adversarial loss: 0.516524\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046530; batch adversarial loss: 0.472359\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036922; batch adversarial loss: 0.465083\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043855; batch adversarial loss: 0.536029\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054486; batch adversarial loss: 0.468754\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036630; batch adversarial loss: 0.516261\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045359; batch adversarial loss: 0.391361\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074582; batch adversarial loss: 0.436778\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073995; batch adversarial loss: 0.443826\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037472; batch adversarial loss: 0.401909\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053041; batch adversarial loss: 0.417953\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076467; batch adversarial loss: 0.532728\n",
      "epoch 105; iter: 0; batch classifier loss: 0.028270; batch adversarial loss: 0.490395\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040640; batch adversarial loss: 0.475232\n",
      "epoch 107; iter: 0; batch classifier loss: 0.024450; batch adversarial loss: 0.457012\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070511; batch adversarial loss: 0.413334\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058429; batch adversarial loss: 0.456686\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060554; batch adversarial loss: 0.462618\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048941; batch adversarial loss: 0.486113\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017189; batch adversarial loss: 0.489130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046129; batch adversarial loss: 0.418332\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025507; batch adversarial loss: 0.410045\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034509; batch adversarial loss: 0.354943\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040741; batch adversarial loss: 0.387282\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025149; batch adversarial loss: 0.449646\n",
      "epoch 118; iter: 0; batch classifier loss: 0.036509; batch adversarial loss: 0.484474\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019044; batch adversarial loss: 0.656713\n",
      "epoch 120; iter: 0; batch classifier loss: 0.023457; batch adversarial loss: 0.395944\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030615; batch adversarial loss: 0.515722\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067719; batch adversarial loss: 0.500369\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016197; batch adversarial loss: 0.439225\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033630; batch adversarial loss: 0.376100\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027301; batch adversarial loss: 0.510664\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072231; batch adversarial loss: 0.564388\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016183; batch adversarial loss: 0.528959\n",
      "epoch 128; iter: 0; batch classifier loss: 0.049291; batch adversarial loss: 0.422956\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022923; batch adversarial loss: 0.396327\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046973; batch adversarial loss: 0.580925\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050948; batch adversarial loss: 0.404989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029311; batch adversarial loss: 0.470155\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036462; batch adversarial loss: 0.440675\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054971; batch adversarial loss: 0.549800\n",
      "epoch 135; iter: 0; batch classifier loss: 0.052990; batch adversarial loss: 0.462861\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036630; batch adversarial loss: 0.534947\n",
      "epoch 137; iter: 0; batch classifier loss: 0.050142; batch adversarial loss: 0.353982\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016262; batch adversarial loss: 0.397177\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027913; batch adversarial loss: 0.444463\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045963; batch adversarial loss: 0.433804\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030239; batch adversarial loss: 0.456550\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023451; batch adversarial loss: 0.504557\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016673; batch adversarial loss: 0.447990\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039135; batch adversarial loss: 0.380563\n",
      "epoch 145; iter: 0; batch classifier loss: 0.014019; batch adversarial loss: 0.431648\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038451; batch adversarial loss: 0.458253\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027029; batch adversarial loss: 0.429652\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029338; batch adversarial loss: 0.455314\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032471; batch adversarial loss: 0.434476\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021299; batch adversarial loss: 0.498888\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032703; batch adversarial loss: 0.438156\n",
      "epoch 152; iter: 0; batch classifier loss: 0.007333; batch adversarial loss: 0.528470\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008603; batch adversarial loss: 0.462831\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031981; batch adversarial loss: 0.471886\n",
      "epoch 155; iter: 0; batch classifier loss: 0.009756; batch adversarial loss: 0.480686\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021329; batch adversarial loss: 0.476876\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033133; batch adversarial loss: 0.475127\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050179; batch adversarial loss: 0.526169\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019834; batch adversarial loss: 0.467022\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037361; batch adversarial loss: 0.433918\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029043; batch adversarial loss: 0.466769\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039797; batch adversarial loss: 0.442238\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018722; batch adversarial loss: 0.499155\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013856; batch adversarial loss: 0.420712\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043029; batch adversarial loss: 0.375604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.019815; batch adversarial loss: 0.403971\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020768; batch adversarial loss: 0.464637\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027745; batch adversarial loss: 0.506890\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041082; batch adversarial loss: 0.568535\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031962; batch adversarial loss: 0.490026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.523034\n",
      "epoch 172; iter: 0; batch classifier loss: 0.028151; batch adversarial loss: 0.552059\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019547; batch adversarial loss: 0.357801\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020699; batch adversarial loss: 0.414209\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035324; batch adversarial loss: 0.401517\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008003; batch adversarial loss: 0.496598\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014293; batch adversarial loss: 0.519553\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019599; batch adversarial loss: 0.389402\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043580; batch adversarial loss: 0.436320\n",
      "epoch 180; iter: 0; batch classifier loss: 0.052284; batch adversarial loss: 0.486316\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027666; batch adversarial loss: 0.396460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014051; batch adversarial loss: 0.484655\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051507; batch adversarial loss: 0.347346\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019956; batch adversarial loss: 0.391648\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018236; batch adversarial loss: 0.497653\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020879; batch adversarial loss: 0.431656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020743; batch adversarial loss: 0.440658\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009595; batch adversarial loss: 0.376922\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011315; batch adversarial loss: 0.360819\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029457; batch adversarial loss: 0.463126\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024456; batch adversarial loss: 0.363185\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019867; batch adversarial loss: 0.423786\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011309; batch adversarial loss: 0.537937\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.466558\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013612; batch adversarial loss: 0.525206\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006090; batch adversarial loss: 0.541822\n",
      "epoch 197; iter: 0; batch classifier loss: 0.049957; batch adversarial loss: 0.359308\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009584; batch adversarial loss: 0.435816\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035602; batch adversarial loss: 0.506009\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690966; batch adversarial loss: 0.720777\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417004; batch adversarial loss: 0.679889\n",
      "epoch 2; iter: 0; batch classifier loss: 0.364806; batch adversarial loss: 0.651446\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398466; batch adversarial loss: 0.617515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.293123; batch adversarial loss: 0.583935\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375949; batch adversarial loss: 0.579011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296053; batch adversarial loss: 0.564451\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271712; batch adversarial loss: 0.497995\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381637; batch adversarial loss: 0.513844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244845; batch adversarial loss: 0.477744\n",
      "epoch 10; iter: 0; batch classifier loss: 0.208226; batch adversarial loss: 0.506623\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275151; batch adversarial loss: 0.463314\n",
      "epoch 12; iter: 0; batch classifier loss: 0.181321; batch adversarial loss: 0.511649\n",
      "epoch 13; iter: 0; batch classifier loss: 0.196953; batch adversarial loss: 0.459126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192245; batch adversarial loss: 0.497566\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182552; batch adversarial loss: 0.512993\n",
      "epoch 16; iter: 0; batch classifier loss: 0.137867; batch adversarial loss: 0.525385\n",
      "epoch 17; iter: 0; batch classifier loss: 0.157102; batch adversarial loss: 0.504293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.142196; batch adversarial loss: 0.522412\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167557; batch adversarial loss: 0.554148\n",
      "epoch 20; iter: 0; batch classifier loss: 0.153077; batch adversarial loss: 0.445940\n",
      "epoch 21; iter: 0; batch classifier loss: 0.134336; batch adversarial loss: 0.437853\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224749; batch adversarial loss: 0.603379\n",
      "epoch 23; iter: 0; batch classifier loss: 0.091777; batch adversarial loss: 0.516892\n",
      "epoch 24; iter: 0; batch classifier loss: 0.134506; batch adversarial loss: 0.508108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.156559; batch adversarial loss: 0.480934\n",
      "epoch 26; iter: 0; batch classifier loss: 0.223964; batch adversarial loss: 0.525339\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241561; batch adversarial loss: 0.576934\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189423; batch adversarial loss: 0.420148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237540; batch adversarial loss: 0.471782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.208747; batch adversarial loss: 0.519043\n",
      "epoch 31; iter: 0; batch classifier loss: 0.285136; batch adversarial loss: 0.426604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201967; batch adversarial loss: 0.486677\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145914; batch adversarial loss: 0.566690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106386; batch adversarial loss: 0.429620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.088281; batch adversarial loss: 0.404362\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098776; batch adversarial loss: 0.486710\n",
      "epoch 37; iter: 0; batch classifier loss: 0.068090; batch adversarial loss: 0.493874\n",
      "epoch 38; iter: 0; batch classifier loss: 0.099494; batch adversarial loss: 0.394797\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082626; batch adversarial loss: 0.427126\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131544; batch adversarial loss: 0.421849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120504; batch adversarial loss: 0.448590\n",
      "epoch 42; iter: 0; batch classifier loss: 0.081003; batch adversarial loss: 0.529637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110456; batch adversarial loss: 0.493979\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101969; batch adversarial loss: 0.506145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138528; batch adversarial loss: 0.369592\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094508; batch adversarial loss: 0.434694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087928; batch adversarial loss: 0.498217\n",
      "epoch 48; iter: 0; batch classifier loss: 0.053902; batch adversarial loss: 0.403811\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086704; batch adversarial loss: 0.426452\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084611; batch adversarial loss: 0.407024\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129023; batch adversarial loss: 0.306579\n",
      "epoch 52; iter: 0; batch classifier loss: 0.052680; batch adversarial loss: 0.378449\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062693; batch adversarial loss: 0.509474\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086996; batch adversarial loss: 0.590071\n",
      "epoch 55; iter: 0; batch classifier loss: 0.119561; batch adversarial loss: 0.417789\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078983; batch adversarial loss: 0.504925\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086990; batch adversarial loss: 0.446326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073481; batch adversarial loss: 0.404788\n",
      "epoch 59; iter: 0; batch classifier loss: 0.062968; batch adversarial loss: 0.486341\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077101; batch adversarial loss: 0.422789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.091042; batch adversarial loss: 0.420586\n",
      "epoch 62; iter: 0; batch classifier loss: 0.061272; batch adversarial loss: 0.417173\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060150; batch adversarial loss: 0.414249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.078071; batch adversarial loss: 0.445480\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056788; batch adversarial loss: 0.439925\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069495; batch adversarial loss: 0.488279\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114903; batch adversarial loss: 0.402850\n",
      "epoch 68; iter: 0; batch classifier loss: 0.059434; batch adversarial loss: 0.409353\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069720; batch adversarial loss: 0.504962\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065680; batch adversarial loss: 0.535909\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105074; batch adversarial loss: 0.479591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071995; batch adversarial loss: 0.434656\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123083; batch adversarial loss: 0.461730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.200298; batch adversarial loss: 0.476427\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065523; batch adversarial loss: 0.493754\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058665; batch adversarial loss: 0.386068\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095883; batch adversarial loss: 0.372803\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059116; batch adversarial loss: 0.490707\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056333; batch adversarial loss: 0.481003\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066508; batch adversarial loss: 0.462521\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068762; batch adversarial loss: 0.489687\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064581; batch adversarial loss: 0.489477\n",
      "epoch 83; iter: 0; batch classifier loss: 0.051157; batch adversarial loss: 0.473662\n",
      "epoch 84; iter: 0; batch classifier loss: 0.090768; batch adversarial loss: 0.384532\n",
      "epoch 85; iter: 0; batch classifier loss: 0.035057; batch adversarial loss: 0.426497\n",
      "epoch 86; iter: 0; batch classifier loss: 0.099721; batch adversarial loss: 0.516882\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058501; batch adversarial loss: 0.455876\n",
      "epoch 88; iter: 0; batch classifier loss: 0.098123; batch adversarial loss: 0.430899\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071625; batch adversarial loss: 0.375262\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054279; batch adversarial loss: 0.512052\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070080; batch adversarial loss: 0.502922\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117294; batch adversarial loss: 0.428478\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062919; batch adversarial loss: 0.418457\n",
      "epoch 94; iter: 0; batch classifier loss: 0.119223; batch adversarial loss: 0.444309\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057767; batch adversarial loss: 0.503772\n",
      "epoch 96; iter: 0; batch classifier loss: 0.031341; batch adversarial loss: 0.478166\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051838; batch adversarial loss: 0.464004\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074618; batch adversarial loss: 0.456936\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041027; batch adversarial loss: 0.472690\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051348; batch adversarial loss: 0.443830\n",
      "epoch 101; iter: 0; batch classifier loss: 0.093448; batch adversarial loss: 0.470240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034245; batch adversarial loss: 0.536346\n",
      "epoch 103; iter: 0; batch classifier loss: 0.069242; batch adversarial loss: 0.409980\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073988; batch adversarial loss: 0.430193\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046532; batch adversarial loss: 0.499244\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055049; batch adversarial loss: 0.406846\n",
      "epoch 107; iter: 0; batch classifier loss: 0.070919; batch adversarial loss: 0.455662\n",
      "epoch 108; iter: 0; batch classifier loss: 0.062200; batch adversarial loss: 0.482329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090536; batch adversarial loss: 0.356506\n",
      "epoch 110; iter: 0; batch classifier loss: 0.072412; batch adversarial loss: 0.541664\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037784; batch adversarial loss: 0.499505\n",
      "epoch 112; iter: 0; batch classifier loss: 0.081748; batch adversarial loss: 0.363879\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042161; batch adversarial loss: 0.542915\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043094; batch adversarial loss: 0.499738\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035945; batch adversarial loss: 0.342425\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037489; batch adversarial loss: 0.462726\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023131; batch adversarial loss: 0.412414\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030250; batch adversarial loss: 0.503457\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033208; batch adversarial loss: 0.518925\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041231; batch adversarial loss: 0.541873\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.447192\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049991; batch adversarial loss: 0.432214\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047677; batch adversarial loss: 0.485304\n",
      "epoch 124; iter: 0; batch classifier loss: 0.043925; batch adversarial loss: 0.398934\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056638; batch adversarial loss: 0.374463\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021427; batch adversarial loss: 0.473873\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053473; batch adversarial loss: 0.460606\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038410; batch adversarial loss: 0.407135\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030054; batch adversarial loss: 0.490246\n",
      "epoch 130; iter: 0; batch classifier loss: 0.018121; batch adversarial loss: 0.434447\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024648; batch adversarial loss: 0.414270\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017334; batch adversarial loss: 0.484024\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038478; batch adversarial loss: 0.448071\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027559; batch adversarial loss: 0.453554\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027534; batch adversarial loss: 0.485612\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028875; batch adversarial loss: 0.458004\n",
      "epoch 137; iter: 0; batch classifier loss: 0.091761; batch adversarial loss: 0.499041\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034578; batch adversarial loss: 0.471183\n",
      "epoch 139; iter: 0; batch classifier loss: 0.012930; batch adversarial loss: 0.478888\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036150; batch adversarial loss: 0.434199\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031347; batch adversarial loss: 0.384249\n",
      "epoch 142; iter: 0; batch classifier loss: 0.048024; batch adversarial loss: 0.408153\n",
      "epoch 143; iter: 0; batch classifier loss: 0.047467; batch adversarial loss: 0.537509\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022467; batch adversarial loss: 0.408299\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022960; batch adversarial loss: 0.450740\n",
      "epoch 146; iter: 0; batch classifier loss: 0.052295; batch adversarial loss: 0.480537\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038861; batch adversarial loss: 0.490988\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024952; batch adversarial loss: 0.455996\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020170; batch adversarial loss: 0.468469\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029009; batch adversarial loss: 0.469137\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033852; batch adversarial loss: 0.404205\n",
      "epoch 152; iter: 0; batch classifier loss: 0.084632; batch adversarial loss: 0.464589\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021654; batch adversarial loss: 0.376741\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021126; batch adversarial loss: 0.356164\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044373; batch adversarial loss: 0.524290\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030704; batch adversarial loss: 0.544317\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013969; batch adversarial loss: 0.523139\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025629; batch adversarial loss: 0.432586\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027053; batch adversarial loss: 0.523177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.045527; batch adversarial loss: 0.480659\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033725; batch adversarial loss: 0.452089\n",
      "epoch 162; iter: 0; batch classifier loss: 0.043043; batch adversarial loss: 0.449450\n",
      "epoch 163; iter: 0; batch classifier loss: 0.020545; batch adversarial loss: 0.454407\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020284; batch adversarial loss: 0.444897\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026192; batch adversarial loss: 0.507896\n",
      "epoch 166; iter: 0; batch classifier loss: 0.004416; batch adversarial loss: 0.391164\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028502; batch adversarial loss: 0.453142\n",
      "epoch 168; iter: 0; batch classifier loss: 0.006129; batch adversarial loss: 0.436096\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013745; batch adversarial loss: 0.491820\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012913; batch adversarial loss: 0.367312\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025738; batch adversarial loss: 0.472477\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008495; batch adversarial loss: 0.470037\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012453; batch adversarial loss: 0.468752\n",
      "epoch 174; iter: 0; batch classifier loss: 0.055142; batch adversarial loss: 0.455692\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012987; batch adversarial loss: 0.445712\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023266; batch adversarial loss: 0.404698\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016048; batch adversarial loss: 0.452214\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015759; batch adversarial loss: 0.520858\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038919; batch adversarial loss: 0.473017\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015275; batch adversarial loss: 0.407960\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047310; batch adversarial loss: 0.331053\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013192; batch adversarial loss: 0.489032\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028219; batch adversarial loss: 0.508635\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019950; batch adversarial loss: 0.395556\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043143; batch adversarial loss: 0.568071\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014340; batch adversarial loss: 0.410541\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017914; batch adversarial loss: 0.579216\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010979; batch adversarial loss: 0.515932\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010052; batch adversarial loss: 0.391773\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.416466\n",
      "epoch 191; iter: 0; batch classifier loss: 0.076712; batch adversarial loss: 0.436025\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012656; batch adversarial loss: 0.382017\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022477; batch adversarial loss: 0.447948\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024188; batch adversarial loss: 0.456578\n",
      "epoch 195; iter: 0; batch classifier loss: 0.046898; batch adversarial loss: 0.518569\n",
      "epoch 196; iter: 0; batch classifier loss: 0.061087; batch adversarial loss: 0.530770\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014315; batch adversarial loss: 0.365298\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037132; batch adversarial loss: 0.434797\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042589; batch adversarial loss: 0.424719\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674344; batch adversarial loss: 0.761785\n",
      "epoch 1; iter: 0; batch classifier loss: 0.480188; batch adversarial loss: 0.721774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.348940; batch adversarial loss: 0.684781\n",
      "epoch 3; iter: 0; batch classifier loss: 0.332477; batch adversarial loss: 0.650895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.414125; batch adversarial loss: 0.619688\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327447; batch adversarial loss: 0.597596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320365; batch adversarial loss: 0.580234\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339000; batch adversarial loss: 0.520734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.263596; batch adversarial loss: 0.555822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316628; batch adversarial loss: 0.534998\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298846; batch adversarial loss: 0.480954\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288755; batch adversarial loss: 0.504488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.181455; batch adversarial loss: 0.481641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249854; batch adversarial loss: 0.485349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253191; batch adversarial loss: 0.443440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167138; batch adversarial loss: 0.463968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.219507; batch adversarial loss: 0.444116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199186; batch adversarial loss: 0.461818\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187273; batch adversarial loss: 0.407669\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219424; batch adversarial loss: 0.430559\n",
      "epoch 20; iter: 0; batch classifier loss: 0.108632; batch adversarial loss: 0.497333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140781; batch adversarial loss: 0.441432\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216648; batch adversarial loss: 0.364037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.139485; batch adversarial loss: 0.429677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185502; batch adversarial loss: 0.486571\n",
      "epoch 25; iter: 0; batch classifier loss: 0.193002; batch adversarial loss: 0.362172\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134970; batch adversarial loss: 0.427759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.116625; batch adversarial loss: 0.424057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.142453; batch adversarial loss: 0.436116\n",
      "epoch 29; iter: 0; batch classifier loss: 0.128647; batch adversarial loss: 0.397204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.108766; batch adversarial loss: 0.420663\n",
      "epoch 31; iter: 0; batch classifier loss: 0.147737; batch adversarial loss: 0.503193\n",
      "epoch 32; iter: 0; batch classifier loss: 0.164267; batch adversarial loss: 0.446448\n",
      "epoch 33; iter: 0; batch classifier loss: 0.108307; batch adversarial loss: 0.383964\n",
      "epoch 34; iter: 0; batch classifier loss: 0.123323; batch adversarial loss: 0.393828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125682; batch adversarial loss: 0.413197\n",
      "epoch 36; iter: 0; batch classifier loss: 0.085222; batch adversarial loss: 0.405833\n",
      "epoch 37; iter: 0; batch classifier loss: 0.083150; batch adversarial loss: 0.391585\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165081; batch adversarial loss: 0.432093\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107074; batch adversarial loss: 0.415100\n",
      "epoch 40; iter: 0; batch classifier loss: 0.127872; batch adversarial loss: 0.329119\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177495; batch adversarial loss: 0.422991\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123282; batch adversarial loss: 0.416179\n",
      "epoch 43; iter: 0; batch classifier loss: 0.127104; batch adversarial loss: 0.438663\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086939; batch adversarial loss: 0.339113\n",
      "epoch 45; iter: 0; batch classifier loss: 0.090680; batch adversarial loss: 0.437293\n",
      "epoch 46; iter: 0; batch classifier loss: 0.126725; batch adversarial loss: 0.495313\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098777; batch adversarial loss: 0.381880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.116971; batch adversarial loss: 0.380192\n",
      "epoch 49; iter: 0; batch classifier loss: 0.083837; batch adversarial loss: 0.369207\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118203; batch adversarial loss: 0.389017\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118684; batch adversarial loss: 0.393406\n",
      "epoch 52; iter: 0; batch classifier loss: 0.120669; batch adversarial loss: 0.422486\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117945; batch adversarial loss: 0.449256\n",
      "epoch 54; iter: 0; batch classifier loss: 0.057995; batch adversarial loss: 0.531614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072904; batch adversarial loss: 0.349013\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069218; batch adversarial loss: 0.335901\n",
      "epoch 57; iter: 0; batch classifier loss: 0.049960; batch adversarial loss: 0.413530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.058703; batch adversarial loss: 0.459365\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072264; batch adversarial loss: 0.379450\n",
      "epoch 60; iter: 0; batch classifier loss: 0.092195; batch adversarial loss: 0.456784\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164453; batch adversarial loss: 0.449094\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113395; batch adversarial loss: 0.478596\n",
      "epoch 63; iter: 0; batch classifier loss: 0.090829; batch adversarial loss: 0.367305\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101879; batch adversarial loss: 0.389933\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113207; batch adversarial loss: 0.429062\n",
      "epoch 66; iter: 0; batch classifier loss: 0.120515; batch adversarial loss: 0.514970\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070113; batch adversarial loss: 0.447900\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091845; batch adversarial loss: 0.423665\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073217; batch adversarial loss: 0.396813\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072546; batch adversarial loss: 0.350707\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071543; batch adversarial loss: 0.402642\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083411; batch adversarial loss: 0.472324\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084000; batch adversarial loss: 0.587656\n",
      "epoch 74; iter: 0; batch classifier loss: 0.046598; batch adversarial loss: 0.363363\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063911; batch adversarial loss: 0.351772\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055284; batch adversarial loss: 0.493572\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046121; batch adversarial loss: 0.381516\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090515; batch adversarial loss: 0.395363\n",
      "epoch 79; iter: 0; batch classifier loss: 0.079850; batch adversarial loss: 0.407718\n",
      "epoch 80; iter: 0; batch classifier loss: 0.059931; batch adversarial loss: 0.377144\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051664; batch adversarial loss: 0.428808\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104137; batch adversarial loss: 0.478272\n",
      "epoch 83; iter: 0; batch classifier loss: 0.067697; batch adversarial loss: 0.375780\n",
      "epoch 84; iter: 0; batch classifier loss: 0.061340; batch adversarial loss: 0.338594\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050717; batch adversarial loss: 0.490607\n",
      "epoch 86; iter: 0; batch classifier loss: 0.062577; batch adversarial loss: 0.482938\n",
      "epoch 87; iter: 0; batch classifier loss: 0.091177; batch adversarial loss: 0.385839\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100284; batch adversarial loss: 0.410055\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050727; batch adversarial loss: 0.352086\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077776; batch adversarial loss: 0.513866\n",
      "epoch 91; iter: 0; batch classifier loss: 0.069678; batch adversarial loss: 0.440275\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061115; batch adversarial loss: 0.406276\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066730; batch adversarial loss: 0.332029\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.369107\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040502; batch adversarial loss: 0.381118\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051767; batch adversarial loss: 0.456590\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059951; batch adversarial loss: 0.432866\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082822; batch adversarial loss: 0.445845\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079020; batch adversarial loss: 0.348102\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069402; batch adversarial loss: 0.367697\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046519; batch adversarial loss: 0.478472\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062829; batch adversarial loss: 0.455535\n",
      "epoch 103; iter: 0; batch classifier loss: 0.034840; batch adversarial loss: 0.443589\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080960; batch adversarial loss: 0.386473\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053867; batch adversarial loss: 0.426716\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039496; batch adversarial loss: 0.386059\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039597; batch adversarial loss: 0.448679\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043627; batch adversarial loss: 0.398956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062886; batch adversarial loss: 0.364129\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077222; batch adversarial loss: 0.462763\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060373; batch adversarial loss: 0.404172\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073732; batch adversarial loss: 0.484469\n",
      "epoch 113; iter: 0; batch classifier loss: 0.087770; batch adversarial loss: 0.415169\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047561; batch adversarial loss: 0.388940\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062722; batch adversarial loss: 0.342863\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056658; batch adversarial loss: 0.404756\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044027; batch adversarial loss: 0.383389\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070051; batch adversarial loss: 0.459053\n",
      "epoch 119; iter: 0; batch classifier loss: 0.072243; batch adversarial loss: 0.309069\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041511; batch adversarial loss: 0.557585\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053744; batch adversarial loss: 0.427890\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064095; batch adversarial loss: 0.449191\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051774; batch adversarial loss: 0.428521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039912; batch adversarial loss: 0.435500\n",
      "epoch 125; iter: 0; batch classifier loss: 0.110352; batch adversarial loss: 0.387007\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058005; batch adversarial loss: 0.387066\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034295; batch adversarial loss: 0.449966\n",
      "epoch 128; iter: 0; batch classifier loss: 0.023543; batch adversarial loss: 0.412324\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041789; batch adversarial loss: 0.496939\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035278; batch adversarial loss: 0.428020\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062290; batch adversarial loss: 0.356646\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.371831\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024230; batch adversarial loss: 0.438651\n",
      "epoch 134; iter: 0; batch classifier loss: 0.014937; batch adversarial loss: 0.477102\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023424; batch adversarial loss: 0.478924\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035969; batch adversarial loss: 0.506091\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026092; batch adversarial loss: 0.490668\n",
      "epoch 138; iter: 0; batch classifier loss: 0.021259; batch adversarial loss: 0.467271\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022208; batch adversarial loss: 0.437428\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036143; batch adversarial loss: 0.430840\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048423; batch adversarial loss: 0.359889\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018825; batch adversarial loss: 0.493387\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025254; batch adversarial loss: 0.539211\n",
      "epoch 144; iter: 0; batch classifier loss: 0.075385; batch adversarial loss: 0.555156\n",
      "epoch 145; iter: 0; batch classifier loss: 0.094471; batch adversarial loss: 0.548578\n",
      "epoch 146; iter: 0; batch classifier loss: 0.090383; batch adversarial loss: 0.566142\n",
      "epoch 147; iter: 0; batch classifier loss: 0.085195; batch adversarial loss: 0.604973\n",
      "epoch 148; iter: 0; batch classifier loss: 0.149626; batch adversarial loss: 0.595758\n",
      "epoch 149; iter: 0; batch classifier loss: 0.088749; batch adversarial loss: 0.616667\n",
      "epoch 150; iter: 0; batch classifier loss: 0.136815; batch adversarial loss: 0.647918\n",
      "epoch 151; iter: 0; batch classifier loss: 0.073533; batch adversarial loss: 0.527443\n",
      "epoch 152; iter: 0; batch classifier loss: 0.268312; batch adversarial loss: 0.811658\n",
      "epoch 153; iter: 0; batch classifier loss: 0.122889; batch adversarial loss: 0.634993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.159761; batch adversarial loss: 0.715034\n",
      "epoch 155; iter: 0; batch classifier loss: 0.119135; batch adversarial loss: 0.599241\n",
      "epoch 156; iter: 0; batch classifier loss: 0.146276; batch adversarial loss: 0.608363\n",
      "epoch 157; iter: 0; batch classifier loss: 0.148316; batch adversarial loss: 0.611448\n",
      "epoch 158; iter: 0; batch classifier loss: 0.224646; batch adversarial loss: 0.683314\n",
      "epoch 159; iter: 0; batch classifier loss: 0.136532; batch adversarial loss: 0.628103\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182539; batch adversarial loss: 0.677285\n",
      "epoch 161; iter: 0; batch classifier loss: 0.275540; batch adversarial loss: 0.831102\n",
      "epoch 162; iter: 0; batch classifier loss: 0.200247; batch adversarial loss: 0.738638\n",
      "epoch 163; iter: 0; batch classifier loss: 0.113463; batch adversarial loss: 0.583269\n",
      "epoch 164; iter: 0; batch classifier loss: 0.273818; batch adversarial loss: 0.733950\n",
      "epoch 165; iter: 0; batch classifier loss: 0.196198; batch adversarial loss: 0.591527\n",
      "epoch 166; iter: 0; batch classifier loss: 0.181654; batch adversarial loss: 0.618819\n",
      "epoch 167; iter: 0; batch classifier loss: 0.254785; batch adversarial loss: 0.713947\n",
      "epoch 168; iter: 0; batch classifier loss: 0.147384; batch adversarial loss: 0.552114\n",
      "epoch 169; iter: 0; batch classifier loss: 0.178654; batch adversarial loss: 0.555613\n",
      "epoch 170; iter: 0; batch classifier loss: 0.182236; batch adversarial loss: 0.634428\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168416; batch adversarial loss: 0.552378\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151507; batch adversarial loss: 0.646238\n",
      "epoch 173; iter: 0; batch classifier loss: 0.170278; batch adversarial loss: 0.560105\n",
      "epoch 174; iter: 0; batch classifier loss: 0.206660; batch adversarial loss: 0.662859\n",
      "epoch 175; iter: 0; batch classifier loss: 0.136885; batch adversarial loss: 0.441621\n",
      "epoch 176; iter: 0; batch classifier loss: 0.152231; batch adversarial loss: 0.543983\n",
      "epoch 177; iter: 0; batch classifier loss: 0.127235; batch adversarial loss: 0.551806\n",
      "epoch 178; iter: 0; batch classifier loss: 0.134738; batch adversarial loss: 0.493059\n",
      "epoch 179; iter: 0; batch classifier loss: 0.151870; batch adversarial loss: 0.534239\n",
      "epoch 180; iter: 0; batch classifier loss: 0.189409; batch adversarial loss: 0.548995\n",
      "epoch 181; iter: 0; batch classifier loss: 0.126158; batch adversarial loss: 0.562390\n",
      "epoch 182; iter: 0; batch classifier loss: 0.141055; batch adversarial loss: 0.511821\n",
      "epoch 183; iter: 0; batch classifier loss: 0.108564; batch adversarial loss: 0.450283\n",
      "epoch 184; iter: 0; batch classifier loss: 0.241548; batch adversarial loss: 0.530396\n",
      "epoch 185; iter: 0; batch classifier loss: 0.160761; batch adversarial loss: 0.500146\n",
      "epoch 186; iter: 0; batch classifier loss: 0.174600; batch adversarial loss: 0.498248\n",
      "epoch 187; iter: 0; batch classifier loss: 0.152374; batch adversarial loss: 0.451570\n",
      "epoch 188; iter: 0; batch classifier loss: 0.117514; batch adversarial loss: 0.442493\n",
      "epoch 189; iter: 0; batch classifier loss: 0.107890; batch adversarial loss: 0.430167\n",
      "epoch 190; iter: 0; batch classifier loss: 0.091252; batch adversarial loss: 0.413681\n",
      "epoch 191; iter: 0; batch classifier loss: 0.141763; batch adversarial loss: 0.570151\n",
      "epoch 192; iter: 0; batch classifier loss: 0.116558; batch adversarial loss: 0.479358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.124365; batch adversarial loss: 0.552228\n",
      "epoch 194; iter: 0; batch classifier loss: 0.127918; batch adversarial loss: 0.537470\n",
      "epoch 195; iter: 0; batch classifier loss: 0.133536; batch adversarial loss: 0.509633\n",
      "epoch 196; iter: 0; batch classifier loss: 0.129681; batch adversarial loss: 0.457859\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017248; batch adversarial loss: 0.385151\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022088; batch adversarial loss: 0.420509\n",
      "epoch 199; iter: 0; batch classifier loss: 0.045599; batch adversarial loss: 0.515550\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674913; batch adversarial loss: 1.051938\n",
      "epoch 1; iter: 0; batch classifier loss: 0.560599; batch adversarial loss: 1.243114\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671789; batch adversarial loss: 1.201006\n",
      "epoch 3; iter: 0; batch classifier loss: 0.880073; batch adversarial loss: 1.157195\n",
      "epoch 4; iter: 0; batch classifier loss: 1.063222; batch adversarial loss: 1.044437\n",
      "epoch 5; iter: 0; batch classifier loss: 0.856301; batch adversarial loss: 0.941073\n",
      "epoch 6; iter: 0; batch classifier loss: 0.644124; batch adversarial loss: 0.907759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.723067; batch adversarial loss: 0.787994\n",
      "epoch 8; iter: 0; batch classifier loss: 0.371299; batch adversarial loss: 0.722511\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323715; batch adversarial loss: 0.648954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.266892; batch adversarial loss: 0.647875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284161; batch adversarial loss: 0.599092\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300180; batch adversarial loss: 0.595971\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301125; batch adversarial loss: 0.596098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231146; batch adversarial loss: 0.589453\n",
      "epoch 15; iter: 0; batch classifier loss: 0.186781; batch adversarial loss: 0.511335\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283227; batch adversarial loss: 0.513301\n",
      "epoch 17; iter: 0; batch classifier loss: 0.231327; batch adversarial loss: 0.485985\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301252; batch adversarial loss: 0.520916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174054; batch adversarial loss: 0.507694\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265402; batch adversarial loss: 0.542383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199411; batch adversarial loss: 0.436560\n",
      "epoch 22; iter: 0; batch classifier loss: 0.237889; batch adversarial loss: 0.482009\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247621; batch adversarial loss: 0.473517\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202007; batch adversarial loss: 0.441757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172992; batch adversarial loss: 0.485909\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182057; batch adversarial loss: 0.431484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203227; batch adversarial loss: 0.429358\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197510; batch adversarial loss: 0.439201\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200302; batch adversarial loss: 0.436785\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162837; batch adversarial loss: 0.508791\n",
      "epoch 31; iter: 0; batch classifier loss: 0.131164; batch adversarial loss: 0.401290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.111747; batch adversarial loss: 0.426198\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181265; batch adversarial loss: 0.481110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194662; batch adversarial loss: 0.498266\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123033; batch adversarial loss: 0.487120\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165338; batch adversarial loss: 0.432429\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177920; batch adversarial loss: 0.472789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.200752; batch adversarial loss: 0.460241\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132059; batch adversarial loss: 0.544583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164569; batch adversarial loss: 0.309293\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108480; batch adversarial loss: 0.331258\n",
      "epoch 42; iter: 0; batch classifier loss: 0.090495; batch adversarial loss: 0.425978\n",
      "epoch 43; iter: 0; batch classifier loss: 0.093442; batch adversarial loss: 0.475258\n",
      "epoch 44; iter: 0; batch classifier loss: 0.128554; batch adversarial loss: 0.378599\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142939; batch adversarial loss: 0.426463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161097; batch adversarial loss: 0.487757\n",
      "epoch 47; iter: 0; batch classifier loss: 0.162823; batch adversarial loss: 0.509094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.093635; batch adversarial loss: 0.488470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101152; batch adversarial loss: 0.503484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.097298; batch adversarial loss: 0.324520\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093267; batch adversarial loss: 0.504256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081651; batch adversarial loss: 0.505966\n",
      "epoch 53; iter: 0; batch classifier loss: 0.101144; batch adversarial loss: 0.441772\n",
      "epoch 54; iter: 0; batch classifier loss: 0.094745; batch adversarial loss: 0.479975\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070588; batch adversarial loss: 0.423460\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085349; batch adversarial loss: 0.428011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073010; batch adversarial loss: 0.478730\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080448; batch adversarial loss: 0.528223\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090389; batch adversarial loss: 0.462903\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088246; batch adversarial loss: 0.424115\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062245; batch adversarial loss: 0.414988\n",
      "epoch 62; iter: 0; batch classifier loss: 0.036905; batch adversarial loss: 0.441550\n",
      "epoch 63; iter: 0; batch classifier loss: 0.043888; batch adversarial loss: 0.464073\n",
      "epoch 64; iter: 0; batch classifier loss: 0.055698; batch adversarial loss: 0.424334\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065528; batch adversarial loss: 0.429828\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112399; batch adversarial loss: 0.471883\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088377; batch adversarial loss: 0.430085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097412; batch adversarial loss: 0.403182\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090044; batch adversarial loss: 0.489953\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067666; batch adversarial loss: 0.375010\n",
      "epoch 71; iter: 0; batch classifier loss: 0.093186; batch adversarial loss: 0.370349\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093673; batch adversarial loss: 0.452769\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087727; batch adversarial loss: 0.371522\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091563; batch adversarial loss: 0.420699\n",
      "epoch 75; iter: 0; batch classifier loss: 0.037087; batch adversarial loss: 0.507472\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056134; batch adversarial loss: 0.377478\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055902; batch adversarial loss: 0.415883\n",
      "epoch 78; iter: 0; batch classifier loss: 0.082602; batch adversarial loss: 0.546188\n",
      "epoch 79; iter: 0; batch classifier loss: 0.043549; batch adversarial loss: 0.357459\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055049; batch adversarial loss: 0.444386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053527; batch adversarial loss: 0.363450\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045386; batch adversarial loss: 0.436642\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090684; batch adversarial loss: 0.453887\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064745; batch adversarial loss: 0.343893\n",
      "epoch 85; iter: 0; batch classifier loss: 0.084783; batch adversarial loss: 0.530025\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090291; batch adversarial loss: 0.516095\n",
      "epoch 87; iter: 0; batch classifier loss: 0.082769; batch adversarial loss: 0.508077\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037871; batch adversarial loss: 0.367125\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050991; batch adversarial loss: 0.338886\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034215; batch adversarial loss: 0.412228\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043498; batch adversarial loss: 0.416564\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060634; batch adversarial loss: 0.541728\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063226; batch adversarial loss: 0.530788\n",
      "epoch 94; iter: 0; batch classifier loss: 0.033204; batch adversarial loss: 0.378429\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045371; batch adversarial loss: 0.522712\n",
      "epoch 96; iter: 0; batch classifier loss: 0.081995; batch adversarial loss: 0.390574\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087109; batch adversarial loss: 0.464685\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032925; batch adversarial loss: 0.511133\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077286; batch adversarial loss: 0.449959\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047590; batch adversarial loss: 0.361338\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058219; batch adversarial loss: 0.474574\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074014; batch adversarial loss: 0.455077\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045367; batch adversarial loss: 0.454543\n",
      "epoch 104; iter: 0; batch classifier loss: 0.045250; batch adversarial loss: 0.395651\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052968; batch adversarial loss: 0.407045\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062004; batch adversarial loss: 0.389928\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079928; batch adversarial loss: 0.383882\n",
      "epoch 108; iter: 0; batch classifier loss: 0.031730; batch adversarial loss: 0.402007\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045918; batch adversarial loss: 0.438652\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058476; batch adversarial loss: 0.548086\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033112; batch adversarial loss: 0.302167\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053436; batch adversarial loss: 0.372710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077469; batch adversarial loss: 0.408654\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059021; batch adversarial loss: 0.412245\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062513; batch adversarial loss: 0.426488\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041685; batch adversarial loss: 0.419830\n",
      "epoch 117; iter: 0; batch classifier loss: 0.065531; batch adversarial loss: 0.480864\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043074; batch adversarial loss: 0.476712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041070; batch adversarial loss: 0.385216\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042423; batch adversarial loss: 0.404904\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038931; batch adversarial loss: 0.417154\n",
      "epoch 122; iter: 0; batch classifier loss: 0.042087; batch adversarial loss: 0.415140\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063618; batch adversarial loss: 0.415332\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039868; batch adversarial loss: 0.404014\n",
      "epoch 125; iter: 0; batch classifier loss: 0.086862; batch adversarial loss: 0.447475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.059268; batch adversarial loss: 0.457474\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057496; batch adversarial loss: 0.426850\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070705; batch adversarial loss: 0.359348\n",
      "epoch 129; iter: 0; batch classifier loss: 0.043245; batch adversarial loss: 0.333628\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045640; batch adversarial loss: 0.462702\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055215; batch adversarial loss: 0.455082\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027763; batch adversarial loss: 0.427191\n",
      "epoch 133; iter: 0; batch classifier loss: 0.064455; batch adversarial loss: 0.493676\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049094; batch adversarial loss: 0.423440\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021138; batch adversarial loss: 0.601327\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039264; batch adversarial loss: 0.328257\n",
      "epoch 137; iter: 0; batch classifier loss: 0.055713; batch adversarial loss: 0.425467\n",
      "epoch 138; iter: 0; batch classifier loss: 0.075606; batch adversarial loss: 0.457577\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065575; batch adversarial loss: 0.419291\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051033; batch adversarial loss: 0.363307\n",
      "epoch 141; iter: 0; batch classifier loss: 0.087805; batch adversarial loss: 0.522751\n",
      "epoch 142; iter: 0; batch classifier loss: 0.068498; batch adversarial loss: 0.489408\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040078; batch adversarial loss: 0.357143\n",
      "epoch 144; iter: 0; batch classifier loss: 0.056253; batch adversarial loss: 0.464554\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061915; batch adversarial loss: 0.509555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.087091; batch adversarial loss: 0.460996\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035323; batch adversarial loss: 0.425882\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024387; batch adversarial loss: 0.488457\n",
      "epoch 149; iter: 0; batch classifier loss: 0.052115; batch adversarial loss: 0.407581\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042308; batch adversarial loss: 0.341483\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028841; batch adversarial loss: 0.323755\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028612; batch adversarial loss: 0.415225\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038609; batch adversarial loss: 0.405532\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031048; batch adversarial loss: 0.413396\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051628; batch adversarial loss: 0.497438\n",
      "epoch 156; iter: 0; batch classifier loss: 0.067911; batch adversarial loss: 0.411796\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042234; batch adversarial loss: 0.436786\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028518; batch adversarial loss: 0.416720\n",
      "epoch 159; iter: 0; batch classifier loss: 0.054708; batch adversarial loss: 0.338033\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041673; batch adversarial loss: 0.495571\n",
      "epoch 161; iter: 0; batch classifier loss: 0.073119; batch adversarial loss: 0.439320\n",
      "epoch 162; iter: 0; batch classifier loss: 0.067957; batch adversarial loss: 0.446536\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039330; batch adversarial loss: 0.442491\n",
      "epoch 164; iter: 0; batch classifier loss: 0.056535; batch adversarial loss: 0.437134\n",
      "epoch 165; iter: 0; batch classifier loss: 0.052668; batch adversarial loss: 0.388465\n",
      "epoch 166; iter: 0; batch classifier loss: 0.060860; batch adversarial loss: 0.442989\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055542; batch adversarial loss: 0.505535\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052479; batch adversarial loss: 0.413524\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047694; batch adversarial loss: 0.415544\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050454; batch adversarial loss: 0.423475\n",
      "epoch 171; iter: 0; batch classifier loss: 0.071468; batch adversarial loss: 0.469481\n",
      "epoch 172; iter: 0; batch classifier loss: 0.073848; batch adversarial loss: 0.452767\n",
      "epoch 173; iter: 0; batch classifier loss: 0.058548; batch adversarial loss: 0.371165\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054954; batch adversarial loss: 0.453036\n",
      "epoch 175; iter: 0; batch classifier loss: 0.055425; batch adversarial loss: 0.516239\n",
      "epoch 176; iter: 0; batch classifier loss: 0.062390; batch adversarial loss: 0.450523\n",
      "epoch 177; iter: 0; batch classifier loss: 0.071284; batch adversarial loss: 0.493173\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055713; batch adversarial loss: 0.375484\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061852; batch adversarial loss: 0.455096\n",
      "epoch 180; iter: 0; batch classifier loss: 0.052470; batch adversarial loss: 0.386695\n",
      "epoch 181; iter: 0; batch classifier loss: 0.059114; batch adversarial loss: 0.457355\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037332; batch adversarial loss: 0.350290\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029414; batch adversarial loss: 0.350786\n",
      "epoch 184; iter: 0; batch classifier loss: 0.051246; batch adversarial loss: 0.446753\n",
      "epoch 185; iter: 0; batch classifier loss: 0.051238; batch adversarial loss: 0.373390\n",
      "epoch 186; iter: 0; batch classifier loss: 0.054566; batch adversarial loss: 0.441278\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034771; batch adversarial loss: 0.322004\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045655; batch adversarial loss: 0.512788\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059504; batch adversarial loss: 0.436408\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041803; batch adversarial loss: 0.481001\n",
      "epoch 191; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.380680\n",
      "epoch 192; iter: 0; batch classifier loss: 0.089617; batch adversarial loss: 0.389456\n",
      "epoch 193; iter: 0; batch classifier loss: 0.054035; batch adversarial loss: 0.364619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.075941; batch adversarial loss: 0.411802\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.476361\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045829; batch adversarial loss: 0.406707\n",
      "epoch 197; iter: 0; batch classifier loss: 0.064063; batch adversarial loss: 0.438148\n",
      "epoch 198; iter: 0; batch classifier loss: 0.040670; batch adversarial loss: 0.427228\n",
      "epoch 199; iter: 0; batch classifier loss: 0.051597; batch adversarial loss: 0.485769\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708898; batch adversarial loss: 0.584631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494229; batch adversarial loss: 0.595904\n",
      "epoch 2; iter: 0; batch classifier loss: 0.464085; batch adversarial loss: 0.611021\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406132; batch adversarial loss: 0.615240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523623; batch adversarial loss: 0.554339\n",
      "epoch 5; iter: 0; batch classifier loss: 0.376433; batch adversarial loss: 0.594757\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381837; batch adversarial loss: 0.608735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523586; batch adversarial loss: 0.529656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475890; batch adversarial loss: 0.584831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590336; batch adversarial loss: 0.566209\n",
      "epoch 10; iter: 0; batch classifier loss: 0.757771; batch adversarial loss: 0.558878\n",
      "epoch 11; iter: 0; batch classifier loss: 0.507844; batch adversarial loss: 0.518162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492526; batch adversarial loss: 0.497276\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357309; batch adversarial loss: 0.482564\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315640; batch adversarial loss: 0.444310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374002; batch adversarial loss: 0.512812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276548; batch adversarial loss: 0.451029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.235624; batch adversarial loss: 0.483013\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259248; batch adversarial loss: 0.485229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278711; batch adversarial loss: 0.536213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.251214; batch adversarial loss: 0.423142\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258559; batch adversarial loss: 0.427354\n",
      "epoch 22; iter: 0; batch classifier loss: 0.252744; batch adversarial loss: 0.477966\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280673; batch adversarial loss: 0.465488\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296538; batch adversarial loss: 0.468875\n",
      "epoch 25; iter: 0; batch classifier loss: 0.280530; batch adversarial loss: 0.370697\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176474; batch adversarial loss: 0.559208\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200364; batch adversarial loss: 0.497611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.194985; batch adversarial loss: 0.480145\n",
      "epoch 29; iter: 0; batch classifier loss: 0.206966; batch adversarial loss: 0.476463\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195330; batch adversarial loss: 0.536963\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187884; batch adversarial loss: 0.419950\n",
      "epoch 32; iter: 0; batch classifier loss: 0.196072; batch adversarial loss: 0.432369\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150202; batch adversarial loss: 0.523608\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197015; batch adversarial loss: 0.483171\n",
      "epoch 35; iter: 0; batch classifier loss: 0.195404; batch adversarial loss: 0.425204\n",
      "epoch 36; iter: 0; batch classifier loss: 0.220697; batch adversarial loss: 0.428057\n",
      "epoch 37; iter: 0; batch classifier loss: 0.168382; batch adversarial loss: 0.447853\n",
      "epoch 38; iter: 0; batch classifier loss: 0.246689; batch adversarial loss: 0.484670\n",
      "epoch 39; iter: 0; batch classifier loss: 0.180243; batch adversarial loss: 0.467402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.191615; batch adversarial loss: 0.456556\n",
      "epoch 41; iter: 0; batch classifier loss: 0.176067; batch adversarial loss: 0.476583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.211123; batch adversarial loss: 0.371431\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219616; batch adversarial loss: 0.322431\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245558; batch adversarial loss: 0.398171\n",
      "epoch 45; iter: 0; batch classifier loss: 0.212334; batch adversarial loss: 0.407382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.183101; batch adversarial loss: 0.471821\n",
      "epoch 47; iter: 0; batch classifier loss: 0.180122; batch adversarial loss: 0.425658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224626; batch adversarial loss: 0.411186\n",
      "epoch 49; iter: 0; batch classifier loss: 0.247408; batch adversarial loss: 0.466802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.252564; batch adversarial loss: 0.456301\n",
      "epoch 51; iter: 0; batch classifier loss: 0.317475; batch adversarial loss: 0.335812\n",
      "epoch 52; iter: 0; batch classifier loss: 0.139262; batch adversarial loss: 0.473219\n",
      "epoch 53; iter: 0; batch classifier loss: 0.199555; batch adversarial loss: 0.507106\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209240; batch adversarial loss: 0.606178\n",
      "epoch 55; iter: 0; batch classifier loss: 0.267616; batch adversarial loss: 0.361071\n",
      "epoch 56; iter: 0; batch classifier loss: 0.187664; batch adversarial loss: 0.459351\n",
      "epoch 57; iter: 0; batch classifier loss: 0.210296; batch adversarial loss: 0.496563\n",
      "epoch 58; iter: 0; batch classifier loss: 0.250497; batch adversarial loss: 0.458560\n",
      "epoch 59; iter: 0; batch classifier loss: 0.206411; batch adversarial loss: 0.485007\n",
      "epoch 60; iter: 0; batch classifier loss: 0.167010; batch adversarial loss: 0.396108\n",
      "epoch 61; iter: 0; batch classifier loss: 0.154438; batch adversarial loss: 0.433312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173063; batch adversarial loss: 0.469101\n",
      "epoch 63; iter: 0; batch classifier loss: 0.214069; batch adversarial loss: 0.422457\n",
      "epoch 64; iter: 0; batch classifier loss: 0.148325; batch adversarial loss: 0.370479\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142837; batch adversarial loss: 0.524458\n",
      "epoch 66; iter: 0; batch classifier loss: 0.190495; batch adversarial loss: 0.484875\n",
      "epoch 67; iter: 0; batch classifier loss: 0.150853; batch adversarial loss: 0.470950\n",
      "epoch 68; iter: 0; batch classifier loss: 0.237797; batch adversarial loss: 0.420465\n",
      "epoch 69; iter: 0; batch classifier loss: 0.217833; batch adversarial loss: 0.497090\n",
      "epoch 70; iter: 0; batch classifier loss: 0.116365; batch adversarial loss: 0.469590\n",
      "epoch 71; iter: 0; batch classifier loss: 0.160888; batch adversarial loss: 0.446515\n",
      "epoch 72; iter: 0; batch classifier loss: 0.173484; batch adversarial loss: 0.409921\n",
      "epoch 73; iter: 0; batch classifier loss: 0.257429; batch adversarial loss: 0.560261\n",
      "epoch 74; iter: 0; batch classifier loss: 0.207231; batch adversarial loss: 0.383881\n",
      "epoch 75; iter: 0; batch classifier loss: 0.150124; batch adversarial loss: 0.471718\n",
      "epoch 76; iter: 0; batch classifier loss: 0.181450; batch adversarial loss: 0.485504\n",
      "epoch 77; iter: 0; batch classifier loss: 0.220167; batch adversarial loss: 0.470160\n",
      "epoch 78; iter: 0; batch classifier loss: 0.172455; batch adversarial loss: 0.459306\n",
      "epoch 79; iter: 0; batch classifier loss: 0.223556; batch adversarial loss: 0.421872\n",
      "epoch 80; iter: 0; batch classifier loss: 0.184604; batch adversarial loss: 0.371270\n",
      "epoch 81; iter: 0; batch classifier loss: 0.178124; batch adversarial loss: 0.446177\n",
      "epoch 82; iter: 0; batch classifier loss: 0.298220; batch adversarial loss: 0.421572\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143147; batch adversarial loss: 0.395169\n",
      "epoch 84; iter: 0; batch classifier loss: 0.115965; batch adversarial loss: 0.380605\n",
      "epoch 85; iter: 0; batch classifier loss: 0.171943; batch adversarial loss: 0.445798\n",
      "epoch 86; iter: 0; batch classifier loss: 0.155266; batch adversarial loss: 0.497386\n",
      "epoch 87; iter: 0; batch classifier loss: 0.176930; batch adversarial loss: 0.359165\n",
      "epoch 88; iter: 0; batch classifier loss: 0.152204; batch adversarial loss: 0.360741\n",
      "epoch 89; iter: 0; batch classifier loss: 0.209532; batch adversarial loss: 0.370180\n",
      "epoch 90; iter: 0; batch classifier loss: 0.152909; batch adversarial loss: 0.485745\n",
      "epoch 91; iter: 0; batch classifier loss: 0.250680; batch adversarial loss: 0.408262\n",
      "epoch 92; iter: 0; batch classifier loss: 0.154624; batch adversarial loss: 0.447255\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169889; batch adversarial loss: 0.295265\n",
      "epoch 94; iter: 0; batch classifier loss: 0.191422; batch adversarial loss: 0.371271\n",
      "epoch 95; iter: 0; batch classifier loss: 0.228741; batch adversarial loss: 0.421907\n",
      "epoch 96; iter: 0; batch classifier loss: 0.208033; batch adversarial loss: 0.446226\n",
      "epoch 97; iter: 0; batch classifier loss: 0.203139; batch adversarial loss: 0.483902\n",
      "epoch 98; iter: 0; batch classifier loss: 0.127717; batch adversarial loss: 0.508624\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059899; batch adversarial loss: 0.477596\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067140; batch adversarial loss: 0.367350\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051035; batch adversarial loss: 0.413009\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050548; batch adversarial loss: 0.451371\n",
      "epoch 103; iter: 0; batch classifier loss: 0.081881; batch adversarial loss: 0.386086\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051603; batch adversarial loss: 0.496705\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056475; batch adversarial loss: 0.465078\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076002; batch adversarial loss: 0.497324\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057402; batch adversarial loss: 0.437067\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047748; batch adversarial loss: 0.414091\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061826; batch adversarial loss: 0.520406\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089318; batch adversarial loss: 0.327041\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038786; batch adversarial loss: 0.421856\n",
      "epoch 112; iter: 0; batch classifier loss: 0.101491; batch adversarial loss: 0.371855\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049089; batch adversarial loss: 0.498349\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049010; batch adversarial loss: 0.363722\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054058; batch adversarial loss: 0.563799\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044013; batch adversarial loss: 0.437086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.081099; batch adversarial loss: 0.449003\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071630; batch adversarial loss: 0.402865\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082914; batch adversarial loss: 0.461740\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046065; batch adversarial loss: 0.396617\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044367; batch adversarial loss: 0.434739\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044686; batch adversarial loss: 0.430182\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056634; batch adversarial loss: 0.480616\n",
      "epoch 124; iter: 0; batch classifier loss: 0.050783; batch adversarial loss: 0.388253\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052421; batch adversarial loss: 0.452320\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049751; batch adversarial loss: 0.459025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050227; batch adversarial loss: 0.354545\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060499; batch adversarial loss: 0.358448\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028818; batch adversarial loss: 0.457592\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045126; batch adversarial loss: 0.373407\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028536; batch adversarial loss: 0.468628\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045166; batch adversarial loss: 0.445806\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046551; batch adversarial loss: 0.523506\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053315; batch adversarial loss: 0.409792\n",
      "epoch 135; iter: 0; batch classifier loss: 0.095946; batch adversarial loss: 0.497723\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024478; batch adversarial loss: 0.408339\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052089; batch adversarial loss: 0.410534\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055894; batch adversarial loss: 0.452045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.049355; batch adversarial loss: 0.427590\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060189; batch adversarial loss: 0.383266\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057405; batch adversarial loss: 0.417945\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054042; batch adversarial loss: 0.388033\n",
      "epoch 143; iter: 0; batch classifier loss: 0.064375; batch adversarial loss: 0.376261\n",
      "epoch 144; iter: 0; batch classifier loss: 0.097078; batch adversarial loss: 0.475096\n",
      "epoch 145; iter: 0; batch classifier loss: 0.067225; batch adversarial loss: 0.393687\n",
      "epoch 146; iter: 0; batch classifier loss: 0.072545; batch adversarial loss: 0.471614\n",
      "epoch 147; iter: 0; batch classifier loss: 0.068468; batch adversarial loss: 0.579636\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035732; batch adversarial loss: 0.407635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069446; batch adversarial loss: 0.469929\n",
      "epoch 150; iter: 0; batch classifier loss: 0.104205; batch adversarial loss: 0.401702\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055937; batch adversarial loss: 0.408910\n",
      "epoch 152; iter: 0; batch classifier loss: 0.046455; batch adversarial loss: 0.458029\n",
      "epoch 153; iter: 0; batch classifier loss: 0.047626; batch adversarial loss: 0.353846\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046086; batch adversarial loss: 0.532048\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055006; batch adversarial loss: 0.425640\n",
      "epoch 156; iter: 0; batch classifier loss: 0.062533; batch adversarial loss: 0.415314\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035109; batch adversarial loss: 0.511088\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048641; batch adversarial loss: 0.529798\n",
      "epoch 159; iter: 0; batch classifier loss: 0.046637; batch adversarial loss: 0.405831\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044367; batch adversarial loss: 0.389528\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038418; batch adversarial loss: 0.382643\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052892; batch adversarial loss: 0.422699\n",
      "epoch 163; iter: 0; batch classifier loss: 0.085379; batch adversarial loss: 0.246061\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040244; batch adversarial loss: 0.336079\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019842; batch adversarial loss: 0.390024\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049859; batch adversarial loss: 0.362374\n",
      "epoch 167; iter: 0; batch classifier loss: 0.086549; batch adversarial loss: 0.391139\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066519; batch adversarial loss: 0.406116\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039245; batch adversarial loss: 0.433701\n",
      "epoch 170; iter: 0; batch classifier loss: 0.063532; batch adversarial loss: 0.350320\n",
      "epoch 171; iter: 0; batch classifier loss: 0.084147; batch adversarial loss: 0.430598\n",
      "epoch 172; iter: 0; batch classifier loss: 0.088700; batch adversarial loss: 0.401328\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050241; batch adversarial loss: 0.348941\n",
      "epoch 174; iter: 0; batch classifier loss: 0.059649; batch adversarial loss: 0.416782\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044811; batch adversarial loss: 0.297124\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036731; batch adversarial loss: 0.346760\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051843; batch adversarial loss: 0.385893\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034492; batch adversarial loss: 0.384716\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036501; batch adversarial loss: 0.379211\n",
      "epoch 180; iter: 0; batch classifier loss: 0.070642; batch adversarial loss: 0.394101\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047056; batch adversarial loss: 0.423866\n",
      "epoch 182; iter: 0; batch classifier loss: 0.067909; batch adversarial loss: 0.373501\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032661; batch adversarial loss: 0.443399\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040161; batch adversarial loss: 0.426600\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042448; batch adversarial loss: 0.347481\n",
      "epoch 186; iter: 0; batch classifier loss: 0.052798; batch adversarial loss: 0.401523\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.447080\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048568; batch adversarial loss: 0.368178\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040090; batch adversarial loss: 0.373792\n",
      "epoch 190; iter: 0; batch classifier loss: 0.056135; batch adversarial loss: 0.478850\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026330; batch adversarial loss: 0.408125\n",
      "epoch 192; iter: 0; batch classifier loss: 0.054650; batch adversarial loss: 0.435410\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030298; batch adversarial loss: 0.371001\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034436; batch adversarial loss: 0.378137\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016481; batch adversarial loss: 0.477393\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030702; batch adversarial loss: 0.451458\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027353; batch adversarial loss: 0.501781\n",
      "epoch 198; iter: 0; batch classifier loss: 0.057294; batch adversarial loss: 0.452634\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034946; batch adversarial loss: 0.325130\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731262; batch adversarial loss: 0.557685\n",
      "epoch 1; iter: 0; batch classifier loss: 0.431503; batch adversarial loss: 0.600308\n",
      "epoch 2; iter: 0; batch classifier loss: 0.277988; batch adversarial loss: 0.632964\n",
      "epoch 3; iter: 0; batch classifier loss: 0.299363; batch adversarial loss: 0.553707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.322791; batch adversarial loss: 0.566176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302428; batch adversarial loss: 0.537113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.260851; batch adversarial loss: 0.529985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298995; batch adversarial loss: 0.523617\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282137; batch adversarial loss: 0.490483\n",
      "epoch 9; iter: 0; batch classifier loss: 0.235434; batch adversarial loss: 0.531263\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218902; batch adversarial loss: 0.493956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.216001; batch adversarial loss: 0.434260\n",
      "epoch 12; iter: 0; batch classifier loss: 0.208832; batch adversarial loss: 0.510522\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274982; batch adversarial loss: 0.503100\n",
      "epoch 14; iter: 0; batch classifier loss: 0.243594; batch adversarial loss: 0.536604\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247526; batch adversarial loss: 0.511113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242462; batch adversarial loss: 0.537160\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226964; batch adversarial loss: 0.482863\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230928; batch adversarial loss: 0.494524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278862; batch adversarial loss: 0.554077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314176; batch adversarial loss: 0.616037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.257546; batch adversarial loss: 0.568185\n",
      "epoch 22; iter: 0; batch classifier loss: 0.225111; batch adversarial loss: 0.522099\n",
      "epoch 23; iter: 0; batch classifier loss: 0.385392; batch adversarial loss: 0.528326\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258504; batch adversarial loss: 0.529613\n",
      "epoch 25; iter: 0; batch classifier loss: 0.379120; batch adversarial loss: 0.513546\n",
      "epoch 26; iter: 0; batch classifier loss: 0.313160; batch adversarial loss: 0.506922\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188672; batch adversarial loss: 0.499286\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135888; batch adversarial loss: 0.463271\n",
      "epoch 29; iter: 0; batch classifier loss: 0.224829; batch adversarial loss: 0.422469\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151583; batch adversarial loss: 0.494925\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130573; batch adversarial loss: 0.459194\n",
      "epoch 32; iter: 0; batch classifier loss: 0.110201; batch adversarial loss: 0.547368\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158700; batch adversarial loss: 0.358191\n",
      "epoch 34; iter: 0; batch classifier loss: 0.083342; batch adversarial loss: 0.483913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112665; batch adversarial loss: 0.428579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.130527; batch adversarial loss: 0.502458\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137475; batch adversarial loss: 0.368925\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107408; batch adversarial loss: 0.554978\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087821; batch adversarial loss: 0.539217\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135874; batch adversarial loss: 0.456844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080814; batch adversarial loss: 0.414260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109240; batch adversarial loss: 0.456401\n",
      "epoch 43; iter: 0; batch classifier loss: 0.087426; batch adversarial loss: 0.415837\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072463; batch adversarial loss: 0.512988\n",
      "epoch 45; iter: 0; batch classifier loss: 0.119426; batch adversarial loss: 0.447284\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072082; batch adversarial loss: 0.472864\n",
      "epoch 47; iter: 0; batch classifier loss: 0.062707; batch adversarial loss: 0.484969\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098728; batch adversarial loss: 0.512159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.119186; batch adversarial loss: 0.462696\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108668; batch adversarial loss: 0.437793\n",
      "epoch 51; iter: 0; batch classifier loss: 0.062676; batch adversarial loss: 0.366759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.067438; batch adversarial loss: 0.487843\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093511; batch adversarial loss: 0.445188\n",
      "epoch 54; iter: 0; batch classifier loss: 0.083118; batch adversarial loss: 0.455084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067590; batch adversarial loss: 0.432477\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078588; batch adversarial loss: 0.426009\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086148; batch adversarial loss: 0.446758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.094785; batch adversarial loss: 0.578813\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140562; batch adversarial loss: 0.504714\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110345; batch adversarial loss: 0.445790\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063623; batch adversarial loss: 0.488941\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080260; batch adversarial loss: 0.493872\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126436; batch adversarial loss: 0.482038\n",
      "epoch 64; iter: 0; batch classifier loss: 0.100701; batch adversarial loss: 0.464074\n",
      "epoch 65; iter: 0; batch classifier loss: 0.054485; batch adversarial loss: 0.419666\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079009; batch adversarial loss: 0.356968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079713; batch adversarial loss: 0.431993\n",
      "epoch 68; iter: 0; batch classifier loss: 0.095385; batch adversarial loss: 0.476732\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083911; batch adversarial loss: 0.478846\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094877; batch adversarial loss: 0.387220\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104030; batch adversarial loss: 0.553526\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068395; batch adversarial loss: 0.486078\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102057; batch adversarial loss: 0.422860\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094948; batch adversarial loss: 0.479253\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077849; batch adversarial loss: 0.396656\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063213; batch adversarial loss: 0.454619\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093244; batch adversarial loss: 0.401518\n",
      "epoch 78; iter: 0; batch classifier loss: 0.112357; batch adversarial loss: 0.556380\n",
      "epoch 79; iter: 0; batch classifier loss: 0.095531; batch adversarial loss: 0.447688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075525; batch adversarial loss: 0.595123\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088830; batch adversarial loss: 0.411320\n",
      "epoch 82; iter: 0; batch classifier loss: 0.119878; batch adversarial loss: 0.419041\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071411; batch adversarial loss: 0.511970\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077286; batch adversarial loss: 0.420185\n",
      "epoch 85; iter: 0; batch classifier loss: 0.074341; batch adversarial loss: 0.388434\n",
      "epoch 86; iter: 0; batch classifier loss: 0.108197; batch adversarial loss: 0.432248\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059303; batch adversarial loss: 0.442341\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040755; batch adversarial loss: 0.472067\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060603; batch adversarial loss: 0.601844\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063091; batch adversarial loss: 0.463905\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076190; batch adversarial loss: 0.410460\n",
      "epoch 92; iter: 0; batch classifier loss: 0.097426; batch adversarial loss: 0.518096\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067954; batch adversarial loss: 0.446433\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.396790\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079199; batch adversarial loss: 0.426814\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.455764\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070847; batch adversarial loss: 0.498655\n",
      "epoch 98; iter: 0; batch classifier loss: 0.082548; batch adversarial loss: 0.560348\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069668; batch adversarial loss: 0.334568\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116046; batch adversarial loss: 0.450638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.080441; batch adversarial loss: 0.427345\n",
      "epoch 102; iter: 0; batch classifier loss: 0.128346; batch adversarial loss: 0.450682\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074608; batch adversarial loss: 0.394799\n",
      "epoch 104; iter: 0; batch classifier loss: 0.088023; batch adversarial loss: 0.456465\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061527; batch adversarial loss: 0.430157\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067114; batch adversarial loss: 0.444953\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059062; batch adversarial loss: 0.461222\n",
      "epoch 108; iter: 0; batch classifier loss: 0.114298; batch adversarial loss: 0.415400\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090655; batch adversarial loss: 0.392959\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059922; batch adversarial loss: 0.405673\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064440; batch adversarial loss: 0.469310\n",
      "epoch 112; iter: 0; batch classifier loss: 0.106883; batch adversarial loss: 0.427579\n",
      "epoch 113; iter: 0; batch classifier loss: 0.069848; batch adversarial loss: 0.472071\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043682; batch adversarial loss: 0.448009\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065339; batch adversarial loss: 0.493832\n",
      "epoch 116; iter: 0; batch classifier loss: 0.069927; batch adversarial loss: 0.416477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030745; batch adversarial loss: 0.436405\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063983; batch adversarial loss: 0.550342\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038248; batch adversarial loss: 0.488610\n",
      "epoch 120; iter: 0; batch classifier loss: 0.075700; batch adversarial loss: 0.522675\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072344; batch adversarial loss: 0.445788\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017527; batch adversarial loss: 0.547875\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026730; batch adversarial loss: 0.474347\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020415; batch adversarial loss: 0.516576\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068853; batch adversarial loss: 0.418126\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056729; batch adversarial loss: 0.480152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.041901; batch adversarial loss: 0.495648\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079870; batch adversarial loss: 0.451050\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045680; batch adversarial loss: 0.480028\n",
      "epoch 130; iter: 0; batch classifier loss: 0.040827; batch adversarial loss: 0.440190\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038544; batch adversarial loss: 0.449969\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037896; batch adversarial loss: 0.461612\n",
      "epoch 133; iter: 0; batch classifier loss: 0.067591; batch adversarial loss: 0.435595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.055351; batch adversarial loss: 0.460507\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057998; batch adversarial loss: 0.401261\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039515; batch adversarial loss: 0.393001\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035547; batch adversarial loss: 0.424755\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033091; batch adversarial loss: 0.444999\n",
      "epoch 139; iter: 0; batch classifier loss: 0.052226; batch adversarial loss: 0.468886\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038597; batch adversarial loss: 0.463113\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025149; batch adversarial loss: 0.481309\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041826; batch adversarial loss: 0.531399\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039022; batch adversarial loss: 0.394010\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037307; batch adversarial loss: 0.496817\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030290; batch adversarial loss: 0.401408\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036934; batch adversarial loss: 0.431076\n",
      "epoch 147; iter: 0; batch classifier loss: 0.055066; batch adversarial loss: 0.454906\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027361; batch adversarial loss: 0.374316\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026572; batch adversarial loss: 0.510099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062269; batch adversarial loss: 0.454008\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011370; batch adversarial loss: 0.424320\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029982; batch adversarial loss: 0.454043\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036789; batch adversarial loss: 0.391844\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027964; batch adversarial loss: 0.495549\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032125; batch adversarial loss: 0.509742\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012654; batch adversarial loss: 0.500893\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019389; batch adversarial loss: 0.376708\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015705; batch adversarial loss: 0.432026\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031148; batch adversarial loss: 0.429945\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017006; batch adversarial loss: 0.413980\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029711; batch adversarial loss: 0.443260\n",
      "epoch 162; iter: 0; batch classifier loss: 0.010919; batch adversarial loss: 0.422577\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050054; batch adversarial loss: 0.560335\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026779; batch adversarial loss: 0.357415\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012300; batch adversarial loss: 0.386553\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027756; batch adversarial loss: 0.427602\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032943; batch adversarial loss: 0.419157\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011855; batch adversarial loss: 0.456598\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035767; batch adversarial loss: 0.548254\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021196; batch adversarial loss: 0.406766\n",
      "epoch 171; iter: 0; batch classifier loss: 0.024385; batch adversarial loss: 0.413389\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031110; batch adversarial loss: 0.465053\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013823; batch adversarial loss: 0.513375\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025435; batch adversarial loss: 0.449779\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037627; batch adversarial loss: 0.367864\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018426; batch adversarial loss: 0.422018\n",
      "epoch 177; iter: 0; batch classifier loss: 0.062818; batch adversarial loss: 0.448007\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014091; batch adversarial loss: 0.498752\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.397981\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022038; batch adversarial loss: 0.445246\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015376; batch adversarial loss: 0.483198\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034212; batch adversarial loss: 0.539577\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019268; batch adversarial loss: 0.472892\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025961; batch adversarial loss: 0.481455\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014071; batch adversarial loss: 0.436304\n",
      "epoch 186; iter: 0; batch classifier loss: 0.031867; batch adversarial loss: 0.464453\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011901; batch adversarial loss: 0.468928\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014567; batch adversarial loss: 0.488104\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010571; batch adversarial loss: 0.491354\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039353; batch adversarial loss: 0.420040\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029921; batch adversarial loss: 0.472519\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036782; batch adversarial loss: 0.519358\n",
      "epoch 193; iter: 0; batch classifier loss: 0.023096; batch adversarial loss: 0.484457\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022042; batch adversarial loss: 0.412029\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034409; batch adversarial loss: 0.471923\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024231; batch adversarial loss: 0.451833\n",
      "epoch 197; iter: 0; batch classifier loss: 0.068337; batch adversarial loss: 0.477036\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012831; batch adversarial loss: 0.460791\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021968; batch adversarial loss: 0.420062\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669298; batch adversarial loss: 0.723861\n",
      "epoch 1; iter: 0; batch classifier loss: 0.546933; batch adversarial loss: 0.699397\n",
      "epoch 2; iter: 0; batch classifier loss: 0.500708; batch adversarial loss: 0.660414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313601; batch adversarial loss: 0.620099\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344232; batch adversarial loss: 0.604081\n",
      "epoch 5; iter: 0; batch classifier loss: 0.306673; batch adversarial loss: 0.545283\n",
      "epoch 6; iter: 0; batch classifier loss: 0.267752; batch adversarial loss: 0.529808\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281380; batch adversarial loss: 0.557781\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278761; batch adversarial loss: 0.529224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284164; batch adversarial loss: 0.522282\n",
      "epoch 10; iter: 0; batch classifier loss: 0.299982; batch adversarial loss: 0.502288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.224353; batch adversarial loss: 0.551779\n",
      "epoch 12; iter: 0; batch classifier loss: 0.193964; batch adversarial loss: 0.502114\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234922; batch adversarial loss: 0.438772\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285478; batch adversarial loss: 0.483628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.210261; batch adversarial loss: 0.479382\n",
      "epoch 16; iter: 0; batch classifier loss: 0.234173; batch adversarial loss: 0.501088\n",
      "epoch 17; iter: 0; batch classifier loss: 0.240760; batch adversarial loss: 0.479597\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227365; batch adversarial loss: 0.565034\n",
      "epoch 19; iter: 0; batch classifier loss: 0.254899; batch adversarial loss: 0.412459\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204774; batch adversarial loss: 0.471616\n",
      "epoch 21; iter: 0; batch classifier loss: 0.154537; batch adversarial loss: 0.502447\n",
      "epoch 22; iter: 0; batch classifier loss: 0.181231; batch adversarial loss: 0.433672\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157870; batch adversarial loss: 0.477352\n",
      "epoch 24; iter: 0; batch classifier loss: 0.142732; batch adversarial loss: 0.484562\n",
      "epoch 25; iter: 0; batch classifier loss: 0.174632; batch adversarial loss: 0.512501\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172889; batch adversarial loss: 0.495050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172937; batch adversarial loss: 0.423681\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161306; batch adversarial loss: 0.480433\n",
      "epoch 29; iter: 0; batch classifier loss: 0.148927; batch adversarial loss: 0.417310\n",
      "epoch 30; iter: 0; batch classifier loss: 0.166694; batch adversarial loss: 0.459432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.171772; batch adversarial loss: 0.455240\n",
      "epoch 32; iter: 0; batch classifier loss: 0.112331; batch adversarial loss: 0.454682\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141356; batch adversarial loss: 0.412357\n",
      "epoch 34; iter: 0; batch classifier loss: 0.156204; batch adversarial loss: 0.452681\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136627; batch adversarial loss: 0.526776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109213; batch adversarial loss: 0.445421\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110023; batch adversarial loss: 0.517755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.149430; batch adversarial loss: 0.524838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132805; batch adversarial loss: 0.459137\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095409; batch adversarial loss: 0.483342\n",
      "epoch 41; iter: 0; batch classifier loss: 0.130174; batch adversarial loss: 0.450437\n",
      "epoch 42; iter: 0; batch classifier loss: 0.129276; batch adversarial loss: 0.342863\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126196; batch adversarial loss: 0.514772\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124261; batch adversarial loss: 0.417245\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126888; batch adversarial loss: 0.379708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120430; batch adversarial loss: 0.477824\n",
      "epoch 47; iter: 0; batch classifier loss: 0.071270; batch adversarial loss: 0.488951\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109986; batch adversarial loss: 0.508313\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095990; batch adversarial loss: 0.534538\n",
      "epoch 50; iter: 0; batch classifier loss: 0.097823; batch adversarial loss: 0.419725\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103613; batch adversarial loss: 0.394690\n",
      "epoch 52; iter: 0; batch classifier loss: 0.075945; batch adversarial loss: 0.430265\n",
      "epoch 53; iter: 0; batch classifier loss: 0.099382; batch adversarial loss: 0.492919\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077217; batch adversarial loss: 0.441821\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097862; batch adversarial loss: 0.392960\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072375; batch adversarial loss: 0.476592\n",
      "epoch 57; iter: 0; batch classifier loss: 0.059502; batch adversarial loss: 0.523688\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080411; batch adversarial loss: 0.420230\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084663; batch adversarial loss: 0.512227\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066977; batch adversarial loss: 0.493610\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078968; batch adversarial loss: 0.535550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094860; batch adversarial loss: 0.477179\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077622; batch adversarial loss: 0.495100\n",
      "epoch 64; iter: 0; batch classifier loss: 0.068120; batch adversarial loss: 0.443578\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078296; batch adversarial loss: 0.386824\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095784; batch adversarial loss: 0.485185\n",
      "epoch 67; iter: 0; batch classifier loss: 0.113375; batch adversarial loss: 0.365187\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065831; batch adversarial loss: 0.431632\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093443; batch adversarial loss: 0.475584\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080588; batch adversarial loss: 0.507774\n",
      "epoch 71; iter: 0; batch classifier loss: 0.051632; batch adversarial loss: 0.506752\n",
      "epoch 72; iter: 0; batch classifier loss: 0.046605; batch adversarial loss: 0.454983\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065881; batch adversarial loss: 0.525740\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068238; batch adversarial loss: 0.508393\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116331; batch adversarial loss: 0.437025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064793; batch adversarial loss: 0.490617\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054479; batch adversarial loss: 0.461726\n",
      "epoch 78; iter: 0; batch classifier loss: 0.038497; batch adversarial loss: 0.427769\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042475; batch adversarial loss: 0.428448\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073742; batch adversarial loss: 0.470220\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097535; batch adversarial loss: 0.405454\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045118; batch adversarial loss: 0.491250\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080965; batch adversarial loss: 0.413262\n",
      "epoch 84; iter: 0; batch classifier loss: 0.036575; batch adversarial loss: 0.457080\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044519; batch adversarial loss: 0.569887\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064882; batch adversarial loss: 0.485204\n",
      "epoch 87; iter: 0; batch classifier loss: 0.087270; batch adversarial loss: 0.471227\n",
      "epoch 88; iter: 0; batch classifier loss: 0.088822; batch adversarial loss: 0.556062\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086910; batch adversarial loss: 0.555179\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051161; batch adversarial loss: 0.422774\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043226; batch adversarial loss: 0.427616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090546; batch adversarial loss: 0.428223\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050234; batch adversarial loss: 0.379823\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036206; batch adversarial loss: 0.563186\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066925; batch adversarial loss: 0.462702\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046764; batch adversarial loss: 0.488924\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039376; batch adversarial loss: 0.455848\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055420; batch adversarial loss: 0.440339\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043729; batch adversarial loss: 0.435956\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058255; batch adversarial loss: 0.456879\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036872; batch adversarial loss: 0.429799\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053799; batch adversarial loss: 0.512879\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085446; batch adversarial loss: 0.448939\n",
      "epoch 104; iter: 0; batch classifier loss: 0.065323; batch adversarial loss: 0.468176\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045267; batch adversarial loss: 0.480920\n",
      "epoch 106; iter: 0; batch classifier loss: 0.096467; batch adversarial loss: 0.427624\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037476; batch adversarial loss: 0.517559\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049195; batch adversarial loss: 0.378753\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025082; batch adversarial loss: 0.526792\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041961; batch adversarial loss: 0.442491\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053892; batch adversarial loss: 0.571836\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045974; batch adversarial loss: 0.500159\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031333; batch adversarial loss: 0.423059\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031554; batch adversarial loss: 0.391762\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044898; batch adversarial loss: 0.452891\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041336; batch adversarial loss: 0.425773\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031048; batch adversarial loss: 0.580562\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056609; batch adversarial loss: 0.398692\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028107; batch adversarial loss: 0.427624\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032401; batch adversarial loss: 0.447760\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031606; batch adversarial loss: 0.457294\n",
      "epoch 122; iter: 0; batch classifier loss: 0.053053; batch adversarial loss: 0.467091\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051921; batch adversarial loss: 0.565743\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027816; batch adversarial loss: 0.533202\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039852; batch adversarial loss: 0.483731\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028440; batch adversarial loss: 0.408490\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048357; batch adversarial loss: 0.372065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.032049; batch adversarial loss: 0.442039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.034688; batch adversarial loss: 0.509683\n",
      "epoch 130; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.481127\n",
      "epoch 131; iter: 0; batch classifier loss: 0.011889; batch adversarial loss: 0.487505\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024707; batch adversarial loss: 0.471106\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024958; batch adversarial loss: 0.464772\n",
      "epoch 134; iter: 0; batch classifier loss: 0.023645; batch adversarial loss: 0.434813\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042436; batch adversarial loss: 0.477519\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024092; batch adversarial loss: 0.503502\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040483; batch adversarial loss: 0.489046\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036526; batch adversarial loss: 0.475489\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019387; batch adversarial loss: 0.485634\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036370; batch adversarial loss: 0.470265\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032251; batch adversarial loss: 0.425267\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032677; batch adversarial loss: 0.443940\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030904; batch adversarial loss: 0.508436\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038897; batch adversarial loss: 0.393254\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024280; batch adversarial loss: 0.387977\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034442; batch adversarial loss: 0.510304\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051137; batch adversarial loss: 0.432818\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021418; batch adversarial loss: 0.417952\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033958; batch adversarial loss: 0.427181\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048437; batch adversarial loss: 0.502187\n",
      "epoch 151; iter: 0; batch classifier loss: 0.038700; batch adversarial loss: 0.408348\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019538; batch adversarial loss: 0.375319\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021878; batch adversarial loss: 0.522280\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020285; batch adversarial loss: 0.443208\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030370; batch adversarial loss: 0.507671\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043538; batch adversarial loss: 0.450332\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052939; batch adversarial loss: 0.474867\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016581; batch adversarial loss: 0.469721\n",
      "epoch 159; iter: 0; batch classifier loss: 0.008804; batch adversarial loss: 0.408530\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038493; batch adversarial loss: 0.473809\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035364; batch adversarial loss: 0.406690\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028213; batch adversarial loss: 0.427409\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012051; batch adversarial loss: 0.468476\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010965; batch adversarial loss: 0.513365\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039629; batch adversarial loss: 0.449644\n",
      "epoch 166; iter: 0; batch classifier loss: 0.058324; batch adversarial loss: 0.480041\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020828; batch adversarial loss: 0.472710\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024161; batch adversarial loss: 0.451851\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014135; batch adversarial loss: 0.479254\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027562; batch adversarial loss: 0.432885\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014185; batch adversarial loss: 0.509542\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030212; batch adversarial loss: 0.452770\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022416; batch adversarial loss: 0.426303\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039671; batch adversarial loss: 0.455122\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013469; batch adversarial loss: 0.552410\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007968; batch adversarial loss: 0.427268\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022525; batch adversarial loss: 0.385466\n",
      "epoch 178; iter: 0; batch classifier loss: 0.036484; batch adversarial loss: 0.475703\n",
      "epoch 179; iter: 0; batch classifier loss: 0.022880; batch adversarial loss: 0.519800\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054187; batch adversarial loss: 0.453355\n",
      "epoch 181; iter: 0; batch classifier loss: 0.072899; batch adversarial loss: 0.394335\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035627; batch adversarial loss: 0.460588\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025839; batch adversarial loss: 0.459398\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011757; batch adversarial loss: 0.400476\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033879; batch adversarial loss: 0.466921\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004289; batch adversarial loss: 0.412360\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048922; batch adversarial loss: 0.436209\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026399; batch adversarial loss: 0.426483\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017441; batch adversarial loss: 0.482768\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016158; batch adversarial loss: 0.455358\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013364; batch adversarial loss: 0.479827\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019816; batch adversarial loss: 0.383864\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027008; batch adversarial loss: 0.441907\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040786; batch adversarial loss: 0.428251\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010083; batch adversarial loss: 0.441131\n",
      "epoch 196; iter: 0; batch classifier loss: 0.060700; batch adversarial loss: 0.506025\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013442; batch adversarial loss: 0.409519\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029603; batch adversarial loss: 0.436309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026781; batch adversarial loss: 0.382369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682914; batch adversarial loss: 0.706205\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414515; batch adversarial loss: 0.665765\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519989; batch adversarial loss: 0.636839\n",
      "epoch 3; iter: 0; batch classifier loss: 0.471486; batch adversarial loss: 0.611606\n",
      "epoch 4; iter: 0; batch classifier loss: 0.403679; batch adversarial loss: 0.616894\n",
      "epoch 5; iter: 0; batch classifier loss: 0.443982; batch adversarial loss: 0.569268\n",
      "epoch 6; iter: 0; batch classifier loss: 0.472472; batch adversarial loss: 0.568786\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482555; batch adversarial loss: 0.585003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582551; batch adversarial loss: 0.516920\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517120; batch adversarial loss: 0.539184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.412909; batch adversarial loss: 0.559018\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371493; batch adversarial loss: 0.512757\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403364; batch adversarial loss: 0.543193\n",
      "epoch 13; iter: 0; batch classifier loss: 0.573850; batch adversarial loss: 0.502951\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370609; batch adversarial loss: 0.524057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415648; batch adversarial loss: 0.480018\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391963; batch adversarial loss: 0.527402\n",
      "epoch 17; iter: 0; batch classifier loss: 0.411633; batch adversarial loss: 0.477998\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358681; batch adversarial loss: 0.489331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.358855; batch adversarial loss: 0.415858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.323021; batch adversarial loss: 0.478883\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283502; batch adversarial loss: 0.440500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.346310; batch adversarial loss: 0.480132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308669; batch adversarial loss: 0.442405\n",
      "epoch 24; iter: 0; batch classifier loss: 0.246885; batch adversarial loss: 0.464942\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345293; batch adversarial loss: 0.409148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.332233; batch adversarial loss: 0.491492\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278031; batch adversarial loss: 0.451658\n",
      "epoch 28; iter: 0; batch classifier loss: 0.289033; batch adversarial loss: 0.455628\n",
      "epoch 29; iter: 0; batch classifier loss: 0.229272; batch adversarial loss: 0.475807\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186403; batch adversarial loss: 0.415541\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234250; batch adversarial loss: 0.470445\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275045; batch adversarial loss: 0.486514\n",
      "epoch 33; iter: 0; batch classifier loss: 0.250726; batch adversarial loss: 0.506235\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306109; batch adversarial loss: 0.427457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337759; batch adversarial loss: 0.394448\n",
      "epoch 36; iter: 0; batch classifier loss: 0.265555; batch adversarial loss: 0.437075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277465; batch adversarial loss: 0.426458\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279715; batch adversarial loss: 0.414004\n",
      "epoch 39; iter: 0; batch classifier loss: 0.252593; batch adversarial loss: 0.495580\n",
      "epoch 40; iter: 0; batch classifier loss: 0.238581; batch adversarial loss: 0.424758\n",
      "epoch 41; iter: 0; batch classifier loss: 0.240677; batch adversarial loss: 0.447579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.143682; batch adversarial loss: 0.459270\n",
      "epoch 43; iter: 0; batch classifier loss: 0.169665; batch adversarial loss: 0.507088\n",
      "epoch 44; iter: 0; batch classifier loss: 0.276920; batch adversarial loss: 0.434823\n",
      "epoch 45; iter: 0; batch classifier loss: 0.178582; batch adversarial loss: 0.410313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.148001; batch adversarial loss: 0.446921\n",
      "epoch 47; iter: 0; batch classifier loss: 0.191453; batch adversarial loss: 0.435809\n",
      "epoch 48; iter: 0; batch classifier loss: 0.142421; batch adversarial loss: 0.507686\n",
      "epoch 49; iter: 0; batch classifier loss: 0.166516; batch adversarial loss: 0.447638\n",
      "epoch 50; iter: 0; batch classifier loss: 0.253638; batch adversarial loss: 0.434417\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189721; batch adversarial loss: 0.371987\n",
      "epoch 52; iter: 0; batch classifier loss: 0.145798; batch adversarial loss: 0.384445\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132401; batch adversarial loss: 0.421536\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124569; batch adversarial loss: 0.497000\n",
      "epoch 55; iter: 0; batch classifier loss: 0.213907; batch adversarial loss: 0.484063\n",
      "epoch 56; iter: 0; batch classifier loss: 0.171084; batch adversarial loss: 0.446374\n",
      "epoch 57; iter: 0; batch classifier loss: 0.119539; batch adversarial loss: 0.473278\n",
      "epoch 58; iter: 0; batch classifier loss: 0.179272; batch adversarial loss: 0.446190\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150392; batch adversarial loss: 0.520928\n",
      "epoch 60; iter: 0; batch classifier loss: 0.251709; batch adversarial loss: 0.433323\n",
      "epoch 61; iter: 0; batch classifier loss: 0.151902; batch adversarial loss: 0.396277\n",
      "epoch 62; iter: 0; batch classifier loss: 0.155813; batch adversarial loss: 0.433551\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115810; batch adversarial loss: 0.496378\n",
      "epoch 64; iter: 0; batch classifier loss: 0.196314; batch adversarial loss: 0.420836\n",
      "epoch 65; iter: 0; batch classifier loss: 0.137083; batch adversarial loss: 0.357271\n",
      "epoch 66; iter: 0; batch classifier loss: 0.167830; batch adversarial loss: 0.447411\n",
      "epoch 67; iter: 0; batch classifier loss: 0.310227; batch adversarial loss: 0.433563\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103745; batch adversarial loss: 0.421400\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101651; batch adversarial loss: 0.534983\n",
      "epoch 70; iter: 0; batch classifier loss: 0.150650; batch adversarial loss: 0.508552\n",
      "epoch 71; iter: 0; batch classifier loss: 0.206297; batch adversarial loss: 0.446434\n",
      "epoch 72; iter: 0; batch classifier loss: 0.164267; batch adversarial loss: 0.457786\n",
      "epoch 73; iter: 0; batch classifier loss: 0.181931; batch adversarial loss: 0.407559\n",
      "epoch 74; iter: 0; batch classifier loss: 0.211382; batch adversarial loss: 0.460560\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096541; batch adversarial loss: 0.383503\n",
      "epoch 76; iter: 0; batch classifier loss: 0.071557; batch adversarial loss: 0.461237\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067700; batch adversarial loss: 0.432795\n",
      "epoch 78; iter: 0; batch classifier loss: 0.085275; batch adversarial loss: 0.418198\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076524; batch adversarial loss: 0.406158\n",
      "epoch 80; iter: 0; batch classifier loss: 0.115230; batch adversarial loss: 0.418604\n",
      "epoch 81; iter: 0; batch classifier loss: 0.174748; batch adversarial loss: 0.372539\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085494; batch adversarial loss: 0.393470\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153407; batch adversarial loss: 0.355740\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108834; batch adversarial loss: 0.472802\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097901; batch adversarial loss: 0.393889\n",
      "epoch 86; iter: 0; batch classifier loss: 0.113428; batch adversarial loss: 0.354802\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073280; batch adversarial loss: 0.523761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.101616; batch adversarial loss: 0.485745\n",
      "epoch 89; iter: 0; batch classifier loss: 0.086995; batch adversarial loss: 0.493245\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075016; batch adversarial loss: 0.497578\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099510; batch adversarial loss: 0.419314\n",
      "epoch 92; iter: 0; batch classifier loss: 0.098747; batch adversarial loss: 0.469083\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069150; batch adversarial loss: 0.553196\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061382; batch adversarial loss: 0.397629\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051309; batch adversarial loss: 0.471850\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067739; batch adversarial loss: 0.451940\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074489; batch adversarial loss: 0.351460\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063075; batch adversarial loss: 0.544826\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069695; batch adversarial loss: 0.441278\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061730; batch adversarial loss: 0.438274\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055361; batch adversarial loss: 0.363593\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057080; batch adversarial loss: 0.568229\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038987; batch adversarial loss: 0.480449\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053452; batch adversarial loss: 0.400405\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069012; batch adversarial loss: 0.365566\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053458; batch adversarial loss: 0.476395\n",
      "epoch 107; iter: 0; batch classifier loss: 0.034869; batch adversarial loss: 0.370676\n",
      "epoch 108; iter: 0; batch classifier loss: 0.041847; batch adversarial loss: 0.394481\n",
      "epoch 109; iter: 0; batch classifier loss: 0.024775; batch adversarial loss: 0.497609\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060338; batch adversarial loss: 0.452322\n",
      "epoch 111; iter: 0; batch classifier loss: 0.019058; batch adversarial loss: 0.431862\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037993; batch adversarial loss: 0.507113\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048026; batch adversarial loss: 0.542545\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033671; batch adversarial loss: 0.412225\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050718; batch adversarial loss: 0.400762\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038788; batch adversarial loss: 0.489299\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029495; batch adversarial loss: 0.412956\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055514; batch adversarial loss: 0.378025\n",
      "epoch 119; iter: 0; batch classifier loss: 0.015701; batch adversarial loss: 0.418354\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043668; batch adversarial loss: 0.382632\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070288; batch adversarial loss: 0.360329\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015213; batch adversarial loss: 0.454614\n",
      "epoch 123; iter: 0; batch classifier loss: 0.065506; batch adversarial loss: 0.409325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.021900; batch adversarial loss: 0.465756\n",
      "epoch 125; iter: 0; batch classifier loss: 0.008259; batch adversarial loss: 0.368298\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031853; batch adversarial loss: 0.456544\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030741; batch adversarial loss: 0.476980\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035775; batch adversarial loss: 0.425529\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045137; batch adversarial loss: 0.500284\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035247; batch adversarial loss: 0.432549\n",
      "epoch 131; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.513405\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016842; batch adversarial loss: 0.418105\n",
      "epoch 133; iter: 0; batch classifier loss: 0.010893; batch adversarial loss: 0.485294\n",
      "epoch 134; iter: 0; batch classifier loss: 0.007276; batch adversarial loss: 0.461204\n",
      "epoch 135; iter: 0; batch classifier loss: 0.015072; batch adversarial loss: 0.443152\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020406; batch adversarial loss: 0.407518\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034099; batch adversarial loss: 0.437990\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010221; batch adversarial loss: 0.483207\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010243; batch adversarial loss: 0.483378\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044425; batch adversarial loss: 0.468318\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039074; batch adversarial loss: 0.455118\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026105; batch adversarial loss: 0.542948\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019163; batch adversarial loss: 0.392645\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014417; batch adversarial loss: 0.371980\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010577; batch adversarial loss: 0.472680\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016857; batch adversarial loss: 0.417107\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018538; batch adversarial loss: 0.477346\n",
      "epoch 148; iter: 0; batch classifier loss: 0.012163; batch adversarial loss: 0.462086\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026413; batch adversarial loss: 0.435770\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025026; batch adversarial loss: 0.393020\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022375; batch adversarial loss: 0.420469\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013638; batch adversarial loss: 0.472287\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042035; batch adversarial loss: 0.470274\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015781; batch adversarial loss: 0.477079\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016745; batch adversarial loss: 0.440259\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019467; batch adversarial loss: 0.481810\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.444506\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010111; batch adversarial loss: 0.442926\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012922; batch adversarial loss: 0.450011\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038908; batch adversarial loss: 0.402954\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008988; batch adversarial loss: 0.448935\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026031; batch adversarial loss: 0.515020\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017108; batch adversarial loss: 0.387852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065123; batch adversarial loss: 0.382605\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024970; batch adversarial loss: 0.441600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011968; batch adversarial loss: 0.445573\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021811; batch adversarial loss: 0.447791\n",
      "epoch 168; iter: 0; batch classifier loss: 0.014632; batch adversarial loss: 0.415592\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047793; batch adversarial loss: 0.492520\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023864; batch adversarial loss: 0.407337\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004150; batch adversarial loss: 0.543542\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009575; batch adversarial loss: 0.445566\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034944; batch adversarial loss: 0.429015\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026952; batch adversarial loss: 0.480918\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015890; batch adversarial loss: 0.374248\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018817; batch adversarial loss: 0.463140\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015827; batch adversarial loss: 0.493835\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021311; batch adversarial loss: 0.459737\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008096; batch adversarial loss: 0.474083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019170; batch adversarial loss: 0.444077\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006253; batch adversarial loss: 0.531366\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009470; batch adversarial loss: 0.381023\n",
      "epoch 183; iter: 0; batch classifier loss: 0.005985; batch adversarial loss: 0.352184\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037603; batch adversarial loss: 0.525894\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005586; batch adversarial loss: 0.424809\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011863; batch adversarial loss: 0.399503\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010131; batch adversarial loss: 0.479975\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013676; batch adversarial loss: 0.410088\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009692; batch adversarial loss: 0.306544\n",
      "epoch 190; iter: 0; batch classifier loss: 0.002467; batch adversarial loss: 0.446258\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006362; batch adversarial loss: 0.362581\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006177; batch adversarial loss: 0.538406\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015509; batch adversarial loss: 0.400409\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012957; batch adversarial loss: 0.474677\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027961; batch adversarial loss: 0.354390\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025868; batch adversarial loss: 0.507274\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015458; batch adversarial loss: 0.411049\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020050; batch adversarial loss: 0.411230\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021911; batch adversarial loss: 0.504876\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686599; batch adversarial loss: 0.697059\n",
      "epoch 1; iter: 0; batch classifier loss: 0.497007; batch adversarial loss: 0.656485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.474744; batch adversarial loss: 0.646777\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434994; batch adversarial loss: 0.616634\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367483; batch adversarial loss: 0.611646\n",
      "epoch 5; iter: 0; batch classifier loss: 0.429274; batch adversarial loss: 0.569788\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434821; batch adversarial loss: 0.565808\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508438; batch adversarial loss: 0.552786\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467096; batch adversarial loss: 0.603269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470197; batch adversarial loss: 0.558606\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402521; batch adversarial loss: 0.577561\n",
      "epoch 11; iter: 0; batch classifier loss: 0.433086; batch adversarial loss: 0.502214\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348801; batch adversarial loss: 0.556332\n",
      "epoch 13; iter: 0; batch classifier loss: 0.386153; batch adversarial loss: 0.520482\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283817; batch adversarial loss: 0.506336\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306986; batch adversarial loss: 0.521299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294376; batch adversarial loss: 0.512977\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253950; batch adversarial loss: 0.544431\n",
      "epoch 18; iter: 0; batch classifier loss: 0.265477; batch adversarial loss: 0.531591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343625; batch adversarial loss: 0.508997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.273682; batch adversarial loss: 0.475065\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235328; batch adversarial loss: 0.479604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.205433; batch adversarial loss: 0.503849\n",
      "epoch 23; iter: 0; batch classifier loss: 0.224397; batch adversarial loss: 0.538447\n",
      "epoch 24; iter: 0; batch classifier loss: 0.190805; batch adversarial loss: 0.531244\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241599; batch adversarial loss: 0.473074\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275310; batch adversarial loss: 0.492555\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278303; batch adversarial loss: 0.452260\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295887; batch adversarial loss: 0.508697\n",
      "epoch 29; iter: 0; batch classifier loss: 0.236278; batch adversarial loss: 0.421800\n",
      "epoch 30; iter: 0; batch classifier loss: 0.244852; batch adversarial loss: 0.441538\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223668; batch adversarial loss: 0.380759\n",
      "epoch 32; iter: 0; batch classifier loss: 0.243403; batch adversarial loss: 0.431901\n",
      "epoch 33; iter: 0; batch classifier loss: 0.206702; batch adversarial loss: 0.411990\n",
      "epoch 34; iter: 0; batch classifier loss: 0.182998; batch adversarial loss: 0.410483\n",
      "epoch 35; iter: 0; batch classifier loss: 0.155565; batch adversarial loss: 0.457574\n",
      "epoch 36; iter: 0; batch classifier loss: 0.211050; batch adversarial loss: 0.478662\n",
      "epoch 37; iter: 0; batch classifier loss: 0.164064; batch adversarial loss: 0.518877\n",
      "epoch 38; iter: 0; batch classifier loss: 0.180249; batch adversarial loss: 0.520566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176460; batch adversarial loss: 0.483982\n",
      "epoch 40; iter: 0; batch classifier loss: 0.142140; batch adversarial loss: 0.344354\n",
      "epoch 41; iter: 0; batch classifier loss: 0.191429; batch adversarial loss: 0.429885\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209746; batch adversarial loss: 0.404973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.176666; batch adversarial loss: 0.478757\n",
      "epoch 44; iter: 0; batch classifier loss: 0.184194; batch adversarial loss: 0.470179\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197111; batch adversarial loss: 0.459570\n",
      "epoch 46; iter: 0; batch classifier loss: 0.205092; batch adversarial loss: 0.480560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.226766; batch adversarial loss: 0.420419\n",
      "epoch 48; iter: 0; batch classifier loss: 0.195238; batch adversarial loss: 0.484213\n",
      "epoch 49; iter: 0; batch classifier loss: 0.169866; batch adversarial loss: 0.493993\n",
      "epoch 50; iter: 0; batch classifier loss: 0.183628; batch adversarial loss: 0.483907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158443; batch adversarial loss: 0.457884\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155522; batch adversarial loss: 0.469654\n",
      "epoch 53; iter: 0; batch classifier loss: 0.184621; batch adversarial loss: 0.457077\n",
      "epoch 54; iter: 0; batch classifier loss: 0.227905; batch adversarial loss: 0.422128\n",
      "epoch 55; iter: 0; batch classifier loss: 0.246931; batch adversarial loss: 0.445633\n",
      "epoch 56; iter: 0; batch classifier loss: 0.177472; batch adversarial loss: 0.460842\n",
      "epoch 57; iter: 0; batch classifier loss: 0.260549; batch adversarial loss: 0.402398\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177710; batch adversarial loss: 0.460281\n",
      "epoch 59; iter: 0; batch classifier loss: 0.171947; batch adversarial loss: 0.447254\n",
      "epoch 60; iter: 0; batch classifier loss: 0.138776; batch adversarial loss: 0.472519\n",
      "epoch 61; iter: 0; batch classifier loss: 0.143358; batch adversarial loss: 0.434488\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125968; batch adversarial loss: 0.381985\n",
      "epoch 63; iter: 0; batch classifier loss: 0.110913; batch adversarial loss: 0.437187\n",
      "epoch 64; iter: 0; batch classifier loss: 0.174871; batch adversarial loss: 0.471993\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196604; batch adversarial loss: 0.505689\n",
      "epoch 66; iter: 0; batch classifier loss: 0.185900; batch adversarial loss: 0.484495\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127681; batch adversarial loss: 0.470954\n",
      "epoch 68; iter: 0; batch classifier loss: 0.134222; batch adversarial loss: 0.409429\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081184; batch adversarial loss: 0.395851\n",
      "epoch 70; iter: 0; batch classifier loss: 0.161962; batch adversarial loss: 0.432972\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112219; batch adversarial loss: 0.489983\n",
      "epoch 72; iter: 0; batch classifier loss: 0.110059; batch adversarial loss: 0.494587\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071089; batch adversarial loss: 0.531047\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100699; batch adversarial loss: 0.474712\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110929; batch adversarial loss: 0.481459\n",
      "epoch 76; iter: 0; batch classifier loss: 0.126411; batch adversarial loss: 0.409520\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114605; batch adversarial loss: 0.405112\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079869; batch adversarial loss: 0.441332\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084931; batch adversarial loss: 0.341780\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053485; batch adversarial loss: 0.288204\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074895; batch adversarial loss: 0.496361\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095784; batch adversarial loss: 0.479688\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115498; batch adversarial loss: 0.388912\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085318; batch adversarial loss: 0.432285\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050536; batch adversarial loss: 0.460417\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054193; batch adversarial loss: 0.471028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.058154; batch adversarial loss: 0.426651\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034666; batch adversarial loss: 0.468263\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062940; batch adversarial loss: 0.378944\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028639; batch adversarial loss: 0.498676\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051392; batch adversarial loss: 0.485790\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054664; batch adversarial loss: 0.437447\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052393; batch adversarial loss: 0.469880\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042225; batch adversarial loss: 0.477782\n",
      "epoch 95; iter: 0; batch classifier loss: 0.067169; batch adversarial loss: 0.448948\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050994; batch adversarial loss: 0.417979\n",
      "epoch 97; iter: 0; batch classifier loss: 0.019063; batch adversarial loss: 0.463678\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043251; batch adversarial loss: 0.405852\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050224; batch adversarial loss: 0.485054\n",
      "epoch 100; iter: 0; batch classifier loss: 0.035679; batch adversarial loss: 0.517376\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050393; batch adversarial loss: 0.408482\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038430; batch adversarial loss: 0.469804\n",
      "epoch 103; iter: 0; batch classifier loss: 0.030707; batch adversarial loss: 0.415363\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061648; batch adversarial loss: 0.414907\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048947; batch adversarial loss: 0.384880\n",
      "epoch 106; iter: 0; batch classifier loss: 0.025079; batch adversarial loss: 0.555274\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027971; batch adversarial loss: 0.438363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035354; batch adversarial loss: 0.415936\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053918; batch adversarial loss: 0.350657\n",
      "epoch 110; iter: 0; batch classifier loss: 0.010967; batch adversarial loss: 0.481131\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043949; batch adversarial loss: 0.482762\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055288; batch adversarial loss: 0.392202\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027665; batch adversarial loss: 0.538585\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025934; batch adversarial loss: 0.454172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.013629; batch adversarial loss: 0.438204\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027252; batch adversarial loss: 0.417595\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.393431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.020534; batch adversarial loss: 0.518061\n",
      "epoch 119; iter: 0; batch classifier loss: 0.015232; batch adversarial loss: 0.371821\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032121; batch adversarial loss: 0.395330\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052105; batch adversarial loss: 0.452279\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015705; batch adversarial loss: 0.436238\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042731; batch adversarial loss: 0.419130\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021301; batch adversarial loss: 0.452817\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020016; batch adversarial loss: 0.435693\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022252; batch adversarial loss: 0.424351\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043665; batch adversarial loss: 0.413169\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014874; batch adversarial loss: 0.422222\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033483; batch adversarial loss: 0.470340\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020998; batch adversarial loss: 0.446412\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040137; batch adversarial loss: 0.398082\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020808; batch adversarial loss: 0.396707\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022019; batch adversarial loss: 0.412399\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028753; batch adversarial loss: 0.456688\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012586; batch adversarial loss: 0.424112\n",
      "epoch 136; iter: 0; batch classifier loss: 0.015806; batch adversarial loss: 0.419866\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043827; batch adversarial loss: 0.436387\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019034; batch adversarial loss: 0.426220\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018615; batch adversarial loss: 0.426052\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043092; batch adversarial loss: 0.441441\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028079; batch adversarial loss: 0.451190\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034561; batch adversarial loss: 0.430518\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033180; batch adversarial loss: 0.441512\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021373; batch adversarial loss: 0.413029\n",
      "epoch 145; iter: 0; batch classifier loss: 0.017766; batch adversarial loss: 0.526099\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014624; batch adversarial loss: 0.520561\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030015; batch adversarial loss: 0.481453\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019110; batch adversarial loss: 0.387062\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014212; batch adversarial loss: 0.517603\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028863; batch adversarial loss: 0.496931\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017879; batch adversarial loss: 0.448402\n",
      "epoch 152; iter: 0; batch classifier loss: 0.016436; batch adversarial loss: 0.483777\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016184; batch adversarial loss: 0.417911\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010346; batch adversarial loss: 0.447440\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046205; batch adversarial loss: 0.458891\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.437732\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006146; batch adversarial loss: 0.432040\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045929; batch adversarial loss: 0.453060\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023651; batch adversarial loss: 0.489103\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007133; batch adversarial loss: 0.398273\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017001; batch adversarial loss: 0.449620\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007982; batch adversarial loss: 0.560406\n",
      "epoch 163; iter: 0; batch classifier loss: 0.040542; batch adversarial loss: 0.389401\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011787; batch adversarial loss: 0.461845\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028594; batch adversarial loss: 0.447157\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013059; batch adversarial loss: 0.422457\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027078; batch adversarial loss: 0.433491\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009003; batch adversarial loss: 0.437612\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006209; batch adversarial loss: 0.471660\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015208; batch adversarial loss: 0.419746\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010591; batch adversarial loss: 0.428823\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025620; batch adversarial loss: 0.494924\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015616; batch adversarial loss: 0.456696\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014105; batch adversarial loss: 0.539188\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021699; batch adversarial loss: 0.446423\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003233; batch adversarial loss: 0.374707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033211; batch adversarial loss: 0.479435\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018516; batch adversarial loss: 0.460444\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025053; batch adversarial loss: 0.432879\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031280; batch adversarial loss: 0.486642\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010188; batch adversarial loss: 0.352035\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017386; batch adversarial loss: 0.418422\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023361; batch adversarial loss: 0.453365\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013913; batch adversarial loss: 0.442238\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010995; batch adversarial loss: 0.492272\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014334; batch adversarial loss: 0.507674\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003861; batch adversarial loss: 0.556149\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007178; batch adversarial loss: 0.460114\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014536; batch adversarial loss: 0.379845\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012838; batch adversarial loss: 0.420682\n",
      "epoch 191; iter: 0; batch classifier loss: 0.004911; batch adversarial loss: 0.431818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015552; batch adversarial loss: 0.464213\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021632; batch adversarial loss: 0.400511\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030266; batch adversarial loss: 0.464607\n",
      "epoch 195; iter: 0; batch classifier loss: 0.002787; batch adversarial loss: 0.443506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005741; batch adversarial loss: 0.481159\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033872; batch adversarial loss: 0.454390\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008013; batch adversarial loss: 0.465204\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013310; batch adversarial loss: 0.497542\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701640; batch adversarial loss: 0.745788\n",
      "epoch 1; iter: 0; batch classifier loss: 0.435919; batch adversarial loss: 0.712212\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399447; batch adversarial loss: 0.698701\n",
      "epoch 3; iter: 0; batch classifier loss: 0.360575; batch adversarial loss: 0.673742\n",
      "epoch 4; iter: 0; batch classifier loss: 0.359511; batch adversarial loss: 0.628502\n",
      "epoch 5; iter: 0; batch classifier loss: 0.433606; batch adversarial loss: 0.618968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.309712; batch adversarial loss: 0.559052\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296330; batch adversarial loss: 0.540477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301254; batch adversarial loss: 0.486572\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289906; batch adversarial loss: 0.523468\n",
      "epoch 10; iter: 0; batch classifier loss: 0.242264; batch adversarial loss: 0.541381\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209696; batch adversarial loss: 0.513335\n",
      "epoch 12; iter: 0; batch classifier loss: 0.198122; batch adversarial loss: 0.456347\n",
      "epoch 13; iter: 0; batch classifier loss: 0.185385; batch adversarial loss: 0.408846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.223617; batch adversarial loss: 0.381173\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236543; batch adversarial loss: 0.479165\n",
      "epoch 16; iter: 0; batch classifier loss: 0.175434; batch adversarial loss: 0.465287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.183501; batch adversarial loss: 0.475768\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197321; batch adversarial loss: 0.461288\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230621; batch adversarial loss: 0.435528\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195929; batch adversarial loss: 0.403193\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148991; batch adversarial loss: 0.423511\n",
      "epoch 22; iter: 0; batch classifier loss: 0.164792; batch adversarial loss: 0.370360\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177527; batch adversarial loss: 0.360943\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229523; batch adversarial loss: 0.466792\n",
      "epoch 25; iter: 0; batch classifier loss: 0.163937; batch adversarial loss: 0.418074\n",
      "epoch 26; iter: 0; batch classifier loss: 0.215911; batch adversarial loss: 0.404056\n",
      "epoch 27; iter: 0; batch classifier loss: 0.163553; batch adversarial loss: 0.370691\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179619; batch adversarial loss: 0.414293\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235356; batch adversarial loss: 0.517860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.189097; batch adversarial loss: 0.433652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.156187; batch adversarial loss: 0.424770\n",
      "epoch 32; iter: 0; batch classifier loss: 0.170744; batch adversarial loss: 0.472004\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187495; batch adversarial loss: 0.390039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170686; batch adversarial loss: 0.422530\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146434; batch adversarial loss: 0.395257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117399; batch adversarial loss: 0.359369\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143079; batch adversarial loss: 0.447621\n",
      "epoch 38; iter: 0; batch classifier loss: 0.139528; batch adversarial loss: 0.457472\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131463; batch adversarial loss: 0.345749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.131048; batch adversarial loss: 0.439434\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115700; batch adversarial loss: 0.448833\n",
      "epoch 42; iter: 0; batch classifier loss: 0.103356; batch adversarial loss: 0.386310\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114562; batch adversarial loss: 0.489822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108502; batch adversarial loss: 0.402916\n",
      "epoch 45; iter: 0; batch classifier loss: 0.162118; batch adversarial loss: 0.416729\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109040; batch adversarial loss: 0.507293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096810; batch adversarial loss: 0.358709\n",
      "epoch 48; iter: 0; batch classifier loss: 0.051330; batch adversarial loss: 0.409455\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110745; batch adversarial loss: 0.341194\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081390; batch adversarial loss: 0.473538\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109044; batch adversarial loss: 0.418044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093074; batch adversarial loss: 0.429775\n",
      "epoch 53; iter: 0; batch classifier loss: 0.097328; batch adversarial loss: 0.418796\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112387; batch adversarial loss: 0.451257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097749; batch adversarial loss: 0.401599\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070237; batch adversarial loss: 0.484000\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072171; batch adversarial loss: 0.504581\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066205; batch adversarial loss: 0.535718\n",
      "epoch 59; iter: 0; batch classifier loss: 0.068389; batch adversarial loss: 0.410694\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100477; batch adversarial loss: 0.400222\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087347; batch adversarial loss: 0.444681\n",
      "epoch 62; iter: 0; batch classifier loss: 0.062892; batch adversarial loss: 0.480966\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066452; batch adversarial loss: 0.425521\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105027; batch adversarial loss: 0.399981\n",
      "epoch 65; iter: 0; batch classifier loss: 0.045251; batch adversarial loss: 0.402971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074097; batch adversarial loss: 0.424874\n",
      "epoch 67; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.300836\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061534; batch adversarial loss: 0.397496\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066496; batch adversarial loss: 0.322958\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090006; batch adversarial loss: 0.451301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080398; batch adversarial loss: 0.346460\n",
      "epoch 72; iter: 0; batch classifier loss: 0.051731; batch adversarial loss: 0.403133\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061057; batch adversarial loss: 0.370608\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071361; batch adversarial loss: 0.435097\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112941; batch adversarial loss: 0.456877\n",
      "epoch 76; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.384342\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052465; batch adversarial loss: 0.442510\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079779; batch adversarial loss: 0.496334\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074487; batch adversarial loss: 0.508051\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064525; batch adversarial loss: 0.399434\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068473; batch adversarial loss: 0.400960\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078339; batch adversarial loss: 0.394789\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068668; batch adversarial loss: 0.380515\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082677; batch adversarial loss: 0.473456\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069052; batch adversarial loss: 0.455045\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074837; batch adversarial loss: 0.538393\n",
      "epoch 87; iter: 0; batch classifier loss: 0.094113; batch adversarial loss: 0.459052\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052549; batch adversarial loss: 0.486248\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036141; batch adversarial loss: 0.455827\n",
      "epoch 90; iter: 0; batch classifier loss: 0.077084; batch adversarial loss: 0.499208\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059449; batch adversarial loss: 0.442865\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063698; batch adversarial loss: 0.364030\n",
      "epoch 93; iter: 0; batch classifier loss: 0.026703; batch adversarial loss: 0.377826\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049238; batch adversarial loss: 0.416451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066653; batch adversarial loss: 0.520924\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053259; batch adversarial loss: 0.474347\n",
      "epoch 97; iter: 0; batch classifier loss: 0.061978; batch adversarial loss: 0.469052\n",
      "epoch 98; iter: 0; batch classifier loss: 0.021749; batch adversarial loss: 0.426397\n",
      "epoch 99; iter: 0; batch classifier loss: 0.025423; batch adversarial loss: 0.462191\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048266; batch adversarial loss: 0.367752\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058574; batch adversarial loss: 0.399286\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033347; batch adversarial loss: 0.464855\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060334; batch adversarial loss: 0.531148\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038926; batch adversarial loss: 0.315234\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022771; batch adversarial loss: 0.390011\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029083; batch adversarial loss: 0.410704\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047215; batch adversarial loss: 0.398597\n",
      "epoch 108; iter: 0; batch classifier loss: 0.039604; batch adversarial loss: 0.452956\n",
      "epoch 109; iter: 0; batch classifier loss: 0.022701; batch adversarial loss: 0.463203\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048490; batch adversarial loss: 0.466795\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060535; batch adversarial loss: 0.422333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.030979; batch adversarial loss: 0.390266\n",
      "epoch 113; iter: 0; batch classifier loss: 0.023235; batch adversarial loss: 0.452915\n",
      "epoch 114; iter: 0; batch classifier loss: 0.029458; batch adversarial loss: 0.473900\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021023; batch adversarial loss: 0.507054\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030921; batch adversarial loss: 0.432477\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.505055\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045931; batch adversarial loss: 0.489548\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045544; batch adversarial loss: 0.474887\n",
      "epoch 120; iter: 0; batch classifier loss: 0.093460; batch adversarial loss: 0.519297\n",
      "epoch 121; iter: 0; batch classifier loss: 0.121631; batch adversarial loss: 0.658200\n",
      "epoch 122; iter: 0; batch classifier loss: 0.110987; batch adversarial loss: 0.565155\n",
      "epoch 123; iter: 0; batch classifier loss: 0.113446; batch adversarial loss: 0.574280\n",
      "epoch 124; iter: 0; batch classifier loss: 0.126259; batch adversarial loss: 0.464568\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062203; batch adversarial loss: 0.514817\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047443; batch adversarial loss: 0.438293\n",
      "epoch 127; iter: 0; batch classifier loss: 0.099891; batch adversarial loss: 0.678987\n",
      "epoch 128; iter: 0; batch classifier loss: 0.113528; batch adversarial loss: 0.583907\n",
      "epoch 129; iter: 0; batch classifier loss: 0.113503; batch adversarial loss: 0.501878\n",
      "epoch 130; iter: 0; batch classifier loss: 0.094096; batch adversarial loss: 0.532367\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049556; batch adversarial loss: 0.477388\n",
      "epoch 132; iter: 0; batch classifier loss: 0.100327; batch adversarial loss: 0.510913\n",
      "epoch 133; iter: 0; batch classifier loss: 0.152849; batch adversarial loss: 0.479860\n",
      "epoch 134; iter: 0; batch classifier loss: 0.128948; batch adversarial loss: 0.612319\n",
      "epoch 135; iter: 0; batch classifier loss: 0.161119; batch adversarial loss: 0.715481\n",
      "epoch 136; iter: 0; batch classifier loss: 0.159137; batch adversarial loss: 0.677190\n",
      "epoch 137; iter: 0; batch classifier loss: 0.075163; batch adversarial loss: 0.487816\n",
      "epoch 138; iter: 0; batch classifier loss: 0.111405; batch adversarial loss: 0.494310\n",
      "epoch 139; iter: 0; batch classifier loss: 0.130522; batch adversarial loss: 0.581971\n",
      "epoch 140; iter: 0; batch classifier loss: 0.125299; batch adversarial loss: 0.444734\n",
      "epoch 141; iter: 0; batch classifier loss: 0.148919; batch adversarial loss: 0.566066\n",
      "epoch 142; iter: 0; batch classifier loss: 0.154769; batch adversarial loss: 0.548785\n",
      "epoch 143; iter: 0; batch classifier loss: 0.172704; batch adversarial loss: 0.613235\n",
      "epoch 144; iter: 0; batch classifier loss: 0.143930; batch adversarial loss: 0.578211\n",
      "epoch 145; iter: 0; batch classifier loss: 0.120403; batch adversarial loss: 0.590768\n",
      "epoch 146; iter: 0; batch classifier loss: 0.149948; batch adversarial loss: 0.690149\n",
      "epoch 147; iter: 0; batch classifier loss: 0.144837; batch adversarial loss: 0.497565\n",
      "epoch 148; iter: 0; batch classifier loss: 0.120480; batch adversarial loss: 0.513816\n",
      "epoch 149; iter: 0; batch classifier loss: 0.127060; batch adversarial loss: 0.514168\n",
      "epoch 150; iter: 0; batch classifier loss: 0.169839; batch adversarial loss: 0.595338\n",
      "epoch 151; iter: 0; batch classifier loss: 0.120368; batch adversarial loss: 0.541567\n",
      "epoch 152; iter: 0; batch classifier loss: 0.160513; batch adversarial loss: 0.498021\n",
      "epoch 153; iter: 0; batch classifier loss: 0.153927; batch adversarial loss: 0.515691\n",
      "epoch 154; iter: 0; batch classifier loss: 0.072624; batch adversarial loss: 0.458430\n",
      "epoch 155; iter: 0; batch classifier loss: 0.100098; batch adversarial loss: 0.423663\n",
      "epoch 156; iter: 0; batch classifier loss: 0.111549; batch adversarial loss: 0.484292\n",
      "epoch 157; iter: 0; batch classifier loss: 0.134281; batch adversarial loss: 0.462004\n",
      "epoch 158; iter: 0; batch classifier loss: 0.088352; batch adversarial loss: 0.467453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.115845; batch adversarial loss: 0.486829\n",
      "epoch 160; iter: 0; batch classifier loss: 0.117554; batch adversarial loss: 0.519968\n",
      "epoch 161; iter: 0; batch classifier loss: 0.078248; batch adversarial loss: 0.380793\n",
      "epoch 162; iter: 0; batch classifier loss: 0.102632; batch adversarial loss: 0.478560\n",
      "epoch 163; iter: 0; batch classifier loss: 0.105974; batch adversarial loss: 0.474479\n",
      "epoch 164; iter: 0; batch classifier loss: 0.065541; batch adversarial loss: 0.460415\n",
      "epoch 165; iter: 0; batch classifier loss: 0.133884; batch adversarial loss: 0.456045\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041708; batch adversarial loss: 0.544064\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017351; batch adversarial loss: 0.540089\n",
      "epoch 168; iter: 0; batch classifier loss: 0.049278; batch adversarial loss: 0.486704\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.420858\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022766; batch adversarial loss: 0.454599\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025180; batch adversarial loss: 0.410623\n",
      "epoch 172; iter: 0; batch classifier loss: 0.065316; batch adversarial loss: 0.423049\n",
      "epoch 173; iter: 0; batch classifier loss: 0.044696; batch adversarial loss: 0.548566\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041608; batch adversarial loss: 0.426231\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025541; batch adversarial loss: 0.346844\n",
      "epoch 176; iter: 0; batch classifier loss: 0.036656; batch adversarial loss: 0.497942\n",
      "epoch 177; iter: 0; batch classifier loss: 0.046579; batch adversarial loss: 0.436946\n",
      "epoch 178; iter: 0; batch classifier loss: 0.070195; batch adversarial loss: 0.464432\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043696; batch adversarial loss: 0.438282\n",
      "epoch 180; iter: 0; batch classifier loss: 0.082390; batch adversarial loss: 0.408570\n",
      "epoch 181; iter: 0; batch classifier loss: 0.053698; batch adversarial loss: 0.396382\n",
      "epoch 182; iter: 0; batch classifier loss: 0.070938; batch adversarial loss: 0.474132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.058363; batch adversarial loss: 0.331914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.061342; batch adversarial loss: 0.391346\n",
      "epoch 185; iter: 0; batch classifier loss: 0.089874; batch adversarial loss: 0.453644\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055515; batch adversarial loss: 0.523182\n",
      "epoch 187; iter: 0; batch classifier loss: 0.066616; batch adversarial loss: 0.527385\n",
      "epoch 188; iter: 0; batch classifier loss: 0.047516; batch adversarial loss: 0.480451\n",
      "epoch 189; iter: 0; batch classifier loss: 0.085594; batch adversarial loss: 0.434243\n",
      "epoch 190; iter: 0; batch classifier loss: 0.114131; batch adversarial loss: 0.487564\n",
      "epoch 191; iter: 0; batch classifier loss: 0.061797; batch adversarial loss: 0.437326\n",
      "epoch 192; iter: 0; batch classifier loss: 0.088155; batch adversarial loss: 0.423427\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037272; batch adversarial loss: 0.427695\n",
      "epoch 194; iter: 0; batch classifier loss: 0.118476; batch adversarial loss: 0.336217\n",
      "epoch 195; iter: 0; batch classifier loss: 0.054119; batch adversarial loss: 0.621608\n",
      "epoch 196; iter: 0; batch classifier loss: 0.087176; batch adversarial loss: 0.434203\n",
      "epoch 197; iter: 0; batch classifier loss: 0.066623; batch adversarial loss: 0.439931\n",
      "epoch 198; iter: 0; batch classifier loss: 0.134234; batch adversarial loss: 0.492643\n",
      "epoch 199; iter: 0; batch classifier loss: 0.110490; batch adversarial loss: 0.451773\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676751; batch adversarial loss: 0.661451\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421673; batch adversarial loss: 0.635218\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396530; batch adversarial loss: 0.617380\n",
      "epoch 3; iter: 0; batch classifier loss: 0.266706; batch adversarial loss: 0.620152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.241660; batch adversarial loss: 0.559612\n",
      "epoch 5; iter: 0; batch classifier loss: 0.306961; batch adversarial loss: 0.564674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.286720; batch adversarial loss: 0.494539\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401476; batch adversarial loss: 0.513728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.283057; batch adversarial loss: 0.500840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269891; batch adversarial loss: 0.504843\n",
      "epoch 10; iter: 0; batch classifier loss: 0.275833; batch adversarial loss: 0.522466\n",
      "epoch 11; iter: 0; batch classifier loss: 0.263592; batch adversarial loss: 0.485649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.179502; batch adversarial loss: 0.523031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.178480; batch adversarial loss: 0.492360\n",
      "epoch 14; iter: 0; batch classifier loss: 0.168309; batch adversarial loss: 0.471789\n",
      "epoch 15; iter: 0; batch classifier loss: 0.253793; batch adversarial loss: 0.538186\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270968; batch adversarial loss: 0.537683\n",
      "epoch 17; iter: 0; batch classifier loss: 0.175004; batch adversarial loss: 0.537218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197305; batch adversarial loss: 0.544290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.132033; batch adversarial loss: 0.467358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159618; batch adversarial loss: 0.536375\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201576; batch adversarial loss: 0.424199\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253844; batch adversarial loss: 0.502661\n",
      "epoch 23; iter: 0; batch classifier loss: 0.128841; batch adversarial loss: 0.450514\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194567; batch adversarial loss: 0.418544\n",
      "epoch 25; iter: 0; batch classifier loss: 0.228401; batch adversarial loss: 0.585041\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187012; batch adversarial loss: 0.461255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294157; batch adversarial loss: 0.432345\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328977; batch adversarial loss: 0.566086\n",
      "epoch 29; iter: 0; batch classifier loss: 0.231782; batch adversarial loss: 0.478512\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185270; batch adversarial loss: 0.436235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.102640; batch adversarial loss: 0.456143\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144111; batch adversarial loss: 0.425380\n",
      "epoch 33; iter: 0; batch classifier loss: 0.172584; batch adversarial loss: 0.375871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.133756; batch adversarial loss: 0.420945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125396; batch adversarial loss: 0.480539\n",
      "epoch 36; iter: 0; batch classifier loss: 0.119067; batch adversarial loss: 0.403406\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130349; batch adversarial loss: 0.410227\n",
      "epoch 38; iter: 0; batch classifier loss: 0.063050; batch adversarial loss: 0.438625\n",
      "epoch 39; iter: 0; batch classifier loss: 0.127791; batch adversarial loss: 0.441742\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103477; batch adversarial loss: 0.483160\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084998; batch adversarial loss: 0.360623\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117827; batch adversarial loss: 0.379327\n",
      "epoch 43; iter: 0; batch classifier loss: 0.101842; batch adversarial loss: 0.524968\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096752; batch adversarial loss: 0.454399\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079765; batch adversarial loss: 0.407577\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094779; batch adversarial loss: 0.470820\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089316; batch adversarial loss: 0.459309\n",
      "epoch 48; iter: 0; batch classifier loss: 0.092173; batch adversarial loss: 0.437106\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107926; batch adversarial loss: 0.440244\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108692; batch adversarial loss: 0.478710\n",
      "epoch 51; iter: 0; batch classifier loss: 0.153695; batch adversarial loss: 0.485803\n",
      "epoch 52; iter: 0; batch classifier loss: 0.116733; batch adversarial loss: 0.500388\n",
      "epoch 53; iter: 0; batch classifier loss: 0.051360; batch adversarial loss: 0.489588\n",
      "epoch 54; iter: 0; batch classifier loss: 0.106150; batch adversarial loss: 0.438577\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083963; batch adversarial loss: 0.382274\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065238; batch adversarial loss: 0.527086\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063771; batch adversarial loss: 0.357752\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090743; batch adversarial loss: 0.412765\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065124; batch adversarial loss: 0.483749\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082214; batch adversarial loss: 0.495789\n",
      "epoch 61; iter: 0; batch classifier loss: 0.113099; batch adversarial loss: 0.403051\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108823; batch adversarial loss: 0.412956\n",
      "epoch 63; iter: 0; batch classifier loss: 0.132316; batch adversarial loss: 0.438416\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066855; batch adversarial loss: 0.450377\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090517; batch adversarial loss: 0.373412\n",
      "epoch 66; iter: 0; batch classifier loss: 0.138775; batch adversarial loss: 0.390741\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091412; batch adversarial loss: 0.413896\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076425; batch adversarial loss: 0.458461\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060221; batch adversarial loss: 0.479923\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094202; batch adversarial loss: 0.492603\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103771; batch adversarial loss: 0.452543\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062194; batch adversarial loss: 0.553150\n",
      "epoch 73; iter: 0; batch classifier loss: 0.119954; batch adversarial loss: 0.431718\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062589; batch adversarial loss: 0.463128\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091439; batch adversarial loss: 0.419614\n",
      "epoch 76; iter: 0; batch classifier loss: 0.097162; batch adversarial loss: 0.434564\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080422; batch adversarial loss: 0.500583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.119130; batch adversarial loss: 0.563952\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076655; batch adversarial loss: 0.412846\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076832; batch adversarial loss: 0.503538\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120948; batch adversarial loss: 0.405835\n",
      "epoch 82; iter: 0; batch classifier loss: 0.060511; batch adversarial loss: 0.472965\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092034; batch adversarial loss: 0.543480\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048254; batch adversarial loss: 0.509358\n",
      "epoch 85; iter: 0; batch classifier loss: 0.067162; batch adversarial loss: 0.392128\n",
      "epoch 86; iter: 0; batch classifier loss: 0.120838; batch adversarial loss: 0.425741\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069496; batch adversarial loss: 0.518575\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064739; batch adversarial loss: 0.466381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031888; batch adversarial loss: 0.482669\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048908; batch adversarial loss: 0.478602\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066676; batch adversarial loss: 0.400455\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094420; batch adversarial loss: 0.387891\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077746; batch adversarial loss: 0.518988\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081043; batch adversarial loss: 0.453322\n",
      "epoch 95; iter: 0; batch classifier loss: 0.103956; batch adversarial loss: 0.433747\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096035; batch adversarial loss: 0.399542\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063347; batch adversarial loss: 0.474430\n",
      "epoch 98; iter: 0; batch classifier loss: 0.112000; batch adversarial loss: 0.536073\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075976; batch adversarial loss: 0.487937\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077780; batch adversarial loss: 0.451266\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090128; batch adversarial loss: 0.420501\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038557; batch adversarial loss: 0.544954\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060738; batch adversarial loss: 0.470510\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087613; batch adversarial loss: 0.414154\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060716; batch adversarial loss: 0.396218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.038386; batch adversarial loss: 0.444993\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044204; batch adversarial loss: 0.401901\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059389; batch adversarial loss: 0.500806\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046823; batch adversarial loss: 0.545608\n",
      "epoch 110; iter: 0; batch classifier loss: 0.029811; batch adversarial loss: 0.491648\n",
      "epoch 111; iter: 0; batch classifier loss: 0.068346; batch adversarial loss: 0.387562\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031158; batch adversarial loss: 0.458628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077054; batch adversarial loss: 0.453943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.017722; batch adversarial loss: 0.516087\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049363; batch adversarial loss: 0.537862\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045849; batch adversarial loss: 0.372564\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053396; batch adversarial loss: 0.382227\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032326; batch adversarial loss: 0.416774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034353; batch adversarial loss: 0.562685\n",
      "epoch 120; iter: 0; batch classifier loss: 0.105252; batch adversarial loss: 0.368854\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041025; batch adversarial loss: 0.389159\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048657; batch adversarial loss: 0.390872\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039824; batch adversarial loss: 0.474718\n",
      "epoch 124; iter: 0; batch classifier loss: 0.020920; batch adversarial loss: 0.416980\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028680; batch adversarial loss: 0.532347\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033233; batch adversarial loss: 0.476079\n",
      "epoch 127; iter: 0; batch classifier loss: 0.033773; batch adversarial loss: 0.448542\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052086; batch adversarial loss: 0.438974\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019926; batch adversarial loss: 0.412548\n",
      "epoch 130; iter: 0; batch classifier loss: 0.026510; batch adversarial loss: 0.590333\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015410; batch adversarial loss: 0.588671\n",
      "epoch 132; iter: 0; batch classifier loss: 0.079741; batch adversarial loss: 0.392381\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053942; batch adversarial loss: 0.395915\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034204; batch adversarial loss: 0.434777\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022228; batch adversarial loss: 0.380234\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024159; batch adversarial loss: 0.470622\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046716; batch adversarial loss: 0.375767\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056759; batch adversarial loss: 0.524972\n",
      "epoch 139; iter: 0; batch classifier loss: 0.040887; batch adversarial loss: 0.482771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.088649; batch adversarial loss: 0.546582\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044947; batch adversarial loss: 0.499015\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043100; batch adversarial loss: 0.472706\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034126; batch adversarial loss: 0.425465\n",
      "epoch 144; iter: 0; batch classifier loss: 0.028895; batch adversarial loss: 0.417802\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027869; batch adversarial loss: 0.452109\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030705; batch adversarial loss: 0.464482\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042197; batch adversarial loss: 0.378176\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043079; batch adversarial loss: 0.432588\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024991; batch adversarial loss: 0.401891\n",
      "epoch 150; iter: 0; batch classifier loss: 0.024253; batch adversarial loss: 0.455792\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025650; batch adversarial loss: 0.409830\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024308; batch adversarial loss: 0.438589\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038077; batch adversarial loss: 0.415759\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044839; batch adversarial loss: 0.454400\n",
      "epoch 155; iter: 0; batch classifier loss: 0.055359; batch adversarial loss: 0.542416\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022954; batch adversarial loss: 0.466076\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046369; batch adversarial loss: 0.502501\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015775; batch adversarial loss: 0.391990\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016406; batch adversarial loss: 0.512034\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014531; batch adversarial loss: 0.462803\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034855; batch adversarial loss: 0.527482\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018437; batch adversarial loss: 0.406350\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052854; batch adversarial loss: 0.410729\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037958; batch adversarial loss: 0.405660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018638; batch adversarial loss: 0.359036\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037593; batch adversarial loss: 0.473536\n",
      "epoch 167; iter: 0; batch classifier loss: 0.008709; batch adversarial loss: 0.546458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.057550; batch adversarial loss: 0.420451\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026167; batch adversarial loss: 0.488324\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013011; batch adversarial loss: 0.494781\n",
      "epoch 171; iter: 0; batch classifier loss: 0.042866; batch adversarial loss: 0.417706\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033850; batch adversarial loss: 0.499756\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021263; batch adversarial loss: 0.415324\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007700; batch adversarial loss: 0.436432\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034226; batch adversarial loss: 0.474127\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011937; batch adversarial loss: 0.442509\n",
      "epoch 177; iter: 0; batch classifier loss: 0.044974; batch adversarial loss: 0.554694\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037320; batch adversarial loss: 0.487875\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012442; batch adversarial loss: 0.437504\n",
      "epoch 180; iter: 0; batch classifier loss: 0.029580; batch adversarial loss: 0.410466\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022978; batch adversarial loss: 0.379789\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010728; batch adversarial loss: 0.468487\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009339; batch adversarial loss: 0.417173\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010852; batch adversarial loss: 0.484664\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037209; batch adversarial loss: 0.451951\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009356; batch adversarial loss: 0.412213\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038364; batch adversarial loss: 0.481983\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035675; batch adversarial loss: 0.535514\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040228; batch adversarial loss: 0.565625\n",
      "epoch 190; iter: 0; batch classifier loss: 0.029616; batch adversarial loss: 0.473264\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014054; batch adversarial loss: 0.371332\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035903; batch adversarial loss: 0.413536\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019188; batch adversarial loss: 0.428851\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022904; batch adversarial loss: 0.452393\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036794; batch adversarial loss: 0.469688\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011056; batch adversarial loss: 0.462362\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020853; batch adversarial loss: 0.545915\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013338; batch adversarial loss: 0.554471\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040899; batch adversarial loss: 0.497730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714861; batch adversarial loss: 0.623748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.463508; batch adversarial loss: 0.636360\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421787; batch adversarial loss: 0.651251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.516003; batch adversarial loss: 0.575435\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439440; batch adversarial loss: 0.605543\n",
      "epoch 5; iter: 0; batch classifier loss: 0.412912; batch adversarial loss: 0.556778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455493; batch adversarial loss: 0.564981\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384236; batch adversarial loss: 0.540481\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417763; batch adversarial loss: 0.550921\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408175; batch adversarial loss: 0.525282\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407797; batch adversarial loss: 0.521725\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413862; batch adversarial loss: 0.508353\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316498; batch adversarial loss: 0.501084\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373499; batch adversarial loss: 0.467989\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325537; batch adversarial loss: 0.526458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250980; batch adversarial loss: 0.534533\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319900; batch adversarial loss: 0.469236\n",
      "epoch 17; iter: 0; batch classifier loss: 0.184154; batch adversarial loss: 0.528769\n",
      "epoch 18; iter: 0; batch classifier loss: 0.244194; batch adversarial loss: 0.501585\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269946; batch adversarial loss: 0.503275\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273588; batch adversarial loss: 0.443564\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209221; batch adversarial loss: 0.471929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255787; batch adversarial loss: 0.391991\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210873; batch adversarial loss: 0.387801\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185220; batch adversarial loss: 0.515411\n",
      "epoch 25; iter: 0; batch classifier loss: 0.178548; batch adversarial loss: 0.515912\n",
      "epoch 26; iter: 0; batch classifier loss: 0.156591; batch adversarial loss: 0.531481\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164714; batch adversarial loss: 0.381098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.127907; batch adversarial loss: 0.396053\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131955; batch adversarial loss: 0.461809\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177694; batch adversarial loss: 0.447180\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133676; batch adversarial loss: 0.511996\n",
      "epoch 32; iter: 0; batch classifier loss: 0.101504; batch adversarial loss: 0.454447\n",
      "epoch 33; iter: 0; batch classifier loss: 0.160617; batch adversarial loss: 0.481160\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171309; batch adversarial loss: 0.431916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.151235; batch adversarial loss: 0.539122\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158085; batch adversarial loss: 0.425433\n",
      "epoch 37; iter: 0; batch classifier loss: 0.056184; batch adversarial loss: 0.536295\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153650; batch adversarial loss: 0.478029\n",
      "epoch 39; iter: 0; batch classifier loss: 0.109787; batch adversarial loss: 0.460439\n",
      "epoch 40; iter: 0; batch classifier loss: 0.146992; batch adversarial loss: 0.440879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118965; batch adversarial loss: 0.529605\n",
      "epoch 42; iter: 0; batch classifier loss: 0.119912; batch adversarial loss: 0.498713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097886; batch adversarial loss: 0.365802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.175914; batch adversarial loss: 0.426699\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099332; batch adversarial loss: 0.362795\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127895; batch adversarial loss: 0.455976\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070124; batch adversarial loss: 0.420039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101281; batch adversarial loss: 0.443797\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070203; batch adversarial loss: 0.362186\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094590; batch adversarial loss: 0.472821\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146407; batch adversarial loss: 0.432497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.085415; batch adversarial loss: 0.430843\n",
      "epoch 53; iter: 0; batch classifier loss: 0.055060; batch adversarial loss: 0.471907\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099200; batch adversarial loss: 0.521910\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091338; batch adversarial loss: 0.460292\n",
      "epoch 56; iter: 0; batch classifier loss: 0.055440; batch adversarial loss: 0.455594\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063004; batch adversarial loss: 0.441524\n",
      "epoch 58; iter: 0; batch classifier loss: 0.063045; batch adversarial loss: 0.439611\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097289; batch adversarial loss: 0.400322\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047628; batch adversarial loss: 0.505236\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090460; batch adversarial loss: 0.376462\n",
      "epoch 62; iter: 0; batch classifier loss: 0.075959; batch adversarial loss: 0.423816\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081646; batch adversarial loss: 0.425934\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074498; batch adversarial loss: 0.570488\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070120; batch adversarial loss: 0.492592\n",
      "epoch 66; iter: 0; batch classifier loss: 0.049562; batch adversarial loss: 0.413032\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090417; batch adversarial loss: 0.419949\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071852; batch adversarial loss: 0.455546\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102330; batch adversarial loss: 0.446961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.056328; batch adversarial loss: 0.489996\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090106; batch adversarial loss: 0.412971\n",
      "epoch 72; iter: 0; batch classifier loss: 0.063641; batch adversarial loss: 0.417342\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101518; batch adversarial loss: 0.476291\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054767; batch adversarial loss: 0.464937\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064636; batch adversarial loss: 0.406829\n",
      "epoch 76; iter: 0; batch classifier loss: 0.062102; batch adversarial loss: 0.412178\n",
      "epoch 77; iter: 0; batch classifier loss: 0.024585; batch adversarial loss: 0.464218\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067213; batch adversarial loss: 0.402286\n",
      "epoch 79; iter: 0; batch classifier loss: 0.047342; batch adversarial loss: 0.397649\n",
      "epoch 80; iter: 0; batch classifier loss: 0.035587; batch adversarial loss: 0.518668\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091822; batch adversarial loss: 0.400173\n",
      "epoch 82; iter: 0; batch classifier loss: 0.033966; batch adversarial loss: 0.380429\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069651; batch adversarial loss: 0.493914\n",
      "epoch 84; iter: 0; batch classifier loss: 0.037565; batch adversarial loss: 0.470390\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082120; batch adversarial loss: 0.503523\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066714; batch adversarial loss: 0.522709\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048555; batch adversarial loss: 0.544036\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049586; batch adversarial loss: 0.365954\n",
      "epoch 89; iter: 0; batch classifier loss: 0.064113; batch adversarial loss: 0.321775\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072908; batch adversarial loss: 0.453711\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060317; batch adversarial loss: 0.362500\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046101; batch adversarial loss: 0.544070\n",
      "epoch 93; iter: 0; batch classifier loss: 0.083457; batch adversarial loss: 0.429282\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047948; batch adversarial loss: 0.366657\n",
      "epoch 95; iter: 0; batch classifier loss: 0.080420; batch adversarial loss: 0.497708\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036791; batch adversarial loss: 0.396633\n",
      "epoch 97; iter: 0; batch classifier loss: 0.041592; batch adversarial loss: 0.318950\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048168; batch adversarial loss: 0.359083\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031302; batch adversarial loss: 0.505363\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038586; batch adversarial loss: 0.440565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.049040; batch adversarial loss: 0.489318\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044077; batch adversarial loss: 0.426101\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046053; batch adversarial loss: 0.533669\n",
      "epoch 104; iter: 0; batch classifier loss: 0.026477; batch adversarial loss: 0.417835\n",
      "epoch 105; iter: 0; batch classifier loss: 0.018059; batch adversarial loss: 0.555645\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045073; batch adversarial loss: 0.483434\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065207; batch adversarial loss: 0.474807\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067840; batch adversarial loss: 0.431795\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034089; batch adversarial loss: 0.523960\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043734; batch adversarial loss: 0.395187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062923; batch adversarial loss: 0.405999\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040693; batch adversarial loss: 0.393645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043548; batch adversarial loss: 0.352085\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052175; batch adversarial loss: 0.567260\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023560; batch adversarial loss: 0.453898\n",
      "epoch 116; iter: 0; batch classifier loss: 0.024031; batch adversarial loss: 0.480914\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048862; batch adversarial loss: 0.514914\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060279; batch adversarial loss: 0.372332\n",
      "epoch 119; iter: 0; batch classifier loss: 0.085551; batch adversarial loss: 0.395706\n",
      "epoch 120; iter: 0; batch classifier loss: 0.021762; batch adversarial loss: 0.386235\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049497; batch adversarial loss: 0.399343\n",
      "epoch 122; iter: 0; batch classifier loss: 0.024696; batch adversarial loss: 0.488919\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070628; batch adversarial loss: 0.427257\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029534; batch adversarial loss: 0.324004\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028323; batch adversarial loss: 0.430138\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026463; batch adversarial loss: 0.442918\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028670; batch adversarial loss: 0.490600\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054913; batch adversarial loss: 0.425452\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021524; batch adversarial loss: 0.421289\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041753; batch adversarial loss: 0.391198\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026516; batch adversarial loss: 0.563467\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037558; batch adversarial loss: 0.466061\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031302; batch adversarial loss: 0.468764\n",
      "epoch 134; iter: 0; batch classifier loss: 0.081183; batch adversarial loss: 0.459927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032529; batch adversarial loss: 0.360517\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013308; batch adversarial loss: 0.466276\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034154; batch adversarial loss: 0.367124\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018562; batch adversarial loss: 0.481171\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024847; batch adversarial loss: 0.415827\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026768; batch adversarial loss: 0.426882\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022145; batch adversarial loss: 0.448821\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021011; batch adversarial loss: 0.561101\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019026; batch adversarial loss: 0.471878\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041717; batch adversarial loss: 0.507008\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034742; batch adversarial loss: 0.388532\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020599; batch adversarial loss: 0.448255\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045250; batch adversarial loss: 0.434710\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053171; batch adversarial loss: 0.454038\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026032; batch adversarial loss: 0.358434\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019719; batch adversarial loss: 0.427977\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028188; batch adversarial loss: 0.455340\n",
      "epoch 152; iter: 0; batch classifier loss: 0.085409; batch adversarial loss: 0.446631\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020208; batch adversarial loss: 0.405856\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012600; batch adversarial loss: 0.530951\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025811; batch adversarial loss: 0.396748\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045040; batch adversarial loss: 0.463178\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018305; batch adversarial loss: 0.569484\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024228; batch adversarial loss: 0.438921\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007723; batch adversarial loss: 0.474242\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030561; batch adversarial loss: 0.385318\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017438; batch adversarial loss: 0.444046\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014554; batch adversarial loss: 0.409557\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028605; batch adversarial loss: 0.483304\n",
      "epoch 164; iter: 0; batch classifier loss: 0.054031; batch adversarial loss: 0.419274\n",
      "epoch 165; iter: 0; batch classifier loss: 0.009253; batch adversarial loss: 0.548069\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020876; batch adversarial loss: 0.438853\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005202; batch adversarial loss: 0.465482\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032432; batch adversarial loss: 0.597443\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019209; batch adversarial loss: 0.428078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.006706; batch adversarial loss: 0.459394\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027733; batch adversarial loss: 0.434137\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039109; batch adversarial loss: 0.445173\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019844; batch adversarial loss: 0.370793\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009071; batch adversarial loss: 0.428919\n",
      "epoch 175; iter: 0; batch classifier loss: 0.067806; batch adversarial loss: 0.422819\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017553; batch adversarial loss: 0.474999\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021101; batch adversarial loss: 0.481460\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012020; batch adversarial loss: 0.480802\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017306; batch adversarial loss: 0.456311\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032571; batch adversarial loss: 0.437855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025146; batch adversarial loss: 0.456283\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026518; batch adversarial loss: 0.451472\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040378; batch adversarial loss: 0.482315\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005131; batch adversarial loss: 0.391565\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027429; batch adversarial loss: 0.481362\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034450; batch adversarial loss: 0.572421\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.402828\n",
      "epoch 188; iter: 0; batch classifier loss: 0.021526; batch adversarial loss: 0.466851\n",
      "epoch 189; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.508822\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022271; batch adversarial loss: 0.460962\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046764; batch adversarial loss: 0.428180\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010317; batch adversarial loss: 0.366034\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019276; batch adversarial loss: 0.421522\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003792; batch adversarial loss: 0.451863\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051196; batch adversarial loss: 0.514638\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011207; batch adversarial loss: 0.464868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.040514; batch adversarial loss: 0.415400\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031004; batch adversarial loss: 0.497944\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020570; batch adversarial loss: 0.387962\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689260; batch adversarial loss: 0.638761\n",
      "epoch 1; iter: 0; batch classifier loss: 0.553160; batch adversarial loss: 0.643159\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437148; batch adversarial loss: 0.619737\n",
      "epoch 3; iter: 0; batch classifier loss: 0.470543; batch adversarial loss: 0.615609\n",
      "epoch 4; iter: 0; batch classifier loss: 0.389623; batch adversarial loss: 0.616833\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506630; batch adversarial loss: 0.617386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527230; batch adversarial loss: 0.601388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567164; batch adversarial loss: 0.578642\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491675; batch adversarial loss: 0.547990\n",
      "epoch 9; iter: 0; batch classifier loss: 0.406768; batch adversarial loss: 0.502251\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370490; batch adversarial loss: 0.549984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451092; batch adversarial loss: 0.504204\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.483151\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419244; batch adversarial loss: 0.476252\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403757; batch adversarial loss: 0.452239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334758; batch adversarial loss: 0.498118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384842; batch adversarial loss: 0.426796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391203; batch adversarial loss: 0.498509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234200; batch adversarial loss: 0.514054\n",
      "epoch 19; iter: 0; batch classifier loss: 0.255685; batch adversarial loss: 0.498343\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350556; batch adversarial loss: 0.468741\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325659; batch adversarial loss: 0.470729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305010; batch adversarial loss: 0.484353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259507; batch adversarial loss: 0.557864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.269204; batch adversarial loss: 0.475805\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242041; batch adversarial loss: 0.472049\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296056; batch adversarial loss: 0.430573\n",
      "epoch 27; iter: 0; batch classifier loss: 0.233784; batch adversarial loss: 0.487744\n",
      "epoch 28; iter: 0; batch classifier loss: 0.327960; batch adversarial loss: 0.468721\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258140; batch adversarial loss: 0.492357\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281560; batch adversarial loss: 0.489213\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249683; batch adversarial loss: 0.454634\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258575; batch adversarial loss: 0.486542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.217753; batch adversarial loss: 0.396452\n",
      "epoch 34; iter: 0; batch classifier loss: 0.225578; batch adversarial loss: 0.418555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.183293; batch adversarial loss: 0.514842\n",
      "epoch 36; iter: 0; batch classifier loss: 0.202524; batch adversarial loss: 0.472874\n",
      "epoch 37; iter: 0; batch classifier loss: 0.230523; batch adversarial loss: 0.460756\n",
      "epoch 38; iter: 0; batch classifier loss: 0.239459; batch adversarial loss: 0.539501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.245216; batch adversarial loss: 0.448438\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260527; batch adversarial loss: 0.438104\n",
      "epoch 41; iter: 0; batch classifier loss: 0.216178; batch adversarial loss: 0.483970\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249135; batch adversarial loss: 0.517330\n",
      "epoch 43; iter: 0; batch classifier loss: 0.220085; batch adversarial loss: 0.417658\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202395; batch adversarial loss: 0.451648\n",
      "epoch 45; iter: 0; batch classifier loss: 0.214627; batch adversarial loss: 0.510133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.202906; batch adversarial loss: 0.454946\n",
      "epoch 47; iter: 0; batch classifier loss: 0.223466; batch adversarial loss: 0.460727\n",
      "epoch 48; iter: 0; batch classifier loss: 0.168317; batch adversarial loss: 0.464734\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225519; batch adversarial loss: 0.520870\n",
      "epoch 50; iter: 0; batch classifier loss: 0.238361; batch adversarial loss: 0.408669\n",
      "epoch 51; iter: 0; batch classifier loss: 0.217624; batch adversarial loss: 0.493652\n",
      "epoch 52; iter: 0; batch classifier loss: 0.257665; batch adversarial loss: 0.447019\n",
      "epoch 53; iter: 0; batch classifier loss: 0.253447; batch adversarial loss: 0.531954\n",
      "epoch 54; iter: 0; batch classifier loss: 0.265647; batch adversarial loss: 0.494385\n",
      "epoch 55; iter: 0; batch classifier loss: 0.290791; batch adversarial loss: 0.507802\n",
      "epoch 56; iter: 0; batch classifier loss: 0.275079; batch adversarial loss: 0.447434\n",
      "epoch 57; iter: 0; batch classifier loss: 0.245266; batch adversarial loss: 0.434254\n",
      "epoch 58; iter: 0; batch classifier loss: 0.150626; batch adversarial loss: 0.470802\n",
      "epoch 59; iter: 0; batch classifier loss: 0.123216; batch adversarial loss: 0.458313\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101000; batch adversarial loss: 0.478626\n",
      "epoch 61; iter: 0; batch classifier loss: 0.254157; batch adversarial loss: 0.546717\n",
      "epoch 62; iter: 0; batch classifier loss: 0.164866; batch adversarial loss: 0.444454\n",
      "epoch 63; iter: 0; batch classifier loss: 0.152869; batch adversarial loss: 0.408297\n",
      "epoch 64; iter: 0; batch classifier loss: 0.215294; batch adversarial loss: 0.558627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.206841; batch adversarial loss: 0.420852\n",
      "epoch 66; iter: 0; batch classifier loss: 0.202638; batch adversarial loss: 0.469682\n",
      "epoch 67; iter: 0; batch classifier loss: 0.225276; batch adversarial loss: 0.484416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.190190; batch adversarial loss: 0.434175\n",
      "epoch 69; iter: 0; batch classifier loss: 0.225710; batch adversarial loss: 0.421915\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169944; batch adversarial loss: 0.483783\n",
      "epoch 71; iter: 0; batch classifier loss: 0.120653; batch adversarial loss: 0.519851\n",
      "epoch 72; iter: 0; batch classifier loss: 0.144526; batch adversarial loss: 0.524221\n",
      "epoch 73; iter: 0; batch classifier loss: 0.251795; batch adversarial loss: 0.434206\n",
      "epoch 74; iter: 0; batch classifier loss: 0.168632; batch adversarial loss: 0.496698\n",
      "epoch 75; iter: 0; batch classifier loss: 0.196347; batch adversarial loss: 0.473120\n",
      "epoch 76; iter: 0; batch classifier loss: 0.240646; batch adversarial loss: 0.562365\n",
      "epoch 77; iter: 0; batch classifier loss: 0.317420; batch adversarial loss: 0.432898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260670; batch adversarial loss: 0.396744\n",
      "epoch 79; iter: 0; batch classifier loss: 0.204075; batch adversarial loss: 0.359669\n",
      "epoch 80; iter: 0; batch classifier loss: 0.327238; batch adversarial loss: 0.434379\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069954; batch adversarial loss: 0.446219\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065792; batch adversarial loss: 0.445479\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100694; batch adversarial loss: 0.395641\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063509; batch adversarial loss: 0.415972\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070291; batch adversarial loss: 0.574148\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048935; batch adversarial loss: 0.479209\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064055; batch adversarial loss: 0.506252\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080743; batch adversarial loss: 0.428830\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072389; batch adversarial loss: 0.463330\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058308; batch adversarial loss: 0.416887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045365; batch adversarial loss: 0.418935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057914; batch adversarial loss: 0.445270\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053559; batch adversarial loss: 0.431016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.051585; batch adversarial loss: 0.427859\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034338; batch adversarial loss: 0.400187\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069054; batch adversarial loss: 0.411896\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043464; batch adversarial loss: 0.353103\n",
      "epoch 98; iter: 0; batch classifier loss: 0.038176; batch adversarial loss: 0.419772\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058967; batch adversarial loss: 0.417710\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047526; batch adversarial loss: 0.401719\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067896; batch adversarial loss: 0.431054\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056624; batch adversarial loss: 0.438069\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048774; batch adversarial loss: 0.452525\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062119; batch adversarial loss: 0.416145\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050092; batch adversarial loss: 0.440002\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035243; batch adversarial loss: 0.425036\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052900; batch adversarial loss: 0.472861\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034700; batch adversarial loss: 0.459571\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047823; batch adversarial loss: 0.415722\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028221; batch adversarial loss: 0.485179\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.446478\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034811; batch adversarial loss: 0.498530\n",
      "epoch 113; iter: 0; batch classifier loss: 0.074455; batch adversarial loss: 0.365880\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033981; batch adversarial loss: 0.568472\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038246; batch adversarial loss: 0.435187\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.487586\n",
      "epoch 117; iter: 0; batch classifier loss: 0.037083; batch adversarial loss: 0.411934\n",
      "epoch 118; iter: 0; batch classifier loss: 0.083096; batch adversarial loss: 0.424162\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042086; batch adversarial loss: 0.482831\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066854; batch adversarial loss: 0.518486\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017428; batch adversarial loss: 0.425765\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041287; batch adversarial loss: 0.493440\n",
      "epoch 123; iter: 0; batch classifier loss: 0.045217; batch adversarial loss: 0.494061\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054312; batch adversarial loss: 0.411184\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012764; batch adversarial loss: 0.405713\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030971; batch adversarial loss: 0.415103\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027356; batch adversarial loss: 0.426012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037489; batch adversarial loss: 0.468001\n",
      "epoch 129; iter: 0; batch classifier loss: 0.089848; batch adversarial loss: 0.414350\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020118; batch adversarial loss: 0.493178\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024287; batch adversarial loss: 0.520100\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.470235\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014321; batch adversarial loss: 0.543812\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048561; batch adversarial loss: 0.351315\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042941; batch adversarial loss: 0.401245\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028060; batch adversarial loss: 0.469526\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023701; batch adversarial loss: 0.353505\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026877; batch adversarial loss: 0.431599\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022248; batch adversarial loss: 0.474749\n",
      "epoch 140; iter: 0; batch classifier loss: 0.014035; batch adversarial loss: 0.389322\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039756; batch adversarial loss: 0.535886\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052198; batch adversarial loss: 0.469963\n",
      "epoch 143; iter: 0; batch classifier loss: 0.038364; batch adversarial loss: 0.534114\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027641; batch adversarial loss: 0.369539\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034211; batch adversarial loss: 0.464630\n",
      "epoch 146; iter: 0; batch classifier loss: 0.012266; batch adversarial loss: 0.444635\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021779; batch adversarial loss: 0.491851\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016945; batch adversarial loss: 0.462688\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026710; batch adversarial loss: 0.436442\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013632; batch adversarial loss: 0.504776\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014301; batch adversarial loss: 0.471183\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010870; batch adversarial loss: 0.434335\n",
      "epoch 153; iter: 0; batch classifier loss: 0.046703; batch adversarial loss: 0.460940\n",
      "epoch 154; iter: 0; batch classifier loss: 0.046082; batch adversarial loss: 0.419379\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031849; batch adversarial loss: 0.427137\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024774; batch adversarial loss: 0.476765\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041428; batch adversarial loss: 0.548716\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018236; batch adversarial loss: 0.565675\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027424; batch adversarial loss: 0.503964\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021408; batch adversarial loss: 0.438129\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030430; batch adversarial loss: 0.504654\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029433; batch adversarial loss: 0.501214\n",
      "epoch 163; iter: 0; batch classifier loss: 0.031919; batch adversarial loss: 0.388080\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010933; batch adversarial loss: 0.395341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.042165; batch adversarial loss: 0.498274\n",
      "epoch 166; iter: 0; batch classifier loss: 0.027708; batch adversarial loss: 0.479858\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033007; batch adversarial loss: 0.408816\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016328; batch adversarial loss: 0.416774\n",
      "epoch 169; iter: 0; batch classifier loss: 0.007281; batch adversarial loss: 0.454658\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047943; batch adversarial loss: 0.503775\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005962; batch adversarial loss: 0.562774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012303; batch adversarial loss: 0.440556\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014891; batch adversarial loss: 0.422557\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020557; batch adversarial loss: 0.439695\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019094; batch adversarial loss: 0.542318\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016922; batch adversarial loss: 0.413745\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010938; batch adversarial loss: 0.476654\n",
      "epoch 178; iter: 0; batch classifier loss: 0.033595; batch adversarial loss: 0.457766\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036769; batch adversarial loss: 0.508137\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007587; batch adversarial loss: 0.379782\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005362; batch adversarial loss: 0.423173\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017967; batch adversarial loss: 0.387942\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025604; batch adversarial loss: 0.433569\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011724; batch adversarial loss: 0.361864\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021477; batch adversarial loss: 0.424391\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014991; batch adversarial loss: 0.367825\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028929; batch adversarial loss: 0.438534\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007505; batch adversarial loss: 0.388500\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063837; batch adversarial loss: 0.392556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.008165; batch adversarial loss: 0.395753\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015014; batch adversarial loss: 0.275878\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014803; batch adversarial loss: 0.415148\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028543; batch adversarial loss: 0.353540\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033165; batch adversarial loss: 0.367381\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021983; batch adversarial loss: 0.423488\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016529; batch adversarial loss: 0.408116\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018067; batch adversarial loss: 0.469637\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018059; batch adversarial loss: 0.541077\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006107; batch adversarial loss: 0.405827\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696779; batch adversarial loss: 0.672457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476451; batch adversarial loss: 0.615813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.328564; batch adversarial loss: 0.654899\n",
      "epoch 3; iter: 0; batch classifier loss: 0.322131; batch adversarial loss: 0.631666\n",
      "epoch 4; iter: 0; batch classifier loss: 0.329743; batch adversarial loss: 0.651148\n",
      "epoch 5; iter: 0; batch classifier loss: 0.289228; batch adversarial loss: 0.541679\n",
      "epoch 6; iter: 0; batch classifier loss: 0.285320; batch adversarial loss: 0.530943\n",
      "epoch 7; iter: 0; batch classifier loss: 0.295626; batch adversarial loss: 0.526263\n",
      "epoch 8; iter: 0; batch classifier loss: 0.190744; batch adversarial loss: 0.622124\n",
      "epoch 9; iter: 0; batch classifier loss: 0.256912; batch adversarial loss: 0.581751\n",
      "epoch 10; iter: 0; batch classifier loss: 0.158854; batch adversarial loss: 0.507095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256722; batch adversarial loss: 0.546283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359713; batch adversarial loss: 0.521789\n",
      "epoch 13; iter: 0; batch classifier loss: 0.164049; batch adversarial loss: 0.523525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.202425; batch adversarial loss: 0.510386\n",
      "epoch 15; iter: 0; batch classifier loss: 0.200706; batch adversarial loss: 0.394694\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211954; batch adversarial loss: 0.486556\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234017; batch adversarial loss: 0.470979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245550; batch adversarial loss: 0.484189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.201763; batch adversarial loss: 0.475782\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261328; batch adversarial loss: 0.490442\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175792; batch adversarial loss: 0.475074\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229341; batch adversarial loss: 0.503936\n",
      "epoch 23; iter: 0; batch classifier loss: 0.180201; batch adversarial loss: 0.506383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181830; batch adversarial loss: 0.422108\n",
      "epoch 25; iter: 0; batch classifier loss: 0.150315; batch adversarial loss: 0.510912\n",
      "epoch 26; iter: 0; batch classifier loss: 0.138234; batch adversarial loss: 0.490998\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141044; batch adversarial loss: 0.489047\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141673; batch adversarial loss: 0.480740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166701; batch adversarial loss: 0.507966\n",
      "epoch 30; iter: 0; batch classifier loss: 0.223498; batch adversarial loss: 0.452014\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173675; batch adversarial loss: 0.520454\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124992; batch adversarial loss: 0.463616\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187009; batch adversarial loss: 0.419112\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131969; batch adversarial loss: 0.440761\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148137; batch adversarial loss: 0.465577\n",
      "epoch 36; iter: 0; batch classifier loss: 0.204137; batch adversarial loss: 0.541116\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146830; batch adversarial loss: 0.450309\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164935; batch adversarial loss: 0.488872\n",
      "epoch 39; iter: 0; batch classifier loss: 0.194120; batch adversarial loss: 0.438559\n",
      "epoch 40; iter: 0; batch classifier loss: 0.139168; batch adversarial loss: 0.532188\n",
      "epoch 41; iter: 0; batch classifier loss: 0.122956; batch adversarial loss: 0.471224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.197735; batch adversarial loss: 0.467627\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126881; batch adversarial loss: 0.458178\n",
      "epoch 44; iter: 0; batch classifier loss: 0.134263; batch adversarial loss: 0.431376\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096901; batch adversarial loss: 0.482881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110723; batch adversarial loss: 0.565266\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133631; batch adversarial loss: 0.488157\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104346; batch adversarial loss: 0.444449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079490; batch adversarial loss: 0.576588\n",
      "epoch 50; iter: 0; batch classifier loss: 0.150326; batch adversarial loss: 0.490374\n",
      "epoch 51; iter: 0; batch classifier loss: 0.128557; batch adversarial loss: 0.480422\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112905; batch adversarial loss: 0.513503\n",
      "epoch 53; iter: 0; batch classifier loss: 0.176684; batch adversarial loss: 0.503836\n",
      "epoch 54; iter: 0; batch classifier loss: 0.146548; batch adversarial loss: 0.454351\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104231; batch adversarial loss: 0.462906\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153273; batch adversarial loss: 0.359953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122198; batch adversarial loss: 0.575501\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187021; batch adversarial loss: 0.476701\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086927; batch adversarial loss: 0.382966\n",
      "epoch 60; iter: 0; batch classifier loss: 0.131004; batch adversarial loss: 0.497247\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115950; batch adversarial loss: 0.384383\n",
      "epoch 62; iter: 0; batch classifier loss: 0.151848; batch adversarial loss: 0.556685\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077387; batch adversarial loss: 0.526278\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115908; batch adversarial loss: 0.354898\n",
      "epoch 65; iter: 0; batch classifier loss: 0.133567; batch adversarial loss: 0.563188\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081012; batch adversarial loss: 0.451188\n",
      "epoch 67; iter: 0; batch classifier loss: 0.132215; batch adversarial loss: 0.446986\n",
      "epoch 68; iter: 0; batch classifier loss: 0.072654; batch adversarial loss: 0.498994\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097986; batch adversarial loss: 0.431482\n",
      "epoch 70; iter: 0; batch classifier loss: 0.131935; batch adversarial loss: 0.438301\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105084; batch adversarial loss: 0.409369\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090904; batch adversarial loss: 0.435186\n",
      "epoch 73; iter: 0; batch classifier loss: 0.096735; batch adversarial loss: 0.430463\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063380; batch adversarial loss: 0.505562\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060229; batch adversarial loss: 0.518969\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083002; batch adversarial loss: 0.480250\n",
      "epoch 77; iter: 0; batch classifier loss: 0.077958; batch adversarial loss: 0.491046\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115588; batch adversarial loss: 0.408673\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041780; batch adversarial loss: 0.403058\n",
      "epoch 80; iter: 0; batch classifier loss: 0.081745; batch adversarial loss: 0.449918\n",
      "epoch 81; iter: 0; batch classifier loss: 0.055487; batch adversarial loss: 0.560608\n",
      "epoch 82; iter: 0; batch classifier loss: 0.150012; batch adversarial loss: 0.484762\n",
      "epoch 83; iter: 0; batch classifier loss: 0.071184; batch adversarial loss: 0.426686\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069261; batch adversarial loss: 0.529809\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068174; batch adversarial loss: 0.529214\n",
      "epoch 86; iter: 0; batch classifier loss: 0.125502; batch adversarial loss: 0.385741\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081768; batch adversarial loss: 0.462861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.113152; batch adversarial loss: 0.470241\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059685; batch adversarial loss: 0.424294\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061306; batch adversarial loss: 0.554017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058740; batch adversarial loss: 0.432404\n",
      "epoch 92; iter: 0; batch classifier loss: 0.058366; batch adversarial loss: 0.501033\n",
      "epoch 93; iter: 0; batch classifier loss: 0.045333; batch adversarial loss: 0.526962\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045653; batch adversarial loss: 0.475395\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060374; batch adversarial loss: 0.389124\n",
      "epoch 96; iter: 0; batch classifier loss: 0.030293; batch adversarial loss: 0.477196\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070676; batch adversarial loss: 0.439557\n",
      "epoch 98; iter: 0; batch classifier loss: 0.046576; batch adversarial loss: 0.507094\n",
      "epoch 99; iter: 0; batch classifier loss: 0.098691; batch adversarial loss: 0.484354\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048850; batch adversarial loss: 0.486324\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038059; batch adversarial loss: 0.458577\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029927; batch adversarial loss: 0.421612\n",
      "epoch 103; iter: 0; batch classifier loss: 0.045647; batch adversarial loss: 0.393520\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.408531\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049182; batch adversarial loss: 0.401879\n",
      "epoch 106; iter: 0; batch classifier loss: 0.055826; batch adversarial loss: 0.366981\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021737; batch adversarial loss: 0.447048\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053423; batch adversarial loss: 0.444222\n",
      "epoch 109; iter: 0; batch classifier loss: 0.035008; batch adversarial loss: 0.444049\n",
      "epoch 110; iter: 0; batch classifier loss: 0.043463; batch adversarial loss: 0.480250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049519; batch adversarial loss: 0.455686\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043917; batch adversarial loss: 0.436648\n",
      "epoch 113; iter: 0; batch classifier loss: 0.068226; batch adversarial loss: 0.410901\n",
      "epoch 114; iter: 0; batch classifier loss: 0.069286; batch adversarial loss: 0.389313\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021697; batch adversarial loss: 0.487195\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043007; batch adversarial loss: 0.423258\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038935; batch adversarial loss: 0.451093\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057292; batch adversarial loss: 0.411782\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064471; batch adversarial loss: 0.417219\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047162; batch adversarial loss: 0.406075\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045812; batch adversarial loss: 0.486742\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028343; batch adversarial loss: 0.468394\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044607; batch adversarial loss: 0.540419\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026435; batch adversarial loss: 0.506555\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027228; batch adversarial loss: 0.528833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024246; batch adversarial loss: 0.381680\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029646; batch adversarial loss: 0.515504\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021504; batch adversarial loss: 0.488043\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057108; batch adversarial loss: 0.390126\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054537; batch adversarial loss: 0.474385\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018999; batch adversarial loss: 0.364007\n",
      "epoch 132; iter: 0; batch classifier loss: 0.042665; batch adversarial loss: 0.511019\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.611335\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021673; batch adversarial loss: 0.469344\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054945; batch adversarial loss: 0.423703\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025237; batch adversarial loss: 0.409423\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022754; batch adversarial loss: 0.453288\n",
      "epoch 138; iter: 0; batch classifier loss: 0.060499; batch adversarial loss: 0.448420\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055705; batch adversarial loss: 0.458669\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034123; batch adversarial loss: 0.416823\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040143; batch adversarial loss: 0.482804\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020997; batch adversarial loss: 0.357456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034517; batch adversarial loss: 0.378206\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014380; batch adversarial loss: 0.399883\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057564; batch adversarial loss: 0.397277\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026486; batch adversarial loss: 0.466993\n",
      "epoch 147; iter: 0; batch classifier loss: 0.062291; batch adversarial loss: 0.497370\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019452; batch adversarial loss: 0.511567\n",
      "epoch 149; iter: 0; batch classifier loss: 0.047450; batch adversarial loss: 0.487907\n",
      "epoch 150; iter: 0; batch classifier loss: 0.005434; batch adversarial loss: 0.472275\n",
      "epoch 151; iter: 0; batch classifier loss: 0.050364; batch adversarial loss: 0.438420\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032027; batch adversarial loss: 0.484438\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015423; batch adversarial loss: 0.495730\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012008; batch adversarial loss: 0.421925\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027261; batch adversarial loss: 0.501744\n",
      "epoch 156; iter: 0; batch classifier loss: 0.073965; batch adversarial loss: 0.379074\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010153; batch adversarial loss: 0.487552\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024926; batch adversarial loss: 0.501515\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013108; batch adversarial loss: 0.401994\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014030; batch adversarial loss: 0.445233\n",
      "epoch 161; iter: 0; batch classifier loss: 0.053373; batch adversarial loss: 0.431271\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024323; batch adversarial loss: 0.480562\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039595; batch adversarial loss: 0.376640\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018397; batch adversarial loss: 0.418783\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016281; batch adversarial loss: 0.508145\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040100; batch adversarial loss: 0.395799\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023489; batch adversarial loss: 0.456230\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012709; batch adversarial loss: 0.511094\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015519; batch adversarial loss: 0.455226\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020731; batch adversarial loss: 0.398664\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023994; batch adversarial loss: 0.537953\n",
      "epoch 172; iter: 0; batch classifier loss: 0.003539; batch adversarial loss: 0.377337\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025461; batch adversarial loss: 0.443498\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029125; batch adversarial loss: 0.329469\n",
      "epoch 175; iter: 0; batch classifier loss: 0.010722; batch adversarial loss: 0.468052\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031681; batch adversarial loss: 0.386126\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020142; batch adversarial loss: 0.412412\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008732; batch adversarial loss: 0.386138\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032051; batch adversarial loss: 0.453809\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017394; batch adversarial loss: 0.394958\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029504; batch adversarial loss: 0.490092\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017870; batch adversarial loss: 0.590964\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008566; batch adversarial loss: 0.461649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.004471; batch adversarial loss: 0.491630\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011292; batch adversarial loss: 0.475669\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019258; batch adversarial loss: 0.483712\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018040; batch adversarial loss: 0.462141\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020117; batch adversarial loss: 0.385542\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011852; batch adversarial loss: 0.476916\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024404; batch adversarial loss: 0.510843\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031407; batch adversarial loss: 0.523254\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020681; batch adversarial loss: 0.470279\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018772; batch adversarial loss: 0.442571\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008350; batch adversarial loss: 0.410793\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030753; batch adversarial loss: 0.407088\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012233; batch adversarial loss: 0.483117\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033703; batch adversarial loss: 0.497269\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002772; batch adversarial loss: 0.508520\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011818; batch adversarial loss: 0.551019\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716949; batch adversarial loss: 0.796026\n",
      "epoch 1; iter: 0; batch classifier loss: 0.571919; batch adversarial loss: 0.780869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.740743; batch adversarial loss: 0.780314\n",
      "epoch 3; iter: 0; batch classifier loss: 0.819963; batch adversarial loss: 0.714381\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746007; batch adversarial loss: 0.655941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496965; batch adversarial loss: 0.588563\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454041; batch adversarial loss: 0.576085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296660; batch adversarial loss: 0.574407\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396679; batch adversarial loss: 0.569855\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373487; batch adversarial loss: 0.544673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322399; batch adversarial loss: 0.527192\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321337; batch adversarial loss: 0.516653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349254; batch adversarial loss: 0.517892\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307757; batch adversarial loss: 0.510713\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306059; batch adversarial loss: 0.470064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350023; batch adversarial loss: 0.505199\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242498; batch adversarial loss: 0.546773\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375508; batch adversarial loss: 0.458009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259967; batch adversarial loss: 0.514951\n",
      "epoch 19; iter: 0; batch classifier loss: 0.268249; batch adversarial loss: 0.427879\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316165; batch adversarial loss: 0.488355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285376; batch adversarial loss: 0.494417\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258358; batch adversarial loss: 0.543738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284146; batch adversarial loss: 0.498481\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282409; batch adversarial loss: 0.470432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.289823; batch adversarial loss: 0.521747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271548; batch adversarial loss: 0.544002\n",
      "epoch 27; iter: 0; batch classifier loss: 0.257087; batch adversarial loss: 0.547801\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306120; batch adversarial loss: 0.412907\n",
      "epoch 29; iter: 0; batch classifier loss: 0.250492; batch adversarial loss: 0.407446\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285840; batch adversarial loss: 0.550159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283080; batch adversarial loss: 0.430241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.258355; batch adversarial loss: 0.392895\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194371; batch adversarial loss: 0.507687\n",
      "epoch 34; iter: 0; batch classifier loss: 0.221232; batch adversarial loss: 0.432268\n",
      "epoch 35; iter: 0; batch classifier loss: 0.200308; batch adversarial loss: 0.572855\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280231; batch adversarial loss: 0.445719\n",
      "epoch 37; iter: 0; batch classifier loss: 0.256597; batch adversarial loss: 0.427906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218953; batch adversarial loss: 0.462122\n",
      "epoch 39; iter: 0; batch classifier loss: 0.208793; batch adversarial loss: 0.418019\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164725; batch adversarial loss: 0.452961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.270227; batch adversarial loss: 0.531001\n",
      "epoch 42; iter: 0; batch classifier loss: 0.253149; batch adversarial loss: 0.474260\n",
      "epoch 43; iter: 0; batch classifier loss: 0.227447; batch adversarial loss: 0.386117\n",
      "epoch 44; iter: 0; batch classifier loss: 0.272862; batch adversarial loss: 0.436344\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225150; batch adversarial loss: 0.457463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.265390; batch adversarial loss: 0.501453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.206163; batch adversarial loss: 0.516613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.202278; batch adversarial loss: 0.424140\n",
      "epoch 49; iter: 0; batch classifier loss: 0.276461; batch adversarial loss: 0.530213\n",
      "epoch 50; iter: 0; batch classifier loss: 0.247681; batch adversarial loss: 0.376015\n",
      "epoch 51; iter: 0; batch classifier loss: 0.230771; batch adversarial loss: 0.425445\n",
      "epoch 52; iter: 0; batch classifier loss: 0.234610; batch adversarial loss: 0.458202\n",
      "epoch 53; iter: 0; batch classifier loss: 0.205152; batch adversarial loss: 0.433895\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200907; batch adversarial loss: 0.407169\n",
      "epoch 55; iter: 0; batch classifier loss: 0.156518; batch adversarial loss: 0.532194\n",
      "epoch 56; iter: 0; batch classifier loss: 0.259460; batch adversarial loss: 0.412444\n",
      "epoch 57; iter: 0; batch classifier loss: 0.178935; batch adversarial loss: 0.508975\n",
      "epoch 58; iter: 0; batch classifier loss: 0.241854; batch adversarial loss: 0.509329\n",
      "epoch 59; iter: 0; batch classifier loss: 0.242146; batch adversarial loss: 0.422718\n",
      "epoch 60; iter: 0; batch classifier loss: 0.181305; batch adversarial loss: 0.447146\n",
      "epoch 61; iter: 0; batch classifier loss: 0.202583; batch adversarial loss: 0.457730\n",
      "epoch 62; iter: 0; batch classifier loss: 0.249632; batch adversarial loss: 0.445810\n",
      "epoch 63; iter: 0; batch classifier loss: 0.195423; batch adversarial loss: 0.546821\n",
      "epoch 64; iter: 0; batch classifier loss: 0.216376; batch adversarial loss: 0.434234\n",
      "epoch 65; iter: 0; batch classifier loss: 0.211647; batch adversarial loss: 0.520765\n",
      "epoch 66; iter: 0; batch classifier loss: 0.233292; batch adversarial loss: 0.483850\n",
      "epoch 67; iter: 0; batch classifier loss: 0.149949; batch adversarial loss: 0.483645\n",
      "epoch 68; iter: 0; batch classifier loss: 0.182762; batch adversarial loss: 0.409596\n",
      "epoch 69; iter: 0; batch classifier loss: 0.243128; batch adversarial loss: 0.408923\n",
      "epoch 70; iter: 0; batch classifier loss: 0.185911; batch adversarial loss: 0.483775\n",
      "epoch 71; iter: 0; batch classifier loss: 0.207585; batch adversarial loss: 0.433978\n",
      "epoch 72; iter: 0; batch classifier loss: 0.237591; batch adversarial loss: 0.433988\n",
      "epoch 73; iter: 0; batch classifier loss: 0.261825; batch adversarial loss: 0.421805\n",
      "epoch 74; iter: 0; batch classifier loss: 0.261428; batch adversarial loss: 0.421814\n",
      "epoch 75; iter: 0; batch classifier loss: 0.123656; batch adversarial loss: 0.421443\n",
      "epoch 76; iter: 0; batch classifier loss: 0.132514; batch adversarial loss: 0.421350\n",
      "epoch 77; iter: 0; batch classifier loss: 0.162944; batch adversarial loss: 0.521093\n",
      "epoch 78; iter: 0; batch classifier loss: 0.208121; batch adversarial loss: 0.471320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120861; batch adversarial loss: 0.508873\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111357; batch adversarial loss: 0.471408\n",
      "epoch 81; iter: 0; batch classifier loss: 0.148056; batch adversarial loss: 0.436272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.195513; batch adversarial loss: 0.497896\n",
      "epoch 83; iter: 0; batch classifier loss: 0.276829; batch adversarial loss: 0.408039\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184336; batch adversarial loss: 0.408950\n",
      "epoch 85; iter: 0; batch classifier loss: 0.153344; batch adversarial loss: 0.395747\n",
      "epoch 86; iter: 0; batch classifier loss: 0.199099; batch adversarial loss: 0.470259\n",
      "epoch 87; iter: 0; batch classifier loss: 0.227138; batch adversarial loss: 0.508918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.144590; batch adversarial loss: 0.557281\n",
      "epoch 89; iter: 0; batch classifier loss: 0.146782; batch adversarial loss: 0.382271\n",
      "epoch 90; iter: 0; batch classifier loss: 0.095100; batch adversarial loss: 0.431744\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131098; batch adversarial loss: 0.534257\n",
      "epoch 92; iter: 0; batch classifier loss: 0.237694; batch adversarial loss: 0.392632\n",
      "epoch 93; iter: 0; batch classifier loss: 0.109247; batch adversarial loss: 0.456537\n",
      "epoch 94; iter: 0; batch classifier loss: 0.145416; batch adversarial loss: 0.446190\n",
      "epoch 95; iter: 0; batch classifier loss: 0.160267; batch adversarial loss: 0.473781\n",
      "epoch 96; iter: 0; batch classifier loss: 0.117794; batch adversarial loss: 0.472635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.105255; batch adversarial loss: 0.421561\n",
      "epoch 98; iter: 0; batch classifier loss: 0.111342; batch adversarial loss: 0.442057\n",
      "epoch 99; iter: 0; batch classifier loss: 0.099671; batch adversarial loss: 0.450575\n",
      "epoch 100; iter: 0; batch classifier loss: 0.140612; batch adversarial loss: 0.343967\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074065; batch adversarial loss: 0.464471\n",
      "epoch 102; iter: 0; batch classifier loss: 0.090404; batch adversarial loss: 0.458569\n",
      "epoch 103; iter: 0; batch classifier loss: 0.105394; batch adversarial loss: 0.393668\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090920; batch adversarial loss: 0.368211\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077738; batch adversarial loss: 0.529500\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069322; batch adversarial loss: 0.490225\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050350; batch adversarial loss: 0.545349\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037853; batch adversarial loss: 0.455492\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058143; batch adversarial loss: 0.351106\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067072; batch adversarial loss: 0.395179\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023490; batch adversarial loss: 0.415400\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034838; batch adversarial loss: 0.409478\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036526; batch adversarial loss: 0.466783\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068327; batch adversarial loss: 0.408938\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029965; batch adversarial loss: 0.423133\n",
      "epoch 116; iter: 0; batch classifier loss: 0.014491; batch adversarial loss: 0.438354\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027582; batch adversarial loss: 0.384021\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052893; batch adversarial loss: 0.419387\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.454159\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039730; batch adversarial loss: 0.480003\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024465; batch adversarial loss: 0.432506\n",
      "epoch 122; iter: 0; batch classifier loss: 0.087374; batch adversarial loss: 0.381337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037177; batch adversarial loss: 0.396820\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046717; batch adversarial loss: 0.341998\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032157; batch adversarial loss: 0.429999\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045421; batch adversarial loss: 0.443025\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051738; batch adversarial loss: 0.486272\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014366; batch adversarial loss: 0.496712\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.433390\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037192; batch adversarial loss: 0.382400\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035776; batch adversarial loss: 0.539979\n",
      "epoch 132; iter: 0; batch classifier loss: 0.026797; batch adversarial loss: 0.436597\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018157; batch adversarial loss: 0.341921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.072604; batch adversarial loss: 0.556324\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021842; batch adversarial loss: 0.458759\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019420; batch adversarial loss: 0.456005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028965; batch adversarial loss: 0.437782\n",
      "epoch 138; iter: 0; batch classifier loss: 0.012110; batch adversarial loss: 0.472574\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013040; batch adversarial loss: 0.402341\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.416439\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019377; batch adversarial loss: 0.432046\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022907; batch adversarial loss: 0.431241\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044445; batch adversarial loss: 0.477821\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031194; batch adversarial loss: 0.506004\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031305; batch adversarial loss: 0.386796\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011539; batch adversarial loss: 0.494044\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018337; batch adversarial loss: 0.499409\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018134; batch adversarial loss: 0.405575\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019782; batch adversarial loss: 0.347222\n",
      "epoch 150; iter: 0; batch classifier loss: 0.009685; batch adversarial loss: 0.466904\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036622; batch adversarial loss: 0.333675\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017795; batch adversarial loss: 0.419723\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018638; batch adversarial loss: 0.540824\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012662; batch adversarial loss: 0.438412\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046692; batch adversarial loss: 0.387667\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016076; batch adversarial loss: 0.378221\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012236; batch adversarial loss: 0.449925\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064506; batch adversarial loss: 0.436282\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028001; batch adversarial loss: 0.401968\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017298; batch adversarial loss: 0.438395\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007356; batch adversarial loss: 0.437377\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011388; batch adversarial loss: 0.462982\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034948; batch adversarial loss: 0.390654\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023818; batch adversarial loss: 0.406320\n",
      "epoch 165; iter: 0; batch classifier loss: 0.014145; batch adversarial loss: 0.455301\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007290; batch adversarial loss: 0.396968\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028509; batch adversarial loss: 0.359753\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020766; batch adversarial loss: 0.454280\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012332; batch adversarial loss: 0.471664\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023063; batch adversarial loss: 0.381061\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025475; batch adversarial loss: 0.422069\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009307; batch adversarial loss: 0.440268\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023760; batch adversarial loss: 0.431010\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019729; batch adversarial loss: 0.445255\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007591; batch adversarial loss: 0.437637\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.467112\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016861; batch adversarial loss: 0.481142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.008168; batch adversarial loss: 0.416035\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039755; batch adversarial loss: 0.374325\n",
      "epoch 180; iter: 0; batch classifier loss: 0.024376; batch adversarial loss: 0.497369\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022901; batch adversarial loss: 0.415785\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016554; batch adversarial loss: 0.502930\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011179; batch adversarial loss: 0.482413\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012341; batch adversarial loss: 0.418622\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007275; batch adversarial loss: 0.358510\n",
      "epoch 186; iter: 0; batch classifier loss: 0.003998; batch adversarial loss: 0.534303\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024871; batch adversarial loss: 0.460086\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009495; batch adversarial loss: 0.380528\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017968; batch adversarial loss: 0.495554\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010039; batch adversarial loss: 0.466734\n",
      "epoch 191; iter: 0; batch classifier loss: 0.026648; batch adversarial loss: 0.405419\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007270; batch adversarial loss: 0.507345\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018556; batch adversarial loss: 0.479977\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010432; batch adversarial loss: 0.441009\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008463; batch adversarial loss: 0.371556\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010137; batch adversarial loss: 0.386697\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012811; batch adversarial loss: 0.468303\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007994; batch adversarial loss: 0.474126\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035809; batch adversarial loss: 0.425521\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677868; batch adversarial loss: 0.798219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.475492; batch adversarial loss: 0.765356\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597967; batch adversarial loss: 0.755276\n",
      "epoch 3; iter: 0; batch classifier loss: 0.750080; batch adversarial loss: 0.700859\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676357; batch adversarial loss: 0.637636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512539; batch adversarial loss: 0.587810\n",
      "epoch 6; iter: 0; batch classifier loss: 0.350504; batch adversarial loss: 0.590046\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400983; batch adversarial loss: 0.569541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.380220; batch adversarial loss: 0.525239\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321328; batch adversarial loss: 0.563061\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314421; batch adversarial loss: 0.506670\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284833; batch adversarial loss: 0.525272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342690; batch adversarial loss: 0.509891\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272312; batch adversarial loss: 0.516597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313555; batch adversarial loss: 0.488287\n",
      "epoch 15; iter: 0; batch classifier loss: 0.222998; batch adversarial loss: 0.550337\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224329; batch adversarial loss: 0.482514\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273961; batch adversarial loss: 0.476380\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252158; batch adversarial loss: 0.489064\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275030; batch adversarial loss: 0.502350\n",
      "epoch 20; iter: 0; batch classifier loss: 0.233069; batch adversarial loss: 0.478383\n",
      "epoch 21; iter: 0; batch classifier loss: 0.259435; batch adversarial loss: 0.499117\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303477; batch adversarial loss: 0.468898\n",
      "epoch 23; iter: 0; batch classifier loss: 0.270809; batch adversarial loss: 0.445519\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274625; batch adversarial loss: 0.426583\n",
      "epoch 25; iter: 0; batch classifier loss: 0.230744; batch adversarial loss: 0.442926\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264643; batch adversarial loss: 0.487024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273373; batch adversarial loss: 0.425931\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159990; batch adversarial loss: 0.579954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172421; batch adversarial loss: 0.567862\n",
      "epoch 30; iter: 0; batch classifier loss: 0.181106; batch adversarial loss: 0.436665\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207432; batch adversarial loss: 0.468398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.152896; batch adversarial loss: 0.458046\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179852; batch adversarial loss: 0.526975\n",
      "epoch 34; iter: 0; batch classifier loss: 0.163130; batch adversarial loss: 0.496693\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142656; batch adversarial loss: 0.497003\n",
      "epoch 36; iter: 0; batch classifier loss: 0.170475; batch adversarial loss: 0.473102\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133604; batch adversarial loss: 0.544388\n",
      "epoch 38; iter: 0; batch classifier loss: 0.153236; batch adversarial loss: 0.557159\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148935; batch adversarial loss: 0.474366\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135916; batch adversarial loss: 0.431719\n",
      "epoch 41; iter: 0; batch classifier loss: 0.158026; batch adversarial loss: 0.443491\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130744; batch adversarial loss: 0.502442\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094949; batch adversarial loss: 0.503323\n",
      "epoch 44; iter: 0; batch classifier loss: 0.149179; batch adversarial loss: 0.404273\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083010; batch adversarial loss: 0.519978\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116624; batch adversarial loss: 0.426018\n",
      "epoch 47; iter: 0; batch classifier loss: 0.143380; batch adversarial loss: 0.488793\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103944; batch adversarial loss: 0.429361\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115258; batch adversarial loss: 0.447501\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105008; batch adversarial loss: 0.474382\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101918; batch adversarial loss: 0.412378\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089688; batch adversarial loss: 0.441980\n",
      "epoch 53; iter: 0; batch classifier loss: 0.086332; batch adversarial loss: 0.489245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.067698; batch adversarial loss: 0.440498\n",
      "epoch 55; iter: 0; batch classifier loss: 0.115842; batch adversarial loss: 0.440411\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070979; batch adversarial loss: 0.435375\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106810; batch adversarial loss: 0.463709\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077949; batch adversarial loss: 0.476957\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076073; batch adversarial loss: 0.421713\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075664; batch adversarial loss: 0.474384\n",
      "epoch 61; iter: 0; batch classifier loss: 0.054576; batch adversarial loss: 0.473261\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063531; batch adversarial loss: 0.459224\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070559; batch adversarial loss: 0.379447\n",
      "epoch 64; iter: 0; batch classifier loss: 0.039097; batch adversarial loss: 0.452945\n",
      "epoch 65; iter: 0; batch classifier loss: 0.046489; batch adversarial loss: 0.370543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056052; batch adversarial loss: 0.422025\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085908; batch adversarial loss: 0.432746\n",
      "epoch 68; iter: 0; batch classifier loss: 0.088130; batch adversarial loss: 0.410245\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067233; batch adversarial loss: 0.555218\n",
      "epoch 70; iter: 0; batch classifier loss: 0.047412; batch adversarial loss: 0.452850\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064379; batch adversarial loss: 0.438381\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050721; batch adversarial loss: 0.429187\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102498; batch adversarial loss: 0.350500\n",
      "epoch 74; iter: 0; batch classifier loss: 0.049022; batch adversarial loss: 0.425317\n",
      "epoch 75; iter: 0; batch classifier loss: 0.069444; batch adversarial loss: 0.444382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.021477; batch adversarial loss: 0.513930\n",
      "epoch 77; iter: 0; batch classifier loss: 0.055703; batch adversarial loss: 0.592073\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064050; batch adversarial loss: 0.471922\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065251; batch adversarial loss: 0.532925\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054024; batch adversarial loss: 0.416218\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080204; batch adversarial loss: 0.435762\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043431; batch adversarial loss: 0.475470\n",
      "epoch 83; iter: 0; batch classifier loss: 0.030856; batch adversarial loss: 0.487235\n",
      "epoch 84; iter: 0; batch classifier loss: 0.017606; batch adversarial loss: 0.430364\n",
      "epoch 85; iter: 0; batch classifier loss: 0.017508; batch adversarial loss: 0.586451\n",
      "epoch 86; iter: 0; batch classifier loss: 0.028769; batch adversarial loss: 0.524115\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.440754\n",
      "epoch 88; iter: 0; batch classifier loss: 0.039890; batch adversarial loss: 0.461665\n",
      "epoch 89; iter: 0; batch classifier loss: 0.111008; batch adversarial loss: 0.495753\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039785; batch adversarial loss: 0.402129\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041636; batch adversarial loss: 0.486065\n",
      "epoch 92; iter: 0; batch classifier loss: 0.047500; batch adversarial loss: 0.457859\n",
      "epoch 93; iter: 0; batch classifier loss: 0.036842; batch adversarial loss: 0.532072\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082777; batch adversarial loss: 0.438743\n",
      "epoch 95; iter: 0; batch classifier loss: 0.032527; batch adversarial loss: 0.440766\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056104; batch adversarial loss: 0.432893\n",
      "epoch 97; iter: 0; batch classifier loss: 0.027618; batch adversarial loss: 0.524397\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034290; batch adversarial loss: 0.494705\n",
      "epoch 99; iter: 0; batch classifier loss: 0.030648; batch adversarial loss: 0.477408\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044109; batch adversarial loss: 0.436822\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032547; batch adversarial loss: 0.348320\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042707; batch adversarial loss: 0.450798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071322; batch adversarial loss: 0.383456\n",
      "epoch 104; iter: 0; batch classifier loss: 0.023375; batch adversarial loss: 0.456401\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037791; batch adversarial loss: 0.404794\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067256; batch adversarial loss: 0.446787\n",
      "epoch 107; iter: 0; batch classifier loss: 0.065673; batch adversarial loss: 0.550235\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036961; batch adversarial loss: 0.445256\n",
      "epoch 109; iter: 0; batch classifier loss: 0.034283; batch adversarial loss: 0.442985\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036541; batch adversarial loss: 0.341941\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028938; batch adversarial loss: 0.472218\n",
      "epoch 112; iter: 0; batch classifier loss: 0.021801; batch adversarial loss: 0.470267\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041948; batch adversarial loss: 0.469033\n",
      "epoch 114; iter: 0; batch classifier loss: 0.067165; batch adversarial loss: 0.526606\n",
      "epoch 115; iter: 0; batch classifier loss: 0.030347; batch adversarial loss: 0.433608\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027467; batch adversarial loss: 0.495626\n",
      "epoch 117; iter: 0; batch classifier loss: 0.015207; batch adversarial loss: 0.483010\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029186; batch adversarial loss: 0.467013\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048103; batch adversarial loss: 0.398485\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035183; batch adversarial loss: 0.527759\n",
      "epoch 121; iter: 0; batch classifier loss: 0.022476; batch adversarial loss: 0.521347\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028009; batch adversarial loss: 0.573632\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.353337\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019649; batch adversarial loss: 0.472891\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026674; batch adversarial loss: 0.527592\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062728; batch adversarial loss: 0.472514\n",
      "epoch 127; iter: 0; batch classifier loss: 0.007829; batch adversarial loss: 0.374493\n",
      "epoch 128; iter: 0; batch classifier loss: 0.008179; batch adversarial loss: 0.435356\n",
      "epoch 129; iter: 0; batch classifier loss: 0.012751; batch adversarial loss: 0.449917\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021642; batch adversarial loss: 0.388583\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032405; batch adversarial loss: 0.526376\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011727; batch adversarial loss: 0.478664\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012149; batch adversarial loss: 0.471218\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044525; batch adversarial loss: 0.397434\n",
      "epoch 135; iter: 0; batch classifier loss: 0.008492; batch adversarial loss: 0.426642\n",
      "epoch 136; iter: 0; batch classifier loss: 0.020517; batch adversarial loss: 0.464925\n",
      "epoch 137; iter: 0; batch classifier loss: 0.027754; batch adversarial loss: 0.476009\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018163; batch adversarial loss: 0.483419\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019143; batch adversarial loss: 0.411776\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026955; batch adversarial loss: 0.448792\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022843; batch adversarial loss: 0.480608\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040381; batch adversarial loss: 0.471915\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014002; batch adversarial loss: 0.452280\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029797; batch adversarial loss: 0.527555\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019497; batch adversarial loss: 0.534332\n",
      "epoch 146; iter: 0; batch classifier loss: 0.014784; batch adversarial loss: 0.578774\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048458; batch adversarial loss: 0.469673\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.438267\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038544; batch adversarial loss: 0.469804\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012507; batch adversarial loss: 0.452412\n",
      "epoch 151; iter: 0; batch classifier loss: 0.014667; batch adversarial loss: 0.522012\n",
      "epoch 152; iter: 0; batch classifier loss: 0.009220; batch adversarial loss: 0.502896\n",
      "epoch 153; iter: 0; batch classifier loss: 0.005373; batch adversarial loss: 0.560122\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012811; batch adversarial loss: 0.342080\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023537; batch adversarial loss: 0.529958\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021577; batch adversarial loss: 0.438995\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013329; batch adversarial loss: 0.475848\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027531; batch adversarial loss: 0.490199\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009100; batch adversarial loss: 0.463691\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035985; batch adversarial loss: 0.542717\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025835; batch adversarial loss: 0.499323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.004376; batch adversarial loss: 0.443903\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030779; batch adversarial loss: 0.361530\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009795; batch adversarial loss: 0.504764\n",
      "epoch 165; iter: 0; batch classifier loss: 0.007044; batch adversarial loss: 0.458028\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012671; batch adversarial loss: 0.483318\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028902; batch adversarial loss: 0.457653\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034891; batch adversarial loss: 0.430567\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013719; batch adversarial loss: 0.508695\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008911; batch adversarial loss: 0.479164\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019736; batch adversarial loss: 0.538573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.015746; batch adversarial loss: 0.407633\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023491; batch adversarial loss: 0.375035\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015091; batch adversarial loss: 0.447251\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013701; batch adversarial loss: 0.472591\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011329; batch adversarial loss: 0.434083\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011718; batch adversarial loss: 0.495169\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024968; batch adversarial loss: 0.423855\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023379; batch adversarial loss: 0.471739\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019992; batch adversarial loss: 0.393472\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010508; batch adversarial loss: 0.507467\n",
      "epoch 182; iter: 0; batch classifier loss: 0.031965; batch adversarial loss: 0.431308\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021560; batch adversarial loss: 0.495818\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014565; batch adversarial loss: 0.519714\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021994; batch adversarial loss: 0.389012\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008212; batch adversarial loss: 0.420253\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024377; batch adversarial loss: 0.572424\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005165; batch adversarial loss: 0.460190\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.433802\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019578; batch adversarial loss: 0.391305\n",
      "epoch 191; iter: 0; batch classifier loss: 0.002457; batch adversarial loss: 0.370236\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010225; batch adversarial loss: 0.486811\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037388; batch adversarial loss: 0.428924\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008507; batch adversarial loss: 0.449420\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008229; batch adversarial loss: 0.513306\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012645; batch adversarial loss: 0.413239\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008561; batch adversarial loss: 0.474994\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015188; batch adversarial loss: 0.483770\n",
      "epoch 199; iter: 0; batch classifier loss: 0.006144; batch adversarial loss: 0.420511\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709290; batch adversarial loss: 1.009904\n",
      "epoch 1; iter: 0; batch classifier loss: 0.667398; batch adversarial loss: 1.077265\n",
      "epoch 2; iter: 0; batch classifier loss: 0.899604; batch adversarial loss: 1.092046\n",
      "epoch 3; iter: 0; batch classifier loss: 1.217819; batch adversarial loss: 1.047293\n",
      "epoch 4; iter: 0; batch classifier loss: 1.130234; batch adversarial loss: 0.931772\n",
      "epoch 5; iter: 0; batch classifier loss: 1.067215; batch adversarial loss: 0.835054\n",
      "epoch 6; iter: 0; batch classifier loss: 1.106950; batch adversarial loss: 0.766252\n",
      "epoch 7; iter: 0; batch classifier loss: 1.085540; batch adversarial loss: 0.695761\n",
      "epoch 8; iter: 0; batch classifier loss: 1.133802; batch adversarial loss: 0.633181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.855485; batch adversarial loss: 0.598124\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594492; batch adversarial loss: 0.537679\n",
      "epoch 11; iter: 0; batch classifier loss: 0.453596; batch adversarial loss: 0.528512\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373811; batch adversarial loss: 0.491248\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267038; batch adversarial loss: 0.551247\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288400; batch adversarial loss: 0.540960\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257650; batch adversarial loss: 0.533282\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294537; batch adversarial loss: 0.474996\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302602; batch adversarial loss: 0.476278\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283796; batch adversarial loss: 0.538402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306249; batch adversarial loss: 0.456110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286197; batch adversarial loss: 0.500926\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234642; batch adversarial loss: 0.510231\n",
      "epoch 22; iter: 0; batch classifier loss: 0.253095; batch adversarial loss: 0.491910\n",
      "epoch 23; iter: 0; batch classifier loss: 0.232465; batch adversarial loss: 0.480523\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228658; batch adversarial loss: 0.464308\n",
      "epoch 25; iter: 0; batch classifier loss: 0.212785; batch adversarial loss: 0.450457\n",
      "epoch 26; iter: 0; batch classifier loss: 0.187614; batch adversarial loss: 0.536102\n",
      "epoch 27; iter: 0; batch classifier loss: 0.219934; batch adversarial loss: 0.510236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.188690; batch adversarial loss: 0.515933\n",
      "epoch 29; iter: 0; batch classifier loss: 0.207336; batch adversarial loss: 0.554411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130636; batch adversarial loss: 0.477854\n",
      "epoch 31; iter: 0; batch classifier loss: 0.188832; batch adversarial loss: 0.456936\n",
      "epoch 32; iter: 0; batch classifier loss: 0.189011; batch adversarial loss: 0.485262\n",
      "epoch 33; iter: 0; batch classifier loss: 0.209096; batch adversarial loss: 0.491202\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145265; batch adversarial loss: 0.591857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160235; batch adversarial loss: 0.495049\n",
      "epoch 36; iter: 0; batch classifier loss: 0.200773; batch adversarial loss: 0.514090\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172861; batch adversarial loss: 0.394935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129398; batch adversarial loss: 0.483452\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158389; batch adversarial loss: 0.467204\n",
      "epoch 40; iter: 0; batch classifier loss: 0.194206; batch adversarial loss: 0.427182\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147220; batch adversarial loss: 0.408251\n",
      "epoch 42; iter: 0; batch classifier loss: 0.150397; batch adversarial loss: 0.367949\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145469; batch adversarial loss: 0.469712\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129856; batch adversarial loss: 0.508846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.164214; batch adversarial loss: 0.477205\n",
      "epoch 46; iter: 0; batch classifier loss: 0.144251; batch adversarial loss: 0.411503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.190550; batch adversarial loss: 0.432524\n",
      "epoch 48; iter: 0; batch classifier loss: 0.105240; batch adversarial loss: 0.459846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096824; batch adversarial loss: 0.477055\n",
      "epoch 50; iter: 0; batch classifier loss: 0.079549; batch adversarial loss: 0.406302\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117804; batch adversarial loss: 0.405819\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079909; batch adversarial loss: 0.477586\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113335; batch adversarial loss: 0.454945\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108207; batch adversarial loss: 0.408974\n",
      "epoch 55; iter: 0; batch classifier loss: 0.076070; batch adversarial loss: 0.464885\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119768; batch adversarial loss: 0.410717\n",
      "epoch 57; iter: 0; batch classifier loss: 0.162106; batch adversarial loss: 0.486068\n",
      "epoch 58; iter: 0; batch classifier loss: 0.069328; batch adversarial loss: 0.404221\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110130; batch adversarial loss: 0.433640\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115952; batch adversarial loss: 0.472119\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109511; batch adversarial loss: 0.400968\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105326; batch adversarial loss: 0.391812\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112335; batch adversarial loss: 0.480416\n",
      "epoch 64; iter: 0; batch classifier loss: 0.140275; batch adversarial loss: 0.341156\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085415; batch adversarial loss: 0.521681\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102310; batch adversarial loss: 0.501495\n",
      "epoch 67; iter: 0; batch classifier loss: 0.079218; batch adversarial loss: 0.418313\n",
      "epoch 68; iter: 0; batch classifier loss: 0.109242; batch adversarial loss: 0.557267\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106471; batch adversarial loss: 0.455131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.090514; batch adversarial loss: 0.506453\n",
      "epoch 71; iter: 0; batch classifier loss: 0.088622; batch adversarial loss: 0.492911\n",
      "epoch 72; iter: 0; batch classifier loss: 0.048088; batch adversarial loss: 0.428876\n",
      "epoch 73; iter: 0; batch classifier loss: 0.127691; batch adversarial loss: 0.436630\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066193; batch adversarial loss: 0.494333\n",
      "epoch 75; iter: 0; batch classifier loss: 0.054320; batch adversarial loss: 0.472018\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061357; batch adversarial loss: 0.383314\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072447; batch adversarial loss: 0.470746\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104827; batch adversarial loss: 0.454431\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077821; batch adversarial loss: 0.358635\n",
      "epoch 80; iter: 0; batch classifier loss: 0.119904; batch adversarial loss: 0.452018\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069780; batch adversarial loss: 0.458855\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087435; batch adversarial loss: 0.486907\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.464652\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064609; batch adversarial loss: 0.459644\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070741; batch adversarial loss: 0.458192\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079547; batch adversarial loss: 0.357880\n",
      "epoch 87; iter: 0; batch classifier loss: 0.039387; batch adversarial loss: 0.445442\n",
      "epoch 88; iter: 0; batch classifier loss: 0.056096; batch adversarial loss: 0.514103\n",
      "epoch 89; iter: 0; batch classifier loss: 0.084354; batch adversarial loss: 0.450364\n",
      "epoch 90; iter: 0; batch classifier loss: 0.043430; batch adversarial loss: 0.515327\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059346; batch adversarial loss: 0.450933\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057778; batch adversarial loss: 0.490163\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072993; batch adversarial loss: 0.425955\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048092; batch adversarial loss: 0.462734\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057912; batch adversarial loss: 0.498115\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041875; batch adversarial loss: 0.556009\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054675; batch adversarial loss: 0.475306\n",
      "epoch 98; iter: 0; batch classifier loss: 0.085287; batch adversarial loss: 0.465131\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085419; batch adversarial loss: 0.460197\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043930; batch adversarial loss: 0.458597\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058709; batch adversarial loss: 0.469156\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044598; batch adversarial loss: 0.521253\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033887; batch adversarial loss: 0.529347\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057412; batch adversarial loss: 0.496869\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075658; batch adversarial loss: 0.440304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044260; batch adversarial loss: 0.412790\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039023; batch adversarial loss: 0.379895\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063638; batch adversarial loss: 0.516220\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039963; batch adversarial loss: 0.434390\n",
      "epoch 110; iter: 0; batch classifier loss: 0.058340; batch adversarial loss: 0.466353\n",
      "epoch 111; iter: 0; batch classifier loss: 0.020322; batch adversarial loss: 0.500409\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050508; batch adversarial loss: 0.395769\n",
      "epoch 113; iter: 0; batch classifier loss: 0.024766; batch adversarial loss: 0.410878\n",
      "epoch 114; iter: 0; batch classifier loss: 0.023276; batch adversarial loss: 0.478505\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039489; batch adversarial loss: 0.500531\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056361; batch adversarial loss: 0.351553\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038307; batch adversarial loss: 0.403059\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.460156\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036443; batch adversarial loss: 0.408562\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027259; batch adversarial loss: 0.423665\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042105; batch adversarial loss: 0.452789\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043269; batch adversarial loss: 0.414403\n",
      "epoch 123; iter: 0; batch classifier loss: 0.017943; batch adversarial loss: 0.405420\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048499; batch adversarial loss: 0.498536\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048215; batch adversarial loss: 0.485784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026348; batch adversarial loss: 0.459689\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054118; batch adversarial loss: 0.448216\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025254; batch adversarial loss: 0.420601\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019787; batch adversarial loss: 0.390566\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024523; batch adversarial loss: 0.420240\n",
      "epoch 131; iter: 0; batch classifier loss: 0.011469; batch adversarial loss: 0.410632\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023759; batch adversarial loss: 0.414805\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014797; batch adversarial loss: 0.379542\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031948; batch adversarial loss: 0.471742\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029000; batch adversarial loss: 0.396948\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030959; batch adversarial loss: 0.458412\n",
      "epoch 137; iter: 0; batch classifier loss: 0.051229; batch adversarial loss: 0.371415\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027005; batch adversarial loss: 0.416345\n",
      "epoch 139; iter: 0; batch classifier loss: 0.011610; batch adversarial loss: 0.480859\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067707; batch adversarial loss: 0.467371\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021607; batch adversarial loss: 0.445734\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028289; batch adversarial loss: 0.464538\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033373; batch adversarial loss: 0.467681\n",
      "epoch 144; iter: 0; batch classifier loss: 0.032498; batch adversarial loss: 0.391547\n",
      "epoch 145; iter: 0; batch classifier loss: 0.059050; batch adversarial loss: 0.450312\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022628; batch adversarial loss: 0.464042\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026872; batch adversarial loss: 0.378689\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021157; batch adversarial loss: 0.414350\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028740; batch adversarial loss: 0.432945\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015876; batch adversarial loss: 0.386983\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035549; batch adversarial loss: 0.432829\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032232; batch adversarial loss: 0.497491\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030412; batch adversarial loss: 0.420059\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031086; batch adversarial loss: 0.499674\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017401; batch adversarial loss: 0.428623\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014397; batch adversarial loss: 0.476095\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006512; batch adversarial loss: 0.496577\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016938; batch adversarial loss: 0.505735\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022919; batch adversarial loss: 0.415601\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006127; batch adversarial loss: 0.565105\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011593; batch adversarial loss: 0.480504\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046703; batch adversarial loss: 0.439033\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018859; batch adversarial loss: 0.421784\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023033; batch adversarial loss: 0.408094\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015411; batch adversarial loss: 0.437083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.015697; batch adversarial loss: 0.514507\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006439; batch adversarial loss: 0.424420\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007454; batch adversarial loss: 0.447784\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028684; batch adversarial loss: 0.412806\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020032; batch adversarial loss: 0.504514\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020167; batch adversarial loss: 0.393249\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009347; batch adversarial loss: 0.482963\n",
      "epoch 173; iter: 0; batch classifier loss: 0.007240; batch adversarial loss: 0.391109\n",
      "epoch 174; iter: 0; batch classifier loss: 0.009009; batch adversarial loss: 0.443615\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021125; batch adversarial loss: 0.458641\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030842; batch adversarial loss: 0.449390\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013806; batch adversarial loss: 0.503734\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025672; batch adversarial loss: 0.531423\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037698; batch adversarial loss: 0.414466\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014691; batch adversarial loss: 0.487775\n",
      "epoch 181; iter: 0; batch classifier loss: 0.012036; batch adversarial loss: 0.461557\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035108; batch adversarial loss: 0.449063\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014454; batch adversarial loss: 0.521327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010134; batch adversarial loss: 0.445184\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011485; batch adversarial loss: 0.454328\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009444; batch adversarial loss: 0.431346\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023687; batch adversarial loss: 0.431605\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008823; batch adversarial loss: 0.516046\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011997; batch adversarial loss: 0.436208\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013542; batch adversarial loss: 0.355707\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019788; batch adversarial loss: 0.441854\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041840; batch adversarial loss: 0.384934\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016308; batch adversarial loss: 0.446470\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.441313\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028472; batch adversarial loss: 0.520402\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016164; batch adversarial loss: 0.428206\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024151; batch adversarial loss: 0.519385\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020464; batch adversarial loss: 0.478392\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014764; batch adversarial loss: 0.475194\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660175; batch adversarial loss: 0.646027\n",
      "epoch 1; iter: 0; batch classifier loss: 0.358346; batch adversarial loss: 0.627088\n",
      "epoch 2; iter: 0; batch classifier loss: 0.247844; batch adversarial loss: 0.612339\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400478; batch adversarial loss: 0.608220\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320580; batch adversarial loss: 0.564199\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415570; batch adversarial loss: 0.564030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345994; batch adversarial loss: 0.557730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.263456; batch adversarial loss: 0.552841\n",
      "epoch 8; iter: 0; batch classifier loss: 0.383234; batch adversarial loss: 0.558994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381138; batch adversarial loss: 0.519802\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433940; batch adversarial loss: 0.551175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326088; batch adversarial loss: 0.462471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503698; batch adversarial loss: 0.531311\n",
      "epoch 13; iter: 0; batch classifier loss: 0.654454; batch adversarial loss: 0.532503\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469784; batch adversarial loss: 0.534280\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381537; batch adversarial loss: 0.480474\n",
      "epoch 16; iter: 0; batch classifier loss: 0.326334; batch adversarial loss: 0.488703\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340529; batch adversarial loss: 0.478953\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282594; batch adversarial loss: 0.415216\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236988; batch adversarial loss: 0.514417\n",
      "epoch 20; iter: 0; batch classifier loss: 0.205083; batch adversarial loss: 0.429882\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258990; batch adversarial loss: 0.520015\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244861; batch adversarial loss: 0.459788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236760; batch adversarial loss: 0.400363\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248524; batch adversarial loss: 0.404256\n",
      "epoch 25; iter: 0; batch classifier loss: 0.243111; batch adversarial loss: 0.475900\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275861; batch adversarial loss: 0.457261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229566; batch adversarial loss: 0.578086\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195341; batch adversarial loss: 0.495816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.238331; batch adversarial loss: 0.408576\n",
      "epoch 30; iter: 0; batch classifier loss: 0.231193; batch adversarial loss: 0.480509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174311; batch adversarial loss: 0.454417\n",
      "epoch 32; iter: 0; batch classifier loss: 0.177486; batch adversarial loss: 0.494067\n",
      "epoch 33; iter: 0; batch classifier loss: 0.173335; batch adversarial loss: 0.458343\n",
      "epoch 34; iter: 0; batch classifier loss: 0.230715; batch adversarial loss: 0.413938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171424; batch adversarial loss: 0.447323\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123883; batch adversarial loss: 0.485968\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194517; batch adversarial loss: 0.424110\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164289; batch adversarial loss: 0.394892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138497; batch adversarial loss: 0.469483\n",
      "epoch 40; iter: 0; batch classifier loss: 0.197620; batch adversarial loss: 0.419893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.221422; batch adversarial loss: 0.421530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.225608; batch adversarial loss: 0.428892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159403; batch adversarial loss: 0.508211\n",
      "epoch 44; iter: 0; batch classifier loss: 0.183070; batch adversarial loss: 0.442897\n",
      "epoch 45; iter: 0; batch classifier loss: 0.214818; batch adversarial loss: 0.505897\n",
      "epoch 46; iter: 0; batch classifier loss: 0.134553; batch adversarial loss: 0.508703\n",
      "epoch 47; iter: 0; batch classifier loss: 0.171911; batch adversarial loss: 0.339016\n",
      "epoch 48; iter: 0; batch classifier loss: 0.155816; batch adversarial loss: 0.409728\n",
      "epoch 49; iter: 0; batch classifier loss: 0.168002; batch adversarial loss: 0.484391\n",
      "epoch 50; iter: 0; batch classifier loss: 0.160695; batch adversarial loss: 0.549463\n",
      "epoch 51; iter: 0; batch classifier loss: 0.221490; batch adversarial loss: 0.459976\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154440; batch adversarial loss: 0.481824\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137322; batch adversarial loss: 0.445288\n",
      "epoch 54; iter: 0; batch classifier loss: 0.177661; batch adversarial loss: 0.458541\n",
      "epoch 55; iter: 0; batch classifier loss: 0.140147; batch adversarial loss: 0.461449\n",
      "epoch 56; iter: 0; batch classifier loss: 0.126902; batch adversarial loss: 0.446731\n",
      "epoch 57; iter: 0; batch classifier loss: 0.196931; batch adversarial loss: 0.384913\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135077; batch adversarial loss: 0.495398\n",
      "epoch 59; iter: 0; batch classifier loss: 0.174664; batch adversarial loss: 0.408941\n",
      "epoch 60; iter: 0; batch classifier loss: 0.201747; batch adversarial loss: 0.472679\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167058; batch adversarial loss: 0.447117\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179056; batch adversarial loss: 0.485044\n",
      "epoch 63; iter: 0; batch classifier loss: 0.183695; batch adversarial loss: 0.470136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.197925; batch adversarial loss: 0.433529\n",
      "epoch 65; iter: 0; batch classifier loss: 0.196858; batch adversarial loss: 0.370223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.173312; batch adversarial loss: 0.433557\n",
      "epoch 67; iter: 0; batch classifier loss: 0.112539; batch adversarial loss: 0.383368\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068372; batch adversarial loss: 0.482755\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092188; batch adversarial loss: 0.471726\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075359; batch adversarial loss: 0.357459\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073549; batch adversarial loss: 0.433888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.069833; batch adversarial loss: 0.505873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062637; batch adversarial loss: 0.424729\n",
      "epoch 74; iter: 0; batch classifier loss: 0.091063; batch adversarial loss: 0.482838\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158860; batch adversarial loss: 0.511469\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069862; batch adversarial loss: 0.396064\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126720; batch adversarial loss: 0.481661\n",
      "epoch 78; iter: 0; batch classifier loss: 0.076017; batch adversarial loss: 0.381593\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064479; batch adversarial loss: 0.446298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.050239; batch adversarial loss: 0.415772\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096428; batch adversarial loss: 0.470537\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085529; batch adversarial loss: 0.380029\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074838; batch adversarial loss: 0.451746\n",
      "epoch 84; iter: 0; batch classifier loss: 0.094368; batch adversarial loss: 0.431583\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078274; batch adversarial loss: 0.407491\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058658; batch adversarial loss: 0.427285\n",
      "epoch 87; iter: 0; batch classifier loss: 0.065028; batch adversarial loss: 0.427389\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082793; batch adversarial loss: 0.420251\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087501; batch adversarial loss: 0.428070\n",
      "epoch 90; iter: 0; batch classifier loss: 0.039735; batch adversarial loss: 0.523721\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061760; batch adversarial loss: 0.558312\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059523; batch adversarial loss: 0.477927\n",
      "epoch 93; iter: 0; batch classifier loss: 0.104571; batch adversarial loss: 0.434882\n",
      "epoch 94; iter: 0; batch classifier loss: 0.103221; batch adversarial loss: 0.317358\n",
      "epoch 95; iter: 0; batch classifier loss: 0.050594; batch adversarial loss: 0.586911\n",
      "epoch 96; iter: 0; batch classifier loss: 0.025707; batch adversarial loss: 0.479369\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089088; batch adversarial loss: 0.411486\n",
      "epoch 98; iter: 0; batch classifier loss: 0.075088; batch adversarial loss: 0.522377\n",
      "epoch 99; iter: 0; batch classifier loss: 0.083907; batch adversarial loss: 0.470233\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049716; batch adversarial loss: 0.509303\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083948; batch adversarial loss: 0.380290\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054482; batch adversarial loss: 0.370836\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061740; batch adversarial loss: 0.369352\n",
      "epoch 104; iter: 0; batch classifier loss: 0.034829; batch adversarial loss: 0.336841\n",
      "epoch 105; iter: 0; batch classifier loss: 0.038247; batch adversarial loss: 0.481581\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045508; batch adversarial loss: 0.377672\n",
      "epoch 107; iter: 0; batch classifier loss: 0.043208; batch adversarial loss: 0.510202\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076787; batch adversarial loss: 0.469031\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063028; batch adversarial loss: 0.484826\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035560; batch adversarial loss: 0.558954\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067041; batch adversarial loss: 0.479390\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040819; batch adversarial loss: 0.395271\n",
      "epoch 113; iter: 0; batch classifier loss: 0.048351; batch adversarial loss: 0.335152\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020106; batch adversarial loss: 0.480916\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048535; batch adversarial loss: 0.349860\n",
      "epoch 116; iter: 0; batch classifier loss: 0.046078; batch adversarial loss: 0.533918\n",
      "epoch 117; iter: 0; batch classifier loss: 0.070102; batch adversarial loss: 0.474657\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029576; batch adversarial loss: 0.583180\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065148; batch adversarial loss: 0.494827\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033277; batch adversarial loss: 0.370660\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024076; batch adversarial loss: 0.521659\n",
      "epoch 122; iter: 0; batch classifier loss: 0.014770; batch adversarial loss: 0.442713\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056160; batch adversarial loss: 0.467521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024661; batch adversarial loss: 0.452250\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027726; batch adversarial loss: 0.487727\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031589; batch adversarial loss: 0.463959\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039711; batch adversarial loss: 0.452992\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035601; batch adversarial loss: 0.451349\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036440; batch adversarial loss: 0.399864\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045257; batch adversarial loss: 0.518440\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015440; batch adversarial loss: 0.437424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024448; batch adversarial loss: 0.457775\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036644; batch adversarial loss: 0.348723\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020197; batch adversarial loss: 0.494741\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014583; batch adversarial loss: 0.438367\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035701; batch adversarial loss: 0.397587\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033210; batch adversarial loss: 0.483984\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040065; batch adversarial loss: 0.414599\n",
      "epoch 139; iter: 0; batch classifier loss: 0.058101; batch adversarial loss: 0.451019\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017797; batch adversarial loss: 0.437112\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039997; batch adversarial loss: 0.377854\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022869; batch adversarial loss: 0.395784\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040368; batch adversarial loss: 0.450465\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038516; batch adversarial loss: 0.432490\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052913; batch adversarial loss: 0.359783\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037629; batch adversarial loss: 0.366093\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018593; batch adversarial loss: 0.465505\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011613; batch adversarial loss: 0.451814\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012279; batch adversarial loss: 0.534916\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016074; batch adversarial loss: 0.456372\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027111; batch adversarial loss: 0.530293\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030803; batch adversarial loss: 0.387667\n",
      "epoch 153; iter: 0; batch classifier loss: 0.045404; batch adversarial loss: 0.391254\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032682; batch adversarial loss: 0.464850\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026996; batch adversarial loss: 0.473394\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043737; batch adversarial loss: 0.504737\n",
      "epoch 157; iter: 0; batch classifier loss: 0.042091; batch adversarial loss: 0.422489\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014452; batch adversarial loss: 0.529220\n",
      "epoch 159; iter: 0; batch classifier loss: 0.009880; batch adversarial loss: 0.537748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.039998; batch adversarial loss: 0.342641\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023781; batch adversarial loss: 0.433998\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026714; batch adversarial loss: 0.439817\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011835; batch adversarial loss: 0.439089\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011470; batch adversarial loss: 0.473167\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018946; batch adversarial loss: 0.435272\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023785; batch adversarial loss: 0.362644\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017458; batch adversarial loss: 0.445088\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018371; batch adversarial loss: 0.424944\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014348; batch adversarial loss: 0.367696\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013785; batch adversarial loss: 0.426984\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020930; batch adversarial loss: 0.395141\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015902; batch adversarial loss: 0.544099\n",
      "epoch 173; iter: 0; batch classifier loss: 0.022597; batch adversarial loss: 0.376700\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033421; batch adversarial loss: 0.510854\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033493; batch adversarial loss: 0.450491\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012511; batch adversarial loss: 0.411986\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022745; batch adversarial loss: 0.426645\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025770; batch adversarial loss: 0.432709\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009331; batch adversarial loss: 0.409083\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019367; batch adversarial loss: 0.399956\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026200; batch adversarial loss: 0.420930\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009916; batch adversarial loss: 0.426518\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031319; batch adversarial loss: 0.470837\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010482; batch adversarial loss: 0.472353\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013381; batch adversarial loss: 0.438114\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016779; batch adversarial loss: 0.523713\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015351; batch adversarial loss: 0.414381\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033193; batch adversarial loss: 0.382044\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010135; batch adversarial loss: 0.489058\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028301; batch adversarial loss: 0.452344\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028716; batch adversarial loss: 0.461319\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029867; batch adversarial loss: 0.381421\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031670; batch adversarial loss: 0.390804\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009484; batch adversarial loss: 0.339222\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007327; batch adversarial loss: 0.533357\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005297; batch adversarial loss: 0.454459\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024712; batch adversarial loss: 0.461903\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011348; batch adversarial loss: 0.390006\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014518; batch adversarial loss: 0.438857\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685121; batch adversarial loss: 0.872038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.529328; batch adversarial loss: 0.834893\n",
      "epoch 2; iter: 0; batch classifier loss: 0.819731; batch adversarial loss: 0.856869\n",
      "epoch 3; iter: 0; batch classifier loss: 0.833774; batch adversarial loss: 0.774818\n",
      "epoch 4; iter: 0; batch classifier loss: 0.760983; batch adversarial loss: 0.689077\n",
      "epoch 5; iter: 0; batch classifier loss: 0.654785; batch adversarial loss: 0.640151\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562422; batch adversarial loss: 0.606311\n",
      "epoch 7; iter: 0; batch classifier loss: 0.397836; batch adversarial loss: 0.566921\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317326; batch adversarial loss: 0.544069\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328278; batch adversarial loss: 0.549866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288954; batch adversarial loss: 0.556321\n",
      "epoch 11; iter: 0; batch classifier loss: 0.318304; batch adversarial loss: 0.546102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.237237; batch adversarial loss: 0.490518\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252621; batch adversarial loss: 0.502116\n",
      "epoch 14; iter: 0; batch classifier loss: 0.201956; batch adversarial loss: 0.498809\n",
      "epoch 15; iter: 0; batch classifier loss: 0.251387; batch adversarial loss: 0.459594\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233507; batch adversarial loss: 0.431817\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232316; batch adversarial loss: 0.511229\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228609; batch adversarial loss: 0.548138\n",
      "epoch 19; iter: 0; batch classifier loss: 0.189180; batch adversarial loss: 0.489043\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217876; batch adversarial loss: 0.456464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219111; batch adversarial loss: 0.517480\n",
      "epoch 22; iter: 0; batch classifier loss: 0.120912; batch adversarial loss: 0.383292\n",
      "epoch 23; iter: 0; batch classifier loss: 0.195786; batch adversarial loss: 0.491835\n",
      "epoch 24; iter: 0; batch classifier loss: 0.225455; batch adversarial loss: 0.491985\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141780; batch adversarial loss: 0.526668\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180704; batch adversarial loss: 0.497996\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188743; batch adversarial loss: 0.496761\n",
      "epoch 28; iter: 0; batch classifier loss: 0.177933; batch adversarial loss: 0.541026\n",
      "epoch 29; iter: 0; batch classifier loss: 0.132034; batch adversarial loss: 0.485381\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162386; batch adversarial loss: 0.445225\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157538; batch adversarial loss: 0.464559\n",
      "epoch 32; iter: 0; batch classifier loss: 0.094300; batch adversarial loss: 0.482434\n",
      "epoch 33; iter: 0; batch classifier loss: 0.093420; batch adversarial loss: 0.460905\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120136; batch adversarial loss: 0.456361\n",
      "epoch 35; iter: 0; batch classifier loss: 0.132564; batch adversarial loss: 0.358059\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120261; batch adversarial loss: 0.472204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134491; batch adversarial loss: 0.402285\n",
      "epoch 38; iter: 0; batch classifier loss: 0.124216; batch adversarial loss: 0.455416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.075612; batch adversarial loss: 0.523813\n",
      "epoch 40; iter: 0; batch classifier loss: 0.144396; batch adversarial loss: 0.524575\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137124; batch adversarial loss: 0.489028\n",
      "epoch 42; iter: 0; batch classifier loss: 0.075944; batch adversarial loss: 0.438616\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096880; batch adversarial loss: 0.454737\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098947; batch adversarial loss: 0.490781\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080835; batch adversarial loss: 0.543728\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104389; batch adversarial loss: 0.380356\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101133; batch adversarial loss: 0.437169\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101891; batch adversarial loss: 0.592617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.081318; batch adversarial loss: 0.413935\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084770; batch adversarial loss: 0.430753\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107603; batch adversarial loss: 0.386750\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089312; batch adversarial loss: 0.523146\n",
      "epoch 53; iter: 0; batch classifier loss: 0.041909; batch adversarial loss: 0.488011\n",
      "epoch 54; iter: 0; batch classifier loss: 0.109309; batch adversarial loss: 0.509483\n",
      "epoch 55; iter: 0; batch classifier loss: 0.078872; batch adversarial loss: 0.398970\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065384; batch adversarial loss: 0.418766\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084969; batch adversarial loss: 0.443277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.085771; batch adversarial loss: 0.473178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070431; batch adversarial loss: 0.449016\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095596; batch adversarial loss: 0.489316\n",
      "epoch 61; iter: 0; batch classifier loss: 0.101094; batch adversarial loss: 0.410059\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085708; batch adversarial loss: 0.468012\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076068; batch adversarial loss: 0.437583\n",
      "epoch 64; iter: 0; batch classifier loss: 0.062320; batch adversarial loss: 0.435665\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118400; batch adversarial loss: 0.451446\n",
      "epoch 66; iter: 0; batch classifier loss: 0.086162; batch adversarial loss: 0.483137\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067068; batch adversarial loss: 0.486416\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050456; batch adversarial loss: 0.499798\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078599; batch adversarial loss: 0.448814\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071207; batch adversarial loss: 0.443846\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050451; batch adversarial loss: 0.387401\n",
      "epoch 72; iter: 0; batch classifier loss: 0.116574; batch adversarial loss: 0.422161\n",
      "epoch 73; iter: 0; batch classifier loss: 0.128284; batch adversarial loss: 0.452864\n",
      "epoch 74; iter: 0; batch classifier loss: 0.056632; batch adversarial loss: 0.432696\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055398; batch adversarial loss: 0.374142\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061950; batch adversarial loss: 0.498119\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091734; batch adversarial loss: 0.556686\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097094; batch adversarial loss: 0.448974\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094840; batch adversarial loss: 0.518255\n",
      "epoch 80; iter: 0; batch classifier loss: 0.060725; batch adversarial loss: 0.515990\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041369; batch adversarial loss: 0.425495\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071490; batch adversarial loss: 0.481468\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092640; batch adversarial loss: 0.521044\n",
      "epoch 84; iter: 0; batch classifier loss: 0.100013; batch adversarial loss: 0.453005\n",
      "epoch 85; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.510844\n",
      "epoch 86; iter: 0; batch classifier loss: 0.077610; batch adversarial loss: 0.536093\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055072; batch adversarial loss: 0.410639\n",
      "epoch 88; iter: 0; batch classifier loss: 0.033467; batch adversarial loss: 0.410315\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053885; batch adversarial loss: 0.400521\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041828; batch adversarial loss: 0.489629\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068689; batch adversarial loss: 0.366561\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041451; batch adversarial loss: 0.428784\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054156; batch adversarial loss: 0.404684\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039141; batch adversarial loss: 0.439879\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035638; batch adversarial loss: 0.465424\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036801; batch adversarial loss: 0.478838\n",
      "epoch 97; iter: 0; batch classifier loss: 0.028833; batch adversarial loss: 0.413049\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042976; batch adversarial loss: 0.392414\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049525; batch adversarial loss: 0.500296\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037423; batch adversarial loss: 0.474570\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051548; batch adversarial loss: 0.376847\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074077; batch adversarial loss: 0.435899\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059531; batch adversarial loss: 0.414319\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055712; batch adversarial loss: 0.459424\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053127; batch adversarial loss: 0.420269\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041762; batch adversarial loss: 0.385901\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057741; batch adversarial loss: 0.515755\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055235; batch adversarial loss: 0.363232\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037344; batch adversarial loss: 0.464688\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057436; batch adversarial loss: 0.441933\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062916; batch adversarial loss: 0.456291\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048953; batch adversarial loss: 0.557230\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051238; batch adversarial loss: 0.438775\n",
      "epoch 114; iter: 0; batch classifier loss: 0.091351; batch adversarial loss: 0.446378\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040384; batch adversarial loss: 0.561218\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041146; batch adversarial loss: 0.431569\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043103; batch adversarial loss: 0.463151\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037021; batch adversarial loss: 0.438226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065355; batch adversarial loss: 0.494847\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026437; batch adversarial loss: 0.482310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031293; batch adversarial loss: 0.431927\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023057; batch adversarial loss: 0.528801\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027236; batch adversarial loss: 0.396281\n",
      "epoch 124; iter: 0; batch classifier loss: 0.105844; batch adversarial loss: 0.495653\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057772; batch adversarial loss: 0.402371\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031623; batch adversarial loss: 0.463841\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021796; batch adversarial loss: 0.397081\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020294; batch adversarial loss: 0.366683\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047695; batch adversarial loss: 0.496035\n",
      "epoch 130; iter: 0; batch classifier loss: 0.023093; batch adversarial loss: 0.460667\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037999; batch adversarial loss: 0.463326\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044892; batch adversarial loss: 0.501640\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051275; batch adversarial loss: 0.409777\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013066; batch adversarial loss: 0.386534\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.372332\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037653; batch adversarial loss: 0.455507\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032365; batch adversarial loss: 0.406766\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038477; batch adversarial loss: 0.423652\n",
      "epoch 139; iter: 0; batch classifier loss: 0.027383; batch adversarial loss: 0.474928\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048512; batch adversarial loss: 0.415074\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050061; batch adversarial loss: 0.446612\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039549; batch adversarial loss: 0.440288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.006779; batch adversarial loss: 0.531265\n",
      "epoch 144; iter: 0; batch classifier loss: 0.018498; batch adversarial loss: 0.495377\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032691; batch adversarial loss: 0.469678\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044184; batch adversarial loss: 0.406272\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031229; batch adversarial loss: 0.432967\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027564; batch adversarial loss: 0.480227\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020562; batch adversarial loss: 0.485244\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018250; batch adversarial loss: 0.350513\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019326; batch adversarial loss: 0.418925\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.506782\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029926; batch adversarial loss: 0.480950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.054929; batch adversarial loss: 0.436249\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035378; batch adversarial loss: 0.366827\n",
      "epoch 156; iter: 0; batch classifier loss: 0.091019; batch adversarial loss: 0.286251\n",
      "epoch 157; iter: 0; batch classifier loss: 0.033254; batch adversarial loss: 0.389385\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018394; batch adversarial loss: 0.369000\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007647; batch adversarial loss: 0.437491\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014650; batch adversarial loss: 0.427501\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017779; batch adversarial loss: 0.425553\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011026; batch adversarial loss: 0.556203\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018658; batch adversarial loss: 0.397255\n",
      "epoch 164; iter: 0; batch classifier loss: 0.005800; batch adversarial loss: 0.424063\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024241; batch adversarial loss: 0.458805\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018516; batch adversarial loss: 0.361116\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012794; batch adversarial loss: 0.503315\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033924; batch adversarial loss: 0.405431\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025534; batch adversarial loss: 0.602667\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035009; batch adversarial loss: 0.579458\n",
      "epoch 171; iter: 0; batch classifier loss: 0.045785; batch adversarial loss: 0.441854\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006610; batch adversarial loss: 0.381907\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035462; batch adversarial loss: 0.457489\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018375; batch adversarial loss: 0.501428\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.486552\n",
      "epoch 176; iter: 0; batch classifier loss: 0.038857; batch adversarial loss: 0.469714\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049125; batch adversarial loss: 0.413837\n",
      "epoch 178; iter: 0; batch classifier loss: 0.009949; batch adversarial loss: 0.439171\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039505; batch adversarial loss: 0.458162\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023312; batch adversarial loss: 0.437391\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013747; batch adversarial loss: 0.552638\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017484; batch adversarial loss: 0.402109\n",
      "epoch 183; iter: 0; batch classifier loss: 0.037985; batch adversarial loss: 0.549954\n",
      "epoch 184; iter: 0; batch classifier loss: 0.003493; batch adversarial loss: 0.532364\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021713; batch adversarial loss: 0.406035\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027303; batch adversarial loss: 0.414547\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.442391\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024112; batch adversarial loss: 0.477184\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010313; batch adversarial loss: 0.542276\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007816; batch adversarial loss: 0.568466\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.475832\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016811; batch adversarial loss: 0.420655\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019718; batch adversarial loss: 0.487754\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021486; batch adversarial loss: 0.442878\n",
      "epoch 195; iter: 0; batch classifier loss: 0.063184; batch adversarial loss: 0.471615\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.498063\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033441; batch adversarial loss: 0.512097\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.479279\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007905; batch adversarial loss: 0.386664\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725223; batch adversarial loss: 0.794462\n",
      "epoch 1; iter: 0; batch classifier loss: 0.559075; batch adversarial loss: 0.730758\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621140; batch adversarial loss: 0.708485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648152; batch adversarial loss: 0.659108\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362865; batch adversarial loss: 0.594387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366112; batch adversarial loss: 0.568206\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414183; batch adversarial loss: 0.584695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.363354; batch adversarial loss: 0.568050\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354972; batch adversarial loss: 0.542366\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342393; batch adversarial loss: 0.506115\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460104; batch adversarial loss: 0.481434\n",
      "epoch 11; iter: 0; batch classifier loss: 0.355892; batch adversarial loss: 0.553603\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307524; batch adversarial loss: 0.521571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438752; batch adversarial loss: 0.496155\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368198; batch adversarial loss: 0.547663\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302769; batch adversarial loss: 0.498828\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235524; batch adversarial loss: 0.513434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.279842; batch adversarial loss: 0.526913\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255390; batch adversarial loss: 0.586321\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248750; batch adversarial loss: 0.476164\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278232; batch adversarial loss: 0.576259\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292199; batch adversarial loss: 0.440413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.198239; batch adversarial loss: 0.427997\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310966; batch adversarial loss: 0.516139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320372; batch adversarial loss: 0.479740\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272180; batch adversarial loss: 0.440678\n",
      "epoch 26; iter: 0; batch classifier loss: 0.245063; batch adversarial loss: 0.412752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243700; batch adversarial loss: 0.445358\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183391; batch adversarial loss: 0.381950\n",
      "epoch 29; iter: 0; batch classifier loss: 0.205376; batch adversarial loss: 0.479338\n",
      "epoch 30; iter: 0; batch classifier loss: 0.242559; batch adversarial loss: 0.426498\n",
      "epoch 31; iter: 0; batch classifier loss: 0.212161; batch adversarial loss: 0.358741\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186516; batch adversarial loss: 0.472182\n",
      "epoch 33; iter: 0; batch classifier loss: 0.198168; batch adversarial loss: 0.445638\n",
      "epoch 34; iter: 0; batch classifier loss: 0.241028; batch adversarial loss: 0.492432\n",
      "epoch 35; iter: 0; batch classifier loss: 0.201390; batch adversarial loss: 0.461490\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203463; batch adversarial loss: 0.436646\n",
      "epoch 37; iter: 0; batch classifier loss: 0.174814; batch adversarial loss: 0.430135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198109; batch adversarial loss: 0.512063\n",
      "epoch 39; iter: 0; batch classifier loss: 0.143515; batch adversarial loss: 0.452752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.119598; batch adversarial loss: 0.449583\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174546; batch adversarial loss: 0.428681\n",
      "epoch 42; iter: 0; batch classifier loss: 0.165183; batch adversarial loss: 0.423474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149852; batch adversarial loss: 0.515075\n",
      "epoch 44; iter: 0; batch classifier loss: 0.136167; batch adversarial loss: 0.435617\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098938; batch adversarial loss: 0.442783\n",
      "epoch 46; iter: 0; batch classifier loss: 0.139787; batch adversarial loss: 0.486269\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099202; batch adversarial loss: 0.494018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.075016; batch adversarial loss: 0.456602\n",
      "epoch 49; iter: 0; batch classifier loss: 0.095974; batch adversarial loss: 0.383501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.092450; batch adversarial loss: 0.432705\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086252; batch adversarial loss: 0.433441\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074518; batch adversarial loss: 0.430996\n",
      "epoch 53; iter: 0; batch classifier loss: 0.114999; batch adversarial loss: 0.422468\n",
      "epoch 54; iter: 0; batch classifier loss: 0.051982; batch adversarial loss: 0.468605\n",
      "epoch 55; iter: 0; batch classifier loss: 0.129465; batch adversarial loss: 0.419221\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073668; batch adversarial loss: 0.460162\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113020; batch adversarial loss: 0.471936\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112169; batch adversarial loss: 0.411549\n",
      "epoch 59; iter: 0; batch classifier loss: 0.061835; batch adversarial loss: 0.448246\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096489; batch adversarial loss: 0.529375\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075511; batch adversarial loss: 0.419184\n",
      "epoch 62; iter: 0; batch classifier loss: 0.055672; batch adversarial loss: 0.482864\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059447; batch adversarial loss: 0.359052\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072005; batch adversarial loss: 0.430321\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070669; batch adversarial loss: 0.581714\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057836; batch adversarial loss: 0.436855\n",
      "epoch 67; iter: 0; batch classifier loss: 0.116348; batch adversarial loss: 0.415863\n",
      "epoch 68; iter: 0; batch classifier loss: 0.048529; batch adversarial loss: 0.444612\n",
      "epoch 69; iter: 0; batch classifier loss: 0.045909; batch adversarial loss: 0.438731\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108365; batch adversarial loss: 0.473309\n",
      "epoch 71; iter: 0; batch classifier loss: 0.054567; batch adversarial loss: 0.471318\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047559; batch adversarial loss: 0.399462\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055170; batch adversarial loss: 0.377811\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068230; batch adversarial loss: 0.413814\n",
      "epoch 75; iter: 0; batch classifier loss: 0.030962; batch adversarial loss: 0.508351\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052499; batch adversarial loss: 0.474340\n",
      "epoch 77; iter: 0; batch classifier loss: 0.074322; batch adversarial loss: 0.541852\n",
      "epoch 78; iter: 0; batch classifier loss: 0.042689; batch adversarial loss: 0.442107\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062935; batch adversarial loss: 0.522784\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054679; batch adversarial loss: 0.406664\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069226; batch adversarial loss: 0.365743\n",
      "epoch 82; iter: 0; batch classifier loss: 0.035375; batch adversarial loss: 0.484008\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061019; batch adversarial loss: 0.465379\n",
      "epoch 84; iter: 0; batch classifier loss: 0.041750; batch adversarial loss: 0.456639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.494983\n",
      "epoch 86; iter: 0; batch classifier loss: 0.058745; batch adversarial loss: 0.491169\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049382; batch adversarial loss: 0.468267\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051763; batch adversarial loss: 0.433352\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092184; batch adversarial loss: 0.417635\n",
      "epoch 90; iter: 0; batch classifier loss: 0.027447; batch adversarial loss: 0.398533\n",
      "epoch 91; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.472475\n",
      "epoch 92; iter: 0; batch classifier loss: 0.034992; batch adversarial loss: 0.572285\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052746; batch adversarial loss: 0.344274\n",
      "epoch 94; iter: 0; batch classifier loss: 0.020135; batch adversarial loss: 0.459260\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066067; batch adversarial loss: 0.457527\n",
      "epoch 96; iter: 0; batch classifier loss: 0.027260; batch adversarial loss: 0.550803\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047408; batch adversarial loss: 0.364463\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056642; batch adversarial loss: 0.456850\n",
      "epoch 99; iter: 0; batch classifier loss: 0.018522; batch adversarial loss: 0.466048\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069821; batch adversarial loss: 0.512716\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053363; batch adversarial loss: 0.464338\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035348; batch adversarial loss: 0.413742\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041786; batch adversarial loss: 0.410496\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053493; batch adversarial loss: 0.519420\n",
      "epoch 105; iter: 0; batch classifier loss: 0.024719; batch adversarial loss: 0.443387\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047869; batch adversarial loss: 0.456821\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038670; batch adversarial loss: 0.451136\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024096; batch adversarial loss: 0.557459\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071992; batch adversarial loss: 0.466526\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028786; batch adversarial loss: 0.417087\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018727; batch adversarial loss: 0.453160\n",
      "epoch 112; iter: 0; batch classifier loss: 0.015869; batch adversarial loss: 0.444442\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025185; batch adversarial loss: 0.377292\n",
      "epoch 114; iter: 0; batch classifier loss: 0.061782; batch adversarial loss: 0.440791\n",
      "epoch 115; iter: 0; batch classifier loss: 0.019631; batch adversarial loss: 0.463383\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055157; batch adversarial loss: 0.527050\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026171; batch adversarial loss: 0.392645\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030842; batch adversarial loss: 0.384301\n",
      "epoch 119; iter: 0; batch classifier loss: 0.016703; batch adversarial loss: 0.480389\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022527; batch adversarial loss: 0.389939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.024139; batch adversarial loss: 0.587828\n",
      "epoch 122; iter: 0; batch classifier loss: 0.044680; batch adversarial loss: 0.535034\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025944; batch adversarial loss: 0.475243\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012089; batch adversarial loss: 0.426493\n",
      "epoch 125; iter: 0; batch classifier loss: 0.014597; batch adversarial loss: 0.370589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.032238; batch adversarial loss: 0.403235\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024424; batch adversarial loss: 0.378248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.575367\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026629; batch adversarial loss: 0.449811\n",
      "epoch 130; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.548167\n",
      "epoch 131; iter: 0; batch classifier loss: 0.012154; batch adversarial loss: 0.458051\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025401; batch adversarial loss: 0.428722\n",
      "epoch 133; iter: 0; batch classifier loss: 0.007761; batch adversarial loss: 0.505531\n",
      "epoch 134; iter: 0; batch classifier loss: 0.015125; batch adversarial loss: 0.401962\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029773; batch adversarial loss: 0.430837\n",
      "epoch 136; iter: 0; batch classifier loss: 0.008455; batch adversarial loss: 0.471818\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045185; batch adversarial loss: 0.483973\n",
      "epoch 138; iter: 0; batch classifier loss: 0.017129; batch adversarial loss: 0.417602\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026384; batch adversarial loss: 0.498013\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042146; batch adversarial loss: 0.464012\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021336; batch adversarial loss: 0.405769\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013401; batch adversarial loss: 0.379595\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013541; batch adversarial loss: 0.415904\n",
      "epoch 144; iter: 0; batch classifier loss: 0.013285; batch adversarial loss: 0.401166\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022380; batch adversarial loss: 0.421455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.038293; batch adversarial loss: 0.469526\n",
      "epoch 147; iter: 0; batch classifier loss: 0.009057; batch adversarial loss: 0.484463\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022480; batch adversarial loss: 0.353912\n",
      "epoch 149; iter: 0; batch classifier loss: 0.005451; batch adversarial loss: 0.456636\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030190; batch adversarial loss: 0.435501\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012225; batch adversarial loss: 0.474647\n",
      "epoch 152; iter: 0; batch classifier loss: 0.057540; batch adversarial loss: 0.361835\n",
      "epoch 153; iter: 0; batch classifier loss: 0.007807; batch adversarial loss: 0.475572\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021383; batch adversarial loss: 0.399283\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012693; batch adversarial loss: 0.501658\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030369; batch adversarial loss: 0.506165\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028559; batch adversarial loss: 0.511237\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026075; batch adversarial loss: 0.378896\n",
      "epoch 159; iter: 0; batch classifier loss: 0.010326; batch adversarial loss: 0.431288\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014402; batch adversarial loss: 0.509607\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034022; batch adversarial loss: 0.470916\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039951; batch adversarial loss: 0.468793\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025463; batch adversarial loss: 0.392349\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030252; batch adversarial loss: 0.542251\n",
      "epoch 165; iter: 0; batch classifier loss: 0.049852; batch adversarial loss: 0.445437\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011706; batch adversarial loss: 0.503537\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015035; batch adversarial loss: 0.432611\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023368; batch adversarial loss: 0.391442\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037740; batch adversarial loss: 0.426409\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017885; batch adversarial loss: 0.540218\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021619; batch adversarial loss: 0.432774\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032475; batch adversarial loss: 0.452426\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043012; batch adversarial loss: 0.489630\n",
      "epoch 174; iter: 0; batch classifier loss: 0.002872; batch adversarial loss: 0.388249\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007385; batch adversarial loss: 0.459610\n",
      "epoch 176; iter: 0; batch classifier loss: 0.020753; batch adversarial loss: 0.462732\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017664; batch adversarial loss: 0.508503\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026586; batch adversarial loss: 0.403514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036635; batch adversarial loss: 0.480479\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014683; batch adversarial loss: 0.493519\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009400; batch adversarial loss: 0.432785\n",
      "epoch 182; iter: 0; batch classifier loss: 0.005817; batch adversarial loss: 0.571230\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020807; batch adversarial loss: 0.387208\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011717; batch adversarial loss: 0.393915\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019910; batch adversarial loss: 0.388119\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016172; batch adversarial loss: 0.488029\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005620; batch adversarial loss: 0.531065\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028195; batch adversarial loss: 0.558385\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018701; batch adversarial loss: 0.490678\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024684; batch adversarial loss: 0.508081\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009175; batch adversarial loss: 0.473166\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013040; batch adversarial loss: 0.474426\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018749; batch adversarial loss: 0.411434\n",
      "epoch 194; iter: 0; batch classifier loss: 0.006466; batch adversarial loss: 0.362832\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009127; batch adversarial loss: 0.395296\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011594; batch adversarial loss: 0.473970\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008617; batch adversarial loss: 0.403157\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033001; batch adversarial loss: 0.429785\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019446; batch adversarial loss: 0.507166\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698601; batch adversarial loss: 0.740395\n",
      "epoch 1; iter: 0; batch classifier loss: 0.523130; batch adversarial loss: 0.675863\n",
      "epoch 2; iter: 0; batch classifier loss: 0.462294; batch adversarial loss: 0.648427\n",
      "epoch 3; iter: 0; batch classifier loss: 0.374419; batch adversarial loss: 0.636856\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407503; batch adversarial loss: 0.610647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379799; batch adversarial loss: 0.585613\n",
      "epoch 6; iter: 0; batch classifier loss: 0.367794; batch adversarial loss: 0.586401\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401030; batch adversarial loss: 0.551817\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417762; batch adversarial loss: 0.529946\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449004; batch adversarial loss: 0.540457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480984; batch adversarial loss: 0.532706\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372565; batch adversarial loss: 0.478323\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289077; batch adversarial loss: 0.521572\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425601; batch adversarial loss: 0.519878\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343151; batch adversarial loss: 0.485627\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376374; batch adversarial loss: 0.522776\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397789; batch adversarial loss: 0.517433\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387771; batch adversarial loss: 0.486560\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434489; batch adversarial loss: 0.535284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338172; batch adversarial loss: 0.440543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271420; batch adversarial loss: 0.420659\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330619; batch adversarial loss: 0.447273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264441; batch adversarial loss: 0.470482\n",
      "epoch 23; iter: 0; batch classifier loss: 0.299663; batch adversarial loss: 0.506965\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303388; batch adversarial loss: 0.556828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279702; batch adversarial loss: 0.508082\n",
      "epoch 26; iter: 0; batch classifier loss: 0.226105; batch adversarial loss: 0.539761\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256644; batch adversarial loss: 0.453399\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211126; batch adversarial loss: 0.458650\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179537; batch adversarial loss: 0.393303\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338975; batch adversarial loss: 0.406334\n",
      "epoch 31; iter: 0; batch classifier loss: 0.253277; batch adversarial loss: 0.449914\n",
      "epoch 32; iter: 0; batch classifier loss: 0.269372; batch adversarial loss: 0.450424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267557; batch adversarial loss: 0.415750\n",
      "epoch 34; iter: 0; batch classifier loss: 0.221459; batch adversarial loss: 0.478042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.176952; batch adversarial loss: 0.466156\n",
      "epoch 36; iter: 0; batch classifier loss: 0.244382; batch adversarial loss: 0.464005\n",
      "epoch 37; iter: 0; batch classifier loss: 0.278630; batch adversarial loss: 0.393201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.220486; batch adversarial loss: 0.400555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193885; batch adversarial loss: 0.463456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240348; batch adversarial loss: 0.521141\n",
      "epoch 41; iter: 0; batch classifier loss: 0.219337; batch adversarial loss: 0.472421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.192567; batch adversarial loss: 0.494154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.158992; batch adversarial loss: 0.520276\n",
      "epoch 44; iter: 0; batch classifier loss: 0.232397; batch adversarial loss: 0.363417\n",
      "epoch 45; iter: 0; batch classifier loss: 0.227310; batch adversarial loss: 0.412349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.186267; batch adversarial loss: 0.374876\n",
      "epoch 47; iter: 0; batch classifier loss: 0.195306; batch adversarial loss: 0.498253\n",
      "epoch 48; iter: 0; batch classifier loss: 0.187007; batch adversarial loss: 0.458057\n",
      "epoch 49; iter: 0; batch classifier loss: 0.235757; batch adversarial loss: 0.447422\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215732; batch adversarial loss: 0.491993\n",
      "epoch 51; iter: 0; batch classifier loss: 0.199327; batch adversarial loss: 0.435890\n",
      "epoch 52; iter: 0; batch classifier loss: 0.184685; batch adversarial loss: 0.447630\n",
      "epoch 53; iter: 0; batch classifier loss: 0.194683; batch adversarial loss: 0.446064\n",
      "epoch 54; iter: 0; batch classifier loss: 0.165769; batch adversarial loss: 0.498150\n",
      "epoch 55; iter: 0; batch classifier loss: 0.175550; batch adversarial loss: 0.334704\n",
      "epoch 56; iter: 0; batch classifier loss: 0.160373; batch adversarial loss: 0.483627\n",
      "epoch 57; iter: 0; batch classifier loss: 0.168726; batch adversarial loss: 0.371440\n",
      "epoch 58; iter: 0; batch classifier loss: 0.306697; batch adversarial loss: 0.396551\n",
      "epoch 59; iter: 0; batch classifier loss: 0.216637; batch adversarial loss: 0.471606\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130055; batch adversarial loss: 0.471468\n",
      "epoch 61; iter: 0; batch classifier loss: 0.165819; batch adversarial loss: 0.496280\n",
      "epoch 62; iter: 0; batch classifier loss: 0.248340; batch adversarial loss: 0.357734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.198001; batch adversarial loss: 0.407985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.134589; batch adversarial loss: 0.572617\n",
      "epoch 65; iter: 0; batch classifier loss: 0.203852; batch adversarial loss: 0.510296\n",
      "epoch 66; iter: 0; batch classifier loss: 0.258208; batch adversarial loss: 0.483684\n",
      "epoch 67; iter: 0; batch classifier loss: 0.158069; batch adversarial loss: 0.408381\n",
      "epoch 68; iter: 0; batch classifier loss: 0.269281; batch adversarial loss: 0.408747\n",
      "epoch 69; iter: 0; batch classifier loss: 0.218019; batch adversarial loss: 0.560333\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090513; batch adversarial loss: 0.457945\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082457; batch adversarial loss: 0.458032\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098398; batch adversarial loss: 0.456688\n",
      "epoch 73; iter: 0; batch classifier loss: 0.121682; batch adversarial loss: 0.471877\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088513; batch adversarial loss: 0.423285\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130929; batch adversarial loss: 0.471715\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083545; batch adversarial loss: 0.389337\n",
      "epoch 77; iter: 0; batch classifier loss: 0.149141; batch adversarial loss: 0.419902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052196; batch adversarial loss: 0.404724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.098333; batch adversarial loss: 0.408376\n",
      "epoch 80; iter: 0; batch classifier loss: 0.103899; batch adversarial loss: 0.420865\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073231; batch adversarial loss: 0.359468\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096829; batch adversarial loss: 0.417350\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091425; batch adversarial loss: 0.441011\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086617; batch adversarial loss: 0.412092\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071377; batch adversarial loss: 0.424272\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073614; batch adversarial loss: 0.413477\n",
      "epoch 87; iter: 0; batch classifier loss: 0.131819; batch adversarial loss: 0.495715\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058969; batch adversarial loss: 0.494283\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059449; batch adversarial loss: 0.493295\n",
      "epoch 90; iter: 0; batch classifier loss: 0.061095; batch adversarial loss: 0.594287\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073096; batch adversarial loss: 0.406522\n",
      "epoch 92; iter: 0; batch classifier loss: 0.061106; batch adversarial loss: 0.374325\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044027; batch adversarial loss: 0.481169\n",
      "epoch 94; iter: 0; batch classifier loss: 0.060176; batch adversarial loss: 0.403541\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043006; batch adversarial loss: 0.438582\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086091; batch adversarial loss: 0.456065\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037781; batch adversarial loss: 0.509487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045193; batch adversarial loss: 0.468293\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037976; batch adversarial loss: 0.424025\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028197; batch adversarial loss: 0.397653\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044883; batch adversarial loss: 0.350363\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051898; batch adversarial loss: 0.369792\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048520; batch adversarial loss: 0.485358\n",
      "epoch 104; iter: 0; batch classifier loss: 0.022266; batch adversarial loss: 0.469031\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047779; batch adversarial loss: 0.438279\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040830; batch adversarial loss: 0.419200\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021506; batch adversarial loss: 0.392849\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059230; batch adversarial loss: 0.476101\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070399; batch adversarial loss: 0.541149\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050211; batch adversarial loss: 0.437772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.372306\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052731; batch adversarial loss: 0.502546\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027085; batch adversarial loss: 0.404639\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022771; batch adversarial loss: 0.440939\n",
      "epoch 115; iter: 0; batch classifier loss: 0.011422; batch adversarial loss: 0.399506\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027715; batch adversarial loss: 0.372034\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017864; batch adversarial loss: 0.421314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060826; batch adversarial loss: 0.377564\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040442; batch adversarial loss: 0.338524\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.477513\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032650; batch adversarial loss: 0.420109\n",
      "epoch 122; iter: 0; batch classifier loss: 0.023001; batch adversarial loss: 0.379589\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048342; batch adversarial loss: 0.504646\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021113; batch adversarial loss: 0.453008\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035669; batch adversarial loss: 0.437784\n",
      "epoch 126; iter: 0; batch classifier loss: 0.043527; batch adversarial loss: 0.448327\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028359; batch adversarial loss: 0.418470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039621; batch adversarial loss: 0.419284\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027351; batch adversarial loss: 0.494012\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027787; batch adversarial loss: 0.444448\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038515; batch adversarial loss: 0.487662\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054986; batch adversarial loss: 0.407834\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031335; batch adversarial loss: 0.373254\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027682; batch adversarial loss: 0.493532\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020392; batch adversarial loss: 0.396723\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019241; batch adversarial loss: 0.435397\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041601; batch adversarial loss: 0.491957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.017727; batch adversarial loss: 0.515615\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018284; batch adversarial loss: 0.378353\n",
      "epoch 140; iter: 0; batch classifier loss: 0.055186; batch adversarial loss: 0.548977\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014598; batch adversarial loss: 0.413270\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026041; batch adversarial loss: 0.408388\n",
      "epoch 143; iter: 0; batch classifier loss: 0.019116; batch adversarial loss: 0.464940\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021832; batch adversarial loss: 0.446885\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036073; batch adversarial loss: 0.432111\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019781; batch adversarial loss: 0.451676\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021224; batch adversarial loss: 0.387492\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015846; batch adversarial loss: 0.462766\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.402334\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025336; batch adversarial loss: 0.452651\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033305; batch adversarial loss: 0.420375\n",
      "epoch 152; iter: 0; batch classifier loss: 0.012063; batch adversarial loss: 0.407143\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006221; batch adversarial loss: 0.386426\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016340; batch adversarial loss: 0.329564\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027594; batch adversarial loss: 0.517549\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016809; batch adversarial loss: 0.498029\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030789; batch adversarial loss: 0.386407\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009045; batch adversarial loss: 0.562687\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012997; batch adversarial loss: 0.426980\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.494491\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032270; batch adversarial loss: 0.485480\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046227; batch adversarial loss: 0.354340\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013935; batch adversarial loss: 0.470522\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010925; batch adversarial loss: 0.492058\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011582; batch adversarial loss: 0.441506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005635; batch adversarial loss: 0.460108\n",
      "epoch 167; iter: 0; batch classifier loss: 0.007065; batch adversarial loss: 0.358487\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035275; batch adversarial loss: 0.543977\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021492; batch adversarial loss: 0.375805\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008856; batch adversarial loss: 0.387309\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025167; batch adversarial loss: 0.429609\n",
      "epoch 172; iter: 0; batch classifier loss: 0.032080; batch adversarial loss: 0.406556\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032783; batch adversarial loss: 0.331514\n",
      "epoch 174; iter: 0; batch classifier loss: 0.033836; batch adversarial loss: 0.439688\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012215; batch adversarial loss: 0.391943\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016643; batch adversarial loss: 0.432784\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051292; batch adversarial loss: 0.417596\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005684; batch adversarial loss: 0.454848\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006034; batch adversarial loss: 0.493199\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006676; batch adversarial loss: 0.401717\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018617; batch adversarial loss: 0.432598\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012771; batch adversarial loss: 0.514402\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026405; batch adversarial loss: 0.460889\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040880; batch adversarial loss: 0.398686\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011098; batch adversarial loss: 0.439175\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025401; batch adversarial loss: 0.484500\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015459; batch adversarial loss: 0.444301\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011332; batch adversarial loss: 0.334535\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014907; batch adversarial loss: 0.337445\n",
      "epoch 190; iter: 0; batch classifier loss: 0.003304; batch adversarial loss: 0.510238\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015604; batch adversarial loss: 0.389712\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009434; batch adversarial loss: 0.430545\n",
      "epoch 193; iter: 0; batch classifier loss: 0.004645; batch adversarial loss: 0.425576\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014230; batch adversarial loss: 0.417767\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023703; batch adversarial loss: 0.430407\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010626; batch adversarial loss: 0.460927\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006988; batch adversarial loss: 0.411468\n",
      "epoch 198; iter: 0; batch classifier loss: 0.046436; batch adversarial loss: 0.423977\n",
      "epoch 199; iter: 0; batch classifier loss: 0.004061; batch adversarial loss: 0.425638\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677255; batch adversarial loss: 0.801209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.389086; batch adversarial loss: 0.793426\n",
      "epoch 2; iter: 0; batch classifier loss: 0.325266; batch adversarial loss: 0.766496\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351756; batch adversarial loss: 0.763211\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327911; batch adversarial loss: 0.727427\n",
      "epoch 5; iter: 0; batch classifier loss: 0.407723; batch adversarial loss: 0.659711\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288745; batch adversarial loss: 0.615471\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345453; batch adversarial loss: 0.578812\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259537; batch adversarial loss: 0.597977\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280745; batch adversarial loss: 0.530835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261248; batch adversarial loss: 0.507283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275895; batch adversarial loss: 0.508811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248822; batch adversarial loss: 0.450634\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235143; batch adversarial loss: 0.467420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225671; batch adversarial loss: 0.468775\n",
      "epoch 15; iter: 0; batch classifier loss: 0.178585; batch adversarial loss: 0.459173\n",
      "epoch 16; iter: 0; batch classifier loss: 0.180941; batch adversarial loss: 0.431289\n",
      "epoch 17; iter: 0; batch classifier loss: 0.203617; batch adversarial loss: 0.448299\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214280; batch adversarial loss: 0.415772\n",
      "epoch 19; iter: 0; batch classifier loss: 0.159481; batch adversarial loss: 0.493086\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170157; batch adversarial loss: 0.438753\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182232; batch adversarial loss: 0.452457\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210954; batch adversarial loss: 0.369259\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171890; batch adversarial loss: 0.395750\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165797; batch adversarial loss: 0.400275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169576; batch adversarial loss: 0.436400\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176344; batch adversarial loss: 0.430911\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170840; batch adversarial loss: 0.437637\n",
      "epoch 28; iter: 0; batch classifier loss: 0.107672; batch adversarial loss: 0.406313\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153743; batch adversarial loss: 0.487725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.097195; batch adversarial loss: 0.447482\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140223; batch adversarial loss: 0.477280\n",
      "epoch 32; iter: 0; batch classifier loss: 0.093661; batch adversarial loss: 0.397360\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162907; batch adversarial loss: 0.413849\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137518; batch adversarial loss: 0.484846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.150574; batch adversarial loss: 0.394064\n",
      "epoch 36; iter: 0; batch classifier loss: 0.122509; batch adversarial loss: 0.368593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.100211; batch adversarial loss: 0.411900\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148249; batch adversarial loss: 0.378581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.158630; batch adversarial loss: 0.406456\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128162; batch adversarial loss: 0.384003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100464; batch adversarial loss: 0.439731\n",
      "epoch 42; iter: 0; batch classifier loss: 0.125368; batch adversarial loss: 0.426631\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110983; batch adversarial loss: 0.391408\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086590; batch adversarial loss: 0.411535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126838; batch adversarial loss: 0.429067\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092113; batch adversarial loss: 0.405620\n",
      "epoch 47; iter: 0; batch classifier loss: 0.141904; batch adversarial loss: 0.348412\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099506; batch adversarial loss: 0.404863\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080130; batch adversarial loss: 0.346899\n",
      "epoch 50; iter: 0; batch classifier loss: 0.105119; batch adversarial loss: 0.468051\n",
      "epoch 51; iter: 0; batch classifier loss: 0.109530; batch adversarial loss: 0.469099\n",
      "epoch 52; iter: 0; batch classifier loss: 0.148492; batch adversarial loss: 0.409426\n",
      "epoch 53; iter: 0; batch classifier loss: 0.053546; batch adversarial loss: 0.421218\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077157; batch adversarial loss: 0.461819\n",
      "epoch 55; iter: 0; batch classifier loss: 0.059591; batch adversarial loss: 0.454629\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103223; batch adversarial loss: 0.461920\n",
      "epoch 57; iter: 0; batch classifier loss: 0.077427; batch adversarial loss: 0.389170\n",
      "epoch 58; iter: 0; batch classifier loss: 0.106526; batch adversarial loss: 0.460830\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099604; batch adversarial loss: 0.328522\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115193; batch adversarial loss: 0.371282\n",
      "epoch 61; iter: 0; batch classifier loss: 0.056245; batch adversarial loss: 0.429338\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082431; batch adversarial loss: 0.372523\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089643; batch adversarial loss: 0.400018\n",
      "epoch 64; iter: 0; batch classifier loss: 0.060396; batch adversarial loss: 0.424860\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067971; batch adversarial loss: 0.485156\n",
      "epoch 66; iter: 0; batch classifier loss: 0.068675; batch adversarial loss: 0.456423\n",
      "epoch 67; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.330060\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045009; batch adversarial loss: 0.424121\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055355; batch adversarial loss: 0.449582\n",
      "epoch 70; iter: 0; batch classifier loss: 0.056824; batch adversarial loss: 0.357623\n",
      "epoch 71; iter: 0; batch classifier loss: 0.033758; batch adversarial loss: 0.431592\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053233; batch adversarial loss: 0.418996\n",
      "epoch 73; iter: 0; batch classifier loss: 0.064700; batch adversarial loss: 0.387114\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059202; batch adversarial loss: 0.373200\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073934; batch adversarial loss: 0.495070\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064206; batch adversarial loss: 0.346354\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054855; batch adversarial loss: 0.394690\n",
      "epoch 78; iter: 0; batch classifier loss: 0.031060; batch adversarial loss: 0.415687\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059305; batch adversarial loss: 0.478976\n",
      "epoch 80; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.430691\n",
      "epoch 81; iter: 0; batch classifier loss: 0.069762; batch adversarial loss: 0.533203\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053775; batch adversarial loss: 0.442652\n",
      "epoch 83; iter: 0; batch classifier loss: 0.030136; batch adversarial loss: 0.369473\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042529; batch adversarial loss: 0.399623\n",
      "epoch 85; iter: 0; batch classifier loss: 0.050926; batch adversarial loss: 0.477164\n",
      "epoch 86; iter: 0; batch classifier loss: 0.033655; batch adversarial loss: 0.464708\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050428; batch adversarial loss: 0.382362\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067870; batch adversarial loss: 0.454799\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.390287\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038959; batch adversarial loss: 0.488125\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028336; batch adversarial loss: 0.497019\n",
      "epoch 92; iter: 0; batch classifier loss: 0.035363; batch adversarial loss: 0.385464\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048451; batch adversarial loss: 0.392433\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050856; batch adversarial loss: 0.422549\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036199; batch adversarial loss: 0.450399\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046003; batch adversarial loss: 0.402505\n",
      "epoch 97; iter: 0; batch classifier loss: 0.037781; batch adversarial loss: 0.366383\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032407; batch adversarial loss: 0.440416\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046563; batch adversarial loss: 0.344558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039329; batch adversarial loss: 0.378868\n",
      "epoch 101; iter: 0; batch classifier loss: 0.124162; batch adversarial loss: 0.442126\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024603; batch adversarial loss: 0.484299\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062938; batch adversarial loss: 0.459425\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057895; batch adversarial loss: 0.476989\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063850; batch adversarial loss: 0.469680\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042671; batch adversarial loss: 0.451302\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053222; batch adversarial loss: 0.499589\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.481375\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061051; batch adversarial loss: 0.505022\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059308; batch adversarial loss: 0.442957\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101333; batch adversarial loss: 0.605010\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054759; batch adversarial loss: 0.448978\n",
      "epoch 113; iter: 0; batch classifier loss: 0.167469; batch adversarial loss: 0.527900\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062038; batch adversarial loss: 0.468173\n",
      "epoch 115; iter: 0; batch classifier loss: 0.185162; batch adversarial loss: 0.785386\n",
      "epoch 116; iter: 0; batch classifier loss: 0.118723; batch adversarial loss: 0.606260\n",
      "epoch 117; iter: 0; batch classifier loss: 0.110889; batch adversarial loss: 0.554483\n",
      "epoch 118; iter: 0; batch classifier loss: 0.153768; batch adversarial loss: 0.580543\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120708; batch adversarial loss: 0.635855\n",
      "epoch 120; iter: 0; batch classifier loss: 0.139253; batch adversarial loss: 0.596694\n",
      "epoch 121; iter: 0; batch classifier loss: 0.124955; batch adversarial loss: 0.593673\n",
      "epoch 122; iter: 0; batch classifier loss: 0.131663; batch adversarial loss: 0.557030\n",
      "epoch 123; iter: 0; batch classifier loss: 0.162393; batch adversarial loss: 0.540441\n",
      "epoch 124; iter: 0; batch classifier loss: 0.151304; batch adversarial loss: 0.575551\n",
      "epoch 125; iter: 0; batch classifier loss: 0.088831; batch adversarial loss: 0.409145\n",
      "epoch 126; iter: 0; batch classifier loss: 0.120449; batch adversarial loss: 0.548923\n",
      "epoch 127; iter: 0; batch classifier loss: 0.095022; batch adversarial loss: 0.518047\n",
      "epoch 128; iter: 0; batch classifier loss: 0.146873; batch adversarial loss: 0.465709\n",
      "epoch 129; iter: 0; batch classifier loss: 0.097652; batch adversarial loss: 0.471947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.081994; batch adversarial loss: 0.491342\n",
      "epoch 131; iter: 0; batch classifier loss: 0.121898; batch adversarial loss: 0.603100\n",
      "epoch 132; iter: 0; batch classifier loss: 0.112547; batch adversarial loss: 0.439669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.084285; batch adversarial loss: 0.467739\n",
      "epoch 134; iter: 0; batch classifier loss: 0.124973; batch adversarial loss: 0.535074\n",
      "epoch 135; iter: 0; batch classifier loss: 0.108104; batch adversarial loss: 0.450886\n",
      "epoch 136; iter: 0; batch classifier loss: 0.107742; batch adversarial loss: 0.527266\n",
      "epoch 137; iter: 0; batch classifier loss: 0.117375; batch adversarial loss: 0.425159\n",
      "epoch 138; iter: 0; batch classifier loss: 0.092532; batch adversarial loss: 0.454143\n",
      "epoch 139; iter: 0; batch classifier loss: 0.072323; batch adversarial loss: 0.389240\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073962; batch adversarial loss: 0.473467\n",
      "epoch 141; iter: 0; batch classifier loss: 0.113214; batch adversarial loss: 0.515960\n",
      "epoch 142; iter: 0; batch classifier loss: 0.071560; batch adversarial loss: 0.444535\n",
      "epoch 143; iter: 0; batch classifier loss: 0.085991; batch adversarial loss: 0.382772\n",
      "epoch 144; iter: 0; batch classifier loss: 0.082646; batch adversarial loss: 0.479154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.136170; batch adversarial loss: 0.513430\n",
      "epoch 146; iter: 0; batch classifier loss: 0.137624; batch adversarial loss: 0.524011\n",
      "epoch 147; iter: 0; batch classifier loss: 0.104788; batch adversarial loss: 0.321109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055350; batch adversarial loss: 0.445747\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056631; batch adversarial loss: 0.416430\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043832; batch adversarial loss: 0.427633\n",
      "epoch 151; iter: 0; batch classifier loss: 0.058856; batch adversarial loss: 0.374723\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039529; batch adversarial loss: 0.440050\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042554; batch adversarial loss: 0.518767\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030121; batch adversarial loss: 0.418752\n",
      "epoch 155; iter: 0; batch classifier loss: 0.015134; batch adversarial loss: 0.419228\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030090; batch adversarial loss: 0.324918\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.487632\n",
      "epoch 158; iter: 0; batch classifier loss: 0.036213; batch adversarial loss: 0.437004\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039924; batch adversarial loss: 0.532009\n",
      "epoch 160; iter: 0; batch classifier loss: 0.068767; batch adversarial loss: 0.295666\n",
      "epoch 161; iter: 0; batch classifier loss: 0.040030; batch adversarial loss: 0.463388\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026889; batch adversarial loss: 0.387811\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050531; batch adversarial loss: 0.485916\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018486; batch adversarial loss: 0.413205\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021322; batch adversarial loss: 0.363739\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055148; batch adversarial loss: 0.406910\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049011; batch adversarial loss: 0.435113\n",
      "epoch 168; iter: 0; batch classifier loss: 0.056055; batch adversarial loss: 0.493811\n",
      "epoch 169; iter: 0; batch classifier loss: 0.059721; batch adversarial loss: 0.385128\n",
      "epoch 170; iter: 0; batch classifier loss: 0.078752; batch adversarial loss: 0.430077\n",
      "epoch 171; iter: 0; batch classifier loss: 0.061702; batch adversarial loss: 0.450898\n",
      "epoch 172; iter: 0; batch classifier loss: 0.065718; batch adversarial loss: 0.432075\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052825; batch adversarial loss: 0.491339\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056144; batch adversarial loss: 0.490408\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029763; batch adversarial loss: 0.477776\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014655; batch adversarial loss: 0.429965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.050801; batch adversarial loss: 0.513421\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049960; batch adversarial loss: 0.472233\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038765; batch adversarial loss: 0.434972\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047094; batch adversarial loss: 0.490098\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032134; batch adversarial loss: 0.450369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029982; batch adversarial loss: 0.443213\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034566; batch adversarial loss: 0.480876\n",
      "epoch 184; iter: 0; batch classifier loss: 0.033572; batch adversarial loss: 0.437658\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025711; batch adversarial loss: 0.355311\n",
      "epoch 186; iter: 0; batch classifier loss: 0.059508; batch adversarial loss: 0.506369\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039163; batch adversarial loss: 0.418489\n",
      "epoch 188; iter: 0; batch classifier loss: 0.042620; batch adversarial loss: 0.497106\n",
      "epoch 189; iter: 0; batch classifier loss: 0.065795; batch adversarial loss: 0.347393\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040781; batch adversarial loss: 0.438846\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031563; batch adversarial loss: 0.430817\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022210; batch adversarial loss: 0.452931\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027277; batch adversarial loss: 0.461182\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036202; batch adversarial loss: 0.441171\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044381; batch adversarial loss: 0.450483\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047980; batch adversarial loss: 0.370211\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039248; batch adversarial loss: 0.473991\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015331; batch adversarial loss: 0.487968\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030436; batch adversarial loss: 0.485646\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692684; batch adversarial loss: 0.842883\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395953; batch adversarial loss: 0.784790\n",
      "epoch 2; iter: 0; batch classifier loss: 0.373112; batch adversarial loss: 0.774896\n",
      "epoch 3; iter: 0; batch classifier loss: 0.479793; batch adversarial loss: 0.737960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375793; batch adversarial loss: 0.706571\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343507; batch adversarial loss: 0.653808\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307229; batch adversarial loss: 0.633140\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307291; batch adversarial loss: 0.608605\n",
      "epoch 8; iter: 0; batch classifier loss: 0.372527; batch adversarial loss: 0.571541\n",
      "epoch 9; iter: 0; batch classifier loss: 0.262643; batch adversarial loss: 0.553295\n",
      "epoch 10; iter: 0; batch classifier loss: 0.256563; batch adversarial loss: 0.547657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316474; batch adversarial loss: 0.534938\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270774; batch adversarial loss: 0.492949\n",
      "epoch 13; iter: 0; batch classifier loss: 0.189096; batch adversarial loss: 0.483369\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262360; batch adversarial loss: 0.450406\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244871; batch adversarial loss: 0.420048\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244754; batch adversarial loss: 0.497290\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230554; batch adversarial loss: 0.422690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.248535; batch adversarial loss: 0.430368\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276224; batch adversarial loss: 0.430952\n",
      "epoch 20; iter: 0; batch classifier loss: 0.240628; batch adversarial loss: 0.434775\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252265; batch adversarial loss: 0.432095\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224173; batch adversarial loss: 0.396785\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261723; batch adversarial loss: 0.397501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230159; batch adversarial loss: 0.398397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248576; batch adversarial loss: 0.423822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247939; batch adversarial loss: 0.442825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178894; batch adversarial loss: 0.434213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.201808; batch adversarial loss: 0.401032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179384; batch adversarial loss: 0.438966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.161986; batch adversarial loss: 0.408799\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190063; batch adversarial loss: 0.476368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157171; batch adversarial loss: 0.394586\n",
      "epoch 33; iter: 0; batch classifier loss: 0.129386; batch adversarial loss: 0.395673\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166955; batch adversarial loss: 0.409394\n",
      "epoch 35; iter: 0; batch classifier loss: 0.136080; batch adversarial loss: 0.362639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.143005; batch adversarial loss: 0.332240\n",
      "epoch 37; iter: 0; batch classifier loss: 0.180992; batch adversarial loss: 0.367511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.137011; batch adversarial loss: 0.395784\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135391; batch adversarial loss: 0.376833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.164460; batch adversarial loss: 0.455633\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173602; batch adversarial loss: 0.367333\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141342; batch adversarial loss: 0.486427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103807; batch adversarial loss: 0.349034\n",
      "epoch 44; iter: 0; batch classifier loss: 0.182400; batch adversarial loss: 0.417622\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135549; batch adversarial loss: 0.401319\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090874; batch adversarial loss: 0.437692\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117526; batch adversarial loss: 0.347266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.115128; batch adversarial loss: 0.407653\n",
      "epoch 49; iter: 0; batch classifier loss: 0.138139; batch adversarial loss: 0.403956\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106816; batch adversarial loss: 0.470745\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095060; batch adversarial loss: 0.273934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082639; batch adversarial loss: 0.454385\n",
      "epoch 53; iter: 0; batch classifier loss: 0.110484; batch adversarial loss: 0.366579\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068949; batch adversarial loss: 0.379661\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089422; batch adversarial loss: 0.456894\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138762; batch adversarial loss: 0.506805\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082401; batch adversarial loss: 0.420714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065284; batch adversarial loss: 0.373435\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086769; batch adversarial loss: 0.505395\n",
      "epoch 60; iter: 0; batch classifier loss: 0.120626; batch adversarial loss: 0.461314\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093499; batch adversarial loss: 0.497358\n",
      "epoch 62; iter: 0; batch classifier loss: 0.100629; batch adversarial loss: 0.373749\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096657; batch adversarial loss: 0.419890\n",
      "epoch 64; iter: 0; batch classifier loss: 0.097440; batch adversarial loss: 0.454964\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118757; batch adversarial loss: 0.381833\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062801; batch adversarial loss: 0.440426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067199; batch adversarial loss: 0.391276\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087460; batch adversarial loss: 0.408826\n",
      "epoch 69; iter: 0; batch classifier loss: 0.083797; batch adversarial loss: 0.479168\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108416; batch adversarial loss: 0.408824\n",
      "epoch 71; iter: 0; batch classifier loss: 0.104704; batch adversarial loss: 0.527593\n",
      "epoch 72; iter: 0; batch classifier loss: 0.078515; batch adversarial loss: 0.427727\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070387; batch adversarial loss: 0.357552\n",
      "epoch 74; iter: 0; batch classifier loss: 0.072494; batch adversarial loss: 0.440732\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080000; batch adversarial loss: 0.386840\n",
      "epoch 76; iter: 0; batch classifier loss: 0.056548; batch adversarial loss: 0.488441\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087497; batch adversarial loss: 0.375583\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081093; batch adversarial loss: 0.393639\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071977; batch adversarial loss: 0.488989\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097316; batch adversarial loss: 0.417956\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096313; batch adversarial loss: 0.382807\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075594; batch adversarial loss: 0.389107\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089701; batch adversarial loss: 0.473124\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064786; batch adversarial loss: 0.489102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046348; batch adversarial loss: 0.463647\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067728; batch adversarial loss: 0.408793\n",
      "epoch 87; iter: 0; batch classifier loss: 0.109398; batch adversarial loss: 0.414397\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089434; batch adversarial loss: 0.457233\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059446; batch adversarial loss: 0.522047\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088595; batch adversarial loss: 0.357230\n",
      "epoch 91; iter: 0; batch classifier loss: 0.107091; batch adversarial loss: 0.415845\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048689; batch adversarial loss: 0.466660\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067887; batch adversarial loss: 0.356912\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042523; batch adversarial loss: 0.475709\n",
      "epoch 95; iter: 0; batch classifier loss: 0.082150; batch adversarial loss: 0.435651\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065517; batch adversarial loss: 0.435193\n",
      "epoch 97; iter: 0; batch classifier loss: 0.077991; batch adversarial loss: 0.395114\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032567; batch adversarial loss: 0.496835\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085366; batch adversarial loss: 0.392727\n",
      "epoch 100; iter: 0; batch classifier loss: 0.074033; batch adversarial loss: 0.412298\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077349; batch adversarial loss: 0.472431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060924; batch adversarial loss: 0.438326\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071281; batch adversarial loss: 0.473510\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038905; batch adversarial loss: 0.399914\n",
      "epoch 105; iter: 0; batch classifier loss: 0.080001; batch adversarial loss: 0.408640\n",
      "epoch 106; iter: 0; batch classifier loss: 0.073242; batch adversarial loss: 0.403128\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053840; batch adversarial loss: 0.423464\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068563; batch adversarial loss: 0.422021\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039880; batch adversarial loss: 0.494866\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050162; batch adversarial loss: 0.434325\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044803; batch adversarial loss: 0.437786\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054530; batch adversarial loss: 0.499889\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077037; batch adversarial loss: 0.412784\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049554; batch adversarial loss: 0.543887\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042307; batch adversarial loss: 0.451308\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035667; batch adversarial loss: 0.419506\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044386; batch adversarial loss: 0.463091\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021603; batch adversarial loss: 0.427167\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063960; batch adversarial loss: 0.471282\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039671; batch adversarial loss: 0.470191\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040742; batch adversarial loss: 0.520707\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048371; batch adversarial loss: 0.434647\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051323; batch adversarial loss: 0.467083\n",
      "epoch 124; iter: 0; batch classifier loss: 0.062136; batch adversarial loss: 0.490990\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042999; batch adversarial loss: 0.392191\n",
      "epoch 126; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.468201\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.434040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.038931; batch adversarial loss: 0.469097\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038564; batch adversarial loss: 0.362795\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049267; batch adversarial loss: 0.354832\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036861; batch adversarial loss: 0.426845\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024366; batch adversarial loss: 0.504786\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051941; batch adversarial loss: 0.502983\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052808; batch adversarial loss: 0.556737\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012350; batch adversarial loss: 0.455531\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055789; batch adversarial loss: 0.435575\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024131; batch adversarial loss: 0.464747\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047409; batch adversarial loss: 0.438407\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033139; batch adversarial loss: 0.547933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.012027; batch adversarial loss: 0.402645\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045954; batch adversarial loss: 0.511329\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038786; batch adversarial loss: 0.479062\n",
      "epoch 143; iter: 0; batch classifier loss: 0.076112; batch adversarial loss: 0.611085\n",
      "epoch 144; iter: 0; batch classifier loss: 0.049107; batch adversarial loss: 0.490748\n",
      "epoch 145; iter: 0; batch classifier loss: 0.074415; batch adversarial loss: 0.520047\n",
      "epoch 146; iter: 0; batch classifier loss: 0.111173; batch adversarial loss: 0.618467\n",
      "epoch 147; iter: 0; batch classifier loss: 0.164515; batch adversarial loss: 0.757109\n",
      "epoch 148; iter: 0; batch classifier loss: 0.151777; batch adversarial loss: 0.658396\n",
      "epoch 149; iter: 0; batch classifier loss: 0.181942; batch adversarial loss: 0.641514\n",
      "epoch 150; iter: 0; batch classifier loss: 0.159349; batch adversarial loss: 0.598921\n",
      "epoch 151; iter: 0; batch classifier loss: 0.125646; batch adversarial loss: 0.568314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.126963; batch adversarial loss: 0.628551\n",
      "epoch 153; iter: 0; batch classifier loss: 0.173854; batch adversarial loss: 0.670212\n",
      "epoch 154; iter: 0; batch classifier loss: 0.104511; batch adversarial loss: 0.577273\n",
      "epoch 155; iter: 0; batch classifier loss: 0.125743; batch adversarial loss: 0.559935\n",
      "epoch 156; iter: 0; batch classifier loss: 0.131236; batch adversarial loss: 0.535384\n",
      "epoch 157; iter: 0; batch classifier loss: 0.159057; batch adversarial loss: 0.668515\n",
      "epoch 158; iter: 0; batch classifier loss: 0.107404; batch adversarial loss: 0.539606\n",
      "epoch 159; iter: 0; batch classifier loss: 0.171239; batch adversarial loss: 0.658759\n",
      "epoch 160; iter: 0; batch classifier loss: 0.142921; batch adversarial loss: 0.557286\n",
      "epoch 161; iter: 0; batch classifier loss: 0.134640; batch adversarial loss: 0.580776\n",
      "epoch 162; iter: 0; batch classifier loss: 0.151176; batch adversarial loss: 0.561282\n",
      "epoch 163; iter: 0; batch classifier loss: 0.125308; batch adversarial loss: 0.601505\n",
      "epoch 164; iter: 0; batch classifier loss: 0.133507; batch adversarial loss: 0.548374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.165452; batch adversarial loss: 0.512254\n",
      "epoch 166; iter: 0; batch classifier loss: 0.168480; batch adversarial loss: 0.667131\n",
      "epoch 167; iter: 0; batch classifier loss: 0.178414; batch adversarial loss: 0.564636\n",
      "epoch 168; iter: 0; batch classifier loss: 0.159186; batch adversarial loss: 0.607542\n",
      "epoch 169; iter: 0; batch classifier loss: 0.251616; batch adversarial loss: 0.667717\n",
      "epoch 170; iter: 0; batch classifier loss: 0.111653; batch adversarial loss: 0.497308\n",
      "epoch 171; iter: 0; batch classifier loss: 0.150774; batch adversarial loss: 0.582080\n",
      "epoch 172; iter: 0; batch classifier loss: 0.124800; batch adversarial loss: 0.473391\n",
      "epoch 173; iter: 0; batch classifier loss: 0.189520; batch adversarial loss: 0.642152\n",
      "epoch 174; iter: 0; batch classifier loss: 0.180107; batch adversarial loss: 0.619725\n",
      "epoch 175; iter: 0; batch classifier loss: 0.165376; batch adversarial loss: 0.530996\n",
      "epoch 176; iter: 0; batch classifier loss: 0.177466; batch adversarial loss: 0.613403\n",
      "epoch 177; iter: 0; batch classifier loss: 0.161517; batch adversarial loss: 0.533054\n",
      "epoch 178; iter: 0; batch classifier loss: 0.187632; batch adversarial loss: 0.561768\n",
      "epoch 179; iter: 0; batch classifier loss: 0.148896; batch adversarial loss: 0.523392\n",
      "epoch 180; iter: 0; batch classifier loss: 0.179833; batch adversarial loss: 0.592623\n",
      "epoch 181; iter: 0; batch classifier loss: 0.148289; batch adversarial loss: 0.559646\n",
      "epoch 182; iter: 0; batch classifier loss: 0.125137; batch adversarial loss: 0.467148\n",
      "epoch 183; iter: 0; batch classifier loss: 0.149462; batch adversarial loss: 0.563090\n",
      "epoch 184; iter: 0; batch classifier loss: 0.132328; batch adversarial loss: 0.570374\n",
      "epoch 185; iter: 0; batch classifier loss: 0.154862; batch adversarial loss: 0.543282\n",
      "epoch 186; iter: 0; batch classifier loss: 0.169632; batch adversarial loss: 0.511495\n",
      "epoch 187; iter: 0; batch classifier loss: 0.128836; batch adversarial loss: 0.493326\n",
      "epoch 188; iter: 0; batch classifier loss: 0.104543; batch adversarial loss: 0.439717\n",
      "epoch 189; iter: 0; batch classifier loss: 0.149770; batch adversarial loss: 0.489327\n",
      "epoch 190; iter: 0; batch classifier loss: 0.113858; batch adversarial loss: 0.518547\n",
      "epoch 191; iter: 0; batch classifier loss: 0.102047; batch adversarial loss: 0.430231\n",
      "epoch 192; iter: 0; batch classifier loss: 0.118547; batch adversarial loss: 0.449482\n",
      "epoch 193; iter: 0; batch classifier loss: 0.123970; batch adversarial loss: 0.474376\n",
      "epoch 194; iter: 0; batch classifier loss: 0.057500; batch adversarial loss: 0.376681\n",
      "epoch 195; iter: 0; batch classifier loss: 0.062020; batch adversarial loss: 0.396495\n",
      "epoch 196; iter: 0; batch classifier loss: 0.045700; batch adversarial loss: 0.468137\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039880; batch adversarial loss: 0.395850\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038988; batch adversarial loss: 0.406382\n",
      "epoch 199; iter: 0; batch classifier loss: 0.041051; batch adversarial loss: 0.509661\n",
      "epoch 0; iter: 0; batch classifier loss: 0.654737; batch adversarial loss: 0.747070\n",
      "epoch 1; iter: 0; batch classifier loss: 0.470231; batch adversarial loss: 0.707342\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423677; batch adversarial loss: 0.676282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.644736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380943; batch adversarial loss: 0.603946\n",
      "epoch 5; iter: 0; batch classifier loss: 0.286069; batch adversarial loss: 0.587716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.538286\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318494; batch adversarial loss: 0.494336\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255337; batch adversarial loss: 0.507772\n",
      "epoch 9; iter: 0; batch classifier loss: 0.273214; batch adversarial loss: 0.500302\n",
      "epoch 10; iter: 0; batch classifier loss: 0.198708; batch adversarial loss: 0.494619\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266469; batch adversarial loss: 0.515971\n",
      "epoch 12; iter: 0; batch classifier loss: 0.174573; batch adversarial loss: 0.469825\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295383; batch adversarial loss: 0.397133\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180856; batch adversarial loss: 0.409284\n",
      "epoch 15; iter: 0; batch classifier loss: 0.203792; batch adversarial loss: 0.394097\n",
      "epoch 16; iter: 0; batch classifier loss: 0.177264; batch adversarial loss: 0.443038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.188479; batch adversarial loss: 0.479591\n",
      "epoch 18; iter: 0; batch classifier loss: 0.148420; batch adversarial loss: 0.417956\n",
      "epoch 19; iter: 0; batch classifier loss: 0.133524; batch adversarial loss: 0.367786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224730; batch adversarial loss: 0.409868\n",
      "epoch 21; iter: 0; batch classifier loss: 0.157484; batch adversarial loss: 0.389872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.177936; batch adversarial loss: 0.486387\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187477; batch adversarial loss: 0.410586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 0; batch classifier loss: 0.209615; batch adversarial loss: 0.446436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146351; batch adversarial loss: 0.380860\n",
      "epoch 26; iter: 0; batch classifier loss: 0.214341; batch adversarial loss: 0.323427\n",
      "epoch 27; iter: 0; batch classifier loss: 0.214527; batch adversarial loss: 0.378046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.114151; batch adversarial loss: 0.421291\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129605; batch adversarial loss: 0.460730\n",
      "epoch 30; iter: 0; batch classifier loss: 0.110439; batch adversarial loss: 0.399798\n",
      "epoch 31; iter: 0; batch classifier loss: 0.130896; batch adversarial loss: 0.358234\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126215; batch adversarial loss: 0.340859\n",
      "epoch 33; iter: 0; batch classifier loss: 0.122896; batch adversarial loss: 0.310748\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155249; batch adversarial loss: 0.441321\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118086; batch adversarial loss: 0.436404\n",
      "epoch 36; iter: 0; batch classifier loss: 0.091864; batch adversarial loss: 0.342894\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126061; batch adversarial loss: 0.391519\n",
      "epoch 38; iter: 0; batch classifier loss: 0.112908; batch adversarial loss: 0.433184\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124792; batch adversarial loss: 0.385178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112113; batch adversarial loss: 0.462244\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091591; batch adversarial loss: 0.418907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.185861; batch adversarial loss: 0.420237\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105621; batch adversarial loss: 0.358396\n",
      "epoch 44; iter: 0; batch classifier loss: 0.169813; batch adversarial loss: 0.391685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.088145; batch adversarial loss: 0.443605\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090407; batch adversarial loss: 0.430174\n",
      "epoch 47; iter: 0; batch classifier loss: 0.114673; batch adversarial loss: 0.383222\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090899; batch adversarial loss: 0.456479\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103156; batch adversarial loss: 0.467591\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112926; batch adversarial loss: 0.357018\n",
      "epoch 51; iter: 0; batch classifier loss: 0.156441; batch adversarial loss: 0.432622\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092082; batch adversarial loss: 0.410203\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093622; batch adversarial loss: 0.425690\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081115; batch adversarial loss: 0.390625\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098057; batch adversarial loss: 0.479966\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069015; batch adversarial loss: 0.414692\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053874; batch adversarial loss: 0.367024\n",
      "epoch 58; iter: 0; batch classifier loss: 0.067318; batch adversarial loss: 0.398036\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100999; batch adversarial loss: 0.400651\n",
      "epoch 60; iter: 0; batch classifier loss: 0.084714; batch adversarial loss: 0.472030\n",
      "epoch 61; iter: 0; batch classifier loss: 0.065663; batch adversarial loss: 0.494765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.109632; batch adversarial loss: 0.442610\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059023; batch adversarial loss: 0.406961\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071848; batch adversarial loss: 0.416220\n",
      "epoch 65; iter: 0; batch classifier loss: 0.108364; batch adversarial loss: 0.324739\n",
      "epoch 66; iter: 0; batch classifier loss: 0.145071; batch adversarial loss: 0.453653\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099221; batch adversarial loss: 0.391179\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097123; batch adversarial loss: 0.280074\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094688; batch adversarial loss: 0.429488\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077927; batch adversarial loss: 0.388165\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067809; batch adversarial loss: 0.385066\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077353; batch adversarial loss: 0.414535\n",
      "epoch 73; iter: 0; batch classifier loss: 0.078689; batch adversarial loss: 0.302706\n",
      "epoch 74; iter: 0; batch classifier loss: 0.076182; batch adversarial loss: 0.475363\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078150; batch adversarial loss: 0.474919\n",
      "epoch 76; iter: 0; batch classifier loss: 0.057383; batch adversarial loss: 0.436836\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065802; batch adversarial loss: 0.443613\n",
      "epoch 78; iter: 0; batch classifier loss: 0.084046; batch adversarial loss: 0.371436\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088342; batch adversarial loss: 0.465975\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111584; batch adversarial loss: 0.419320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096087; batch adversarial loss: 0.360916\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059445; batch adversarial loss: 0.362787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085180; batch adversarial loss: 0.485673\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078799; batch adversarial loss: 0.421060\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088684; batch adversarial loss: 0.434396\n",
      "epoch 86; iter: 0; batch classifier loss: 0.034040; batch adversarial loss: 0.453101\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054854; batch adversarial loss: 0.410912\n",
      "epoch 88; iter: 0; batch classifier loss: 0.079986; batch adversarial loss: 0.372229\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066567; batch adversarial loss: 0.405650\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053739; batch adversarial loss: 0.354622\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063005; batch adversarial loss: 0.388935\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065197; batch adversarial loss: 0.340661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078548; batch adversarial loss: 0.393468\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041431; batch adversarial loss: 0.445979\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075793; batch adversarial loss: 0.458333\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049322; batch adversarial loss: 0.412721\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098801; batch adversarial loss: 0.412220\n",
      "epoch 98; iter: 0; batch classifier loss: 0.083728; batch adversarial loss: 0.407634\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059898; batch adversarial loss: 0.448047\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050730; batch adversarial loss: 0.376143\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068507; batch adversarial loss: 0.402750\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047516; batch adversarial loss: 0.391027\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055378; batch adversarial loss: 0.433902\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056725; batch adversarial loss: 0.423462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055579; batch adversarial loss: 0.384682\n",
      "epoch 106; iter: 0; batch classifier loss: 0.060979; batch adversarial loss: 0.385087\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032047; batch adversarial loss: 0.414888\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081488; batch adversarial loss: 0.436868\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075986; batch adversarial loss: 0.495610\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.449061\n",
      "epoch 111; iter: 0; batch classifier loss: 0.039068; batch adversarial loss: 0.443230\n",
      "epoch 112; iter: 0; batch classifier loss: 0.028956; batch adversarial loss: 0.325889\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047787; batch adversarial loss: 0.430215\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034659; batch adversarial loss: 0.356927\n",
      "epoch 115; iter: 0; batch classifier loss: 0.021955; batch adversarial loss: 0.365450\n",
      "epoch 116; iter: 0; batch classifier loss: 0.030021; batch adversarial loss: 0.426792\n",
      "epoch 117; iter: 0; batch classifier loss: 0.042236; batch adversarial loss: 0.455735\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025256; batch adversarial loss: 0.456968\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.422744\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039056; batch adversarial loss: 0.386391\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019995; batch adversarial loss: 0.415437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 0; batch classifier loss: 0.059728; batch adversarial loss: 0.475491\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023932; batch adversarial loss: 0.430381\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035267; batch adversarial loss: 0.503868\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015839; batch adversarial loss: 0.346821\n",
      "epoch 126; iter: 0; batch classifier loss: 0.018544; batch adversarial loss: 0.424276\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019287; batch adversarial loss: 0.492298\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029875; batch adversarial loss: 0.492155\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015892; batch adversarial loss: 0.463138\n",
      "epoch 130; iter: 0; batch classifier loss: 0.019109; batch adversarial loss: 0.422510\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025878; batch adversarial loss: 0.464956\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053319; batch adversarial loss: 0.440773\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036704; batch adversarial loss: 0.411042\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021251; batch adversarial loss: 0.406758\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.521864\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022387; batch adversarial loss: 0.422383\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033696; batch adversarial loss: 0.405918\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053700; batch adversarial loss: 0.550395\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.390980\n",
      "epoch 140; iter: 0; batch classifier loss: 0.065234; batch adversarial loss: 0.547132\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030058; batch adversarial loss: 0.629537\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035125; batch adversarial loss: 0.408667\n",
      "epoch 143; iter: 0; batch classifier loss: 0.121881; batch adversarial loss: 0.623355\n",
      "epoch 144; iter: 0; batch classifier loss: 0.134550; batch adversarial loss: 0.686207\n",
      "epoch 145; iter: 0; batch classifier loss: 0.070216; batch adversarial loss: 0.423931\n",
      "epoch 146; iter: 0; batch classifier loss: 0.075112; batch adversarial loss: 0.484025\n",
      "epoch 147; iter: 0; batch classifier loss: 0.085496; batch adversarial loss: 0.571406\n",
      "epoch 148; iter: 0; batch classifier loss: 0.062121; batch adversarial loss: 0.505625\n",
      "epoch 149; iter: 0; batch classifier loss: 0.164360; batch adversarial loss: 0.737463\n",
      "epoch 150; iter: 0; batch classifier loss: 0.127729; batch adversarial loss: 0.659096\n",
      "epoch 151; iter: 0; batch classifier loss: 0.125393; batch adversarial loss: 0.609636\n",
      "epoch 152; iter: 0; batch classifier loss: 0.160882; batch adversarial loss: 0.705355\n",
      "epoch 153; iter: 0; batch classifier loss: 0.184527; batch adversarial loss: 0.700943\n",
      "epoch 154; iter: 0; batch classifier loss: 0.206444; batch adversarial loss: 0.717146\n",
      "epoch 155; iter: 0; batch classifier loss: 0.184454; batch adversarial loss: 0.667758\n",
      "epoch 156; iter: 0; batch classifier loss: 0.123789; batch adversarial loss: 0.631910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.144982; batch adversarial loss: 0.619253\n",
      "epoch 158; iter: 0; batch classifier loss: 0.148407; batch adversarial loss: 0.610774\n",
      "epoch 159; iter: 0; batch classifier loss: 0.133785; batch adversarial loss: 0.502543\n",
      "epoch 160; iter: 0; batch classifier loss: 0.182643; batch adversarial loss: 0.497353\n",
      "epoch 161; iter: 0; batch classifier loss: 0.160100; batch adversarial loss: 0.679457\n",
      "epoch 162; iter: 0; batch classifier loss: 0.206503; batch adversarial loss: 0.625307\n",
      "epoch 163; iter: 0; batch classifier loss: 0.106172; batch adversarial loss: 0.468339\n",
      "epoch 164; iter: 0; batch classifier loss: 0.141811; batch adversarial loss: 0.625564\n",
      "epoch 165; iter: 0; batch classifier loss: 0.108995; batch adversarial loss: 0.526162\n",
      "epoch 166; iter: 0; batch classifier loss: 0.136763; batch adversarial loss: 0.502656\n",
      "epoch 167; iter: 0; batch classifier loss: 0.107621; batch adversarial loss: 0.443313\n",
      "epoch 168; iter: 0; batch classifier loss: 0.169992; batch adversarial loss: 0.580717\n",
      "epoch 169; iter: 0; batch classifier loss: 0.125830; batch adversarial loss: 0.529363\n",
      "epoch 170; iter: 0; batch classifier loss: 0.092330; batch adversarial loss: 0.473808\n",
      "epoch 171; iter: 0; batch classifier loss: 0.130678; batch adversarial loss: 0.508328\n",
      "epoch 172; iter: 0; batch classifier loss: 0.161079; batch adversarial loss: 0.483835\n",
      "epoch 173; iter: 0; batch classifier loss: 0.081338; batch adversarial loss: 0.456598\n",
      "epoch 174; iter: 0; batch classifier loss: 0.075981; batch adversarial loss: 0.411264\n",
      "epoch 175; iter: 0; batch classifier loss: 0.201970; batch adversarial loss: 0.609716\n",
      "epoch 176; iter: 0; batch classifier loss: 0.105705; batch adversarial loss: 0.541116\n",
      "epoch 177; iter: 0; batch classifier loss: 0.147798; batch adversarial loss: 0.509532\n",
      "epoch 178; iter: 0; batch classifier loss: 0.167193; batch adversarial loss: 0.555426\n",
      "epoch 179; iter: 0; batch classifier loss: 0.173746; batch adversarial loss: 0.516599\n",
      "epoch 180; iter: 0; batch classifier loss: 0.068967; batch adversarial loss: 0.416390\n",
      "epoch 181; iter: 0; batch classifier loss: 0.095345; batch adversarial loss: 0.447468\n",
      "epoch 182; iter: 0; batch classifier loss: 0.126456; batch adversarial loss: 0.406591\n",
      "epoch 183; iter: 0; batch classifier loss: 0.101435; batch adversarial loss: 0.400472\n",
      "epoch 184; iter: 0; batch classifier loss: 0.109872; batch adversarial loss: 0.493700\n",
      "epoch 185; iter: 0; batch classifier loss: 0.093445; batch adversarial loss: 0.371027\n",
      "epoch 186; iter: 0; batch classifier loss: 0.144384; batch adversarial loss: 0.459736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.142909; batch adversarial loss: 0.509503\n",
      "epoch 188; iter: 0; batch classifier loss: 0.100337; batch adversarial loss: 0.402826\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060639; batch adversarial loss: 0.413240\n",
      "epoch 190; iter: 0; batch classifier loss: 0.096996; batch adversarial loss: 0.398042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.064729; batch adversarial loss: 0.421668\n",
      "epoch 192; iter: 0; batch classifier loss: 0.036027; batch adversarial loss: 0.408609\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019811; batch adversarial loss: 0.456137\n",
      "epoch 194; iter: 0; batch classifier loss: 0.055850; batch adversarial loss: 0.568664\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022505; batch adversarial loss: 0.558730\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038140; batch adversarial loss: 0.405863\n",
      "epoch 197; iter: 0; batch classifier loss: 0.063057; batch adversarial loss: 0.437501\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049803; batch adversarial loss: 0.314163\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035187; batch adversarial loss: 0.391317\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678827; batch adversarial loss: 0.554154\n",
      "epoch 1; iter: 0; batch classifier loss: 0.388095; batch adversarial loss: 0.601068\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402762; batch adversarial loss: 0.621096\n",
      "epoch 3; iter: 0; batch classifier loss: 0.425670; batch adversarial loss: 0.631897\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525574; batch adversarial loss: 0.596628\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457888; batch adversarial loss: 0.607436\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604715; batch adversarial loss: 0.614265\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524948; batch adversarial loss: 0.595696\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519680; batch adversarial loss: 0.561048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591463; batch adversarial loss: 0.563208\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491445; batch adversarial loss: 0.529709\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400469; batch adversarial loss: 0.508593\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368864; batch adversarial loss: 0.518444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271650; batch adversarial loss: 0.441511\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308108; batch adversarial loss: 0.467066\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285242; batch adversarial loss: 0.472482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286367; batch adversarial loss: 0.390100\n",
      "epoch 17; iter: 0; batch classifier loss: 0.214082; batch adversarial loss: 0.497304\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221495; batch adversarial loss: 0.453811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 0; batch classifier loss: 0.244781; batch adversarial loss: 0.513716\n",
      "epoch 20; iter: 0; batch classifier loss: 0.234962; batch adversarial loss: 0.461260\n",
      "epoch 21; iter: 0; batch classifier loss: 0.236713; batch adversarial loss: 0.458326\n",
      "epoch 22; iter: 0; batch classifier loss: 0.195037; batch adversarial loss: 0.415732\n",
      "epoch 23; iter: 0; batch classifier loss: 0.210894; batch adversarial loss: 0.515621\n",
      "epoch 24; iter: 0; batch classifier loss: 0.207146; batch adversarial loss: 0.470095\n",
      "epoch 25; iter: 0; batch classifier loss: 0.194113; batch adversarial loss: 0.370864\n",
      "epoch 26; iter: 0; batch classifier loss: 0.157540; batch adversarial loss: 0.539553\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149354; batch adversarial loss: 0.547327\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182930; batch adversarial loss: 0.425268\n",
      "epoch 29; iter: 0; batch classifier loss: 0.184125; batch adversarial loss: 0.437547\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140992; batch adversarial loss: 0.428555\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137891; batch adversarial loss: 0.449968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167767; batch adversarial loss: 0.443190\n",
      "epoch 33; iter: 0; batch classifier loss: 0.087607; batch adversarial loss: 0.487330\n",
      "epoch 34; iter: 0; batch classifier loss: 0.087358; batch adversarial loss: 0.443143\n",
      "epoch 35; iter: 0; batch classifier loss: 0.095759; batch adversarial loss: 0.430337\n",
      "epoch 36; iter: 0; batch classifier loss: 0.152244; batch adversarial loss: 0.441350\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117352; batch adversarial loss: 0.396183\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126271; batch adversarial loss: 0.363399\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141055; batch adversarial loss: 0.466121\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104981; batch adversarial loss: 0.449181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089483; batch adversarial loss: 0.469836\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094605; batch adversarial loss: 0.451645\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098769; batch adversarial loss: 0.411045\n",
      "epoch 44; iter: 0; batch classifier loss: 0.112489; batch adversarial loss: 0.337135\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103798; batch adversarial loss: 0.386729\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110443; batch adversarial loss: 0.422389\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112044; batch adversarial loss: 0.405899\n",
      "epoch 48; iter: 0; batch classifier loss: 0.078116; batch adversarial loss: 0.548313\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098422; batch adversarial loss: 0.433274\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099988; batch adversarial loss: 0.323885\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121169; batch adversarial loss: 0.482007\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101739; batch adversarial loss: 0.409037\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080909; batch adversarial loss: 0.475611\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113238; batch adversarial loss: 0.320809\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111250; batch adversarial loss: 0.515009\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095494; batch adversarial loss: 0.424469\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118535; batch adversarial loss: 0.462527\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114758; batch adversarial loss: 0.399139\n",
      "epoch 59; iter: 0; batch classifier loss: 0.051222; batch adversarial loss: 0.513405\n",
      "epoch 60; iter: 0; batch classifier loss: 0.054567; batch adversarial loss: 0.507556\n",
      "epoch 61; iter: 0; batch classifier loss: 0.086506; batch adversarial loss: 0.525402\n",
      "epoch 62; iter: 0; batch classifier loss: 0.067539; batch adversarial loss: 0.372099\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085169; batch adversarial loss: 0.362462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107699; batch adversarial loss: 0.475391\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048538; batch adversarial loss: 0.515973\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078588; batch adversarial loss: 0.433252\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154730; batch adversarial loss: 0.347836\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151420; batch adversarial loss: 0.403337\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069451; batch adversarial loss: 0.463139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.079573; batch adversarial loss: 0.454570\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062698; batch adversarial loss: 0.485448\n",
      "epoch 72; iter: 0; batch classifier loss: 0.045294; batch adversarial loss: 0.395615\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050542; batch adversarial loss: 0.518703\n",
      "epoch 74; iter: 0; batch classifier loss: 0.105796; batch adversarial loss: 0.414489\n",
      "epoch 75; iter: 0; batch classifier loss: 0.065783; batch adversarial loss: 0.429554\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069171; batch adversarial loss: 0.464125\n",
      "epoch 77; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.460707\n",
      "epoch 78; iter: 0; batch classifier loss: 0.057725; batch adversarial loss: 0.493278\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061774; batch adversarial loss: 0.496961\n",
      "epoch 80; iter: 0; batch classifier loss: 0.089450; batch adversarial loss: 0.515684\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081148; batch adversarial loss: 0.439813\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050680; batch adversarial loss: 0.407155\n",
      "epoch 83; iter: 0; batch classifier loss: 0.114547; batch adversarial loss: 0.363922\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051374; batch adversarial loss: 0.416396\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070071; batch adversarial loss: 0.662074\n",
      "epoch 86; iter: 0; batch classifier loss: 0.094456; batch adversarial loss: 0.435037\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088955; batch adversarial loss: 0.377469\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048343; batch adversarial loss: 0.526887\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098499; batch adversarial loss: 0.420025\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059043; batch adversarial loss: 0.395312\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090108; batch adversarial loss: 0.374982\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076153; batch adversarial loss: 0.512090\n",
      "epoch 93; iter: 0; batch classifier loss: 0.118800; batch adversarial loss: 0.489855\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039239; batch adversarial loss: 0.582383\n",
      "epoch 95; iter: 0; batch classifier loss: 0.035921; batch adversarial loss: 0.552430\n",
      "epoch 96; iter: 0; batch classifier loss: 0.089746; batch adversarial loss: 0.402109\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052957; batch adversarial loss: 0.400168\n",
      "epoch 98; iter: 0; batch classifier loss: 0.080826; batch adversarial loss: 0.419447\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048665; batch adversarial loss: 0.509982\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042569; batch adversarial loss: 0.465752\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059532; batch adversarial loss: 0.402340\n",
      "epoch 102; iter: 0; batch classifier loss: 0.125292; batch adversarial loss: 0.334118\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063028; batch adversarial loss: 0.467590\n",
      "epoch 104; iter: 0; batch classifier loss: 0.028354; batch adversarial loss: 0.449585\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062817; batch adversarial loss: 0.465759\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050801; batch adversarial loss: 0.398565\n",
      "epoch 107; iter: 0; batch classifier loss: 0.078911; batch adversarial loss: 0.436885\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064450; batch adversarial loss: 0.430592\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039058; batch adversarial loss: 0.469320\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033257; batch adversarial loss: 0.485108\n",
      "epoch 111; iter: 0; batch classifier loss: 0.030498; batch adversarial loss: 0.472002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.062013; batch adversarial loss: 0.378129\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039351; batch adversarial loss: 0.518256\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054781; batch adversarial loss: 0.421149\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048886; batch adversarial loss: 0.419621\n",
      "epoch 116; iter: 0; batch classifier loss: 0.051343; batch adversarial loss: 0.455072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 117; iter: 0; batch classifier loss: 0.040247; batch adversarial loss: 0.445158\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060062; batch adversarial loss: 0.382325\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052518; batch adversarial loss: 0.443915\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054341; batch adversarial loss: 0.421438\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065451; batch adversarial loss: 0.405266\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040192; batch adversarial loss: 0.487554\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038288; batch adversarial loss: 0.505501\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047692; batch adversarial loss: 0.511861\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042690; batch adversarial loss: 0.507260\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041712; batch adversarial loss: 0.438287\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043150; batch adversarial loss: 0.448888\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.450694\n",
      "epoch 129; iter: 0; batch classifier loss: 0.044032; batch adversarial loss: 0.461382\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058991; batch adversarial loss: 0.376645\n",
      "epoch 131; iter: 0; batch classifier loss: 0.018697; batch adversarial loss: 0.307504\n",
      "epoch 132; iter: 0; batch classifier loss: 0.058002; batch adversarial loss: 0.377313\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020332; batch adversarial loss: 0.495528\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045903; batch adversarial loss: 0.506885\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029621; batch adversarial loss: 0.365057\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042772; batch adversarial loss: 0.591040\n",
      "epoch 137; iter: 0; batch classifier loss: 0.009022; batch adversarial loss: 0.484093\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034012; batch adversarial loss: 0.448428\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026626; batch adversarial loss: 0.544609\n",
      "epoch 140; iter: 0; batch classifier loss: 0.069646; batch adversarial loss: 0.497180\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015962; batch adversarial loss: 0.396499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014959; batch adversarial loss: 0.435993\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032555; batch adversarial loss: 0.474106\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020620; batch adversarial loss: 0.442154\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043994; batch adversarial loss: 0.453700\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024630; batch adversarial loss: 0.369464\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036543; batch adversarial loss: 0.440166\n",
      "epoch 148; iter: 0; batch classifier loss: 0.075395; batch adversarial loss: 0.465979\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023597; batch adversarial loss: 0.523452\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012578; batch adversarial loss: 0.425995\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022114; batch adversarial loss: 0.408669\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018058; batch adversarial loss: 0.502268\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037892; batch adversarial loss: 0.542937\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010336; batch adversarial loss: 0.422866\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040613; batch adversarial loss: 0.479617\n",
      "epoch 156; iter: 0; batch classifier loss: 0.007604; batch adversarial loss: 0.514965\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037125; batch adversarial loss: 0.435027\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015162; batch adversarial loss: 0.428222\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021126; batch adversarial loss: 0.427785\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012147; batch adversarial loss: 0.450517\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014325; batch adversarial loss: 0.500816\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013859; batch adversarial loss: 0.457797\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052288; batch adversarial loss: 0.351536\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019695; batch adversarial loss: 0.456828\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012522; batch adversarial loss: 0.460251\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.366984\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013844; batch adversarial loss: 0.484988\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024236; batch adversarial loss: 0.522013\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031341; batch adversarial loss: 0.400050\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030379; batch adversarial loss: 0.448006\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005826; batch adversarial loss: 0.452635\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026673; batch adversarial loss: 0.393098\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030562; batch adversarial loss: 0.526287\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.482174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018200; batch adversarial loss: 0.360304\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028300; batch adversarial loss: 0.420250\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026858; batch adversarial loss: 0.398578\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037992; batch adversarial loss: 0.397355\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026847; batch adversarial loss: 0.461425\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026179; batch adversarial loss: 0.487701\n",
      "epoch 181; iter: 0; batch classifier loss: 0.005057; batch adversarial loss: 0.374760\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036972; batch adversarial loss: 0.446340\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008658; batch adversarial loss: 0.380914\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011848; batch adversarial loss: 0.472673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028621; batch adversarial loss: 0.496139\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017057; batch adversarial loss: 0.509546\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008490; batch adversarial loss: 0.415790\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003238; batch adversarial loss: 0.513345\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013300; batch adversarial loss: 0.482852\n",
      "epoch 190; iter: 0; batch classifier loss: 0.004543; batch adversarial loss: 0.480750\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010325; batch adversarial loss: 0.435849\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011370; batch adversarial loss: 0.440122\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039719; batch adversarial loss: 0.378115\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031383; batch adversarial loss: 0.464780\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029577; batch adversarial loss: 0.425468\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015971; batch adversarial loss: 0.560466\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039123; batch adversarial loss: 0.391052\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020024; batch adversarial loss: 0.411082\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032220; batch adversarial loss: 0.399391\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699270; batch adversarial loss: 0.576204\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417772; batch adversarial loss: 0.615321\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338384; batch adversarial loss: 0.609501\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362709; batch adversarial loss: 0.587184\n",
      "epoch 4; iter: 0; batch classifier loss: 0.365616; batch adversarial loss: 0.533729\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279186; batch adversarial loss: 0.542619\n",
      "epoch 6; iter: 0; batch classifier loss: 0.298636; batch adversarial loss: 0.514305\n",
      "epoch 7; iter: 0; batch classifier loss: 0.261535; batch adversarial loss: 0.536759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294827; batch adversarial loss: 0.525590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299621; batch adversarial loss: 0.581189\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258563; batch adversarial loss: 0.518652\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283433; batch adversarial loss: 0.593696\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295352; batch adversarial loss: 0.591229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308353; batch adversarial loss: 0.530617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.343059; batch adversarial loss: 0.546919\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358997; batch adversarial loss: 0.557387\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381058; batch adversarial loss: 0.511323\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399614; batch adversarial loss: 0.548238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258599; batch adversarial loss: 0.480896\n",
      "epoch 19; iter: 0; batch classifier loss: 0.219753; batch adversarial loss: 0.489529\n",
      "epoch 20; iter: 0; batch classifier loss: 0.144171; batch adversarial loss: 0.522827\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197887; batch adversarial loss: 0.473936\n",
      "epoch 22; iter: 0; batch classifier loss: 0.206308; batch adversarial loss: 0.486992\n",
      "epoch 23; iter: 0; batch classifier loss: 0.201751; batch adversarial loss: 0.516231\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161004; batch adversarial loss: 0.459570\n",
      "epoch 25; iter: 0; batch classifier loss: 0.139601; batch adversarial loss: 0.460267\n",
      "epoch 26; iter: 0; batch classifier loss: 0.143612; batch adversarial loss: 0.564321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.157527; batch adversarial loss: 0.506634\n",
      "epoch 28; iter: 0; batch classifier loss: 0.110332; batch adversarial loss: 0.350874\n",
      "epoch 29; iter: 0; batch classifier loss: 0.126604; batch adversarial loss: 0.488055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.127261; batch adversarial loss: 0.562369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190144; batch adversarial loss: 0.469056\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123179; batch adversarial loss: 0.469287\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133300; batch adversarial loss: 0.400382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088557; batch adversarial loss: 0.433209\n",
      "epoch 35; iter: 0; batch classifier loss: 0.167251; batch adversarial loss: 0.419243\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114012; batch adversarial loss: 0.469706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.069185; batch adversarial loss: 0.495583\n",
      "epoch 38; iter: 0; batch classifier loss: 0.054138; batch adversarial loss: 0.500826\n",
      "epoch 39; iter: 0; batch classifier loss: 0.098020; batch adversarial loss: 0.458170\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110510; batch adversarial loss: 0.513993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135965; batch adversarial loss: 0.439508\n",
      "epoch 42; iter: 0; batch classifier loss: 0.072657; batch adversarial loss: 0.528838\n",
      "epoch 43; iter: 0; batch classifier loss: 0.124643; batch adversarial loss: 0.504083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085317; batch adversarial loss: 0.502012\n",
      "epoch 45; iter: 0; batch classifier loss: 0.120373; batch adversarial loss: 0.405281\n",
      "epoch 46; iter: 0; batch classifier loss: 0.093272; batch adversarial loss: 0.550003\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088584; batch adversarial loss: 0.453263\n",
      "epoch 48; iter: 0; batch classifier loss: 0.101698; batch adversarial loss: 0.492012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.073992; batch adversarial loss: 0.481944\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075060; batch adversarial loss: 0.451185\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079427; batch adversarial loss: 0.535080\n",
      "epoch 52; iter: 0; batch classifier loss: 0.074887; batch adversarial loss: 0.482908\n",
      "epoch 53; iter: 0; batch classifier loss: 0.059214; batch adversarial loss: 0.480158\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074955; batch adversarial loss: 0.391228\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068458; batch adversarial loss: 0.504871\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098270; batch adversarial loss: 0.481079\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092996; batch adversarial loss: 0.609894\n",
      "epoch 58; iter: 0; batch classifier loss: 0.103413; batch adversarial loss: 0.398296\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105674; batch adversarial loss: 0.452594\n",
      "epoch 60; iter: 0; batch classifier loss: 0.094966; batch adversarial loss: 0.459191\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075628; batch adversarial loss: 0.462012\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108945; batch adversarial loss: 0.545781\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117318; batch adversarial loss: 0.486377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.124356; batch adversarial loss: 0.344456\n",
      "epoch 65; iter: 0; batch classifier loss: 0.100099; batch adversarial loss: 0.390659\n",
      "epoch 66; iter: 0; batch classifier loss: 0.097095; batch adversarial loss: 0.426013\n",
      "epoch 67; iter: 0; batch classifier loss: 0.049537; batch adversarial loss: 0.472009\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064556; batch adversarial loss: 0.545056\n",
      "epoch 69; iter: 0; batch classifier loss: 0.112357; batch adversarial loss: 0.524823\n",
      "epoch 70; iter: 0; batch classifier loss: 0.071166; batch adversarial loss: 0.385698\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080837; batch adversarial loss: 0.551783\n",
      "epoch 72; iter: 0; batch classifier loss: 0.086645; batch adversarial loss: 0.423236\n",
      "epoch 73; iter: 0; batch classifier loss: 0.093539; batch adversarial loss: 0.424825\n",
      "epoch 74; iter: 0; batch classifier loss: 0.119103; batch adversarial loss: 0.465310\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122160; batch adversarial loss: 0.468820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080669; batch adversarial loss: 0.439741\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067971; batch adversarial loss: 0.439870\n",
      "epoch 78; iter: 0; batch classifier loss: 0.044796; batch adversarial loss: 0.473992\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063745; batch adversarial loss: 0.530712\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079353; batch adversarial loss: 0.412401\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066025; batch adversarial loss: 0.465374\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090769; batch adversarial loss: 0.430854\n",
      "epoch 83; iter: 0; batch classifier loss: 0.048280; batch adversarial loss: 0.438817\n",
      "epoch 84; iter: 0; batch classifier loss: 0.093933; batch adversarial loss: 0.448681\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068571; batch adversarial loss: 0.429968\n",
      "epoch 86; iter: 0; batch classifier loss: 0.066254; batch adversarial loss: 0.369306\n",
      "epoch 87; iter: 0; batch classifier loss: 0.096998; batch adversarial loss: 0.457075\n",
      "epoch 88; iter: 0; batch classifier loss: 0.040007; batch adversarial loss: 0.434276\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075473; batch adversarial loss: 0.368744\n",
      "epoch 90; iter: 0; batch classifier loss: 0.088844; batch adversarial loss: 0.445010\n",
      "epoch 91; iter: 0; batch classifier loss: 0.042598; batch adversarial loss: 0.452647\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078823; batch adversarial loss: 0.458445\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038400; batch adversarial loss: 0.437986\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076371; batch adversarial loss: 0.465280\n",
      "epoch 95; iter: 0; batch classifier loss: 0.110480; batch adversarial loss: 0.431911\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076285; batch adversarial loss: 0.442043\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040520; batch adversarial loss: 0.488900\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050428; batch adversarial loss: 0.496245\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063460; batch adversarial loss: 0.498893\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068128; batch adversarial loss: 0.403816\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057162; batch adversarial loss: 0.464142\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050375; batch adversarial loss: 0.481629\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052744; batch adversarial loss: 0.423940\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048233; batch adversarial loss: 0.417021\n",
      "epoch 105; iter: 0; batch classifier loss: 0.067919; batch adversarial loss: 0.547734\n",
      "epoch 106; iter: 0; batch classifier loss: 0.064497; batch adversarial loss: 0.487485\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037333; batch adversarial loss: 0.435747\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037641; batch adversarial loss: 0.599724\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027699; batch adversarial loss: 0.398089\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074234; batch adversarial loss: 0.489010\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063848; batch adversarial loss: 0.437421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.062654; batch adversarial loss: 0.414409\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045684; batch adversarial loss: 0.423392\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022190; batch adversarial loss: 0.495880\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037821; batch adversarial loss: 0.466956\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048301; batch adversarial loss: 0.391304\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049149; batch adversarial loss: 0.385804\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057692; batch adversarial loss: 0.404047\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038875; batch adversarial loss: 0.570077\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057687; batch adversarial loss: 0.439287\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030339; batch adversarial loss: 0.489685\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062016; batch adversarial loss: 0.525579\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030701; batch adversarial loss: 0.481799\n",
      "epoch 124; iter: 0; batch classifier loss: 0.063901; batch adversarial loss: 0.438632\n",
      "epoch 125; iter: 0; batch classifier loss: 0.043107; batch adversarial loss: 0.457833\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045746; batch adversarial loss: 0.437154\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059102; batch adversarial loss: 0.473982\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041239; batch adversarial loss: 0.495548\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049584; batch adversarial loss: 0.408813\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032343; batch adversarial loss: 0.439383\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026288; batch adversarial loss: 0.391765\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046954; batch adversarial loss: 0.405692\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044846; batch adversarial loss: 0.375024\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036609; batch adversarial loss: 0.439689\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061691; batch adversarial loss: 0.386644\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043510; batch adversarial loss: 0.439291\n",
      "epoch 137; iter: 0; batch classifier loss: 0.082480; batch adversarial loss: 0.379852\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035749; batch adversarial loss: 0.381629\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031796; batch adversarial loss: 0.469775\n",
      "epoch 140; iter: 0; batch classifier loss: 0.009466; batch adversarial loss: 0.412147\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030749; batch adversarial loss: 0.461492\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.403028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028730; batch adversarial loss: 0.415413\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047043; batch adversarial loss: 0.561635\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.457650\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021035; batch adversarial loss: 0.488745\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035355; batch adversarial loss: 0.459624\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026077; batch adversarial loss: 0.456951\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059322; batch adversarial loss: 0.540602\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033037; batch adversarial loss: 0.475048\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039629; batch adversarial loss: 0.436317\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036928; batch adversarial loss: 0.598064\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017679; batch adversarial loss: 0.445776\n",
      "epoch 154; iter: 0; batch classifier loss: 0.036895; batch adversarial loss: 0.508378\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040762; batch adversarial loss: 0.527087\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031705; batch adversarial loss: 0.459735\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016896; batch adversarial loss: 0.482259\n",
      "epoch 158; iter: 0; batch classifier loss: 0.021896; batch adversarial loss: 0.396448\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017013; batch adversarial loss: 0.426317\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030527; batch adversarial loss: 0.397271\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031209; batch adversarial loss: 0.429633\n",
      "epoch 162; iter: 0; batch classifier loss: 0.008643; batch adversarial loss: 0.488243\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.396373\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023345; batch adversarial loss: 0.451093\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019009; batch adversarial loss: 0.493363\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036337; batch adversarial loss: 0.459819\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068167; batch adversarial loss: 0.408649\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029828; batch adversarial loss: 0.478902\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012553; batch adversarial loss: 0.419826\n",
      "epoch 170; iter: 0; batch classifier loss: 0.044929; batch adversarial loss: 0.435305\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018787; batch adversarial loss: 0.474534\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012222; batch adversarial loss: 0.489810\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036046; batch adversarial loss: 0.431254\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044160; batch adversarial loss: 0.380065\n",
      "epoch 175; iter: 0; batch classifier loss: 0.061381; batch adversarial loss: 0.385193\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012978; batch adversarial loss: 0.457454\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018742; batch adversarial loss: 0.597620\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017987; batch adversarial loss: 0.489409\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009218; batch adversarial loss: 0.468792\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033022; batch adversarial loss: 0.524830\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022442; batch adversarial loss: 0.497168\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021779; batch adversarial loss: 0.408103\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016826; batch adversarial loss: 0.477634\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021434; batch adversarial loss: 0.530599\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017284; batch adversarial loss: 0.387653\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012279; batch adversarial loss: 0.519426\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042375; batch adversarial loss: 0.411180\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031966; batch adversarial loss: 0.471318\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014313; batch adversarial loss: 0.463688\n",
      "epoch 190; iter: 0; batch classifier loss: 0.047064; batch adversarial loss: 0.445221\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012346; batch adversarial loss: 0.427432\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009756; batch adversarial loss: 0.422199\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009512; batch adversarial loss: 0.365826\n",
      "epoch 194; iter: 0; batch classifier loss: 0.046645; batch adversarial loss: 0.427473\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011195; batch adversarial loss: 0.479761\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030567; batch adversarial loss: 0.420923\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026495; batch adversarial loss: 0.362718\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007084; batch adversarial loss: 0.451424\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022894; batch adversarial loss: 0.589137\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705555; batch adversarial loss: 0.793742\n",
      "epoch 1; iter: 0; batch classifier loss: 0.405769; batch adversarial loss: 0.772892\n",
      "epoch 2; iter: 0; batch classifier loss: 0.350247; batch adversarial loss: 0.743353\n",
      "epoch 3; iter: 0; batch classifier loss: 0.420668; batch adversarial loss: 0.684401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.296026; batch adversarial loss: 0.662545\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363464; batch adversarial loss: 0.636145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322872; batch adversarial loss: 0.611167\n",
      "epoch 7; iter: 0; batch classifier loss: 0.339866; batch adversarial loss: 0.591887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.331396; batch adversarial loss: 0.568385\n",
      "epoch 9; iter: 0; batch classifier loss: 0.303337; batch adversarial loss: 0.567075\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344059; batch adversarial loss: 0.495075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.237039; batch adversarial loss: 0.478224\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274712; batch adversarial loss: 0.485039\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306940; batch adversarial loss: 0.473968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.175847; batch adversarial loss: 0.454917\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291639; batch adversarial loss: 0.434302\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224461; batch adversarial loss: 0.446347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210546; batch adversarial loss: 0.416201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.170760; batch adversarial loss: 0.447023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240737; batch adversarial loss: 0.405520\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189374; batch adversarial loss: 0.387630\n",
      "epoch 21; iter: 0; batch classifier loss: 0.175941; batch adversarial loss: 0.420799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166339; batch adversarial loss: 0.432763\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177273; batch adversarial loss: 0.406515\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167345; batch adversarial loss: 0.355842\n",
      "epoch 25; iter: 0; batch classifier loss: 0.169385; batch adversarial loss: 0.348478\n",
      "epoch 26; iter: 0; batch classifier loss: 0.143633; batch adversarial loss: 0.429430\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134177; batch adversarial loss: 0.422221\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190092; batch adversarial loss: 0.398315\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162421; batch adversarial loss: 0.390192\n",
      "epoch 30; iter: 0; batch classifier loss: 0.173170; batch adversarial loss: 0.356724\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160620; batch adversarial loss: 0.332035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140444; batch adversarial loss: 0.385967\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144371; batch adversarial loss: 0.346364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.143394; batch adversarial loss: 0.392925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160748; batch adversarial loss: 0.372946\n",
      "epoch 36; iter: 0; batch classifier loss: 0.097406; batch adversarial loss: 0.375605\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133013; batch adversarial loss: 0.369221\n",
      "epoch 38; iter: 0; batch classifier loss: 0.073200; batch adversarial loss: 0.411027\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105298; batch adversarial loss: 0.376976\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091450; batch adversarial loss: 0.468240\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140319; batch adversarial loss: 0.351920\n",
      "epoch 42; iter: 0; batch classifier loss: 0.155905; batch adversarial loss: 0.436153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112088; batch adversarial loss: 0.427639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118709; batch adversarial loss: 0.429939\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103819; batch adversarial loss: 0.427476\n",
      "epoch 46; iter: 0; batch classifier loss: 0.086242; batch adversarial loss: 0.364841\n",
      "epoch 47; iter: 0; batch classifier loss: 0.107618; batch adversarial loss: 0.485580\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112066; batch adversarial loss: 0.400154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.142527; batch adversarial loss: 0.449543\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077638; batch adversarial loss: 0.406519\n",
      "epoch 51; iter: 0; batch classifier loss: 0.075803; batch adversarial loss: 0.355240\n",
      "epoch 52; iter: 0; batch classifier loss: 0.101898; batch adversarial loss: 0.426443\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091752; batch adversarial loss: 0.301195\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108005; batch adversarial loss: 0.328813\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084991; batch adversarial loss: 0.423410\n",
      "epoch 56; iter: 0; batch classifier loss: 0.088704; batch adversarial loss: 0.445403\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.438103\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082964; batch adversarial loss: 0.436407\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084840; batch adversarial loss: 0.322475\n",
      "epoch 60; iter: 0; batch classifier loss: 0.097279; batch adversarial loss: 0.330429\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094873; batch adversarial loss: 0.410477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047241; batch adversarial loss: 0.450776\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081545; batch adversarial loss: 0.472349\n",
      "epoch 64; iter: 0; batch classifier loss: 0.052259; batch adversarial loss: 0.489444\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107964; batch adversarial loss: 0.398592\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105761; batch adversarial loss: 0.366905\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065360; batch adversarial loss: 0.374200\n",
      "epoch 68; iter: 0; batch classifier loss: 0.043270; batch adversarial loss: 0.413291\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092085; batch adversarial loss: 0.439336\n",
      "epoch 70; iter: 0; batch classifier loss: 0.089964; batch adversarial loss: 0.347362\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063380; batch adversarial loss: 0.462950\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092954; batch adversarial loss: 0.418220\n",
      "epoch 73; iter: 0; batch classifier loss: 0.055665; batch adversarial loss: 0.447179\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067083; batch adversarial loss: 0.316274\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080048; batch adversarial loss: 0.454206\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060417; batch adversarial loss: 0.615647\n",
      "epoch 77; iter: 0; batch classifier loss: 0.039286; batch adversarial loss: 0.384891\n",
      "epoch 78; iter: 0; batch classifier loss: 0.125721; batch adversarial loss: 0.412641\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064063; batch adversarial loss: 0.394739\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078391; batch adversarial loss: 0.438514\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062172; batch adversarial loss: 0.427206\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067755; batch adversarial loss: 0.365346\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044418; batch adversarial loss: 0.399506\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048722; batch adversarial loss: 0.385517\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090664; batch adversarial loss: 0.361746\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073510; batch adversarial loss: 0.494493\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042619; batch adversarial loss: 0.439337\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057409; batch adversarial loss: 0.480016\n",
      "epoch 89; iter: 0; batch classifier loss: 0.049036; batch adversarial loss: 0.383765\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037463; batch adversarial loss: 0.364721\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087508; batch adversarial loss: 0.386295\n",
      "epoch 92; iter: 0; batch classifier loss: 0.075284; batch adversarial loss: 0.442536\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033962; batch adversarial loss: 0.448340\n",
      "epoch 94; iter: 0; batch classifier loss: 0.024790; batch adversarial loss: 0.409578\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040293; batch adversarial loss: 0.488819\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039119; batch adversarial loss: 0.436892\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056561; batch adversarial loss: 0.374915\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035885; batch adversarial loss: 0.416751\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040470; batch adversarial loss: 0.384599\n",
      "epoch 100; iter: 0; batch classifier loss: 0.028300; batch adversarial loss: 0.402764\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039488; batch adversarial loss: 0.529703\n",
      "epoch 102; iter: 0; batch classifier loss: 0.053502; batch adversarial loss: 0.466128\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057885; batch adversarial loss: 0.338614\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054797; batch adversarial loss: 0.488897\n",
      "epoch 105; iter: 0; batch classifier loss: 0.033207; batch adversarial loss: 0.455138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.036476; batch adversarial loss: 0.398878\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027108; batch adversarial loss: 0.420585\n",
      "epoch 108; iter: 0; batch classifier loss: 0.022724; batch adversarial loss: 0.471719\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039333; batch adversarial loss: 0.382488\n",
      "epoch 110; iter: 0; batch classifier loss: 0.015160; batch adversarial loss: 0.522202\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027059; batch adversarial loss: 0.434794\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033038; batch adversarial loss: 0.511083\n",
      "epoch 113; iter: 0; batch classifier loss: 0.045816; batch adversarial loss: 0.475531\n",
      "epoch 114; iter: 0; batch classifier loss: 0.013497; batch adversarial loss: 0.474355\n",
      "epoch 115; iter: 0; batch classifier loss: 0.009458; batch adversarial loss: 0.521730\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060897; batch adversarial loss: 0.446790\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034396; batch adversarial loss: 0.500183\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057396; batch adversarial loss: 0.410944\n",
      "epoch 119; iter: 0; batch classifier loss: 0.018732; batch adversarial loss: 0.375516\n",
      "epoch 120; iter: 0; batch classifier loss: 0.070439; batch adversarial loss: 0.421401\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051171; batch adversarial loss: 0.444451\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037481; batch adversarial loss: 0.553859\n",
      "epoch 123; iter: 0; batch classifier loss: 0.070433; batch adversarial loss: 0.545837\n",
      "epoch 124; iter: 0; batch classifier loss: 0.086369; batch adversarial loss: 0.617964\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026311; batch adversarial loss: 0.443543\n",
      "epoch 126; iter: 0; batch classifier loss: 0.083992; batch adversarial loss: 0.559666\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069277; batch adversarial loss: 0.441606\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070216; batch adversarial loss: 0.495303\n",
      "epoch 129; iter: 0; batch classifier loss: 0.120013; batch adversarial loss: 0.604846\n",
      "epoch 130; iter: 0; batch classifier loss: 0.178653; batch adversarial loss: 0.792668\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049297; batch adversarial loss: 0.421143\n",
      "epoch 132; iter: 0; batch classifier loss: 0.124764; batch adversarial loss: 0.544121\n",
      "epoch 133; iter: 0; batch classifier loss: 0.183812; batch adversarial loss: 0.620035\n",
      "epoch 134; iter: 0; batch classifier loss: 0.103186; batch adversarial loss: 0.541781\n",
      "epoch 135; iter: 0; batch classifier loss: 0.076613; batch adversarial loss: 0.545555\n",
      "epoch 136; iter: 0; batch classifier loss: 0.130619; batch adversarial loss: 0.516645\n",
      "epoch 137; iter: 0; batch classifier loss: 0.180725; batch adversarial loss: 0.675912\n",
      "epoch 138; iter: 0; batch classifier loss: 0.097838; batch adversarial loss: 0.572038\n",
      "epoch 139; iter: 0; batch classifier loss: 0.097952; batch adversarial loss: 0.551071\n",
      "epoch 140; iter: 0; batch classifier loss: 0.095996; batch adversarial loss: 0.519888\n",
      "epoch 141; iter: 0; batch classifier loss: 0.161186; batch adversarial loss: 0.615727\n",
      "epoch 142; iter: 0; batch classifier loss: 0.098892; batch adversarial loss: 0.476603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.170984; batch adversarial loss: 0.552812\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163205; batch adversarial loss: 0.583789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.160459; batch adversarial loss: 0.543397\n",
      "epoch 146; iter: 0; batch classifier loss: 0.105926; batch adversarial loss: 0.526318\n",
      "epoch 147; iter: 0; batch classifier loss: 0.128437; batch adversarial loss: 0.606822\n",
      "epoch 148; iter: 0; batch classifier loss: 0.130391; batch adversarial loss: 0.624807\n",
      "epoch 149; iter: 0; batch classifier loss: 0.122925; batch adversarial loss: 0.552318\n",
      "epoch 150; iter: 0; batch classifier loss: 0.117497; batch adversarial loss: 0.534100\n",
      "epoch 151; iter: 0; batch classifier loss: 0.121567; batch adversarial loss: 0.535842\n",
      "epoch 152; iter: 0; batch classifier loss: 0.113658; batch adversarial loss: 0.460819\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056843; batch adversarial loss: 0.430373\n",
      "epoch 154; iter: 0; batch classifier loss: 0.082800; batch adversarial loss: 0.457468\n",
      "epoch 155; iter: 0; batch classifier loss: 0.106819; batch adversarial loss: 0.488052\n",
      "epoch 156; iter: 0; batch classifier loss: 0.121434; batch adversarial loss: 0.471177\n",
      "epoch 157; iter: 0; batch classifier loss: 0.108390; batch adversarial loss: 0.522723\n",
      "epoch 158; iter: 0; batch classifier loss: 0.073426; batch adversarial loss: 0.489505\n",
      "epoch 159; iter: 0; batch classifier loss: 0.100925; batch adversarial loss: 0.558258\n",
      "epoch 160; iter: 0; batch classifier loss: 0.078878; batch adversarial loss: 0.385557\n",
      "epoch 161; iter: 0; batch classifier loss: 0.098009; batch adversarial loss: 0.487009\n",
      "epoch 162; iter: 0; batch classifier loss: 0.078959; batch adversarial loss: 0.466775\n",
      "epoch 163; iter: 0; batch classifier loss: 0.067566; batch adversarial loss: 0.460199\n",
      "epoch 164; iter: 0; batch classifier loss: 0.106320; batch adversarial loss: 0.354101\n",
      "epoch 165; iter: 0; batch classifier loss: 0.092709; batch adversarial loss: 0.429696\n",
      "epoch 166; iter: 0; batch classifier loss: 0.120253; batch adversarial loss: 0.539188\n",
      "epoch 167; iter: 0; batch classifier loss: 0.106736; batch adversarial loss: 0.459336\n",
      "epoch 168; iter: 0; batch classifier loss: 0.055441; batch adversarial loss: 0.477363\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033893; batch adversarial loss: 0.472569\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045494; batch adversarial loss: 0.478591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049059; batch adversarial loss: 0.394524\n",
      "epoch 172; iter: 0; batch classifier loss: 0.058495; batch adversarial loss: 0.519787\n",
      "epoch 173; iter: 0; batch classifier loss: 0.050298; batch adversarial loss: 0.494826\n",
      "epoch 174; iter: 0; batch classifier loss: 0.041357; batch adversarial loss: 0.445637\n",
      "epoch 175; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.474837\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041003; batch adversarial loss: 0.405832\n",
      "epoch 177; iter: 0; batch classifier loss: 0.048216; batch adversarial loss: 0.426310\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026534; batch adversarial loss: 0.448671\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025202; batch adversarial loss: 0.569897\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054955; batch adversarial loss: 0.456501\n",
      "epoch 181; iter: 0; batch classifier loss: 0.075689; batch adversarial loss: 0.518532\n",
      "epoch 182; iter: 0; batch classifier loss: 0.068528; batch adversarial loss: 0.344243\n",
      "epoch 183; iter: 0; batch classifier loss: 0.069216; batch adversarial loss: 0.387807\n",
      "epoch 184; iter: 0; batch classifier loss: 0.059108; batch adversarial loss: 0.416460\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038411; batch adversarial loss: 0.410649\n",
      "epoch 186; iter: 0; batch classifier loss: 0.092679; batch adversarial loss: 0.400470\n",
      "epoch 187; iter: 0; batch classifier loss: 0.063347; batch adversarial loss: 0.454702\n",
      "epoch 188; iter: 0; batch classifier loss: 0.115845; batch adversarial loss: 0.404631\n",
      "epoch 189; iter: 0; batch classifier loss: 0.075208; batch adversarial loss: 0.435001\n",
      "epoch 190; iter: 0; batch classifier loss: 0.087731; batch adversarial loss: 0.488169\n",
      "epoch 191; iter: 0; batch classifier loss: 0.056948; batch adversarial loss: 0.546065\n",
      "epoch 192; iter: 0; batch classifier loss: 0.064735; batch adversarial loss: 0.440626\n",
      "epoch 193; iter: 0; batch classifier loss: 0.045566; batch adversarial loss: 0.496090\n",
      "epoch 194; iter: 0; batch classifier loss: 0.060293; batch adversarial loss: 0.449692\n",
      "epoch 195; iter: 0; batch classifier loss: 0.127023; batch adversarial loss: 0.548866\n",
      "epoch 196; iter: 0; batch classifier loss: 0.089558; batch adversarial loss: 0.398549\n",
      "epoch 197; iter: 0; batch classifier loss: 0.098533; batch adversarial loss: 0.487496\n",
      "epoch 198; iter: 0; batch classifier loss: 0.056689; batch adversarial loss: 0.509881\n",
      "epoch 199; iter: 0; batch classifier loss: 0.064736; batch adversarial loss: 0.453053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702139; batch adversarial loss: 0.788357\n",
      "epoch 1; iter: 0; batch classifier loss: 0.383265; batch adversarial loss: 0.753885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.293541; batch adversarial loss: 0.707985\n",
      "epoch 3; iter: 0; batch classifier loss: 0.347441; batch adversarial loss: 0.662621\n",
      "epoch 4; iter: 0; batch classifier loss: 0.587188; batch adversarial loss: 0.644858\n",
      "epoch 5; iter: 0; batch classifier loss: 0.306733; batch adversarial loss: 0.606719\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363159; batch adversarial loss: 0.568233\n",
      "epoch 7; iter: 0; batch classifier loss: 0.358061; batch adversarial loss: 0.564021\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377994; batch adversarial loss: 0.537559\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275619; batch adversarial loss: 0.506887\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334901; batch adversarial loss: 0.531298\n",
      "epoch 11; iter: 0; batch classifier loss: 0.260670; batch adversarial loss: 0.481974\n",
      "epoch 12; iter: 0; batch classifier loss: 0.224249; batch adversarial loss: 0.515359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195074; batch adversarial loss: 0.453404\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222508; batch adversarial loss: 0.485118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260560; batch adversarial loss: 0.472294\n",
      "epoch 16; iter: 0; batch classifier loss: 0.247639; batch adversarial loss: 0.470474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.208135; batch adversarial loss: 0.450308\n",
      "epoch 18; iter: 0; batch classifier loss: 0.215823; batch adversarial loss: 0.460834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222049; batch adversarial loss: 0.428792\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163892; batch adversarial loss: 0.451349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215416; batch adversarial loss: 0.471721\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169130; batch adversarial loss: 0.480637\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211430; batch adversarial loss: 0.354036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.216554; batch adversarial loss: 0.368290\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192156; batch adversarial loss: 0.371288\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182390; batch adversarial loss: 0.401805\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162519; batch adversarial loss: 0.359952\n",
      "epoch 28; iter: 0; batch classifier loss: 0.190136; batch adversarial loss: 0.433127\n",
      "epoch 29; iter: 0; batch classifier loss: 0.161351; batch adversarial loss: 0.357825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.141187; batch adversarial loss: 0.388859\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120221; batch adversarial loss: 0.329269\n",
      "epoch 32; iter: 0; batch classifier loss: 0.141964; batch adversarial loss: 0.408147\n",
      "epoch 33; iter: 0; batch classifier loss: 0.090205; batch adversarial loss: 0.332139\n",
      "epoch 34; iter: 0; batch classifier loss: 0.097144; batch adversarial loss: 0.459463\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150390; batch adversarial loss: 0.394462\n",
      "epoch 36; iter: 0; batch classifier loss: 0.175850; batch adversarial loss: 0.404136\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148491; batch adversarial loss: 0.366930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126274; batch adversarial loss: 0.397080\n",
      "epoch 39; iter: 0; batch classifier loss: 0.082921; batch adversarial loss: 0.415259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122003; batch adversarial loss: 0.372574\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123355; batch adversarial loss: 0.399742\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110260; batch adversarial loss: 0.400609\n",
      "epoch 43; iter: 0; batch classifier loss: 0.125387; batch adversarial loss: 0.357522\n",
      "epoch 44; iter: 0; batch classifier loss: 0.120036; batch adversarial loss: 0.407087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.146236; batch adversarial loss: 0.423409\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127848; batch adversarial loss: 0.442239\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111036; batch adversarial loss: 0.406862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.096539; batch adversarial loss: 0.512733\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113715; batch adversarial loss: 0.500196\n",
      "epoch 50; iter: 0; batch classifier loss: 0.147374; batch adversarial loss: 0.509546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098591; batch adversarial loss: 0.458061\n",
      "epoch 52; iter: 0; batch classifier loss: 0.137370; batch adversarial loss: 0.400010\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098692; batch adversarial loss: 0.406610\n",
      "epoch 54; iter: 0; batch classifier loss: 0.122535; batch adversarial loss: 0.497800\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093846; batch adversarial loss: 0.495615\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071027; batch adversarial loss: 0.375270\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078741; batch adversarial loss: 0.437648\n",
      "epoch 58; iter: 0; batch classifier loss: 0.049515; batch adversarial loss: 0.376485\n",
      "epoch 59; iter: 0; batch classifier loss: 0.062386; batch adversarial loss: 0.516688\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066761; batch adversarial loss: 0.533092\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078686; batch adversarial loss: 0.446347\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082211; batch adversarial loss: 0.403752\n",
      "epoch 63; iter: 0; batch classifier loss: 0.050389; batch adversarial loss: 0.453718\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103825; batch adversarial loss: 0.463925\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118118; batch adversarial loss: 0.402066\n",
      "epoch 66; iter: 0; batch classifier loss: 0.070657; batch adversarial loss: 0.428801\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053840; batch adversarial loss: 0.437141\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065524; batch adversarial loss: 0.456028\n",
      "epoch 69; iter: 0; batch classifier loss: 0.074062; batch adversarial loss: 0.394218\n",
      "epoch 70; iter: 0; batch classifier loss: 0.078901; batch adversarial loss: 0.440720\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099301; batch adversarial loss: 0.425946\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047407; batch adversarial loss: 0.447125\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062723; batch adversarial loss: 0.388011\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102793; batch adversarial loss: 0.426991\n",
      "epoch 75; iter: 0; batch classifier loss: 0.147588; batch adversarial loss: 0.429154\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093568; batch adversarial loss: 0.372883\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062299; batch adversarial loss: 0.447272\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066880; batch adversarial loss: 0.448839\n",
      "epoch 79; iter: 0; batch classifier loss: 0.078576; batch adversarial loss: 0.389291\n",
      "epoch 80; iter: 0; batch classifier loss: 0.144843; batch adversarial loss: 0.466501\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048370; batch adversarial loss: 0.410919\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090435; batch adversarial loss: 0.577572\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092630; batch adversarial loss: 0.553879\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060877; batch adversarial loss: 0.481625\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040066; batch adversarial loss: 0.434046\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035537; batch adversarial loss: 0.330494\n",
      "epoch 87; iter: 0; batch classifier loss: 0.102798; batch adversarial loss: 0.413430\n",
      "epoch 88; iter: 0; batch classifier loss: 0.052476; batch adversarial loss: 0.446000\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046631; batch adversarial loss: 0.464170\n",
      "epoch 90; iter: 0; batch classifier loss: 0.046463; batch adversarial loss: 0.435915\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090519; batch adversarial loss: 0.436247\n",
      "epoch 92; iter: 0; batch classifier loss: 0.049048; batch adversarial loss: 0.453922\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051745; batch adversarial loss: 0.457695\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073796; batch adversarial loss: 0.374676\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038977; batch adversarial loss: 0.421314\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062023; batch adversarial loss: 0.408709\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052788; batch adversarial loss: 0.427802\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056109; batch adversarial loss: 0.403304\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064317; batch adversarial loss: 0.434870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.046158; batch adversarial loss: 0.437919\n",
      "epoch 101; iter: 0; batch classifier loss: 0.102122; batch adversarial loss: 0.435240\n",
      "epoch 102; iter: 0; batch classifier loss: 0.066765; batch adversarial loss: 0.395873\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041912; batch adversarial loss: 0.387833\n",
      "epoch 104; iter: 0; batch classifier loss: 0.090666; batch adversarial loss: 0.499921\n",
      "epoch 105; iter: 0; batch classifier loss: 0.088755; batch adversarial loss: 0.373318\n",
      "epoch 106; iter: 0; batch classifier loss: 0.083070; batch adversarial loss: 0.431352\n",
      "epoch 107; iter: 0; batch classifier loss: 0.087309; batch adversarial loss: 0.441353\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063750; batch adversarial loss: 0.501311\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088649; batch adversarial loss: 0.449788\n",
      "epoch 110; iter: 0; batch classifier loss: 0.089964; batch adversarial loss: 0.480436\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.439817\n",
      "epoch 112; iter: 0; batch classifier loss: 0.049878; batch adversarial loss: 0.497959\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057112; batch adversarial loss: 0.406735\n",
      "epoch 114; iter: 0; batch classifier loss: 0.042806; batch adversarial loss: 0.417139\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042868; batch adversarial loss: 0.362180\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048642; batch adversarial loss: 0.372517\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027811; batch adversarial loss: 0.455378\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054725; batch adversarial loss: 0.487401\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052016; batch adversarial loss: 0.370108\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055850; batch adversarial loss: 0.462863\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027575; batch adversarial loss: 0.458937\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046673; batch adversarial loss: 0.453870\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048398; batch adversarial loss: 0.441542\n",
      "epoch 124; iter: 0; batch classifier loss: 0.047516; batch adversarial loss: 0.415265\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037154; batch adversarial loss: 0.452053\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065056; batch adversarial loss: 0.553697\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026487; batch adversarial loss: 0.505917\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034280; batch adversarial loss: 0.551713\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029269; batch adversarial loss: 0.450684\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045093; batch adversarial loss: 0.508187\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015435; batch adversarial loss: 0.449310\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030522; batch adversarial loss: 0.370226\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013451; batch adversarial loss: 0.439029\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030247; batch adversarial loss: 0.391322\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047467; batch adversarial loss: 0.429599\n",
      "epoch 136; iter: 0; batch classifier loss: 0.065719; batch adversarial loss: 0.467618\n",
      "epoch 137; iter: 0; batch classifier loss: 0.086916; batch adversarial loss: 0.551957\n",
      "epoch 138; iter: 0; batch classifier loss: 0.082176; batch adversarial loss: 0.576773\n",
      "epoch 139; iter: 0; batch classifier loss: 0.089388; batch adversarial loss: 0.609601\n",
      "epoch 140; iter: 0; batch classifier loss: 0.139375; batch adversarial loss: 0.819598\n",
      "epoch 141; iter: 0; batch classifier loss: 0.112867; batch adversarial loss: 0.504174\n",
      "epoch 142; iter: 0; batch classifier loss: 0.088248; batch adversarial loss: 0.581411\n",
      "epoch 143; iter: 0; batch classifier loss: 0.121795; batch adversarial loss: 0.562133\n",
      "epoch 144; iter: 0; batch classifier loss: 0.125698; batch adversarial loss: 0.632110\n",
      "epoch 145; iter: 0; batch classifier loss: 0.142391; batch adversarial loss: 0.590155\n",
      "epoch 146; iter: 0; batch classifier loss: 0.147710; batch adversarial loss: 0.588588\n",
      "epoch 147; iter: 0; batch classifier loss: 0.157614; batch adversarial loss: 0.759821\n",
      "epoch 148; iter: 0; batch classifier loss: 0.148136; batch adversarial loss: 0.553531\n",
      "epoch 149; iter: 0; batch classifier loss: 0.208508; batch adversarial loss: 0.663449\n",
      "epoch 150; iter: 0; batch classifier loss: 0.173273; batch adversarial loss: 0.676070\n",
      "epoch 151; iter: 0; batch classifier loss: 0.178839; batch adversarial loss: 0.630241\n",
      "epoch 152; iter: 0; batch classifier loss: 0.182636; batch adversarial loss: 0.684968\n",
      "epoch 153; iter: 0; batch classifier loss: 0.112378; batch adversarial loss: 0.531678\n",
      "epoch 154; iter: 0; batch classifier loss: 0.121825; batch adversarial loss: 0.606020\n",
      "epoch 155; iter: 0; batch classifier loss: 0.144111; batch adversarial loss: 0.703338\n",
      "epoch 156; iter: 0; batch classifier loss: 0.122270; batch adversarial loss: 0.544515\n",
      "epoch 157; iter: 0; batch classifier loss: 0.171343; batch adversarial loss: 0.546429\n",
      "epoch 158; iter: 0; batch classifier loss: 0.140977; batch adversarial loss: 0.557607\n",
      "epoch 159; iter: 0; batch classifier loss: 0.291588; batch adversarial loss: 0.664295\n",
      "epoch 160; iter: 0; batch classifier loss: 0.130878; batch adversarial loss: 0.433105\n",
      "epoch 161; iter: 0; batch classifier loss: 0.113056; batch adversarial loss: 0.455370\n",
      "epoch 162; iter: 0; batch classifier loss: 0.156930; batch adversarial loss: 0.523735\n",
      "epoch 163; iter: 0; batch classifier loss: 0.147704; batch adversarial loss: 0.528304\n",
      "epoch 164; iter: 0; batch classifier loss: 0.126691; batch adversarial loss: 0.493713\n",
      "epoch 165; iter: 0; batch classifier loss: 0.124310; batch adversarial loss: 0.455938\n",
      "epoch 166; iter: 0; batch classifier loss: 0.114251; batch adversarial loss: 0.524853\n",
      "epoch 167; iter: 0; batch classifier loss: 0.202554; batch adversarial loss: 0.638180\n",
      "epoch 168; iter: 0; batch classifier loss: 0.110905; batch adversarial loss: 0.520872\n",
      "epoch 169; iter: 0; batch classifier loss: 0.146634; batch adversarial loss: 0.499984\n",
      "epoch 170; iter: 0; batch classifier loss: 0.144358; batch adversarial loss: 0.496727\n",
      "epoch 171; iter: 0; batch classifier loss: 0.172081; batch adversarial loss: 0.558375\n",
      "epoch 172; iter: 0; batch classifier loss: 0.138436; batch adversarial loss: 0.500358\n",
      "epoch 173; iter: 0; batch classifier loss: 0.126154; batch adversarial loss: 0.538440\n",
      "epoch 174; iter: 0; batch classifier loss: 0.086179; batch adversarial loss: 0.357761\n",
      "epoch 175; iter: 0; batch classifier loss: 0.075145; batch adversarial loss: 0.403380\n",
      "epoch 176; iter: 0; batch classifier loss: 0.132257; batch adversarial loss: 0.513185\n",
      "epoch 177; iter: 0; batch classifier loss: 0.129901; batch adversarial loss: 0.513778\n",
      "epoch 178; iter: 0; batch classifier loss: 0.124745; batch adversarial loss: 0.517742\n",
      "epoch 179; iter: 0; batch classifier loss: 0.153025; batch adversarial loss: 0.578506\n",
      "epoch 180; iter: 0; batch classifier loss: 0.099268; batch adversarial loss: 0.394004\n",
      "epoch 181; iter: 0; batch classifier loss: 0.142298; batch adversarial loss: 0.473480\n",
      "epoch 182; iter: 0; batch classifier loss: 0.104937; batch adversarial loss: 0.437042\n",
      "epoch 183; iter: 0; batch classifier loss: 0.073687; batch adversarial loss: 0.444257\n",
      "epoch 184; iter: 0; batch classifier loss: 0.047986; batch adversarial loss: 0.512733\n",
      "epoch 185; iter: 0; batch classifier loss: 0.052229; batch adversarial loss: 0.511638\n",
      "epoch 186; iter: 0; batch classifier loss: 0.046691; batch adversarial loss: 0.493413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026805; batch adversarial loss: 0.494371\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028684; batch adversarial loss: 0.567925\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017488; batch adversarial loss: 0.499911\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022016; batch adversarial loss: 0.429600\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037605; batch adversarial loss: 0.470468\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033929; batch adversarial loss: 0.490847\n",
      "epoch 193; iter: 0; batch classifier loss: 0.061395; batch adversarial loss: 0.401919\n",
      "epoch 194; iter: 0; batch classifier loss: 0.064021; batch adversarial loss: 0.378097\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042365; batch adversarial loss: 0.472143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.071000; batch adversarial loss: 0.448118\n",
      "epoch 197; iter: 0; batch classifier loss: 0.051808; batch adversarial loss: 0.421883\n",
      "epoch 198; iter: 0; batch classifier loss: 0.062055; batch adversarial loss: 0.421013\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029764; batch adversarial loss: 0.548989\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689379; batch adversarial loss: 0.770175\n",
      "epoch 1; iter: 0; batch classifier loss: 0.372905; batch adversarial loss: 0.735506\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376452; batch adversarial loss: 0.686441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326753; batch adversarial loss: 0.663226\n",
      "epoch 4; iter: 0; batch classifier loss: 0.371796; batch adversarial loss: 0.628711\n",
      "epoch 5; iter: 0; batch classifier loss: 0.309990; batch adversarial loss: 0.590068\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373499; batch adversarial loss: 0.584935\n",
      "epoch 7; iter: 0; batch classifier loss: 0.201392; batch adversarial loss: 0.589767\n",
      "epoch 8; iter: 0; batch classifier loss: 0.234793; batch adversarial loss: 0.516854\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333238; batch adversarial loss: 0.526671\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257825; batch adversarial loss: 0.515127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.283324; batch adversarial loss: 0.495831\n",
      "epoch 12; iter: 0; batch classifier loss: 0.248252; batch adversarial loss: 0.496661\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203959; batch adversarial loss: 0.524110\n",
      "epoch 14; iter: 0; batch classifier loss: 0.213854; batch adversarial loss: 0.498956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.130898; batch adversarial loss: 0.534844\n",
      "epoch 16; iter: 0; batch classifier loss: 0.161692; batch adversarial loss: 0.522779\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192183; batch adversarial loss: 0.481330\n",
      "epoch 18; iter: 0; batch classifier loss: 0.194185; batch adversarial loss: 0.462714\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174004; batch adversarial loss: 0.517880\n",
      "epoch 20; iter: 0; batch classifier loss: 0.140480; batch adversarial loss: 0.418783\n",
      "epoch 21; iter: 0; batch classifier loss: 0.187590; batch adversarial loss: 0.517203\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217264; batch adversarial loss: 0.490270\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205974; batch adversarial loss: 0.453637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.173262; batch adversarial loss: 0.466705\n",
      "epoch 25; iter: 0; batch classifier loss: 0.334652; batch adversarial loss: 0.521572\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336603; batch adversarial loss: 0.480919\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312461; batch adversarial loss: 0.484102\n",
      "epoch 28; iter: 0; batch classifier loss: 0.232966; batch adversarial loss: 0.417140\n",
      "epoch 29; iter: 0; batch classifier loss: 0.108390; batch adversarial loss: 0.477877\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196882; batch adversarial loss: 0.448720\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125333; batch adversarial loss: 0.438825\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138635; batch adversarial loss: 0.519958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.191170; batch adversarial loss: 0.473649\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130412; batch adversarial loss: 0.455118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137260; batch adversarial loss: 0.470248\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121675; batch adversarial loss: 0.494135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113926; batch adversarial loss: 0.480375\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122588; batch adversarial loss: 0.408920\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125733; batch adversarial loss: 0.363050\n",
      "epoch 40; iter: 0; batch classifier loss: 0.179079; batch adversarial loss: 0.416951\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142004; batch adversarial loss: 0.448942\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135186; batch adversarial loss: 0.412459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084717; batch adversarial loss: 0.462036\n",
      "epoch 44; iter: 0; batch classifier loss: 0.171152; batch adversarial loss: 0.479620\n",
      "epoch 45; iter: 0; batch classifier loss: 0.150752; batch adversarial loss: 0.582616\n",
      "epoch 46; iter: 0; batch classifier loss: 0.081648; batch adversarial loss: 0.451409\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106330; batch adversarial loss: 0.508404\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080438; batch adversarial loss: 0.431285\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094482; batch adversarial loss: 0.476864\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075421; batch adversarial loss: 0.427441\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119648; batch adversarial loss: 0.365606\n",
      "epoch 52; iter: 0; batch classifier loss: 0.063901; batch adversarial loss: 0.454944\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098746; batch adversarial loss: 0.439015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114947; batch adversarial loss: 0.427461\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125908; batch adversarial loss: 0.441500\n",
      "epoch 56; iter: 0; batch classifier loss: 0.063705; batch adversarial loss: 0.477109\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076931; batch adversarial loss: 0.413631\n",
      "epoch 58; iter: 0; batch classifier loss: 0.130411; batch adversarial loss: 0.376099\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081304; batch adversarial loss: 0.487322\n",
      "epoch 60; iter: 0; batch classifier loss: 0.056306; batch adversarial loss: 0.483385\n",
      "epoch 61; iter: 0; batch classifier loss: 0.096471; batch adversarial loss: 0.435219\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154201; batch adversarial loss: 0.390454\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124581; batch adversarial loss: 0.524106\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071069; batch adversarial loss: 0.421232\n",
      "epoch 65; iter: 0; batch classifier loss: 0.129625; batch adversarial loss: 0.472428\n",
      "epoch 66; iter: 0; batch classifier loss: 0.119629; batch adversarial loss: 0.467717\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094579; batch adversarial loss: 0.411781\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152134; batch adversarial loss: 0.473000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084517; batch adversarial loss: 0.500593\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090393; batch adversarial loss: 0.528935\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084625; batch adversarial loss: 0.504174\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054932; batch adversarial loss: 0.430931\n",
      "epoch 73; iter: 0; batch classifier loss: 0.060801; batch adversarial loss: 0.380515\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080582; batch adversarial loss: 0.472834\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082206; batch adversarial loss: 0.515043\n",
      "epoch 76; iter: 0; batch classifier loss: 0.067390; batch adversarial loss: 0.462095\n",
      "epoch 77; iter: 0; batch classifier loss: 0.093372; batch adversarial loss: 0.499681\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104096; batch adversarial loss: 0.499294\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051000; batch adversarial loss: 0.470054\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083802; batch adversarial loss: 0.367149\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058558; batch adversarial loss: 0.418361\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111834; batch adversarial loss: 0.332496\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035705; batch adversarial loss: 0.415088\n",
      "epoch 84; iter: 0; batch classifier loss: 0.124873; batch adversarial loss: 0.477733\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077507; batch adversarial loss: 0.495546\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036917; batch adversarial loss: 0.459813\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060424; batch adversarial loss: 0.452735\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059144; batch adversarial loss: 0.473975\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149916; batch adversarial loss: 0.359652\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057984; batch adversarial loss: 0.440606\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101546; batch adversarial loss: 0.403753\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071591; batch adversarial loss: 0.386802\n",
      "epoch 93; iter: 0; batch classifier loss: 0.115263; batch adversarial loss: 0.496158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.046082; batch adversarial loss: 0.462026\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046108; batch adversarial loss: 0.493129\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059336; batch adversarial loss: 0.447541\n",
      "epoch 97; iter: 0; batch classifier loss: 0.088910; batch adversarial loss: 0.470674\n",
      "epoch 98; iter: 0; batch classifier loss: 0.054360; batch adversarial loss: 0.473047\n",
      "epoch 99; iter: 0; batch classifier loss: 0.123022; batch adversarial loss: 0.467041\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056201; batch adversarial loss: 0.480179\n",
      "epoch 101; iter: 0; batch classifier loss: 0.045122; batch adversarial loss: 0.429751\n",
      "epoch 102; iter: 0; batch classifier loss: 0.050477; batch adversarial loss: 0.467893\n",
      "epoch 103; iter: 0; batch classifier loss: 0.036198; batch adversarial loss: 0.424874\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054790; batch adversarial loss: 0.469654\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034111; batch adversarial loss: 0.407394\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047576; batch adversarial loss: 0.415197\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058957; batch adversarial loss: 0.453897\n",
      "epoch 108; iter: 0; batch classifier loss: 0.072387; batch adversarial loss: 0.431826\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043760; batch adversarial loss: 0.544344\n",
      "epoch 110; iter: 0; batch classifier loss: 0.116410; batch adversarial loss: 0.438770\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050588; batch adversarial loss: 0.453272\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044294; batch adversarial loss: 0.488713\n",
      "epoch 113; iter: 0; batch classifier loss: 0.050979; batch adversarial loss: 0.445468\n",
      "epoch 114; iter: 0; batch classifier loss: 0.079962; batch adversarial loss: 0.467040\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032958; batch adversarial loss: 0.468892\n",
      "epoch 116; iter: 0; batch classifier loss: 0.098226; batch adversarial loss: 0.473386\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030777; batch adversarial loss: 0.495345\n",
      "epoch 118; iter: 0; batch classifier loss: 0.086626; batch adversarial loss: 0.409197\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045112; batch adversarial loss: 0.439292\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048572; batch adversarial loss: 0.353074\n",
      "epoch 121; iter: 0; batch classifier loss: 0.052231; batch adversarial loss: 0.434361\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046993; batch adversarial loss: 0.400162\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031493; batch adversarial loss: 0.443134\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044373; batch adversarial loss: 0.400939\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027593; batch adversarial loss: 0.383475\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031422; batch adversarial loss: 0.375533\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059749; batch adversarial loss: 0.425645\n",
      "epoch 128; iter: 0; batch classifier loss: 0.030901; batch adversarial loss: 0.403920\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030923; batch adversarial loss: 0.419945\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067550; batch adversarial loss: 0.416013\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023140; batch adversarial loss: 0.411729\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.451233\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034328; batch adversarial loss: 0.452699\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044739; batch adversarial loss: 0.384337\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029044; batch adversarial loss: 0.452317\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019556; batch adversarial loss: 0.401699\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036810; batch adversarial loss: 0.497988\n",
      "epoch 138; iter: 0; batch classifier loss: 0.047357; batch adversarial loss: 0.554270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.030637; batch adversarial loss: 0.420968\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034496; batch adversarial loss: 0.418023\n",
      "epoch 141; iter: 0; batch classifier loss: 0.075036; batch adversarial loss: 0.398711\n",
      "epoch 142; iter: 0; batch classifier loss: 0.054293; batch adversarial loss: 0.367525\n",
      "epoch 143; iter: 0; batch classifier loss: 0.060038; batch adversarial loss: 0.534363\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009574; batch adversarial loss: 0.461680\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024153; batch adversarial loss: 0.415500\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028013; batch adversarial loss: 0.519031\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033079; batch adversarial loss: 0.427916\n",
      "epoch 148; iter: 0; batch classifier loss: 0.053610; batch adversarial loss: 0.353530\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015713; batch adversarial loss: 0.454043\n",
      "epoch 150; iter: 0; batch classifier loss: 0.067001; batch adversarial loss: 0.426886\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025333; batch adversarial loss: 0.409139\n",
      "epoch 152; iter: 0; batch classifier loss: 0.041014; batch adversarial loss: 0.395937\n",
      "epoch 153; iter: 0; batch classifier loss: 0.065339; batch adversarial loss: 0.400231\n",
      "epoch 154; iter: 0; batch classifier loss: 0.063465; batch adversarial loss: 0.481311\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045808; batch adversarial loss: 0.485995\n",
      "epoch 156; iter: 0; batch classifier loss: 0.011720; batch adversarial loss: 0.436752\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018252; batch adversarial loss: 0.474654\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038680; batch adversarial loss: 0.412689\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014751; batch adversarial loss: 0.410827\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042974; batch adversarial loss: 0.495828\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026234; batch adversarial loss: 0.441816\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034278; batch adversarial loss: 0.431482\n",
      "epoch 163; iter: 0; batch classifier loss: 0.018465; batch adversarial loss: 0.428625\n",
      "epoch 164; iter: 0; batch classifier loss: 0.007566; batch adversarial loss: 0.451548\n",
      "epoch 165; iter: 0; batch classifier loss: 0.061022; batch adversarial loss: 0.495170\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045677; batch adversarial loss: 0.438404\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030120; batch adversarial loss: 0.453193\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019068; batch adversarial loss: 0.571538\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021038; batch adversarial loss: 0.436409\n",
      "epoch 170; iter: 0; batch classifier loss: 0.063153; batch adversarial loss: 0.384613\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008106; batch adversarial loss: 0.427249\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020717; batch adversarial loss: 0.401371\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023796; batch adversarial loss: 0.431373\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011776; batch adversarial loss: 0.437839\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012675; batch adversarial loss: 0.521694\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041576; batch adversarial loss: 0.399617\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014169; batch adversarial loss: 0.443399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028258; batch adversarial loss: 0.403095\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019099; batch adversarial loss: 0.451897\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026313; batch adversarial loss: 0.413511\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035187; batch adversarial loss: 0.400420\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024032; batch adversarial loss: 0.499594\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012692; batch adversarial loss: 0.392862\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010081; batch adversarial loss: 0.528722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037018; batch adversarial loss: 0.473564\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032709; batch adversarial loss: 0.402181\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018157; batch adversarial loss: 0.433308\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014914; batch adversarial loss: 0.442996\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041631; batch adversarial loss: 0.581531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.045362; batch adversarial loss: 0.420399\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011986; batch adversarial loss: 0.425819\n",
      "epoch 192; iter: 0; batch classifier loss: 0.023415; batch adversarial loss: 0.485086\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016739; batch adversarial loss: 0.388821\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030278; batch adversarial loss: 0.452656\n",
      "epoch 195; iter: 0; batch classifier loss: 0.020403; batch adversarial loss: 0.375167\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018923; batch adversarial loss: 0.412365\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012243; batch adversarial loss: 0.581484\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010721; batch adversarial loss: 0.415479\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012496; batch adversarial loss: 0.498518\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683184; batch adversarial loss: 1.112903\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631652; batch adversarial loss: 1.355598\n",
      "epoch 2; iter: 0; batch classifier loss: 0.922644; batch adversarial loss: 1.440547\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017905; batch adversarial loss: 1.307104\n",
      "epoch 4; iter: 0; batch classifier loss: 1.123695; batch adversarial loss: 1.221355\n",
      "epoch 5; iter: 0; batch classifier loss: 1.003719; batch adversarial loss: 1.117391\n",
      "epoch 6; iter: 0; batch classifier loss: 1.046769; batch adversarial loss: 1.018547\n",
      "epoch 7; iter: 0; batch classifier loss: 1.016672; batch adversarial loss: 0.926445\n",
      "epoch 8; iter: 0; batch classifier loss: 1.035718; batch adversarial loss: 0.832380\n",
      "epoch 9; iter: 0; batch classifier loss: 1.015394; batch adversarial loss: 0.755428\n",
      "epoch 10; iter: 0; batch classifier loss: 1.005975; batch adversarial loss: 0.713179\n",
      "epoch 11; iter: 0; batch classifier loss: 0.781349; batch adversarial loss: 0.682794\n",
      "epoch 12; iter: 0; batch classifier loss: 0.700693; batch adversarial loss: 0.635095\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576380; batch adversarial loss: 0.607473\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349547; batch adversarial loss: 0.606918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247160; batch adversarial loss: 0.523434\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255045; batch adversarial loss: 0.497777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.259239; batch adversarial loss: 0.465447\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211268; batch adversarial loss: 0.494886\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271724; batch adversarial loss: 0.494378\n",
      "epoch 20; iter: 0; batch classifier loss: 0.191471; batch adversarial loss: 0.467753\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204266; batch adversarial loss: 0.501987\n",
      "epoch 22; iter: 0; batch classifier loss: 0.151572; batch adversarial loss: 0.514375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175538; batch adversarial loss: 0.470687\n",
      "epoch 24; iter: 0; batch classifier loss: 0.215565; batch adversarial loss: 0.531351\n",
      "epoch 25; iter: 0; batch classifier loss: 0.181234; batch adversarial loss: 0.529773\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172422; batch adversarial loss: 0.537041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147693; batch adversarial loss: 0.465695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.099396; batch adversarial loss: 0.400813\n",
      "epoch 29; iter: 0; batch classifier loss: 0.119752; batch adversarial loss: 0.424407\n",
      "epoch 30; iter: 0; batch classifier loss: 0.097429; batch adversarial loss: 0.496444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109514; batch adversarial loss: 0.436530\n",
      "epoch 32; iter: 0; batch classifier loss: 0.092776; batch adversarial loss: 0.534767\n",
      "epoch 33; iter: 0; batch classifier loss: 0.103958; batch adversarial loss: 0.505413\n",
      "epoch 34; iter: 0; batch classifier loss: 0.145759; batch adversarial loss: 0.431587\n",
      "epoch 35; iter: 0; batch classifier loss: 0.184811; batch adversarial loss: 0.508986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.209729; batch adversarial loss: 0.476404\n",
      "epoch 37; iter: 0; batch classifier loss: 0.261450; batch adversarial loss: 0.465190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.192907; batch adversarial loss: 0.407042\n",
      "epoch 39; iter: 0; batch classifier loss: 0.249430; batch adversarial loss: 0.477818\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270574; batch adversarial loss: 0.394457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.196373; batch adversarial loss: 0.481998\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172286; batch adversarial loss: 0.488950\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225243; batch adversarial loss: 0.438603\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147824; batch adversarial loss: 0.509184\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135523; batch adversarial loss: 0.471929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154667; batch adversarial loss: 0.438562\n",
      "epoch 47; iter: 0; batch classifier loss: 0.198392; batch adversarial loss: 0.472862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.124264; batch adversarial loss: 0.469550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096839; batch adversarial loss: 0.527783\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138641; batch adversarial loss: 0.527659\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126770; batch adversarial loss: 0.477994\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096105; batch adversarial loss: 0.470734\n",
      "epoch 53; iter: 0; batch classifier loss: 0.155298; batch adversarial loss: 0.500165\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138139; batch adversarial loss: 0.401502\n",
      "epoch 55; iter: 0; batch classifier loss: 0.121501; batch adversarial loss: 0.463889\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113948; batch adversarial loss: 0.536399\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112052; batch adversarial loss: 0.504029\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124221; batch adversarial loss: 0.408749\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090757; batch adversarial loss: 0.433988\n",
      "epoch 60; iter: 0; batch classifier loss: 0.148421; batch adversarial loss: 0.618870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.083633; batch adversarial loss: 0.516613\n",
      "epoch 62; iter: 0; batch classifier loss: 0.173788; batch adversarial loss: 0.461250\n",
      "epoch 63; iter: 0; batch classifier loss: 0.163820; batch adversarial loss: 0.505057\n",
      "epoch 64; iter: 0; batch classifier loss: 0.144642; batch adversarial loss: 0.416425\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092802; batch adversarial loss: 0.506594\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090707; batch adversarial loss: 0.505865\n",
      "epoch 67; iter: 0; batch classifier loss: 0.123493; batch adversarial loss: 0.486290\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170128; batch adversarial loss: 0.477313\n",
      "epoch 69; iter: 0; batch classifier loss: 0.183709; batch adversarial loss: 0.342443\n",
      "epoch 70; iter: 0; batch classifier loss: 0.121680; batch adversarial loss: 0.455224\n",
      "epoch 71; iter: 0; batch classifier loss: 0.156596; batch adversarial loss: 0.459240\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149951; batch adversarial loss: 0.420410\n",
      "epoch 73; iter: 0; batch classifier loss: 0.133305; batch adversarial loss: 0.491155\n",
      "epoch 74; iter: 0; batch classifier loss: 0.102191; batch adversarial loss: 0.530337\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107022; batch adversarial loss: 0.449730\n",
      "epoch 76; iter: 0; batch classifier loss: 0.160376; batch adversarial loss: 0.438045\n",
      "epoch 77; iter: 0; batch classifier loss: 0.097191; batch adversarial loss: 0.498601\n",
      "epoch 78; iter: 0; batch classifier loss: 0.123244; batch adversarial loss: 0.446685\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087173; batch adversarial loss: 0.468720\n",
      "epoch 80; iter: 0; batch classifier loss: 0.106179; batch adversarial loss: 0.456006\n",
      "epoch 81; iter: 0; batch classifier loss: 0.117515; batch adversarial loss: 0.557081\n",
      "epoch 82; iter: 0; batch classifier loss: 0.095651; batch adversarial loss: 0.518122\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088885; batch adversarial loss: 0.445103\n",
      "epoch 84; iter: 0; batch classifier loss: 0.153393; batch adversarial loss: 0.506331\n",
      "epoch 85; iter: 0; batch classifier loss: 0.100513; batch adversarial loss: 0.410166\n",
      "epoch 86; iter: 0; batch classifier loss: 0.128380; batch adversarial loss: 0.493916\n",
      "epoch 87; iter: 0; batch classifier loss: 0.123096; batch adversarial loss: 0.486444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.148768; batch adversarial loss: 0.406984\n",
      "epoch 89; iter: 0; batch classifier loss: 0.124237; batch adversarial loss: 0.545222\n",
      "epoch 90; iter: 0; batch classifier loss: 0.135345; batch adversarial loss: 0.369401\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085582; batch adversarial loss: 0.451248\n",
      "epoch 92; iter: 0; batch classifier loss: 0.172053; batch adversarial loss: 0.432661\n",
      "epoch 93; iter: 0; batch classifier loss: 0.090735; batch adversarial loss: 0.400190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.107545; batch adversarial loss: 0.398223\n",
      "epoch 95; iter: 0; batch classifier loss: 0.131375; batch adversarial loss: 0.401079\n",
      "epoch 96; iter: 0; batch classifier loss: 0.129985; batch adversarial loss: 0.456645\n",
      "epoch 97; iter: 0; batch classifier loss: 0.128214; batch adversarial loss: 0.429968\n",
      "epoch 98; iter: 0; batch classifier loss: 0.070820; batch adversarial loss: 0.455789\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071457; batch adversarial loss: 0.524569\n",
      "epoch 100; iter: 0; batch classifier loss: 0.130852; batch adversarial loss: 0.507347\n",
      "epoch 101; iter: 0; batch classifier loss: 0.152897; batch adversarial loss: 0.403732\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085613; batch adversarial loss: 0.482644\n",
      "epoch 103; iter: 0; batch classifier loss: 0.118424; batch adversarial loss: 0.507667\n",
      "epoch 104; iter: 0; batch classifier loss: 0.105659; batch adversarial loss: 0.488367\n",
      "epoch 105; iter: 0; batch classifier loss: 0.085813; batch adversarial loss: 0.523751\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108872; batch adversarial loss: 0.400399\n",
      "epoch 107; iter: 0; batch classifier loss: 0.113455; batch adversarial loss: 0.419015\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065392; batch adversarial loss: 0.500158\n",
      "epoch 109; iter: 0; batch classifier loss: 0.127021; batch adversarial loss: 0.436694\n",
      "epoch 110; iter: 0; batch classifier loss: 0.091060; batch adversarial loss: 0.479444\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076607; batch adversarial loss: 0.420808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071729; batch adversarial loss: 0.480214\n",
      "epoch 113; iter: 0; batch classifier loss: 0.095902; batch adversarial loss: 0.377657\n",
      "epoch 114; iter: 0; batch classifier loss: 0.091929; batch adversarial loss: 0.516833\n",
      "epoch 115; iter: 0; batch classifier loss: 0.082938; batch adversarial loss: 0.401237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.087168; batch adversarial loss: 0.499433\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039549; batch adversarial loss: 0.512135\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055658; batch adversarial loss: 0.484161\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045090; batch adversarial loss: 0.426598\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033908; batch adversarial loss: 0.483015\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047786; batch adversarial loss: 0.585677\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076481; batch adversarial loss: 0.478751\n",
      "epoch 123; iter: 0; batch classifier loss: 0.084190; batch adversarial loss: 0.376423\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051020; batch adversarial loss: 0.422734\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048928; batch adversarial loss: 0.452533\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028332; batch adversarial loss: 0.464331\n",
      "epoch 127; iter: 0; batch classifier loss: 0.031033; batch adversarial loss: 0.530412\n",
      "epoch 128; iter: 0; batch classifier loss: 0.070220; batch adversarial loss: 0.402494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032730; batch adversarial loss: 0.461876\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053466; batch adversarial loss: 0.464557\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051894; batch adversarial loss: 0.463934\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041389; batch adversarial loss: 0.538629\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052225; batch adversarial loss: 0.408360\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037595; batch adversarial loss: 0.476487\n",
      "epoch 135; iter: 0; batch classifier loss: 0.060985; batch adversarial loss: 0.464406\n",
      "epoch 136; iter: 0; batch classifier loss: 0.069084; batch adversarial loss: 0.416141\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034496; batch adversarial loss: 0.395706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030967; batch adversarial loss: 0.431173\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033633; batch adversarial loss: 0.444438\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039960; batch adversarial loss: 0.440998\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029499; batch adversarial loss: 0.462533\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050032; batch adversarial loss: 0.555432\n",
      "epoch 143; iter: 0; batch classifier loss: 0.064269; batch adversarial loss: 0.398781\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031774; batch adversarial loss: 0.422283\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025956; batch adversarial loss: 0.498584\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024421; batch adversarial loss: 0.553622\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024386; batch adversarial loss: 0.417015\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072705; batch adversarial loss: 0.464053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024922; batch adversarial loss: 0.546171\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012901; batch adversarial loss: 0.465520\n",
      "epoch 151; iter: 0; batch classifier loss: 0.011484; batch adversarial loss: 0.413107\n",
      "epoch 152; iter: 0; batch classifier loss: 0.026091; batch adversarial loss: 0.391972\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052501; batch adversarial loss: 0.368310\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013442; batch adversarial loss: 0.475018\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042616; batch adversarial loss: 0.468840\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034870; batch adversarial loss: 0.571743\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046855; batch adversarial loss: 0.424731\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031789; batch adversarial loss: 0.475123\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017648; batch adversarial loss: 0.475462\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031508; batch adversarial loss: 0.465382\n",
      "epoch 161; iter: 0; batch classifier loss: 0.037473; batch adversarial loss: 0.453851\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026117; batch adversarial loss: 0.439651\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034748; batch adversarial loss: 0.508520\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030962; batch adversarial loss: 0.415037\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028071; batch adversarial loss: 0.466584\n",
      "epoch 166; iter: 0; batch classifier loss: 0.041792; batch adversarial loss: 0.487651\n",
      "epoch 167; iter: 0; batch classifier loss: 0.051697; batch adversarial loss: 0.390695\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029064; batch adversarial loss: 0.439503\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034062; batch adversarial loss: 0.452285\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011167; batch adversarial loss: 0.497702\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022418; batch adversarial loss: 0.552595\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027632; batch adversarial loss: 0.473556\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026606; batch adversarial loss: 0.477499\n",
      "epoch 174; iter: 0; batch classifier loss: 0.006166; batch adversarial loss: 0.502250\n",
      "epoch 175; iter: 0; batch classifier loss: 0.089684; batch adversarial loss: 0.480849\n",
      "epoch 176; iter: 0; batch classifier loss: 0.049365; batch adversarial loss: 0.482486\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015222; batch adversarial loss: 0.494535\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021551; batch adversarial loss: 0.567343\n",
      "epoch 179; iter: 0; batch classifier loss: 0.004972; batch adversarial loss: 0.446455\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010555; batch adversarial loss: 0.396872\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034153; batch adversarial loss: 0.423825\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038537; batch adversarial loss: 0.441882\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015712; batch adversarial loss: 0.495625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.046242; batch adversarial loss: 0.409671\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018630; batch adversarial loss: 0.515351\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022590; batch adversarial loss: 0.505927\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021750; batch adversarial loss: 0.403270\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022084; batch adversarial loss: 0.439086\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051075; batch adversarial loss: 0.503586\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024115; batch adversarial loss: 0.575015\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018929; batch adversarial loss: 0.433433\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024441; batch adversarial loss: 0.363519\n",
      "epoch 193; iter: 0; batch classifier loss: 0.041395; batch adversarial loss: 0.507861\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008415; batch adversarial loss: 0.493509\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.455270\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012887; batch adversarial loss: 0.424425\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010218; batch adversarial loss: 0.432181\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009364; batch adversarial loss: 0.454494\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036019; batch adversarial loss: 0.451474\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719298; batch adversarial loss: 0.644703\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489238; batch adversarial loss: 0.668151\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490803; batch adversarial loss: 0.612968\n",
      "epoch 3; iter: 0; batch classifier loss: 0.303930; batch adversarial loss: 0.614928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.347247; batch adversarial loss: 0.579884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.279126; batch adversarial loss: 0.531069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.317869; batch adversarial loss: 0.496998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239081; batch adversarial loss: 0.512762\n",
      "epoch 8; iter: 0; batch classifier loss: 0.282187; batch adversarial loss: 0.503644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297036; batch adversarial loss: 0.459981\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288876; batch adversarial loss: 0.503428\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231354; batch adversarial loss: 0.512301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.180549; batch adversarial loss: 0.513376\n",
      "epoch 13; iter: 0; batch classifier loss: 0.176521; batch adversarial loss: 0.457363\n",
      "epoch 14; iter: 0; batch classifier loss: 0.223099; batch adversarial loss: 0.458957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306808; batch adversarial loss: 0.475231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.178516; batch adversarial loss: 0.459941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.134671; batch adversarial loss: 0.446312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.161276; batch adversarial loss: 0.420233\n",
      "epoch 19; iter: 0; batch classifier loss: 0.156852; batch adversarial loss: 0.493987\n",
      "epoch 20; iter: 0; batch classifier loss: 0.171540; batch adversarial loss: 0.410230\n",
      "epoch 21; iter: 0; batch classifier loss: 0.139419; batch adversarial loss: 0.487703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.155693; batch adversarial loss: 0.431757\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178951; batch adversarial loss: 0.637075\n",
      "epoch 24; iter: 0; batch classifier loss: 0.146028; batch adversarial loss: 0.499636\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155148; batch adversarial loss: 0.522956\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188185; batch adversarial loss: 0.532686\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166839; batch adversarial loss: 0.508508\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161314; batch adversarial loss: 0.436770\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167930; batch adversarial loss: 0.535880\n",
      "epoch 30; iter: 0; batch classifier loss: 0.153278; batch adversarial loss: 0.493847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125158; batch adversarial loss: 0.437576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202537; batch adversarial loss: 0.499085\n",
      "epoch 33; iter: 0; batch classifier loss: 0.154844; batch adversarial loss: 0.452566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.162929; batch adversarial loss: 0.446968\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198634; batch adversarial loss: 0.435261\n",
      "epoch 36; iter: 0; batch classifier loss: 0.295961; batch adversarial loss: 0.590599\n",
      "epoch 37; iter: 0; batch classifier loss: 0.213605; batch adversarial loss: 0.491393\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247000; batch adversarial loss: 0.470210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.191347; batch adversarial loss: 0.415556\n",
      "epoch 40; iter: 0; batch classifier loss: 0.112848; batch adversarial loss: 0.431421\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120088; batch adversarial loss: 0.534130\n",
      "epoch 42; iter: 0; batch classifier loss: 0.104116; batch adversarial loss: 0.551505\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128713; batch adversarial loss: 0.488785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.107796; batch adversarial loss: 0.440465\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083503; batch adversarial loss: 0.461538\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100019; batch adversarial loss: 0.319014\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074859; batch adversarial loss: 0.438826\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084482; batch adversarial loss: 0.439263\n",
      "epoch 49; iter: 0; batch classifier loss: 0.068198; batch adversarial loss: 0.449191\n",
      "epoch 50; iter: 0; batch classifier loss: 0.068132; batch adversarial loss: 0.447893\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089933; batch adversarial loss: 0.509600\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123038; batch adversarial loss: 0.416999\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076812; batch adversarial loss: 0.525210\n",
      "epoch 54; iter: 0; batch classifier loss: 0.102092; batch adversarial loss: 0.458913\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069230; batch adversarial loss: 0.495387\n",
      "epoch 56; iter: 0; batch classifier loss: 0.051879; batch adversarial loss: 0.411080\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062124; batch adversarial loss: 0.477398\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079328; batch adversarial loss: 0.420201\n",
      "epoch 59; iter: 0; batch classifier loss: 0.071086; batch adversarial loss: 0.417014\n",
      "epoch 60; iter: 0; batch classifier loss: 0.074564; batch adversarial loss: 0.464624\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074351; batch adversarial loss: 0.437761\n",
      "epoch 62; iter: 0; batch classifier loss: 0.074914; batch adversarial loss: 0.464606\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124195; batch adversarial loss: 0.456458\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067990; batch adversarial loss: 0.489367\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077610; batch adversarial loss: 0.442568\n",
      "epoch 66; iter: 0; batch classifier loss: 0.046823; batch adversarial loss: 0.394222\n",
      "epoch 67; iter: 0; batch classifier loss: 0.040055; batch adversarial loss: 0.508793\n",
      "epoch 68; iter: 0; batch classifier loss: 0.085832; batch adversarial loss: 0.405929\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102930; batch adversarial loss: 0.462947\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069545; batch adversarial loss: 0.428256\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077033; batch adversarial loss: 0.382263\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062480; batch adversarial loss: 0.494618\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053680; batch adversarial loss: 0.477497\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086267; batch adversarial loss: 0.489318\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106266; batch adversarial loss: 0.580894\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116075; batch adversarial loss: 0.453343\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068812; batch adversarial loss: 0.398588\n",
      "epoch 78; iter: 0; batch classifier loss: 0.090442; batch adversarial loss: 0.506872\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068835; batch adversarial loss: 0.465176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107566; batch adversarial loss: 0.401666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81; iter: 0; batch classifier loss: 0.082535; batch adversarial loss: 0.483789\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043179; batch adversarial loss: 0.616387\n",
      "epoch 83; iter: 0; batch classifier loss: 0.053030; batch adversarial loss: 0.405931\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055598; batch adversarial loss: 0.394871\n",
      "epoch 85; iter: 0; batch classifier loss: 0.044808; batch adversarial loss: 0.453813\n",
      "epoch 86; iter: 0; batch classifier loss: 0.045972; batch adversarial loss: 0.531100\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061420; batch adversarial loss: 0.498215\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058838; batch adversarial loss: 0.428329\n",
      "epoch 89; iter: 0; batch classifier loss: 0.033548; batch adversarial loss: 0.429606\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083390; batch adversarial loss: 0.458855\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067549; batch adversarial loss: 0.466767\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079325; batch adversarial loss: 0.456648\n",
      "epoch 93; iter: 0; batch classifier loss: 0.111155; batch adversarial loss: 0.443717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.083083; batch adversarial loss: 0.503129\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043434; batch adversarial loss: 0.353572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.106731; batch adversarial loss: 0.490223\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032024; batch adversarial loss: 0.489577\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042940; batch adversarial loss: 0.516027\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066998; batch adversarial loss: 0.475152\n",
      "epoch 100; iter: 0; batch classifier loss: 0.138099; batch adversarial loss: 0.458605\n",
      "epoch 101; iter: 0; batch classifier loss: 0.096486; batch adversarial loss: 0.427433\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034305; batch adversarial loss: 0.429031\n",
      "epoch 103; iter: 0; batch classifier loss: 0.032509; batch adversarial loss: 0.439333\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074447; batch adversarial loss: 0.486697\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056368; batch adversarial loss: 0.445403\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029842; batch adversarial loss: 0.490409\n",
      "epoch 107; iter: 0; batch classifier loss: 0.077916; batch adversarial loss: 0.495270\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079994; batch adversarial loss: 0.394658\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042104; batch adversarial loss: 0.441985\n",
      "epoch 110; iter: 0; batch classifier loss: 0.073689; batch adversarial loss: 0.423248\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054665; batch adversarial loss: 0.442586\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071596; batch adversarial loss: 0.490123\n",
      "epoch 113; iter: 0; batch classifier loss: 0.063324; batch adversarial loss: 0.422494\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049861; batch adversarial loss: 0.565382\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036682; batch adversarial loss: 0.449251\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066240; batch adversarial loss: 0.396137\n",
      "epoch 117; iter: 0; batch classifier loss: 0.018335; batch adversarial loss: 0.465775\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071901; batch adversarial loss: 0.484106\n",
      "epoch 119; iter: 0; batch classifier loss: 0.046811; batch adversarial loss: 0.489946\n",
      "epoch 120; iter: 0; batch classifier loss: 0.068567; batch adversarial loss: 0.445788\n",
      "epoch 121; iter: 0; batch classifier loss: 0.087406; batch adversarial loss: 0.368115\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063206; batch adversarial loss: 0.526563\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047389; batch adversarial loss: 0.476676\n",
      "epoch 124; iter: 0; batch classifier loss: 0.071088; batch adversarial loss: 0.327818\n",
      "epoch 125; iter: 0; batch classifier loss: 0.019548; batch adversarial loss: 0.429167\n",
      "epoch 126; iter: 0; batch classifier loss: 0.056377; batch adversarial loss: 0.478990\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016673; batch adversarial loss: 0.442085\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050221; batch adversarial loss: 0.436607\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047010; batch adversarial loss: 0.476928\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045474; batch adversarial loss: 0.426289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020695; batch adversarial loss: 0.449204\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021878; batch adversarial loss: 0.525360\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045401; batch adversarial loss: 0.419321\n",
      "epoch 134; iter: 0; batch classifier loss: 0.083964; batch adversarial loss: 0.551523\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037396; batch adversarial loss: 0.480741\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.414961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033966; batch adversarial loss: 0.505763\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036213; batch adversarial loss: 0.433976\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043372; batch adversarial loss: 0.511847\n",
      "epoch 140; iter: 0; batch classifier loss: 0.098333; batch adversarial loss: 0.497848\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048707; batch adversarial loss: 0.370848\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021724; batch adversarial loss: 0.433197\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035235; batch adversarial loss: 0.614166\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047423; batch adversarial loss: 0.458884\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044991; batch adversarial loss: 0.502420\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034435; batch adversarial loss: 0.368812\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043324; batch adversarial loss: 0.583853\n",
      "epoch 148; iter: 0; batch classifier loss: 0.084090; batch adversarial loss: 0.434620\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043817; batch adversarial loss: 0.540878\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034572; batch adversarial loss: 0.443565\n",
      "epoch 151; iter: 0; batch classifier loss: 0.030498; batch adversarial loss: 0.363934\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051767; batch adversarial loss: 0.477807\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020726; batch adversarial loss: 0.394669\n",
      "epoch 154; iter: 0; batch classifier loss: 0.051082; batch adversarial loss: 0.395845\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028066; batch adversarial loss: 0.473817\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041415; batch adversarial loss: 0.442085\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018991; batch adversarial loss: 0.438249\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047762; batch adversarial loss: 0.405984\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026251; batch adversarial loss: 0.416339\n",
      "epoch 160; iter: 0; batch classifier loss: 0.062286; batch adversarial loss: 0.411894\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039314; batch adversarial loss: 0.440560\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017492; batch adversarial loss: 0.395724\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013840; batch adversarial loss: 0.427786\n",
      "epoch 164; iter: 0; batch classifier loss: 0.036987; batch adversarial loss: 0.488497\n",
      "epoch 165; iter: 0; batch classifier loss: 0.082052; batch adversarial loss: 0.538706\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037184; batch adversarial loss: 0.476992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037418; batch adversarial loss: 0.466991\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027904; batch adversarial loss: 0.397271\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017993; batch adversarial loss: 0.515130\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023122; batch adversarial loss: 0.410161\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037894; batch adversarial loss: 0.457171\n",
      "epoch 172; iter: 0; batch classifier loss: 0.006531; batch adversarial loss: 0.456162\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013366; batch adversarial loss: 0.437557\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039816; batch adversarial loss: 0.413772\n",
      "epoch 175; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.442169\n",
      "epoch 176; iter: 0; batch classifier loss: 0.047274; batch adversarial loss: 0.466918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 177; iter: 0; batch classifier loss: 0.021443; batch adversarial loss: 0.426586\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023108; batch adversarial loss: 0.458297\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040468; batch adversarial loss: 0.493620\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039259; batch adversarial loss: 0.443244\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016340; batch adversarial loss: 0.373884\n",
      "epoch 182; iter: 0; batch classifier loss: 0.066871; batch adversarial loss: 0.388363\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.433860\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010815; batch adversarial loss: 0.350815\n",
      "epoch 185; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.514606\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027708; batch adversarial loss: 0.510086\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038612; batch adversarial loss: 0.420331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012619; batch adversarial loss: 0.470791\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023586; batch adversarial loss: 0.433594\n",
      "epoch 190; iter: 0; batch classifier loss: 0.066549; batch adversarial loss: 0.433065\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018183; batch adversarial loss: 0.486919\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016587; batch adversarial loss: 0.382128\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024724; batch adversarial loss: 0.545382\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005213; batch adversarial loss: 0.439650\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029058; batch adversarial loss: 0.441277\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009736; batch adversarial loss: 0.516418\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035310; batch adversarial loss: 0.468190\n",
      "epoch 198; iter: 0; batch classifier loss: 0.045287; batch adversarial loss: 0.505892\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.404445\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667799; batch adversarial loss: 0.758899\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387792; batch adversarial loss: 0.709331\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393688; batch adversarial loss: 0.676934\n",
      "epoch 3; iter: 0; batch classifier loss: 0.366728; batch adversarial loss: 0.635419\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328920; batch adversarial loss: 0.609973\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357075; batch adversarial loss: 0.585953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253628; batch adversarial loss: 0.542274\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306365; batch adversarial loss: 0.512166\n",
      "epoch 8; iter: 0; batch classifier loss: 0.235636; batch adversarial loss: 0.508626\n",
      "epoch 9; iter: 0; batch classifier loss: 0.232790; batch adversarial loss: 0.489766\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218990; batch adversarial loss: 0.504921\n",
      "epoch 11; iter: 0; batch classifier loss: 0.188207; batch adversarial loss: 0.497430\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254136; batch adversarial loss: 0.495521\n",
      "epoch 13; iter: 0; batch classifier loss: 0.226219; batch adversarial loss: 0.511874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234124; batch adversarial loss: 0.514125\n",
      "epoch 15; iter: 0; batch classifier loss: 0.161032; batch adversarial loss: 0.464718\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213221; batch adversarial loss: 0.479287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.173807; batch adversarial loss: 0.406838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173212; batch adversarial loss: 0.476756\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157387; batch adversarial loss: 0.411864\n",
      "epoch 20; iter: 0; batch classifier loss: 0.199403; batch adversarial loss: 0.429150\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173955; batch adversarial loss: 0.433642\n",
      "epoch 22; iter: 0; batch classifier loss: 0.207196; batch adversarial loss: 0.491028\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207249; batch adversarial loss: 0.461001\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209374; batch adversarial loss: 0.507478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.196388; batch adversarial loss: 0.416919\n",
      "epoch 26; iter: 0; batch classifier loss: 0.192467; batch adversarial loss: 0.409683\n",
      "epoch 27; iter: 0; batch classifier loss: 0.423460; batch adversarial loss: 0.363233\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328698; batch adversarial loss: 0.487037\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221105; batch adversarial loss: 0.396025\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167965; batch adversarial loss: 0.451551\n",
      "epoch 31; iter: 0; batch classifier loss: 0.117653; batch adversarial loss: 0.401041\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166882; batch adversarial loss: 0.446293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.114413; batch adversarial loss: 0.490736\n",
      "epoch 34; iter: 0; batch classifier loss: 0.120871; batch adversarial loss: 0.501719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.089996; batch adversarial loss: 0.541475\n",
      "epoch 36; iter: 0; batch classifier loss: 0.103192; batch adversarial loss: 0.468940\n",
      "epoch 37; iter: 0; batch classifier loss: 0.148634; batch adversarial loss: 0.510718\n",
      "epoch 38; iter: 0; batch classifier loss: 0.089663; batch adversarial loss: 0.492419\n",
      "epoch 39; iter: 0; batch classifier loss: 0.214004; batch adversarial loss: 0.464794\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117179; batch adversarial loss: 0.415839\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123930; batch adversarial loss: 0.462926\n",
      "epoch 42; iter: 0; batch classifier loss: 0.116233; batch adversarial loss: 0.368158\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089550; batch adversarial loss: 0.510754\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104844; batch adversarial loss: 0.378610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093577; batch adversarial loss: 0.411741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.114512; batch adversarial loss: 0.398594\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098116; batch adversarial loss: 0.482077\n",
      "epoch 48; iter: 0; batch classifier loss: 0.061342; batch adversarial loss: 0.461522\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066723; batch adversarial loss: 0.407714\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099311; batch adversarial loss: 0.406506\n",
      "epoch 51; iter: 0; batch classifier loss: 0.086063; batch adversarial loss: 0.378746\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112231; batch adversarial loss: 0.429971\n",
      "epoch 53; iter: 0; batch classifier loss: 0.053960; batch adversarial loss: 0.482189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075568; batch adversarial loss: 0.465177\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099725; batch adversarial loss: 0.463632\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084971; batch adversarial loss: 0.450870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069776; batch adversarial loss: 0.505290\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074621; batch adversarial loss: 0.433053\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075217; batch adversarial loss: 0.435436\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077336; batch adversarial loss: 0.437366\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114555; batch adversarial loss: 0.507732\n",
      "epoch 62; iter: 0; batch classifier loss: 0.084852; batch adversarial loss: 0.463229\n",
      "epoch 63; iter: 0; batch classifier loss: 0.130096; batch adversarial loss: 0.532314\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123063; batch adversarial loss: 0.468194\n",
      "epoch 65; iter: 0; batch classifier loss: 0.073044; batch adversarial loss: 0.436261\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102202; batch adversarial loss: 0.476285\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100933; batch adversarial loss: 0.507123\n",
      "epoch 68; iter: 0; batch classifier loss: 0.091388; batch adversarial loss: 0.494273\n",
      "epoch 69; iter: 0; batch classifier loss: 0.061759; batch adversarial loss: 0.427745\n",
      "epoch 70; iter: 0; batch classifier loss: 0.067013; batch adversarial loss: 0.432242\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063108; batch adversarial loss: 0.523836\n",
      "epoch 72; iter: 0; batch classifier loss: 0.157703; batch adversarial loss: 0.327495\n",
      "epoch 73; iter: 0; batch classifier loss: 0.160164; batch adversarial loss: 0.488413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74; iter: 0; batch classifier loss: 0.075691; batch adversarial loss: 0.345756\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070003; batch adversarial loss: 0.530290\n",
      "epoch 76; iter: 0; batch classifier loss: 0.070978; batch adversarial loss: 0.489329\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061006; batch adversarial loss: 0.496024\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091994; batch adversarial loss: 0.451107\n",
      "epoch 79; iter: 0; batch classifier loss: 0.028034; batch adversarial loss: 0.463802\n",
      "epoch 80; iter: 0; batch classifier loss: 0.055080; batch adversarial loss: 0.482094\n",
      "epoch 81; iter: 0; batch classifier loss: 0.103358; batch adversarial loss: 0.356566\n",
      "epoch 82; iter: 0; batch classifier loss: 0.040325; batch adversarial loss: 0.451713\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055493; batch adversarial loss: 0.480608\n",
      "epoch 84; iter: 0; batch classifier loss: 0.096506; batch adversarial loss: 0.395864\n",
      "epoch 85; iter: 0; batch classifier loss: 0.076587; batch adversarial loss: 0.423289\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036539; batch adversarial loss: 0.460227\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077637; batch adversarial loss: 0.371641\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045822; batch adversarial loss: 0.448911\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031659; batch adversarial loss: 0.361508\n",
      "epoch 90; iter: 0; batch classifier loss: 0.097734; batch adversarial loss: 0.401826\n",
      "epoch 91; iter: 0; batch classifier loss: 0.106847; batch adversarial loss: 0.403455\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052147; batch adversarial loss: 0.476701\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072588; batch adversarial loss: 0.497718\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078796; batch adversarial loss: 0.366590\n",
      "epoch 95; iter: 0; batch classifier loss: 0.043825; batch adversarial loss: 0.459480\n",
      "epoch 96; iter: 0; batch classifier loss: 0.044824; batch adversarial loss: 0.449255\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075476; batch adversarial loss: 0.545576\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043818; batch adversarial loss: 0.403830\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061852; batch adversarial loss: 0.525392\n",
      "epoch 100; iter: 0; batch classifier loss: 0.033073; batch adversarial loss: 0.383167\n",
      "epoch 101; iter: 0; batch classifier loss: 0.017812; batch adversarial loss: 0.441731\n",
      "epoch 102; iter: 0; batch classifier loss: 0.082758; batch adversarial loss: 0.535625\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048939; batch adversarial loss: 0.511431\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082040; batch adversarial loss: 0.474574\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054559; batch adversarial loss: 0.476758\n",
      "epoch 106; iter: 0; batch classifier loss: 0.027095; batch adversarial loss: 0.436516\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063969; batch adversarial loss: 0.378913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055672; batch adversarial loss: 0.452819\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078176; batch adversarial loss: 0.475427\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051884; batch adversarial loss: 0.527550\n",
      "epoch 111; iter: 0; batch classifier loss: 0.075818; batch adversarial loss: 0.451487\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037726; batch adversarial loss: 0.345464\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055891; batch adversarial loss: 0.347999\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027071; batch adversarial loss: 0.408326\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045834; batch adversarial loss: 0.441359\n",
      "epoch 116; iter: 0; batch classifier loss: 0.095930; batch adversarial loss: 0.379316\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043627; batch adversarial loss: 0.474287\n",
      "epoch 118; iter: 0; batch classifier loss: 0.079665; batch adversarial loss: 0.487088\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047776; batch adversarial loss: 0.434994\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050466; batch adversarial loss: 0.411619\n",
      "epoch 121; iter: 0; batch classifier loss: 0.046939; batch adversarial loss: 0.494117\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034456; batch adversarial loss: 0.490253\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060286; batch adversarial loss: 0.432475\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029153; batch adversarial loss: 0.417594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047640; batch adversarial loss: 0.431598\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071443; batch adversarial loss: 0.416906\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023459; batch adversarial loss: 0.582400\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074657; batch adversarial loss: 0.367223\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034359; batch adversarial loss: 0.416842\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032455; batch adversarial loss: 0.404453\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039664; batch adversarial loss: 0.468034\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030266; batch adversarial loss: 0.391450\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018586; batch adversarial loss: 0.422239\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057472; batch adversarial loss: 0.350536\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042394; batch adversarial loss: 0.468506\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057709; batch adversarial loss: 0.430794\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031147; batch adversarial loss: 0.505995\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.434076\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021619; batch adversarial loss: 0.430020\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047877; batch adversarial loss: 0.515655\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022688; batch adversarial loss: 0.431393\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057115; batch adversarial loss: 0.475603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046814; batch adversarial loss: 0.513582\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016389; batch adversarial loss: 0.405539\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018872; batch adversarial loss: 0.521292\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027331; batch adversarial loss: 0.497619\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019132; batch adversarial loss: 0.475698\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030382; batch adversarial loss: 0.509360\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.451029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.021493; batch adversarial loss: 0.398294\n",
      "epoch 151; iter: 0; batch classifier loss: 0.051647; batch adversarial loss: 0.441383\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038216; batch adversarial loss: 0.419733\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012628; batch adversarial loss: 0.428496\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027418; batch adversarial loss: 0.431228\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016399; batch adversarial loss: 0.396846\n",
      "epoch 156; iter: 0; batch classifier loss: 0.044224; batch adversarial loss: 0.390129\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038520; batch adversarial loss: 0.468471\n",
      "epoch 158; iter: 0; batch classifier loss: 0.052963; batch adversarial loss: 0.494357\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047388; batch adversarial loss: 0.393284\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015940; batch adversarial loss: 0.381197\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021745; batch adversarial loss: 0.499902\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026396; batch adversarial loss: 0.505041\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012659; batch adversarial loss: 0.510091\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032511; batch adversarial loss: 0.465295\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034229; batch adversarial loss: 0.333827\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035464; batch adversarial loss: 0.424928\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025016; batch adversarial loss: 0.473840\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041515; batch adversarial loss: 0.409902\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049126; batch adversarial loss: 0.425709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 170; iter: 0; batch classifier loss: 0.026646; batch adversarial loss: 0.512529\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028320; batch adversarial loss: 0.521001\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011748; batch adversarial loss: 0.404726\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008475; batch adversarial loss: 0.627128\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040190; batch adversarial loss: 0.422151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.082583; batch adversarial loss: 0.407932\n",
      "epoch 176; iter: 0; batch classifier loss: 0.007045; batch adversarial loss: 0.376837\n",
      "epoch 177; iter: 0; batch classifier loss: 0.039947; batch adversarial loss: 0.409511\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017810; batch adversarial loss: 0.466201\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033367; batch adversarial loss: 0.498943\n",
      "epoch 180; iter: 0; batch classifier loss: 0.048922; batch adversarial loss: 0.479331\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049033; batch adversarial loss: 0.478142\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039122; batch adversarial loss: 0.462772\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026042; batch adversarial loss: 0.478308\n",
      "epoch 184; iter: 0; batch classifier loss: 0.007835; batch adversarial loss: 0.407969\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018489; batch adversarial loss: 0.503076\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024380; batch adversarial loss: 0.415705\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055099; batch adversarial loss: 0.448550\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032698; batch adversarial loss: 0.399167\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034163; batch adversarial loss: 0.412263\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022383; batch adversarial loss: 0.424646\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008946; batch adversarial loss: 0.418660\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025813; batch adversarial loss: 0.426261\n",
      "epoch 193; iter: 0; batch classifier loss: 0.049031; batch adversarial loss: 0.453105\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042746; batch adversarial loss: 0.438728\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047013; batch adversarial loss: 0.454912\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.380145\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008194; batch adversarial loss: 0.485990\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004965; batch adversarial loss: 0.408080\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019988; batch adversarial loss: 0.446772\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702023; batch adversarial loss: 0.587455\n",
      "epoch 1; iter: 0; batch classifier loss: 0.383767; batch adversarial loss: 0.592475\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406271; batch adversarial loss: 0.588024\n",
      "epoch 3; iter: 0; batch classifier loss: 0.302427; batch adversarial loss: 0.564643\n",
      "epoch 4; iter: 0; batch classifier loss: 0.315980; batch adversarial loss: 0.533315\n",
      "epoch 5; iter: 0; batch classifier loss: 0.248125; batch adversarial loss: 0.523490\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254347; batch adversarial loss: 0.537632\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336435; batch adversarial loss: 0.536924\n",
      "epoch 8; iter: 0; batch classifier loss: 0.237120; batch adversarial loss: 0.474152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270269; batch adversarial loss: 0.504184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.327921; batch adversarial loss: 0.515691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.238621; batch adversarial loss: 0.535253\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209232; batch adversarial loss: 0.485945\n",
      "epoch 13; iter: 0; batch classifier loss: 0.259551; batch adversarial loss: 0.518926\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232651; batch adversarial loss: 0.475260\n",
      "epoch 15; iter: 0; batch classifier loss: 0.223040; batch adversarial loss: 0.503327\n",
      "epoch 16; iter: 0; batch classifier loss: 0.237779; batch adversarial loss: 0.474598\n",
      "epoch 17; iter: 0; batch classifier loss: 0.284774; batch adversarial loss: 0.539362\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213653; batch adversarial loss: 0.561682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241449; batch adversarial loss: 0.526044\n",
      "epoch 20; iter: 0; batch classifier loss: 0.258722; batch adversarial loss: 0.444688\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285517; batch adversarial loss: 0.517571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.259755; batch adversarial loss: 0.451721\n",
      "epoch 23; iter: 0; batch classifier loss: 0.231948; batch adversarial loss: 0.473115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341383; batch adversarial loss: 0.414529\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262447; batch adversarial loss: 0.516602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404450; batch adversarial loss: 0.415944\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238218; batch adversarial loss: 0.430273\n",
      "epoch 28; iter: 0; batch classifier loss: 0.169620; batch adversarial loss: 0.386691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112370; batch adversarial loss: 0.372819\n",
      "epoch 30; iter: 0; batch classifier loss: 0.096758; batch adversarial loss: 0.495523\n",
      "epoch 31; iter: 0; batch classifier loss: 0.167508; batch adversarial loss: 0.449783\n",
      "epoch 32; iter: 0; batch classifier loss: 0.136601; batch adversarial loss: 0.431755\n",
      "epoch 33; iter: 0; batch classifier loss: 0.111765; batch adversarial loss: 0.416861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122023; batch adversarial loss: 0.535810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.112976; batch adversarial loss: 0.448923\n",
      "epoch 36; iter: 0; batch classifier loss: 0.096950; batch adversarial loss: 0.374155\n",
      "epoch 37; iter: 0; batch classifier loss: 0.053553; batch adversarial loss: 0.440122\n",
      "epoch 38; iter: 0; batch classifier loss: 0.162070; batch adversarial loss: 0.396458\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092758; batch adversarial loss: 0.476378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104128; batch adversarial loss: 0.414164\n",
      "epoch 41; iter: 0; batch classifier loss: 0.092322; batch adversarial loss: 0.503415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.093747; batch adversarial loss: 0.421343\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109423; batch adversarial loss: 0.516636\n",
      "epoch 44; iter: 0; batch classifier loss: 0.077457; batch adversarial loss: 0.421162\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123509; batch adversarial loss: 0.519883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116931; batch adversarial loss: 0.461915\n",
      "epoch 47; iter: 0; batch classifier loss: 0.098911; batch adversarial loss: 0.412724\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099838; batch adversarial loss: 0.463054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086743; batch adversarial loss: 0.503361\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096295; batch adversarial loss: 0.356116\n",
      "epoch 51; iter: 0; batch classifier loss: 0.079191; batch adversarial loss: 0.428044\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094938; batch adversarial loss: 0.397618\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085227; batch adversarial loss: 0.404622\n",
      "epoch 54; iter: 0; batch classifier loss: 0.049287; batch adversarial loss: 0.484004\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084753; batch adversarial loss: 0.437415\n",
      "epoch 56; iter: 0; batch classifier loss: 0.070813; batch adversarial loss: 0.352371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.053842; batch adversarial loss: 0.512568\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064489; batch adversarial loss: 0.395760\n",
      "epoch 59; iter: 0; batch classifier loss: 0.097959; batch adversarial loss: 0.433725\n",
      "epoch 60; iter: 0; batch classifier loss: 0.116566; batch adversarial loss: 0.382901\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069084; batch adversarial loss: 0.387323\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097053; batch adversarial loss: 0.470069\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099274; batch adversarial loss: 0.358114\n",
      "epoch 64; iter: 0; batch classifier loss: 0.070805; batch adversarial loss: 0.395950\n",
      "epoch 65; iter: 0; batch classifier loss: 0.096983; batch adversarial loss: 0.395158\n",
      "epoch 66; iter: 0; batch classifier loss: 0.042564; batch adversarial loss: 0.476505\n",
      "epoch 67; iter: 0; batch classifier loss: 0.088790; batch adversarial loss: 0.569657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68; iter: 0; batch classifier loss: 0.079945; batch adversarial loss: 0.413752\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057632; batch adversarial loss: 0.499872\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058264; batch adversarial loss: 0.466491\n",
      "epoch 71; iter: 0; batch classifier loss: 0.048062; batch adversarial loss: 0.497333\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072334; batch adversarial loss: 0.361581\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069611; batch adversarial loss: 0.394389\n",
      "epoch 74; iter: 0; batch classifier loss: 0.070167; batch adversarial loss: 0.461463\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112544; batch adversarial loss: 0.393946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060457; batch adversarial loss: 0.479102\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080280; batch adversarial loss: 0.415597\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079448; batch adversarial loss: 0.423051\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062210; batch adversarial loss: 0.395333\n",
      "epoch 80; iter: 0; batch classifier loss: 0.049412; batch adversarial loss: 0.457177\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083415; batch adversarial loss: 0.403326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.123716; batch adversarial loss: 0.434398\n",
      "epoch 83; iter: 0; batch classifier loss: 0.040867; batch adversarial loss: 0.442289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.110738; batch adversarial loss: 0.459165\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052133; batch adversarial loss: 0.443604\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056422; batch adversarial loss: 0.459061\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033907; batch adversarial loss: 0.400290\n",
      "epoch 88; iter: 0; batch classifier loss: 0.126705; batch adversarial loss: 0.443447\n",
      "epoch 89; iter: 0; batch classifier loss: 0.057898; batch adversarial loss: 0.497522\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067324; batch adversarial loss: 0.444306\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066845; batch adversarial loss: 0.496273\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065813; batch adversarial loss: 0.577364\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053231; batch adversarial loss: 0.511126\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.449754\n",
      "epoch 95; iter: 0; batch classifier loss: 0.045551; batch adversarial loss: 0.462357\n",
      "epoch 96; iter: 0; batch classifier loss: 0.054991; batch adversarial loss: 0.434594\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069273; batch adversarial loss: 0.529430\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035230; batch adversarial loss: 0.385745\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065361; batch adversarial loss: 0.338757\n",
      "epoch 100; iter: 0; batch classifier loss: 0.087301; batch adversarial loss: 0.479315\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036668; batch adversarial loss: 0.482662\n",
      "epoch 102; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.489084\n",
      "epoch 103; iter: 0; batch classifier loss: 0.080040; batch adversarial loss: 0.499678\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069232; batch adversarial loss: 0.492967\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047281; batch adversarial loss: 0.401232\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045910; batch adversarial loss: 0.443868\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032926; batch adversarial loss: 0.373501\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068593; batch adversarial loss: 0.358563\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062840; batch adversarial loss: 0.511142\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056996; batch adversarial loss: 0.417208\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023388; batch adversarial loss: 0.443666\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058290; batch adversarial loss: 0.423197\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030175; batch adversarial loss: 0.411740\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032060; batch adversarial loss: 0.477188\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062225; batch adversarial loss: 0.372215\n",
      "epoch 116; iter: 0; batch classifier loss: 0.069530; batch adversarial loss: 0.448027\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050308; batch adversarial loss: 0.402958\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031063; batch adversarial loss: 0.426337\n",
      "epoch 119; iter: 0; batch classifier loss: 0.100981; batch adversarial loss: 0.508670\n",
      "epoch 120; iter: 0; batch classifier loss: 0.019227; batch adversarial loss: 0.453884\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032951; batch adversarial loss: 0.371583\n",
      "epoch 122; iter: 0; batch classifier loss: 0.081020; batch adversarial loss: 0.386789\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.501960\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039042; batch adversarial loss: 0.454039\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039973; batch adversarial loss: 0.455500\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038289; batch adversarial loss: 0.405055\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042569; batch adversarial loss: 0.417627\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058817; batch adversarial loss: 0.468432\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041081; batch adversarial loss: 0.545431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031480; batch adversarial loss: 0.402332\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058687; batch adversarial loss: 0.405530\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059641; batch adversarial loss: 0.387214\n",
      "epoch 133; iter: 0; batch classifier loss: 0.020835; batch adversarial loss: 0.486921\n",
      "epoch 134; iter: 0; batch classifier loss: 0.078087; batch adversarial loss: 0.452523\n",
      "epoch 135; iter: 0; batch classifier loss: 0.057237; batch adversarial loss: 0.413991\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030711; batch adversarial loss: 0.571033\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078661; batch adversarial loss: 0.399638\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053351; batch adversarial loss: 0.410226\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036852; batch adversarial loss: 0.459146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015970; batch adversarial loss: 0.457798\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032784; batch adversarial loss: 0.435086\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014970; batch adversarial loss: 0.337982\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029950; batch adversarial loss: 0.449028\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036799; batch adversarial loss: 0.378789\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042703; batch adversarial loss: 0.376914\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028630; batch adversarial loss: 0.579961\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030871; batch adversarial loss: 0.449246\n",
      "epoch 148; iter: 0; batch classifier loss: 0.076298; batch adversarial loss: 0.485249\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024425; batch adversarial loss: 0.406396\n",
      "epoch 150; iter: 0; batch classifier loss: 0.042372; batch adversarial loss: 0.495137\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022706; batch adversarial loss: 0.476767\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044747; batch adversarial loss: 0.419433\n",
      "epoch 153; iter: 0; batch classifier loss: 0.093408; batch adversarial loss: 0.453057\n",
      "epoch 154; iter: 0; batch classifier loss: 0.008086; batch adversarial loss: 0.424302\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030131; batch adversarial loss: 0.455874\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008740; batch adversarial loss: 0.472534\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044783; batch adversarial loss: 0.429863\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025633; batch adversarial loss: 0.486323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014198; batch adversarial loss: 0.503431\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030535; batch adversarial loss: 0.447772\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031657; batch adversarial loss: 0.330718\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025730; batch adversarial loss: 0.402773\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016823; batch adversarial loss: 0.412336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 164; iter: 0; batch classifier loss: 0.047120; batch adversarial loss: 0.410706\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021754; batch adversarial loss: 0.410095\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019642; batch adversarial loss: 0.524724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045008; batch adversarial loss: 0.438612\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016268; batch adversarial loss: 0.388430\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023363; batch adversarial loss: 0.441399\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050410; batch adversarial loss: 0.454565\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034433; batch adversarial loss: 0.519563\n",
      "epoch 172; iter: 0; batch classifier loss: 0.043692; batch adversarial loss: 0.373918\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039489; batch adversarial loss: 0.509345\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019106; batch adversarial loss: 0.395936\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014519; batch adversarial loss: 0.440802\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030063; batch adversarial loss: 0.429168\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042222; batch adversarial loss: 0.387115\n",
      "epoch 178; iter: 0; batch classifier loss: 0.072490; batch adversarial loss: 0.368269\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029720; batch adversarial loss: 0.469372\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.397691\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049766; batch adversarial loss: 0.408043\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017650; batch adversarial loss: 0.447972\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054079; batch adversarial loss: 0.479748\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056186; batch adversarial loss: 0.477411\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041127; batch adversarial loss: 0.432762\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032810; batch adversarial loss: 0.481842\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040973; batch adversarial loss: 0.417173\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034207; batch adversarial loss: 0.517647\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021537; batch adversarial loss: 0.412822\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040108; batch adversarial loss: 0.521551\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033306; batch adversarial loss: 0.300788\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015824; batch adversarial loss: 0.446986\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029373; batch adversarial loss: 0.486684\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034797; batch adversarial loss: 0.422079\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013398; batch adversarial loss: 0.458101\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031873; batch adversarial loss: 0.385731\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027419; batch adversarial loss: 0.461056\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023600; batch adversarial loss: 0.390389\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011681; batch adversarial loss: 0.396168\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678810; batch adversarial loss: 0.632566\n",
      "epoch 1; iter: 0; batch classifier loss: 0.408099; batch adversarial loss: 0.647420\n",
      "epoch 2; iter: 0; batch classifier loss: 0.424770; batch adversarial loss: 0.591995\n",
      "epoch 3; iter: 0; batch classifier loss: 0.421843; batch adversarial loss: 0.590124\n",
      "epoch 4; iter: 0; batch classifier loss: 0.342276; batch adversarial loss: 0.548814\n",
      "epoch 5; iter: 0; batch classifier loss: 0.281530; batch adversarial loss: 0.538407\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282327; batch adversarial loss: 0.532972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.283373; batch adversarial loss: 0.516102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.219028; batch adversarial loss: 0.501288\n",
      "epoch 9; iter: 0; batch classifier loss: 0.281987; batch adversarial loss: 0.506635\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284962; batch adversarial loss: 0.500201\n",
      "epoch 11; iter: 0; batch classifier loss: 0.212906; batch adversarial loss: 0.443784\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233909; batch adversarial loss: 0.471036\n",
      "epoch 13; iter: 0; batch classifier loss: 0.167865; batch adversarial loss: 0.441168\n",
      "epoch 14; iter: 0; batch classifier loss: 0.135828; batch adversarial loss: 0.464185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.164289; batch adversarial loss: 0.389898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.171480; batch adversarial loss: 0.463882\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164885; batch adversarial loss: 0.448342\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172392; batch adversarial loss: 0.517134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176745; batch adversarial loss: 0.425330\n",
      "epoch 20; iter: 0; batch classifier loss: 0.180764; batch adversarial loss: 0.471690\n",
      "epoch 21; iter: 0; batch classifier loss: 0.182857; batch adversarial loss: 0.538015\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226523; batch adversarial loss: 0.558362\n",
      "epoch 23; iter: 0; batch classifier loss: 0.176498; batch adversarial loss: 0.557759\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169756; batch adversarial loss: 0.532682\n",
      "epoch 25; iter: 0; batch classifier loss: 0.256461; batch adversarial loss: 0.560118\n",
      "epoch 26; iter: 0; batch classifier loss: 0.267302; batch adversarial loss: 0.512481\n",
      "epoch 27; iter: 0; batch classifier loss: 0.139221; batch adversarial loss: 0.528557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.242945; batch adversarial loss: 0.585267\n",
      "epoch 29; iter: 0; batch classifier loss: 0.240274; batch adversarial loss: 0.484989\n",
      "epoch 30; iter: 0; batch classifier loss: 0.285582; batch adversarial loss: 0.504992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202580; batch adversarial loss: 0.463296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.201681; batch adversarial loss: 0.432733\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352306; batch adversarial loss: 0.488359\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367841; batch adversarial loss: 0.456487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157361; batch adversarial loss: 0.451649\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092628; batch adversarial loss: 0.561747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.099299; batch adversarial loss: 0.436660\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086881; batch adversarial loss: 0.360954\n",
      "epoch 39; iter: 0; batch classifier loss: 0.087710; batch adversarial loss: 0.416140\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095774; batch adversarial loss: 0.382400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.082639; batch adversarial loss: 0.473847\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105931; batch adversarial loss: 0.462497\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104174; batch adversarial loss: 0.395051\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075705; batch adversarial loss: 0.454507\n",
      "epoch 45; iter: 0; batch classifier loss: 0.069784; batch adversarial loss: 0.371627\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077762; batch adversarial loss: 0.493155\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125944; batch adversarial loss: 0.481351\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090603; batch adversarial loss: 0.514095\n",
      "epoch 49; iter: 0; batch classifier loss: 0.096366; batch adversarial loss: 0.539789\n",
      "epoch 50; iter: 0; batch classifier loss: 0.091147; batch adversarial loss: 0.569879\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070319; batch adversarial loss: 0.385050\n",
      "epoch 52; iter: 0; batch classifier loss: 0.055092; batch adversarial loss: 0.452873\n",
      "epoch 53; iter: 0; batch classifier loss: 0.119234; batch adversarial loss: 0.451265\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092496; batch adversarial loss: 0.477885\n",
      "epoch 55; iter: 0; batch classifier loss: 0.117128; batch adversarial loss: 0.455297\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098037; batch adversarial loss: 0.467665\n",
      "epoch 57; iter: 0; batch classifier loss: 0.092595; batch adversarial loss: 0.435214\n",
      "epoch 58; iter: 0; batch classifier loss: 0.049247; batch adversarial loss: 0.543195\n",
      "epoch 59; iter: 0; batch classifier loss: 0.090076; batch adversarial loss: 0.418366\n",
      "epoch 60; iter: 0; batch classifier loss: 0.106616; batch adversarial loss: 0.517818\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122312; batch adversarial loss: 0.311257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.094258; batch adversarial loss: 0.509104\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070036; batch adversarial loss: 0.446416\n",
      "epoch 64; iter: 0; batch classifier loss: 0.116346; batch adversarial loss: 0.483183\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078035; batch adversarial loss: 0.445429\n",
      "epoch 66; iter: 0; batch classifier loss: 0.115504; batch adversarial loss: 0.455592\n",
      "epoch 67; iter: 0; batch classifier loss: 0.114708; batch adversarial loss: 0.451330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111199; batch adversarial loss: 0.437918\n",
      "epoch 69; iter: 0; batch classifier loss: 0.129604; batch adversarial loss: 0.557007\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061680; batch adversarial loss: 0.425104\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091663; batch adversarial loss: 0.455848\n",
      "epoch 72; iter: 0; batch classifier loss: 0.093290; batch adversarial loss: 0.476936\n",
      "epoch 73; iter: 0; batch classifier loss: 0.120771; batch adversarial loss: 0.459625\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077617; batch adversarial loss: 0.444608\n",
      "epoch 75; iter: 0; batch classifier loss: 0.114091; batch adversarial loss: 0.427457\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093890; batch adversarial loss: 0.504581\n",
      "epoch 77; iter: 0; batch classifier loss: 0.118115; batch adversarial loss: 0.454412\n",
      "epoch 78; iter: 0; batch classifier loss: 0.149299; batch adversarial loss: 0.403342\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071476; batch adversarial loss: 0.498117\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097266; batch adversarial loss: 0.505696\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113565; batch adversarial loss: 0.474319\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080885; batch adversarial loss: 0.424290\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070197; batch adversarial loss: 0.452882\n",
      "epoch 84; iter: 0; batch classifier loss: 0.140128; batch adversarial loss: 0.385019\n",
      "epoch 85; iter: 0; batch classifier loss: 0.130883; batch adversarial loss: 0.383999\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084685; batch adversarial loss: 0.475819\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072137; batch adversarial loss: 0.424759\n",
      "epoch 88; iter: 0; batch classifier loss: 0.076770; batch adversarial loss: 0.446519\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037316; batch adversarial loss: 0.446464\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066303; batch adversarial loss: 0.522415\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050775; batch adversarial loss: 0.392073\n",
      "epoch 92; iter: 0; batch classifier loss: 0.139880; batch adversarial loss: 0.524484\n",
      "epoch 93; iter: 0; batch classifier loss: 0.086249; batch adversarial loss: 0.501284\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079258; batch adversarial loss: 0.518214\n",
      "epoch 95; iter: 0; batch classifier loss: 0.110561; batch adversarial loss: 0.404082\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067802; batch adversarial loss: 0.577648\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059528; batch adversarial loss: 0.447067\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035057; batch adversarial loss: 0.446922\n",
      "epoch 99; iter: 0; batch classifier loss: 0.079717; batch adversarial loss: 0.432942\n",
      "epoch 100; iter: 0; batch classifier loss: 0.056877; batch adversarial loss: 0.404452\n",
      "epoch 101; iter: 0; batch classifier loss: 0.107594; batch adversarial loss: 0.429155\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079052; batch adversarial loss: 0.405763\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086546; batch adversarial loss: 0.406741\n",
      "epoch 104; iter: 0; batch classifier loss: 0.078550; batch adversarial loss: 0.385998\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059166; batch adversarial loss: 0.498118\n",
      "epoch 106; iter: 0; batch classifier loss: 0.105181; batch adversarial loss: 0.470474\n",
      "epoch 107; iter: 0; batch classifier loss: 0.076203; batch adversarial loss: 0.495973\n",
      "epoch 108; iter: 0; batch classifier loss: 0.095937; batch adversarial loss: 0.460249\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046657; batch adversarial loss: 0.505865\n",
      "epoch 110; iter: 0; batch classifier loss: 0.060823; batch adversarial loss: 0.532037\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083600; batch adversarial loss: 0.452541\n",
      "epoch 112; iter: 0; batch classifier loss: 0.056671; batch adversarial loss: 0.472360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047738; batch adversarial loss: 0.441110\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048100; batch adversarial loss: 0.459415\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042797; batch adversarial loss: 0.582006\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045711; batch adversarial loss: 0.475006\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044861; batch adversarial loss: 0.551623\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.466351\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045033; batch adversarial loss: 0.451718\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048474; batch adversarial loss: 0.520460\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050009; batch adversarial loss: 0.475862\n",
      "epoch 122; iter: 0; batch classifier loss: 0.097018; batch adversarial loss: 0.407352\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038366; batch adversarial loss: 0.473601\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054894; batch adversarial loss: 0.404860\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067520; batch adversarial loss: 0.471978\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037709; batch adversarial loss: 0.478333\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036178; batch adversarial loss: 0.385811\n",
      "epoch 128; iter: 0; batch classifier loss: 0.050155; batch adversarial loss: 0.431187\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035615; batch adversarial loss: 0.446697\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027926; batch adversarial loss: 0.404009\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070112; batch adversarial loss: 0.359768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032425; batch adversarial loss: 0.433184\n",
      "epoch 133; iter: 0; batch classifier loss: 0.081347; batch adversarial loss: 0.498770\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064910; batch adversarial loss: 0.443740\n",
      "epoch 135; iter: 0; batch classifier loss: 0.042705; batch adversarial loss: 0.489009\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042685; batch adversarial loss: 0.438195\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053510; batch adversarial loss: 0.385931\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020002; batch adversarial loss: 0.455594\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050794; batch adversarial loss: 0.478368\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060680; batch adversarial loss: 0.409928\n",
      "epoch 141; iter: 0; batch classifier loss: 0.023952; batch adversarial loss: 0.377138\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032117; batch adversarial loss: 0.586910\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.425500\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039692; batch adversarial loss: 0.281502\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027273; batch adversarial loss: 0.554705\n",
      "epoch 146; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.469044\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019227; batch adversarial loss: 0.387873\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055446; batch adversarial loss: 0.494940\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041792; batch adversarial loss: 0.499713\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043707; batch adversarial loss: 0.477568\n",
      "epoch 151; iter: 0; batch classifier loss: 0.052124; batch adversarial loss: 0.584600\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019932; batch adversarial loss: 0.504371\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015472; batch adversarial loss: 0.394547\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015766; batch adversarial loss: 0.480635\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040568; batch adversarial loss: 0.436263\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033064; batch adversarial loss: 0.520120\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024601; batch adversarial loss: 0.465900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.010407; batch adversarial loss: 0.381057\n",
      "epoch 159; iter: 0; batch classifier loss: 0.036502; batch adversarial loss: 0.449953\n",
      "epoch 160; iter: 0; batch classifier loss: 0.061956; batch adversarial loss: 0.465264\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015276; batch adversarial loss: 0.404198\n",
      "epoch 162; iter: 0; batch classifier loss: 0.061307; batch adversarial loss: 0.350053\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036060; batch adversarial loss: 0.430577\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020227; batch adversarial loss: 0.375863\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010390; batch adversarial loss: 0.541533\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029129; batch adversarial loss: 0.560992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031953; batch adversarial loss: 0.487659\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021943; batch adversarial loss: 0.368005\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026123; batch adversarial loss: 0.397454\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048933; batch adversarial loss: 0.396573\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014879; batch adversarial loss: 0.414670\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029028; batch adversarial loss: 0.456939\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037555; batch adversarial loss: 0.346787\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035932; batch adversarial loss: 0.493548\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018592; batch adversarial loss: 0.393355\n",
      "epoch 176; iter: 0; batch classifier loss: 0.023330; batch adversarial loss: 0.486834\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023875; batch adversarial loss: 0.422643\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031672; batch adversarial loss: 0.483427\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012980; batch adversarial loss: 0.465490\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007838; batch adversarial loss: 0.321180\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023305; batch adversarial loss: 0.439971\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026437; batch adversarial loss: 0.346621\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012812; batch adversarial loss: 0.348111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005812; batch adversarial loss: 0.461877\n",
      "epoch 185; iter: 0; batch classifier loss: 0.057369; batch adversarial loss: 0.432202\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022487; batch adversarial loss: 0.455418\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025389; batch adversarial loss: 0.474034\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012229; batch adversarial loss: 0.369265\n",
      "epoch 189; iter: 0; batch classifier loss: 0.080448; batch adversarial loss: 0.465555\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021905; batch adversarial loss: 0.426339\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.449085\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028952; batch adversarial loss: 0.491081\n",
      "epoch 193; iter: 0; batch classifier loss: 0.034073; batch adversarial loss: 0.338026\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.458125\n",
      "epoch 195; iter: 0; batch classifier loss: 0.068493; batch adversarial loss: 0.465692\n",
      "epoch 196; iter: 0; batch classifier loss: 0.014355; batch adversarial loss: 0.402433\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.325976\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026148; batch adversarial loss: 0.399587\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036028; batch adversarial loss: 0.383465\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723320; batch adversarial loss: 0.665307\n",
      "epoch 1; iter: 0; batch classifier loss: 0.454079; batch adversarial loss: 0.647784\n",
      "epoch 2; iter: 0; batch classifier loss: 0.478855; batch adversarial loss: 0.635513\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409306; batch adversarial loss: 0.651540\n",
      "epoch 4; iter: 0; batch classifier loss: 0.421875; batch adversarial loss: 0.596252\n",
      "epoch 5; iter: 0; batch classifier loss: 0.361258; batch adversarial loss: 0.591610\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529112; batch adversarial loss: 0.577863\n",
      "epoch 7; iter: 0; batch classifier loss: 0.427174; batch adversarial loss: 0.557758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.472121; batch adversarial loss: 0.582138\n",
      "epoch 9; iter: 0; batch classifier loss: 0.419525; batch adversarial loss: 0.575154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372562; batch adversarial loss: 0.547432\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339577; batch adversarial loss: 0.515843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382698; batch adversarial loss: 0.533499\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349500; batch adversarial loss: 0.531347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.304012; batch adversarial loss: 0.531325\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264513; batch adversarial loss: 0.584748\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286189; batch adversarial loss: 0.510188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314769; batch adversarial loss: 0.472129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316941; batch adversarial loss: 0.494715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306059; batch adversarial loss: 0.490726\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225522; batch adversarial loss: 0.532035\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258911; batch adversarial loss: 0.563380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238078; batch adversarial loss: 0.535351\n",
      "epoch 23; iter: 0; batch classifier loss: 0.296470; batch adversarial loss: 0.400643\n",
      "epoch 24; iter: 0; batch classifier loss: 0.318175; batch adversarial loss: 0.451947\n",
      "epoch 25; iter: 0; batch classifier loss: 0.233808; batch adversarial loss: 0.459012\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224312; batch adversarial loss: 0.449278\n",
      "epoch 27; iter: 0; batch classifier loss: 0.225364; batch adversarial loss: 0.440397\n",
      "epoch 28; iter: 0; batch classifier loss: 0.261954; batch adversarial loss: 0.472258\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266463; batch adversarial loss: 0.398134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210270; batch adversarial loss: 0.476313\n",
      "epoch 31; iter: 0; batch classifier loss: 0.286703; batch adversarial loss: 0.452818\n",
      "epoch 32; iter: 0; batch classifier loss: 0.175205; batch adversarial loss: 0.506585\n",
      "epoch 33; iter: 0; batch classifier loss: 0.250724; batch adversarial loss: 0.505427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193318; batch adversarial loss: 0.493634\n",
      "epoch 35; iter: 0; batch classifier loss: 0.217200; batch adversarial loss: 0.554032\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141011; batch adversarial loss: 0.547403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.186828; batch adversarial loss: 0.400007\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165286; batch adversarial loss: 0.488098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168273; batch adversarial loss: 0.426061\n",
      "epoch 40; iter: 0; batch classifier loss: 0.153037; batch adversarial loss: 0.377639\n",
      "epoch 41; iter: 0; batch classifier loss: 0.213872; batch adversarial loss: 0.385396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.218631; batch adversarial loss: 0.428923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.219653; batch adversarial loss: 0.415472\n",
      "epoch 44; iter: 0; batch classifier loss: 0.179189; batch adversarial loss: 0.451807\n",
      "epoch 45; iter: 0; batch classifier loss: 0.133994; batch adversarial loss: 0.514212\n",
      "epoch 46; iter: 0; batch classifier loss: 0.194210; batch adversarial loss: 0.435992\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112102; batch adversarial loss: 0.448109\n",
      "epoch 48; iter: 0; batch classifier loss: 0.089299; batch adversarial loss: 0.508373\n",
      "epoch 49; iter: 0; batch classifier loss: 0.141474; batch adversarial loss: 0.452329\n",
      "epoch 50; iter: 0; batch classifier loss: 0.142047; batch adversarial loss: 0.468338\n",
      "epoch 51; iter: 0; batch classifier loss: 0.159427; batch adversarial loss: 0.518218\n",
      "epoch 52; iter: 0; batch classifier loss: 0.094466; batch adversarial loss: 0.466912\n",
      "epoch 53; iter: 0; batch classifier loss: 0.186282; batch adversarial loss: 0.494394\n",
      "epoch 54; iter: 0; batch classifier loss: 0.130611; batch adversarial loss: 0.459058\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137264; batch adversarial loss: 0.422526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.104235; batch adversarial loss: 0.495339\n",
      "epoch 57; iter: 0; batch classifier loss: 0.228131; batch adversarial loss: 0.452163\n",
      "epoch 58; iter: 0; batch classifier loss: 0.122611; batch adversarial loss: 0.510325\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167728; batch adversarial loss: 0.419946\n",
      "epoch 60; iter: 0; batch classifier loss: 0.093560; batch adversarial loss: 0.435372\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089087; batch adversarial loss: 0.455660\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113868; batch adversarial loss: 0.479727\n",
      "epoch 63; iter: 0; batch classifier loss: 0.159228; batch adversarial loss: 0.405870\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084568; batch adversarial loss: 0.492982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122918; batch adversarial loss: 0.470286\n",
      "epoch 66; iter: 0; batch classifier loss: 0.085050; batch adversarial loss: 0.534468\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077560; batch adversarial loss: 0.506201\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075877; batch adversarial loss: 0.429551\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149700; batch adversarial loss: 0.369385\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194577; batch adversarial loss: 0.451072\n",
      "epoch 71; iter: 0; batch classifier loss: 0.109936; batch adversarial loss: 0.534340\n",
      "epoch 72; iter: 0; batch classifier loss: 0.106373; batch adversarial loss: 0.507535\n",
      "epoch 73; iter: 0; batch classifier loss: 0.104552; batch adversarial loss: 0.475121\n",
      "epoch 74; iter: 0; batch classifier loss: 0.115755; batch adversarial loss: 0.444566\n",
      "epoch 75; iter: 0; batch classifier loss: 0.122182; batch adversarial loss: 0.533217\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120234; batch adversarial loss: 0.454993\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056705; batch adversarial loss: 0.525059\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080448; batch adversarial loss: 0.528119\n",
      "epoch 79; iter: 0; batch classifier loss: 0.090242; batch adversarial loss: 0.413226\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075086; batch adversarial loss: 0.458656\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078429; batch adversarial loss: 0.468320\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053559; batch adversarial loss: 0.448097\n",
      "epoch 83; iter: 0; batch classifier loss: 0.137563; batch adversarial loss: 0.363705\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077103; batch adversarial loss: 0.374922\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069178; batch adversarial loss: 0.473954\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055520; batch adversarial loss: 0.483417\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056931; batch adversarial loss: 0.384077\n",
      "epoch 88; iter: 0; batch classifier loss: 0.080720; batch adversarial loss: 0.424014\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060991; batch adversarial loss: 0.514142\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065786; batch adversarial loss: 0.444421\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040264; batch adversarial loss: 0.524370\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055732; batch adversarial loss: 0.428307\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067639; batch adversarial loss: 0.449506\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077576; batch adversarial loss: 0.360330\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057526; batch adversarial loss: 0.444059\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045920; batch adversarial loss: 0.502304\n",
      "epoch 97; iter: 0; batch classifier loss: 0.098900; batch adversarial loss: 0.508475\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055807; batch adversarial loss: 0.424659\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039378; batch adversarial loss: 0.387640\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049287; batch adversarial loss: 0.400254\n",
      "epoch 101; iter: 0; batch classifier loss: 0.103637; batch adversarial loss: 0.547827\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063683; batch adversarial loss: 0.432095\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037949; batch adversarial loss: 0.445626\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039251; batch adversarial loss: 0.497055\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051032; batch adversarial loss: 0.432736\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045271; batch adversarial loss: 0.458907\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042195; batch adversarial loss: 0.479813\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067072; batch adversarial loss: 0.424677\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046586; batch adversarial loss: 0.406747\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034700; batch adversarial loss: 0.462191\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060834; batch adversarial loss: 0.481104\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038321; batch adversarial loss: 0.491821\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040809; batch adversarial loss: 0.430968\n",
      "epoch 114; iter: 0; batch classifier loss: 0.031128; batch adversarial loss: 0.417687\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028363; batch adversarial loss: 0.479694\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038031; batch adversarial loss: 0.465415\n",
      "epoch 117; iter: 0; batch classifier loss: 0.029199; batch adversarial loss: 0.382945\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031584; batch adversarial loss: 0.449805\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029073; batch adversarial loss: 0.460012\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033041; batch adversarial loss: 0.376427\n",
      "epoch 121; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.460590\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033465; batch adversarial loss: 0.458879\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063685; batch adversarial loss: 0.507684\n",
      "epoch 124; iter: 0; batch classifier loss: 0.049666; batch adversarial loss: 0.455298\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029432; batch adversarial loss: 0.463050\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038200; batch adversarial loss: 0.441745\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044639; batch adversarial loss: 0.446522\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031299; batch adversarial loss: 0.395034\n",
      "epoch 129; iter: 0; batch classifier loss: 0.034859; batch adversarial loss: 0.450916\n",
      "epoch 130; iter: 0; batch classifier loss: 0.015665; batch adversarial loss: 0.500525\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037372; batch adversarial loss: 0.502347\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053231; batch adversarial loss: 0.369068\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015900; batch adversarial loss: 0.461085\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029733; batch adversarial loss: 0.470586\n",
      "epoch 135; iter: 0; batch classifier loss: 0.045148; batch adversarial loss: 0.492797\n",
      "epoch 136; iter: 0; batch classifier loss: 0.048572; batch adversarial loss: 0.478638\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038229; batch adversarial loss: 0.445616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.052322; batch adversarial loss: 0.459319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029142; batch adversarial loss: 0.403907\n",
      "epoch 140; iter: 0; batch classifier loss: 0.021185; batch adversarial loss: 0.322249\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027971; batch adversarial loss: 0.471614\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036775; batch adversarial loss: 0.515527\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036241; batch adversarial loss: 0.378599\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019984; batch adversarial loss: 0.483147\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011534; batch adversarial loss: 0.454424\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010269; batch adversarial loss: 0.404564\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030109; batch adversarial loss: 0.361851\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028669; batch adversarial loss: 0.458159\n",
      "epoch 149; iter: 0; batch classifier loss: 0.008274; batch adversarial loss: 0.424905\n",
      "epoch 150; iter: 0; batch classifier loss: 0.045205; batch adversarial loss: 0.470380\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025718; batch adversarial loss: 0.411969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.020449; batch adversarial loss: 0.461385\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019805; batch adversarial loss: 0.463908\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027085; batch adversarial loss: 0.379261\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018605; batch adversarial loss: 0.340955\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029977; batch adversarial loss: 0.510349\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.422755\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034449; batch adversarial loss: 0.443862\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025827; batch adversarial loss: 0.435865\n",
      "epoch 160; iter: 0; batch classifier loss: 0.008897; batch adversarial loss: 0.471551\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018774; batch adversarial loss: 0.464220\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031286; batch adversarial loss: 0.356363\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014809; batch adversarial loss: 0.407949\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010406; batch adversarial loss: 0.410149\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016095; batch adversarial loss: 0.425930\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012636; batch adversarial loss: 0.483072\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012681; batch adversarial loss: 0.462677\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018541; batch adversarial loss: 0.399955\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009693; batch adversarial loss: 0.567291\n",
      "epoch 170; iter: 0; batch classifier loss: 0.018356; batch adversarial loss: 0.501202\n",
      "epoch 171; iter: 0; batch classifier loss: 0.051092; batch adversarial loss: 0.488682\n",
      "epoch 172; iter: 0; batch classifier loss: 0.025027; batch adversarial loss: 0.402347\n",
      "epoch 173; iter: 0; batch classifier loss: 0.015852; batch adversarial loss: 0.466167\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019070; batch adversarial loss: 0.393840\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028208; batch adversarial loss: 0.586077\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035253; batch adversarial loss: 0.481884\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027617; batch adversarial loss: 0.369334\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006850; batch adversarial loss: 0.546510\n",
      "epoch 179; iter: 0; batch classifier loss: 0.045969; batch adversarial loss: 0.548181\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032544; batch adversarial loss: 0.438852\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010103; batch adversarial loss: 0.535307\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022412; batch adversarial loss: 0.391181\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030737; batch adversarial loss: 0.482551\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009064; batch adversarial loss: 0.415802\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031735; batch adversarial loss: 0.435587\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020820; batch adversarial loss: 0.407290\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042682; batch adversarial loss: 0.411223\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003364; batch adversarial loss: 0.387526\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043188; batch adversarial loss: 0.566670\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006190; batch adversarial loss: 0.442376\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015409; batch adversarial loss: 0.372252\n",
      "epoch 192; iter: 0; batch classifier loss: 0.049026; batch adversarial loss: 0.530540\n",
      "epoch 193; iter: 0; batch classifier loss: 0.013475; batch adversarial loss: 0.473648\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020411; batch adversarial loss: 0.477695\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015346; batch adversarial loss: 0.477293\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012980; batch adversarial loss: 0.440173\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027763; batch adversarial loss: 0.491507\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010653; batch adversarial loss: 0.430705\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019691; batch adversarial loss: 0.421238\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704130; batch adversarial loss: 0.834891\n",
      "epoch 1; iter: 0; batch classifier loss: 0.517363; batch adversarial loss: 0.782098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.693863; batch adversarial loss: 0.767675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.869615; batch adversarial loss: 0.707603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.687801; batch adversarial loss: 0.655325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422760; batch adversarial loss: 0.592993\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310186; batch adversarial loss: 0.593724\n",
      "epoch 7; iter: 0; batch classifier loss: 0.415200; batch adversarial loss: 0.538946\n",
      "epoch 8; iter: 0; batch classifier loss: 0.352725; batch adversarial loss: 0.542228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381007; batch adversarial loss: 0.551737\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307296; batch adversarial loss: 0.545457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.377771; batch adversarial loss: 0.569024\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364019; batch adversarial loss: 0.522568\n",
      "epoch 13; iter: 0; batch classifier loss: 0.410242; batch adversarial loss: 0.471988\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352194; batch adversarial loss: 0.546583\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305648; batch adversarial loss: 0.496809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268901; batch adversarial loss: 0.541677\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331256; batch adversarial loss: 0.552259\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294383; batch adversarial loss: 0.471530\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244970; batch adversarial loss: 0.503820\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273551; batch adversarial loss: 0.476493\n",
      "epoch 21; iter: 0; batch classifier loss: 0.393370; batch adversarial loss: 0.447645\n",
      "epoch 22; iter: 0; batch classifier loss: 0.251377; batch adversarial loss: 0.510405\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233502; batch adversarial loss: 0.485126\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214535; batch adversarial loss: 0.497777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197766; batch adversarial loss: 0.482354\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221906; batch adversarial loss: 0.481061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.243183; batch adversarial loss: 0.410835\n",
      "epoch 28; iter: 0; batch classifier loss: 0.226946; batch adversarial loss: 0.538674\n",
      "epoch 29; iter: 0; batch classifier loss: 0.182720; batch adversarial loss: 0.430451\n",
      "epoch 30; iter: 0; batch classifier loss: 0.201807; batch adversarial loss: 0.437058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202228; batch adversarial loss: 0.485528\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247645; batch adversarial loss: 0.502007\n",
      "epoch 33; iter: 0; batch classifier loss: 0.219321; batch adversarial loss: 0.497031\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194202; batch adversarial loss: 0.462542\n",
      "epoch 35; iter: 0; batch classifier loss: 0.188971; batch adversarial loss: 0.500828\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179490; batch adversarial loss: 0.406259\n",
      "epoch 37; iter: 0; batch classifier loss: 0.176542; batch adversarial loss: 0.506625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186918; batch adversarial loss: 0.489018\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148183; batch adversarial loss: 0.587430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154864; batch adversarial loss: 0.524129\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106870; batch adversarial loss: 0.489743\n",
      "epoch 42; iter: 0; batch classifier loss: 0.114515; batch adversarial loss: 0.491290\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114895; batch adversarial loss: 0.508156\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129510; batch adversarial loss: 0.455591\n",
      "epoch 45; iter: 0; batch classifier loss: 0.173147; batch adversarial loss: 0.422273\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116098; batch adversarial loss: 0.468473\n",
      "epoch 47; iter: 0; batch classifier loss: 0.159451; batch adversarial loss: 0.467996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.190273; batch adversarial loss: 0.444229\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080718; batch adversarial loss: 0.507781\n",
      "epoch 50; iter: 0; batch classifier loss: 0.186680; batch adversarial loss: 0.467220\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146816; batch adversarial loss: 0.392689\n",
      "epoch 52; iter: 0; batch classifier loss: 0.130399; batch adversarial loss: 0.521302\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085498; batch adversarial loss: 0.439449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103215; batch adversarial loss: 0.418017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090284; batch adversarial loss: 0.406417\n",
      "epoch 56; iter: 0; batch classifier loss: 0.181227; batch adversarial loss: 0.485283\n",
      "epoch 57; iter: 0; batch classifier loss: 0.149090; batch adversarial loss: 0.447961\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074233; batch adversarial loss: 0.480205\n",
      "epoch 59; iter: 0; batch classifier loss: 0.112453; batch adversarial loss: 0.407201\n",
      "epoch 60; iter: 0; batch classifier loss: 0.136473; batch adversarial loss: 0.460673\n",
      "epoch 61; iter: 0; batch classifier loss: 0.115287; batch adversarial loss: 0.385853\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097423; batch adversarial loss: 0.396743\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105835; batch adversarial loss: 0.411929\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107046; batch adversarial loss: 0.532911\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067421; batch adversarial loss: 0.473861\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061833; batch adversarial loss: 0.516846\n",
      "epoch 67; iter: 0; batch classifier loss: 0.148268; batch adversarial loss: 0.481899\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108075; batch adversarial loss: 0.512533\n",
      "epoch 69; iter: 0; batch classifier loss: 0.066374; batch adversarial loss: 0.464729\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075584; batch adversarial loss: 0.431600\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083620; batch adversarial loss: 0.503968\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099446; batch adversarial loss: 0.492012\n",
      "epoch 73; iter: 0; batch classifier loss: 0.052578; batch adversarial loss: 0.452224\n",
      "epoch 74; iter: 0; batch classifier loss: 0.088759; batch adversarial loss: 0.452372\n",
      "epoch 75; iter: 0; batch classifier loss: 0.062337; batch adversarial loss: 0.443822\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073648; batch adversarial loss: 0.467454\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063387; batch adversarial loss: 0.473043\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103053; batch adversarial loss: 0.488169\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056058; batch adversarial loss: 0.432483\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092098; batch adversarial loss: 0.453776\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057051; batch adversarial loss: 0.513723\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072898; batch adversarial loss: 0.382649\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100740; batch adversarial loss: 0.404421\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080252; batch adversarial loss: 0.510003\n",
      "epoch 85; iter: 0; batch classifier loss: 0.117307; batch adversarial loss: 0.458481\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075464; batch adversarial loss: 0.439148\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080949; batch adversarial loss: 0.454349\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078523; batch adversarial loss: 0.445943\n",
      "epoch 89; iter: 0; batch classifier loss: 0.026911; batch adversarial loss: 0.477687\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066780; batch adversarial loss: 0.507272\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051375; batch adversarial loss: 0.402117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074419; batch adversarial loss: 0.400962\n",
      "epoch 93; iter: 0; batch classifier loss: 0.075923; batch adversarial loss: 0.453248\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036867; batch adversarial loss: 0.401465\n",
      "epoch 95; iter: 0; batch classifier loss: 0.041344; batch adversarial loss: 0.503297\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058227; batch adversarial loss: 0.519877\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059517; batch adversarial loss: 0.354185\n",
      "epoch 98; iter: 0; batch classifier loss: 0.025177; batch adversarial loss: 0.446968\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092196; batch adversarial loss: 0.448335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.079991; batch adversarial loss: 0.446463\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032044; batch adversarial loss: 0.475360\n",
      "epoch 102; iter: 0; batch classifier loss: 0.025593; batch adversarial loss: 0.460201\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057207; batch adversarial loss: 0.448355\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069422; batch adversarial loss: 0.452805\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030606; batch adversarial loss: 0.487472\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037525; batch adversarial loss: 0.401747\n",
      "epoch 107; iter: 0; batch classifier loss: 0.020755; batch adversarial loss: 0.426376\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054660; batch adversarial loss: 0.479014\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041542; batch adversarial loss: 0.520171\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028159; batch adversarial loss: 0.372250\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061046; batch adversarial loss: 0.449808\n",
      "epoch 112; iter: 0; batch classifier loss: 0.047073; batch adversarial loss: 0.412803\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029696; batch adversarial loss: 0.403153\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037037; batch adversarial loss: 0.470219\n",
      "epoch 115; iter: 0; batch classifier loss: 0.067754; batch adversarial loss: 0.508081\n",
      "epoch 116; iter: 0; batch classifier loss: 0.012862; batch adversarial loss: 0.378589\n",
      "epoch 117; iter: 0; batch classifier loss: 0.046041; batch adversarial loss: 0.439972\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.329323\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028322; batch adversarial loss: 0.505148\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032348; batch adversarial loss: 0.630129\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042771; batch adversarial loss: 0.435398\n",
      "epoch 122; iter: 0; batch classifier loss: 0.028733; batch adversarial loss: 0.356771\n",
      "epoch 123; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.513388\n",
      "epoch 124; iter: 0; batch classifier loss: 0.012207; batch adversarial loss: 0.613355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.034661; batch adversarial loss: 0.378698\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031222; batch adversarial loss: 0.517229\n",
      "epoch 127; iter: 0; batch classifier loss: 0.075539; batch adversarial loss: 0.480434\n",
      "epoch 128; iter: 0; batch classifier loss: 0.009987; batch adversarial loss: 0.506327\n",
      "epoch 129; iter: 0; batch classifier loss: 0.050765; batch adversarial loss: 0.360448\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031834; batch adversarial loss: 0.470903\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036163; batch adversarial loss: 0.424586\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038604; batch adversarial loss: 0.436488\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037781; batch adversarial loss: 0.541823\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047131; batch adversarial loss: 0.387920\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030858; batch adversarial loss: 0.487631\n",
      "epoch 136; iter: 0; batch classifier loss: 0.010393; batch adversarial loss: 0.423314\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020244; batch adversarial loss: 0.516948\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044577; batch adversarial loss: 0.461874\n",
      "epoch 139; iter: 0; batch classifier loss: 0.008223; batch adversarial loss: 0.497165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.511113\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.416483\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016297; batch adversarial loss: 0.579477\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013870; batch adversarial loss: 0.592147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.008930; batch adversarial loss: 0.492998\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035356; batch adversarial loss: 0.519186\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.409515\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024881; batch adversarial loss: 0.508012\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016201; batch adversarial loss: 0.464211\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027014; batch adversarial loss: 0.438610\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017788; batch adversarial loss: 0.342644\n",
      "epoch 151; iter: 0; batch classifier loss: 0.004839; batch adversarial loss: 0.514405\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029250; batch adversarial loss: 0.521016\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020749; batch adversarial loss: 0.501736\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025139; batch adversarial loss: 0.436553\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.416810\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028399; batch adversarial loss: 0.537433\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031226; batch adversarial loss: 0.505132\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008273; batch adversarial loss: 0.421192\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020333; batch adversarial loss: 0.453697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018504; batch adversarial loss: 0.534051\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032182; batch adversarial loss: 0.462461\n",
      "epoch 162; iter: 0; batch classifier loss: 0.012447; batch adversarial loss: 0.483847\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028043; batch adversarial loss: 0.470462\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020519; batch adversarial loss: 0.455743\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008984; batch adversarial loss: 0.417770\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030781; batch adversarial loss: 0.448169\n",
      "epoch 167; iter: 0; batch classifier loss: 0.004180; batch adversarial loss: 0.599847\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009305; batch adversarial loss: 0.388845\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031094; batch adversarial loss: 0.395691\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013142; batch adversarial loss: 0.462707\n",
      "epoch 171; iter: 0; batch classifier loss: 0.006820; batch adversarial loss: 0.418772\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015078; batch adversarial loss: 0.504185\n",
      "epoch 173; iter: 0; batch classifier loss: 0.072170; batch adversarial loss: 0.365252\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015617; batch adversarial loss: 0.440161\n",
      "epoch 175; iter: 0; batch classifier loss: 0.003531; batch adversarial loss: 0.367407\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012397; batch adversarial loss: 0.447810\n",
      "epoch 177; iter: 0; batch classifier loss: 0.002954; batch adversarial loss: 0.491931\n",
      "epoch 178; iter: 0; batch classifier loss: 0.010178; batch adversarial loss: 0.547569\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008145; batch adversarial loss: 0.429716\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010776; batch adversarial loss: 0.379245\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004090; batch adversarial loss: 0.490681\n",
      "epoch 182; iter: 0; batch classifier loss: 0.030520; batch adversarial loss: 0.515907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014961; batch adversarial loss: 0.420359\n",
      "epoch 184; iter: 0; batch classifier loss: 0.015509; batch adversarial loss: 0.419737\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015934; batch adversarial loss: 0.488460\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007523; batch adversarial loss: 0.511441\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009285; batch adversarial loss: 0.547559\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051768; batch adversarial loss: 0.547911\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030697; batch adversarial loss: 0.477241\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007655; batch adversarial loss: 0.528514\n",
      "epoch 191; iter: 0; batch classifier loss: 0.036521; batch adversarial loss: 0.463602\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.394924\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012764; batch adversarial loss: 0.333036\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010618; batch adversarial loss: 0.484364\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014668; batch adversarial loss: 0.536983\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020937; batch adversarial loss: 0.362885\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021459; batch adversarial loss: 0.527060\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004454; batch adversarial loss: 0.381702\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013312; batch adversarial loss: 0.442477\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700888; batch adversarial loss: 0.640282\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512071; batch adversarial loss: 0.632089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523906; batch adversarial loss: 0.626945\n",
      "epoch 3; iter: 0; batch classifier loss: 0.497539; batch adversarial loss: 0.593705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399079; batch adversarial loss: 0.594499\n",
      "epoch 5; iter: 0; batch classifier loss: 0.502986; batch adversarial loss: 0.600121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523998; batch adversarial loss: 0.649865\n",
      "epoch 7; iter: 0; batch classifier loss: 0.413121; batch adversarial loss: 0.575604\n",
      "epoch 8; iter: 0; batch classifier loss: 0.443801; batch adversarial loss: 0.587799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.430132; batch adversarial loss: 0.557183\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344969; batch adversarial loss: 0.511361\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403884; batch adversarial loss: 0.555999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391779; batch adversarial loss: 0.506106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330002; batch adversarial loss: 0.534499\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339034; batch adversarial loss: 0.522755\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341352; batch adversarial loss: 0.490149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346803; batch adversarial loss: 0.443307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316289; batch adversarial loss: 0.503555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325929; batch adversarial loss: 0.494549\n",
      "epoch 19; iter: 0; batch classifier loss: 0.205486; batch adversarial loss: 0.484469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.200743; batch adversarial loss: 0.481821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290922; batch adversarial loss: 0.457538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243579; batch adversarial loss: 0.468925\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240719; batch adversarial loss: 0.432698\n",
      "epoch 24; iter: 0; batch classifier loss: 0.279235; batch adversarial loss: 0.483167\n",
      "epoch 25; iter: 0; batch classifier loss: 0.211682; batch adversarial loss: 0.399729\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185200; batch adversarial loss: 0.535908\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200486; batch adversarial loss: 0.469238\n",
      "epoch 28; iter: 0; batch classifier loss: 0.260778; batch adversarial loss: 0.439720\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235473; batch adversarial loss: 0.414825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.284728; batch adversarial loss: 0.388729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169809; batch adversarial loss: 0.557090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202615; batch adversarial loss: 0.495739\n",
      "epoch 33; iter: 0; batch classifier loss: 0.178789; batch adversarial loss: 0.486590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.231507; batch adversarial loss: 0.461983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.244464; batch adversarial loss: 0.424939\n",
      "epoch 36; iter: 0; batch classifier loss: 0.181322; batch adversarial loss: 0.455293\n",
      "epoch 37; iter: 0; batch classifier loss: 0.223057; batch adversarial loss: 0.389924\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244098; batch adversarial loss: 0.466370\n",
      "epoch 39; iter: 0; batch classifier loss: 0.252146; batch adversarial loss: 0.459137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.251585; batch adversarial loss: 0.407558\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248930; batch adversarial loss: 0.495979\n",
      "epoch 42; iter: 0; batch classifier loss: 0.178616; batch adversarial loss: 0.448201\n",
      "epoch 43; iter: 0; batch classifier loss: 0.225081; batch adversarial loss: 0.558325\n",
      "epoch 44; iter: 0; batch classifier loss: 0.262821; batch adversarial loss: 0.503547\n",
      "epoch 45; iter: 0; batch classifier loss: 0.207063; batch adversarial loss: 0.523965\n",
      "epoch 46; iter: 0; batch classifier loss: 0.199173; batch adversarial loss: 0.514063\n",
      "epoch 47; iter: 0; batch classifier loss: 0.233585; batch adversarial loss: 0.508854\n",
      "epoch 48; iter: 0; batch classifier loss: 0.212957; batch adversarial loss: 0.525998\n",
      "epoch 49; iter: 0; batch classifier loss: 0.265250; batch adversarial loss: 0.500418\n",
      "epoch 50; iter: 0; batch classifier loss: 0.140198; batch adversarial loss: 0.503452\n",
      "epoch 51; iter: 0; batch classifier loss: 0.257360; batch adversarial loss: 0.389543\n",
      "epoch 52; iter: 0; batch classifier loss: 0.215225; batch adversarial loss: 0.424875\n",
      "epoch 53; iter: 0; batch classifier loss: 0.237717; batch adversarial loss: 0.444686\n",
      "epoch 54; iter: 0; batch classifier loss: 0.221192; batch adversarial loss: 0.410854\n",
      "epoch 55; iter: 0; batch classifier loss: 0.197250; batch adversarial loss: 0.338111\n",
      "epoch 56; iter: 0; batch classifier loss: 0.319178; batch adversarial loss: 0.442989\n",
      "epoch 57; iter: 0; batch classifier loss: 0.296084; batch adversarial loss: 0.459242\n",
      "epoch 58; iter: 0; batch classifier loss: 0.167856; batch adversarial loss: 0.531919\n",
      "epoch 59; iter: 0; batch classifier loss: 0.252208; batch adversarial loss: 0.435148\n",
      "epoch 60; iter: 0; batch classifier loss: 0.226873; batch adversarial loss: 0.457168\n",
      "epoch 61; iter: 0; batch classifier loss: 0.200287; batch adversarial loss: 0.410161\n",
      "epoch 62; iter: 0; batch classifier loss: 0.246718; batch adversarial loss: 0.447734\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158447; batch adversarial loss: 0.434534\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072143; batch adversarial loss: 0.432337\n",
      "epoch 65; iter: 0; batch classifier loss: 0.067111; batch adversarial loss: 0.418321\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105836; batch adversarial loss: 0.448157\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061610; batch adversarial loss: 0.393987\n",
      "epoch 68; iter: 0; batch classifier loss: 0.108573; batch adversarial loss: 0.445683\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082446; batch adversarial loss: 0.406764\n",
      "epoch 70; iter: 0; batch classifier loss: 0.128560; batch adversarial loss: 0.501481\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073305; batch adversarial loss: 0.441591\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077275; batch adversarial loss: 0.364212\n",
      "epoch 73; iter: 0; batch classifier loss: 0.138947; batch adversarial loss: 0.427976\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082691; batch adversarial loss: 0.527465\n",
      "epoch 75; iter: 0; batch classifier loss: 0.098913; batch adversarial loss: 0.288681\n",
      "epoch 76; iter: 0; batch classifier loss: 0.085875; batch adversarial loss: 0.466645\n",
      "epoch 77; iter: 0; batch classifier loss: 0.109750; batch adversarial loss: 0.390235\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081064; batch adversarial loss: 0.566308\n",
      "epoch 79; iter: 0; batch classifier loss: 0.110623; batch adversarial loss: 0.476268\n",
      "epoch 80; iter: 0; batch classifier loss: 0.102420; batch adversarial loss: 0.499292\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073251; batch adversarial loss: 0.447023\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102731; batch adversarial loss: 0.378878\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068533; batch adversarial loss: 0.504818\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056942; batch adversarial loss: 0.473276\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066280; batch adversarial loss: 0.341630\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090311; batch adversarial loss: 0.473709\n",
      "epoch 87; iter: 0; batch classifier loss: 0.153349; batch adversarial loss: 0.530357\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063776; batch adversarial loss: 0.418773\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.508435\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052975; batch adversarial loss: 0.455513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079110; batch adversarial loss: 0.369128\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054985; batch adversarial loss: 0.452110\n",
      "epoch 93; iter: 0; batch classifier loss: 0.050125; batch adversarial loss: 0.470325\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094007; batch adversarial loss: 0.495886\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058618; batch adversarial loss: 0.507674\n",
      "epoch 96; iter: 0; batch classifier loss: 0.077624; batch adversarial loss: 0.491190\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051290; batch adversarial loss: 0.459615\n",
      "epoch 98; iter: 0; batch classifier loss: 0.064481; batch adversarial loss: 0.466330\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069155; batch adversarial loss: 0.402387\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054208; batch adversarial loss: 0.465956\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032675; batch adversarial loss: 0.449976\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032450; batch adversarial loss: 0.454880\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052875; batch adversarial loss: 0.442814\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043197; batch adversarial loss: 0.398539\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069485; batch adversarial loss: 0.390395\n",
      "epoch 106; iter: 0; batch classifier loss: 0.028112; batch adversarial loss: 0.357883\n",
      "epoch 107; iter: 0; batch classifier loss: 0.050201; batch adversarial loss: 0.521101\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049296; batch adversarial loss: 0.403162\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046013; batch adversarial loss: 0.468833\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034260; batch adversarial loss: 0.481550\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040577; batch adversarial loss: 0.426410\n",
      "epoch 112; iter: 0; batch classifier loss: 0.017489; batch adversarial loss: 0.448509\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044200; batch adversarial loss: 0.506451\n",
      "epoch 114; iter: 0; batch classifier loss: 0.035324; batch adversarial loss: 0.433151\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025095; batch adversarial loss: 0.477203\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045893; batch adversarial loss: 0.342491\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048732; batch adversarial loss: 0.412790\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030752; batch adversarial loss: 0.382674\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059350; batch adversarial loss: 0.475584\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056249; batch adversarial loss: 0.489508\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021195; batch adversarial loss: 0.369560\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048162; batch adversarial loss: 0.391014\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025488; batch adversarial loss: 0.386970\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059560; batch adversarial loss: 0.429643\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040289; batch adversarial loss: 0.413021\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021585; batch adversarial loss: 0.520729\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035845; batch adversarial loss: 0.428325\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022484; batch adversarial loss: 0.425082\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035186; batch adversarial loss: 0.473111\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041385; batch adversarial loss: 0.478682\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030993; batch adversarial loss: 0.376784\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.586310\n",
      "epoch 133; iter: 0; batch classifier loss: 0.019606; batch adversarial loss: 0.395631\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035356; batch adversarial loss: 0.469266\n",
      "epoch 135; iter: 0; batch classifier loss: 0.027139; batch adversarial loss: 0.449970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.025829; batch adversarial loss: 0.472005\n",
      "epoch 137; iter: 0; batch classifier loss: 0.067869; batch adversarial loss: 0.423712\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032325; batch adversarial loss: 0.395700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044929; batch adversarial loss: 0.454850\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027675; batch adversarial loss: 0.530687\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040875; batch adversarial loss: 0.468124\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014938; batch adversarial loss: 0.411815\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030813; batch adversarial loss: 0.505487\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024722; batch adversarial loss: 0.532220\n",
      "epoch 145; iter: 0; batch classifier loss: 0.033060; batch adversarial loss: 0.513233\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019352; batch adversarial loss: 0.414868\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011888; batch adversarial loss: 0.516348\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024847; batch adversarial loss: 0.387303\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017897; batch adversarial loss: 0.482326\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025817; batch adversarial loss: 0.434711\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023151; batch adversarial loss: 0.431014\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017441; batch adversarial loss: 0.401011\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021012; batch adversarial loss: 0.444878\n",
      "epoch 154; iter: 0; batch classifier loss: 0.021122; batch adversarial loss: 0.491909\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032486; batch adversarial loss: 0.487104\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022393; batch adversarial loss: 0.541701\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047230; batch adversarial loss: 0.397563\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042891; batch adversarial loss: 0.494304\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018262; batch adversarial loss: 0.400848\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028806; batch adversarial loss: 0.432026\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013896; batch adversarial loss: 0.493400\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.462904\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013545; batch adversarial loss: 0.421033\n",
      "epoch 164; iter: 0; batch classifier loss: 0.022605; batch adversarial loss: 0.538341\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021651; batch adversarial loss: 0.342776\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014301; batch adversarial loss: 0.473158\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012288; batch adversarial loss: 0.401982\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023073; batch adversarial loss: 0.473537\n",
      "epoch 169; iter: 0; batch classifier loss: 0.035511; batch adversarial loss: 0.540015\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032553; batch adversarial loss: 0.403078\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029336; batch adversarial loss: 0.498552\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015362; batch adversarial loss: 0.421842\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014807; batch adversarial loss: 0.471216\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018119; batch adversarial loss: 0.503947\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019222; batch adversarial loss: 0.487609\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012290; batch adversarial loss: 0.411864\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018393; batch adversarial loss: 0.445126\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008787; batch adversarial loss: 0.546324\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027806; batch adversarial loss: 0.506746\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030173; batch adversarial loss: 0.353826\n",
      "epoch 181; iter: 0; batch classifier loss: 0.037344; batch adversarial loss: 0.459755\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012711; batch adversarial loss: 0.510313\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034851; batch adversarial loss: 0.406140\n",
      "epoch 184; iter: 0; batch classifier loss: 0.057533; batch adversarial loss: 0.502925\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022166; batch adversarial loss: 0.471555\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023771; batch adversarial loss: 0.497115\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023480; batch adversarial loss: 0.465113\n",
      "epoch 188; iter: 0; batch classifier loss: 0.051685; batch adversarial loss: 0.469731\n",
      "epoch 189; iter: 0; batch classifier loss: 0.051504; batch adversarial loss: 0.386078\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015794; batch adversarial loss: 0.398054\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015289; batch adversarial loss: 0.396313\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012054; batch adversarial loss: 0.469107\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007592; batch adversarial loss: 0.448395\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025741; batch adversarial loss: 0.578312\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017933; batch adversarial loss: 0.404399\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015524; batch adversarial loss: 0.473296\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025922; batch adversarial loss: 0.410070\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024540; batch adversarial loss: 0.372105\n",
      "epoch 199; iter: 0; batch classifier loss: 0.014382; batch adversarial loss: 0.467869\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729485; batch adversarial loss: 1.030380\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677601; batch adversarial loss: 1.101924\n",
      "epoch 2; iter: 0; batch classifier loss: 0.940139; batch adversarial loss: 1.129848\n",
      "epoch 3; iter: 0; batch classifier loss: 1.126691; batch adversarial loss: 1.045628\n",
      "epoch 4; iter: 0; batch classifier loss: 0.982156; batch adversarial loss: 0.913430\n",
      "epoch 5; iter: 0; batch classifier loss: 1.137718; batch adversarial loss: 0.858893\n",
      "epoch 6; iter: 0; batch classifier loss: 1.024600; batch adversarial loss: 0.789920\n",
      "epoch 7; iter: 0; batch classifier loss: 1.003610; batch adversarial loss: 0.712757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.847286; batch adversarial loss: 0.689395\n",
      "epoch 9; iter: 0; batch classifier loss: 0.654942; batch adversarial loss: 0.591030\n",
      "epoch 10; iter: 0; batch classifier loss: 0.606955; batch adversarial loss: 0.570692\n",
      "epoch 11; iter: 0; batch classifier loss: 0.475535; batch adversarial loss: 0.547418\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331418; batch adversarial loss: 0.542920\n",
      "epoch 13; iter: 0; batch classifier loss: 0.311209; batch adversarial loss: 0.531335\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282257; batch adversarial loss: 0.547206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229917; batch adversarial loss: 0.485860\n",
      "epoch 16; iter: 0; batch classifier loss: 0.192748; batch adversarial loss: 0.511883\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290352; batch adversarial loss: 0.461644\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303878; batch adversarial loss: 0.481133\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281782; batch adversarial loss: 0.428453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.238495; batch adversarial loss: 0.460558\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209185; batch adversarial loss: 0.473650\n",
      "epoch 22; iter: 0; batch classifier loss: 0.215979; batch adversarial loss: 0.495769\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202265; batch adversarial loss: 0.492407\n",
      "epoch 24; iter: 0; batch classifier loss: 0.170755; batch adversarial loss: 0.430318\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146779; batch adversarial loss: 0.539526\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247322; batch adversarial loss: 0.464797\n",
      "epoch 27; iter: 0; batch classifier loss: 0.153494; batch adversarial loss: 0.442087\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158042; batch adversarial loss: 0.477742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.187531; batch adversarial loss: 0.462541\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177250; batch adversarial loss: 0.446539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162238; batch adversarial loss: 0.505011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.154766; batch adversarial loss: 0.475378\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158179; batch adversarial loss: 0.470500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193589; batch adversarial loss: 0.451187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.116664; batch adversarial loss: 0.442218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.179777; batch adversarial loss: 0.519197\n",
      "epoch 37; iter: 0; batch classifier loss: 0.155655; batch adversarial loss: 0.406683\n",
      "epoch 38; iter: 0; batch classifier loss: 0.184824; batch adversarial loss: 0.448034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102673; batch adversarial loss: 0.398727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130758; batch adversarial loss: 0.521330\n",
      "epoch 41; iter: 0; batch classifier loss: 0.107801; batch adversarial loss: 0.542096\n",
      "epoch 42; iter: 0; batch classifier loss: 0.165351; batch adversarial loss: 0.452425\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156911; batch adversarial loss: 0.442188\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110904; batch adversarial loss: 0.473163\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093495; batch adversarial loss: 0.465818\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096117; batch adversarial loss: 0.452506\n",
      "epoch 47; iter: 0; batch classifier loss: 0.097549; batch adversarial loss: 0.410562\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098803; batch adversarial loss: 0.492379\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094028; batch adversarial loss: 0.447343\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110469; batch adversarial loss: 0.390780\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107787; batch adversarial loss: 0.447742\n",
      "epoch 52; iter: 0; batch classifier loss: 0.134968; batch adversarial loss: 0.461834\n",
      "epoch 53; iter: 0; batch classifier loss: 0.125861; batch adversarial loss: 0.472446\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065770; batch adversarial loss: 0.463386\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086185; batch adversarial loss: 0.535280\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113656; batch adversarial loss: 0.391557\n",
      "epoch 57; iter: 0; batch classifier loss: 0.132628; batch adversarial loss: 0.393697\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086663; batch adversarial loss: 0.344312\n",
      "epoch 59; iter: 0; batch classifier loss: 0.106708; batch adversarial loss: 0.468263\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086987; batch adversarial loss: 0.530449\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080707; batch adversarial loss: 0.385354\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083723; batch adversarial loss: 0.556287\n",
      "epoch 63; iter: 0; batch classifier loss: 0.084522; batch adversarial loss: 0.507320\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080931; batch adversarial loss: 0.490512\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113632; batch adversarial loss: 0.432749\n",
      "epoch 66; iter: 0; batch classifier loss: 0.112383; batch adversarial loss: 0.459455\n",
      "epoch 67; iter: 0; batch classifier loss: 0.110276; batch adversarial loss: 0.372844\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096105; batch adversarial loss: 0.375197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078008; batch adversarial loss: 0.478883\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130127; batch adversarial loss: 0.485319\n",
      "epoch 71; iter: 0; batch classifier loss: 0.135410; batch adversarial loss: 0.521015\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108829; batch adversarial loss: 0.521039\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083776; batch adversarial loss: 0.457541\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063105; batch adversarial loss: 0.463002\n",
      "epoch 75; iter: 0; batch classifier loss: 0.091653; batch adversarial loss: 0.479409\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049875; batch adversarial loss: 0.490633\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063943; batch adversarial loss: 0.523502\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073486; batch adversarial loss: 0.438921\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064725; batch adversarial loss: 0.480298\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048879; batch adversarial loss: 0.417659\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044044; batch adversarial loss: 0.563164\n",
      "epoch 82; iter: 0; batch classifier loss: 0.070119; batch adversarial loss: 0.466787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.034113; batch adversarial loss: 0.501390\n",
      "epoch 84; iter: 0; batch classifier loss: 0.092639; batch adversarial loss: 0.495263\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055341; batch adversarial loss: 0.489240\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043080; batch adversarial loss: 0.511583\n",
      "epoch 87; iter: 0; batch classifier loss: 0.035384; batch adversarial loss: 0.379346\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062453; batch adversarial loss: 0.355729\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106869; batch adversarial loss: 0.454245\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075179; batch adversarial loss: 0.394283\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039164; batch adversarial loss: 0.495488\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059549; batch adversarial loss: 0.376996\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064524; batch adversarial loss: 0.429113\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075365; batch adversarial loss: 0.464139\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066603; batch adversarial loss: 0.545301\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047127; batch adversarial loss: 0.437908\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067478; batch adversarial loss: 0.423745\n",
      "epoch 98; iter: 0; batch classifier loss: 0.099832; batch adversarial loss: 0.303478\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062517; batch adversarial loss: 0.439115\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075235; batch adversarial loss: 0.558527\n",
      "epoch 101; iter: 0; batch classifier loss: 0.077313; batch adversarial loss: 0.487829\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048072; batch adversarial loss: 0.364481\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063448; batch adversarial loss: 0.493493\n",
      "epoch 104; iter: 0; batch classifier loss: 0.070634; batch adversarial loss: 0.526445\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064836; batch adversarial loss: 0.383065\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053833; batch adversarial loss: 0.444662\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036927; batch adversarial loss: 0.375801\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050450; batch adversarial loss: 0.422925\n",
      "epoch 109; iter: 0; batch classifier loss: 0.036606; batch adversarial loss: 0.477212\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044289; batch adversarial loss: 0.486031\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042326; batch adversarial loss: 0.442468\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058807; batch adversarial loss: 0.278830\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053541; batch adversarial loss: 0.440520\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046282; batch adversarial loss: 0.465452\n",
      "epoch 115; iter: 0; batch classifier loss: 0.117969; batch adversarial loss: 0.396690\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045733; batch adversarial loss: 0.436440\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023895; batch adversarial loss: 0.403180\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041085; batch adversarial loss: 0.471344\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013317; batch adversarial loss: 0.490195\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048442; batch adversarial loss: 0.467994\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037334; batch adversarial loss: 0.432663\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054816; batch adversarial loss: 0.469255\n",
      "epoch 123; iter: 0; batch classifier loss: 0.023594; batch adversarial loss: 0.467302\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054393; batch adversarial loss: 0.547594\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060633; batch adversarial loss: 0.417063\n",
      "epoch 126; iter: 0; batch classifier loss: 0.041602; batch adversarial loss: 0.397684\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042973; batch adversarial loss: 0.544134\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040752; batch adversarial loss: 0.508105\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048946; batch adversarial loss: 0.355621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 130; iter: 0; batch classifier loss: 0.036544; batch adversarial loss: 0.528676\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058686; batch adversarial loss: 0.435191\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038168; batch adversarial loss: 0.479293\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045219; batch adversarial loss: 0.348100\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049361; batch adversarial loss: 0.497263\n",
      "epoch 135; iter: 0; batch classifier loss: 0.085883; batch adversarial loss: 0.389858\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029670; batch adversarial loss: 0.450742\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043634; batch adversarial loss: 0.357206\n",
      "epoch 138; iter: 0; batch classifier loss: 0.025575; batch adversarial loss: 0.352909\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033690; batch adversarial loss: 0.518548\n",
      "epoch 140; iter: 0; batch classifier loss: 0.007781; batch adversarial loss: 0.524568\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053411; batch adversarial loss: 0.427974\n",
      "epoch 142; iter: 0; batch classifier loss: 0.008006; batch adversarial loss: 0.458684\n",
      "epoch 143; iter: 0; batch classifier loss: 0.018824; batch adversarial loss: 0.510632\n",
      "epoch 144; iter: 0; batch classifier loss: 0.035862; batch adversarial loss: 0.469641\n",
      "epoch 145; iter: 0; batch classifier loss: 0.050521; batch adversarial loss: 0.520386\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019713; batch adversarial loss: 0.540515\n",
      "epoch 147; iter: 0; batch classifier loss: 0.050566; batch adversarial loss: 0.495241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.022335; batch adversarial loss: 0.419075\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043366; batch adversarial loss: 0.381765\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022727; batch adversarial loss: 0.471872\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043191; batch adversarial loss: 0.543686\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029772; batch adversarial loss: 0.422710\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020755; batch adversarial loss: 0.472194\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029314; batch adversarial loss: 0.423050\n",
      "epoch 155; iter: 0; batch classifier loss: 0.014589; batch adversarial loss: 0.525605\n",
      "epoch 156; iter: 0; batch classifier loss: 0.012353; batch adversarial loss: 0.490373\n",
      "epoch 157; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.468334\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028753; batch adversarial loss: 0.520189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016804; batch adversarial loss: 0.459218\n",
      "epoch 160; iter: 0; batch classifier loss: 0.028996; batch adversarial loss: 0.401038\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038404; batch adversarial loss: 0.506311\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029376; batch adversarial loss: 0.491252\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050989; batch adversarial loss: 0.460520\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014833; batch adversarial loss: 0.367315\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.448665\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015912; batch adversarial loss: 0.351990\n",
      "epoch 167; iter: 0; batch classifier loss: 0.082048; batch adversarial loss: 0.337409\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032370; batch adversarial loss: 0.436171\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031641; batch adversarial loss: 0.529663\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014592; batch adversarial loss: 0.465731\n",
      "epoch 171; iter: 0; batch classifier loss: 0.033442; batch adversarial loss: 0.353530\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.457315\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017966; batch adversarial loss: 0.472464\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023948; batch adversarial loss: 0.387982\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007461; batch adversarial loss: 0.520994\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026644; batch adversarial loss: 0.441258\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029497; batch adversarial loss: 0.425199\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022316; batch adversarial loss: 0.448768\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017289; batch adversarial loss: 0.432502\n",
      "epoch 180; iter: 0; batch classifier loss: 0.002205; batch adversarial loss: 0.343786\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031838; batch adversarial loss: 0.382343\n",
      "epoch 182; iter: 0; batch classifier loss: 0.008717; batch adversarial loss: 0.416217\n",
      "epoch 183; iter: 0; batch classifier loss: 0.053555; batch adversarial loss: 0.481581\n",
      "epoch 184; iter: 0; batch classifier loss: 0.056371; batch adversarial loss: 0.353492\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033574; batch adversarial loss: 0.386835\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055204; batch adversarial loss: 0.413690\n",
      "epoch 187; iter: 0; batch classifier loss: 0.050335; batch adversarial loss: 0.431123\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032731; batch adversarial loss: 0.398268\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043515; batch adversarial loss: 0.434505\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034505; batch adversarial loss: 0.474790\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007133; batch adversarial loss: 0.360766\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014952; batch adversarial loss: 0.426922\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019098; batch adversarial loss: 0.455651\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031029; batch adversarial loss: 0.534902\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011488; batch adversarial loss: 0.487369\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044928; batch adversarial loss: 0.328862\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003118; batch adversarial loss: 0.459840\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022438; batch adversarial loss: 0.509248\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025479; batch adversarial loss: 0.358139\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678802; batch adversarial loss: 0.841160\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461735; batch adversarial loss: 0.791915\n",
      "epoch 2; iter: 0; batch classifier loss: 0.393686; batch adversarial loss: 0.723815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.432134; batch adversarial loss: 0.713330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320377; batch adversarial loss: 0.660064\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377557; batch adversarial loss: 0.665622\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340993; batch adversarial loss: 0.621068\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320650; batch adversarial loss: 0.568675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325579; batch adversarial loss: 0.568196\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299539; batch adversarial loss: 0.527815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308471; batch adversarial loss: 0.486098\n",
      "epoch 11; iter: 0; batch classifier loss: 0.220663; batch adversarial loss: 0.501163\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217755; batch adversarial loss: 0.477167\n",
      "epoch 13; iter: 0; batch classifier loss: 0.230128; batch adversarial loss: 0.458622\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236253; batch adversarial loss: 0.481401\n",
      "epoch 15; iter: 0; batch classifier loss: 0.209288; batch adversarial loss: 0.459108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.226227; batch adversarial loss: 0.429541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200026; batch adversarial loss: 0.453920\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279533; batch adversarial loss: 0.390450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.161402; batch adversarial loss: 0.368361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178741; batch adversarial loss: 0.514250\n",
      "epoch 21; iter: 0; batch classifier loss: 0.153443; batch adversarial loss: 0.413917\n",
      "epoch 22; iter: 0; batch classifier loss: 0.210418; batch adversarial loss: 0.386707\n",
      "epoch 23; iter: 0; batch classifier loss: 0.200526; batch adversarial loss: 0.459796\n",
      "epoch 24; iter: 0; batch classifier loss: 0.182490; batch adversarial loss: 0.355702\n",
      "epoch 25; iter: 0; batch classifier loss: 0.138757; batch adversarial loss: 0.398048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.155517; batch adversarial loss: 0.421211\n",
      "epoch 27; iter: 0; batch classifier loss: 0.117902; batch adversarial loss: 0.324532\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144625; batch adversarial loss: 0.438496\n",
      "epoch 29; iter: 0; batch classifier loss: 0.166981; batch adversarial loss: 0.409538\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145170; batch adversarial loss: 0.454145\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132383; batch adversarial loss: 0.465398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134281; batch adversarial loss: 0.477589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118008; batch adversarial loss: 0.410525\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153101; batch adversarial loss: 0.324193\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122456; batch adversarial loss: 0.356417\n",
      "epoch 36; iter: 0; batch classifier loss: 0.111641; batch adversarial loss: 0.405545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121266; batch adversarial loss: 0.375476\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119491; batch adversarial loss: 0.441758\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096509; batch adversarial loss: 0.403289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089806; batch adversarial loss: 0.401686\n",
      "epoch 41; iter: 0; batch classifier loss: 0.142952; batch adversarial loss: 0.356759\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105877; batch adversarial loss: 0.403864\n",
      "epoch 43; iter: 0; batch classifier loss: 0.086876; batch adversarial loss: 0.502843\n",
      "epoch 44; iter: 0; batch classifier loss: 0.160736; batch adversarial loss: 0.440248\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095753; batch adversarial loss: 0.371483\n",
      "epoch 46; iter: 0; batch classifier loss: 0.108813; batch adversarial loss: 0.388998\n",
      "epoch 47; iter: 0; batch classifier loss: 0.076698; batch adversarial loss: 0.449407\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082901; batch adversarial loss: 0.406302\n",
      "epoch 49; iter: 0; batch classifier loss: 0.097419; batch adversarial loss: 0.331818\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094373; batch adversarial loss: 0.504507\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108224; batch adversarial loss: 0.417820\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071386; batch adversarial loss: 0.414834\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122322; batch adversarial loss: 0.418900\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079102; batch adversarial loss: 0.475201\n",
      "epoch 55; iter: 0; batch classifier loss: 0.049475; batch adversarial loss: 0.402473\n",
      "epoch 56; iter: 0; batch classifier loss: 0.112065; batch adversarial loss: 0.448476\n",
      "epoch 57; iter: 0; batch classifier loss: 0.076983; batch adversarial loss: 0.385315\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091114; batch adversarial loss: 0.411936\n",
      "epoch 59; iter: 0; batch classifier loss: 0.100143; batch adversarial loss: 0.422551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070325; batch adversarial loss: 0.432724\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133983; batch adversarial loss: 0.470060\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083071; batch adversarial loss: 0.394817\n",
      "epoch 63; iter: 0; batch classifier loss: 0.085920; batch adversarial loss: 0.411178\n",
      "epoch 64; iter: 0; batch classifier loss: 0.078824; batch adversarial loss: 0.472476\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113316; batch adversarial loss: 0.385839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057994; batch adversarial loss: 0.449724\n",
      "epoch 67; iter: 0; batch classifier loss: 0.083172; batch adversarial loss: 0.306277\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061701; batch adversarial loss: 0.405142\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095559; batch adversarial loss: 0.347709\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073638; batch adversarial loss: 0.371322\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079120; batch adversarial loss: 0.400412\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099414; batch adversarial loss: 0.401686\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083328; batch adversarial loss: 0.422646\n",
      "epoch 74; iter: 0; batch classifier loss: 0.081909; batch adversarial loss: 0.368468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076759; batch adversarial loss: 0.331239\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068125; batch adversarial loss: 0.515875\n",
      "epoch 77; iter: 0; batch classifier loss: 0.116565; batch adversarial loss: 0.427980\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078160; batch adversarial loss: 0.437504\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072442; batch adversarial loss: 0.472087\n",
      "epoch 80; iter: 0; batch classifier loss: 0.094887; batch adversarial loss: 0.443272\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044368; batch adversarial loss: 0.443267\n",
      "epoch 82; iter: 0; batch classifier loss: 0.034506; batch adversarial loss: 0.461327\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057837; batch adversarial loss: 0.396012\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054039; batch adversarial loss: 0.462909\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059650; batch adversarial loss: 0.464791\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046749; batch adversarial loss: 0.411753\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055173; batch adversarial loss: 0.442270\n",
      "epoch 88; iter: 0; batch classifier loss: 0.048050; batch adversarial loss: 0.557232\n",
      "epoch 89; iter: 0; batch classifier loss: 0.041298; batch adversarial loss: 0.419499\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038538; batch adversarial loss: 0.401766\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071351; batch adversarial loss: 0.391890\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046604; batch adversarial loss: 0.411813\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041798; batch adversarial loss: 0.413915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.058954; batch adversarial loss: 0.384615\n",
      "epoch 95; iter: 0; batch classifier loss: 0.021572; batch adversarial loss: 0.482353\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040399; batch adversarial loss: 0.430968\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052811; batch adversarial loss: 0.501487\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077666; batch adversarial loss: 0.362962\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033477; batch adversarial loss: 0.384991\n",
      "epoch 100; iter: 0; batch classifier loss: 0.025662; batch adversarial loss: 0.476652\n",
      "epoch 101; iter: 0; batch classifier loss: 0.029946; batch adversarial loss: 0.480672\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036985; batch adversarial loss: 0.328907\n",
      "epoch 103; iter: 0; batch classifier loss: 0.026177; batch adversarial loss: 0.489869\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046963; batch adversarial loss: 0.450224\n",
      "epoch 105; iter: 0; batch classifier loss: 0.062398; batch adversarial loss: 0.469314\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024489; batch adversarial loss: 0.406746\n",
      "epoch 107; iter: 0; batch classifier loss: 0.029978; batch adversarial loss: 0.456582\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025897; batch adversarial loss: 0.458156\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067978; batch adversarial loss: 0.372680\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053751; batch adversarial loss: 0.442871\n",
      "epoch 111; iter: 0; batch classifier loss: 0.018239; batch adversarial loss: 0.439774\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029814; batch adversarial loss: 0.366232\n",
      "epoch 113; iter: 0; batch classifier loss: 0.021638; batch adversarial loss: 0.499980\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032493; batch adversarial loss: 0.389306\n",
      "epoch 115; iter: 0; batch classifier loss: 0.033127; batch adversarial loss: 0.434208\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072509; batch adversarial loss: 0.461917\n",
      "epoch 117; iter: 0; batch classifier loss: 0.020183; batch adversarial loss: 0.440216\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030079; batch adversarial loss: 0.409791\n",
      "epoch 119; iter: 0; batch classifier loss: 0.011598; batch adversarial loss: 0.383873\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046562; batch adversarial loss: 0.423310\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042722; batch adversarial loss: 0.494954\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033750; batch adversarial loss: 0.480982\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025856; batch adversarial loss: 0.444623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.094601; batch adversarial loss: 0.450162\n",
      "epoch 125; iter: 0; batch classifier loss: 0.012175; batch adversarial loss: 0.392282\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036092; batch adversarial loss: 0.567752\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022069; batch adversarial loss: 0.425562\n",
      "epoch 128; iter: 0; batch classifier loss: 0.027797; batch adversarial loss: 0.439501\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017647; batch adversarial loss: 0.485247\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030631; batch adversarial loss: 0.410469\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039847; batch adversarial loss: 0.438125\n",
      "epoch 132; iter: 0; batch classifier loss: 0.014666; batch adversarial loss: 0.545755\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021890; batch adversarial loss: 0.430690\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016834; batch adversarial loss: 0.414558\n",
      "epoch 135; iter: 0; batch classifier loss: 0.068914; batch adversarial loss: 0.527778\n",
      "epoch 136; iter: 0; batch classifier loss: 0.109985; batch adversarial loss: 0.542583\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034555; batch adversarial loss: 0.478463\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085470; batch adversarial loss: 0.603807\n",
      "epoch 139; iter: 0; batch classifier loss: 0.124588; batch adversarial loss: 0.607795\n",
      "epoch 140; iter: 0; batch classifier loss: 0.075744; batch adversarial loss: 0.613479\n",
      "epoch 141; iter: 0; batch classifier loss: 0.170095; batch adversarial loss: 0.778900\n",
      "epoch 142; iter: 0; batch classifier loss: 0.126161; batch adversarial loss: 0.720252\n",
      "epoch 143; iter: 0; batch classifier loss: 0.164614; batch adversarial loss: 0.775869\n",
      "epoch 144; iter: 0; batch classifier loss: 0.144901; batch adversarial loss: 0.689396\n",
      "epoch 145; iter: 0; batch classifier loss: 0.141060; batch adversarial loss: 0.635325\n",
      "epoch 146; iter: 0; batch classifier loss: 0.093868; batch adversarial loss: 0.500977\n",
      "epoch 147; iter: 0; batch classifier loss: 0.165175; batch adversarial loss: 0.807067\n",
      "epoch 148; iter: 0; batch classifier loss: 0.113405; batch adversarial loss: 0.645854\n",
      "epoch 149; iter: 0; batch classifier loss: 0.083777; batch adversarial loss: 0.617511\n",
      "epoch 150; iter: 0; batch classifier loss: 0.200994; batch adversarial loss: 0.727741\n",
      "epoch 151; iter: 0; batch classifier loss: 0.139008; batch adversarial loss: 0.579460\n",
      "epoch 152; iter: 0; batch classifier loss: 0.193347; batch adversarial loss: 0.651401\n",
      "epoch 153; iter: 0; batch classifier loss: 0.187322; batch adversarial loss: 0.637448\n",
      "epoch 154; iter: 0; batch classifier loss: 0.196991; batch adversarial loss: 0.735291\n",
      "epoch 155; iter: 0; batch classifier loss: 0.170606; batch adversarial loss: 0.742763\n",
      "epoch 156; iter: 0; batch classifier loss: 0.114113; batch adversarial loss: 0.568792\n",
      "epoch 157; iter: 0; batch classifier loss: 0.185426; batch adversarial loss: 0.615744\n",
      "epoch 158; iter: 0; batch classifier loss: 0.160056; batch adversarial loss: 0.661453\n",
      "epoch 159; iter: 0; batch classifier loss: 0.190006; batch adversarial loss: 0.734293\n",
      "epoch 160; iter: 0; batch classifier loss: 0.134388; batch adversarial loss: 0.485569\n",
      "epoch 161; iter: 0; batch classifier loss: 0.146756; batch adversarial loss: 0.535188\n",
      "epoch 162; iter: 0; batch classifier loss: 0.205225; batch adversarial loss: 0.694222\n",
      "epoch 163; iter: 0; batch classifier loss: 0.204416; batch adversarial loss: 0.542128\n",
      "epoch 164; iter: 0; batch classifier loss: 0.163538; batch adversarial loss: 0.474818\n",
      "epoch 165; iter: 0; batch classifier loss: 0.104214; batch adversarial loss: 0.479074\n",
      "epoch 166; iter: 0; batch classifier loss: 0.142440; batch adversarial loss: 0.462016\n",
      "epoch 167; iter: 0; batch classifier loss: 0.230023; batch adversarial loss: 0.591340\n",
      "epoch 168; iter: 0; batch classifier loss: 0.180483; batch adversarial loss: 0.538317\n",
      "epoch 169; iter: 0; batch classifier loss: 0.205949; batch adversarial loss: 0.555420\n",
      "epoch 170; iter: 0; batch classifier loss: 0.162492; batch adversarial loss: 0.607207\n",
      "epoch 171; iter: 0; batch classifier loss: 0.158611; batch adversarial loss: 0.489420\n",
      "epoch 172; iter: 0; batch classifier loss: 0.095645; batch adversarial loss: 0.443989\n",
      "epoch 173; iter: 0; batch classifier loss: 0.135633; batch adversarial loss: 0.484435\n",
      "epoch 174; iter: 0; batch classifier loss: 0.227570; batch adversarial loss: 0.646151\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147285; batch adversarial loss: 0.499519\n",
      "epoch 176; iter: 0; batch classifier loss: 0.132062; batch adversarial loss: 0.493707\n",
      "epoch 177; iter: 0; batch classifier loss: 0.136152; batch adversarial loss: 0.477166\n",
      "epoch 178; iter: 0; batch classifier loss: 0.098656; batch adversarial loss: 0.441618\n",
      "epoch 179; iter: 0; batch classifier loss: 0.137076; batch adversarial loss: 0.453129\n",
      "epoch 180; iter: 0; batch classifier loss: 0.102589; batch adversarial loss: 0.396805\n",
      "epoch 181; iter: 0; batch classifier loss: 0.164656; batch adversarial loss: 0.489570\n",
      "epoch 182; iter: 0; batch classifier loss: 0.148449; batch adversarial loss: 0.531429\n",
      "epoch 183; iter: 0; batch classifier loss: 0.087634; batch adversarial loss: 0.435793\n",
      "epoch 184; iter: 0; batch classifier loss: 0.078728; batch adversarial loss: 0.355603\n",
      "epoch 185; iter: 0; batch classifier loss: 0.127676; batch adversarial loss: 0.421237\n",
      "epoch 186; iter: 0; batch classifier loss: 0.134824; batch adversarial loss: 0.453783\n",
      "epoch 187; iter: 0; batch classifier loss: 0.100378; batch adversarial loss: 0.454118\n",
      "epoch 188; iter: 0; batch classifier loss: 0.093757; batch adversarial loss: 0.398437\n",
      "epoch 189; iter: 0; batch classifier loss: 0.175114; batch adversarial loss: 0.491750\n",
      "epoch 190; iter: 0; batch classifier loss: 0.096515; batch adversarial loss: 0.335881\n",
      "epoch 191; iter: 0; batch classifier loss: 0.040362; batch adversarial loss: 0.451009\n",
      "epoch 192; iter: 0; batch classifier loss: 0.064752; batch adversarial loss: 0.495716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035161; batch adversarial loss: 0.457103\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034534; batch adversarial loss: 0.545961\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029945; batch adversarial loss: 0.437938\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020326; batch adversarial loss: 0.534610\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021144; batch adversarial loss: 0.413607\n",
      "epoch 198; iter: 0; batch classifier loss: 0.055856; batch adversarial loss: 0.369321\n",
      "epoch 199; iter: 0; batch classifier loss: 0.046237; batch adversarial loss: 0.442635\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685121; batch adversarial loss: 0.641201\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423180; batch adversarial loss: 0.609636\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412526; batch adversarial loss: 0.598789\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403952; batch adversarial loss: 0.554922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.350900; batch adversarial loss: 0.552449\n",
      "epoch 5; iter: 0; batch classifier loss: 0.333102; batch adversarial loss: 0.534308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349077; batch adversarial loss: 0.554198\n",
      "epoch 7; iter: 0; batch classifier loss: 0.266824; batch adversarial loss: 0.570532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.240365; batch adversarial loss: 0.545230\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300856; batch adversarial loss: 0.523453\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264346; batch adversarial loss: 0.540361\n",
      "epoch 11; iter: 0; batch classifier loss: 0.258295; batch adversarial loss: 0.553954\n",
      "epoch 12; iter: 0; batch classifier loss: 0.203849; batch adversarial loss: 0.526620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294017; batch adversarial loss: 0.528415\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285182; batch adversarial loss: 0.575790\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277118; batch adversarial loss: 0.478482\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330032; batch adversarial loss: 0.477997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373282; batch adversarial loss: 0.460869\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544187; batch adversarial loss: 0.440240\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427702; batch adversarial loss: 0.497546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.284885; batch adversarial loss: 0.460588\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242309; batch adversarial loss: 0.463732\n",
      "epoch 22; iter: 0; batch classifier loss: 0.204332; batch adversarial loss: 0.403367\n",
      "epoch 23; iter: 0; batch classifier loss: 0.166131; batch adversarial loss: 0.432034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159327; batch adversarial loss: 0.426811\n",
      "epoch 25; iter: 0; batch classifier loss: 0.190820; batch adversarial loss: 0.452848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126981; batch adversarial loss: 0.481529\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166143; batch adversarial loss: 0.541326\n",
      "epoch 28; iter: 0; batch classifier loss: 0.151420; batch adversarial loss: 0.482539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.131054; batch adversarial loss: 0.461140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.084283; batch adversarial loss: 0.487252\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139349; batch adversarial loss: 0.409665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.123122; batch adversarial loss: 0.539248\n",
      "epoch 33; iter: 0; batch classifier loss: 0.133021; batch adversarial loss: 0.373815\n",
      "epoch 34; iter: 0; batch classifier loss: 0.111305; batch adversarial loss: 0.426257\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110082; batch adversarial loss: 0.534471\n",
      "epoch 36; iter: 0; batch classifier loss: 0.137567; batch adversarial loss: 0.411726\n",
      "epoch 37; iter: 0; batch classifier loss: 0.109748; batch adversarial loss: 0.609779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130953; batch adversarial loss: 0.554400\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132155; batch adversarial loss: 0.443555\n",
      "epoch 40; iter: 0; batch classifier loss: 0.161897; batch adversarial loss: 0.482280\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173237; batch adversarial loss: 0.463019\n",
      "epoch 42; iter: 0; batch classifier loss: 0.122548; batch adversarial loss: 0.463069\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084162; batch adversarial loss: 0.346580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130329; batch adversarial loss: 0.510120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103925; batch adversarial loss: 0.460471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116452; batch adversarial loss: 0.489661\n",
      "epoch 47; iter: 0; batch classifier loss: 0.125617; batch adversarial loss: 0.501068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097866; batch adversarial loss: 0.469803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086027; batch adversarial loss: 0.514511\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085915; batch adversarial loss: 0.549500\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116331; batch adversarial loss: 0.603281\n",
      "epoch 52; iter: 0; batch classifier loss: 0.088766; batch adversarial loss: 0.438891\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094678; batch adversarial loss: 0.510502\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114044; batch adversarial loss: 0.396797\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123557; batch adversarial loss: 0.493067\n",
      "epoch 56; iter: 0; batch classifier loss: 0.121701; batch adversarial loss: 0.512689\n",
      "epoch 57; iter: 0; batch classifier loss: 0.185744; batch adversarial loss: 0.453606\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133983; batch adversarial loss: 0.417387\n",
      "epoch 59; iter: 0; batch classifier loss: 0.093805; batch adversarial loss: 0.435505\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146229; batch adversarial loss: 0.388483\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104135; batch adversarial loss: 0.402300\n",
      "epoch 62; iter: 0; batch classifier loss: 0.079079; batch adversarial loss: 0.363970\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071310; batch adversarial loss: 0.540756\n",
      "epoch 64; iter: 0; batch classifier loss: 0.104254; batch adversarial loss: 0.354723\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070295; batch adversarial loss: 0.423502\n",
      "epoch 66; iter: 0; batch classifier loss: 0.100006; batch adversarial loss: 0.547563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124076; batch adversarial loss: 0.448435\n",
      "epoch 68; iter: 0; batch classifier loss: 0.154058; batch adversarial loss: 0.463831\n",
      "epoch 69; iter: 0; batch classifier loss: 0.108417; batch adversarial loss: 0.402675\n",
      "epoch 70; iter: 0; batch classifier loss: 0.101233; batch adversarial loss: 0.490841\n",
      "epoch 71; iter: 0; batch classifier loss: 0.073327; batch adversarial loss: 0.544799\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081929; batch adversarial loss: 0.398066\n",
      "epoch 73; iter: 0; batch classifier loss: 0.119080; batch adversarial loss: 0.462798\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066093; batch adversarial loss: 0.432534\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130133; batch adversarial loss: 0.528746\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093896; batch adversarial loss: 0.427953\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071538; batch adversarial loss: 0.490554\n",
      "epoch 78; iter: 0; batch classifier loss: 0.110313; batch adversarial loss: 0.542952\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068476; batch adversarial loss: 0.551156\n",
      "epoch 80; iter: 0; batch classifier loss: 0.068225; batch adversarial loss: 0.505857\n",
      "epoch 81; iter: 0; batch classifier loss: 0.073079; batch adversarial loss: 0.414505\n",
      "epoch 82; iter: 0; batch classifier loss: 0.174128; batch adversarial loss: 0.438274\n",
      "epoch 83; iter: 0; batch classifier loss: 0.094172; batch adversarial loss: 0.482917\n",
      "epoch 84; iter: 0; batch classifier loss: 0.080521; batch adversarial loss: 0.445830\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086488; batch adversarial loss: 0.394516\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071375; batch adversarial loss: 0.489485\n",
      "epoch 87; iter: 0; batch classifier loss: 0.052891; batch adversarial loss: 0.407035\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063258; batch adversarial loss: 0.355840\n",
      "epoch 89; iter: 0; batch classifier loss: 0.102248; batch adversarial loss: 0.415406\n",
      "epoch 90; iter: 0; batch classifier loss: 0.119346; batch adversarial loss: 0.446887\n",
      "epoch 91; iter: 0; batch classifier loss: 0.079720; batch adversarial loss: 0.447783\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055588; batch adversarial loss: 0.443121\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067370; batch adversarial loss: 0.545601\n",
      "epoch 94; iter: 0; batch classifier loss: 0.094694; batch adversarial loss: 0.410998\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073639; batch adversarial loss: 0.454120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.087845; batch adversarial loss: 0.355329\n",
      "epoch 97; iter: 0; batch classifier loss: 0.071320; batch adversarial loss: 0.413077\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062246; batch adversarial loss: 0.475238\n",
      "epoch 99; iter: 0; batch classifier loss: 0.085024; batch adversarial loss: 0.480004\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094473; batch adversarial loss: 0.451285\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098717; batch adversarial loss: 0.511256\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048228; batch adversarial loss: 0.501822\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071642; batch adversarial loss: 0.508333\n",
      "epoch 104; iter: 0; batch classifier loss: 0.014099; batch adversarial loss: 0.536181\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084764; batch adversarial loss: 0.534728\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075109; batch adversarial loss: 0.433537\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046706; batch adversarial loss: 0.460663\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033997; batch adversarial loss: 0.456382\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070767; batch adversarial loss: 0.453919\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050420; batch adversarial loss: 0.544940\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069611; batch adversarial loss: 0.535812\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038169; batch adversarial loss: 0.414470\n",
      "epoch 113; iter: 0; batch classifier loss: 0.088137; batch adversarial loss: 0.433485\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054106; batch adversarial loss: 0.431845\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039061; batch adversarial loss: 0.506657\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071074; batch adversarial loss: 0.431106\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038724; batch adversarial loss: 0.501994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.042691; batch adversarial loss: 0.488204\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065233; batch adversarial loss: 0.389701\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042411; batch adversarial loss: 0.428270\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041713; batch adversarial loss: 0.418280\n",
      "epoch 122; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.508747\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036917; batch adversarial loss: 0.478470\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016037; batch adversarial loss: 0.511178\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023268; batch adversarial loss: 0.427355\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042031; batch adversarial loss: 0.551098\n",
      "epoch 127; iter: 0; batch classifier loss: 0.016706; batch adversarial loss: 0.464868\n",
      "epoch 128; iter: 0; batch classifier loss: 0.045324; batch adversarial loss: 0.411138\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024543; batch adversarial loss: 0.418165\n",
      "epoch 130; iter: 0; batch classifier loss: 0.028515; batch adversarial loss: 0.456351\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058288; batch adversarial loss: 0.509981\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040043; batch adversarial loss: 0.422729\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034007; batch adversarial loss: 0.465238\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051052; batch adversarial loss: 0.354683\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046857; batch adversarial loss: 0.397609\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040877; batch adversarial loss: 0.408352\n",
      "epoch 137; iter: 0; batch classifier loss: 0.041838; batch adversarial loss: 0.388176\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023690; batch adversarial loss: 0.417869\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033491; batch adversarial loss: 0.519893\n",
      "epoch 140; iter: 0; batch classifier loss: 0.075886; batch adversarial loss: 0.433751\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017135; batch adversarial loss: 0.476444\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015461; batch adversarial loss: 0.425130\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046522; batch adversarial loss: 0.459841\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024382; batch adversarial loss: 0.451538\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045040; batch adversarial loss: 0.558298\n",
      "epoch 146; iter: 0; batch classifier loss: 0.050986; batch adversarial loss: 0.482318\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024258; batch adversarial loss: 0.494961\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014871; batch adversarial loss: 0.430448\n",
      "epoch 149; iter: 0; batch classifier loss: 0.070610; batch adversarial loss: 0.484035\n",
      "epoch 150; iter: 0; batch classifier loss: 0.061377; batch adversarial loss: 0.509672\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012068; batch adversarial loss: 0.574643\n",
      "epoch 152; iter: 0; batch classifier loss: 0.045626; batch adversarial loss: 0.402034\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011917; batch adversarial loss: 0.508031\n",
      "epoch 154; iter: 0; batch classifier loss: 0.016584; batch adversarial loss: 0.429822\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018509; batch adversarial loss: 0.450472\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019586; batch adversarial loss: 0.526396\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023544; batch adversarial loss: 0.485589\n",
      "epoch 158; iter: 0; batch classifier loss: 0.016271; batch adversarial loss: 0.507864\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013134; batch adversarial loss: 0.315062\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017947; batch adversarial loss: 0.623160\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026119; batch adversarial loss: 0.499643\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041689; batch adversarial loss: 0.421117\n",
      "epoch 163; iter: 0; batch classifier loss: 0.060242; batch adversarial loss: 0.399173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035042; batch adversarial loss: 0.412884\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.458991\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025277; batch adversarial loss: 0.385154\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029657; batch adversarial loss: 0.436166\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038006; batch adversarial loss: 0.497758\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017563; batch adversarial loss: 0.492563\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046762; batch adversarial loss: 0.389262\n",
      "epoch 171; iter: 0; batch classifier loss: 0.060281; batch adversarial loss: 0.503089\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011367; batch adversarial loss: 0.435506\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018920; batch adversarial loss: 0.429569\n",
      "epoch 174; iter: 0; batch classifier loss: 0.047625; batch adversarial loss: 0.381306\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029582; batch adversarial loss: 0.422191\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014953; batch adversarial loss: 0.462521\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024692; batch adversarial loss: 0.348935\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022402; batch adversarial loss: 0.422991\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044763; batch adversarial loss: 0.392369\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009949; batch adversarial loss: 0.455903\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035544; batch adversarial loss: 0.467060\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028851; batch adversarial loss: 0.484704\n",
      "epoch 183; iter: 0; batch classifier loss: 0.016796; batch adversarial loss: 0.410268\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025033; batch adversarial loss: 0.436776\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028853; batch adversarial loss: 0.511203\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009486; batch adversarial loss: 0.390350\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033952; batch adversarial loss: 0.398853\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010692; batch adversarial loss: 0.512102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021599; batch adversarial loss: 0.414645\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020296; batch adversarial loss: 0.499714\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011171; batch adversarial loss: 0.494220\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005307; batch adversarial loss: 0.419339\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011822; batch adversarial loss: 0.424224\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011839; batch adversarial loss: 0.646001\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015014; batch adversarial loss: 0.461144\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008917; batch adversarial loss: 0.449223\n",
      "epoch 197; iter: 0; batch classifier loss: 0.007434; batch adversarial loss: 0.514819\n",
      "epoch 198; iter: 0; batch classifier loss: 0.026617; batch adversarial loss: 0.449498\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011438; batch adversarial loss: 0.450464\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700713; batch adversarial loss: 0.664316\n",
      "epoch 1; iter: 0; batch classifier loss: 0.452714; batch adversarial loss: 0.637333\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399528; batch adversarial loss: 0.616838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.354836; batch adversarial loss: 0.581190\n",
      "epoch 4; iter: 0; batch classifier loss: 0.319646; batch adversarial loss: 0.603923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.359003; batch adversarial loss: 0.564562\n",
      "epoch 6; iter: 0; batch classifier loss: 0.265451; batch adversarial loss: 0.520250\n",
      "epoch 7; iter: 0; batch classifier loss: 0.233907; batch adversarial loss: 0.524376\n",
      "epoch 8; iter: 0; batch classifier loss: 0.218389; batch adversarial loss: 0.526322\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242634; batch adversarial loss: 0.528655\n",
      "epoch 10; iter: 0; batch classifier loss: 0.179520; batch adversarial loss: 0.506143\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267052; batch adversarial loss: 0.468875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.224291; batch adversarial loss: 0.550531\n",
      "epoch 13; iter: 0; batch classifier loss: 0.198800; batch adversarial loss: 0.501008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.287696; batch adversarial loss: 0.509484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.189067; batch adversarial loss: 0.589774\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211885; batch adversarial loss: 0.511035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192407; batch adversarial loss: 0.503440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.230677; batch adversarial loss: 0.503284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.225208; batch adversarial loss: 0.523064\n",
      "epoch 20; iter: 0; batch classifier loss: 0.249700; batch adversarial loss: 0.468641\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258242; batch adversarial loss: 0.491922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.192461; batch adversarial loss: 0.458070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342355; batch adversarial loss: 0.562356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377270; batch adversarial loss: 0.447232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395708; batch adversarial loss: 0.517708\n",
      "epoch 26; iter: 0; batch classifier loss: 0.333125; batch adversarial loss: 0.430541\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175020; batch adversarial loss: 0.451087\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158579; batch adversarial loss: 0.510540\n",
      "epoch 29; iter: 0; batch classifier loss: 0.169298; batch adversarial loss: 0.433505\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134935; batch adversarial loss: 0.451848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133587; batch adversarial loss: 0.478368\n",
      "epoch 32; iter: 0; batch classifier loss: 0.097490; batch adversarial loss: 0.395863\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118815; batch adversarial loss: 0.509840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154077; batch adversarial loss: 0.449709\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096448; batch adversarial loss: 0.422366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.120356; batch adversarial loss: 0.464683\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075433; batch adversarial loss: 0.450281\n",
      "epoch 38; iter: 0; batch classifier loss: 0.096390; batch adversarial loss: 0.491317\n",
      "epoch 39; iter: 0; batch classifier loss: 0.119911; batch adversarial loss: 0.431940\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103057; batch adversarial loss: 0.461658\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129286; batch adversarial loss: 0.537073\n",
      "epoch 42; iter: 0; batch classifier loss: 0.086493; batch adversarial loss: 0.406025\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097796; batch adversarial loss: 0.523067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.063156; batch adversarial loss: 0.566069\n",
      "epoch 45; iter: 0; batch classifier loss: 0.108616; batch adversarial loss: 0.525500\n",
      "epoch 46; iter: 0; batch classifier loss: 0.072372; batch adversarial loss: 0.431832\n",
      "epoch 47; iter: 0; batch classifier loss: 0.134456; batch adversarial loss: 0.450439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082104; batch adversarial loss: 0.498917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089107; batch adversarial loss: 0.427818\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117568; batch adversarial loss: 0.374080\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085496; batch adversarial loss: 0.542197\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099029; batch adversarial loss: 0.487488\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068043; batch adversarial loss: 0.458761\n",
      "epoch 54; iter: 0; batch classifier loss: 0.080682; batch adversarial loss: 0.478599\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073365; batch adversarial loss: 0.398791\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067476; batch adversarial loss: 0.451144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087491; batch adversarial loss: 0.503749\n",
      "epoch 58; iter: 0; batch classifier loss: 0.136168; batch adversarial loss: 0.452019\n",
      "epoch 59; iter: 0; batch classifier loss: 0.094433; batch adversarial loss: 0.475737\n",
      "epoch 60; iter: 0; batch classifier loss: 0.125933; batch adversarial loss: 0.350853\n",
      "epoch 61; iter: 0; batch classifier loss: 0.077638; batch adversarial loss: 0.493205\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071874; batch adversarial loss: 0.500220\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086234; batch adversarial loss: 0.470419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.123779; batch adversarial loss: 0.389276\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088090; batch adversarial loss: 0.517605\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083446; batch adversarial loss: 0.429066\n",
      "epoch 67; iter: 0; batch classifier loss: 0.070859; batch adversarial loss: 0.415744\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126518; batch adversarial loss: 0.431045\n",
      "epoch 69; iter: 0; batch classifier loss: 0.092107; batch adversarial loss: 0.540375\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117913; batch adversarial loss: 0.434729\n",
      "epoch 71; iter: 0; batch classifier loss: 0.099319; batch adversarial loss: 0.469658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.096980; batch adversarial loss: 0.468235\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092617; batch adversarial loss: 0.452806\n",
      "epoch 74; iter: 0; batch classifier loss: 0.117876; batch adversarial loss: 0.466439\n",
      "epoch 75; iter: 0; batch classifier loss: 0.078346; batch adversarial loss: 0.384357\n",
      "epoch 76; iter: 0; batch classifier loss: 0.084861; batch adversarial loss: 0.381217\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056309; batch adversarial loss: 0.479815\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068960; batch adversarial loss: 0.589330\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107027; batch adversarial loss: 0.593176\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054007; batch adversarial loss: 0.465075\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109151; batch adversarial loss: 0.423781\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084893; batch adversarial loss: 0.454947\n",
      "epoch 83; iter: 0; batch classifier loss: 0.112040; batch adversarial loss: 0.432273\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046488; batch adversarial loss: 0.418751\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070274; batch adversarial loss: 0.461038\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047463; batch adversarial loss: 0.478427\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076313; batch adversarial loss: 0.448367\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140602; batch adversarial loss: 0.284660\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058515; batch adversarial loss: 0.483647\n",
      "epoch 90; iter: 0; batch classifier loss: 0.096067; batch adversarial loss: 0.386902\n",
      "epoch 91; iter: 0; batch classifier loss: 0.063622; batch adversarial loss: 0.344214\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117070; batch adversarial loss: 0.530917\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080310; batch adversarial loss: 0.510006\n",
      "epoch 94; iter: 0; batch classifier loss: 0.101678; batch adversarial loss: 0.501846\n",
      "epoch 95; iter: 0; batch classifier loss: 0.034216; batch adversarial loss: 0.513228\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062323; batch adversarial loss: 0.398635\n",
      "epoch 97; iter: 0; batch classifier loss: 0.067392; batch adversarial loss: 0.526727\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065323; batch adversarial loss: 0.468683\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064641; batch adversarial loss: 0.437573\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037442; batch adversarial loss: 0.419497\n",
      "epoch 101; iter: 0; batch classifier loss: 0.028151; batch adversarial loss: 0.491770\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024945; batch adversarial loss: 0.523493\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082894; batch adversarial loss: 0.418022\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054227; batch adversarial loss: 0.375045\n",
      "epoch 105; iter: 0; batch classifier loss: 0.080426; batch adversarial loss: 0.487760\n",
      "epoch 106; iter: 0; batch classifier loss: 0.032118; batch adversarial loss: 0.556323\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055824; batch adversarial loss: 0.404035\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042612; batch adversarial loss: 0.529697\n",
      "epoch 109; iter: 0; batch classifier loss: 0.057025; batch adversarial loss: 0.480012\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063943; batch adversarial loss: 0.423959\n",
      "epoch 111; iter: 0; batch classifier loss: 0.025781; batch adversarial loss: 0.508579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.084650; batch adversarial loss: 0.516823\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037678; batch adversarial loss: 0.457234\n",
      "epoch 114; iter: 0; batch classifier loss: 0.020819; batch adversarial loss: 0.464551\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070301; batch adversarial loss: 0.479792\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080579; batch adversarial loss: 0.502993\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022781; batch adversarial loss: 0.474329\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024766; batch adversarial loss: 0.517102\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034193; batch adversarial loss: 0.503745\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022953; batch adversarial loss: 0.433324\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036556; batch adversarial loss: 0.546950\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036721; batch adversarial loss: 0.485070\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029101; batch adversarial loss: 0.427686\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046798; batch adversarial loss: 0.412880\n",
      "epoch 125; iter: 0; batch classifier loss: 0.051759; batch adversarial loss: 0.432671\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039834; batch adversarial loss: 0.424514\n",
      "epoch 127; iter: 0; batch classifier loss: 0.006504; batch adversarial loss: 0.527948\n",
      "epoch 128; iter: 0; batch classifier loss: 0.060440; batch adversarial loss: 0.514141\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.462094\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051493; batch adversarial loss: 0.547566\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055918; batch adversarial loss: 0.479047\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028692; batch adversarial loss: 0.597250\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028289; batch adversarial loss: 0.437599\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039953; batch adversarial loss: 0.407456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035889; batch adversarial loss: 0.419561\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022611; batch adversarial loss: 0.478507\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028170; batch adversarial loss: 0.550015\n",
      "epoch 138; iter: 0; batch classifier loss: 0.034820; batch adversarial loss: 0.417231\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034182; batch adversarial loss: 0.429009\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048757; batch adversarial loss: 0.581761\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047294; batch adversarial loss: 0.397056\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021463; batch adversarial loss: 0.468955\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013950; batch adversarial loss: 0.548824\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041562; batch adversarial loss: 0.494723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010706; batch adversarial loss: 0.453542\n",
      "epoch 146; iter: 0; batch classifier loss: 0.062248; batch adversarial loss: 0.442404\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047316; batch adversarial loss: 0.533695\n",
      "epoch 148; iter: 0; batch classifier loss: 0.010417; batch adversarial loss: 0.478402\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019023; batch adversarial loss: 0.538660\n",
      "epoch 150; iter: 0; batch classifier loss: 0.031305; batch adversarial loss: 0.448774\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024857; batch adversarial loss: 0.468927\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013024; batch adversarial loss: 0.503051\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008897; batch adversarial loss: 0.390834\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018183; batch adversarial loss: 0.485891\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018713; batch adversarial loss: 0.402121\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033116; batch adversarial loss: 0.459027\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026143; batch adversarial loss: 0.427039\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024065; batch adversarial loss: 0.425269\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034018; batch adversarial loss: 0.458491\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030233; batch adversarial loss: 0.537371\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033047; batch adversarial loss: 0.563628\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013705; batch adversarial loss: 0.443862\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023904; batch adversarial loss: 0.468260\n",
      "epoch 164; iter: 0; batch classifier loss: 0.035622; batch adversarial loss: 0.580925\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013081; batch adversarial loss: 0.466825\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011816; batch adversarial loss: 0.506357\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022578; batch adversarial loss: 0.440105\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031533; batch adversarial loss: 0.498155\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037794; batch adversarial loss: 0.478168\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.435990\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032740; batch adversarial loss: 0.399305\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023773; batch adversarial loss: 0.479431\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019539; batch adversarial loss: 0.472560\n",
      "epoch 174; iter: 0; batch classifier loss: 0.030038; batch adversarial loss: 0.350753\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013276; batch adversarial loss: 0.492139\n",
      "epoch 176; iter: 0; batch classifier loss: 0.035574; batch adversarial loss: 0.471134\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029188; batch adversarial loss: 0.413909\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019609; batch adversarial loss: 0.409287\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017706; batch adversarial loss: 0.515253\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022083; batch adversarial loss: 0.443941\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.444795\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021556; batch adversarial loss: 0.406628\n",
      "epoch 183; iter: 0; batch classifier loss: 0.054788; batch adversarial loss: 0.493455\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019599; batch adversarial loss: 0.479227\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.450862\n",
      "epoch 186; iter: 0; batch classifier loss: 0.020347; batch adversarial loss: 0.495027\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011360; batch adversarial loss: 0.542496\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014279; batch adversarial loss: 0.513669\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017394; batch adversarial loss: 0.466052\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018051; batch adversarial loss: 0.455634\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012309; batch adversarial loss: 0.486888\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029119; batch adversarial loss: 0.427698\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012864; batch adversarial loss: 0.538306\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011371; batch adversarial loss: 0.464746\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027656; batch adversarial loss: 0.417651\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030037; batch adversarial loss: 0.502141\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020769; batch adversarial loss: 0.394156\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022059; batch adversarial loss: 0.432352\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027663; batch adversarial loss: 0.405158\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723049; batch adversarial loss: 0.663271\n",
      "epoch 1; iter: 0; batch classifier loss: 0.493688; batch adversarial loss: 0.638440\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429277; batch adversarial loss: 0.627563\n",
      "epoch 3; iter: 0; batch classifier loss: 0.484000; batch adversarial loss: 0.601697\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393289; batch adversarial loss: 0.586755\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418220; batch adversarial loss: 0.572165\n",
      "epoch 6; iter: 0; batch classifier loss: 0.430857; batch adversarial loss: 0.600697\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474299; batch adversarial loss: 0.529316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.347557; batch adversarial loss: 0.522532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 0; batch classifier loss: 0.503810; batch adversarial loss: 0.481268\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434357; batch adversarial loss: 0.572409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409031; batch adversarial loss: 0.511619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366442; batch adversarial loss: 0.535013\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419107; batch adversarial loss: 0.562436\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314776; batch adversarial loss: 0.488487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349033; batch adversarial loss: 0.459830\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297774; batch adversarial loss: 0.484188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380557; batch adversarial loss: 0.456639\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320338; batch adversarial loss: 0.454129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313415; batch adversarial loss: 0.462752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.261113; batch adversarial loss: 0.497436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.261040; batch adversarial loss: 0.435501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271782; batch adversarial loss: 0.551646\n",
      "epoch 23; iter: 0; batch classifier loss: 0.254268; batch adversarial loss: 0.489084\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271129; batch adversarial loss: 0.491823\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267106; batch adversarial loss: 0.414623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239672; batch adversarial loss: 0.515519\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199473; batch adversarial loss: 0.436578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267209; batch adversarial loss: 0.460695\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272976; batch adversarial loss: 0.490726\n",
      "epoch 30; iter: 0; batch classifier loss: 0.273970; batch adversarial loss: 0.506448\n",
      "epoch 31; iter: 0; batch classifier loss: 0.202476; batch adversarial loss: 0.485155\n",
      "epoch 32; iter: 0; batch classifier loss: 0.350466; batch adversarial loss: 0.459795\n",
      "epoch 33; iter: 0; batch classifier loss: 0.289544; batch adversarial loss: 0.528514\n",
      "epoch 34; iter: 0; batch classifier loss: 0.285218; batch adversarial loss: 0.486536\n",
      "epoch 35; iter: 0; batch classifier loss: 0.313927; batch adversarial loss: 0.459824\n",
      "epoch 36; iter: 0; batch classifier loss: 0.276111; batch adversarial loss: 0.460255\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214381; batch adversarial loss: 0.390674\n",
      "epoch 38; iter: 0; batch classifier loss: 0.312109; batch adversarial loss: 0.438526\n",
      "epoch 39; iter: 0; batch classifier loss: 0.286103; batch adversarial loss: 0.426513\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240222; batch adversarial loss: 0.411743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.317432; batch adversarial loss: 0.495743\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283605; batch adversarial loss: 0.353533\n",
      "epoch 43; iter: 0; batch classifier loss: 0.138249; batch adversarial loss: 0.350257\n",
      "epoch 44; iter: 0; batch classifier loss: 0.127557; batch adversarial loss: 0.542723\n",
      "epoch 45; iter: 0; batch classifier loss: 0.135528; batch adversarial loss: 0.445068\n",
      "epoch 46; iter: 0; batch classifier loss: 0.079029; batch adversarial loss: 0.392039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.073478; batch adversarial loss: 0.514022\n",
      "epoch 48; iter: 0; batch classifier loss: 0.067785; batch adversarial loss: 0.416244\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080517; batch adversarial loss: 0.426360\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099344; batch adversarial loss: 0.495273\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072686; batch adversarial loss: 0.486953\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071084; batch adversarial loss: 0.494483\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122068; batch adversarial loss: 0.448248\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098643; batch adversarial loss: 0.431897\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098484; batch adversarial loss: 0.412514\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080644; batch adversarial loss: 0.373720\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062740; batch adversarial loss: 0.428078\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101146; batch adversarial loss: 0.464946\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077442; batch adversarial loss: 0.485540\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047642; batch adversarial loss: 0.436505\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100646; batch adversarial loss: 0.369161\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065674; batch adversarial loss: 0.434525\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057800; batch adversarial loss: 0.358872\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084219; batch adversarial loss: 0.377968\n",
      "epoch 65; iter: 0; batch classifier loss: 0.048380; batch adversarial loss: 0.265593\n",
      "epoch 66; iter: 0; batch classifier loss: 0.035434; batch adversarial loss: 0.419687\n",
      "epoch 67; iter: 0; batch classifier loss: 0.055804; batch adversarial loss: 0.414644\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081955; batch adversarial loss: 0.316719\n",
      "epoch 69; iter: 0; batch classifier loss: 0.065340; batch adversarial loss: 0.416540\n",
      "epoch 70; iter: 0; batch classifier loss: 0.077100; batch adversarial loss: 0.399587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063656; batch adversarial loss: 0.415344\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047539; batch adversarial loss: 0.441089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069911; batch adversarial loss: 0.370117\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052686; batch adversarial loss: 0.383003\n",
      "epoch 75; iter: 0; batch classifier loss: 0.051129; batch adversarial loss: 0.314909\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049419; batch adversarial loss: 0.488279\n",
      "epoch 77; iter: 0; batch classifier loss: 0.094968; batch adversarial loss: 0.376765\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066806; batch adversarial loss: 0.429040\n",
      "epoch 79; iter: 0; batch classifier loss: 0.041341; batch adversarial loss: 0.453134\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101534; batch adversarial loss: 0.378673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057200; batch adversarial loss: 0.377270\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065839; batch adversarial loss: 0.387485\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068380; batch adversarial loss: 0.355631\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062891; batch adversarial loss: 0.450823\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088699; batch adversarial loss: 0.463454\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064167; batch adversarial loss: 0.433526\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042590; batch adversarial loss: 0.364504\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037409; batch adversarial loss: 0.435578\n",
      "epoch 89; iter: 0; batch classifier loss: 0.043931; batch adversarial loss: 0.511773\n",
      "epoch 90; iter: 0; batch classifier loss: 0.049896; batch adversarial loss: 0.459081\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064350; batch adversarial loss: 0.457359\n",
      "epoch 92; iter: 0; batch classifier loss: 0.046878; batch adversarial loss: 0.428163\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060674; batch adversarial loss: 0.433756\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046797; batch adversarial loss: 0.469228\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087845; batch adversarial loss: 0.451983\n",
      "epoch 96; iter: 0; batch classifier loss: 0.079237; batch adversarial loss: 0.461967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060772; batch adversarial loss: 0.382607\n",
      "epoch 98; iter: 0; batch classifier loss: 0.089645; batch adversarial loss: 0.512603\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059698; batch adversarial loss: 0.450427\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055941; batch adversarial loss: 0.376275\n",
      "epoch 101; iter: 0; batch classifier loss: 0.054263; batch adversarial loss: 0.489370\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046658; batch adversarial loss: 0.376182\n",
      "epoch 103; iter: 0; batch classifier loss: 0.037879; batch adversarial loss: 0.403287\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042418; batch adversarial loss: 0.333121\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053420; batch adversarial loss: 0.369069\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048330; batch adversarial loss: 0.422657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 0; batch classifier loss: 0.066381; batch adversarial loss: 0.404062\n",
      "epoch 108; iter: 0; batch classifier loss: 0.092160; batch adversarial loss: 0.306424\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047688; batch adversarial loss: 0.417006\n",
      "epoch 110; iter: 0; batch classifier loss: 0.072570; batch adversarial loss: 0.449009\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042292; batch adversarial loss: 0.395916\n",
      "epoch 112; iter: 0; batch classifier loss: 0.054068; batch adversarial loss: 0.435987\n",
      "epoch 113; iter: 0; batch classifier loss: 0.064099; batch adversarial loss: 0.374403\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047241; batch adversarial loss: 0.341726\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041654; batch adversarial loss: 0.364856\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067741; batch adversarial loss: 0.376093\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051049; batch adversarial loss: 0.467139\n",
      "epoch 118; iter: 0; batch classifier loss: 0.064914; batch adversarial loss: 0.421662\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082875; batch adversarial loss: 0.339155\n",
      "epoch 120; iter: 0; batch classifier loss: 0.032165; batch adversarial loss: 0.455528\n",
      "epoch 121; iter: 0; batch classifier loss: 0.050369; batch adversarial loss: 0.496105\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037136; batch adversarial loss: 0.355130\n",
      "epoch 123; iter: 0; batch classifier loss: 0.072291; batch adversarial loss: 0.402952\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.472287\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050748; batch adversarial loss: 0.366518\n",
      "epoch 126; iter: 0; batch classifier loss: 0.049754; batch adversarial loss: 0.375012\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047964; batch adversarial loss: 0.408798\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053823; batch adversarial loss: 0.450983\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046420; batch adversarial loss: 0.570742\n",
      "epoch 130; iter: 0; batch classifier loss: 0.076154; batch adversarial loss: 0.367016\n",
      "epoch 131; iter: 0; batch classifier loss: 0.036774; batch adversarial loss: 0.389934\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043812; batch adversarial loss: 0.363201\n",
      "epoch 133; iter: 0; batch classifier loss: 0.023396; batch adversarial loss: 0.495826\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036374; batch adversarial loss: 0.411973\n",
      "epoch 135; iter: 0; batch classifier loss: 0.025234; batch adversarial loss: 0.354668\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043570; batch adversarial loss: 0.396961\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056548; batch adversarial loss: 0.494016\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029642; batch adversarial loss: 0.330609\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042205; batch adversarial loss: 0.359801\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048621; batch adversarial loss: 0.478564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048521; batch adversarial loss: 0.478541\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034535; batch adversarial loss: 0.392677\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023194; batch adversarial loss: 0.377873\n",
      "epoch 144; iter: 0; batch classifier loss: 0.021620; batch adversarial loss: 0.440346\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043048; batch adversarial loss: 0.403211\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023307; batch adversarial loss: 0.432868\n",
      "epoch 147; iter: 0; batch classifier loss: 0.048040; batch adversarial loss: 0.381559\n",
      "epoch 148; iter: 0; batch classifier loss: 0.029446; batch adversarial loss: 0.338220\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033940; batch adversarial loss: 0.433637\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016321; batch adversarial loss: 0.376431\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016482; batch adversarial loss: 0.472377\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039185; batch adversarial loss: 0.458228\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030156; batch adversarial loss: 0.355345\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018813; batch adversarial loss: 0.412564\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048146; batch adversarial loss: 0.388262\n",
      "epoch 156; iter: 0; batch classifier loss: 0.032029; batch adversarial loss: 0.433223\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019166; batch adversarial loss: 0.413777\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047871; batch adversarial loss: 0.387139\n",
      "epoch 159; iter: 0; batch classifier loss: 0.028529; batch adversarial loss: 0.431189\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022604; batch adversarial loss: 0.442544\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034609; batch adversarial loss: 0.471684\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.435544\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022232; batch adversarial loss: 0.402076\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031016; batch adversarial loss: 0.380777\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022440; batch adversarial loss: 0.398974\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022745; batch adversarial loss: 0.379217\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029154; batch adversarial loss: 0.467961\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028173; batch adversarial loss: 0.392871\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019247; batch adversarial loss: 0.331703\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030195; batch adversarial loss: 0.439044\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014997; batch adversarial loss: 0.549733\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030029; batch adversarial loss: 0.429250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029244; batch adversarial loss: 0.447331\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010209; batch adversarial loss: 0.395999\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038223; batch adversarial loss: 0.452605\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022294; batch adversarial loss: 0.375366\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025201; batch adversarial loss: 0.436762\n",
      "epoch 178; iter: 0; batch classifier loss: 0.023386; batch adversarial loss: 0.421306\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014410; batch adversarial loss: 0.479709\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017505; batch adversarial loss: 0.536187\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044623; batch adversarial loss: 0.406383\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018975; batch adversarial loss: 0.410722\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010194; batch adversarial loss: 0.556630\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013288; batch adversarial loss: 0.553758\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011715; batch adversarial loss: 0.450134\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019097; batch adversarial loss: 0.330659\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030885; batch adversarial loss: 0.444589\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048251; batch adversarial loss: 0.397104\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011635; batch adversarial loss: 0.361159\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027560; batch adversarial loss: 0.448609\n",
      "epoch 191; iter: 0; batch classifier loss: 0.013549; batch adversarial loss: 0.403137\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008027; batch adversarial loss: 0.404289\n",
      "epoch 193; iter: 0; batch classifier loss: 0.027647; batch adversarial loss: 0.352485\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022581; batch adversarial loss: 0.476093\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024964; batch adversarial loss: 0.554145\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021459; batch adversarial loss: 0.390419\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022607; batch adversarial loss: 0.489416\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013346; batch adversarial loss: 0.526990\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016660; batch adversarial loss: 0.448713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701098; batch adversarial loss: 0.560915\n",
      "epoch 1; iter: 0; batch classifier loss: 0.413978; batch adversarial loss: 0.590079\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467775; batch adversarial loss: 0.603445\n",
      "epoch 3; iter: 0; batch classifier loss: 0.295901; batch adversarial loss: 0.538256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.389423; batch adversarial loss: 0.563479\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408402; batch adversarial loss: 0.539864\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358161; batch adversarial loss: 0.579005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306867; batch adversarial loss: 0.476540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343277; batch adversarial loss: 0.536220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289408; batch adversarial loss: 0.556615\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316938; batch adversarial loss: 0.509910\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273909; batch adversarial loss: 0.557929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379050; batch adversarial loss: 0.493604\n",
      "epoch 13; iter: 0; batch classifier loss: 0.410131; batch adversarial loss: 0.465520\n",
      "epoch 14; iter: 0; batch classifier loss: 0.496628; batch adversarial loss: 0.557332\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484345; batch adversarial loss: 0.446027\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285799; batch adversarial loss: 0.489956\n",
      "epoch 17; iter: 0; batch classifier loss: 0.253355; batch adversarial loss: 0.461647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.269759; batch adversarial loss: 0.463226\n",
      "epoch 19; iter: 0; batch classifier loss: 0.240392; batch adversarial loss: 0.464782\n",
      "epoch 20; iter: 0; batch classifier loss: 0.212154; batch adversarial loss: 0.491047\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146135; batch adversarial loss: 0.494336\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166155; batch adversarial loss: 0.460652\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213882; batch adversarial loss: 0.434647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.133307; batch adversarial loss: 0.399383\n",
      "epoch 25; iter: 0; batch classifier loss: 0.198968; batch adversarial loss: 0.515777\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137703; batch adversarial loss: 0.461837\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151870; batch adversarial loss: 0.475861\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175015; batch adversarial loss: 0.419180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147509; batch adversarial loss: 0.429185\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148240; batch adversarial loss: 0.402961\n",
      "epoch 31; iter: 0; batch classifier loss: 0.190794; batch adversarial loss: 0.491097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147724; batch adversarial loss: 0.526876\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125199; batch adversarial loss: 0.454685\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149864; batch adversarial loss: 0.496323\n",
      "epoch 35; iter: 0; batch classifier loss: 0.137071; batch adversarial loss: 0.463285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.087263; batch adversarial loss: 0.491461\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101267; batch adversarial loss: 0.475617\n",
      "epoch 38; iter: 0; batch classifier loss: 0.152822; batch adversarial loss: 0.539432\n",
      "epoch 39; iter: 0; batch classifier loss: 0.096548; batch adversarial loss: 0.449400\n",
      "epoch 40; iter: 0; batch classifier loss: 0.152664; batch adversarial loss: 0.442150\n",
      "epoch 41; iter: 0; batch classifier loss: 0.134729; batch adversarial loss: 0.394206\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095811; batch adversarial loss: 0.563733\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129359; batch adversarial loss: 0.486777\n",
      "epoch 44; iter: 0; batch classifier loss: 0.117504; batch adversarial loss: 0.543019\n",
      "epoch 45; iter: 0; batch classifier loss: 0.118296; batch adversarial loss: 0.419183\n",
      "epoch 46; iter: 0; batch classifier loss: 0.153114; batch adversarial loss: 0.453563\n",
      "epoch 47; iter: 0; batch classifier loss: 0.117317; batch adversarial loss: 0.479912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144274; batch adversarial loss: 0.539597\n",
      "epoch 49; iter: 0; batch classifier loss: 0.123581; batch adversarial loss: 0.567238\n",
      "epoch 50; iter: 0; batch classifier loss: 0.118466; batch adversarial loss: 0.501310\n",
      "epoch 51; iter: 0; batch classifier loss: 0.123290; batch adversarial loss: 0.446331\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142612; batch adversarial loss: 0.417076\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084324; batch adversarial loss: 0.452599\n",
      "epoch 54; iter: 0; batch classifier loss: 0.138054; batch adversarial loss: 0.408419\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124456; batch adversarial loss: 0.473376\n",
      "epoch 56; iter: 0; batch classifier loss: 0.157470; batch adversarial loss: 0.383925\n",
      "epoch 57; iter: 0; batch classifier loss: 0.143892; batch adversarial loss: 0.496466\n",
      "epoch 58; iter: 0; batch classifier loss: 0.110709; batch adversarial loss: 0.539159\n",
      "epoch 59; iter: 0; batch classifier loss: 0.111685; batch adversarial loss: 0.440082\n",
      "epoch 60; iter: 0; batch classifier loss: 0.136372; batch adversarial loss: 0.401177\n",
      "epoch 61; iter: 0; batch classifier loss: 0.134245; batch adversarial loss: 0.454309\n",
      "epoch 62; iter: 0; batch classifier loss: 0.142647; batch adversarial loss: 0.419988\n",
      "epoch 63; iter: 0; batch classifier loss: 0.140761; batch adversarial loss: 0.530278\n",
      "epoch 64; iter: 0; batch classifier loss: 0.149589; batch adversarial loss: 0.407955\n",
      "epoch 65; iter: 0; batch classifier loss: 0.149837; batch adversarial loss: 0.464688\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121691; batch adversarial loss: 0.482255\n",
      "epoch 67; iter: 0; batch classifier loss: 0.199048; batch adversarial loss: 0.406196\n",
      "epoch 68; iter: 0; batch classifier loss: 0.132756; batch adversarial loss: 0.385597\n",
      "epoch 69; iter: 0; batch classifier loss: 0.146884; batch adversarial loss: 0.468961\n",
      "epoch 70; iter: 0; batch classifier loss: 0.119278; batch adversarial loss: 0.349819\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111573; batch adversarial loss: 0.501145\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176355; batch adversarial loss: 0.466084\n",
      "epoch 73; iter: 0; batch classifier loss: 0.166391; batch adversarial loss: 0.468813\n",
      "epoch 74; iter: 0; batch classifier loss: 0.112628; batch adversarial loss: 0.461316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.097936; batch adversarial loss: 0.469778\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153724; batch adversarial loss: 0.491277\n",
      "epoch 77; iter: 0; batch classifier loss: 0.211503; batch adversarial loss: 0.347567\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091615; batch adversarial loss: 0.436120\n",
      "epoch 79; iter: 0; batch classifier loss: 0.133001; batch adversarial loss: 0.472291\n",
      "epoch 80; iter: 0; batch classifier loss: 0.189912; batch adversarial loss: 0.456900\n",
      "epoch 81; iter: 0; batch classifier loss: 0.107670; batch adversarial loss: 0.385676\n",
      "epoch 82; iter: 0; batch classifier loss: 0.160076; batch adversarial loss: 0.496363\n",
      "epoch 83; iter: 0; batch classifier loss: 0.153319; batch adversarial loss: 0.519677\n",
      "epoch 84; iter: 0; batch classifier loss: 0.127654; batch adversarial loss: 0.444684\n",
      "epoch 85; iter: 0; batch classifier loss: 0.148543; batch adversarial loss: 0.473427\n",
      "epoch 86; iter: 0; batch classifier loss: 0.136634; batch adversarial loss: 0.495399\n",
      "epoch 87; iter: 0; batch classifier loss: 0.191639; batch adversarial loss: 0.485680\n",
      "epoch 88; iter: 0; batch classifier loss: 0.163110; batch adversarial loss: 0.480549\n",
      "epoch 89; iter: 0; batch classifier loss: 0.222453; batch adversarial loss: 0.503711\n",
      "epoch 90; iter: 0; batch classifier loss: 0.126063; batch adversarial loss: 0.506801\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162536; batch adversarial loss: 0.361298\n",
      "epoch 92; iter: 0; batch classifier loss: 0.132053; batch adversarial loss: 0.495299\n",
      "epoch 93; iter: 0; batch classifier loss: 0.204439; batch adversarial loss: 0.567961\n",
      "epoch 94; iter: 0; batch classifier loss: 0.158015; batch adversarial loss: 0.395764\n",
      "epoch 95; iter: 0; batch classifier loss: 0.174963; batch adversarial loss: 0.468754\n",
      "epoch 96; iter: 0; batch classifier loss: 0.158305; batch adversarial loss: 0.510225\n",
      "epoch 97; iter: 0; batch classifier loss: 0.120742; batch adversarial loss: 0.534806\n",
      "epoch 98; iter: 0; batch classifier loss: 0.138422; batch adversarial loss: 0.469839\n",
      "epoch 99; iter: 0; batch classifier loss: 0.095611; batch adversarial loss: 0.411898\n",
      "epoch 100; iter: 0; batch classifier loss: 0.140965; batch adversarial loss: 0.436097\n",
      "epoch 101; iter: 0; batch classifier loss: 0.126738; batch adversarial loss: 0.485740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.087440; batch adversarial loss: 0.495857\n",
      "epoch 103; iter: 0; batch classifier loss: 0.131785; batch adversarial loss: 0.447759\n",
      "epoch 104; iter: 0; batch classifier loss: 0.126101; batch adversarial loss: 0.533022\n",
      "epoch 105; iter: 0; batch classifier loss: 0.117877; batch adversarial loss: 0.596172\n",
      "epoch 106; iter: 0; batch classifier loss: 0.169240; batch adversarial loss: 0.384817\n",
      "epoch 107; iter: 0; batch classifier loss: 0.141764; batch adversarial loss: 0.504628\n",
      "epoch 108; iter: 0; batch classifier loss: 0.133952; batch adversarial loss: 0.481443\n",
      "epoch 109; iter: 0; batch classifier loss: 0.146930; batch adversarial loss: 0.419367\n",
      "epoch 110; iter: 0; batch classifier loss: 0.116294; batch adversarial loss: 0.492769\n",
      "epoch 111; iter: 0; batch classifier loss: 0.125444; batch adversarial loss: 0.432861\n",
      "epoch 112; iter: 0; batch classifier loss: 0.122726; batch adversarial loss: 0.430567\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065089; batch adversarial loss: 0.517366\n",
      "epoch 114; iter: 0; batch classifier loss: 0.133004; batch adversarial loss: 0.419323\n",
      "epoch 115; iter: 0; batch classifier loss: 0.127431; batch adversarial loss: 0.568786\n",
      "epoch 116; iter: 0; batch classifier loss: 0.097754; batch adversarial loss: 0.505719\n",
      "epoch 117; iter: 0; batch classifier loss: 0.123215; batch adversarial loss: 0.399025\n",
      "epoch 118; iter: 0; batch classifier loss: 0.114032; batch adversarial loss: 0.457656\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082712; batch adversarial loss: 0.389089\n",
      "epoch 120; iter: 0; batch classifier loss: 0.098149; batch adversarial loss: 0.429396\n",
      "epoch 121; iter: 0; batch classifier loss: 0.072891; batch adversarial loss: 0.405252\n",
      "epoch 122; iter: 0; batch classifier loss: 0.077994; batch adversarial loss: 0.447760\n",
      "epoch 123; iter: 0; batch classifier loss: 0.066118; batch adversarial loss: 0.409636\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060070; batch adversarial loss: 0.445120\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060810; batch adversarial loss: 0.475069\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050183; batch adversarial loss: 0.467807\n",
      "epoch 127; iter: 0; batch classifier loss: 0.053239; batch adversarial loss: 0.425054\n",
      "epoch 128; iter: 0; batch classifier loss: 0.051715; batch adversarial loss: 0.339494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063879; batch adversarial loss: 0.477318\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042147; batch adversarial loss: 0.369391\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026590; batch adversarial loss: 0.503570\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049640; batch adversarial loss: 0.376099\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032473; batch adversarial loss: 0.449873\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062735; batch adversarial loss: 0.401387\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044401; batch adversarial loss: 0.453431\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028681; batch adversarial loss: 0.444168\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026522; batch adversarial loss: 0.383448\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031704; batch adversarial loss: 0.376951\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033466; batch adversarial loss: 0.416723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052055; batch adversarial loss: 0.425111\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035703; batch adversarial loss: 0.445404\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030934; batch adversarial loss: 0.428260\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030642; batch adversarial loss: 0.454861\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034974; batch adversarial loss: 0.462094\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027445; batch adversarial loss: 0.515924\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016311; batch adversarial loss: 0.514515\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047853; batch adversarial loss: 0.456460\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021421; batch adversarial loss: 0.471861\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012406; batch adversarial loss: 0.421605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055106; batch adversarial loss: 0.461012\n",
      "epoch 151; iter: 0; batch classifier loss: 0.044034; batch adversarial loss: 0.601658\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015370; batch adversarial loss: 0.561383\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021349; batch adversarial loss: 0.399431\n",
      "epoch 154; iter: 0; batch classifier loss: 0.040336; batch adversarial loss: 0.539308\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025614; batch adversarial loss: 0.472673\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016872; batch adversarial loss: 0.445410\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027080; batch adversarial loss: 0.402139\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029654; batch adversarial loss: 0.482961\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030052; batch adversarial loss: 0.441129\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043977; batch adversarial loss: 0.346364\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029079; batch adversarial loss: 0.546218\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019395; batch adversarial loss: 0.405378\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006008; batch adversarial loss: 0.457468\n",
      "epoch 164; iter: 0; batch classifier loss: 0.026270; batch adversarial loss: 0.499521\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013634; batch adversarial loss: 0.513021\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024908; batch adversarial loss: 0.440449\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009669; batch adversarial loss: 0.490562\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031591; batch adversarial loss: 0.428461\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031958; batch adversarial loss: 0.380386\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043369; batch adversarial loss: 0.541462\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031725; batch adversarial loss: 0.419818\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017966; batch adversarial loss: 0.511587\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018627; batch adversarial loss: 0.405476\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012229; batch adversarial loss: 0.395652\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020160; batch adversarial loss: 0.454639\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044685; batch adversarial loss: 0.497460\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011604; batch adversarial loss: 0.401413\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.519963\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033651; batch adversarial loss: 0.438747\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038520; batch adversarial loss: 0.449361\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010777; batch adversarial loss: 0.450476\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038430; batch adversarial loss: 0.424752\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033446; batch adversarial loss: 0.480901\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020300; batch adversarial loss: 0.480354\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016591; batch adversarial loss: 0.550714\n",
      "epoch 186; iter: 0; batch classifier loss: 0.012670; batch adversarial loss: 0.366288\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005559; batch adversarial loss: 0.430556\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026502; batch adversarial loss: 0.402049\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008802; batch adversarial loss: 0.358390\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022675; batch adversarial loss: 0.524003\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018572; batch adversarial loss: 0.457676\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011050; batch adversarial loss: 0.422450\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018418; batch adversarial loss: 0.376239\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017713; batch adversarial loss: 0.530113\n",
      "epoch 195; iter: 0; batch classifier loss: 0.028341; batch adversarial loss: 0.468598\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019585; batch adversarial loss: 0.344616\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031946; batch adversarial loss: 0.459445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.009467; batch adversarial loss: 0.491970\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023787; batch adversarial loss: 0.456648\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682931; batch adversarial loss: 0.830917\n",
      "epoch 1; iter: 0; batch classifier loss: 0.328841; batch adversarial loss: 0.773438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.329966; batch adversarial loss: 0.747777\n",
      "epoch 3; iter: 0; batch classifier loss: 0.280116; batch adversarial loss: 0.703920\n",
      "epoch 4; iter: 0; batch classifier loss: 0.421397; batch adversarial loss: 0.662318\n",
      "epoch 5; iter: 0; batch classifier loss: 0.274178; batch adversarial loss: 0.631002\n",
      "epoch 6; iter: 0; batch classifier loss: 0.312762; batch adversarial loss: 0.608439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389162; batch adversarial loss: 0.575195\n",
      "epoch 8; iter: 0; batch classifier loss: 0.227017; batch adversarial loss: 0.607303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.270291; batch adversarial loss: 0.522535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.291993; batch adversarial loss: 0.523219\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286387; batch adversarial loss: 0.492166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.243567; batch adversarial loss: 0.512641\n",
      "epoch 13; iter: 0; batch classifier loss: 0.186121; batch adversarial loss: 0.539534\n",
      "epoch 14; iter: 0; batch classifier loss: 0.219854; batch adversarial loss: 0.491277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.208813; batch adversarial loss: 0.408204\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263395; batch adversarial loss: 0.501645\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217150; batch adversarial loss: 0.411151\n",
      "epoch 18; iter: 0; batch classifier loss: 0.187599; batch adversarial loss: 0.423229\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198449; batch adversarial loss: 0.462471\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187898; batch adversarial loss: 0.416474\n",
      "epoch 21; iter: 0; batch classifier loss: 0.173703; batch adversarial loss: 0.393442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.146903; batch adversarial loss: 0.405137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.152820; batch adversarial loss: 0.426813\n",
      "epoch 24; iter: 0; batch classifier loss: 0.161118; batch adversarial loss: 0.421341\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141442; batch adversarial loss: 0.358096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193596; batch adversarial loss: 0.472348\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171527; batch adversarial loss: 0.509017\n",
      "epoch 28; iter: 0; batch classifier loss: 0.171574; batch adversarial loss: 0.386101\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173116; batch adversarial loss: 0.427422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.179459; batch adversarial loss: 0.494096\n",
      "epoch 31; iter: 0; batch classifier loss: 0.179037; batch adversarial loss: 0.416512\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129472; batch adversarial loss: 0.417490\n",
      "epoch 33; iter: 0; batch classifier loss: 0.162868; batch adversarial loss: 0.479847\n",
      "epoch 34; iter: 0; batch classifier loss: 0.189384; batch adversarial loss: 0.388407\n",
      "epoch 35; iter: 0; batch classifier loss: 0.099486; batch adversarial loss: 0.419221\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183608; batch adversarial loss: 0.375317\n",
      "epoch 37; iter: 0; batch classifier loss: 0.134341; batch adversarial loss: 0.382886\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119314; batch adversarial loss: 0.374297\n",
      "epoch 39; iter: 0; batch classifier loss: 0.111295; batch adversarial loss: 0.438073\n",
      "epoch 40; iter: 0; batch classifier loss: 0.168016; batch adversarial loss: 0.457267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.109393; batch adversarial loss: 0.409960\n",
      "epoch 42; iter: 0; batch classifier loss: 0.079612; batch adversarial loss: 0.339794\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109113; batch adversarial loss: 0.461307\n",
      "epoch 44; iter: 0; batch classifier loss: 0.111849; batch adversarial loss: 0.343264\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097831; batch adversarial loss: 0.400697\n",
      "epoch 46; iter: 0; batch classifier loss: 0.113864; batch adversarial loss: 0.414702\n",
      "epoch 47; iter: 0; batch classifier loss: 0.095481; batch adversarial loss: 0.419873\n",
      "epoch 48; iter: 0; batch classifier loss: 0.056826; batch adversarial loss: 0.420361\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113234; batch adversarial loss: 0.429742\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089125; batch adversarial loss: 0.415606\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097536; batch adversarial loss: 0.422930\n",
      "epoch 52; iter: 0; batch classifier loss: 0.121094; batch adversarial loss: 0.484341\n",
      "epoch 53; iter: 0; batch classifier loss: 0.072690; batch adversarial loss: 0.414016\n",
      "epoch 54; iter: 0; batch classifier loss: 0.088853; batch adversarial loss: 0.452617\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089347; batch adversarial loss: 0.388052\n",
      "epoch 56; iter: 0; batch classifier loss: 0.097180; batch adversarial loss: 0.403246\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110203; batch adversarial loss: 0.452513\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072819; batch adversarial loss: 0.418401\n",
      "epoch 59; iter: 0; batch classifier loss: 0.119190; batch adversarial loss: 0.386330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137370; batch adversarial loss: 0.373527\n",
      "epoch 61; iter: 0; batch classifier loss: 0.099851; batch adversarial loss: 0.438947\n",
      "epoch 62; iter: 0; batch classifier loss: 0.125449; batch adversarial loss: 0.381367\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072369; batch adversarial loss: 0.426982\n",
      "epoch 64; iter: 0; batch classifier loss: 0.088165; batch adversarial loss: 0.406415\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065104; batch adversarial loss: 0.459723\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062905; batch adversarial loss: 0.458620\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073891; batch adversarial loss: 0.390214\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.468983\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072778; batch adversarial loss: 0.402886\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050092; batch adversarial loss: 0.323721\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071431; batch adversarial loss: 0.418567\n",
      "epoch 72; iter: 0; batch classifier loss: 0.083049; batch adversarial loss: 0.397165\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082184; batch adversarial loss: 0.486454\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061214; batch adversarial loss: 0.427787\n",
      "epoch 75; iter: 0; batch classifier loss: 0.090182; batch adversarial loss: 0.409875\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086519; batch adversarial loss: 0.445439\n",
      "epoch 77; iter: 0; batch classifier loss: 0.060525; batch adversarial loss: 0.382458\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118005; batch adversarial loss: 0.578971\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055979; batch adversarial loss: 0.438063\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063521; batch adversarial loss: 0.476518\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118904; batch adversarial loss: 0.434937\n",
      "epoch 82; iter: 0; batch classifier loss: 0.132007; batch adversarial loss: 0.478061\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064374; batch adversarial loss: 0.488436\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048030; batch adversarial loss: 0.422077\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058829; batch adversarial loss: 0.465855\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084885; batch adversarial loss: 0.506705\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046561; batch adversarial loss: 0.399419\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067593; batch adversarial loss: 0.399126\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051467; batch adversarial loss: 0.391991\n",
      "epoch 90; iter: 0; batch classifier loss: 0.099120; batch adversarial loss: 0.409909\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074696; batch adversarial loss: 0.287365\n",
      "epoch 92; iter: 0; batch classifier loss: 0.106626; batch adversarial loss: 0.386734\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054525; batch adversarial loss: 0.410388\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093036; batch adversarial loss: 0.463760\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060520; batch adversarial loss: 0.485432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.069920; batch adversarial loss: 0.404976\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054217; batch adversarial loss: 0.501855\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092626; batch adversarial loss: 0.387838\n",
      "epoch 99; iter: 0; batch classifier loss: 0.082225; batch adversarial loss: 0.463113\n",
      "epoch 100; iter: 0; batch classifier loss: 0.051273; batch adversarial loss: 0.397284\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072248; batch adversarial loss: 0.437139\n",
      "epoch 102; iter: 0; batch classifier loss: 0.076442; batch adversarial loss: 0.553955\n",
      "epoch 103; iter: 0; batch classifier loss: 0.090415; batch adversarial loss: 0.373147\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073518; batch adversarial loss: 0.391950\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042276; batch adversarial loss: 0.481578\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044896; batch adversarial loss: 0.424532\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033877; batch adversarial loss: 0.452906\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079056; batch adversarial loss: 0.483842\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090741; batch adversarial loss: 0.433883\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048364; batch adversarial loss: 0.447187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062310; batch adversarial loss: 0.414905\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080624; batch adversarial loss: 0.405944\n",
      "epoch 113; iter: 0; batch classifier loss: 0.077896; batch adversarial loss: 0.379832\n",
      "epoch 114; iter: 0; batch classifier loss: 0.084079; batch adversarial loss: 0.421975\n",
      "epoch 115; iter: 0; batch classifier loss: 0.068925; batch adversarial loss: 0.495133\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059514; batch adversarial loss: 0.398233\n",
      "epoch 117; iter: 0; batch classifier loss: 0.078185; batch adversarial loss: 0.470028\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067234; batch adversarial loss: 0.419463\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052830; batch adversarial loss: 0.412602\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031237; batch adversarial loss: 0.411487\n",
      "epoch 121; iter: 0; batch classifier loss: 0.066264; batch adversarial loss: 0.365717\n",
      "epoch 122; iter: 0; batch classifier loss: 0.043812; batch adversarial loss: 0.416017\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051136; batch adversarial loss: 0.483101\n",
      "epoch 124; iter: 0; batch classifier loss: 0.089805; batch adversarial loss: 0.422873\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077802; batch adversarial loss: 0.338403\n",
      "epoch 126; iter: 0; batch classifier loss: 0.065115; batch adversarial loss: 0.438247\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057321; batch adversarial loss: 0.386356\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061676; batch adversarial loss: 0.514484\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030506; batch adversarial loss: 0.415840\n",
      "epoch 130; iter: 0; batch classifier loss: 0.074317; batch adversarial loss: 0.349902\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070381; batch adversarial loss: 0.402146\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048481; batch adversarial loss: 0.445857\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043990; batch adversarial loss: 0.384019\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038551; batch adversarial loss: 0.466007\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032686; batch adversarial loss: 0.432542\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039326; batch adversarial loss: 0.414444\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025959; batch adversarial loss: 0.421257\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057201; batch adversarial loss: 0.348195\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044047; batch adversarial loss: 0.397520\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042043; batch adversarial loss: 0.367859\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040858; batch adversarial loss: 0.485819\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058097; batch adversarial loss: 0.454992\n",
      "epoch 143; iter: 0; batch classifier loss: 0.023614; batch adversarial loss: 0.417615\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048449; batch adversarial loss: 0.490315\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024000; batch adversarial loss: 0.389454\n",
      "epoch 146; iter: 0; batch classifier loss: 0.065820; batch adversarial loss: 0.516361\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044211; batch adversarial loss: 0.444912\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051841; batch adversarial loss: 0.428366\n",
      "epoch 149; iter: 0; batch classifier loss: 0.049686; batch adversarial loss: 0.524124\n",
      "epoch 150; iter: 0; batch classifier loss: 0.081249; batch adversarial loss: 0.403404\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033818; batch adversarial loss: 0.522954\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029721; batch adversarial loss: 0.476793\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048623; batch adversarial loss: 0.446527\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043423; batch adversarial loss: 0.434525\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027717; batch adversarial loss: 0.429386\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042418; batch adversarial loss: 0.417725\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052731; batch adversarial loss: 0.526089\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037860; batch adversarial loss: 0.426396\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037337; batch adversarial loss: 0.494781\n",
      "epoch 160; iter: 0; batch classifier loss: 0.053724; batch adversarial loss: 0.382244\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025701; batch adversarial loss: 0.422475\n",
      "epoch 162; iter: 0; batch classifier loss: 0.040258; batch adversarial loss: 0.370245\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039547; batch adversarial loss: 0.475447\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021129; batch adversarial loss: 0.383193\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024489; batch adversarial loss: 0.444501\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038331; batch adversarial loss: 0.512912\n",
      "epoch 167; iter: 0; batch classifier loss: 0.028963; batch adversarial loss: 0.449919\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024388; batch adversarial loss: 0.528057\n",
      "epoch 169; iter: 0; batch classifier loss: 0.032746; batch adversarial loss: 0.527972\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037323; batch adversarial loss: 0.453557\n",
      "epoch 171; iter: 0; batch classifier loss: 0.037612; batch adversarial loss: 0.470168\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017708; batch adversarial loss: 0.426910\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039364; batch adversarial loss: 0.353659\n",
      "epoch 174; iter: 0; batch classifier loss: 0.052831; batch adversarial loss: 0.493988\n",
      "epoch 175; iter: 0; batch classifier loss: 0.015408; batch adversarial loss: 0.421830\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041979; batch adversarial loss: 0.505595\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020777; batch adversarial loss: 0.441409\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014874; batch adversarial loss: 0.450431\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025262; batch adversarial loss: 0.535971\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025486; batch adversarial loss: 0.450503\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039757; batch adversarial loss: 0.430031\n",
      "epoch 182; iter: 0; batch classifier loss: 0.040741; batch adversarial loss: 0.411299\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010228; batch adversarial loss: 0.448004\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026131; batch adversarial loss: 0.471827\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013685; batch adversarial loss: 0.434846\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018149; batch adversarial loss: 0.452059\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012376; batch adversarial loss: 0.434335\n",
      "epoch 188; iter: 0; batch classifier loss: 0.032314; batch adversarial loss: 0.518826\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008128; batch adversarial loss: 0.356392\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010915; batch adversarial loss: 0.589687\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019057; batch adversarial loss: 0.456309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.083128; batch adversarial loss: 0.500411\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019149; batch adversarial loss: 0.468310\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021695; batch adversarial loss: 0.418224\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.608799\n",
      "epoch 196; iter: 0; batch classifier loss: 0.044547; batch adversarial loss: 0.501608\n",
      "epoch 197; iter: 0; batch classifier loss: 0.055236; batch adversarial loss: 0.537295\n",
      "epoch 198; iter: 0; batch classifier loss: 0.050824; batch adversarial loss: 0.626087\n",
      "epoch 199; iter: 0; batch classifier loss: 0.086977; batch adversarial loss: 0.604508\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696898; batch adversarial loss: 0.699102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.548748; batch adversarial loss: 0.707708\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446847; batch adversarial loss: 0.713206\n",
      "epoch 3; iter: 0; batch classifier loss: 0.304795; batch adversarial loss: 0.677399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356551; batch adversarial loss: 0.615844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422715; batch adversarial loss: 0.587576\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336780; batch adversarial loss: 0.537152\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334760; batch adversarial loss: 0.496759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.257379; batch adversarial loss: 0.530399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.231857; batch adversarial loss: 0.491994\n",
      "epoch 10; iter: 0; batch classifier loss: 0.261675; batch adversarial loss: 0.498784\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214922; batch adversarial loss: 0.510911\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236349; batch adversarial loss: 0.463768\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227948; batch adversarial loss: 0.510291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186420; batch adversarial loss: 0.492672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167114; batch adversarial loss: 0.500537\n",
      "epoch 16; iter: 0; batch classifier loss: 0.199579; batch adversarial loss: 0.480146\n",
      "epoch 17; iter: 0; batch classifier loss: 0.130924; batch adversarial loss: 0.462179\n",
      "epoch 18; iter: 0; batch classifier loss: 0.137588; batch adversarial loss: 0.417085\n",
      "epoch 19; iter: 0; batch classifier loss: 0.148965; batch adversarial loss: 0.492786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.150289; batch adversarial loss: 0.409610\n",
      "epoch 21; iter: 0; batch classifier loss: 0.109651; batch adversarial loss: 0.386380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.132663; batch adversarial loss: 0.432108\n",
      "epoch 23; iter: 0; batch classifier loss: 0.121009; batch adversarial loss: 0.483518\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162675; batch adversarial loss: 0.555079\n",
      "epoch 25; iter: 0; batch classifier loss: 0.083017; batch adversarial loss: 0.462103\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134128; batch adversarial loss: 0.559918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.120839; batch adversarial loss: 0.527711\n",
      "epoch 28; iter: 0; batch classifier loss: 0.096930; batch adversarial loss: 0.523124\n",
      "epoch 29; iter: 0; batch classifier loss: 0.110348; batch adversarial loss: 0.444479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145975; batch adversarial loss: 0.608624\n",
      "epoch 31; iter: 0; batch classifier loss: 0.165179; batch adversarial loss: 0.440677\n",
      "epoch 32; iter: 0; batch classifier loss: 0.182509; batch adversarial loss: 0.495958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188013; batch adversarial loss: 0.586214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152373; batch adversarial loss: 0.476614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.140572; batch adversarial loss: 0.427793\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148211; batch adversarial loss: 0.447316\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167174; batch adversarial loss: 0.480264\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117228; batch adversarial loss: 0.444417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.167495; batch adversarial loss: 0.518222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.183100; batch adversarial loss: 0.442687\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144164; batch adversarial loss: 0.446730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.163510; batch adversarial loss: 0.389598\n",
      "epoch 43; iter: 0; batch classifier loss: 0.237175; batch adversarial loss: 0.493984\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173810; batch adversarial loss: 0.474946\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124859; batch adversarial loss: 0.485101\n",
      "epoch 46; iter: 0; batch classifier loss: 0.102374; batch adversarial loss: 0.481663\n",
      "epoch 47; iter: 0; batch classifier loss: 0.108001; batch adversarial loss: 0.480534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.052748; batch adversarial loss: 0.524037\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059762; batch adversarial loss: 0.471870\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085692; batch adversarial loss: 0.413224\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057253; batch adversarial loss: 0.439917\n",
      "epoch 52; iter: 0; batch classifier loss: 0.052793; batch adversarial loss: 0.339369\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082565; batch adversarial loss: 0.471951\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092844; batch adversarial loss: 0.377559\n",
      "epoch 55; iter: 0; batch classifier loss: 0.065601; batch adversarial loss: 0.410202\n",
      "epoch 56; iter: 0; batch classifier loss: 0.071265; batch adversarial loss: 0.458529\n",
      "epoch 57; iter: 0; batch classifier loss: 0.034039; batch adversarial loss: 0.478990\n",
      "epoch 58; iter: 0; batch classifier loss: 0.070747; batch adversarial loss: 0.403132\n",
      "epoch 59; iter: 0; batch classifier loss: 0.059108; batch adversarial loss: 0.413328\n",
      "epoch 60; iter: 0; batch classifier loss: 0.086224; batch adversarial loss: 0.490596\n",
      "epoch 61; iter: 0; batch classifier loss: 0.039177; batch adversarial loss: 0.544357\n",
      "epoch 62; iter: 0; batch classifier loss: 0.050555; batch adversarial loss: 0.433481\n",
      "epoch 63; iter: 0; batch classifier loss: 0.045703; batch adversarial loss: 0.531555\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067063; batch adversarial loss: 0.499113\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070169; batch adversarial loss: 0.434770\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083064; batch adversarial loss: 0.550700\n",
      "epoch 67; iter: 0; batch classifier loss: 0.090368; batch adversarial loss: 0.401327\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067813; batch adversarial loss: 0.363907\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095279; batch adversarial loss: 0.424221\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084802; batch adversarial loss: 0.428450\n",
      "epoch 71; iter: 0; batch classifier loss: 0.058502; batch adversarial loss: 0.504572\n",
      "epoch 72; iter: 0; batch classifier loss: 0.021390; batch adversarial loss: 0.551189\n",
      "epoch 73; iter: 0; batch classifier loss: 0.091207; batch adversarial loss: 0.405683\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077624; batch adversarial loss: 0.380831\n",
      "epoch 75; iter: 0; batch classifier loss: 0.047885; batch adversarial loss: 0.441867\n",
      "epoch 76; iter: 0; batch classifier loss: 0.040394; batch adversarial loss: 0.444715\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045938; batch adversarial loss: 0.439249\n",
      "epoch 78; iter: 0; batch classifier loss: 0.083499; batch adversarial loss: 0.477706\n",
      "epoch 79; iter: 0; batch classifier loss: 0.069304; batch adversarial loss: 0.404111\n",
      "epoch 80; iter: 0; batch classifier loss: 0.107335; batch adversarial loss: 0.430014\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096916; batch adversarial loss: 0.338794\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110959; batch adversarial loss: 0.383381\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052491; batch adversarial loss: 0.482080\n",
      "epoch 84; iter: 0; batch classifier loss: 0.030864; batch adversarial loss: 0.460294\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054876; batch adversarial loss: 0.414729\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057425; batch adversarial loss: 0.425670\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.432969\n",
      "epoch 88; iter: 0; batch classifier loss: 0.099783; batch adversarial loss: 0.493747\n",
      "epoch 89; iter: 0; batch classifier loss: 0.061054; batch adversarial loss: 0.407743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.067080; batch adversarial loss: 0.483452\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066592; batch adversarial loss: 0.500679\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079691; batch adversarial loss: 0.370485\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063945; batch adversarial loss: 0.417795\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075512; batch adversarial loss: 0.453814\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085642; batch adversarial loss: 0.421109\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045076; batch adversarial loss: 0.382160\n",
      "epoch 97; iter: 0; batch classifier loss: 0.073148; batch adversarial loss: 0.582039\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079901; batch adversarial loss: 0.521847\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055759; batch adversarial loss: 0.453519\n",
      "epoch 100; iter: 0; batch classifier loss: 0.091894; batch adversarial loss: 0.397871\n",
      "epoch 101; iter: 0; batch classifier loss: 0.063221; batch adversarial loss: 0.451577\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027370; batch adversarial loss: 0.466400\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049293; batch adversarial loss: 0.366945\n",
      "epoch 104; iter: 0; batch classifier loss: 0.085253; batch adversarial loss: 0.507741\n",
      "epoch 105; iter: 0; batch classifier loss: 0.017105; batch adversarial loss: 0.457382\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051875; batch adversarial loss: 0.492439\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032220; batch adversarial loss: 0.337560\n",
      "epoch 108; iter: 0; batch classifier loss: 0.055786; batch adversarial loss: 0.259788\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032844; batch adversarial loss: 0.435108\n",
      "epoch 110; iter: 0; batch classifier loss: 0.074061; batch adversarial loss: 0.415207\n",
      "epoch 111; iter: 0; batch classifier loss: 0.090651; batch adversarial loss: 0.494387\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073017; batch adversarial loss: 0.554080\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060355; batch adversarial loss: 0.545284\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050069; batch adversarial loss: 0.509756\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036702; batch adversarial loss: 0.464244\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036720; batch adversarial loss: 0.393219\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035346; batch adversarial loss: 0.418996\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032990; batch adversarial loss: 0.424423\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056575; batch adversarial loss: 0.413642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.043865; batch adversarial loss: 0.428852\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038456; batch adversarial loss: 0.434449\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076959; batch adversarial loss: 0.450985\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050834; batch adversarial loss: 0.415026\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029855; batch adversarial loss: 0.433473\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026376; batch adversarial loss: 0.461243\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045440; batch adversarial loss: 0.465128\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036942; batch adversarial loss: 0.361829\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041741; batch adversarial loss: 0.405472\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066142; batch adversarial loss: 0.528493\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049594; batch adversarial loss: 0.479093\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030930; batch adversarial loss: 0.384270\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022749; batch adversarial loss: 0.387169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030522; batch adversarial loss: 0.439679\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040383; batch adversarial loss: 0.427348\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039275; batch adversarial loss: 0.410073\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072667; batch adversarial loss: 0.425271\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021849; batch adversarial loss: 0.495951\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027698; batch adversarial loss: 0.493417\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026272; batch adversarial loss: 0.448943\n",
      "epoch 140; iter: 0; batch classifier loss: 0.028510; batch adversarial loss: 0.384972\n",
      "epoch 141; iter: 0; batch classifier loss: 0.014746; batch adversarial loss: 0.323024\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046116; batch adversarial loss: 0.472605\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043821; batch adversarial loss: 0.441740\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037204; batch adversarial loss: 0.581731\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035614; batch adversarial loss: 0.507260\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030764; batch adversarial loss: 0.429579\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029133; batch adversarial loss: 0.434298\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039772; batch adversarial loss: 0.496779\n",
      "epoch 149; iter: 0; batch classifier loss: 0.053494; batch adversarial loss: 0.461393\n",
      "epoch 150; iter: 0; batch classifier loss: 0.023622; batch adversarial loss: 0.486323\n",
      "epoch 151; iter: 0; batch classifier loss: 0.013042; batch adversarial loss: 0.512791\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022798; batch adversarial loss: 0.421944\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019013; batch adversarial loss: 0.419671\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022808; batch adversarial loss: 0.527840\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016387; batch adversarial loss: 0.528946\n",
      "epoch 156; iter: 0; batch classifier loss: 0.031225; batch adversarial loss: 0.467262\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013440; batch adversarial loss: 0.399417\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040749; batch adversarial loss: 0.471238\n",
      "epoch 159; iter: 0; batch classifier loss: 0.065693; batch adversarial loss: 0.425405\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025282; batch adversarial loss: 0.423036\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006892; batch adversarial loss: 0.493096\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042738; batch adversarial loss: 0.483331\n",
      "epoch 163; iter: 0; batch classifier loss: 0.009366; batch adversarial loss: 0.417584\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019585; batch adversarial loss: 0.440644\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033854; batch adversarial loss: 0.469863\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015568; batch adversarial loss: 0.408859\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022733; batch adversarial loss: 0.453110\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025977; batch adversarial loss: 0.468028\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031457; batch adversarial loss: 0.378963\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015702; batch adversarial loss: 0.487415\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016217; batch adversarial loss: 0.487288\n",
      "epoch 172; iter: 0; batch classifier loss: 0.037361; batch adversarial loss: 0.422831\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016124; batch adversarial loss: 0.395487\n",
      "epoch 174; iter: 0; batch classifier loss: 0.034980; batch adversarial loss: 0.467921\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024149; batch adversarial loss: 0.412253\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040359; batch adversarial loss: 0.444145\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038720; batch adversarial loss: 0.420495\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012478; batch adversarial loss: 0.443313\n",
      "epoch 179; iter: 0; batch classifier loss: 0.051689; batch adversarial loss: 0.369968\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023406; batch adversarial loss: 0.489606\n",
      "epoch 181; iter: 0; batch classifier loss: 0.021940; batch adversarial loss: 0.415917\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010101; batch adversarial loss: 0.534629\n",
      "epoch 183; iter: 0; batch classifier loss: 0.026498; batch adversarial loss: 0.536963\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017418; batch adversarial loss: 0.375047\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010452; batch adversarial loss: 0.447830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.028975; batch adversarial loss: 0.509398\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013791; batch adversarial loss: 0.501916\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017675; batch adversarial loss: 0.402055\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049261; batch adversarial loss: 0.426839\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024374; batch adversarial loss: 0.487112\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033036; batch adversarial loss: 0.513292\n",
      "epoch 192; iter: 0; batch classifier loss: 0.018451; batch adversarial loss: 0.499175\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022763; batch adversarial loss: 0.484330\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021966; batch adversarial loss: 0.508494\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037745; batch adversarial loss: 0.409686\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005624; batch adversarial loss: 0.539880\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029811; batch adversarial loss: 0.465971\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024858; batch adversarial loss: 0.390287\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007728; batch adversarial loss: 0.327917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687662; batch adversarial loss: 1.012872\n",
      "epoch 1; iter: 0; batch classifier loss: 0.623778; batch adversarial loss: 1.244434\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589505; batch adversarial loss: 1.070496\n",
      "epoch 3; iter: 0; batch classifier loss: 0.740119; batch adversarial loss: 1.054351\n",
      "epoch 4; iter: 0; batch classifier loss: 0.703550; batch adversarial loss: 1.049091\n",
      "epoch 5; iter: 0; batch classifier loss: 0.688799; batch adversarial loss: 0.929181\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588520; batch adversarial loss: 0.788420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441732; batch adversarial loss: 0.721248\n",
      "epoch 8; iter: 0; batch classifier loss: 0.308233; batch adversarial loss: 0.652259\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296524; batch adversarial loss: 0.667443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.258114; batch adversarial loss: 0.610828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348672; batch adversarial loss: 0.586429\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284531; batch adversarial loss: 0.582591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276127; batch adversarial loss: 0.543840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.228915; batch adversarial loss: 0.530132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.247087; batch adversarial loss: 0.516117\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233874; batch adversarial loss: 0.531573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.234561; batch adversarial loss: 0.585171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246031; batch adversarial loss: 0.554102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295656; batch adversarial loss: 0.491080\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217277; batch adversarial loss: 0.540897\n",
      "epoch 21; iter: 0; batch classifier loss: 0.203000; batch adversarial loss: 0.576394\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228214; batch adversarial loss: 0.477420\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193547; batch adversarial loss: 0.522726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184981; batch adversarial loss: 0.523293\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182662; batch adversarial loss: 0.438913\n",
      "epoch 26; iter: 0; batch classifier loss: 0.185912; batch adversarial loss: 0.442802\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154165; batch adversarial loss: 0.489684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.148351; batch adversarial loss: 0.558353\n",
      "epoch 29; iter: 0; batch classifier loss: 0.160828; batch adversarial loss: 0.524877\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217389; batch adversarial loss: 0.435908\n",
      "epoch 31; iter: 0; batch classifier loss: 0.229106; batch adversarial loss: 0.482949\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180185; batch adversarial loss: 0.430944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.187335; batch adversarial loss: 0.456797\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168376; batch adversarial loss: 0.457982\n",
      "epoch 35; iter: 0; batch classifier loss: 0.196784; batch adversarial loss: 0.365829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163176; batch adversarial loss: 0.407305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116263; batch adversarial loss: 0.469792\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103524; batch adversarial loss: 0.456486\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110536; batch adversarial loss: 0.465537\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096045; batch adversarial loss: 0.474283\n",
      "epoch 41; iter: 0; batch classifier loss: 0.110295; batch adversarial loss: 0.419358\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087507; batch adversarial loss: 0.446922\n",
      "epoch 43; iter: 0; batch classifier loss: 0.133549; batch adversarial loss: 0.445091\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095112; batch adversarial loss: 0.352288\n",
      "epoch 45; iter: 0; batch classifier loss: 0.127255; batch adversarial loss: 0.431487\n",
      "epoch 46; iter: 0; batch classifier loss: 0.077983; batch adversarial loss: 0.486164\n",
      "epoch 47; iter: 0; batch classifier loss: 0.069957; batch adversarial loss: 0.428184\n",
      "epoch 48; iter: 0; batch classifier loss: 0.047243; batch adversarial loss: 0.391903\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074898; batch adversarial loss: 0.426335\n",
      "epoch 50; iter: 0; batch classifier loss: 0.073035; batch adversarial loss: 0.460703\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072774; batch adversarial loss: 0.403694\n",
      "epoch 52; iter: 0; batch classifier loss: 0.048435; batch adversarial loss: 0.444893\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096097; batch adversarial loss: 0.395629\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056523; batch adversarial loss: 0.365509\n",
      "epoch 55; iter: 0; batch classifier loss: 0.097480; batch adversarial loss: 0.432767\n",
      "epoch 56; iter: 0; batch classifier loss: 0.106581; batch adversarial loss: 0.489005\n",
      "epoch 57; iter: 0; batch classifier loss: 0.055098; batch adversarial loss: 0.483714\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064670; batch adversarial loss: 0.492575\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067426; batch adversarial loss: 0.513598\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077594; batch adversarial loss: 0.426417\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062966; batch adversarial loss: 0.381732\n",
      "epoch 62; iter: 0; batch classifier loss: 0.065908; batch adversarial loss: 0.415660\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055621; batch adversarial loss: 0.420183\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076112; batch adversarial loss: 0.476336\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057930; batch adversarial loss: 0.442718\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081417; batch adversarial loss: 0.492902\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060723; batch adversarial loss: 0.480036\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050987; batch adversarial loss: 0.376894\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068386; batch adversarial loss: 0.488823\n",
      "epoch 70; iter: 0; batch classifier loss: 0.075713; batch adversarial loss: 0.378284\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049664; batch adversarial loss: 0.510688\n",
      "epoch 72; iter: 0; batch classifier loss: 0.140344; batch adversarial loss: 0.395342\n",
      "epoch 73; iter: 0; batch classifier loss: 0.050043; batch adversarial loss: 0.400282\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064193; batch adversarial loss: 0.344214\n",
      "epoch 75; iter: 0; batch classifier loss: 0.099771; batch adversarial loss: 0.473096\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072682; batch adversarial loss: 0.446998\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057764; batch adversarial loss: 0.372011\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077659; batch adversarial loss: 0.531216\n",
      "epoch 79; iter: 0; batch classifier loss: 0.056647; batch adversarial loss: 0.448291\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053284; batch adversarial loss: 0.460575\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056735; batch adversarial loss: 0.409000\n",
      "epoch 82; iter: 0; batch classifier loss: 0.042102; batch adversarial loss: 0.413796\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075073; batch adversarial loss: 0.521798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.082264; batch adversarial loss: 0.433204\n",
      "epoch 85; iter: 0; batch classifier loss: 0.033186; batch adversarial loss: 0.442594\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075434; batch adversarial loss: 0.467414\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076352; batch adversarial loss: 0.449477\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050646; batch adversarial loss: 0.416030\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053386; batch adversarial loss: 0.370955\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050460; batch adversarial loss: 0.435562\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074496; batch adversarial loss: 0.569402\n",
      "epoch 92; iter: 0; batch classifier loss: 0.056058; batch adversarial loss: 0.507219\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048392; batch adversarial loss: 0.380038\n",
      "epoch 94; iter: 0; batch classifier loss: 0.101786; batch adversarial loss: 0.446773\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083328; batch adversarial loss: 0.393243\n",
      "epoch 96; iter: 0; batch classifier loss: 0.101772; batch adversarial loss: 0.419281\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055037; batch adversarial loss: 0.498138\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055173; batch adversarial loss: 0.364812\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050653; batch adversarial loss: 0.474369\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044874; batch adversarial loss: 0.464786\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055500; batch adversarial loss: 0.478220\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036773; batch adversarial loss: 0.393281\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068734; batch adversarial loss: 0.441465\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047225; batch adversarial loss: 0.428139\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032563; batch adversarial loss: 0.458562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.070590; batch adversarial loss: 0.336955\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048541; batch adversarial loss: 0.346759\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063152; batch adversarial loss: 0.483768\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038280; batch adversarial loss: 0.454121\n",
      "epoch 110; iter: 0; batch classifier loss: 0.076497; batch adversarial loss: 0.407111\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050876; batch adversarial loss: 0.383257\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055360; batch adversarial loss: 0.415641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030113; batch adversarial loss: 0.391278\n",
      "epoch 114; iter: 0; batch classifier loss: 0.093221; batch adversarial loss: 0.485953\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090064; batch adversarial loss: 0.455738\n",
      "epoch 116; iter: 0; batch classifier loss: 0.035056; batch adversarial loss: 0.369159\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057402; batch adversarial loss: 0.492551\n",
      "epoch 118; iter: 0; batch classifier loss: 0.025009; batch adversarial loss: 0.458650\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042017; batch adversarial loss: 0.395272\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045837; batch adversarial loss: 0.447941\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021208; batch adversarial loss: 0.360885\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055619; batch adversarial loss: 0.433945\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043213; batch adversarial loss: 0.441410\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042704; batch adversarial loss: 0.454443\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053384; batch adversarial loss: 0.412095\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048390; batch adversarial loss: 0.410442\n",
      "epoch 127; iter: 0; batch classifier loss: 0.070790; batch adversarial loss: 0.388381\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026070; batch adversarial loss: 0.412270\n",
      "epoch 129; iter: 0; batch classifier loss: 0.106473; batch adversarial loss: 0.439288\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070906; batch adversarial loss: 0.540691\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029664; batch adversarial loss: 0.481662\n",
      "epoch 132; iter: 0; batch classifier loss: 0.045839; batch adversarial loss: 0.437095\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038660; batch adversarial loss: 0.361557\n",
      "epoch 134; iter: 0; batch classifier loss: 0.055631; batch adversarial loss: 0.403731\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044170; batch adversarial loss: 0.397202\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043898; batch adversarial loss: 0.440068\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040641; batch adversarial loss: 0.479784\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046784; batch adversarial loss: 0.411566\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044676; batch adversarial loss: 0.515713\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041659; batch adversarial loss: 0.411953\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043499; batch adversarial loss: 0.422200\n",
      "epoch 142; iter: 0; batch classifier loss: 0.101507; batch adversarial loss: 0.499028\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033144; batch adversarial loss: 0.459109\n",
      "epoch 144; iter: 0; batch classifier loss: 0.061016; batch adversarial loss: 0.418177\n",
      "epoch 145; iter: 0; batch classifier loss: 0.070981; batch adversarial loss: 0.485892\n",
      "epoch 146; iter: 0; batch classifier loss: 0.060773; batch adversarial loss: 0.377391\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036517; batch adversarial loss: 0.424434\n",
      "epoch 148; iter: 0; batch classifier loss: 0.056935; batch adversarial loss: 0.457717\n",
      "epoch 149; iter: 0; batch classifier loss: 0.041355; batch adversarial loss: 0.405068\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052382; batch adversarial loss: 0.514155\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032644; batch adversarial loss: 0.344360\n",
      "epoch 152; iter: 0; batch classifier loss: 0.091874; batch adversarial loss: 0.509713\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058381; batch adversarial loss: 0.424632\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019712; batch adversarial loss: 0.397309\n",
      "epoch 155; iter: 0; batch classifier loss: 0.049103; batch adversarial loss: 0.333513\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045113; batch adversarial loss: 0.460664\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040875; batch adversarial loss: 0.397079\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037998; batch adversarial loss: 0.427370\n",
      "epoch 159; iter: 0; batch classifier loss: 0.060835; batch adversarial loss: 0.436715\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046081; batch adversarial loss: 0.507493\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050086; batch adversarial loss: 0.439996\n",
      "epoch 162; iter: 0; batch classifier loss: 0.056489; batch adversarial loss: 0.439436\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025684; batch adversarial loss: 0.461371\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031864; batch adversarial loss: 0.376997\n",
      "epoch 165; iter: 0; batch classifier loss: 0.047943; batch adversarial loss: 0.355600\n",
      "epoch 166; iter: 0; batch classifier loss: 0.059963; batch adversarial loss: 0.337031\n",
      "epoch 167; iter: 0; batch classifier loss: 0.055116; batch adversarial loss: 0.455119\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031561; batch adversarial loss: 0.387606\n",
      "epoch 169; iter: 0; batch classifier loss: 0.044437; batch adversarial loss: 0.386231\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.395889\n",
      "epoch 171; iter: 0; batch classifier loss: 0.069523; batch adversarial loss: 0.554961\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045357; batch adversarial loss: 0.420011\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040171; batch adversarial loss: 0.397745\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046544; batch adversarial loss: 0.479631\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053622; batch adversarial loss: 0.436741\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029554; batch adversarial loss: 0.361959\n",
      "epoch 177; iter: 0; batch classifier loss: 0.070992; batch adversarial loss: 0.364351\n",
      "epoch 178; iter: 0; batch classifier loss: 0.076449; batch adversarial loss: 0.399263\n",
      "epoch 179; iter: 0; batch classifier loss: 0.035652; batch adversarial loss: 0.404678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.037879; batch adversarial loss: 0.448578\n",
      "epoch 181; iter: 0; batch classifier loss: 0.051660; batch adversarial loss: 0.392393\n",
      "epoch 182; iter: 0; batch classifier loss: 0.077618; batch adversarial loss: 0.523171\n",
      "epoch 183; iter: 0; batch classifier loss: 0.055155; batch adversarial loss: 0.463917\n",
      "epoch 184; iter: 0; batch classifier loss: 0.072624; batch adversarial loss: 0.417327\n",
      "epoch 185; iter: 0; batch classifier loss: 0.059013; batch adversarial loss: 0.454212\n",
      "epoch 186; iter: 0; batch classifier loss: 0.067267; batch adversarial loss: 0.480887\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044064; batch adversarial loss: 0.537560\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033496; batch adversarial loss: 0.444619\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034861; batch adversarial loss: 0.406214\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034950; batch adversarial loss: 0.475523\n",
      "epoch 191; iter: 0; batch classifier loss: 0.065778; batch adversarial loss: 0.443209\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037036; batch adversarial loss: 0.417652\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047069; batch adversarial loss: 0.440685\n",
      "epoch 194; iter: 0; batch classifier loss: 0.040316; batch adversarial loss: 0.487280\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030790; batch adversarial loss: 0.504991\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031809; batch adversarial loss: 0.415100\n",
      "epoch 197; iter: 0; batch classifier loss: 0.031959; batch adversarial loss: 0.388554\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035261; batch adversarial loss: 0.464165\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024758; batch adversarial loss: 0.423287\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698929; batch adversarial loss: 0.663457\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424159; batch adversarial loss: 0.656263\n",
      "epoch 2; iter: 0; batch classifier loss: 0.456013; batch adversarial loss: 0.608942\n",
      "epoch 3; iter: 0; batch classifier loss: 0.411355; batch adversarial loss: 0.604449\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401403; batch adversarial loss: 0.622986\n",
      "epoch 5; iter: 0; batch classifier loss: 0.396991; batch adversarial loss: 0.598767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502188; batch adversarial loss: 0.605779\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388825; batch adversarial loss: 0.560635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444955; batch adversarial loss: 0.524491\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414843; batch adversarial loss: 0.511247\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426932; batch adversarial loss: 0.517780\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344981; batch adversarial loss: 0.526399\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391217; batch adversarial loss: 0.483806\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400974; batch adversarial loss: 0.508500\n",
      "epoch 14; iter: 0; batch classifier loss: 0.454224; batch adversarial loss: 0.495765\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329223; batch adversarial loss: 0.509562\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309897; batch adversarial loss: 0.466045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270926; batch adversarial loss: 0.508639\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310820; batch adversarial loss: 0.460257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310636; batch adversarial loss: 0.524480\n",
      "epoch 20; iter: 0; batch classifier loss: 0.228600; batch adversarial loss: 0.467691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228520; batch adversarial loss: 0.501093\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303536; batch adversarial loss: 0.477998\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226668; batch adversarial loss: 0.407003\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194743; batch adversarial loss: 0.521253\n",
      "epoch 25; iter: 0; batch classifier loss: 0.242265; batch adversarial loss: 0.497601\n",
      "epoch 26; iter: 0; batch classifier loss: 0.234195; batch adversarial loss: 0.452726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.186961; batch adversarial loss: 0.514700\n",
      "epoch 28; iter: 0; batch classifier loss: 0.296844; batch adversarial loss: 0.447656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233172; batch adversarial loss: 0.454389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262652; batch adversarial loss: 0.392202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.199039; batch adversarial loss: 0.384996\n",
      "epoch 32; iter: 0; batch classifier loss: 0.216833; batch adversarial loss: 0.500859\n",
      "epoch 33; iter: 0; batch classifier loss: 0.261407; batch adversarial loss: 0.475339\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262931; batch adversarial loss: 0.439184\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220503; batch adversarial loss: 0.408285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.218352; batch adversarial loss: 0.550248\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209862; batch adversarial loss: 0.422896\n",
      "epoch 38; iter: 0; batch classifier loss: 0.294432; batch adversarial loss: 0.492945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255836; batch adversarial loss: 0.406878\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193797; batch adversarial loss: 0.550715\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174028; batch adversarial loss: 0.572250\n",
      "epoch 42; iter: 0; batch classifier loss: 0.168684; batch adversarial loss: 0.448836\n",
      "epoch 43; iter: 0; batch classifier loss: 0.128902; batch adversarial loss: 0.517338\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132464; batch adversarial loss: 0.492977\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111993; batch adversarial loss: 0.519461\n",
      "epoch 46; iter: 0; batch classifier loss: 0.199446; batch adversarial loss: 0.520535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169136; batch adversarial loss: 0.386398\n",
      "epoch 48; iter: 0; batch classifier loss: 0.128126; batch adversarial loss: 0.399752\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196309; batch adversarial loss: 0.516815\n",
      "epoch 50; iter: 0; batch classifier loss: 0.165564; batch adversarial loss: 0.390300\n",
      "epoch 51; iter: 0; batch classifier loss: 0.151604; batch adversarial loss: 0.527635\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164899; batch adversarial loss: 0.471738\n",
      "epoch 53; iter: 0; batch classifier loss: 0.166703; batch adversarial loss: 0.482124\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171579; batch adversarial loss: 0.436221\n",
      "epoch 55; iter: 0; batch classifier loss: 0.199059; batch adversarial loss: 0.447386\n",
      "epoch 56; iter: 0; batch classifier loss: 0.250074; batch adversarial loss: 0.530421\n",
      "epoch 57; iter: 0; batch classifier loss: 0.186099; batch adversarial loss: 0.483519\n",
      "epoch 58; iter: 0; batch classifier loss: 0.107629; batch adversarial loss: 0.483975\n",
      "epoch 59; iter: 0; batch classifier loss: 0.200487; batch adversarial loss: 0.494621\n",
      "epoch 60; iter: 0; batch classifier loss: 0.126081; batch adversarial loss: 0.458765\n",
      "epoch 61; iter: 0; batch classifier loss: 0.140030; batch adversarial loss: 0.519410\n",
      "epoch 62; iter: 0; batch classifier loss: 0.181057; batch adversarial loss: 0.484497\n",
      "epoch 63; iter: 0; batch classifier loss: 0.147429; batch adversarial loss: 0.410454\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120013; batch adversarial loss: 0.495027\n",
      "epoch 65; iter: 0; batch classifier loss: 0.145364; batch adversarial loss: 0.482778\n",
      "epoch 66; iter: 0; batch classifier loss: 0.221450; batch adversarial loss: 0.410373\n",
      "epoch 67; iter: 0; batch classifier loss: 0.171533; batch adversarial loss: 0.458916\n",
      "epoch 68; iter: 0; batch classifier loss: 0.184801; batch adversarial loss: 0.457855\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157661; batch adversarial loss: 0.482817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175201; batch adversarial loss: 0.446965\n",
      "epoch 71; iter: 0; batch classifier loss: 0.173466; batch adversarial loss: 0.421400\n",
      "epoch 72; iter: 0; batch classifier loss: 0.185553; batch adversarial loss: 0.471116\n",
      "epoch 73; iter: 0; batch classifier loss: 0.215068; batch adversarial loss: 0.543084\n",
      "epoch 74; iter: 0; batch classifier loss: 0.162128; batch adversarial loss: 0.349316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.126224; batch adversarial loss: 0.458536\n",
      "epoch 76; iter: 0; batch classifier loss: 0.204952; batch adversarial loss: 0.447732\n",
      "epoch 77; iter: 0; batch classifier loss: 0.143674; batch adversarial loss: 0.470043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.176996; batch adversarial loss: 0.398231\n",
      "epoch 79; iter: 0; batch classifier loss: 0.202062; batch adversarial loss: 0.435856\n",
      "epoch 80; iter: 0; batch classifier loss: 0.209426; batch adversarial loss: 0.517609\n",
      "epoch 81; iter: 0; batch classifier loss: 0.216993; batch adversarial loss: 0.470716\n",
      "epoch 82; iter: 0; batch classifier loss: 0.110395; batch adversarial loss: 0.458394\n",
      "epoch 83; iter: 0; batch classifier loss: 0.122146; batch adversarial loss: 0.566289\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102023; batch adversarial loss: 0.505368\n",
      "epoch 85; iter: 0; batch classifier loss: 0.143725; batch adversarial loss: 0.516363\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192752; batch adversarial loss: 0.447973\n",
      "epoch 87; iter: 0; batch classifier loss: 0.166489; batch adversarial loss: 0.409103\n",
      "epoch 88; iter: 0; batch classifier loss: 0.118999; batch adversarial loss: 0.434005\n",
      "epoch 89; iter: 0; batch classifier loss: 0.182503; batch adversarial loss: 0.412344\n",
      "epoch 90; iter: 0; batch classifier loss: 0.118061; batch adversarial loss: 0.456245\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110332; batch adversarial loss: 0.456199\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109637; batch adversarial loss: 0.423605\n",
      "epoch 93; iter: 0; batch classifier loss: 0.126069; batch adversarial loss: 0.518600\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096920; batch adversarial loss: 0.478912\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091168; batch adversarial loss: 0.411125\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067434; batch adversarial loss: 0.428528\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072572; batch adversarial loss: 0.478370\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059197; batch adversarial loss: 0.506849\n",
      "epoch 99; iter: 0; batch classifier loss: 0.092831; batch adversarial loss: 0.432375\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063938; batch adversarial loss: 0.528195\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083463; batch adversarial loss: 0.334114\n",
      "epoch 102; iter: 0; batch classifier loss: 0.063443; batch adversarial loss: 0.439355\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051891; batch adversarial loss: 0.466761\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055983; batch adversarial loss: 0.459092\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064736; batch adversarial loss: 0.481911\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059352; batch adversarial loss: 0.414583\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054320; batch adversarial loss: 0.545751\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065930; batch adversarial loss: 0.511199\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040852; batch adversarial loss: 0.453799\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065202; batch adversarial loss: 0.462322\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067138; batch adversarial loss: 0.403900\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031741; batch adversarial loss: 0.528793\n",
      "epoch 113; iter: 0; batch classifier loss: 0.079846; batch adversarial loss: 0.341082\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036158; batch adversarial loss: 0.614065\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065427; batch adversarial loss: 0.492543\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022005; batch adversarial loss: 0.478883\n",
      "epoch 117; iter: 0; batch classifier loss: 0.044893; batch adversarial loss: 0.484033\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028733; batch adversarial loss: 0.537642\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045386; batch adversarial loss: 0.498107\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033580; batch adversarial loss: 0.441353\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028066; batch adversarial loss: 0.579212\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037468; batch adversarial loss: 0.495910\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033742; batch adversarial loss: 0.490166\n",
      "epoch 124; iter: 0; batch classifier loss: 0.038437; batch adversarial loss: 0.441371\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035868; batch adversarial loss: 0.428982\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045058; batch adversarial loss: 0.454122\n",
      "epoch 127; iter: 0; batch classifier loss: 0.018416; batch adversarial loss: 0.566733\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016499; batch adversarial loss: 0.468537\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029863; batch adversarial loss: 0.432456\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048327; batch adversarial loss: 0.364923\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017899; batch adversarial loss: 0.452240\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035696; batch adversarial loss: 0.461698\n",
      "epoch 133; iter: 0; batch classifier loss: 0.012970; batch adversarial loss: 0.405793\n",
      "epoch 134; iter: 0; batch classifier loss: 0.024980; batch adversarial loss: 0.480253\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030573; batch adversarial loss: 0.552114\n",
      "epoch 136; iter: 0; batch classifier loss: 0.022166; batch adversarial loss: 0.454280\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025245; batch adversarial loss: 0.455594\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014340; batch adversarial loss: 0.508972\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017861; batch adversarial loss: 0.478235\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027776; batch adversarial loss: 0.469838\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015886; batch adversarial loss: 0.536511\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024152; batch adversarial loss: 0.496875\n",
      "epoch 143; iter: 0; batch classifier loss: 0.015288; batch adversarial loss: 0.463161\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029655; batch adversarial loss: 0.370172\n",
      "epoch 145; iter: 0; batch classifier loss: 0.009534; batch adversarial loss: 0.555653\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008436; batch adversarial loss: 0.500903\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014620; batch adversarial loss: 0.434347\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025788; batch adversarial loss: 0.426065\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021337; batch adversarial loss: 0.442343\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015674; batch adversarial loss: 0.474547\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017955; batch adversarial loss: 0.402598\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051336; batch adversarial loss: 0.441022\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016795; batch adversarial loss: 0.576664\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035358; batch adversarial loss: 0.500485\n",
      "epoch 155; iter: 0; batch classifier loss: 0.013522; batch adversarial loss: 0.385179\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019706; batch adversarial loss: 0.456213\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006040; batch adversarial loss: 0.483276\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008433; batch adversarial loss: 0.444081\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044855; batch adversarial loss: 0.440365\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007262; batch adversarial loss: 0.481516\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038043; batch adversarial loss: 0.514275\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024597; batch adversarial loss: 0.473850\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035091; batch adversarial loss: 0.482448\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037775; batch adversarial loss: 0.480588\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044907; batch adversarial loss: 0.446110\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030181; batch adversarial loss: 0.450359\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017034; batch adversarial loss: 0.415729\n",
      "epoch 168; iter: 0; batch classifier loss: 0.004157; batch adversarial loss: 0.464143\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011502; batch adversarial loss: 0.422734\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025886; batch adversarial loss: 0.418762\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029041; batch adversarial loss: 0.442423\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020956; batch adversarial loss: 0.404655\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030690; batch adversarial loss: 0.435756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.014310; batch adversarial loss: 0.516316\n",
      "epoch 175; iter: 0; batch classifier loss: 0.089399; batch adversarial loss: 0.430349\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013092; batch adversarial loss: 0.464651\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013286; batch adversarial loss: 0.504687\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034108; batch adversarial loss: 0.457198\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010588; batch adversarial loss: 0.393712\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022694; batch adversarial loss: 0.441046\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029806; batch adversarial loss: 0.433671\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010853; batch adversarial loss: 0.510369\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015145; batch adversarial loss: 0.505193\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009009; batch adversarial loss: 0.523545\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017171; batch adversarial loss: 0.456040\n",
      "epoch 186; iter: 0; batch classifier loss: 0.002395; batch adversarial loss: 0.476638\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016761; batch adversarial loss: 0.439295\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006178; batch adversarial loss: 0.383569\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006029; batch adversarial loss: 0.439872\n",
      "epoch 190; iter: 0; batch classifier loss: 0.027960; batch adversarial loss: 0.391201\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019024; batch adversarial loss: 0.413988\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050563; batch adversarial loss: 0.452198\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025061; batch adversarial loss: 0.387957\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025764; batch adversarial loss: 0.439458\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006356; batch adversarial loss: 0.392380\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041278; batch adversarial loss: 0.509790\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.442392\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015967; batch adversarial loss: 0.383598\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042894; batch adversarial loss: 0.573978\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695032; batch adversarial loss: 0.848721\n",
      "epoch 1; iter: 0; batch classifier loss: 0.489995; batch adversarial loss: 0.877478\n",
      "epoch 2; iter: 0; batch classifier loss: 0.302148; batch adversarial loss: 0.789131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.427912; batch adversarial loss: 0.759948\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377450; batch adversarial loss: 0.693401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317730; batch adversarial loss: 0.671085\n",
      "epoch 6; iter: 0; batch classifier loss: 0.294789; batch adversarial loss: 0.655949\n",
      "epoch 7; iter: 0; batch classifier loss: 0.285799; batch adversarial loss: 0.618882\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307325; batch adversarial loss: 0.625459\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295316; batch adversarial loss: 0.584523\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303367; batch adversarial loss: 0.544275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.241382; batch adversarial loss: 0.486192\n",
      "epoch 12; iter: 0; batch classifier loss: 0.199946; batch adversarial loss: 0.521028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266165; batch adversarial loss: 0.490821\n",
      "epoch 14; iter: 0; batch classifier loss: 0.268954; batch adversarial loss: 0.499783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236725; batch adversarial loss: 0.490737\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229442; batch adversarial loss: 0.486059\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251983; batch adversarial loss: 0.455707\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227761; batch adversarial loss: 0.413386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.251893; batch adversarial loss: 0.462614\n",
      "epoch 20; iter: 0; batch classifier loss: 0.187654; batch adversarial loss: 0.463830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.221725; batch adversarial loss: 0.517878\n",
      "epoch 22; iter: 0; batch classifier loss: 0.130861; batch adversarial loss: 0.474619\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172527; batch adversarial loss: 0.496632\n",
      "epoch 24; iter: 0; batch classifier loss: 0.234764; batch adversarial loss: 0.373284\n",
      "epoch 25; iter: 0; batch classifier loss: 0.133619; batch adversarial loss: 0.409693\n",
      "epoch 26; iter: 0; batch classifier loss: 0.137419; batch adversarial loss: 0.401400\n",
      "epoch 27; iter: 0; batch classifier loss: 0.165194; batch adversarial loss: 0.461075\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129966; batch adversarial loss: 0.354044\n",
      "epoch 29; iter: 0; batch classifier loss: 0.140359; batch adversarial loss: 0.374455\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147992; batch adversarial loss: 0.497711\n",
      "epoch 31; iter: 0; batch classifier loss: 0.114446; batch adversarial loss: 0.342157\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156825; batch adversarial loss: 0.410717\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152491; batch adversarial loss: 0.464845\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136642; batch adversarial loss: 0.456134\n",
      "epoch 35; iter: 0; batch classifier loss: 0.139852; batch adversarial loss: 0.413019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.134324; batch adversarial loss: 0.455884\n",
      "epoch 37; iter: 0; batch classifier loss: 0.172336; batch adversarial loss: 0.404333\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186575; batch adversarial loss: 0.411384\n",
      "epoch 39; iter: 0; batch classifier loss: 0.131216; batch adversarial loss: 0.491763\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124850; batch adversarial loss: 0.433126\n",
      "epoch 41; iter: 0; batch classifier loss: 0.095474; batch adversarial loss: 0.451283\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131558; batch adversarial loss: 0.383094\n",
      "epoch 43; iter: 0; batch classifier loss: 0.127565; batch adversarial loss: 0.352469\n",
      "epoch 44; iter: 0; batch classifier loss: 0.097966; batch adversarial loss: 0.412081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.083760; batch adversarial loss: 0.383162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101446; batch adversarial loss: 0.364664\n",
      "epoch 47; iter: 0; batch classifier loss: 0.104399; batch adversarial loss: 0.480848\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154712; batch adversarial loss: 0.439748\n",
      "epoch 49; iter: 0; batch classifier loss: 0.125718; batch adversarial loss: 0.403514\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087640; batch adversarial loss: 0.431944\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097241; batch adversarial loss: 0.469013\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110784; batch adversarial loss: 0.377550\n",
      "epoch 53; iter: 0; batch classifier loss: 0.117679; batch adversarial loss: 0.375916\n",
      "epoch 54; iter: 0; batch classifier loss: 0.098763; batch adversarial loss: 0.485768\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087140; batch adversarial loss: 0.351218\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102472; batch adversarial loss: 0.365339\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098125; batch adversarial loss: 0.389518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078967; batch adversarial loss: 0.385713\n",
      "epoch 59; iter: 0; batch classifier loss: 0.063380; batch adversarial loss: 0.440796\n",
      "epoch 60; iter: 0; batch classifier loss: 0.101177; batch adversarial loss: 0.393503\n",
      "epoch 61; iter: 0; batch classifier loss: 0.098848; batch adversarial loss: 0.452765\n",
      "epoch 62; iter: 0; batch classifier loss: 0.048019; batch adversarial loss: 0.369448\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094965; batch adversarial loss: 0.396003\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115161; batch adversarial loss: 0.479099\n",
      "epoch 65; iter: 0; batch classifier loss: 0.088023; batch adversarial loss: 0.411112\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077375; batch adversarial loss: 0.440975\n",
      "epoch 67; iter: 0; batch classifier loss: 0.087835; batch adversarial loss: 0.417031\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101498; batch adversarial loss: 0.392577\n",
      "epoch 69; iter: 0; batch classifier loss: 0.093371; batch adversarial loss: 0.345123\n",
      "epoch 70; iter: 0; batch classifier loss: 0.110981; batch adversarial loss: 0.423582\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064220; batch adversarial loss: 0.507485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.088765; batch adversarial loss: 0.523011\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049922; batch adversarial loss: 0.366337\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079521; batch adversarial loss: 0.448445\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107036; batch adversarial loss: 0.431765\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073269; batch adversarial loss: 0.420622\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070926; batch adversarial loss: 0.488351\n",
      "epoch 78; iter: 0; batch classifier loss: 0.084534; batch adversarial loss: 0.435782\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050058; batch adversarial loss: 0.404789\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084171; batch adversarial loss: 0.466189\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059528; batch adversarial loss: 0.462071\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071843; batch adversarial loss: 0.409414\n",
      "epoch 83; iter: 0; batch classifier loss: 0.099380; batch adversarial loss: 0.374933\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079526; batch adversarial loss: 0.480873\n",
      "epoch 85; iter: 0; batch classifier loss: 0.039398; batch adversarial loss: 0.309421\n",
      "epoch 86; iter: 0; batch classifier loss: 0.047491; batch adversarial loss: 0.410716\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046052; batch adversarial loss: 0.419554\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091234; batch adversarial loss: 0.439311\n",
      "epoch 89; iter: 0; batch classifier loss: 0.070907; batch adversarial loss: 0.461558\n",
      "epoch 90; iter: 0; batch classifier loss: 0.069790; batch adversarial loss: 0.332997\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046006; batch adversarial loss: 0.392342\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102188; batch adversarial loss: 0.557980\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076568; batch adversarial loss: 0.378069\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075243; batch adversarial loss: 0.511811\n",
      "epoch 95; iter: 0; batch classifier loss: 0.063926; batch adversarial loss: 0.423779\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070528; batch adversarial loss: 0.412886\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053795; batch adversarial loss: 0.500203\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063176; batch adversarial loss: 0.429603\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052060; batch adversarial loss: 0.484698\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053743; batch adversarial loss: 0.345539\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065476; batch adversarial loss: 0.383590\n",
      "epoch 102; iter: 0; batch classifier loss: 0.084879; batch adversarial loss: 0.423746\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059650; batch adversarial loss: 0.416098\n",
      "epoch 104; iter: 0; batch classifier loss: 0.039387; batch adversarial loss: 0.408745\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054582; batch adversarial loss: 0.470938\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051059; batch adversarial loss: 0.396990\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066086; batch adversarial loss: 0.423821\n",
      "epoch 108; iter: 0; batch classifier loss: 0.068552; batch adversarial loss: 0.393594\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067153; batch adversarial loss: 0.447616\n",
      "epoch 110; iter: 0; batch classifier loss: 0.071823; batch adversarial loss: 0.402453\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048842; batch adversarial loss: 0.552475\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046026; batch adversarial loss: 0.427196\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056142; batch adversarial loss: 0.349619\n",
      "epoch 114; iter: 0; batch classifier loss: 0.063599; batch adversarial loss: 0.495160\n",
      "epoch 115; iter: 0; batch classifier loss: 0.098878; batch adversarial loss: 0.465199\n",
      "epoch 116; iter: 0; batch classifier loss: 0.091706; batch adversarial loss: 0.351374\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054949; batch adversarial loss: 0.459677\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071716; batch adversarial loss: 0.467150\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029014; batch adversarial loss: 0.443654\n",
      "epoch 120; iter: 0; batch classifier loss: 0.072675; batch adversarial loss: 0.537273\n",
      "epoch 121; iter: 0; batch classifier loss: 0.041269; batch adversarial loss: 0.368266\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051289; batch adversarial loss: 0.437442\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041418; batch adversarial loss: 0.447793\n",
      "epoch 124; iter: 0; batch classifier loss: 0.080037; batch adversarial loss: 0.390532\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050262; batch adversarial loss: 0.410851\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076293; batch adversarial loss: 0.485851\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043461; batch adversarial loss: 0.451083\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039969; batch adversarial loss: 0.471775\n",
      "epoch 129; iter: 0; batch classifier loss: 0.079988; batch adversarial loss: 0.418381\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036611; batch adversarial loss: 0.370330\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037222; batch adversarial loss: 0.353289\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034110; batch adversarial loss: 0.366602\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053968; batch adversarial loss: 0.342269\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032604; batch adversarial loss: 0.464272\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046569; batch adversarial loss: 0.456098\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037646; batch adversarial loss: 0.358097\n",
      "epoch 137; iter: 0; batch classifier loss: 0.047688; batch adversarial loss: 0.467045\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039569; batch adversarial loss: 0.390994\n",
      "epoch 139; iter: 0; batch classifier loss: 0.038531; batch adversarial loss: 0.389811\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033574; batch adversarial loss: 0.457159\n",
      "epoch 141; iter: 0; batch classifier loss: 0.069176; batch adversarial loss: 0.343826\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031166; batch adversarial loss: 0.405023\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040329; batch adversarial loss: 0.438453\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031167; batch adversarial loss: 0.451974\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020510; batch adversarial loss: 0.469304\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.499992\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024836; batch adversarial loss: 0.394446\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021281; batch adversarial loss: 0.471273\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017737; batch adversarial loss: 0.435868\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016251; batch adversarial loss: 0.443074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021980; batch adversarial loss: 0.436991\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031602; batch adversarial loss: 0.474760\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029319; batch adversarial loss: 0.466393\n",
      "epoch 154; iter: 0; batch classifier loss: 0.024433; batch adversarial loss: 0.504550\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039561; batch adversarial loss: 0.424427\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024379; batch adversarial loss: 0.553703\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028541; batch adversarial loss: 0.443096\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029555; batch adversarial loss: 0.459947\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013751; batch adversarial loss: 0.407777\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017084; batch adversarial loss: 0.468380\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031597; batch adversarial loss: 0.437242\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026726; batch adversarial loss: 0.439114\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026037; batch adversarial loss: 0.434217\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019853; batch adversarial loss: 0.415726\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022850; batch adversarial loss: 0.463227\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015565; batch adversarial loss: 0.370860\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015063; batch adversarial loss: 0.422464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.027061; batch adversarial loss: 0.446190\n",
      "epoch 169; iter: 0; batch classifier loss: 0.019618; batch adversarial loss: 0.492398\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015911; batch adversarial loss: 0.417452\n",
      "epoch 171; iter: 0; batch classifier loss: 0.044918; batch adversarial loss: 0.507665\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022441; batch adversarial loss: 0.466499\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024610; batch adversarial loss: 0.361178\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017850; batch adversarial loss: 0.423262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023489; batch adversarial loss: 0.453315\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013304; batch adversarial loss: 0.465600\n",
      "epoch 177; iter: 0; batch classifier loss: 0.043865; batch adversarial loss: 0.448367\n",
      "epoch 178; iter: 0; batch classifier loss: 0.058396; batch adversarial loss: 0.468399\n",
      "epoch 179; iter: 0; batch classifier loss: 0.119756; batch adversarial loss: 0.490650\n",
      "epoch 180; iter: 0; batch classifier loss: 0.063948; batch adversarial loss: 0.558433\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044809; batch adversarial loss: 0.555838\n",
      "epoch 182; iter: 0; batch classifier loss: 0.071467; batch adversarial loss: 0.619507\n",
      "epoch 183; iter: 0; batch classifier loss: 0.075197; batch adversarial loss: 0.393342\n",
      "epoch 184; iter: 0; batch classifier loss: 0.072554; batch adversarial loss: 0.565281\n",
      "epoch 185; iter: 0; batch classifier loss: 0.114803; batch adversarial loss: 0.740147\n",
      "epoch 186; iter: 0; batch classifier loss: 0.100602; batch adversarial loss: 0.575584\n",
      "epoch 187; iter: 0; batch classifier loss: 0.108069; batch adversarial loss: 0.759420\n",
      "epoch 188; iter: 0; batch classifier loss: 0.178017; batch adversarial loss: 0.692376\n",
      "epoch 189; iter: 0; batch classifier loss: 0.152951; batch adversarial loss: 0.865020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.165757; batch adversarial loss: 0.695992\n",
      "epoch 191; iter: 0; batch classifier loss: 0.116587; batch adversarial loss: 0.575786\n",
      "epoch 192; iter: 0; batch classifier loss: 0.133638; batch adversarial loss: 0.677165\n",
      "epoch 193; iter: 0; batch classifier loss: 0.168402; batch adversarial loss: 0.762777\n",
      "epoch 194; iter: 0; batch classifier loss: 0.148788; batch adversarial loss: 0.661664\n",
      "epoch 195; iter: 0; batch classifier loss: 0.212642; batch adversarial loss: 0.645955\n",
      "epoch 196; iter: 0; batch classifier loss: 0.164497; batch adversarial loss: 0.639799\n",
      "epoch 197; iter: 0; batch classifier loss: 0.186450; batch adversarial loss: 0.698064\n",
      "epoch 198; iter: 0; batch classifier loss: 0.124605; batch adversarial loss: 0.593767\n",
      "epoch 199; iter: 0; batch classifier loss: 0.111943; batch adversarial loss: 0.520614\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693333; batch adversarial loss: 0.701743\n",
      "epoch 1; iter: 0; batch classifier loss: 0.504284; batch adversarial loss: 0.669196\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527941; batch adversarial loss: 0.615932\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378415; batch adversarial loss: 0.646066\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380106; batch adversarial loss: 0.616585\n",
      "epoch 5; iter: 0; batch classifier loss: 0.441695; batch adversarial loss: 0.623408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453238; batch adversarial loss: 0.575091\n",
      "epoch 7; iter: 0; batch classifier loss: 0.442128; batch adversarial loss: 0.544057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484814; batch adversarial loss: 0.509883\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421156; batch adversarial loss: 0.596375\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489454; batch adversarial loss: 0.480526\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410616; batch adversarial loss: 0.505568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446860; batch adversarial loss: 0.530906\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452768; batch adversarial loss: 0.483521\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358936; batch adversarial loss: 0.559603\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289429; batch adversarial loss: 0.485947\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309359; batch adversarial loss: 0.445909\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332931; batch adversarial loss: 0.535884\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358803; batch adversarial loss: 0.478487\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354627; batch adversarial loss: 0.531440\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230282; batch adversarial loss: 0.475404\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368880; batch adversarial loss: 0.476363\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348078; batch adversarial loss: 0.519645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389542; batch adversarial loss: 0.479028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280166; batch adversarial loss: 0.444276\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248499; batch adversarial loss: 0.580865\n",
      "epoch 26; iter: 0; batch classifier loss: 0.218019; batch adversarial loss: 0.439821\n",
      "epoch 27; iter: 0; batch classifier loss: 0.247394; batch adversarial loss: 0.505242\n",
      "epoch 28; iter: 0; batch classifier loss: 0.259586; batch adversarial loss: 0.476959\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258546; batch adversarial loss: 0.421073\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162751; batch adversarial loss: 0.470803\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174493; batch adversarial loss: 0.489641\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211483; batch adversarial loss: 0.477166\n",
      "epoch 33; iter: 0; batch classifier loss: 0.256914; batch adversarial loss: 0.408587\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240205; batch adversarial loss: 0.457984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.202115; batch adversarial loss: 0.489445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.258539; batch adversarial loss: 0.469508\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226663; batch adversarial loss: 0.352597\n",
      "epoch 38; iter: 0; batch classifier loss: 0.238762; batch adversarial loss: 0.403984\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243740; batch adversarial loss: 0.472360\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220328; batch adversarial loss: 0.540540\n",
      "epoch 41; iter: 0; batch classifier loss: 0.222129; batch adversarial loss: 0.391248\n",
      "epoch 42; iter: 0; batch classifier loss: 0.191527; batch adversarial loss: 0.634458\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290186; batch adversarial loss: 0.425099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206437; batch adversarial loss: 0.401627\n",
      "epoch 45; iter: 0; batch classifier loss: 0.229918; batch adversarial loss: 0.506720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.189847; batch adversarial loss: 0.411198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.118755; batch adversarial loss: 0.444940\n",
      "epoch 48; iter: 0; batch classifier loss: 0.244328; batch adversarial loss: 0.408929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.186553; batch adversarial loss: 0.575822\n",
      "epoch 50; iter: 0; batch classifier loss: 0.149315; batch adversarial loss: 0.458272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178929; batch adversarial loss: 0.506207\n",
      "epoch 52; iter: 0; batch classifier loss: 0.267075; batch adversarial loss: 0.422309\n",
      "epoch 53; iter: 0; batch classifier loss: 0.134458; batch adversarial loss: 0.494734\n",
      "epoch 54; iter: 0; batch classifier loss: 0.243087; batch adversarial loss: 0.434203\n",
      "epoch 55; iter: 0; batch classifier loss: 0.158902; batch adversarial loss: 0.422709\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161643; batch adversarial loss: 0.472118\n",
      "epoch 57; iter: 0; batch classifier loss: 0.271783; batch adversarial loss: 0.301217\n",
      "epoch 58; iter: 0; batch classifier loss: 0.121662; batch adversarial loss: 0.447080\n",
      "epoch 59; iter: 0; batch classifier loss: 0.140289; batch adversarial loss: 0.483088\n",
      "epoch 60; iter: 0; batch classifier loss: 0.137706; batch adversarial loss: 0.470262\n",
      "epoch 61; iter: 0; batch classifier loss: 0.190883; batch adversarial loss: 0.471879\n",
      "epoch 62; iter: 0; batch classifier loss: 0.129965; batch adversarial loss: 0.421680\n",
      "epoch 63; iter: 0; batch classifier loss: 0.177403; batch adversarial loss: 0.482787\n",
      "epoch 64; iter: 0; batch classifier loss: 0.178252; batch adversarial loss: 0.461593\n",
      "epoch 65; iter: 0; batch classifier loss: 0.101656; batch adversarial loss: 0.433764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.088237; batch adversarial loss: 0.422349\n",
      "epoch 67; iter: 0; batch classifier loss: 0.154121; batch adversarial loss: 0.395843\n",
      "epoch 68; iter: 0; batch classifier loss: 0.245662; batch adversarial loss: 0.398347\n",
      "epoch 69; iter: 0; batch classifier loss: 0.204500; batch adversarial loss: 0.482752\n",
      "epoch 70; iter: 0; batch classifier loss: 0.175702; batch adversarial loss: 0.493150\n",
      "epoch 71; iter: 0; batch classifier loss: 0.196773; batch adversarial loss: 0.546288\n",
      "epoch 72; iter: 0; batch classifier loss: 0.239986; batch adversarial loss: 0.484461\n",
      "epoch 73; iter: 0; batch classifier loss: 0.169388; batch adversarial loss: 0.484186\n",
      "epoch 74; iter: 0; batch classifier loss: 0.192132; batch adversarial loss: 0.446664\n",
      "epoch 75; iter: 0; batch classifier loss: 0.233562; batch adversarial loss: 0.520542\n",
      "epoch 76; iter: 0; batch classifier loss: 0.133864; batch adversarial loss: 0.458870\n",
      "epoch 77; iter: 0; batch classifier loss: 0.120075; batch adversarial loss: 0.456951\n",
      "epoch 78; iter: 0; batch classifier loss: 0.039795; batch adversarial loss: 0.468391\n",
      "epoch 79; iter: 0; batch classifier loss: 0.045942; batch adversarial loss: 0.485103\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063592; batch adversarial loss: 0.490968\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076754; batch adversarial loss: 0.445230\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063599; batch adversarial loss: 0.478499\n",
      "epoch 83; iter: 0; batch classifier loss: 0.073585; batch adversarial loss: 0.449440\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063086; batch adversarial loss: 0.517189\n",
      "epoch 85; iter: 0; batch classifier loss: 0.105292; batch adversarial loss: 0.455415\n",
      "epoch 86; iter: 0; batch classifier loss: 0.118931; batch adversarial loss: 0.406172\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095271; batch adversarial loss: 0.472419\n",
      "epoch 88; iter: 0; batch classifier loss: 0.108810; batch adversarial loss: 0.475481\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053978; batch adversarial loss: 0.457073\n",
      "epoch 90; iter: 0; batch classifier loss: 0.094922; batch adversarial loss: 0.422523\n",
      "epoch 91; iter: 0; batch classifier loss: 0.065004; batch adversarial loss: 0.473895\n",
      "epoch 92; iter: 0; batch classifier loss: 0.028795; batch adversarial loss: 0.403726\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069188; batch adversarial loss: 0.470052\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079664; batch adversarial loss: 0.473189\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077522; batch adversarial loss: 0.487164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.074875; batch adversarial loss: 0.411003\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084824; batch adversarial loss: 0.514786\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077804; batch adversarial loss: 0.478740\n",
      "epoch 99; iter: 0; batch classifier loss: 0.105201; batch adversarial loss: 0.410160\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069048; batch adversarial loss: 0.546448\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083915; batch adversarial loss: 0.439464\n",
      "epoch 102; iter: 0; batch classifier loss: 0.079593; batch adversarial loss: 0.418200\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042452; batch adversarial loss: 0.442982\n",
      "epoch 104; iter: 0; batch classifier loss: 0.042921; batch adversarial loss: 0.567835\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037376; batch adversarial loss: 0.504651\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078416; batch adversarial loss: 0.434468\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052844; batch adversarial loss: 0.555010\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061091; batch adversarial loss: 0.417947\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037030; batch adversarial loss: 0.486945\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051762; batch adversarial loss: 0.400590\n",
      "epoch 111; iter: 0; batch classifier loss: 0.063092; batch adversarial loss: 0.421449\n",
      "epoch 112; iter: 0; batch classifier loss: 0.036114; batch adversarial loss: 0.419493\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034625; batch adversarial loss: 0.547794\n",
      "epoch 114; iter: 0; batch classifier loss: 0.027076; batch adversarial loss: 0.458403\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058104; batch adversarial loss: 0.524721\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060872; batch adversarial loss: 0.386554\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052759; batch adversarial loss: 0.488950\n",
      "epoch 118; iter: 0; batch classifier loss: 0.019279; batch adversarial loss: 0.586476\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043308; batch adversarial loss: 0.485469\n",
      "epoch 120; iter: 0; batch classifier loss: 0.059338; batch adversarial loss: 0.404393\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017255; batch adversarial loss: 0.346878\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035960; batch adversarial loss: 0.392658\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032314; batch adversarial loss: 0.518340\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029751; batch adversarial loss: 0.404591\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.367953\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040401; batch adversarial loss: 0.570350\n",
      "epoch 127; iter: 0; batch classifier loss: 0.068204; batch adversarial loss: 0.415070\n",
      "epoch 128; iter: 0; batch classifier loss: 0.021676; batch adversarial loss: 0.386875\n",
      "epoch 129; iter: 0; batch classifier loss: 0.020641; batch adversarial loss: 0.519100\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017833; batch adversarial loss: 0.429664\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015353; batch adversarial loss: 0.409157\n",
      "epoch 132; iter: 0; batch classifier loss: 0.011676; batch adversarial loss: 0.547018\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044264; batch adversarial loss: 0.392840\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009408; batch adversarial loss: 0.410913\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031816; batch adversarial loss: 0.425330\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023443; batch adversarial loss: 0.418783\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042378; batch adversarial loss: 0.377896\n",
      "epoch 138; iter: 0; batch classifier loss: 0.073207; batch adversarial loss: 0.445083\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026564; batch adversarial loss: 0.483329\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025588; batch adversarial loss: 0.499537\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034572; batch adversarial loss: 0.480890\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019616; batch adversarial loss: 0.439176\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024411; batch adversarial loss: 0.541640\n",
      "epoch 144; iter: 0; batch classifier loss: 0.045060; batch adversarial loss: 0.419349\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019487; batch adversarial loss: 0.421601\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025251; batch adversarial loss: 0.403035\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041434; batch adversarial loss: 0.490028\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059140; batch adversarial loss: 0.410919\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063717; batch adversarial loss: 0.360716\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040552; batch adversarial loss: 0.360844\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043581; batch adversarial loss: 0.449314\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017423; batch adversarial loss: 0.462127\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018579; batch adversarial loss: 0.395228\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026007; batch adversarial loss: 0.395028\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022944; batch adversarial loss: 0.431907\n",
      "epoch 156; iter: 0; batch classifier loss: 0.021175; batch adversarial loss: 0.437820\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015430; batch adversarial loss: 0.442431\n",
      "epoch 158; iter: 0; batch classifier loss: 0.013892; batch adversarial loss: 0.498652\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013459; batch adversarial loss: 0.483921\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031314; batch adversarial loss: 0.409807\n",
      "epoch 161; iter: 0; batch classifier loss: 0.021507; batch adversarial loss: 0.432971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.007508; batch adversarial loss: 0.409552\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021841; batch adversarial loss: 0.379634\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014434; batch adversarial loss: 0.494372\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015268; batch adversarial loss: 0.408341\n",
      "epoch 166; iter: 0; batch classifier loss: 0.018222; batch adversarial loss: 0.437727\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011167; batch adversarial loss: 0.415740\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019671; batch adversarial loss: 0.406338\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018598; batch adversarial loss: 0.452747\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022258; batch adversarial loss: 0.547369\n",
      "epoch 171; iter: 0; batch classifier loss: 0.010300; batch adversarial loss: 0.431264\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011801; batch adversarial loss: 0.442944\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008785; batch adversarial loss: 0.464016\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019257; batch adversarial loss: 0.388100\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022405; batch adversarial loss: 0.530970\n",
      "epoch 176; iter: 0; batch classifier loss: 0.041994; batch adversarial loss: 0.513823\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030280; batch adversarial loss: 0.465712\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013608; batch adversarial loss: 0.432070\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011999; batch adversarial loss: 0.459627\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022281; batch adversarial loss: 0.425387\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008042; batch adversarial loss: 0.515104\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038951; batch adversarial loss: 0.434628\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010989; batch adversarial loss: 0.437809\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020255; batch adversarial loss: 0.480296\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011800; batch adversarial loss: 0.381108\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014334; batch adversarial loss: 0.495318\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026172; batch adversarial loss: 0.499033\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010915; batch adversarial loss: 0.443635\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025190; batch adversarial loss: 0.430124\n",
      "epoch 190; iter: 0; batch classifier loss: 0.016875; batch adversarial loss: 0.427795\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016361; batch adversarial loss: 0.384786\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040224; batch adversarial loss: 0.436041\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012105; batch adversarial loss: 0.475022\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013733; batch adversarial loss: 0.413052\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007343; batch adversarial loss: 0.501586\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029050; batch adversarial loss: 0.527366\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022066; batch adversarial loss: 0.385628\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024914; batch adversarial loss: 0.412088\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013194; batch adversarial loss: 0.508662\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694485; batch adversarial loss: 0.731571\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544359; batch adversarial loss: 0.717782\n",
      "epoch 2; iter: 0; batch classifier loss: 0.501160; batch adversarial loss: 0.685919\n",
      "epoch 3; iter: 0; batch classifier loss: 0.355069; batch adversarial loss: 0.650829\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354758; batch adversarial loss: 0.619294\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331057; batch adversarial loss: 0.593304\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282425; batch adversarial loss: 0.552756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.325642; batch adversarial loss: 0.523955\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270625; batch adversarial loss: 0.563380\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326857; batch adversarial loss: 0.520945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.244355; batch adversarial loss: 0.501655\n",
      "epoch 11; iter: 0; batch classifier loss: 0.183443; batch adversarial loss: 0.481129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.208765; batch adversarial loss: 0.477543\n",
      "epoch 13; iter: 0; batch classifier loss: 0.183911; batch adversarial loss: 0.430135\n",
      "epoch 14; iter: 0; batch classifier loss: 0.185983; batch adversarial loss: 0.382670\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196601; batch adversarial loss: 0.449649\n",
      "epoch 16; iter: 0; batch classifier loss: 0.207448; batch adversarial loss: 0.427903\n",
      "epoch 17; iter: 0; batch classifier loss: 0.185652; batch adversarial loss: 0.408146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.193285; batch adversarial loss: 0.403634\n",
      "epoch 19; iter: 0; batch classifier loss: 0.148422; batch adversarial loss: 0.366345\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189613; batch adversarial loss: 0.432829\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170322; batch adversarial loss: 0.398956\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167911; batch adversarial loss: 0.482309\n",
      "epoch 23; iter: 0; batch classifier loss: 0.179216; batch adversarial loss: 0.419395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.203854; batch adversarial loss: 0.375299\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158489; batch adversarial loss: 0.356230\n",
      "epoch 26; iter: 0; batch classifier loss: 0.183691; batch adversarial loss: 0.383133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.198052; batch adversarial loss: 0.475468\n",
      "epoch 28; iter: 0; batch classifier loss: 0.182349; batch adversarial loss: 0.480276\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168234; batch adversarial loss: 0.448193\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163958; batch adversarial loss: 0.420830\n",
      "epoch 31; iter: 0; batch classifier loss: 0.137755; batch adversarial loss: 0.409813\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183562; batch adversarial loss: 0.390928\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130432; batch adversarial loss: 0.360415\n",
      "epoch 34; iter: 0; batch classifier loss: 0.148523; batch adversarial loss: 0.418776\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123293; batch adversarial loss: 0.447668\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116118; batch adversarial loss: 0.417481\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101167; batch adversarial loss: 0.356630\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105958; batch adversarial loss: 0.374204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.171729; batch adversarial loss: 0.485820\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103985; batch adversarial loss: 0.344122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106151; batch adversarial loss: 0.479987\n",
      "epoch 42; iter: 0; batch classifier loss: 0.101773; batch adversarial loss: 0.470801\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117856; batch adversarial loss: 0.335818\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099959; batch adversarial loss: 0.342899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094634; batch adversarial loss: 0.381571\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112572; batch adversarial loss: 0.399686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.083793; batch adversarial loss: 0.386536\n",
      "epoch 48; iter: 0; batch classifier loss: 0.104651; batch adversarial loss: 0.396387\n",
      "epoch 49; iter: 0; batch classifier loss: 0.082615; batch adversarial loss: 0.367868\n",
      "epoch 50; iter: 0; batch classifier loss: 0.072616; batch adversarial loss: 0.465403\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113728; batch adversarial loss: 0.433929\n",
      "epoch 52; iter: 0; batch classifier loss: 0.115665; batch adversarial loss: 0.442411\n",
      "epoch 53; iter: 0; batch classifier loss: 0.088305; batch adversarial loss: 0.432416\n",
      "epoch 54; iter: 0; batch classifier loss: 0.100900; batch adversarial loss: 0.438211\n",
      "epoch 55; iter: 0; batch classifier loss: 0.069026; batch adversarial loss: 0.378170\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113556; batch adversarial loss: 0.414936\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086389; batch adversarial loss: 0.365811\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073352; batch adversarial loss: 0.405885\n",
      "epoch 59; iter: 0; batch classifier loss: 0.096829; batch adversarial loss: 0.443938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.047907; batch adversarial loss: 0.371785\n",
      "epoch 61; iter: 0; batch classifier loss: 0.067642; batch adversarial loss: 0.437479\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117917; batch adversarial loss: 0.370858\n",
      "epoch 63; iter: 0; batch classifier loss: 0.059078; batch adversarial loss: 0.468368\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066976; batch adversarial loss: 0.437276\n",
      "epoch 65; iter: 0; batch classifier loss: 0.063663; batch adversarial loss: 0.405914\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082638; batch adversarial loss: 0.386398\n",
      "epoch 67; iter: 0; batch classifier loss: 0.065853; batch adversarial loss: 0.412944\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075326; batch adversarial loss: 0.447999\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070213; batch adversarial loss: 0.422995\n",
      "epoch 70; iter: 0; batch classifier loss: 0.082345; batch adversarial loss: 0.473028\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069009; batch adversarial loss: 0.426708\n",
      "epoch 72; iter: 0; batch classifier loss: 0.088898; batch adversarial loss: 0.443064\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080048; batch adversarial loss: 0.305759\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093967; batch adversarial loss: 0.371548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064218; batch adversarial loss: 0.367189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.060711; batch adversarial loss: 0.434129\n",
      "epoch 77; iter: 0; batch classifier loss: 0.065536; batch adversarial loss: 0.374373\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064121; batch adversarial loss: 0.431129\n",
      "epoch 79; iter: 0; batch classifier loss: 0.076166; batch adversarial loss: 0.329019\n",
      "epoch 80; iter: 0; batch classifier loss: 0.111683; batch adversarial loss: 0.391204\n",
      "epoch 81; iter: 0; batch classifier loss: 0.084610; batch adversarial loss: 0.425386\n",
      "epoch 82; iter: 0; batch classifier loss: 0.051571; batch adversarial loss: 0.383112\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062342; batch adversarial loss: 0.391611\n",
      "epoch 84; iter: 0; batch classifier loss: 0.045527; batch adversarial loss: 0.453147\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058148; batch adversarial loss: 0.393904\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043104; batch adversarial loss: 0.399017\n",
      "epoch 87; iter: 0; batch classifier loss: 0.045641; batch adversarial loss: 0.506758\n",
      "epoch 88; iter: 0; batch classifier loss: 0.036674; batch adversarial loss: 0.445527\n",
      "epoch 89; iter: 0; batch classifier loss: 0.060601; batch adversarial loss: 0.496717\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048054; batch adversarial loss: 0.452710\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060141; batch adversarial loss: 0.351542\n",
      "epoch 92; iter: 0; batch classifier loss: 0.050632; batch adversarial loss: 0.450470\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039609; batch adversarial loss: 0.467212\n",
      "epoch 94; iter: 0; batch classifier loss: 0.035537; batch adversarial loss: 0.435823\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068822; batch adversarial loss: 0.390363\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033443; batch adversarial loss: 0.445942\n",
      "epoch 97; iter: 0; batch classifier loss: 0.039154; batch adversarial loss: 0.410417\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063325; batch adversarial loss: 0.426659\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063655; batch adversarial loss: 0.416063\n",
      "epoch 100; iter: 0; batch classifier loss: 0.026170; batch adversarial loss: 0.466469\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055435; batch adversarial loss: 0.375628\n",
      "epoch 102; iter: 0; batch classifier loss: 0.042174; batch adversarial loss: 0.498529\n",
      "epoch 103; iter: 0; batch classifier loss: 0.021054; batch adversarial loss: 0.460090\n",
      "epoch 104; iter: 0; batch classifier loss: 0.019291; batch adversarial loss: 0.559081\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061003; batch adversarial loss: 0.462220\n",
      "epoch 106; iter: 0; batch classifier loss: 0.069452; batch adversarial loss: 0.346029\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047283; batch adversarial loss: 0.512937\n",
      "epoch 108; iter: 0; batch classifier loss: 0.050571; batch adversarial loss: 0.456338\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029333; batch adversarial loss: 0.429324\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020602; batch adversarial loss: 0.404216\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042578; batch adversarial loss: 0.472488\n",
      "epoch 112; iter: 0; batch classifier loss: 0.013513; batch adversarial loss: 0.483628\n",
      "epoch 113; iter: 0; batch classifier loss: 0.052931; batch adversarial loss: 0.418907\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022853; batch adversarial loss: 0.452229\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028072; batch adversarial loss: 0.425612\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045580; batch adversarial loss: 0.414897\n",
      "epoch 117; iter: 0; batch classifier loss: 0.057357; batch adversarial loss: 0.395660\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022383; batch adversarial loss: 0.408992\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022051; batch adversarial loss: 0.508931\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036391; batch adversarial loss: 0.563669\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032448; batch adversarial loss: 0.449885\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030527; batch adversarial loss: 0.452472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.088538; batch adversarial loss: 0.595857\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.415690\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041812; batch adversarial loss: 0.450297\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031714; batch adversarial loss: 0.455296\n",
      "epoch 127; iter: 0; batch classifier loss: 0.134063; batch adversarial loss: 0.676475\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056284; batch adversarial loss: 0.546517\n",
      "epoch 129; iter: 0; batch classifier loss: 0.099483; batch adversarial loss: 0.661756\n",
      "epoch 130; iter: 0; batch classifier loss: 0.196374; batch adversarial loss: 0.822129\n",
      "epoch 131; iter: 0; batch classifier loss: 0.193033; batch adversarial loss: 0.692023\n",
      "epoch 132; iter: 0; batch classifier loss: 0.104946; batch adversarial loss: 0.737877\n",
      "epoch 133; iter: 0; batch classifier loss: 0.082032; batch adversarial loss: 0.477744\n",
      "epoch 134; iter: 0; batch classifier loss: 0.143219; batch adversarial loss: 0.625795\n",
      "epoch 135; iter: 0; batch classifier loss: 0.178329; batch adversarial loss: 0.818401\n",
      "epoch 136; iter: 0; batch classifier loss: 0.116967; batch adversarial loss: 0.507615\n",
      "epoch 137; iter: 0; batch classifier loss: 0.121338; batch adversarial loss: 0.538287\n",
      "epoch 138; iter: 0; batch classifier loss: 0.221615; batch adversarial loss: 0.728339\n",
      "epoch 139; iter: 0; batch classifier loss: 0.101069; batch adversarial loss: 0.568444\n",
      "epoch 140; iter: 0; batch classifier loss: 0.239924; batch adversarial loss: 0.856789\n",
      "epoch 141; iter: 0; batch classifier loss: 0.104142; batch adversarial loss: 0.547074\n",
      "epoch 142; iter: 0; batch classifier loss: 0.116872; batch adversarial loss: 0.510117\n",
      "epoch 143; iter: 0; batch classifier loss: 0.145040; batch adversarial loss: 0.616618\n",
      "epoch 144; iter: 0; batch classifier loss: 0.119054; batch adversarial loss: 0.475723\n",
      "epoch 145; iter: 0; batch classifier loss: 0.213571; batch adversarial loss: 0.706706\n",
      "epoch 146; iter: 0; batch classifier loss: 0.136117; batch adversarial loss: 0.494875\n",
      "epoch 147; iter: 0; batch classifier loss: 0.085810; batch adversarial loss: 0.499281\n",
      "epoch 148; iter: 0; batch classifier loss: 0.123951; batch adversarial loss: 0.618467\n",
      "epoch 149; iter: 0; batch classifier loss: 0.117203; batch adversarial loss: 0.545029\n",
      "epoch 150; iter: 0; batch classifier loss: 0.203131; batch adversarial loss: 0.631022\n",
      "epoch 151; iter: 0; batch classifier loss: 0.153005; batch adversarial loss: 0.622556\n",
      "epoch 152; iter: 0; batch classifier loss: 0.152775; batch adversarial loss: 0.539545\n",
      "epoch 153; iter: 0; batch classifier loss: 0.206619; batch adversarial loss: 0.630587\n",
      "epoch 154; iter: 0; batch classifier loss: 0.187986; batch adversarial loss: 0.689471\n",
      "epoch 155; iter: 0; batch classifier loss: 0.140230; batch adversarial loss: 0.549551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.136722; batch adversarial loss: 0.502933\n",
      "epoch 157; iter: 0; batch classifier loss: 0.193653; batch adversarial loss: 0.587976\n",
      "epoch 158; iter: 0; batch classifier loss: 0.198183; batch adversarial loss: 0.648584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.148903; batch adversarial loss: 0.445470\n",
      "epoch 160; iter: 0; batch classifier loss: 0.119686; batch adversarial loss: 0.474994\n",
      "epoch 161; iter: 0; batch classifier loss: 0.141393; batch adversarial loss: 0.534891\n",
      "epoch 162; iter: 0; batch classifier loss: 0.149867; batch adversarial loss: 0.474038\n",
      "epoch 163; iter: 0; batch classifier loss: 0.154415; batch adversarial loss: 0.498957\n",
      "epoch 164; iter: 0; batch classifier loss: 0.109025; batch adversarial loss: 0.454683\n",
      "epoch 165; iter: 0; batch classifier loss: 0.072245; batch adversarial loss: 0.429681\n",
      "epoch 166; iter: 0; batch classifier loss: 0.154229; batch adversarial loss: 0.514298\n",
      "epoch 167; iter: 0; batch classifier loss: 0.077401; batch adversarial loss: 0.420842\n",
      "epoch 168; iter: 0; batch classifier loss: 0.094512; batch adversarial loss: 0.439707\n",
      "epoch 169; iter: 0; batch classifier loss: 0.099088; batch adversarial loss: 0.470105\n",
      "epoch 170; iter: 0; batch classifier loss: 0.102081; batch adversarial loss: 0.515323\n",
      "epoch 171; iter: 0; batch classifier loss: 0.088316; batch adversarial loss: 0.382983\n",
      "epoch 172; iter: 0; batch classifier loss: 0.116794; batch adversarial loss: 0.473874\n",
      "epoch 173; iter: 0; batch classifier loss: 0.059487; batch adversarial loss: 0.378866\n",
      "epoch 174; iter: 0; batch classifier loss: 0.095400; batch adversarial loss: 0.478311\n",
      "epoch 175; iter: 0; batch classifier loss: 0.102871; batch adversarial loss: 0.473575\n",
      "epoch 176; iter: 0; batch classifier loss: 0.102717; batch adversarial loss: 0.535023\n",
      "epoch 177; iter: 0; batch classifier loss: 0.133655; batch adversarial loss: 0.457593\n",
      "epoch 178; iter: 0; batch classifier loss: 0.043851; batch adversarial loss: 0.493136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040057; batch adversarial loss: 0.493265\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025910; batch adversarial loss: 0.464587\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047868; batch adversarial loss: 0.383180\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027869; batch adversarial loss: 0.501489\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020778; batch adversarial loss: 0.483101\n",
      "epoch 184; iter: 0; batch classifier loss: 0.077945; batch adversarial loss: 0.386825\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044540; batch adversarial loss: 0.470769\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034438; batch adversarial loss: 0.431571\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043677; batch adversarial loss: 0.446394\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028707; batch adversarial loss: 0.410239\n",
      "epoch 189; iter: 0; batch classifier loss: 0.056031; batch adversarial loss: 0.433864\n",
      "epoch 190; iter: 0; batch classifier loss: 0.091521; batch adversarial loss: 0.397043\n",
      "epoch 191; iter: 0; batch classifier loss: 0.044039; batch adversarial loss: 0.378185\n",
      "epoch 192; iter: 0; batch classifier loss: 0.082211; batch adversarial loss: 0.537824\n",
      "epoch 193; iter: 0; batch classifier loss: 0.058651; batch adversarial loss: 0.429538\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025879; batch adversarial loss: 0.592991\n",
      "epoch 195; iter: 0; batch classifier loss: 0.051977; batch adversarial loss: 0.471651\n",
      "epoch 196; iter: 0; batch classifier loss: 0.098737; batch adversarial loss: 0.396549\n",
      "epoch 197; iter: 0; batch classifier loss: 0.082499; batch adversarial loss: 0.583629\n",
      "epoch 198; iter: 0; batch classifier loss: 0.063207; batch adversarial loss: 0.415147\n",
      "epoch 199; iter: 0; batch classifier loss: 0.103359; batch adversarial loss: 0.470686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678459; batch adversarial loss: 0.882257\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508990; batch adversarial loss: 0.849849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433849; batch adversarial loss: 0.815723\n",
      "epoch 3; iter: 0; batch classifier loss: 0.478005; batch adversarial loss: 0.770012\n",
      "epoch 4; iter: 0; batch classifier loss: 0.413708; batch adversarial loss: 0.706715\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403421; batch adversarial loss: 0.679917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314143; batch adversarial loss: 0.622229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319111; batch adversarial loss: 0.608840\n",
      "epoch 8; iter: 0; batch classifier loss: 0.277671; batch adversarial loss: 0.593990\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292693; batch adversarial loss: 0.589087\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240617; batch adversarial loss: 0.544061\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280559; batch adversarial loss: 0.551645\n",
      "epoch 12; iter: 0; batch classifier loss: 0.222118; batch adversarial loss: 0.496981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.179478; batch adversarial loss: 0.482539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249005; batch adversarial loss: 0.466484\n",
      "epoch 15; iter: 0; batch classifier loss: 0.183330; batch adversarial loss: 0.477522\n",
      "epoch 16; iter: 0; batch classifier loss: 0.174189; batch adversarial loss: 0.470307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.190581; batch adversarial loss: 0.539972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.154698; batch adversarial loss: 0.460478\n",
      "epoch 19; iter: 0; batch classifier loss: 0.159908; batch adversarial loss: 0.491160\n",
      "epoch 20; iter: 0; batch classifier loss: 0.170462; batch adversarial loss: 0.448423\n",
      "epoch 21; iter: 0; batch classifier loss: 0.170838; batch adversarial loss: 0.377467\n",
      "epoch 22; iter: 0; batch classifier loss: 0.217602; batch adversarial loss: 0.452879\n",
      "epoch 23; iter: 0; batch classifier loss: 0.161111; batch adversarial loss: 0.462424\n",
      "epoch 24; iter: 0; batch classifier loss: 0.103885; batch adversarial loss: 0.433877\n",
      "epoch 25; iter: 0; batch classifier loss: 0.172765; batch adversarial loss: 0.464031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.221505; batch adversarial loss: 0.435535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137439; batch adversarial loss: 0.408255\n",
      "epoch 28; iter: 0; batch classifier loss: 0.132030; batch adversarial loss: 0.474045\n",
      "epoch 29; iter: 0; batch classifier loss: 0.103155; batch adversarial loss: 0.427313\n",
      "epoch 30; iter: 0; batch classifier loss: 0.120946; batch adversarial loss: 0.505224\n",
      "epoch 31; iter: 0; batch classifier loss: 0.153110; batch adversarial loss: 0.427429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100826; batch adversarial loss: 0.465961\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181155; batch adversarial loss: 0.460379\n",
      "epoch 34; iter: 0; batch classifier loss: 0.074783; batch adversarial loss: 0.522405\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148613; batch adversarial loss: 0.499771\n",
      "epoch 36; iter: 0; batch classifier loss: 0.130444; batch adversarial loss: 0.401863\n",
      "epoch 37; iter: 0; batch classifier loss: 0.084448; batch adversarial loss: 0.381371\n",
      "epoch 38; iter: 0; batch classifier loss: 0.079803; batch adversarial loss: 0.420263\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121620; batch adversarial loss: 0.491052\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116002; batch adversarial loss: 0.396600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143968; batch adversarial loss: 0.413316\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195079; batch adversarial loss: 0.496464\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137991; batch adversarial loss: 0.482889\n",
      "epoch 44; iter: 0; batch classifier loss: 0.098240; batch adversarial loss: 0.438121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097836; batch adversarial loss: 0.401535\n",
      "epoch 46; iter: 0; batch classifier loss: 0.161850; batch adversarial loss: 0.402064\n",
      "epoch 47; iter: 0; batch classifier loss: 0.096311; batch adversarial loss: 0.377791\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140875; batch adversarial loss: 0.452102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077080; batch adversarial loss: 0.369577\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070759; batch adversarial loss: 0.479292\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083491; batch adversarial loss: 0.433212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.111038; batch adversarial loss: 0.347570\n",
      "epoch 53; iter: 0; batch classifier loss: 0.081529; batch adversarial loss: 0.342423\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101216; batch adversarial loss: 0.421084\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092263; batch adversarial loss: 0.376423\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087661; batch adversarial loss: 0.355870\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105966; batch adversarial loss: 0.372162\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099159; batch adversarial loss: 0.472178\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057569; batch adversarial loss: 0.428561\n",
      "epoch 60; iter: 0; batch classifier loss: 0.071231; batch adversarial loss: 0.449937\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061300; batch adversarial loss: 0.396437\n",
      "epoch 62; iter: 0; batch classifier loss: 0.058170; batch adversarial loss: 0.313731\n",
      "epoch 63; iter: 0; batch classifier loss: 0.124355; batch adversarial loss: 0.425640\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074955; batch adversarial loss: 0.458528\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078820; batch adversarial loss: 0.418839\n",
      "epoch 66; iter: 0; batch classifier loss: 0.060227; batch adversarial loss: 0.485058\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105455; batch adversarial loss: 0.530230\n",
      "epoch 68; iter: 0; batch classifier loss: 0.138438; batch adversarial loss: 0.429276\n",
      "epoch 69; iter: 0; batch classifier loss: 0.073627; batch adversarial loss: 0.512177\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050798; batch adversarial loss: 0.469871\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067883; batch adversarial loss: 0.424563\n",
      "epoch 72; iter: 0; batch classifier loss: 0.060234; batch adversarial loss: 0.488139\n",
      "epoch 73; iter: 0; batch classifier loss: 0.057705; batch adversarial loss: 0.444629\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060816; batch adversarial loss: 0.430930\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081082; batch adversarial loss: 0.417935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096914; batch adversarial loss: 0.368952\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070482; batch adversarial loss: 0.399729\n",
      "epoch 78; iter: 0; batch classifier loss: 0.095551; batch adversarial loss: 0.456418\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087871; batch adversarial loss: 0.471016\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077800; batch adversarial loss: 0.464995\n",
      "epoch 81; iter: 0; batch classifier loss: 0.089929; batch adversarial loss: 0.521461\n",
      "epoch 82; iter: 0; batch classifier loss: 0.046515; batch adversarial loss: 0.350143\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082389; batch adversarial loss: 0.437889\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065304; batch adversarial loss: 0.445611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090613; batch adversarial loss: 0.431546\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072269; batch adversarial loss: 0.425583\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060108; batch adversarial loss: 0.423428\n",
      "epoch 88; iter: 0; batch classifier loss: 0.140212; batch adversarial loss: 0.429656\n",
      "epoch 89; iter: 0; batch classifier loss: 0.036184; batch adversarial loss: 0.370332\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051106; batch adversarial loss: 0.337795\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081016; batch adversarial loss: 0.436325\n",
      "epoch 92; iter: 0; batch classifier loss: 0.092143; batch adversarial loss: 0.325826\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044804; batch adversarial loss: 0.349225\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082202; batch adversarial loss: 0.426170\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107088; batch adversarial loss: 0.349053\n",
      "epoch 96; iter: 0; batch classifier loss: 0.057142; batch adversarial loss: 0.447381\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054686; batch adversarial loss: 0.414446\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084484; batch adversarial loss: 0.509151\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064671; batch adversarial loss: 0.443765\n",
      "epoch 100; iter: 0; batch classifier loss: 0.077171; batch adversarial loss: 0.378700\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057512; batch adversarial loss: 0.431345\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073605; batch adversarial loss: 0.429676\n",
      "epoch 103; iter: 0; batch classifier loss: 0.049006; batch adversarial loss: 0.417953\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079452; batch adversarial loss: 0.486927\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045341; batch adversarial loss: 0.387391\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047671; batch adversarial loss: 0.467667\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033804; batch adversarial loss: 0.401190\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044573; batch adversarial loss: 0.348625\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064051; batch adversarial loss: 0.380396\n",
      "epoch 110; iter: 0; batch classifier loss: 0.090564; batch adversarial loss: 0.488451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070712; batch adversarial loss: 0.432717\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059512; batch adversarial loss: 0.394502\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058311; batch adversarial loss: 0.453151\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051840; batch adversarial loss: 0.333909\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066866; batch adversarial loss: 0.446780\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029063; batch adversarial loss: 0.387010\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052691; batch adversarial loss: 0.462246\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052654; batch adversarial loss: 0.463520\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060968; batch adversarial loss: 0.373520\n",
      "epoch 120; iter: 0; batch classifier loss: 0.064310; batch adversarial loss: 0.439990\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049870; batch adversarial loss: 0.406558\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040413; batch adversarial loss: 0.529619\n",
      "epoch 123; iter: 0; batch classifier loss: 0.096275; batch adversarial loss: 0.457892\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039337; batch adversarial loss: 0.442219\n",
      "epoch 125; iter: 0; batch classifier loss: 0.074361; batch adversarial loss: 0.354423\n",
      "epoch 126; iter: 0; batch classifier loss: 0.040530; batch adversarial loss: 0.386363\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043202; batch adversarial loss: 0.414069\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058500; batch adversarial loss: 0.484603\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040603; batch adversarial loss: 0.536261\n",
      "epoch 130; iter: 0; batch classifier loss: 0.063674; batch adversarial loss: 0.485872\n",
      "epoch 131; iter: 0; batch classifier loss: 0.075189; batch adversarial loss: 0.381177\n",
      "epoch 132; iter: 0; batch classifier loss: 0.090067; batch adversarial loss: 0.460462\n",
      "epoch 133; iter: 0; batch classifier loss: 0.052908; batch adversarial loss: 0.454315\n",
      "epoch 134; iter: 0; batch classifier loss: 0.073849; batch adversarial loss: 0.404717\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036332; batch adversarial loss: 0.341653\n",
      "epoch 136; iter: 0; batch classifier loss: 0.075252; batch adversarial loss: 0.537625\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054101; batch adversarial loss: 0.326970\n",
      "epoch 138; iter: 0; batch classifier loss: 0.053178; batch adversarial loss: 0.450323\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045095; batch adversarial loss: 0.434312\n",
      "epoch 140; iter: 0; batch classifier loss: 0.084551; batch adversarial loss: 0.429432\n",
      "epoch 141; iter: 0; batch classifier loss: 0.047531; batch adversarial loss: 0.445016\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038573; batch adversarial loss: 0.363366\n",
      "epoch 143; iter: 0; batch classifier loss: 0.034986; batch adversarial loss: 0.450041\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.469846\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057808; batch adversarial loss: 0.343407\n",
      "epoch 146; iter: 0; batch classifier loss: 0.047432; batch adversarial loss: 0.428205\n",
      "epoch 147; iter: 0; batch classifier loss: 0.045927; batch adversarial loss: 0.369028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.051962; batch adversarial loss: 0.423368\n",
      "epoch 149; iter: 0; batch classifier loss: 0.064605; batch adversarial loss: 0.411020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.076717; batch adversarial loss: 0.454990\n",
      "epoch 151; iter: 0; batch classifier loss: 0.063931; batch adversarial loss: 0.417723\n",
      "epoch 152; iter: 0; batch classifier loss: 0.052077; batch adversarial loss: 0.478852\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024593; batch adversarial loss: 0.408220\n",
      "epoch 154; iter: 0; batch classifier loss: 0.057775; batch adversarial loss: 0.534743\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044534; batch adversarial loss: 0.469326\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042121; batch adversarial loss: 0.389207\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035333; batch adversarial loss: 0.460339\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029826; batch adversarial loss: 0.416839\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042081; batch adversarial loss: 0.460030\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.405332\n",
      "epoch 161; iter: 0; batch classifier loss: 0.059121; batch adversarial loss: 0.427951\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051845; batch adversarial loss: 0.484254\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030255; batch adversarial loss: 0.395285\n",
      "epoch 164; iter: 0; batch classifier loss: 0.037645; batch adversarial loss: 0.394384\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038373; batch adversarial loss: 0.468515\n",
      "epoch 166; iter: 0; batch classifier loss: 0.067532; batch adversarial loss: 0.412179\n",
      "epoch 167; iter: 0; batch classifier loss: 0.065709; batch adversarial loss: 0.507402\n",
      "epoch 168; iter: 0; batch classifier loss: 0.038739; batch adversarial loss: 0.422700\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039813; batch adversarial loss: 0.402584\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041059; batch adversarial loss: 0.378600\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025946; batch adversarial loss: 0.419497\n",
      "epoch 172; iter: 0; batch classifier loss: 0.038698; batch adversarial loss: 0.467393\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032466; batch adversarial loss: 0.449874\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012971; batch adversarial loss: 0.370905\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024461; batch adversarial loss: 0.383329\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028765; batch adversarial loss: 0.482235\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023384; batch adversarial loss: 0.473846\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025391; batch adversarial loss: 0.473724\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017150; batch adversarial loss: 0.476094\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031245; batch adversarial loss: 0.471221\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032409; batch adversarial loss: 0.514440\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023651; batch adversarial loss: 0.462836\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018843; batch adversarial loss: 0.504947\n",
      "epoch 184; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.407914\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.492378\n",
      "epoch 186; iter: 0; batch classifier loss: 0.029927; batch adversarial loss: 0.451600\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023226; batch adversarial loss: 0.421365\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020656; batch adversarial loss: 0.556927\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034120; batch adversarial loss: 0.497490\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011982; batch adversarial loss: 0.448313\n",
      "epoch 191; iter: 0; batch classifier loss: 0.038755; batch adversarial loss: 0.519240\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034628; batch adversarial loss: 0.634379\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007516; batch adversarial loss: 0.438221\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036163; batch adversarial loss: 0.497044\n",
      "epoch 195; iter: 0; batch classifier loss: 0.044965; batch adversarial loss: 0.497005\n",
      "epoch 196; iter: 0; batch classifier loss: 0.047861; batch adversarial loss: 0.461934\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024336; batch adversarial loss: 0.534295\n",
      "epoch 198; iter: 0; batch classifier loss: 0.081291; batch adversarial loss: 0.520911\n",
      "epoch 199; iter: 0; batch classifier loss: 0.116570; batch adversarial loss: 0.706062\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682047; batch adversarial loss: 0.607224\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411996; batch adversarial loss: 0.609001\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387952; batch adversarial loss: 0.575236\n",
      "epoch 3; iter: 0; batch classifier loss: 0.313516; batch adversarial loss: 0.540385\n",
      "epoch 4; iter: 0; batch classifier loss: 0.230344; batch adversarial loss: 0.538626\n",
      "epoch 5; iter: 0; batch classifier loss: 0.244373; batch adversarial loss: 0.539593\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288398; batch adversarial loss: 0.516581\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336747; batch adversarial loss: 0.516442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.283110; batch adversarial loss: 0.495612\n",
      "epoch 9; iter: 0; batch classifier loss: 0.241788; batch adversarial loss: 0.480745\n",
      "epoch 10; iter: 0; batch classifier loss: 0.208581; batch adversarial loss: 0.479547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.212671; batch adversarial loss: 0.465127\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205332; batch adversarial loss: 0.510955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.191895; batch adversarial loss: 0.441274\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246854; batch adversarial loss: 0.490818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230593; batch adversarial loss: 0.429260\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233886; batch adversarial loss: 0.445730\n",
      "epoch 17; iter: 0; batch classifier loss: 0.176378; batch adversarial loss: 0.507282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243796; batch adversarial loss: 0.468168\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207593; batch adversarial loss: 0.458210\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237044; batch adversarial loss: 0.427129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.235326; batch adversarial loss: 0.474343\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236694; batch adversarial loss: 0.576172\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316306; batch adversarial loss: 0.514813\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209995; batch adversarial loss: 0.493539\n",
      "epoch 25; iter: 0; batch classifier loss: 0.224071; batch adversarial loss: 0.449559\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260751; batch adversarial loss: 0.512160\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258118; batch adversarial loss: 0.512578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298838; batch adversarial loss: 0.381507\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398856; batch adversarial loss: 0.411882\n",
      "epoch 30; iter: 0; batch classifier loss: 0.242501; batch adversarial loss: 0.435214\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146271; batch adversarial loss: 0.518134\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167896; batch adversarial loss: 0.374638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.107046; batch adversarial loss: 0.447640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.134042; batch adversarial loss: 0.512628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.103735; batch adversarial loss: 0.439464\n",
      "epoch 36; iter: 0; batch classifier loss: 0.102617; batch adversarial loss: 0.368339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126325; batch adversarial loss: 0.481566\n",
      "epoch 38; iter: 0; batch classifier loss: 0.086021; batch adversarial loss: 0.392659\n",
      "epoch 39; iter: 0; batch classifier loss: 0.112257; batch adversarial loss: 0.378982\n",
      "epoch 40; iter: 0; batch classifier loss: 0.167133; batch adversarial loss: 0.378567\n",
      "epoch 41; iter: 0; batch classifier loss: 0.100586; batch adversarial loss: 0.423658\n",
      "epoch 42; iter: 0; batch classifier loss: 0.096250; batch adversarial loss: 0.433240\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105208; batch adversarial loss: 0.443363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.095440; batch adversarial loss: 0.479626\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111092; batch adversarial loss: 0.499607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.119578; batch adversarial loss: 0.462485\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088046; batch adversarial loss: 0.498353\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099390; batch adversarial loss: 0.486599\n",
      "epoch 49; iter: 0; batch classifier loss: 0.070161; batch adversarial loss: 0.487231\n",
      "epoch 50; iter: 0; batch classifier loss: 0.100171; batch adversarial loss: 0.502556\n",
      "epoch 51; iter: 0; batch classifier loss: 0.089141; batch adversarial loss: 0.411822\n",
      "epoch 52; iter: 0; batch classifier loss: 0.124527; batch adversarial loss: 0.375638\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122365; batch adversarial loss: 0.437034\n",
      "epoch 54; iter: 0; batch classifier loss: 0.156472; batch adversarial loss: 0.424872\n",
      "epoch 55; iter: 0; batch classifier loss: 0.131867; batch adversarial loss: 0.499558\n",
      "epoch 56; iter: 0; batch classifier loss: 0.144218; batch adversarial loss: 0.437366\n",
      "epoch 57; iter: 0; batch classifier loss: 0.138645; batch adversarial loss: 0.418509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.086763; batch adversarial loss: 0.484706\n",
      "epoch 59; iter: 0; batch classifier loss: 0.135545; batch adversarial loss: 0.439681\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098172; batch adversarial loss: 0.442283\n",
      "epoch 61; iter: 0; batch classifier loss: 0.111108; batch adversarial loss: 0.409141\n",
      "epoch 62; iter: 0; batch classifier loss: 0.160580; batch adversarial loss: 0.429717\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115749; batch adversarial loss: 0.478435\n",
      "epoch 64; iter: 0; batch classifier loss: 0.115853; batch adversarial loss: 0.446893\n",
      "epoch 65; iter: 0; batch classifier loss: 0.118426; batch adversarial loss: 0.424690\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105212; batch adversarial loss: 0.522121\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100636; batch adversarial loss: 0.533647\n",
      "epoch 68; iter: 0; batch classifier loss: 0.101482; batch adversarial loss: 0.446430\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071745; batch adversarial loss: 0.451367\n",
      "epoch 70; iter: 0; batch classifier loss: 0.136466; batch adversarial loss: 0.382380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.136345; batch adversarial loss: 0.477052\n",
      "epoch 72; iter: 0; batch classifier loss: 0.160384; batch adversarial loss: 0.401676\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168214; batch adversarial loss: 0.428380\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111682; batch adversarial loss: 0.491172\n",
      "epoch 75; iter: 0; batch classifier loss: 0.110390; batch adversarial loss: 0.501751\n",
      "epoch 76; iter: 0; batch classifier loss: 0.159380; batch adversarial loss: 0.417772\n",
      "epoch 77; iter: 0; batch classifier loss: 0.132999; batch adversarial loss: 0.402747\n",
      "epoch 78; iter: 0; batch classifier loss: 0.191064; batch adversarial loss: 0.415802\n",
      "epoch 79; iter: 0; batch classifier loss: 0.067871; batch adversarial loss: 0.372121\n",
      "epoch 80; iter: 0; batch classifier loss: 0.176944; batch adversarial loss: 0.433200\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082740; batch adversarial loss: 0.408014\n",
      "epoch 82; iter: 0; batch classifier loss: 0.131125; batch adversarial loss: 0.415620\n",
      "epoch 83; iter: 0; batch classifier loss: 0.160944; batch adversarial loss: 0.389190\n",
      "epoch 84; iter: 0; batch classifier loss: 0.133345; batch adversarial loss: 0.404683\n",
      "epoch 85; iter: 0; batch classifier loss: 0.151919; batch adversarial loss: 0.368769\n",
      "epoch 86; iter: 0; batch classifier loss: 0.044082; batch adversarial loss: 0.367874\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070904; batch adversarial loss: 0.442484\n",
      "epoch 88; iter: 0; batch classifier loss: 0.137178; batch adversarial loss: 0.396823\n",
      "epoch 89; iter: 0; batch classifier loss: 0.115692; batch adversarial loss: 0.405654\n",
      "epoch 90; iter: 0; batch classifier loss: 0.091531; batch adversarial loss: 0.408577\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096717; batch adversarial loss: 0.454547\n",
      "epoch 92; iter: 0; batch classifier loss: 0.109524; batch adversarial loss: 0.439092\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102601; batch adversarial loss: 0.454992\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064025; batch adversarial loss: 0.418781\n",
      "epoch 95; iter: 0; batch classifier loss: 0.091981; batch adversarial loss: 0.420878\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080352; batch adversarial loss: 0.531099\n",
      "epoch 97; iter: 0; batch classifier loss: 0.127985; batch adversarial loss: 0.334152\n",
      "epoch 98; iter: 0; batch classifier loss: 0.111950; batch adversarial loss: 0.405689\n",
      "epoch 99; iter: 0; batch classifier loss: 0.121996; batch adversarial loss: 0.392659\n",
      "epoch 100; iter: 0; batch classifier loss: 0.097121; batch adversarial loss: 0.478060\n",
      "epoch 101; iter: 0; batch classifier loss: 0.149548; batch adversarial loss: 0.434222\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070293; batch adversarial loss: 0.408638\n",
      "epoch 103; iter: 0; batch classifier loss: 0.086159; batch adversarial loss: 0.400855\n",
      "epoch 104; iter: 0; batch classifier loss: 0.099390; batch adversarial loss: 0.421289\n",
      "epoch 105; iter: 0; batch classifier loss: 0.121881; batch adversarial loss: 0.474576\n",
      "epoch 106; iter: 0; batch classifier loss: 0.103564; batch adversarial loss: 0.435659\n",
      "epoch 107; iter: 0; batch classifier loss: 0.098290; batch adversarial loss: 0.531802\n",
      "epoch 108; iter: 0; batch classifier loss: 0.058206; batch adversarial loss: 0.356887\n",
      "epoch 109; iter: 0; batch classifier loss: 0.110808; batch adversarial loss: 0.372410\n",
      "epoch 110; iter: 0; batch classifier loss: 0.077971; batch adversarial loss: 0.404654\n",
      "epoch 111; iter: 0; batch classifier loss: 0.064714; batch adversarial loss: 0.330130\n",
      "epoch 112; iter: 0; batch classifier loss: 0.107365; batch adversarial loss: 0.463374\n",
      "epoch 113; iter: 0; batch classifier loss: 0.099012; batch adversarial loss: 0.385970\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053732; batch adversarial loss: 0.423878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044381; batch adversarial loss: 0.431472\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068458; batch adversarial loss: 0.359330\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034235; batch adversarial loss: 0.399747\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044448; batch adversarial loss: 0.408068\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054853; batch adversarial loss: 0.452426\n",
      "epoch 120; iter: 0; batch classifier loss: 0.087054; batch adversarial loss: 0.365373\n",
      "epoch 121; iter: 0; batch classifier loss: 0.083856; batch adversarial loss: 0.406239\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052691; batch adversarial loss: 0.424967\n",
      "epoch 123; iter: 0; batch classifier loss: 0.083697; batch adversarial loss: 0.463732\n",
      "epoch 124; iter: 0; batch classifier loss: 0.060224; batch adversarial loss: 0.467253\n",
      "epoch 125; iter: 0; batch classifier loss: 0.042973; batch adversarial loss: 0.452240\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048153; batch adversarial loss: 0.395187\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051553; batch adversarial loss: 0.426248\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074179; batch adversarial loss: 0.452304\n",
      "epoch 129; iter: 0; batch classifier loss: 0.059340; batch adversarial loss: 0.462947\n",
      "epoch 130; iter: 0; batch classifier loss: 0.072776; batch adversarial loss: 0.385598\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037130; batch adversarial loss: 0.420461\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043990; batch adversarial loss: 0.361754\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053148; batch adversarial loss: 0.389788\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066586; batch adversarial loss: 0.435804\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019855; batch adversarial loss: 0.401563\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033696; batch adversarial loss: 0.530864\n",
      "epoch 137; iter: 0; batch classifier loss: 0.032549; batch adversarial loss: 0.454291\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040311; batch adversarial loss: 0.428321\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048013; batch adversarial loss: 0.438180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.024892; batch adversarial loss: 0.401127\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025419; batch adversarial loss: 0.483627\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026592; batch adversarial loss: 0.526586\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026501; batch adversarial loss: 0.439760\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029605; batch adversarial loss: 0.335765\n",
      "epoch 145; iter: 0; batch classifier loss: 0.060953; batch adversarial loss: 0.399050\n",
      "epoch 146; iter: 0; batch classifier loss: 0.013223; batch adversarial loss: 0.421135\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018934; batch adversarial loss: 0.451538\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035862; batch adversarial loss: 0.440297\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039894; batch adversarial loss: 0.463047\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047858; batch adversarial loss: 0.350607\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033617; batch adversarial loss: 0.333094\n",
      "epoch 152; iter: 0; batch classifier loss: 0.044633; batch adversarial loss: 0.431387\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034735; batch adversarial loss: 0.445972\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032926; batch adversarial loss: 0.554404\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021401; batch adversarial loss: 0.437036\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040052; batch adversarial loss: 0.438338\n",
      "epoch 157; iter: 0; batch classifier loss: 0.027904; batch adversarial loss: 0.412011\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019031; batch adversarial loss: 0.528456\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026240; batch adversarial loss: 0.457806\n",
      "epoch 160; iter: 0; batch classifier loss: 0.025888; batch adversarial loss: 0.344163\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015739; batch adversarial loss: 0.392301\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017888; batch adversarial loss: 0.519890\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010704; batch adversarial loss: 0.408032\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033932; batch adversarial loss: 0.445936\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030084; batch adversarial loss: 0.422250\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038282; batch adversarial loss: 0.419837\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030721; batch adversarial loss: 0.454773\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034019; batch adversarial loss: 0.438453\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016487; batch adversarial loss: 0.497026\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035779; batch adversarial loss: 0.436929\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017262; batch adversarial loss: 0.446667\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014174; batch adversarial loss: 0.463960\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013380; batch adversarial loss: 0.463377\n",
      "epoch 174; iter: 0; batch classifier loss: 0.025775; batch adversarial loss: 0.465148\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030405; batch adversarial loss: 0.384959\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028518; batch adversarial loss: 0.512580\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024600; batch adversarial loss: 0.446232\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025727; batch adversarial loss: 0.391374\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019459; batch adversarial loss: 0.465359\n",
      "epoch 180; iter: 0; batch classifier loss: 0.045373; batch adversarial loss: 0.471962\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028850; batch adversarial loss: 0.418537\n",
      "epoch 182; iter: 0; batch classifier loss: 0.041514; batch adversarial loss: 0.456868\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010454; batch adversarial loss: 0.430314\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039228; batch adversarial loss: 0.416596\n",
      "epoch 185; iter: 0; batch classifier loss: 0.014303; batch adversarial loss: 0.409610\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027157; batch adversarial loss: 0.408991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023885; batch adversarial loss: 0.446053\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016789; batch adversarial loss: 0.371774\n",
      "epoch 189; iter: 0; batch classifier loss: 0.038100; batch adversarial loss: 0.532524\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010206; batch adversarial loss: 0.433253\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017428; batch adversarial loss: 0.417186\n",
      "epoch 192; iter: 0; batch classifier loss: 0.017907; batch adversarial loss: 0.390464\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011846; batch adversarial loss: 0.372479\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013180; batch adversarial loss: 0.410957\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021541; batch adversarial loss: 0.479189\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011963; batch adversarial loss: 0.500631\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018255; batch adversarial loss: 0.392784\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027062; batch adversarial loss: 0.415118\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016461; batch adversarial loss: 0.500156\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696180; batch adversarial loss: 0.595904\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429635; batch adversarial loss: 0.609824\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383511; batch adversarial loss: 0.593943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.328088; batch adversarial loss: 0.620790\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328372; batch adversarial loss: 0.599586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315680; batch adversarial loss: 0.560028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.352797; batch adversarial loss: 0.509974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.240106; batch adversarial loss: 0.544367\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321642; batch adversarial loss: 0.561062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296632; batch adversarial loss: 0.420049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304380; batch adversarial loss: 0.504753\n",
      "epoch 11; iter: 0; batch classifier loss: 0.377303; batch adversarial loss: 0.550654\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297982; batch adversarial loss: 0.543709\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352494; batch adversarial loss: 0.507152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354981; batch adversarial loss: 0.534633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.519740\n",
      "epoch 16; iter: 0; batch classifier loss: 0.633668; batch adversarial loss: 0.485729\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567467; batch adversarial loss: 0.508006\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359423; batch adversarial loss: 0.477002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.273527; batch adversarial loss: 0.435151\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230964; batch adversarial loss: 0.442993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.269107; batch adversarial loss: 0.363470\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182850; batch adversarial loss: 0.410289\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226644; batch adversarial loss: 0.457191\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164640; batch adversarial loss: 0.427596\n",
      "epoch 25; iter: 0; batch classifier loss: 0.152481; batch adversarial loss: 0.389237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.166867; batch adversarial loss: 0.451521\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192071; batch adversarial loss: 0.429317\n",
      "epoch 28; iter: 0; batch classifier loss: 0.131951; batch adversarial loss: 0.420189\n",
      "epoch 29; iter: 0; batch classifier loss: 0.167547; batch adversarial loss: 0.411482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139582; batch adversarial loss: 0.455658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.122743; batch adversarial loss: 0.406120\n",
      "epoch 32; iter: 0; batch classifier loss: 0.120173; batch adversarial loss: 0.482376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.123161; batch adversarial loss: 0.441521\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149824; batch adversarial loss: 0.486212\n",
      "epoch 35; iter: 0; batch classifier loss: 0.110133; batch adversarial loss: 0.339536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.104195; batch adversarial loss: 0.497033\n",
      "epoch 37; iter: 0; batch classifier loss: 0.085860; batch adversarial loss: 0.436445\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151067; batch adversarial loss: 0.435595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085141; batch adversarial loss: 0.503429\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095324; batch adversarial loss: 0.497516\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105406; batch adversarial loss: 0.442830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.107233; batch adversarial loss: 0.449707\n",
      "epoch 43; iter: 0; batch classifier loss: 0.088266; batch adversarial loss: 0.462832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.071890; batch adversarial loss: 0.444639\n",
      "epoch 45; iter: 0; batch classifier loss: 0.113981; batch adversarial loss: 0.419448\n",
      "epoch 46; iter: 0; batch classifier loss: 0.156440; batch adversarial loss: 0.476124\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079509; batch adversarial loss: 0.409735\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130476; batch adversarial loss: 0.400801\n",
      "epoch 49; iter: 0; batch classifier loss: 0.077403; batch adversarial loss: 0.399844\n",
      "epoch 50; iter: 0; batch classifier loss: 0.127540; batch adversarial loss: 0.472097\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099082; batch adversarial loss: 0.494993\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100580; batch adversarial loss: 0.539872\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100184; batch adversarial loss: 0.479978\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103275; batch adversarial loss: 0.407895\n",
      "epoch 55; iter: 0; batch classifier loss: 0.054196; batch adversarial loss: 0.480743\n",
      "epoch 56; iter: 0; batch classifier loss: 0.076212; batch adversarial loss: 0.537037\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084051; batch adversarial loss: 0.333765\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090659; batch adversarial loss: 0.380109\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072859; batch adversarial loss: 0.487080\n",
      "epoch 60; iter: 0; batch classifier loss: 0.043115; batch adversarial loss: 0.434677\n",
      "epoch 61; iter: 0; batch classifier loss: 0.072357; batch adversarial loss: 0.643926\n",
      "epoch 62; iter: 0; batch classifier loss: 0.117051; batch adversarial loss: 0.468074\n",
      "epoch 63; iter: 0; batch classifier loss: 0.062076; batch adversarial loss: 0.457686\n",
      "epoch 64; iter: 0; batch classifier loss: 0.096540; batch adversarial loss: 0.389799\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125929; batch adversarial loss: 0.417497\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077806; batch adversarial loss: 0.488686\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095419; batch adversarial loss: 0.460135\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075110; batch adversarial loss: 0.451595\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084517; batch adversarial loss: 0.502261\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097455; batch adversarial loss: 0.379511\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077654; batch adversarial loss: 0.430057\n",
      "epoch 72; iter: 0; batch classifier loss: 0.081231; batch adversarial loss: 0.437302\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130125; batch adversarial loss: 0.346726\n",
      "epoch 74; iter: 0; batch classifier loss: 0.093242; batch adversarial loss: 0.464407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079059; batch adversarial loss: 0.408172\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113025; batch adversarial loss: 0.492870\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111998; batch adversarial loss: 0.427124\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118664; batch adversarial loss: 0.525932\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114518; batch adversarial loss: 0.506574\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090196; batch adversarial loss: 0.367937\n",
      "epoch 81; iter: 0; batch classifier loss: 0.096724; batch adversarial loss: 0.475749\n",
      "epoch 82; iter: 0; batch classifier loss: 0.111176; batch adversarial loss: 0.399090\n",
      "epoch 83; iter: 0; batch classifier loss: 0.089108; batch adversarial loss: 0.458468\n",
      "epoch 84; iter: 0; batch classifier loss: 0.117897; batch adversarial loss: 0.516209\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068134; batch adversarial loss: 0.459015\n",
      "epoch 86; iter: 0; batch classifier loss: 0.090132; batch adversarial loss: 0.484573\n",
      "epoch 87; iter: 0; batch classifier loss: 0.103308; batch adversarial loss: 0.393124\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124143; batch adversarial loss: 0.450231\n",
      "epoch 89; iter: 0; batch classifier loss: 0.091692; batch adversarial loss: 0.442334\n",
      "epoch 90; iter: 0; batch classifier loss: 0.051595; batch adversarial loss: 0.521746\n",
      "epoch 91; iter: 0; batch classifier loss: 0.082423; batch adversarial loss: 0.425566\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070180; batch adversarial loss: 0.396501\n",
      "epoch 93; iter: 0; batch classifier loss: 0.112070; batch adversarial loss: 0.487957\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047582; batch adversarial loss: 0.534740\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090067; batch adversarial loss: 0.493300\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049689; batch adversarial loss: 0.486318\n",
      "epoch 97; iter: 0; batch classifier loss: 0.089066; batch adversarial loss: 0.463308\n",
      "epoch 98; iter: 0; batch classifier loss: 0.079632; batch adversarial loss: 0.370312\n",
      "epoch 99; iter: 0; batch classifier loss: 0.142722; batch adversarial loss: 0.401776\n",
      "epoch 100; iter: 0; batch classifier loss: 0.117241; batch adversarial loss: 0.379646\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081081; batch adversarial loss: 0.470929\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060739; batch adversarial loss: 0.386329\n",
      "epoch 103; iter: 0; batch classifier loss: 0.090756; batch adversarial loss: 0.467107\n",
      "epoch 104; iter: 0; batch classifier loss: 0.062780; batch adversarial loss: 0.322348\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052961; batch adversarial loss: 0.410421\n",
      "epoch 106; iter: 0; batch classifier loss: 0.079010; batch adversarial loss: 0.427276\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079939; batch adversarial loss: 0.469061\n",
      "epoch 108; iter: 0; batch classifier loss: 0.048424; batch adversarial loss: 0.448885\n",
      "epoch 109; iter: 0; batch classifier loss: 0.055147; batch adversarial loss: 0.460520\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057113; batch adversarial loss: 0.447148\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.483508\n",
      "epoch 112; iter: 0; batch classifier loss: 0.051275; batch adversarial loss: 0.380785\n",
      "epoch 113; iter: 0; batch classifier loss: 0.095461; batch adversarial loss: 0.477915\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092361; batch adversarial loss: 0.427768\n",
      "epoch 115; iter: 0; batch classifier loss: 0.046517; batch adversarial loss: 0.408335\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040427; batch adversarial loss: 0.473460\n",
      "epoch 117; iter: 0; batch classifier loss: 0.095160; batch adversarial loss: 0.420751\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039127; batch adversarial loss: 0.521557\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059043; batch adversarial loss: 0.420241\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066884; batch adversarial loss: 0.585127\n",
      "epoch 121; iter: 0; batch classifier loss: 0.084702; batch adversarial loss: 0.442440\n",
      "epoch 122; iter: 0; batch classifier loss: 0.054153; batch adversarial loss: 0.517382\n",
      "epoch 123; iter: 0; batch classifier loss: 0.056480; batch adversarial loss: 0.439519\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029498; batch adversarial loss: 0.375759\n",
      "epoch 125; iter: 0; batch classifier loss: 0.050044; batch adversarial loss: 0.429721\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030764; batch adversarial loss: 0.444165\n",
      "epoch 127; iter: 0; batch classifier loss: 0.045018; batch adversarial loss: 0.436959\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036802; batch adversarial loss: 0.480663\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056173; batch adversarial loss: 0.412316\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022764; batch adversarial loss: 0.450975\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030442; batch adversarial loss: 0.456756\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.391776\n",
      "epoch 133; iter: 0; batch classifier loss: 0.054776; batch adversarial loss: 0.430668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.030679; batch adversarial loss: 0.426603\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061387; batch adversarial loss: 0.405587\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056548; batch adversarial loss: 0.372464\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058175; batch adversarial loss: 0.509895\n",
      "epoch 138; iter: 0; batch classifier loss: 0.024368; batch adversarial loss: 0.498269\n",
      "epoch 139; iter: 0; batch classifier loss: 0.062484; batch adversarial loss: 0.406963\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039005; batch adversarial loss: 0.524052\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030229; batch adversarial loss: 0.409023\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040776; batch adversarial loss: 0.499519\n",
      "epoch 143; iter: 0; batch classifier loss: 0.075637; batch adversarial loss: 0.478517\n",
      "epoch 144; iter: 0; batch classifier loss: 0.042308; batch adversarial loss: 0.409285\n",
      "epoch 145; iter: 0; batch classifier loss: 0.052813; batch adversarial loss: 0.464671\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024335; batch adversarial loss: 0.465147\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027104; batch adversarial loss: 0.505576\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025144; batch adversarial loss: 0.488871\n",
      "epoch 149; iter: 0; batch classifier loss: 0.050014; batch adversarial loss: 0.478387\n",
      "epoch 150; iter: 0; batch classifier loss: 0.056446; batch adversarial loss: 0.433604\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027357; batch adversarial loss: 0.512528\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032053; batch adversarial loss: 0.430346\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031867; batch adversarial loss: 0.415268\n",
      "epoch 154; iter: 0; batch classifier loss: 0.042439; batch adversarial loss: 0.429203\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030474; batch adversarial loss: 0.464634\n",
      "epoch 156; iter: 0; batch classifier loss: 0.052468; batch adversarial loss: 0.500819\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047496; batch adversarial loss: 0.379337\n",
      "epoch 158; iter: 0; batch classifier loss: 0.064999; batch adversarial loss: 0.395914\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031916; batch adversarial loss: 0.360464\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014109; batch adversarial loss: 0.429370\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028974; batch adversarial loss: 0.321263\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046520; batch adversarial loss: 0.429846\n",
      "epoch 163; iter: 0; batch classifier loss: 0.046374; batch adversarial loss: 0.475898\n",
      "epoch 164; iter: 0; batch classifier loss: 0.042829; batch adversarial loss: 0.396993\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026643; batch adversarial loss: 0.411316\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032925; batch adversarial loss: 0.458947\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042268; batch adversarial loss: 0.406297\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028682; batch adversarial loss: 0.423560\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042534; batch adversarial loss: 0.473340\n",
      "epoch 170; iter: 0; batch classifier loss: 0.025453; batch adversarial loss: 0.469661\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012722; batch adversarial loss: 0.419058\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012592; batch adversarial loss: 0.457341\n",
      "epoch 173; iter: 0; batch classifier loss: 0.014301; batch adversarial loss: 0.392671\n",
      "epoch 174; iter: 0; batch classifier loss: 0.065488; batch adversarial loss: 0.516221\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017700; batch adversarial loss: 0.351069\n",
      "epoch 176; iter: 0; batch classifier loss: 0.003119; batch adversarial loss: 0.438431\n",
      "epoch 177; iter: 0; batch classifier loss: 0.036042; batch adversarial loss: 0.408070\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027063; batch adversarial loss: 0.496949\n",
      "epoch 179; iter: 0; batch classifier loss: 0.064102; batch adversarial loss: 0.350654\n",
      "epoch 180; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.469223\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032451; batch adversarial loss: 0.470672\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015593; batch adversarial loss: 0.363248\n",
      "epoch 183; iter: 0; batch classifier loss: 0.035545; batch adversarial loss: 0.411473\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016578; batch adversarial loss: 0.448525\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023746; batch adversarial loss: 0.442539\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014144; batch adversarial loss: 0.420241\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014672; batch adversarial loss: 0.511021\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014018; batch adversarial loss: 0.424297\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006566; batch adversarial loss: 0.399431\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022428; batch adversarial loss: 0.416659\n",
      "epoch 191; iter: 0; batch classifier loss: 0.056472; batch adversarial loss: 0.340869\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022958; batch adversarial loss: 0.379176\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017463; batch adversarial loss: 0.450919\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025565; batch adversarial loss: 0.415540\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015366; batch adversarial loss: 0.430332\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007434; batch adversarial loss: 0.478247\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020962; batch adversarial loss: 0.380617\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016637; batch adversarial loss: 0.397216\n",
      "epoch 199; iter: 0; batch classifier loss: 0.030234; batch adversarial loss: 0.451514\n",
      "epoch 0; iter: 0; batch classifier loss: 0.648164; batch adversarial loss: 0.659734\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456187; batch adversarial loss: 0.656687\n",
      "epoch 2; iter: 0; batch classifier loss: 0.361336; batch adversarial loss: 0.603944\n",
      "epoch 3; iter: 0; batch classifier loss: 0.375340; batch adversarial loss: 0.602588\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298380; batch adversarial loss: 0.596653\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326176; batch adversarial loss: 0.573722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325866; batch adversarial loss: 0.540139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367719; batch adversarial loss: 0.534954\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339450; batch adversarial loss: 0.546987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352420; batch adversarial loss: 0.518221\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350594; batch adversarial loss: 0.530307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539093; batch adversarial loss: 0.570987\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566142; batch adversarial loss: 0.518876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489962; batch adversarial loss: 0.507215\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376197; batch adversarial loss: 0.502563\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287856; batch adversarial loss: 0.504750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285498; batch adversarial loss: 0.479090\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294960; batch adversarial loss: 0.435284\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266498; batch adversarial loss: 0.486344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277288; batch adversarial loss: 0.427816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326943; batch adversarial loss: 0.469457\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258306; batch adversarial loss: 0.425452\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269534; batch adversarial loss: 0.540325\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171672; batch adversarial loss: 0.501149\n",
      "epoch 24; iter: 0; batch classifier loss: 0.188110; batch adversarial loss: 0.461657\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232655; batch adversarial loss: 0.442196\n",
      "epoch 26; iter: 0; batch classifier loss: 0.196104; batch adversarial loss: 0.542509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.212115; batch adversarial loss: 0.463529\n",
      "epoch 28; iter: 0; batch classifier loss: 0.179195; batch adversarial loss: 0.470056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.218668; batch adversarial loss: 0.426826\n",
      "epoch 30; iter: 0; batch classifier loss: 0.196371; batch adversarial loss: 0.349106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.204705; batch adversarial loss: 0.460930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.181035; batch adversarial loss: 0.476850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109042; batch adversarial loss: 0.491482\n",
      "epoch 34; iter: 0; batch classifier loss: 0.206434; batch adversarial loss: 0.499128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.230896; batch adversarial loss: 0.426525\n",
      "epoch 36; iter: 0; batch classifier loss: 0.153701; batch adversarial loss: 0.357519\n",
      "epoch 37; iter: 0; batch classifier loss: 0.137669; batch adversarial loss: 0.413879\n",
      "epoch 38; iter: 0; batch classifier loss: 0.147112; batch adversarial loss: 0.404912\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138572; batch adversarial loss: 0.513277\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150314; batch adversarial loss: 0.439422\n",
      "epoch 41; iter: 0; batch classifier loss: 0.184671; batch adversarial loss: 0.474150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097444; batch adversarial loss: 0.355208\n",
      "epoch 43; iter: 0; batch classifier loss: 0.121639; batch adversarial loss: 0.526168\n",
      "epoch 44; iter: 0; batch classifier loss: 0.099741; batch adversarial loss: 0.374328\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102712; batch adversarial loss: 0.486857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133483; batch adversarial loss: 0.471842\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128961; batch adversarial loss: 0.503645\n",
      "epoch 48; iter: 0; batch classifier loss: 0.129023; batch adversarial loss: 0.596669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.175007; batch adversarial loss: 0.461348\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123054; batch adversarial loss: 0.473003\n",
      "epoch 51; iter: 0; batch classifier loss: 0.124257; batch adversarial loss: 0.434907\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155261; batch adversarial loss: 0.450872\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139436; batch adversarial loss: 0.478352\n",
      "epoch 54; iter: 0; batch classifier loss: 0.136394; batch adversarial loss: 0.483710\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098254; batch adversarial loss: 0.542679\n",
      "epoch 56; iter: 0; batch classifier loss: 0.086278; batch adversarial loss: 0.420226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072555; batch adversarial loss: 0.456237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085086; batch adversarial loss: 0.425762\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141581; batch adversarial loss: 0.392384\n",
      "epoch 60; iter: 0; batch classifier loss: 0.130192; batch adversarial loss: 0.470870\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104986; batch adversarial loss: 0.446072\n",
      "epoch 62; iter: 0; batch classifier loss: 0.113703; batch adversarial loss: 0.477944\n",
      "epoch 63; iter: 0; batch classifier loss: 0.119118; batch adversarial loss: 0.413078\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103181; batch adversarial loss: 0.425113\n",
      "epoch 65; iter: 0; batch classifier loss: 0.113872; batch adversarial loss: 0.440125\n",
      "epoch 66; iter: 0; batch classifier loss: 0.084836; batch adversarial loss: 0.499027\n",
      "epoch 67; iter: 0; batch classifier loss: 0.130502; batch adversarial loss: 0.382328\n",
      "epoch 68; iter: 0; batch classifier loss: 0.082698; batch adversarial loss: 0.509762\n",
      "epoch 69; iter: 0; batch classifier loss: 0.098303; batch adversarial loss: 0.408965\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120655; batch adversarial loss: 0.608327\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103823; batch adversarial loss: 0.371667\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085193; batch adversarial loss: 0.528584\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065150; batch adversarial loss: 0.318803\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066628; batch adversarial loss: 0.377302\n",
      "epoch 75; iter: 0; batch classifier loss: 0.115162; batch adversarial loss: 0.409633\n",
      "epoch 76; iter: 0; batch classifier loss: 0.072793; batch adversarial loss: 0.554583\n",
      "epoch 77; iter: 0; batch classifier loss: 0.111679; batch adversarial loss: 0.538794\n",
      "epoch 78; iter: 0; batch classifier loss: 0.120148; batch adversarial loss: 0.436456\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085241; batch adversarial loss: 0.462346\n",
      "epoch 80; iter: 0; batch classifier loss: 0.106953; batch adversarial loss: 0.545985\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068574; batch adversarial loss: 0.484312\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072483; batch adversarial loss: 0.417822\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081739; batch adversarial loss: 0.427676\n",
      "epoch 84; iter: 0; batch classifier loss: 0.075218; batch adversarial loss: 0.394639\n",
      "epoch 85; iter: 0; batch classifier loss: 0.082594; batch adversarial loss: 0.459068\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073326; batch adversarial loss: 0.496063\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095014; batch adversarial loss: 0.484796\n",
      "epoch 88; iter: 0; batch classifier loss: 0.102454; batch adversarial loss: 0.481394\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046484; batch adversarial loss: 0.428736\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050871; batch adversarial loss: 0.435508\n",
      "epoch 91; iter: 0; batch classifier loss: 0.070421; batch adversarial loss: 0.477868\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048582; batch adversarial loss: 0.406001\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051136; batch adversarial loss: 0.434382\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073202; batch adversarial loss: 0.592212\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051480; batch adversarial loss: 0.497226\n",
      "epoch 96; iter: 0; batch classifier loss: 0.076743; batch adversarial loss: 0.399499\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051407; batch adversarial loss: 0.434104\n",
      "epoch 98; iter: 0; batch classifier loss: 0.032794; batch adversarial loss: 0.373322\n",
      "epoch 99; iter: 0; batch classifier loss: 0.034907; batch adversarial loss: 0.464092\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067856; batch adversarial loss: 0.419032\n",
      "epoch 101; iter: 0; batch classifier loss: 0.030875; batch adversarial loss: 0.461878\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056727; batch adversarial loss: 0.429480\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042831; batch adversarial loss: 0.504830\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041225; batch adversarial loss: 0.340967\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053569; batch adversarial loss: 0.439161\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049765; batch adversarial loss: 0.437517\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046846; batch adversarial loss: 0.424433\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033803; batch adversarial loss: 0.428080\n",
      "epoch 109; iter: 0; batch classifier loss: 0.054228; batch adversarial loss: 0.470999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048609; batch adversarial loss: 0.493585\n",
      "epoch 111; iter: 0; batch classifier loss: 0.070359; batch adversarial loss: 0.472745\n",
      "epoch 112; iter: 0; batch classifier loss: 0.077606; batch adversarial loss: 0.379217\n",
      "epoch 113; iter: 0; batch classifier loss: 0.102263; batch adversarial loss: 0.439636\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032264; batch adversarial loss: 0.475976\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049344; batch adversarial loss: 0.455783\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043290; batch adversarial loss: 0.471837\n",
      "epoch 117; iter: 0; batch classifier loss: 0.053754; batch adversarial loss: 0.474145\n",
      "epoch 118; iter: 0; batch classifier loss: 0.091697; batch adversarial loss: 0.407712\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049017; batch adversarial loss: 0.604312\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024460; batch adversarial loss: 0.493303\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058555; batch adversarial loss: 0.457444\n",
      "epoch 122; iter: 0; batch classifier loss: 0.057609; batch adversarial loss: 0.419341\n",
      "epoch 123; iter: 0; batch classifier loss: 0.069132; batch adversarial loss: 0.502956\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023263; batch adversarial loss: 0.546544\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052224; batch adversarial loss: 0.389854\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030383; batch adversarial loss: 0.503981\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030882; batch adversarial loss: 0.437055\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061777; batch adversarial loss: 0.464970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.042460; batch adversarial loss: 0.467219\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030801; batch adversarial loss: 0.478987\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020234; batch adversarial loss: 0.434413\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029314; batch adversarial loss: 0.356312\n",
      "epoch 133; iter: 0; batch classifier loss: 0.050424; batch adversarial loss: 0.406629\n",
      "epoch 134; iter: 0; batch classifier loss: 0.043916; batch adversarial loss: 0.507456\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037730; batch adversarial loss: 0.509036\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036906; batch adversarial loss: 0.407353\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014185; batch adversarial loss: 0.431908\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035693; batch adversarial loss: 0.541908\n",
      "epoch 139; iter: 0; batch classifier loss: 0.063045; batch adversarial loss: 0.390148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.011604; batch adversarial loss: 0.395366\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039605; batch adversarial loss: 0.408220\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021871; batch adversarial loss: 0.372456\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025962; batch adversarial loss: 0.410074\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033762; batch adversarial loss: 0.366525\n",
      "epoch 145; iter: 0; batch classifier loss: 0.011616; batch adversarial loss: 0.482254\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038850; batch adversarial loss: 0.439418\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022317; batch adversarial loss: 0.461247\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032234; batch adversarial loss: 0.445072\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029789; batch adversarial loss: 0.412584\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019278; batch adversarial loss: 0.405284\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017192; batch adversarial loss: 0.393616\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025649; batch adversarial loss: 0.451841\n",
      "epoch 153; iter: 0; batch classifier loss: 0.044627; batch adversarial loss: 0.505504\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026131; batch adversarial loss: 0.408736\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010876; batch adversarial loss: 0.450673\n",
      "epoch 156; iter: 0; batch classifier loss: 0.010388; batch adversarial loss: 0.367727\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011454; batch adversarial loss: 0.387031\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010254; batch adversarial loss: 0.436488\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029701; batch adversarial loss: 0.478841\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033136; batch adversarial loss: 0.351276\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029677; batch adversarial loss: 0.363451\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017712; batch adversarial loss: 0.397657\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030772; batch adversarial loss: 0.400554\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025260; batch adversarial loss: 0.431509\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010289; batch adversarial loss: 0.360273\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036840; batch adversarial loss: 0.418545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023286; batch adversarial loss: 0.512035\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036093; batch adversarial loss: 0.425923\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015071; batch adversarial loss: 0.485145\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020348; batch adversarial loss: 0.454329\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021464; batch adversarial loss: 0.522929\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024737; batch adversarial loss: 0.422022\n",
      "epoch 173; iter: 0; batch classifier loss: 0.043662; batch adversarial loss: 0.518138\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014075; batch adversarial loss: 0.413764\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047887; batch adversarial loss: 0.430117\n",
      "epoch 176; iter: 0; batch classifier loss: 0.060807; batch adversarial loss: 0.363467\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022173; batch adversarial loss: 0.498786\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021558; batch adversarial loss: 0.444514\n",
      "epoch 179; iter: 0; batch classifier loss: 0.015935; batch adversarial loss: 0.532728\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013753; batch adversarial loss: 0.458370\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024616; batch adversarial loss: 0.431548\n",
      "epoch 182; iter: 0; batch classifier loss: 0.010610; batch adversarial loss: 0.466924\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012348; batch adversarial loss: 0.496614\n",
      "epoch 184; iter: 0; batch classifier loss: 0.008554; batch adversarial loss: 0.497920\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013664; batch adversarial loss: 0.510257\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027309; batch adversarial loss: 0.398109\n",
      "epoch 187; iter: 0; batch classifier loss: 0.009343; batch adversarial loss: 0.502843\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011044; batch adversarial loss: 0.411436\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012354; batch adversarial loss: 0.468979\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024636; batch adversarial loss: 0.426080\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014636; batch adversarial loss: 0.432790\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029535; batch adversarial loss: 0.363849\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017735; batch adversarial loss: 0.483656\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032118; batch adversarial loss: 0.479966\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025707; batch adversarial loss: 0.390631\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012270; batch adversarial loss: 0.491151\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009533; batch adversarial loss: 0.465979\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012070; batch adversarial loss: 0.376881\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020600; batch adversarial loss: 0.502295\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683184; batch adversarial loss: 0.721869\n",
      "epoch 1; iter: 0; batch classifier loss: 0.494533; batch adversarial loss: 0.685233\n",
      "epoch 2; iter: 0; batch classifier loss: 0.380349; batch adversarial loss: 0.677119\n",
      "epoch 3; iter: 0; batch classifier loss: 0.360852; batch adversarial loss: 0.617725\n",
      "epoch 4; iter: 0; batch classifier loss: 0.365625; batch adversarial loss: 0.593226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363559; batch adversarial loss: 0.567424\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310957; batch adversarial loss: 0.553120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344651; batch adversarial loss: 0.472003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.280032; batch adversarial loss: 0.532641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243329; batch adversarial loss: 0.486156\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307743; batch adversarial loss: 0.554590\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300905; batch adversarial loss: 0.426693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244164; batch adversarial loss: 0.461035\n",
      "epoch 13; iter: 0; batch classifier loss: 0.188012; batch adversarial loss: 0.438643\n",
      "epoch 14; iter: 0; batch classifier loss: 0.165129; batch adversarial loss: 0.434907\n",
      "epoch 15; iter: 0; batch classifier loss: 0.165602; batch adversarial loss: 0.450235\n",
      "epoch 16; iter: 0; batch classifier loss: 0.137722; batch adversarial loss: 0.443469\n",
      "epoch 17; iter: 0; batch classifier loss: 0.144644; batch adversarial loss: 0.448402\n",
      "epoch 18; iter: 0; batch classifier loss: 0.191809; batch adversarial loss: 0.489465\n",
      "epoch 19; iter: 0; batch classifier loss: 0.145242; batch adversarial loss: 0.436396\n",
      "epoch 20; iter: 0; batch classifier loss: 0.149945; batch adversarial loss: 0.388950\n",
      "epoch 21; iter: 0; batch classifier loss: 0.106669; batch adversarial loss: 0.513540\n",
      "epoch 22; iter: 0; batch classifier loss: 0.154743; batch adversarial loss: 0.496513\n",
      "epoch 23; iter: 0; batch classifier loss: 0.123722; batch adversarial loss: 0.415027\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138813; batch adversarial loss: 0.508698\n",
      "epoch 25; iter: 0; batch classifier loss: 0.134052; batch adversarial loss: 0.399777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.151901; batch adversarial loss: 0.509173\n",
      "epoch 27; iter: 0; batch classifier loss: 0.103264; batch adversarial loss: 0.517101\n",
      "epoch 28; iter: 0; batch classifier loss: 0.183470; batch adversarial loss: 0.449564\n",
      "epoch 29; iter: 0; batch classifier loss: 0.139151; batch adversarial loss: 0.505063\n",
      "epoch 30; iter: 0; batch classifier loss: 0.184997; batch adversarial loss: 0.481317\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168851; batch adversarial loss: 0.445956\n",
      "epoch 32; iter: 0; batch classifier loss: 0.208319; batch adversarial loss: 0.419314\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167995; batch adversarial loss: 0.546996\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139001; batch adversarial loss: 0.399333\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232218; batch adversarial loss: 0.445294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.199724; batch adversarial loss: 0.553353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130782; batch adversarial loss: 0.475579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228764; batch adversarial loss: 0.429434\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255727; batch adversarial loss: 0.481064\n",
      "epoch 40; iter: 0; batch classifier loss: 0.107041; batch adversarial loss: 0.379472\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119009; batch adversarial loss: 0.516001\n",
      "epoch 42; iter: 0; batch classifier loss: 0.076716; batch adversarial loss: 0.440491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.082429; batch adversarial loss: 0.452803\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085181; batch adversarial loss: 0.416075\n",
      "epoch 45; iter: 0; batch classifier loss: 0.079474; batch adversarial loss: 0.555362\n",
      "epoch 46; iter: 0; batch classifier loss: 0.052301; batch adversarial loss: 0.432677\n",
      "epoch 47; iter: 0; batch classifier loss: 0.074411; batch adversarial loss: 0.464287\n",
      "epoch 48; iter: 0; batch classifier loss: 0.076228; batch adversarial loss: 0.372102\n",
      "epoch 49; iter: 0; batch classifier loss: 0.068667; batch adversarial loss: 0.422331\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083713; batch adversarial loss: 0.451532\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077993; batch adversarial loss: 0.447423\n",
      "epoch 52; iter: 0; batch classifier loss: 0.083585; batch adversarial loss: 0.502699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.047103; batch adversarial loss: 0.395729\n",
      "epoch 54; iter: 0; batch classifier loss: 0.068046; batch adversarial loss: 0.461219\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104453; batch adversarial loss: 0.388614\n",
      "epoch 56; iter: 0; batch classifier loss: 0.078964; batch adversarial loss: 0.360746\n",
      "epoch 57; iter: 0; batch classifier loss: 0.043071; batch adversarial loss: 0.503840\n",
      "epoch 58; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.406843\n",
      "epoch 59; iter: 0; batch classifier loss: 0.048833; batch adversarial loss: 0.455942\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065457; batch adversarial loss: 0.403422\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093264; batch adversarial loss: 0.412217\n",
      "epoch 62; iter: 0; batch classifier loss: 0.134941; batch adversarial loss: 0.483199\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057727; batch adversarial loss: 0.470421\n",
      "epoch 64; iter: 0; batch classifier loss: 0.041181; batch adversarial loss: 0.621049\n",
      "epoch 65; iter: 0; batch classifier loss: 0.098756; batch adversarial loss: 0.421878\n",
      "epoch 66; iter: 0; batch classifier loss: 0.047070; batch adversarial loss: 0.457703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.053106; batch adversarial loss: 0.363698\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066232; batch adversarial loss: 0.415809\n",
      "epoch 69; iter: 0; batch classifier loss: 0.034235; batch adversarial loss: 0.463740\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050492; batch adversarial loss: 0.448903\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064906; batch adversarial loss: 0.457937\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062306; batch adversarial loss: 0.404466\n",
      "epoch 73; iter: 0; batch classifier loss: 0.029166; batch adversarial loss: 0.478230\n",
      "epoch 74; iter: 0; batch classifier loss: 0.028978; batch adversarial loss: 0.392577\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081845; batch adversarial loss: 0.502197\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052803; batch adversarial loss: 0.441688\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057886; batch adversarial loss: 0.493773\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052519; batch adversarial loss: 0.415320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.082603; batch adversarial loss: 0.478904\n",
      "epoch 80; iter: 0; batch classifier loss: 0.065579; batch adversarial loss: 0.482015\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063899; batch adversarial loss: 0.411590\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047619; batch adversarial loss: 0.492726\n",
      "epoch 83; iter: 0; batch classifier loss: 0.082777; batch adversarial loss: 0.463916\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048227; batch adversarial loss: 0.465542\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077176; batch adversarial loss: 0.400880\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091461; batch adversarial loss: 0.482848\n",
      "epoch 87; iter: 0; batch classifier loss: 0.030234; batch adversarial loss: 0.491950\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050880; batch adversarial loss: 0.398879\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034171; batch adversarial loss: 0.419209\n",
      "epoch 90; iter: 0; batch classifier loss: 0.028121; batch adversarial loss: 0.499900\n",
      "epoch 91; iter: 0; batch classifier loss: 0.101286; batch adversarial loss: 0.384585\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057175; batch adversarial loss: 0.337775\n",
      "epoch 93; iter: 0; batch classifier loss: 0.046712; batch adversarial loss: 0.475870\n",
      "epoch 94; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.430725\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042825; batch adversarial loss: 0.449455\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045492; batch adversarial loss: 0.414759\n",
      "epoch 97; iter: 0; batch classifier loss: 0.020800; batch adversarial loss: 0.461709\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035829; batch adversarial loss: 0.405226\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058982; batch adversarial loss: 0.522423\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069072; batch adversarial loss: 0.463793\n",
      "epoch 101; iter: 0; batch classifier loss: 0.052619; batch adversarial loss: 0.461272\n",
      "epoch 102; iter: 0; batch classifier loss: 0.028150; batch adversarial loss: 0.457446\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025512; batch adversarial loss: 0.460714\n",
      "epoch 104; iter: 0; batch classifier loss: 0.025799; batch adversarial loss: 0.464982\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025903; batch adversarial loss: 0.472369\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036781; batch adversarial loss: 0.562184\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038984; batch adversarial loss: 0.485544\n",
      "epoch 108; iter: 0; batch classifier loss: 0.054146; batch adversarial loss: 0.446099\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053459; batch adversarial loss: 0.484520\n",
      "epoch 110; iter: 0; batch classifier loss: 0.042720; batch adversarial loss: 0.471347\n",
      "epoch 111; iter: 0; batch classifier loss: 0.034770; batch adversarial loss: 0.505002\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029142; batch adversarial loss: 0.439496\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051154; batch adversarial loss: 0.466218\n",
      "epoch 114; iter: 0; batch classifier loss: 0.024158; batch adversarial loss: 0.465844\n",
      "epoch 115; iter: 0; batch classifier loss: 0.040637; batch adversarial loss: 0.455589\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025232; batch adversarial loss: 0.484507\n",
      "epoch 117; iter: 0; batch classifier loss: 0.050611; batch adversarial loss: 0.349633\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060631; batch adversarial loss: 0.501460\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057329; batch adversarial loss: 0.434309\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044052; batch adversarial loss: 0.436737\n",
      "epoch 121; iter: 0; batch classifier loss: 0.019827; batch adversarial loss: 0.448334\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.414110\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024524; batch adversarial loss: 0.435502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.024436; batch adversarial loss: 0.452635\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029844; batch adversarial loss: 0.363572\n",
      "epoch 126; iter: 0; batch classifier loss: 0.058235; batch adversarial loss: 0.477455\n",
      "epoch 127; iter: 0; batch classifier loss: 0.027966; batch adversarial loss: 0.532944\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029908; batch adversarial loss: 0.441146\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026667; batch adversarial loss: 0.387793\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038588; batch adversarial loss: 0.441121\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049621; batch adversarial loss: 0.536017\n",
      "epoch 132; iter: 0; batch classifier loss: 0.028222; batch adversarial loss: 0.473510\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024330; batch adversarial loss: 0.384816\n",
      "epoch 134; iter: 0; batch classifier loss: 0.056039; batch adversarial loss: 0.379673\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051468; batch adversarial loss: 0.372625\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011080; batch adversarial loss: 0.420561\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028574; batch adversarial loss: 0.482252\n",
      "epoch 138; iter: 0; batch classifier loss: 0.022861; batch adversarial loss: 0.562548\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049172; batch adversarial loss: 0.403654\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022729; batch adversarial loss: 0.444922\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018100; batch adversarial loss: 0.370563\n",
      "epoch 142; iter: 0; batch classifier loss: 0.040237; batch adversarial loss: 0.407157\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009696; batch adversarial loss: 0.429343\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025024; batch adversarial loss: 0.392686\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044639; batch adversarial loss: 0.566460\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037268; batch adversarial loss: 0.412235\n",
      "epoch 147; iter: 0; batch classifier loss: 0.072333; batch adversarial loss: 0.503237\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040930; batch adversarial loss: 0.524015\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024470; batch adversarial loss: 0.416890\n",
      "epoch 150; iter: 0; batch classifier loss: 0.032445; batch adversarial loss: 0.463349\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029765; batch adversarial loss: 0.390507\n",
      "epoch 152; iter: 0; batch classifier loss: 0.017305; batch adversarial loss: 0.472262\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024785; batch adversarial loss: 0.444758\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020187; batch adversarial loss: 0.357119\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026749; batch adversarial loss: 0.473530\n",
      "epoch 156; iter: 0; batch classifier loss: 0.046459; batch adversarial loss: 0.493580\n",
      "epoch 157; iter: 0; batch classifier loss: 0.049708; batch adversarial loss: 0.445007\n",
      "epoch 158; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.393736\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019988; batch adversarial loss: 0.489990\n",
      "epoch 160; iter: 0; batch classifier loss: 0.018882; batch adversarial loss: 0.459853\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009228; batch adversarial loss: 0.461210\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015161; batch adversarial loss: 0.470906\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010281; batch adversarial loss: 0.461178\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012192; batch adversarial loss: 0.409213\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032623; batch adversarial loss: 0.437431\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024293; batch adversarial loss: 0.475280\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026894; batch adversarial loss: 0.387325\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011623; batch adversarial loss: 0.390403\n",
      "epoch 169; iter: 0; batch classifier loss: 0.022770; batch adversarial loss: 0.446171\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026064; batch adversarial loss: 0.441443\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039370; batch adversarial loss: 0.466517\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016297; batch adversarial loss: 0.418532\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026114; batch adversarial loss: 0.401092\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015845; batch adversarial loss: 0.484279\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008454; batch adversarial loss: 0.434869\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044197; batch adversarial loss: 0.404278\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018666; batch adversarial loss: 0.375347\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028430; batch adversarial loss: 0.486981\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026017; batch adversarial loss: 0.400915\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012455; batch adversarial loss: 0.477383\n",
      "epoch 181; iter: 0; batch classifier loss: 0.004727; batch adversarial loss: 0.482158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.435398\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029524; batch adversarial loss: 0.377591\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026722; batch adversarial loss: 0.458302\n",
      "epoch 185; iter: 0; batch classifier loss: 0.023976; batch adversarial loss: 0.467654\n",
      "epoch 186; iter: 0; batch classifier loss: 0.034970; batch adversarial loss: 0.487608\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006396; batch adversarial loss: 0.363257\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014165; batch adversarial loss: 0.509003\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.371454\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013024; batch adversarial loss: 0.425468\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014111; batch adversarial loss: 0.531371\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016792; batch adversarial loss: 0.369347\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024412; batch adversarial loss: 0.448985\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017402; batch adversarial loss: 0.480416\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014212; batch adversarial loss: 0.469336\n",
      "epoch 196; iter: 0; batch classifier loss: 0.034613; batch adversarial loss: 0.404884\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004868; batch adversarial loss: 0.463372\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014061; batch adversarial loss: 0.474528\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015394; batch adversarial loss: 0.509917\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688978; batch adversarial loss: 0.731229\n",
      "epoch 1; iter: 0; batch classifier loss: 0.548606; batch adversarial loss: 0.697402\n",
      "epoch 2; iter: 0; batch classifier loss: 0.339539; batch adversarial loss: 0.666386\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399266; batch adversarial loss: 0.630091\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352271; batch adversarial loss: 0.593910\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332004; batch adversarial loss: 0.555763\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315585; batch adversarial loss: 0.519191\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309467; batch adversarial loss: 0.513691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.252551; batch adversarial loss: 0.515791\n",
      "epoch 9; iter: 0; batch classifier loss: 0.269929; batch adversarial loss: 0.528358\n",
      "epoch 10; iter: 0; batch classifier loss: 0.236124; batch adversarial loss: 0.492023\n",
      "epoch 11; iter: 0; batch classifier loss: 0.187989; batch adversarial loss: 0.497344\n",
      "epoch 12; iter: 0; batch classifier loss: 0.207282; batch adversarial loss: 0.407672\n",
      "epoch 13; iter: 0; batch classifier loss: 0.202639; batch adversarial loss: 0.477325\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200026; batch adversarial loss: 0.445554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.191677; batch adversarial loss: 0.517241\n",
      "epoch 16; iter: 0; batch classifier loss: 0.172856; batch adversarial loss: 0.492015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.107108; batch adversarial loss: 0.479820\n",
      "epoch 18; iter: 0; batch classifier loss: 0.197823; batch adversarial loss: 0.365167\n",
      "epoch 19; iter: 0; batch classifier loss: 0.133601; batch adversarial loss: 0.460234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.201561; batch adversarial loss: 0.453393\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197125; batch adversarial loss: 0.444752\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218368; batch adversarial loss: 0.486967\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153672; batch adversarial loss: 0.358910\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201377; batch adversarial loss: 0.469743\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158003; batch adversarial loss: 0.422269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.144656; batch adversarial loss: 0.410641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154459; batch adversarial loss: 0.406154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.144077; batch adversarial loss: 0.412755\n",
      "epoch 29; iter: 0; batch classifier loss: 0.188160; batch adversarial loss: 0.386372\n",
      "epoch 30; iter: 0; batch classifier loss: 0.105040; batch adversarial loss: 0.451792\n",
      "epoch 31; iter: 0; batch classifier loss: 0.121538; batch adversarial loss: 0.375784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171287; batch adversarial loss: 0.502967\n",
      "epoch 33; iter: 0; batch classifier loss: 0.131998; batch adversarial loss: 0.391431\n",
      "epoch 34; iter: 0; batch classifier loss: 0.151678; batch adversarial loss: 0.447385\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096563; batch adversarial loss: 0.345672\n",
      "epoch 36; iter: 0; batch classifier loss: 0.163387; batch adversarial loss: 0.410604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105353; batch adversarial loss: 0.377201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.115708; batch adversarial loss: 0.474664\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110731; batch adversarial loss: 0.504544\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096424; batch adversarial loss: 0.374513\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106795; batch adversarial loss: 0.420415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.078729; batch adversarial loss: 0.383456\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089850; batch adversarial loss: 0.413443\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125145; batch adversarial loss: 0.409582\n",
      "epoch 45; iter: 0; batch classifier loss: 0.076354; batch adversarial loss: 0.463345\n",
      "epoch 46; iter: 0; batch classifier loss: 0.060403; batch adversarial loss: 0.344992\n",
      "epoch 47; iter: 0; batch classifier loss: 0.088877; batch adversarial loss: 0.391690\n",
      "epoch 48; iter: 0; batch classifier loss: 0.166145; batch adversarial loss: 0.504117\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098888; batch adversarial loss: 0.430018\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094027; batch adversarial loss: 0.444161\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093395; batch adversarial loss: 0.461234\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113839; batch adversarial loss: 0.419881\n",
      "epoch 53; iter: 0; batch classifier loss: 0.073807; batch adversarial loss: 0.417855\n",
      "epoch 54; iter: 0; batch classifier loss: 0.061585; batch adversarial loss: 0.444320\n",
      "epoch 55; iter: 0; batch classifier loss: 0.064984; batch adversarial loss: 0.493729\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136376; batch adversarial loss: 0.463554\n",
      "epoch 57; iter: 0; batch classifier loss: 0.089173; batch adversarial loss: 0.466897\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099164; batch adversarial loss: 0.461153\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070863; batch adversarial loss: 0.462075\n",
      "epoch 60; iter: 0; batch classifier loss: 0.072775; batch adversarial loss: 0.431273\n",
      "epoch 61; iter: 0; batch classifier loss: 0.119252; batch adversarial loss: 0.376587\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087507; batch adversarial loss: 0.457508\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082154; batch adversarial loss: 0.418270\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090216; batch adversarial loss: 0.372293\n",
      "epoch 65; iter: 0; batch classifier loss: 0.107557; batch adversarial loss: 0.422605\n",
      "epoch 66; iter: 0; batch classifier loss: 0.094310; batch adversarial loss: 0.493392\n",
      "epoch 67; iter: 0; batch classifier loss: 0.077919; batch adversarial loss: 0.458607\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054308; batch adversarial loss: 0.380096\n",
      "epoch 69; iter: 0; batch classifier loss: 0.094290; batch adversarial loss: 0.359891\n",
      "epoch 70; iter: 0; batch classifier loss: 0.098675; batch adversarial loss: 0.393143\n",
      "epoch 71; iter: 0; batch classifier loss: 0.120238; batch adversarial loss: 0.428474\n",
      "epoch 72; iter: 0; batch classifier loss: 0.091151; batch adversarial loss: 0.444212\n",
      "epoch 73; iter: 0; batch classifier loss: 0.117784; batch adversarial loss: 0.398517\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061572; batch adversarial loss: 0.453361\n",
      "epoch 75; iter: 0; batch classifier loss: 0.058829; batch adversarial loss: 0.333935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063716; batch adversarial loss: 0.362355\n",
      "epoch 77; iter: 0; batch classifier loss: 0.064817; batch adversarial loss: 0.412721\n",
      "epoch 78; iter: 0; batch classifier loss: 0.088842; batch adversarial loss: 0.336638\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080826; batch adversarial loss: 0.331495\n",
      "epoch 80; iter: 0; batch classifier loss: 0.048954; batch adversarial loss: 0.425267\n",
      "epoch 81; iter: 0; batch classifier loss: 0.091788; batch adversarial loss: 0.483485\n",
      "epoch 82; iter: 0; batch classifier loss: 0.082732; batch adversarial loss: 0.406444\n",
      "epoch 83; iter: 0; batch classifier loss: 0.085715; batch adversarial loss: 0.423203\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058659; batch adversarial loss: 0.375558\n",
      "epoch 85; iter: 0; batch classifier loss: 0.080948; batch adversarial loss: 0.487850\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050660; batch adversarial loss: 0.407875\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057958; batch adversarial loss: 0.368343\n",
      "epoch 88; iter: 0; batch classifier loss: 0.041003; batch adversarial loss: 0.480297\n",
      "epoch 89; iter: 0; batch classifier loss: 0.042576; batch adversarial loss: 0.453272\n",
      "epoch 90; iter: 0; batch classifier loss: 0.024126; batch adversarial loss: 0.430497\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046559; batch adversarial loss: 0.460593\n",
      "epoch 92; iter: 0; batch classifier loss: 0.076063; batch adversarial loss: 0.437310\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035494; batch adversarial loss: 0.405307\n",
      "epoch 94; iter: 0; batch classifier loss: 0.019592; batch adversarial loss: 0.444702\n",
      "epoch 95; iter: 0; batch classifier loss: 0.048377; batch adversarial loss: 0.437785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.032472; batch adversarial loss: 0.470287\n",
      "epoch 97; iter: 0; batch classifier loss: 0.022949; batch adversarial loss: 0.446440\n",
      "epoch 98; iter: 0; batch classifier loss: 0.026177; batch adversarial loss: 0.391658\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052531; batch adversarial loss: 0.507029\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039607; batch adversarial loss: 0.415118\n",
      "epoch 101; iter: 0; batch classifier loss: 0.019154; batch adversarial loss: 0.531487\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056494; batch adversarial loss: 0.410702\n",
      "epoch 103; iter: 0; batch classifier loss: 0.013537; batch adversarial loss: 0.424428\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031318; batch adversarial loss: 0.473391\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030695; batch adversarial loss: 0.477457\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051423; batch adversarial loss: 0.519348\n",
      "epoch 107; iter: 0; batch classifier loss: 0.014540; batch adversarial loss: 0.451037\n",
      "epoch 108; iter: 0; batch classifier loss: 0.047995; batch adversarial loss: 0.491371\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045394; batch adversarial loss: 0.526108\n",
      "epoch 110; iter: 0; batch classifier loss: 0.153817; batch adversarial loss: 0.714980\n",
      "epoch 111; iter: 0; batch classifier loss: 0.126108; batch adversarial loss: 0.716124\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052746; batch adversarial loss: 0.538577\n",
      "epoch 113; iter: 0; batch classifier loss: 0.144921; batch adversarial loss: 0.643269\n",
      "epoch 114; iter: 0; batch classifier loss: 0.127851; batch adversarial loss: 0.572674\n",
      "epoch 115; iter: 0; batch classifier loss: 0.128709; batch adversarial loss: 0.592896\n",
      "epoch 116; iter: 0; batch classifier loss: 0.177183; batch adversarial loss: 0.613168\n",
      "epoch 117; iter: 0; batch classifier loss: 0.085932; batch adversarial loss: 0.533036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.141592; batch adversarial loss: 0.530253\n",
      "epoch 119; iter: 0; batch classifier loss: 0.157834; batch adversarial loss: 0.606958\n",
      "epoch 120; iter: 0; batch classifier loss: 0.195457; batch adversarial loss: 0.665175\n",
      "epoch 121; iter: 0; batch classifier loss: 0.094577; batch adversarial loss: 0.523604\n",
      "epoch 122; iter: 0; batch classifier loss: 0.110646; batch adversarial loss: 0.567882\n",
      "epoch 123; iter: 0; batch classifier loss: 0.159384; batch adversarial loss: 0.571959\n",
      "epoch 124; iter: 0; batch classifier loss: 0.144685; batch adversarial loss: 0.591191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.138425; batch adversarial loss: 0.578047\n",
      "epoch 126; iter: 0; batch classifier loss: 0.141248; batch adversarial loss: 0.507970\n",
      "epoch 127; iter: 0; batch classifier loss: 0.136962; batch adversarial loss: 0.552883\n",
      "epoch 128; iter: 0; batch classifier loss: 0.165917; batch adversarial loss: 0.553850\n",
      "epoch 129; iter: 0; batch classifier loss: 0.183965; batch adversarial loss: 0.586837\n",
      "epoch 130; iter: 0; batch classifier loss: 0.138563; batch adversarial loss: 0.531268\n",
      "epoch 131; iter: 0; batch classifier loss: 0.143423; batch adversarial loss: 0.583950\n",
      "epoch 132; iter: 0; batch classifier loss: 0.167955; batch adversarial loss: 0.553764\n",
      "epoch 133; iter: 0; batch classifier loss: 0.091511; batch adversarial loss: 0.444045\n",
      "epoch 134; iter: 0; batch classifier loss: 0.095266; batch adversarial loss: 0.495012\n",
      "epoch 135; iter: 0; batch classifier loss: 0.086841; batch adversarial loss: 0.467407\n",
      "epoch 136; iter: 0; batch classifier loss: 0.148029; batch adversarial loss: 0.473842\n",
      "epoch 137; iter: 0; batch classifier loss: 0.133041; batch adversarial loss: 0.489743\n",
      "epoch 138; iter: 0; batch classifier loss: 0.118998; batch adversarial loss: 0.503094\n",
      "epoch 139; iter: 0; batch classifier loss: 0.080747; batch adversarial loss: 0.381462\n",
      "epoch 140; iter: 0; batch classifier loss: 0.120073; batch adversarial loss: 0.438493\n",
      "epoch 141; iter: 0; batch classifier loss: 0.107741; batch adversarial loss: 0.511092\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057470; batch adversarial loss: 0.406970\n",
      "epoch 143; iter: 0; batch classifier loss: 0.130884; batch adversarial loss: 0.502073\n",
      "epoch 144; iter: 0; batch classifier loss: 0.103987; batch adversarial loss: 0.441766\n",
      "epoch 145; iter: 0; batch classifier loss: 0.079896; batch adversarial loss: 0.497975\n",
      "epoch 146; iter: 0; batch classifier loss: 0.095625; batch adversarial loss: 0.399573\n",
      "epoch 147; iter: 0; batch classifier loss: 0.044674; batch adversarial loss: 0.432368\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036366; batch adversarial loss: 0.479618\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012613; batch adversarial loss: 0.435190\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017610; batch adversarial loss: 0.505835\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028621; batch adversarial loss: 0.358954\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.418697\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028498; batch adversarial loss: 0.422814\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027386; batch adversarial loss: 0.533666\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046894; batch adversarial loss: 0.447458\n",
      "epoch 156; iter: 0; batch classifier loss: 0.076977; batch adversarial loss: 0.458309\n",
      "epoch 157; iter: 0; batch classifier loss: 0.021686; batch adversarial loss: 0.536557\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025438; batch adversarial loss: 0.496112\n",
      "epoch 159; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.559599\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038412; batch adversarial loss: 0.548203\n",
      "epoch 161; iter: 0; batch classifier loss: 0.045792; batch adversarial loss: 0.491713\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038662; batch adversarial loss: 0.422369\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030383; batch adversarial loss: 0.428236\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020038; batch adversarial loss: 0.442278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.031052; batch adversarial loss: 0.487328\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029470; batch adversarial loss: 0.549444\n",
      "epoch 167; iter: 0; batch classifier loss: 0.022551; batch adversarial loss: 0.475507\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030884; batch adversarial loss: 0.341071\n",
      "epoch 169; iter: 0; batch classifier loss: 0.073354; batch adversarial loss: 0.397987\n",
      "epoch 170; iter: 0; batch classifier loss: 0.052460; batch adversarial loss: 0.446026\n",
      "epoch 171; iter: 0; batch classifier loss: 0.055645; batch adversarial loss: 0.510999\n",
      "epoch 172; iter: 0; batch classifier loss: 0.086712; batch adversarial loss: 0.483034\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037122; batch adversarial loss: 0.400551\n",
      "epoch 174; iter: 0; batch classifier loss: 0.043418; batch adversarial loss: 0.378786\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039829; batch adversarial loss: 0.505161\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044412; batch adversarial loss: 0.389136\n",
      "epoch 177; iter: 0; batch classifier loss: 0.087606; batch adversarial loss: 0.485225\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050791; batch adversarial loss: 0.523675\n",
      "epoch 179; iter: 0; batch classifier loss: 0.055134; batch adversarial loss: 0.410816\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040594; batch adversarial loss: 0.529481\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043898; batch adversarial loss: 0.430511\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017104; batch adversarial loss: 0.584458\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023496; batch adversarial loss: 0.469210\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.501401\n",
      "epoch 185; iter: 0; batch classifier loss: 0.050565; batch adversarial loss: 0.502030\n",
      "epoch 186; iter: 0; batch classifier loss: 0.042612; batch adversarial loss: 0.398135\n",
      "epoch 187; iter: 0; batch classifier loss: 0.027845; batch adversarial loss: 0.409241\n",
      "epoch 188; iter: 0; batch classifier loss: 0.069657; batch adversarial loss: 0.414525\n",
      "epoch 189; iter: 0; batch classifier loss: 0.042443; batch adversarial loss: 0.440437\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036067; batch adversarial loss: 0.434964\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023520; batch adversarial loss: 0.435943\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033164; batch adversarial loss: 0.363005\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037378; batch adversarial loss: 0.421163\n",
      "epoch 194; iter: 0; batch classifier loss: 0.051388; batch adversarial loss: 0.461443\n",
      "epoch 195; iter: 0; batch classifier loss: 0.059027; batch adversarial loss: 0.497962\n",
      "epoch 196; iter: 0; batch classifier loss: 0.046053; batch adversarial loss: 0.386265\n",
      "epoch 197; iter: 0; batch classifier loss: 0.056773; batch adversarial loss: 0.388326\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039832; batch adversarial loss: 0.473895\n",
      "epoch 199; iter: 0; batch classifier loss: 0.054582; batch adversarial loss: 0.597456\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700420; batch adversarial loss: 0.694208\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460626; batch adversarial loss: 0.651118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431939; batch adversarial loss: 0.625093\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362532; batch adversarial loss: 0.612888\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407264; batch adversarial loss: 0.605795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421737; batch adversarial loss: 0.533149\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323021; batch adversarial loss: 0.577192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401358; batch adversarial loss: 0.545999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.307313; batch adversarial loss: 0.543751\n",
      "epoch 9; iter: 0; batch classifier loss: 0.296355; batch adversarial loss: 0.516548\n",
      "epoch 10; iter: 0; batch classifier loss: 0.275596; batch adversarial loss: 0.533073\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326154; batch adversarial loss: 0.458298\n",
      "epoch 12; iter: 0; batch classifier loss: 0.271843; batch adversarial loss: 0.538634\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284052; batch adversarial loss: 0.497003\n",
      "epoch 14; iter: 0; batch classifier loss: 0.361773; batch adversarial loss: 0.533022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.377265; batch adversarial loss: 0.543196\n",
      "epoch 16; iter: 0; batch classifier loss: 0.310282; batch adversarial loss: 0.482453\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278264; batch adversarial loss: 0.486861\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359281; batch adversarial loss: 0.449644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308399; batch adversarial loss: 0.434668\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356928; batch adversarial loss: 0.508344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271954; batch adversarial loss: 0.446872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303122; batch adversarial loss: 0.493054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259476; batch adversarial loss: 0.508210\n",
      "epoch 24; iter: 0; batch classifier loss: 0.312039; batch adversarial loss: 0.432471\n",
      "epoch 25; iter: 0; batch classifier loss: 0.282645; batch adversarial loss: 0.369195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286978; batch adversarial loss: 0.425682\n",
      "epoch 27; iter: 0; batch classifier loss: 0.271250; batch adversarial loss: 0.415954\n",
      "epoch 28; iter: 0; batch classifier loss: 0.281260; batch adversarial loss: 0.509189\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313084; batch adversarial loss: 0.446224\n",
      "epoch 30; iter: 0; batch classifier loss: 0.258870; batch adversarial loss: 0.521504\n",
      "epoch 31; iter: 0; batch classifier loss: 0.280530; batch adversarial loss: 0.504555\n",
      "epoch 32; iter: 0; batch classifier loss: 0.253509; batch adversarial loss: 0.447327\n",
      "epoch 33; iter: 0; batch classifier loss: 0.288269; batch adversarial loss: 0.410331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.299323; batch adversarial loss: 0.368734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301001; batch adversarial loss: 0.411840\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323968; batch adversarial loss: 0.443694\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273174; batch adversarial loss: 0.368789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.230769; batch adversarial loss: 0.438082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.253695; batch adversarial loss: 0.510574\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344643; batch adversarial loss: 0.436739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.294969; batch adversarial loss: 0.437467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231954; batch adversarial loss: 0.426603\n",
      "epoch 43; iter: 0; batch classifier loss: 0.274348; batch adversarial loss: 0.448857\n",
      "epoch 44; iter: 0; batch classifier loss: 0.297442; batch adversarial loss: 0.365958\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282681; batch adversarial loss: 0.470241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344035; batch adversarial loss: 0.434892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.272886; batch adversarial loss: 0.459252\n",
      "epoch 48; iter: 0; batch classifier loss: 0.157987; batch adversarial loss: 0.470727\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100957; batch adversarial loss: 0.519652\n",
      "epoch 50; iter: 0; batch classifier loss: 0.233256; batch adversarial loss: 0.534792\n",
      "epoch 51; iter: 0; batch classifier loss: 0.287886; batch adversarial loss: 0.471098\n",
      "epoch 52; iter: 0; batch classifier loss: 0.176577; batch adversarial loss: 0.421497\n",
      "epoch 53; iter: 0; batch classifier loss: 0.238432; batch adversarial loss: 0.434094\n",
      "epoch 54; iter: 0; batch classifier loss: 0.120253; batch adversarial loss: 0.421728\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090350; batch adversarial loss: 0.433989\n",
      "epoch 56; iter: 0; batch classifier loss: 0.055784; batch adversarial loss: 0.446478\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072295; batch adversarial loss: 0.557382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066587; batch adversarial loss: 0.440609\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085568; batch adversarial loss: 0.411081\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089907; batch adversarial loss: 0.381226\n",
      "epoch 61; iter: 0; batch classifier loss: 0.062001; batch adversarial loss: 0.374890\n",
      "epoch 62; iter: 0; batch classifier loss: 0.053582; batch adversarial loss: 0.471340\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072874; batch adversarial loss: 0.493403\n",
      "epoch 64; iter: 0; batch classifier loss: 0.044261; batch adversarial loss: 0.457514\n",
      "epoch 65; iter: 0; batch classifier loss: 0.040559; batch adversarial loss: 0.430028\n",
      "epoch 66; iter: 0; batch classifier loss: 0.051379; batch adversarial loss: 0.430072\n",
      "epoch 67; iter: 0; batch classifier loss: 0.067805; batch adversarial loss: 0.471434\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054717; batch adversarial loss: 0.404996\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049830; batch adversarial loss: 0.393959\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053240; batch adversarial loss: 0.380882\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082821; batch adversarial loss: 0.514583\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058714; batch adversarial loss: 0.349709\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081860; batch adversarial loss: 0.380878\n",
      "epoch 74; iter: 0; batch classifier loss: 0.048714; batch adversarial loss: 0.391456\n",
      "epoch 75; iter: 0; batch classifier loss: 0.085222; batch adversarial loss: 0.406312\n",
      "epoch 76; iter: 0; batch classifier loss: 0.058197; batch adversarial loss: 0.408396\n",
      "epoch 77; iter: 0; batch classifier loss: 0.043752; batch adversarial loss: 0.503336\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041831; batch adversarial loss: 0.373153\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060449; batch adversarial loss: 0.374678\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072053; batch adversarial loss: 0.375625\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075937; batch adversarial loss: 0.431495\n",
      "epoch 82; iter: 0; batch classifier loss: 0.038291; batch adversarial loss: 0.331546\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065272; batch adversarial loss: 0.497002\n",
      "epoch 84; iter: 0; batch classifier loss: 0.047500; batch adversarial loss: 0.524026\n",
      "epoch 85; iter: 0; batch classifier loss: 0.032487; batch adversarial loss: 0.388126\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071746; batch adversarial loss: 0.503731\n",
      "epoch 87; iter: 0; batch classifier loss: 0.031757; batch adversarial loss: 0.416099\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067054; batch adversarial loss: 0.423478\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048922; batch adversarial loss: 0.383544\n",
      "epoch 90; iter: 0; batch classifier loss: 0.057441; batch adversarial loss: 0.363546\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068018; batch adversarial loss: 0.481318\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062542; batch adversarial loss: 0.422372\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067993; batch adversarial loss: 0.399988\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047405; batch adversarial loss: 0.438451\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070392; batch adversarial loss: 0.455602\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064896; batch adversarial loss: 0.438796\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046733; batch adversarial loss: 0.456056\n",
      "epoch 98; iter: 0; batch classifier loss: 0.041006; batch adversarial loss: 0.430277\n",
      "epoch 99; iter: 0; batch classifier loss: 0.075460; batch adversarial loss: 0.362632\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075270; batch adversarial loss: 0.466744\n",
      "epoch 101; iter: 0; batch classifier loss: 0.083161; batch adversarial loss: 0.463886\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068819; batch adversarial loss: 0.455662\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066615; batch adversarial loss: 0.359495\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063976; batch adversarial loss: 0.479575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056952; batch adversarial loss: 0.422613\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046799; batch adversarial loss: 0.362409\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038396; batch adversarial loss: 0.424834\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035201; batch adversarial loss: 0.397696\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062511; batch adversarial loss: 0.514246\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033178; batch adversarial loss: 0.440991\n",
      "epoch 111; iter: 0; batch classifier loss: 0.044041; batch adversarial loss: 0.378094\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040442; batch adversarial loss: 0.477344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 113; iter: 0; batch classifier loss: 0.062669; batch adversarial loss: 0.380313\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043361; batch adversarial loss: 0.507531\n",
      "epoch 115; iter: 0; batch classifier loss: 0.066644; batch adversarial loss: 0.481178\n",
      "epoch 116; iter: 0; batch classifier loss: 0.084617; batch adversarial loss: 0.365411\n",
      "epoch 117; iter: 0; batch classifier loss: 0.055253; batch adversarial loss: 0.430465\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081532; batch adversarial loss: 0.527190\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065284; batch adversarial loss: 0.385653\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049675; batch adversarial loss: 0.343759\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071213; batch adversarial loss: 0.421037\n",
      "epoch 122; iter: 0; batch classifier loss: 0.086109; batch adversarial loss: 0.409612\n",
      "epoch 123; iter: 0; batch classifier loss: 0.057849; batch adversarial loss: 0.376652\n",
      "epoch 124; iter: 0; batch classifier loss: 0.074795; batch adversarial loss: 0.443170\n",
      "epoch 125; iter: 0; batch classifier loss: 0.065013; batch adversarial loss: 0.479442\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036342; batch adversarial loss: 0.386366\n",
      "epoch 127; iter: 0; batch classifier loss: 0.087455; batch adversarial loss: 0.486527\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056079; batch adversarial loss: 0.512617\n",
      "epoch 129; iter: 0; batch classifier loss: 0.030495; batch adversarial loss: 0.350894\n",
      "epoch 130; iter: 0; batch classifier loss: 0.078635; batch adversarial loss: 0.384095\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048926; batch adversarial loss: 0.389424\n",
      "epoch 132; iter: 0; batch classifier loss: 0.041455; batch adversarial loss: 0.391444\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060844; batch adversarial loss: 0.524077\n",
      "epoch 134; iter: 0; batch classifier loss: 0.062637; batch adversarial loss: 0.347202\n",
      "epoch 135; iter: 0; batch classifier loss: 0.075326; batch adversarial loss: 0.421845\n",
      "epoch 136; iter: 0; batch classifier loss: 0.051867; batch adversarial loss: 0.397099\n",
      "epoch 137; iter: 0; batch classifier loss: 0.024957; batch adversarial loss: 0.468437\n",
      "epoch 138; iter: 0; batch classifier loss: 0.056296; batch adversarial loss: 0.456889\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065996; batch adversarial loss: 0.430296\n",
      "epoch 140; iter: 0; batch classifier loss: 0.075248; batch adversarial loss: 0.477102\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049236; batch adversarial loss: 0.412555\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050351; batch adversarial loss: 0.338907\n",
      "epoch 143; iter: 0; batch classifier loss: 0.079663; batch adversarial loss: 0.342669\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052251; batch adversarial loss: 0.402125\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046678; batch adversarial loss: 0.417158\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032003; batch adversarial loss: 0.406370\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052821; batch adversarial loss: 0.435237\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059083; batch adversarial loss: 0.357574\n",
      "epoch 149; iter: 0; batch classifier loss: 0.051772; batch adversarial loss: 0.404150\n",
      "epoch 150; iter: 0; batch classifier loss: 0.077769; batch adversarial loss: 0.383391\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041896; batch adversarial loss: 0.376772\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036752; batch adversarial loss: 0.445463\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066544; batch adversarial loss: 0.388709\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059745; batch adversarial loss: 0.444600\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045136; batch adversarial loss: 0.414691\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029615; batch adversarial loss: 0.397016\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034569; batch adversarial loss: 0.427859\n",
      "epoch 158; iter: 0; batch classifier loss: 0.018978; batch adversarial loss: 0.504761\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025586; batch adversarial loss: 0.437720\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052856; batch adversarial loss: 0.410097\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025328; batch adversarial loss: 0.483101\n",
      "epoch 162; iter: 0; batch classifier loss: 0.060825; batch adversarial loss: 0.467818\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052432; batch adversarial loss: 0.406824\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029230; batch adversarial loss: 0.359132\n",
      "epoch 165; iter: 0; batch classifier loss: 0.056200; batch adversarial loss: 0.405439\n",
      "epoch 166; iter: 0; batch classifier loss: 0.048941; batch adversarial loss: 0.362661\n",
      "epoch 167; iter: 0; batch classifier loss: 0.033191; batch adversarial loss: 0.512115\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048694; batch adversarial loss: 0.437156\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021850; batch adversarial loss: 0.399078\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046189; batch adversarial loss: 0.427425\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020714; batch adversarial loss: 0.381337\n",
      "epoch 172; iter: 0; batch classifier loss: 0.042783; batch adversarial loss: 0.371426\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032999; batch adversarial loss: 0.418484\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017451; batch adversarial loss: 0.512533\n",
      "epoch 175; iter: 0; batch classifier loss: 0.027351; batch adversarial loss: 0.594891\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037757; batch adversarial loss: 0.403185\n",
      "epoch 177; iter: 0; batch classifier loss: 0.032938; batch adversarial loss: 0.457444\n",
      "epoch 178; iter: 0; batch classifier loss: 0.028542; batch adversarial loss: 0.475338\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034757; batch adversarial loss: 0.473213\n",
      "epoch 180; iter: 0; batch classifier loss: 0.060586; batch adversarial loss: 0.467147\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022160; batch adversarial loss: 0.406712\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053070; batch adversarial loss: 0.506137\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013480; batch adversarial loss: 0.492680\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039012; batch adversarial loss: 0.408321\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018730; batch adversarial loss: 0.410417\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027980; batch adversarial loss: 0.487670\n",
      "epoch 187; iter: 0; batch classifier loss: 0.055617; batch adversarial loss: 0.424821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028791; batch adversarial loss: 0.478443\n",
      "epoch 189; iter: 0; batch classifier loss: 0.024024; batch adversarial loss: 0.369554\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018659; batch adversarial loss: 0.457362\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033349; batch adversarial loss: 0.447790\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031382; batch adversarial loss: 0.523581\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014348; batch adversarial loss: 0.478641\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013638; batch adversarial loss: 0.384972\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022725; batch adversarial loss: 0.470190\n",
      "epoch 196; iter: 0; batch classifier loss: 0.036014; batch adversarial loss: 0.467847\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034635; batch adversarial loss: 0.378833\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029861; batch adversarial loss: 0.412817\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016214; batch adversarial loss: 0.366836\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679313; batch adversarial loss: 0.790774\n",
      "epoch 1; iter: 0; batch classifier loss: 0.464716; batch adversarial loss: 0.740413\n",
      "epoch 2; iter: 0; batch classifier loss: 0.415876; batch adversarial loss: 0.716860\n",
      "epoch 3; iter: 0; batch classifier loss: 0.325233; batch adversarial loss: 0.672852\n",
      "epoch 4; iter: 0; batch classifier loss: 0.349427; batch adversarial loss: 0.628871\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308412; batch adversarial loss: 0.585635\n",
      "epoch 6; iter: 0; batch classifier loss: 0.318738; batch adversarial loss: 0.597632\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323026; batch adversarial loss: 0.577393\n",
      "epoch 8; iter: 0; batch classifier loss: 0.347102; batch adversarial loss: 0.550976\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280673; batch adversarial loss: 0.503227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.260634; batch adversarial loss: 0.470958\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273189; batch adversarial loss: 0.522947\n",
      "epoch 12; iter: 0; batch classifier loss: 0.254432; batch adversarial loss: 0.453200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245362; batch adversarial loss: 0.470402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261120; batch adversarial loss: 0.450444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.162346; batch adversarial loss: 0.441808\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231479; batch adversarial loss: 0.434747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210338; batch adversarial loss: 0.514276\n",
      "epoch 18; iter: 0; batch classifier loss: 0.192922; batch adversarial loss: 0.457809\n",
      "epoch 19; iter: 0; batch classifier loss: 0.180086; batch adversarial loss: 0.463299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.111626; batch adversarial loss: 0.468516\n",
      "epoch 21; iter: 0; batch classifier loss: 0.174191; batch adversarial loss: 0.413862\n",
      "epoch 22; iter: 0; batch classifier loss: 0.154062; batch adversarial loss: 0.412102\n",
      "epoch 23; iter: 0; batch classifier loss: 0.131676; batch adversarial loss: 0.505011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.146695; batch adversarial loss: 0.452557\n",
      "epoch 25; iter: 0; batch classifier loss: 0.182633; batch adversarial loss: 0.518983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181912; batch adversarial loss: 0.494813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.133928; batch adversarial loss: 0.467738\n",
      "epoch 28; iter: 0; batch classifier loss: 0.137951; batch adversarial loss: 0.437015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153819; batch adversarial loss: 0.460047\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185226; batch adversarial loss: 0.388195\n",
      "epoch 31; iter: 0; batch classifier loss: 0.101611; batch adversarial loss: 0.324628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.143053; batch adversarial loss: 0.496720\n",
      "epoch 33; iter: 0; batch classifier loss: 0.168482; batch adversarial loss: 0.407004\n",
      "epoch 34; iter: 0; batch classifier loss: 0.170799; batch adversarial loss: 0.358743\n",
      "epoch 35; iter: 0; batch classifier loss: 0.146024; batch adversarial loss: 0.388092\n",
      "epoch 36; iter: 0; batch classifier loss: 0.135825; batch adversarial loss: 0.384196\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123875; batch adversarial loss: 0.314159\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119625; batch adversarial loss: 0.388321\n",
      "epoch 39; iter: 0; batch classifier loss: 0.168407; batch adversarial loss: 0.367005\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114599; batch adversarial loss: 0.490444\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125835; batch adversarial loss: 0.481346\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102624; batch adversarial loss: 0.444313\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147075; batch adversarial loss: 0.480077\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125064; batch adversarial loss: 0.473465\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091106; batch adversarial loss: 0.409014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.176062; batch adversarial loss: 0.420568\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112899; batch adversarial loss: 0.408736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088604; batch adversarial loss: 0.429376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.106059; batch adversarial loss: 0.427234\n",
      "epoch 50; iter: 0; batch classifier loss: 0.106711; batch adversarial loss: 0.447836\n",
      "epoch 51; iter: 0; batch classifier loss: 0.107613; batch adversarial loss: 0.386643\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071792; batch adversarial loss: 0.408980\n",
      "epoch 53; iter: 0; batch classifier loss: 0.142405; batch adversarial loss: 0.391230\n",
      "epoch 54; iter: 0; batch classifier loss: 0.087755; batch adversarial loss: 0.417440\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086375; batch adversarial loss: 0.473609\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065434; batch adversarial loss: 0.457655\n",
      "epoch 57; iter: 0; batch classifier loss: 0.133483; batch adversarial loss: 0.427723\n",
      "epoch 58; iter: 0; batch classifier loss: 0.099229; batch adversarial loss: 0.339348\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079881; batch adversarial loss: 0.454588\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076442; batch adversarial loss: 0.442035\n",
      "epoch 61; iter: 0; batch classifier loss: 0.123202; batch adversarial loss: 0.392119\n",
      "epoch 62; iter: 0; batch classifier loss: 0.104869; batch adversarial loss: 0.438599\n",
      "epoch 63; iter: 0; batch classifier loss: 0.133961; batch adversarial loss: 0.499689\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067003; batch adversarial loss: 0.414874\n",
      "epoch 65; iter: 0; batch classifier loss: 0.126993; batch adversarial loss: 0.396782\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092423; batch adversarial loss: 0.438356\n",
      "epoch 67; iter: 0; batch classifier loss: 0.115849; batch adversarial loss: 0.417336\n",
      "epoch 68; iter: 0; batch classifier loss: 0.054948; batch adversarial loss: 0.409434\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082447; batch adversarial loss: 0.353827\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053000; batch adversarial loss: 0.385492\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082897; batch adversarial loss: 0.425703\n",
      "epoch 72; iter: 0; batch classifier loss: 0.072436; batch adversarial loss: 0.422323\n",
      "epoch 73; iter: 0; batch classifier loss: 0.087436; batch adversarial loss: 0.409181\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057704; batch adversarial loss: 0.421221\n",
      "epoch 75; iter: 0; batch classifier loss: 0.038956; batch adversarial loss: 0.384705\n",
      "epoch 76; iter: 0; batch classifier loss: 0.093618; batch adversarial loss: 0.375007\n",
      "epoch 77; iter: 0; batch classifier loss: 0.078450; batch adversarial loss: 0.425194\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061422; batch adversarial loss: 0.579080\n",
      "epoch 79; iter: 0; batch classifier loss: 0.068345; batch adversarial loss: 0.392385\n",
      "epoch 80; iter: 0; batch classifier loss: 0.106181; batch adversarial loss: 0.490004\n",
      "epoch 81; iter: 0; batch classifier loss: 0.048762; batch adversarial loss: 0.470172\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102616; batch adversarial loss: 0.383536\n",
      "epoch 83; iter: 0; batch classifier loss: 0.049262; batch adversarial loss: 0.365662\n",
      "epoch 84; iter: 0; batch classifier loss: 0.057546; batch adversarial loss: 0.428502\n",
      "epoch 85; iter: 0; batch classifier loss: 0.087427; batch adversarial loss: 0.435728\n",
      "epoch 86; iter: 0; batch classifier loss: 0.126640; batch adversarial loss: 0.394307\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092834; batch adversarial loss: 0.404980\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066154; batch adversarial loss: 0.366956\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072474; batch adversarial loss: 0.440601\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060968; batch adversarial loss: 0.417535\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078610; batch adversarial loss: 0.444231\n",
      "epoch 92; iter: 0; batch classifier loss: 0.039194; batch adversarial loss: 0.402302\n",
      "epoch 93; iter: 0; batch classifier loss: 0.057061; batch adversarial loss: 0.447999\n",
      "epoch 94; iter: 0; batch classifier loss: 0.098397; batch adversarial loss: 0.489175\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046016; batch adversarial loss: 0.393246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047653; batch adversarial loss: 0.421766\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078366; batch adversarial loss: 0.420836\n",
      "epoch 98; iter: 0; batch classifier loss: 0.091698; batch adversarial loss: 0.494151\n",
      "epoch 99; iter: 0; batch classifier loss: 0.059083; batch adversarial loss: 0.464416\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047050; batch adversarial loss: 0.453060\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058448; batch adversarial loss: 0.412566\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058101; batch adversarial loss: 0.399911\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077171; batch adversarial loss: 0.375212\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083033; batch adversarial loss: 0.437669\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072086; batch adversarial loss: 0.378240\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053353; batch adversarial loss: 0.436427\n",
      "epoch 107; iter: 0; batch classifier loss: 0.081852; batch adversarial loss: 0.562440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.062734; batch adversarial loss: 0.420351\n",
      "epoch 109; iter: 0; batch classifier loss: 0.095011; batch adversarial loss: 0.425119\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057456; batch adversarial loss: 0.331667\n",
      "epoch 111; iter: 0; batch classifier loss: 0.078574; batch adversarial loss: 0.469377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.117805; batch adversarial loss: 0.460645\n",
      "epoch 113; iter: 0; batch classifier loss: 0.100180; batch adversarial loss: 0.507128\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053004; batch adversarial loss: 0.513572\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050188; batch adversarial loss: 0.458887\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067231; batch adversarial loss: 0.331283\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071628; batch adversarial loss: 0.466375\n",
      "epoch 118; iter: 0; batch classifier loss: 0.063510; batch adversarial loss: 0.471493\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049836; batch adversarial loss: 0.361079\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030500; batch adversarial loss: 0.413770\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051497; batch adversarial loss: 0.504210\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032263; batch adversarial loss: 0.415370\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075457; batch adversarial loss: 0.436324\n",
      "epoch 124; iter: 0; batch classifier loss: 0.042532; batch adversarial loss: 0.404239\n",
      "epoch 125; iter: 0; batch classifier loss: 0.072079; batch adversarial loss: 0.421550\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037252; batch adversarial loss: 0.461425\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067319; batch adversarial loss: 0.432012\n",
      "epoch 128; iter: 0; batch classifier loss: 0.096802; batch adversarial loss: 0.415505\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041612; batch adversarial loss: 0.444843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.072802; batch adversarial loss: 0.457595\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058445; batch adversarial loss: 0.432788\n",
      "epoch 132; iter: 0; batch classifier loss: 0.054601; batch adversarial loss: 0.353121\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055751; batch adversarial loss: 0.478629\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060473; batch adversarial loss: 0.464201\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051438; batch adversarial loss: 0.455322\n",
      "epoch 136; iter: 0; batch classifier loss: 0.042349; batch adversarial loss: 0.417054\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049459; batch adversarial loss: 0.497635\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051705; batch adversarial loss: 0.402583\n",
      "epoch 139; iter: 0; batch classifier loss: 0.054754; batch adversarial loss: 0.390029\n",
      "epoch 140; iter: 0; batch classifier loss: 0.035486; batch adversarial loss: 0.404010\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037467; batch adversarial loss: 0.504063\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035056; batch adversarial loss: 0.439139\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037564; batch adversarial loss: 0.320475\n",
      "epoch 144; iter: 0; batch classifier loss: 0.034475; batch adversarial loss: 0.467281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027570; batch adversarial loss: 0.502463\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043413; batch adversarial loss: 0.419648\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051834; batch adversarial loss: 0.467020\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018969; batch adversarial loss: 0.468213\n",
      "epoch 149; iter: 0; batch classifier loss: 0.061436; batch adversarial loss: 0.348644\n",
      "epoch 150; iter: 0; batch classifier loss: 0.020578; batch adversarial loss: 0.491944\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027933; batch adversarial loss: 0.493986\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029702; batch adversarial loss: 0.410237\n",
      "epoch 153; iter: 0; batch classifier loss: 0.024177; batch adversarial loss: 0.428507\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019125; batch adversarial loss: 0.423386\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045800; batch adversarial loss: 0.544177\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022532; batch adversarial loss: 0.472656\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023246; batch adversarial loss: 0.484416\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.383463\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019970; batch adversarial loss: 0.387834\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063263; batch adversarial loss: 0.624647\n",
      "epoch 161; iter: 0; batch classifier loss: 0.033012; batch adversarial loss: 0.586102\n",
      "epoch 162; iter: 0; batch classifier loss: 0.089406; batch adversarial loss: 0.594978\n",
      "epoch 163; iter: 0; batch classifier loss: 0.079122; batch adversarial loss: 0.673056\n",
      "epoch 164; iter: 0; batch classifier loss: 0.108190; batch adversarial loss: 0.602660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.136642; batch adversarial loss: 0.716194\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049237; batch adversarial loss: 0.502641\n",
      "epoch 167; iter: 0; batch classifier loss: 0.140314; batch adversarial loss: 0.624256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.114867; batch adversarial loss: 0.539570\n",
      "epoch 169; iter: 0; batch classifier loss: 0.204447; batch adversarial loss: 0.677254\n",
      "epoch 170; iter: 0; batch classifier loss: 0.167534; batch adversarial loss: 0.613243\n",
      "epoch 171; iter: 0; batch classifier loss: 0.154023; batch adversarial loss: 0.707528\n",
      "epoch 172; iter: 0; batch classifier loss: 0.243939; batch adversarial loss: 0.856808\n",
      "epoch 173; iter: 0; batch classifier loss: 0.143944; batch adversarial loss: 0.596056\n",
      "epoch 174; iter: 0; batch classifier loss: 0.156157; batch adversarial loss: 0.758463\n",
      "epoch 175; iter: 0; batch classifier loss: 0.133121; batch adversarial loss: 0.594187\n",
      "epoch 176; iter: 0; batch classifier loss: 0.205379; batch adversarial loss: 0.666476\n",
      "epoch 177; iter: 0; batch classifier loss: 0.195572; batch adversarial loss: 0.471474\n",
      "epoch 178; iter: 0; batch classifier loss: 0.213495; batch adversarial loss: 0.741934\n",
      "epoch 179; iter: 0; batch classifier loss: 0.140990; batch adversarial loss: 0.505459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.174157; batch adversarial loss: 0.728458\n",
      "epoch 181; iter: 0; batch classifier loss: 0.176543; batch adversarial loss: 0.624277\n",
      "epoch 182; iter: 0; batch classifier loss: 0.172611; batch adversarial loss: 0.639132\n",
      "epoch 183; iter: 0; batch classifier loss: 0.173953; batch adversarial loss: 0.651938\n",
      "epoch 184; iter: 0; batch classifier loss: 0.112741; batch adversarial loss: 0.599281\n",
      "epoch 185; iter: 0; batch classifier loss: 0.204165; batch adversarial loss: 0.664109\n",
      "epoch 186; iter: 0; batch classifier loss: 0.146111; batch adversarial loss: 0.646287\n",
      "epoch 187; iter: 0; batch classifier loss: 0.135555; batch adversarial loss: 0.487476\n",
      "epoch 188; iter: 0; batch classifier loss: 0.199102; batch adversarial loss: 0.628047\n",
      "epoch 189; iter: 0; batch classifier loss: 0.142229; batch adversarial loss: 0.601473\n",
      "epoch 190; iter: 0; batch classifier loss: 0.139319; batch adversarial loss: 0.479196\n",
      "epoch 191; iter: 0; batch classifier loss: 0.140044; batch adversarial loss: 0.471460\n",
      "epoch 192; iter: 0; batch classifier loss: 0.136512; batch adversarial loss: 0.518982\n",
      "epoch 193; iter: 0; batch classifier loss: 0.103533; batch adversarial loss: 0.468806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.159941; batch adversarial loss: 0.525366\n",
      "epoch 195; iter: 0; batch classifier loss: 0.166533; batch adversarial loss: 0.541123\n",
      "epoch 196; iter: 0; batch classifier loss: 0.113027; batch adversarial loss: 0.518146\n",
      "epoch 197; iter: 0; batch classifier loss: 0.148701; batch adversarial loss: 0.475042\n",
      "epoch 198; iter: 0; batch classifier loss: 0.123930; batch adversarial loss: 0.524103\n",
      "epoch 199; iter: 0; batch classifier loss: 0.120864; batch adversarial loss: 0.456156\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707126; batch adversarial loss: 0.783173\n",
      "epoch 1; iter: 0; batch classifier loss: 0.487892; batch adversarial loss: 0.691023\n",
      "epoch 2; iter: 0; batch classifier loss: 0.501500; batch adversarial loss: 0.660549\n",
      "epoch 3; iter: 0; batch classifier loss: 0.425763; batch adversarial loss: 0.608449\n",
      "epoch 4; iter: 0; batch classifier loss: 0.320605; batch adversarial loss: 0.604551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 0; batch classifier loss: 0.310313; batch adversarial loss: 0.549893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357119; batch adversarial loss: 0.578479\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314350; batch adversarial loss: 0.576755\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303688; batch adversarial loss: 0.533298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.243652; batch adversarial loss: 0.579553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316307; batch adversarial loss: 0.509176\n",
      "epoch 11; iter: 0; batch classifier loss: 0.215751; batch adversarial loss: 0.522385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313868; batch adversarial loss: 0.524568\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291342; batch adversarial loss: 0.488016\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274087; batch adversarial loss: 0.523007\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307513; batch adversarial loss: 0.465893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.204227; batch adversarial loss: 0.521057\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286961; batch adversarial loss: 0.516938\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286988; batch adversarial loss: 0.512275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179084; batch adversarial loss: 0.478946\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220083; batch adversarial loss: 0.471083\n",
      "epoch 21; iter: 0; batch classifier loss: 0.277618; batch adversarial loss: 0.516235\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203837; batch adversarial loss: 0.456525\n",
      "epoch 23; iter: 0; batch classifier loss: 0.259748; batch adversarial loss: 0.467890\n",
      "epoch 24; iter: 0; batch classifier loss: 0.210806; batch adversarial loss: 0.492386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255240; batch adversarial loss: 0.441215\n",
      "epoch 26; iter: 0; batch classifier loss: 0.197077; batch adversarial loss: 0.505337\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226135; batch adversarial loss: 0.585379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.180544; batch adversarial loss: 0.515473\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199648; batch adversarial loss: 0.474445\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275412; batch adversarial loss: 0.518798\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180314; batch adversarial loss: 0.503525\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246183; batch adversarial loss: 0.418973\n",
      "epoch 33; iter: 0; batch classifier loss: 0.212043; batch adversarial loss: 0.435061\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250067; batch adversarial loss: 0.466752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160955; batch adversarial loss: 0.497587\n",
      "epoch 36; iter: 0; batch classifier loss: 0.262918; batch adversarial loss: 0.488758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.196308; batch adversarial loss: 0.481451\n",
      "epoch 38; iter: 0; batch classifier loss: 0.236789; batch adversarial loss: 0.448873\n",
      "epoch 39; iter: 0; batch classifier loss: 0.187792; batch adversarial loss: 0.480199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.266105; batch adversarial loss: 0.473711\n",
      "epoch 41; iter: 0; batch classifier loss: 0.250485; batch adversarial loss: 0.490329\n",
      "epoch 42; iter: 0; batch classifier loss: 0.228345; batch adversarial loss: 0.462538\n",
      "epoch 43; iter: 0; batch classifier loss: 0.187930; batch adversarial loss: 0.477288\n",
      "epoch 44; iter: 0; batch classifier loss: 0.177411; batch adversarial loss: 0.502646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.138063; batch adversarial loss: 0.458760\n",
      "epoch 46; iter: 0; batch classifier loss: 0.162077; batch adversarial loss: 0.428603\n",
      "epoch 47; iter: 0; batch classifier loss: 0.231303; batch adversarial loss: 0.497467\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178706; batch adversarial loss: 0.526147\n",
      "epoch 49; iter: 0; batch classifier loss: 0.221519; batch adversarial loss: 0.488659\n",
      "epoch 50; iter: 0; batch classifier loss: 0.157129; batch adversarial loss: 0.448723\n",
      "epoch 51; iter: 0; batch classifier loss: 0.170304; batch adversarial loss: 0.579767\n",
      "epoch 52; iter: 0; batch classifier loss: 0.233633; batch adversarial loss: 0.453670\n",
      "epoch 53; iter: 0; batch classifier loss: 0.137074; batch adversarial loss: 0.524545\n",
      "epoch 54; iter: 0; batch classifier loss: 0.173524; batch adversarial loss: 0.365981\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085567; batch adversarial loss: 0.473341\n",
      "epoch 56; iter: 0; batch classifier loss: 0.175842; batch adversarial loss: 0.493798\n",
      "epoch 57; iter: 0; batch classifier loss: 0.154437; batch adversarial loss: 0.436079\n",
      "epoch 58; iter: 0; batch classifier loss: 0.136964; batch adversarial loss: 0.476334\n",
      "epoch 59; iter: 0; batch classifier loss: 0.150778; batch adversarial loss: 0.403558\n",
      "epoch 60; iter: 0; batch classifier loss: 0.128342; batch adversarial loss: 0.422018\n",
      "epoch 61; iter: 0; batch classifier loss: 0.127068; batch adversarial loss: 0.478300\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148216; batch adversarial loss: 0.494819\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086095; batch adversarial loss: 0.519675\n",
      "epoch 64; iter: 0; batch classifier loss: 0.182078; batch adversarial loss: 0.454900\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116956; batch adversarial loss: 0.471536\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126942; batch adversarial loss: 0.493545\n",
      "epoch 67; iter: 0; batch classifier loss: 0.102438; batch adversarial loss: 0.471746\n",
      "epoch 68; iter: 0; batch classifier loss: 0.170285; batch adversarial loss: 0.398858\n",
      "epoch 69; iter: 0; batch classifier loss: 0.089630; batch adversarial loss: 0.564332\n",
      "epoch 70; iter: 0; batch classifier loss: 0.123397; batch adversarial loss: 0.384544\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084767; batch adversarial loss: 0.455190\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109120; batch adversarial loss: 0.377396\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116807; batch adversarial loss: 0.453433\n",
      "epoch 74; iter: 0; batch classifier loss: 0.155546; batch adversarial loss: 0.485118\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073697; batch adversarial loss: 0.466630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116041; batch adversarial loss: 0.461413\n",
      "epoch 77; iter: 0; batch classifier loss: 0.057904; batch adversarial loss: 0.510766\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073471; batch adversarial loss: 0.485862\n",
      "epoch 79; iter: 0; batch classifier loss: 0.113632; batch adversarial loss: 0.433237\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100269; batch adversarial loss: 0.500808\n",
      "epoch 81; iter: 0; batch classifier loss: 0.072701; batch adversarial loss: 0.499176\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090474; batch adversarial loss: 0.382725\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076042; batch adversarial loss: 0.443946\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060095; batch adversarial loss: 0.491241\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057340; batch adversarial loss: 0.465028\n",
      "epoch 86; iter: 0; batch classifier loss: 0.038596; batch adversarial loss: 0.535634\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054832; batch adversarial loss: 0.476270\n",
      "epoch 88; iter: 0; batch classifier loss: 0.075194; batch adversarial loss: 0.539765\n",
      "epoch 89; iter: 0; batch classifier loss: 0.047988; batch adversarial loss: 0.483312\n",
      "epoch 90; iter: 0; batch classifier loss: 0.041342; batch adversarial loss: 0.467772\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057601; batch adversarial loss: 0.399980\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063364; batch adversarial loss: 0.419504\n",
      "epoch 93; iter: 0; batch classifier loss: 0.110825; batch adversarial loss: 0.436828\n",
      "epoch 94; iter: 0; batch classifier loss: 0.107005; batch adversarial loss: 0.468563\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066869; batch adversarial loss: 0.371073\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059788; batch adversarial loss: 0.471570\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072523; batch adversarial loss: 0.540139\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048857; batch adversarial loss: 0.428500\n",
      "epoch 99; iter: 0; batch classifier loss: 0.066240; batch adversarial loss: 0.449164\n",
      "epoch 100; iter: 0; batch classifier loss: 0.013470; batch adversarial loss: 0.447643\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046122; batch adversarial loss: 0.420374\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058455; batch adversarial loss: 0.476585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 103; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.473738\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056162; batch adversarial loss: 0.381049\n",
      "epoch 105; iter: 0; batch classifier loss: 0.057707; batch adversarial loss: 0.560529\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033334; batch adversarial loss: 0.451086\n",
      "epoch 107; iter: 0; batch classifier loss: 0.042923; batch adversarial loss: 0.428580\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059508; batch adversarial loss: 0.385452\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041541; batch adversarial loss: 0.421302\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033514; batch adversarial loss: 0.443120\n",
      "epoch 111; iter: 0; batch classifier loss: 0.024509; batch adversarial loss: 0.492679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035360; batch adversarial loss: 0.417031\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033231; batch adversarial loss: 0.385326\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049743; batch adversarial loss: 0.524751\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055131; batch adversarial loss: 0.390826\n",
      "epoch 116; iter: 0; batch classifier loss: 0.016113; batch adversarial loss: 0.399966\n",
      "epoch 117; iter: 0; batch classifier loss: 0.016400; batch adversarial loss: 0.353322\n",
      "epoch 118; iter: 0; batch classifier loss: 0.028487; batch adversarial loss: 0.492806\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022632; batch adversarial loss: 0.533633\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041199; batch adversarial loss: 0.433072\n",
      "epoch 121; iter: 0; batch classifier loss: 0.069222; batch adversarial loss: 0.500215\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041867; batch adversarial loss: 0.482868\n",
      "epoch 123; iter: 0; batch classifier loss: 0.039524; batch adversarial loss: 0.473560\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027928; batch adversarial loss: 0.517469\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040969; batch adversarial loss: 0.444130\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063510; batch adversarial loss: 0.431213\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021523; batch adversarial loss: 0.334467\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019565; batch adversarial loss: 0.449797\n",
      "epoch 129; iter: 0; batch classifier loss: 0.009696; batch adversarial loss: 0.467455\n",
      "epoch 130; iter: 0; batch classifier loss: 0.032093; batch adversarial loss: 0.532521\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039017; batch adversarial loss: 0.520768\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030863; batch adversarial loss: 0.600787\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033661; batch adversarial loss: 0.389887\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045502; batch adversarial loss: 0.512657\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030660; batch adversarial loss: 0.365550\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017810; batch adversarial loss: 0.430072\n",
      "epoch 137; iter: 0; batch classifier loss: 0.011716; batch adversarial loss: 0.497401\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029478; batch adversarial loss: 0.593700\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013328; batch adversarial loss: 0.441616\n",
      "epoch 140; iter: 0; batch classifier loss: 0.044097; batch adversarial loss: 0.478326\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019251; batch adversarial loss: 0.394937\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036279; batch adversarial loss: 0.472098\n",
      "epoch 143; iter: 0; batch classifier loss: 0.021760; batch adversarial loss: 0.473151\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019435; batch adversarial loss: 0.528675\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027358; batch adversarial loss: 0.411161\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011724; batch adversarial loss: 0.456552\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013417; batch adversarial loss: 0.459669\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041556; batch adversarial loss: 0.395028\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020485; batch adversarial loss: 0.438219\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.510042\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023976; batch adversarial loss: 0.439798\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010481; batch adversarial loss: 0.445119\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017923; batch adversarial loss: 0.396515\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014205; batch adversarial loss: 0.506663\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029066; batch adversarial loss: 0.519127\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035081; batch adversarial loss: 0.398640\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006814; batch adversarial loss: 0.518772\n",
      "epoch 158; iter: 0; batch classifier loss: 0.046795; batch adversarial loss: 0.521309\n",
      "epoch 159; iter: 0; batch classifier loss: 0.019803; batch adversarial loss: 0.509957\n",
      "epoch 160; iter: 0; batch classifier loss: 0.026221; batch adversarial loss: 0.453684\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012051; batch adversarial loss: 0.489016\n",
      "epoch 162; iter: 0; batch classifier loss: 0.029065; batch adversarial loss: 0.307756\n",
      "epoch 163; iter: 0; batch classifier loss: 0.021784; batch adversarial loss: 0.413568\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003633; batch adversarial loss: 0.513823\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008202; batch adversarial loss: 0.500678\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010375; batch adversarial loss: 0.465992\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026547; batch adversarial loss: 0.556877\n",
      "epoch 168; iter: 0; batch classifier loss: 0.018637; batch adversarial loss: 0.450308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017486; batch adversarial loss: 0.465936\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032953; batch adversarial loss: 0.427401\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035299; batch adversarial loss: 0.366212\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005156; batch adversarial loss: 0.419172\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020694; batch adversarial loss: 0.460122\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024321; batch adversarial loss: 0.371986\n",
      "epoch 175; iter: 0; batch classifier loss: 0.020656; batch adversarial loss: 0.467502\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015511; batch adversarial loss: 0.380982\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013604; batch adversarial loss: 0.507771\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006973; batch adversarial loss: 0.466908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044179; batch adversarial loss: 0.418671\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040071; batch adversarial loss: 0.383243\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.421294\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007084; batch adversarial loss: 0.451344\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013967; batch adversarial loss: 0.447147\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031170; batch adversarial loss: 0.470399\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018586; batch adversarial loss: 0.449052\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008531; batch adversarial loss: 0.470417\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019330; batch adversarial loss: 0.459246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.019659; batch adversarial loss: 0.553014\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041867; batch adversarial loss: 0.515217\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013054; batch adversarial loss: 0.530751\n",
      "epoch 191; iter: 0; batch classifier loss: 0.033524; batch adversarial loss: 0.365874\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030586; batch adversarial loss: 0.475511\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011784; batch adversarial loss: 0.409278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.008258; batch adversarial loss: 0.450388\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009262; batch adversarial loss: 0.444205\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025121; batch adversarial loss: 0.461359\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023780; batch adversarial loss: 0.504527\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.425197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 199; iter: 0; batch classifier loss: 0.027903; batch adversarial loss: 0.390012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689867; batch adversarial loss: 0.908402\n",
      "epoch 1; iter: 0; batch classifier loss: 0.785301; batch adversarial loss: 1.048346\n",
      "epoch 2; iter: 0; batch classifier loss: 0.862616; batch adversarial loss: 0.946606\n",
      "epoch 3; iter: 0; batch classifier loss: 0.907028; batch adversarial loss: 0.877240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.776466; batch adversarial loss: 0.764752\n",
      "epoch 5; iter: 0; batch classifier loss: 0.843073; batch adversarial loss: 0.774875\n",
      "epoch 6; iter: 0; batch classifier loss: 0.819849; batch adversarial loss: 0.714038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603139; batch adversarial loss: 0.648121\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550934; batch adversarial loss: 0.546722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418999; batch adversarial loss: 0.579903\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339709; batch adversarial loss: 0.559685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.354530; batch adversarial loss: 0.502682\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321983; batch adversarial loss: 0.518173\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276370; batch adversarial loss: 0.480291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279725; batch adversarial loss: 0.578941\n",
      "epoch 15; iter: 0; batch classifier loss: 0.233631; batch adversarial loss: 0.501933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.272009; batch adversarial loss: 0.461981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307020; batch adversarial loss: 0.440639\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271225; batch adversarial loss: 0.413117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.224493; batch adversarial loss: 0.454626\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273221; batch adversarial loss: 0.471216\n",
      "epoch 21; iter: 0; batch classifier loss: 0.231756; batch adversarial loss: 0.442552\n",
      "epoch 22; iter: 0; batch classifier loss: 0.150095; batch adversarial loss: 0.393131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.159020; batch adversarial loss: 0.500842\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189486; batch adversarial loss: 0.442957\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161819; batch adversarial loss: 0.455376\n",
      "epoch 26; iter: 0; batch classifier loss: 0.217500; batch adversarial loss: 0.405383\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210048; batch adversarial loss: 0.479397\n",
      "epoch 28; iter: 0; batch classifier loss: 0.125064; batch adversarial loss: 0.469929\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150866; batch adversarial loss: 0.423999\n",
      "epoch 30; iter: 0; batch classifier loss: 0.145658; batch adversarial loss: 0.402068\n",
      "epoch 31; iter: 0; batch classifier loss: 0.120546; batch adversarial loss: 0.417786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.180948; batch adversarial loss: 0.418654\n",
      "epoch 33; iter: 0; batch classifier loss: 0.197134; batch adversarial loss: 0.440720\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160694; batch adversarial loss: 0.435676\n",
      "epoch 35; iter: 0; batch classifier loss: 0.098010; batch adversarial loss: 0.438453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.186809; batch adversarial loss: 0.368820\n",
      "epoch 37; iter: 0; batch classifier loss: 0.123903; batch adversarial loss: 0.430778\n",
      "epoch 38; iter: 0; batch classifier loss: 0.160927; batch adversarial loss: 0.441783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.135905; batch adversarial loss: 0.597306\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130453; batch adversarial loss: 0.460064\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123763; batch adversarial loss: 0.532610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.109508; batch adversarial loss: 0.536519\n",
      "epoch 43; iter: 0; batch classifier loss: 0.072596; batch adversarial loss: 0.408876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.132200; batch adversarial loss: 0.487718\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086367; batch adversarial loss: 0.449702\n",
      "epoch 46; iter: 0; batch classifier loss: 0.171492; batch adversarial loss: 0.320724\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111020; batch adversarial loss: 0.520085\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125131; batch adversarial loss: 0.511623\n",
      "epoch 49; iter: 0; batch classifier loss: 0.111128; batch adversarial loss: 0.402280\n",
      "epoch 50; iter: 0; batch classifier loss: 0.113925; batch adversarial loss: 0.378042\n",
      "epoch 51; iter: 0; batch classifier loss: 0.085391; batch adversarial loss: 0.483551\n",
      "epoch 52; iter: 0; batch classifier loss: 0.089888; batch adversarial loss: 0.413127\n",
      "epoch 53; iter: 0; batch classifier loss: 0.116688; batch adversarial loss: 0.473830\n",
      "epoch 54; iter: 0; batch classifier loss: 0.142154; batch adversarial loss: 0.422514\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083285; batch adversarial loss: 0.380624\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067829; batch adversarial loss: 0.581739\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141580; batch adversarial loss: 0.479239\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105729; batch adversarial loss: 0.466832\n",
      "epoch 59; iter: 0; batch classifier loss: 0.115382; batch adversarial loss: 0.521144\n",
      "epoch 60; iter: 0; batch classifier loss: 0.083932; batch adversarial loss: 0.452761\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071684; batch adversarial loss: 0.460290\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072677; batch adversarial loss: 0.472712\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060263; batch adversarial loss: 0.351380\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083464; batch adversarial loss: 0.522374\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075107; batch adversarial loss: 0.424814\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071291; batch adversarial loss: 0.466461\n",
      "epoch 67; iter: 0; batch classifier loss: 0.086188; batch adversarial loss: 0.407592\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075363; batch adversarial loss: 0.454814\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049012; batch adversarial loss: 0.491929\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103580; batch adversarial loss: 0.529023\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069222; batch adversarial loss: 0.465127\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074524; batch adversarial loss: 0.426614\n",
      "epoch 73; iter: 0; batch classifier loss: 0.086892; batch adversarial loss: 0.473577\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100962; batch adversarial loss: 0.469763\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056562; batch adversarial loss: 0.507580\n",
      "epoch 76; iter: 0; batch classifier loss: 0.102426; batch adversarial loss: 0.474880\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110705; batch adversarial loss: 0.407997\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128179; batch adversarial loss: 0.402017\n",
      "epoch 79; iter: 0; batch classifier loss: 0.122054; batch adversarial loss: 0.390577\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056991; batch adversarial loss: 0.559386\n",
      "epoch 81; iter: 0; batch classifier loss: 0.058860; batch adversarial loss: 0.401663\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072340; batch adversarial loss: 0.418065\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081427; batch adversarial loss: 0.375438\n",
      "epoch 84; iter: 0; batch classifier loss: 0.043594; batch adversarial loss: 0.468516\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103794; batch adversarial loss: 0.408480\n",
      "epoch 86; iter: 0; batch classifier loss: 0.057358; batch adversarial loss: 0.478067\n",
      "epoch 87; iter: 0; batch classifier loss: 0.099453; batch adversarial loss: 0.497644\n",
      "epoch 88; iter: 0; batch classifier loss: 0.099026; batch adversarial loss: 0.478326\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034918; batch adversarial loss: 0.498575\n",
      "epoch 90; iter: 0; batch classifier loss: 0.110110; batch adversarial loss: 0.483719\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075072; batch adversarial loss: 0.505261\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067302; batch adversarial loss: 0.382255\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070190; batch adversarial loss: 0.405286\n",
      "epoch 94; iter: 0; batch classifier loss: 0.104923; batch adversarial loss: 0.449016\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071362; batch adversarial loss: 0.435169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.062666; batch adversarial loss: 0.465191\n",
      "epoch 97; iter: 0; batch classifier loss: 0.068714; batch adversarial loss: 0.458179\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084264; batch adversarial loss: 0.429078\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052792; batch adversarial loss: 0.472755\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081571; batch adversarial loss: 0.436297\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066585; batch adversarial loss: 0.467891\n",
      "epoch 102; iter: 0; batch classifier loss: 0.070914; batch adversarial loss: 0.358652\n",
      "epoch 103; iter: 0; batch classifier loss: 0.093732; batch adversarial loss: 0.412323\n",
      "epoch 104; iter: 0; batch classifier loss: 0.107535; batch adversarial loss: 0.445894\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093976; batch adversarial loss: 0.459446\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092282; batch adversarial loss: 0.455756\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067959; batch adversarial loss: 0.499962\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028938; batch adversarial loss: 0.432639\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090679; batch adversarial loss: 0.424572\n",
      "epoch 110; iter: 0; batch classifier loss: 0.085443; batch adversarial loss: 0.526545\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047094; batch adversarial loss: 0.485390\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045479; batch adversarial loss: 0.436394\n",
      "epoch 113; iter: 0; batch classifier loss: 0.065013; batch adversarial loss: 0.449156\n",
      "epoch 114; iter: 0; batch classifier loss: 0.028932; batch adversarial loss: 0.424545\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065388; batch adversarial loss: 0.457411\n",
      "epoch 116; iter: 0; batch classifier loss: 0.050628; batch adversarial loss: 0.383221\n",
      "epoch 117; iter: 0; batch classifier loss: 0.073257; batch adversarial loss: 0.452528\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035581; batch adversarial loss: 0.567059\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043052; batch adversarial loss: 0.473634\n",
      "epoch 120; iter: 0; batch classifier loss: 0.065670; batch adversarial loss: 0.414878\n",
      "epoch 121; iter: 0; batch classifier loss: 0.042830; batch adversarial loss: 0.501272\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049269; batch adversarial loss: 0.396061\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063928; batch adversarial loss: 0.382004\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051867; batch adversarial loss: 0.420578\n",
      "epoch 125; iter: 0; batch classifier loss: 0.061735; batch adversarial loss: 0.524373\n",
      "epoch 126; iter: 0; batch classifier loss: 0.060604; batch adversarial loss: 0.401859\n",
      "epoch 127; iter: 0; batch classifier loss: 0.085070; batch adversarial loss: 0.407062\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042202; batch adversarial loss: 0.505926\n",
      "epoch 129; iter: 0; batch classifier loss: 0.082981; batch adversarial loss: 0.387212\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067750; batch adversarial loss: 0.435555\n",
      "epoch 131; iter: 0; batch classifier loss: 0.080068; batch adversarial loss: 0.438119\n",
      "epoch 132; iter: 0; batch classifier loss: 0.066688; batch adversarial loss: 0.414302\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046011; batch adversarial loss: 0.408760\n",
      "epoch 134; iter: 0; batch classifier loss: 0.051692; batch adversarial loss: 0.388550\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029819; batch adversarial loss: 0.501106\n",
      "epoch 136; iter: 0; batch classifier loss: 0.062886; batch adversarial loss: 0.408702\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049022; batch adversarial loss: 0.487293\n",
      "epoch 138; iter: 0; batch classifier loss: 0.077420; batch adversarial loss: 0.449243\n",
      "epoch 139; iter: 0; batch classifier loss: 0.053413; batch adversarial loss: 0.458214\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.495478\n",
      "epoch 141; iter: 0; batch classifier loss: 0.066106; batch adversarial loss: 0.432935\n",
      "epoch 142; iter: 0; batch classifier loss: 0.017655; batch adversarial loss: 0.592255\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028779; batch adversarial loss: 0.472374\n",
      "epoch 144; iter: 0; batch classifier loss: 0.030905; batch adversarial loss: 0.443141\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027694; batch adversarial loss: 0.404551\n",
      "epoch 146; iter: 0; batch classifier loss: 0.034322; batch adversarial loss: 0.396018\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039457; batch adversarial loss: 0.390048\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040149; batch adversarial loss: 0.540703\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039617; batch adversarial loss: 0.429923\n",
      "epoch 150; iter: 0; batch classifier loss: 0.046132; batch adversarial loss: 0.470913\n",
      "epoch 151; iter: 0; batch classifier loss: 0.027266; batch adversarial loss: 0.369624\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027638; batch adversarial loss: 0.488103\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025357; batch adversarial loss: 0.485480\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025488; batch adversarial loss: 0.369684\n",
      "epoch 155; iter: 0; batch classifier loss: 0.045562; batch adversarial loss: 0.461251\n",
      "epoch 156; iter: 0; batch classifier loss: 0.069579; batch adversarial loss: 0.492985\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020938; batch adversarial loss: 0.380887\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033024; batch adversarial loss: 0.448310\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050360; batch adversarial loss: 0.510039\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022405; batch adversarial loss: 0.488223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038312; batch adversarial loss: 0.418387\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028482; batch adversarial loss: 0.472712\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008196; batch adversarial loss: 0.437829\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030843; batch adversarial loss: 0.479723\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024487; batch adversarial loss: 0.471807\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026869; batch adversarial loss: 0.333300\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058817; batch adversarial loss: 0.471491\n",
      "epoch 168; iter: 0; batch classifier loss: 0.017496; batch adversarial loss: 0.483155\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046362; batch adversarial loss: 0.415289\n",
      "epoch 170; iter: 0; batch classifier loss: 0.043344; batch adversarial loss: 0.447634\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012011; batch adversarial loss: 0.450221\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036833; batch adversarial loss: 0.479524\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042674; batch adversarial loss: 0.411383\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011592; batch adversarial loss: 0.472339\n",
      "epoch 175; iter: 0; batch classifier loss: 0.048864; batch adversarial loss: 0.568065\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037046; batch adversarial loss: 0.432735\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031078; batch adversarial loss: 0.526467\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019380; batch adversarial loss: 0.390127\n",
      "epoch 179; iter: 0; batch classifier loss: 0.057467; batch adversarial loss: 0.339219\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033514; batch adversarial loss: 0.432452\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018537; batch adversarial loss: 0.416543\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015922; batch adversarial loss: 0.468785\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009097; batch adversarial loss: 0.518339\n",
      "epoch 184; iter: 0; batch classifier loss: 0.027655; batch adversarial loss: 0.372062\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018339; batch adversarial loss: 0.537446\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022202; batch adversarial loss: 0.406404\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032522; batch adversarial loss: 0.480152\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018700; batch adversarial loss: 0.484500\n",
      "epoch 189; iter: 0; batch classifier loss: 0.008189; batch adversarial loss: 0.414230\n",
      "epoch 190; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.422024\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011326; batch adversarial loss: 0.437704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.020243; batch adversarial loss: 0.400304\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015573; batch adversarial loss: 0.457974\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010399; batch adversarial loss: 0.502750\n",
      "epoch 195; iter: 0; batch classifier loss: 0.007320; batch adversarial loss: 0.400780\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023581; batch adversarial loss: 0.561183\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.494823\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038268; batch adversarial loss: 0.400888\n",
      "epoch 199; iter: 0; batch classifier loss: 0.032319; batch adversarial loss: 0.540622\n",
      "epoch 0; iter: 0; batch classifier loss: 0.716092; batch adversarial loss: 0.621377\n",
      "epoch 1; iter: 0; batch classifier loss: 0.385068; batch adversarial loss: 0.629253\n",
      "epoch 2; iter: 0; batch classifier loss: 0.408156; batch adversarial loss: 0.587710\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348176; batch adversarial loss: 0.570426\n",
      "epoch 4; iter: 0; batch classifier loss: 0.273754; batch adversarial loss: 0.547710\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383766; batch adversarial loss: 0.525480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322577; batch adversarial loss: 0.506289\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318199; batch adversarial loss: 0.487427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.305136; batch adversarial loss: 0.469534\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265587; batch adversarial loss: 0.427431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.237803; batch adversarial loss: 0.504027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.199727; batch adversarial loss: 0.473424\n",
      "epoch 12; iter: 0; batch classifier loss: 0.226518; batch adversarial loss: 0.441874\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250148; batch adversarial loss: 0.557822\n",
      "epoch 14; iter: 0; batch classifier loss: 0.238176; batch adversarial loss: 0.535210\n",
      "epoch 15; iter: 0; batch classifier loss: 0.160459; batch adversarial loss: 0.525004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.163078; batch adversarial loss: 0.492946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.164063; batch adversarial loss: 0.537922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.217970; batch adversarial loss: 0.485769\n",
      "epoch 19; iter: 0; batch classifier loss: 0.169900; batch adversarial loss: 0.553452\n",
      "epoch 20; iter: 0; batch classifier loss: 0.160134; batch adversarial loss: 0.556032\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258902; batch adversarial loss: 0.526108\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288282; batch adversarial loss: 0.580853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.205803; batch adversarial loss: 0.494043\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232159; batch adversarial loss: 0.513204\n",
      "epoch 25; iter: 0; batch classifier loss: 0.264584; batch adversarial loss: 0.486732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.295589; batch adversarial loss: 0.452947\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276353; batch adversarial loss: 0.466982\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369868; batch adversarial loss: 0.473305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.180142; batch adversarial loss: 0.554107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.135208; batch adversarial loss: 0.466842\n",
      "epoch 31; iter: 0; batch classifier loss: 0.117471; batch adversarial loss: 0.499847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.147912; batch adversarial loss: 0.413006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141684; batch adversarial loss: 0.503569\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116253; batch adversarial loss: 0.438813\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096521; batch adversarial loss: 0.398659\n",
      "epoch 36; iter: 0; batch classifier loss: 0.100056; batch adversarial loss: 0.430652\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112558; batch adversarial loss: 0.440059\n",
      "epoch 38; iter: 0; batch classifier loss: 0.118313; batch adversarial loss: 0.468443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.090925; batch adversarial loss: 0.525566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.095573; batch adversarial loss: 0.399450\n",
      "epoch 41; iter: 0; batch classifier loss: 0.123877; batch adversarial loss: 0.458171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.099544; batch adversarial loss: 0.447026\n",
      "epoch 43; iter: 0; batch classifier loss: 0.190354; batch adversarial loss: 0.410530\n",
      "epoch 44; iter: 0; batch classifier loss: 0.095416; batch adversarial loss: 0.432339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081414; batch adversarial loss: 0.501329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.105099; batch adversarial loss: 0.359849\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123552; batch adversarial loss: 0.424884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.095187; batch adversarial loss: 0.438553\n",
      "epoch 49; iter: 0; batch classifier loss: 0.069911; batch adversarial loss: 0.530318\n",
      "epoch 50; iter: 0; batch classifier loss: 0.087497; batch adversarial loss: 0.434281\n",
      "epoch 51; iter: 0; batch classifier loss: 0.101969; batch adversarial loss: 0.479908\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099775; batch adversarial loss: 0.461614\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084196; batch adversarial loss: 0.472743\n",
      "epoch 54; iter: 0; batch classifier loss: 0.082825; batch adversarial loss: 0.417543\n",
      "epoch 55; iter: 0; batch classifier loss: 0.084780; batch adversarial loss: 0.389712\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132121; batch adversarial loss: 0.393931\n",
      "epoch 57; iter: 0; batch classifier loss: 0.111002; batch adversarial loss: 0.439783\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125471; batch adversarial loss: 0.507104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095634; batch adversarial loss: 0.432376\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060757; batch adversarial loss: 0.489128\n",
      "epoch 61; iter: 0; batch classifier loss: 0.125586; batch adversarial loss: 0.424347\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093487; batch adversarial loss: 0.358004\n",
      "epoch 63; iter: 0; batch classifier loss: 0.093323; batch adversarial loss: 0.463121\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105451; batch adversarial loss: 0.462336\n",
      "epoch 65; iter: 0; batch classifier loss: 0.091891; batch adversarial loss: 0.434071\n",
      "epoch 66; iter: 0; batch classifier loss: 0.102340; batch adversarial loss: 0.444356\n",
      "epoch 67; iter: 0; batch classifier loss: 0.069669; batch adversarial loss: 0.446590\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103014; batch adversarial loss: 0.480320\n",
      "epoch 69; iter: 0; batch classifier loss: 0.047839; batch adversarial loss: 0.419382\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091685; batch adversarial loss: 0.512981\n",
      "epoch 71; iter: 0; batch classifier loss: 0.077443; batch adversarial loss: 0.504739\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080053; batch adversarial loss: 0.443307\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067190; batch adversarial loss: 0.476513\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075789; batch adversarial loss: 0.372140\n",
      "epoch 75; iter: 0; batch classifier loss: 0.109611; batch adversarial loss: 0.488309\n",
      "epoch 76; iter: 0; batch classifier loss: 0.138399; batch adversarial loss: 0.445722\n",
      "epoch 77; iter: 0; batch classifier loss: 0.075665; batch adversarial loss: 0.455211\n",
      "epoch 78; iter: 0; batch classifier loss: 0.120698; batch adversarial loss: 0.460466\n",
      "epoch 79; iter: 0; batch classifier loss: 0.109544; batch adversarial loss: 0.454147\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143695; batch adversarial loss: 0.522673\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097259; batch adversarial loss: 0.427897\n",
      "epoch 82; iter: 0; batch classifier loss: 0.075302; batch adversarial loss: 0.442657\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066723; batch adversarial loss: 0.425483\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081824; batch adversarial loss: 0.417095\n",
      "epoch 85; iter: 0; batch classifier loss: 0.046297; batch adversarial loss: 0.553593\n",
      "epoch 86; iter: 0; batch classifier loss: 0.064459; batch adversarial loss: 0.533006\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095682; batch adversarial loss: 0.407510\n",
      "epoch 88; iter: 0; batch classifier loss: 0.116095; batch adversarial loss: 0.425171\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098248; batch adversarial loss: 0.403808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90; iter: 0; batch classifier loss: 0.071459; batch adversarial loss: 0.529402\n",
      "epoch 91; iter: 0; batch classifier loss: 0.058976; batch adversarial loss: 0.470381\n",
      "epoch 92; iter: 0; batch classifier loss: 0.096395; batch adversarial loss: 0.432703\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067015; batch adversarial loss: 0.577183\n",
      "epoch 94; iter: 0; batch classifier loss: 0.051058; batch adversarial loss: 0.469521\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087569; batch adversarial loss: 0.376132\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093091; batch adversarial loss: 0.463169\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072427; batch adversarial loss: 0.575340\n",
      "epoch 98; iter: 0; batch classifier loss: 0.068392; batch adversarial loss: 0.494022\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077803; batch adversarial loss: 0.462434\n",
      "epoch 100; iter: 0; batch classifier loss: 0.080313; batch adversarial loss: 0.460235\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098233; batch adversarial loss: 0.425129\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052947; batch adversarial loss: 0.404582\n",
      "epoch 103; iter: 0; batch classifier loss: 0.099956; batch adversarial loss: 0.394268\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087909; batch adversarial loss: 0.447589\n",
      "epoch 105; iter: 0; batch classifier loss: 0.150917; batch adversarial loss: 0.423658\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071333; batch adversarial loss: 0.458881\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069895; batch adversarial loss: 0.397798\n",
      "epoch 108; iter: 0; batch classifier loss: 0.061942; batch adversarial loss: 0.437615\n",
      "epoch 109; iter: 0; batch classifier loss: 0.043063; batch adversarial loss: 0.450202\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067597; batch adversarial loss: 0.454862\n",
      "epoch 111; iter: 0; batch classifier loss: 0.076743; batch adversarial loss: 0.477411\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046349; batch adversarial loss: 0.441173\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043831; batch adversarial loss: 0.590532\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071129; batch adversarial loss: 0.458904\n",
      "epoch 115; iter: 0; batch classifier loss: 0.081915; batch adversarial loss: 0.402494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034949; batch adversarial loss: 0.481943\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039068; batch adversarial loss: 0.381997\n",
      "epoch 118; iter: 0; batch classifier loss: 0.050323; batch adversarial loss: 0.569131\n",
      "epoch 119; iter: 0; batch classifier loss: 0.065469; batch adversarial loss: 0.407976\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044554; batch adversarial loss: 0.473461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040332; batch adversarial loss: 0.497289\n",
      "epoch 122; iter: 0; batch classifier loss: 0.070388; batch adversarial loss: 0.500649\n",
      "epoch 123; iter: 0; batch classifier loss: 0.054722; batch adversarial loss: 0.399713\n",
      "epoch 124; iter: 0; batch classifier loss: 0.024465; batch adversarial loss: 0.527014\n",
      "epoch 125; iter: 0; batch classifier loss: 0.069355; batch adversarial loss: 0.444988\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026666; batch adversarial loss: 0.405173\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024493; batch adversarial loss: 0.503789\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039764; batch adversarial loss: 0.573938\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033247; batch adversarial loss: 0.402592\n",
      "epoch 130; iter: 0; batch classifier loss: 0.055897; batch adversarial loss: 0.515099\n",
      "epoch 131; iter: 0; batch classifier loss: 0.030084; batch adversarial loss: 0.459390\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035602; batch adversarial loss: 0.414950\n",
      "epoch 133; iter: 0; batch classifier loss: 0.071139; batch adversarial loss: 0.460183\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030633; batch adversarial loss: 0.391557\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032229; batch adversarial loss: 0.447559\n",
      "epoch 136; iter: 0; batch classifier loss: 0.023615; batch adversarial loss: 0.349230\n",
      "epoch 137; iter: 0; batch classifier loss: 0.052977; batch adversarial loss: 0.396884\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046028; batch adversarial loss: 0.445383\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019989; batch adversarial loss: 0.339878\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043741; batch adversarial loss: 0.423899\n",
      "epoch 141; iter: 0; batch classifier loss: 0.050483; batch adversarial loss: 0.480161\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035846; batch adversarial loss: 0.512412\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035443; batch adversarial loss: 0.455643\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033399; batch adversarial loss: 0.488834\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023127; batch adversarial loss: 0.448640\n",
      "epoch 146; iter: 0; batch classifier loss: 0.032461; batch adversarial loss: 0.361036\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041791; batch adversarial loss: 0.512004\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017615; batch adversarial loss: 0.447179\n",
      "epoch 149; iter: 0; batch classifier loss: 0.061336; batch adversarial loss: 0.502622\n",
      "epoch 150; iter: 0; batch classifier loss: 0.017583; batch adversarial loss: 0.522682\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037643; batch adversarial loss: 0.475996\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015173; batch adversarial loss: 0.417067\n",
      "epoch 153; iter: 0; batch classifier loss: 0.014706; batch adversarial loss: 0.453914\n",
      "epoch 154; iter: 0; batch classifier loss: 0.068806; batch adversarial loss: 0.498385\n",
      "epoch 155; iter: 0; batch classifier loss: 0.048744; batch adversarial loss: 0.474561\n",
      "epoch 156; iter: 0; batch classifier loss: 0.047642; batch adversarial loss: 0.407506\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037689; batch adversarial loss: 0.444614\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027217; batch adversarial loss: 0.420233\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045698; batch adversarial loss: 0.444697\n",
      "epoch 160; iter: 0; batch classifier loss: 0.039502; batch adversarial loss: 0.397182\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012273; batch adversarial loss: 0.546323\n",
      "epoch 162; iter: 0; batch classifier loss: 0.059024; batch adversarial loss: 0.547731\n",
      "epoch 163; iter: 0; batch classifier loss: 0.058048; batch adversarial loss: 0.490136\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038000; batch adversarial loss: 0.380185\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024003; batch adversarial loss: 0.434754\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022006; batch adversarial loss: 0.475245\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049788; batch adversarial loss: 0.391805\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025320; batch adversarial loss: 0.504480\n",
      "epoch 169; iter: 0; batch classifier loss: 0.028412; batch adversarial loss: 0.531415\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020181; batch adversarial loss: 0.408773\n",
      "epoch 171; iter: 0; batch classifier loss: 0.009151; batch adversarial loss: 0.420855\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026945; batch adversarial loss: 0.345974\n",
      "epoch 173; iter: 0; batch classifier loss: 0.054489; batch adversarial loss: 0.416168\n",
      "epoch 174; iter: 0; batch classifier loss: 0.044322; batch adversarial loss: 0.484621\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041237; batch adversarial loss: 0.475989\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045426; batch adversarial loss: 0.498056\n",
      "epoch 177; iter: 0; batch classifier loss: 0.035856; batch adversarial loss: 0.561834\n",
      "epoch 178; iter: 0; batch classifier loss: 0.046317; batch adversarial loss: 0.478143\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016569; batch adversarial loss: 0.485023\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030866; batch adversarial loss: 0.418213\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009239; batch adversarial loss: 0.510982\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020963; batch adversarial loss: 0.444331\n",
      "epoch 183; iter: 0; batch classifier loss: 0.047054; batch adversarial loss: 0.440477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039885; batch adversarial loss: 0.419066\n",
      "epoch 185; iter: 0; batch classifier loss: 0.047534; batch adversarial loss: 0.440369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186; iter: 0; batch classifier loss: 0.029329; batch adversarial loss: 0.409948\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005558; batch adversarial loss: 0.408857\n",
      "epoch 188; iter: 0; batch classifier loss: 0.015826; batch adversarial loss: 0.481684\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034053; batch adversarial loss: 0.459354\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032613; batch adversarial loss: 0.429103\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032533; batch adversarial loss: 0.426401\n",
      "epoch 192; iter: 0; batch classifier loss: 0.056944; batch adversarial loss: 0.436574\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011797; batch adversarial loss: 0.456379\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034806; batch adversarial loss: 0.448985\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015532; batch adversarial loss: 0.523760\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019191; batch adversarial loss: 0.449158\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023263; batch adversarial loss: 0.411759\n",
      "epoch 198; iter: 0; batch classifier loss: 0.014064; batch adversarial loss: 0.445005\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019121; batch adversarial loss: 0.454831\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691165; batch adversarial loss: 0.640284\n",
      "epoch 1; iter: 0; batch classifier loss: 0.441062; batch adversarial loss: 0.635613\n",
      "epoch 2; iter: 0; batch classifier loss: 0.379078; batch adversarial loss: 0.610148\n",
      "epoch 3; iter: 0; batch classifier loss: 0.371534; batch adversarial loss: 0.574016\n",
      "epoch 4; iter: 0; batch classifier loss: 0.376869; batch adversarial loss: 0.563480\n",
      "epoch 5; iter: 0; batch classifier loss: 0.312932; batch adversarial loss: 0.542643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296508; batch adversarial loss: 0.502607\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385728; batch adversarial loss: 0.506859\n",
      "epoch 8; iter: 0; batch classifier loss: 0.210963; batch adversarial loss: 0.474606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.263549; batch adversarial loss: 0.520946\n",
      "epoch 10; iter: 0; batch classifier loss: 0.232632; batch adversarial loss: 0.482058\n",
      "epoch 11; iter: 0; batch classifier loss: 0.187028; batch adversarial loss: 0.525844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256259; batch adversarial loss: 0.529532\n",
      "epoch 13; iter: 0; batch classifier loss: 0.222597; batch adversarial loss: 0.524695\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251435; batch adversarial loss: 0.480328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235709; batch adversarial loss: 0.521221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.231347; batch adversarial loss: 0.550783\n",
      "epoch 17; iter: 0; batch classifier loss: 0.232658; batch adversarial loss: 0.521042\n",
      "epoch 18; iter: 0; batch classifier loss: 0.201476; batch adversarial loss: 0.491604\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243240; batch adversarial loss: 0.610638\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269163; batch adversarial loss: 0.578065\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252604; batch adversarial loss: 0.385516\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250440; batch adversarial loss: 0.522514\n",
      "epoch 23; iter: 0; batch classifier loss: 0.234002; batch adversarial loss: 0.498134\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306746; batch adversarial loss: 0.426018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.317107; batch adversarial loss: 0.537870\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255474; batch adversarial loss: 0.483991\n",
      "epoch 27; iter: 0; batch classifier loss: 0.220196; batch adversarial loss: 0.467484\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135319; batch adversarial loss: 0.450132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164190; batch adversarial loss: 0.449124\n",
      "epoch 30; iter: 0; batch classifier loss: 0.136273; batch adversarial loss: 0.428812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.108009; batch adversarial loss: 0.513810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.083414; batch adversarial loss: 0.525334\n",
      "epoch 33; iter: 0; batch classifier loss: 0.105171; batch adversarial loss: 0.507817\n",
      "epoch 34; iter: 0; batch classifier loss: 0.092802; batch adversarial loss: 0.511016\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156649; batch adversarial loss: 0.469969\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126829; batch adversarial loss: 0.424956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.112360; batch adversarial loss: 0.413745\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136107; batch adversarial loss: 0.429347\n",
      "epoch 39; iter: 0; batch classifier loss: 0.120787; batch adversarial loss: 0.503736\n",
      "epoch 40; iter: 0; batch classifier loss: 0.061899; batch adversarial loss: 0.481010\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087029; batch adversarial loss: 0.478920\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091393; batch adversarial loss: 0.409124\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103486; batch adversarial loss: 0.457536\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100004; batch adversarial loss: 0.521531\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099863; batch adversarial loss: 0.441985\n",
      "epoch 46; iter: 0; batch classifier loss: 0.128705; batch adversarial loss: 0.420909\n",
      "epoch 47; iter: 0; batch classifier loss: 0.089589; batch adversarial loss: 0.405105\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106958; batch adversarial loss: 0.492937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.091256; batch adversarial loss: 0.435276\n",
      "epoch 50; iter: 0; batch classifier loss: 0.076764; batch adversarial loss: 0.481921\n",
      "epoch 51; iter: 0; batch classifier loss: 0.054997; batch adversarial loss: 0.491206\n",
      "epoch 52; iter: 0; batch classifier loss: 0.127233; batch adversarial loss: 0.457835\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089155; batch adversarial loss: 0.517255\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096040; batch adversarial loss: 0.331838\n",
      "epoch 55; iter: 0; batch classifier loss: 0.104448; batch adversarial loss: 0.465517\n",
      "epoch 56; iter: 0; batch classifier loss: 0.072389; batch adversarial loss: 0.404003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.098389; batch adversarial loss: 0.509804\n",
      "epoch 58; iter: 0; batch classifier loss: 0.062354; batch adversarial loss: 0.473052\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081987; batch adversarial loss: 0.493066\n",
      "epoch 60; iter: 0; batch classifier loss: 0.081662; batch adversarial loss: 0.487123\n",
      "epoch 61; iter: 0; batch classifier loss: 0.069673; batch adversarial loss: 0.500963\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077132; batch adversarial loss: 0.432471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.073883; batch adversarial loss: 0.425056\n",
      "epoch 64; iter: 0; batch classifier loss: 0.090010; batch adversarial loss: 0.401634\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097574; batch adversarial loss: 0.519457\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058473; batch adversarial loss: 0.443862\n",
      "epoch 67; iter: 0; batch classifier loss: 0.176866; batch adversarial loss: 0.418148\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045440; batch adversarial loss: 0.419324\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070329; batch adversarial loss: 0.510834\n",
      "epoch 70; iter: 0; batch classifier loss: 0.050335; batch adversarial loss: 0.476927\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081199; batch adversarial loss: 0.507745\n",
      "epoch 72; iter: 0; batch classifier loss: 0.073642; batch adversarial loss: 0.460222\n",
      "epoch 73; iter: 0; batch classifier loss: 0.068066; batch adversarial loss: 0.504099\n",
      "epoch 74; iter: 0; batch classifier loss: 0.074865; batch adversarial loss: 0.360755\n",
      "epoch 75; iter: 0; batch classifier loss: 0.086503; batch adversarial loss: 0.417339\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063153; batch adversarial loss: 0.351402\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069835; batch adversarial loss: 0.458319\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105360; batch adversarial loss: 0.396762\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065597; batch adversarial loss: 0.479078\n",
      "epoch 80; iter: 0; batch classifier loss: 0.086495; batch adversarial loss: 0.535147\n",
      "epoch 81; iter: 0; batch classifier loss: 0.063715; batch adversarial loss: 0.456744\n",
      "epoch 82; iter: 0; batch classifier loss: 0.061750; batch adversarial loss: 0.553121\n",
      "epoch 83; iter: 0; batch classifier loss: 0.035721; batch adversarial loss: 0.426482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84; iter: 0; batch classifier loss: 0.034431; batch adversarial loss: 0.511167\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072960; batch adversarial loss: 0.513220\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084309; batch adversarial loss: 0.470205\n",
      "epoch 87; iter: 0; batch classifier loss: 0.097085; batch adversarial loss: 0.551516\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047705; batch adversarial loss: 0.449177\n",
      "epoch 89; iter: 0; batch classifier loss: 0.046826; batch adversarial loss: 0.473914\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083089; batch adversarial loss: 0.430315\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057924; batch adversarial loss: 0.502182\n",
      "epoch 92; iter: 0; batch classifier loss: 0.026741; batch adversarial loss: 0.528566\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077504; batch adversarial loss: 0.483717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.061963; batch adversarial loss: 0.470730\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077499; batch adversarial loss: 0.509810\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062796; batch adversarial loss: 0.524514\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080370; batch adversarial loss: 0.447091\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058997; batch adversarial loss: 0.331138\n",
      "epoch 99; iter: 0; batch classifier loss: 0.057931; batch adversarial loss: 0.427930\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024052; batch adversarial loss: 0.382267\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062795; batch adversarial loss: 0.412776\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068934; batch adversarial loss: 0.419648\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052026; batch adversarial loss: 0.362231\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032684; batch adversarial loss: 0.413677\n",
      "epoch 105; iter: 0; batch classifier loss: 0.077029; batch adversarial loss: 0.491278\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068929; batch adversarial loss: 0.501262\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060534; batch adversarial loss: 0.431879\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065467; batch adversarial loss: 0.377937\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044859; batch adversarial loss: 0.416888\n",
      "epoch 110; iter: 0; batch classifier loss: 0.022320; batch adversarial loss: 0.442346\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033420; batch adversarial loss: 0.471078\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066042; batch adversarial loss: 0.377985\n",
      "epoch 113; iter: 0; batch classifier loss: 0.056764; batch adversarial loss: 0.476918\n",
      "epoch 114; iter: 0; batch classifier loss: 0.059645; batch adversarial loss: 0.362270\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050302; batch adversarial loss: 0.373742\n",
      "epoch 116; iter: 0; batch classifier loss: 0.057276; batch adversarial loss: 0.491059\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049748; batch adversarial loss: 0.452330\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060562; batch adversarial loss: 0.421476\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022772; batch adversarial loss: 0.502253\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040552; batch adversarial loss: 0.431838\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036296; batch adversarial loss: 0.564980\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040579; batch adversarial loss: 0.420725\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035076; batch adversarial loss: 0.488516\n",
      "epoch 124; iter: 0; batch classifier loss: 0.033434; batch adversarial loss: 0.454739\n",
      "epoch 125; iter: 0; batch classifier loss: 0.038280; batch adversarial loss: 0.479230\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030682; batch adversarial loss: 0.489654\n",
      "epoch 127; iter: 0; batch classifier loss: 0.040731; batch adversarial loss: 0.466872\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037422; batch adversarial loss: 0.470956\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019084; batch adversarial loss: 0.521122\n",
      "epoch 130; iter: 0; batch classifier loss: 0.043920; batch adversarial loss: 0.472048\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017878; batch adversarial loss: 0.445004\n",
      "epoch 132; iter: 0; batch classifier loss: 0.033699; batch adversarial loss: 0.538847\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059831; batch adversarial loss: 0.443424\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031723; batch adversarial loss: 0.498131\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024404; batch adversarial loss: 0.490134\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025147; batch adversarial loss: 0.442879\n",
      "epoch 137; iter: 0; batch classifier loss: 0.080609; batch adversarial loss: 0.392673\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031051; batch adversarial loss: 0.524888\n",
      "epoch 139; iter: 0; batch classifier loss: 0.088863; batch adversarial loss: 0.415444\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046991; batch adversarial loss: 0.415003\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036114; batch adversarial loss: 0.463477\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034790; batch adversarial loss: 0.413073\n",
      "epoch 143; iter: 0; batch classifier loss: 0.060799; batch adversarial loss: 0.438619\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026553; batch adversarial loss: 0.399469\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018515; batch adversarial loss: 0.556175\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039645; batch adversarial loss: 0.512290\n",
      "epoch 147; iter: 0; batch classifier loss: 0.094854; batch adversarial loss: 0.448105\n",
      "epoch 148; iter: 0; batch classifier loss: 0.032562; batch adversarial loss: 0.534930\n",
      "epoch 149; iter: 0; batch classifier loss: 0.019958; batch adversarial loss: 0.462430\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019734; batch adversarial loss: 0.560450\n",
      "epoch 151; iter: 0; batch classifier loss: 0.035635; batch adversarial loss: 0.450275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037077; batch adversarial loss: 0.476187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027371; batch adversarial loss: 0.448116\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011272; batch adversarial loss: 0.461480\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057091; batch adversarial loss: 0.436187\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015020; batch adversarial loss: 0.448183\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036906; batch adversarial loss: 0.439437\n",
      "epoch 158; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.450850\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017460; batch adversarial loss: 0.405779\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047303; batch adversarial loss: 0.419785\n",
      "epoch 161; iter: 0; batch classifier loss: 0.061566; batch adversarial loss: 0.494020\n",
      "epoch 162; iter: 0; batch classifier loss: 0.017013; batch adversarial loss: 0.489746\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007736; batch adversarial loss: 0.393899\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019944; batch adversarial loss: 0.522387\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017102; batch adversarial loss: 0.435070\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021162; batch adversarial loss: 0.464635\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013778; batch adversarial loss: 0.395576\n",
      "epoch 168; iter: 0; batch classifier loss: 0.009602; batch adversarial loss: 0.468385\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038293; batch adversarial loss: 0.423724\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048238; batch adversarial loss: 0.443309\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017739; batch adversarial loss: 0.518873\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027320; batch adversarial loss: 0.441369\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021962; batch adversarial loss: 0.528078\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037848; batch adversarial loss: 0.439352\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026041; batch adversarial loss: 0.517115\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027045; batch adversarial loss: 0.495668\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029849; batch adversarial loss: 0.515730\n",
      "epoch 178; iter: 0; batch classifier loss: 0.027766; batch adversarial loss: 0.472371\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040919; batch adversarial loss: 0.533334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 180; iter: 0; batch classifier loss: 0.037075; batch adversarial loss: 0.456276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034367; batch adversarial loss: 0.416113\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036448; batch adversarial loss: 0.527162\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010419; batch adversarial loss: 0.432543\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044359; batch adversarial loss: 0.392203\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042131; batch adversarial loss: 0.416118\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015579; batch adversarial loss: 0.479196\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042589; batch adversarial loss: 0.511243\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033678; batch adversarial loss: 0.510993\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013443; batch adversarial loss: 0.474442\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031313; batch adversarial loss: 0.448420\n",
      "epoch 191; iter: 0; batch classifier loss: 0.023783; batch adversarial loss: 0.510234\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044468; batch adversarial loss: 0.433077\n",
      "epoch 193; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.453829\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022589; batch adversarial loss: 0.425375\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030424; batch adversarial loss: 0.478973\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016793; batch adversarial loss: 0.524803\n",
      "epoch 197; iter: 0; batch classifier loss: 0.055423; batch adversarial loss: 0.412850\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021185; batch adversarial loss: 0.348994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022755; batch adversarial loss: 0.475144\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708600; batch adversarial loss: 0.730915\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422164; batch adversarial loss: 0.710201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387695; batch adversarial loss: 0.689097\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331722; batch adversarial loss: 0.664072\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355481; batch adversarial loss: 0.634191\n",
      "epoch 5; iter: 0; batch classifier loss: 0.254926; batch adversarial loss: 0.587375\n",
      "epoch 6; iter: 0; batch classifier loss: 0.272499; batch adversarial loss: 0.555992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.248218; batch adversarial loss: 0.553237\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299871; batch adversarial loss: 0.511722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308249; batch adversarial loss: 0.494571\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282818; batch adversarial loss: 0.464596\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214866; batch adversarial loss: 0.512870\n",
      "epoch 12; iter: 0; batch classifier loss: 0.180015; batch adversarial loss: 0.503017\n",
      "epoch 13; iter: 0; batch classifier loss: 0.195917; batch adversarial loss: 0.446291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.191705; batch adversarial loss: 0.462500\n",
      "epoch 15; iter: 0; batch classifier loss: 0.167180; batch adversarial loss: 0.433253\n",
      "epoch 16; iter: 0; batch classifier loss: 0.176816; batch adversarial loss: 0.354341\n",
      "epoch 17; iter: 0; batch classifier loss: 0.161189; batch adversarial loss: 0.408543\n",
      "epoch 18; iter: 0; batch classifier loss: 0.174079; batch adversarial loss: 0.526672\n",
      "epoch 19; iter: 0; batch classifier loss: 0.158433; batch adversarial loss: 0.494472\n",
      "epoch 20; iter: 0; batch classifier loss: 0.125639; batch adversarial loss: 0.453804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.127009; batch adversarial loss: 0.510839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.127541; batch adversarial loss: 0.520064\n",
      "epoch 23; iter: 0; batch classifier loss: 0.135809; batch adversarial loss: 0.454701\n",
      "epoch 24; iter: 0; batch classifier loss: 0.107190; batch adversarial loss: 0.409307\n",
      "epoch 25; iter: 0; batch classifier loss: 0.140862; batch adversarial loss: 0.363585\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117069; batch adversarial loss: 0.504186\n",
      "epoch 27; iter: 0; batch classifier loss: 0.141948; batch adversarial loss: 0.482592\n",
      "epoch 28; iter: 0; batch classifier loss: 0.098288; batch adversarial loss: 0.380931\n",
      "epoch 29; iter: 0; batch classifier loss: 0.103856; batch adversarial loss: 0.511013\n",
      "epoch 30; iter: 0; batch classifier loss: 0.102950; batch adversarial loss: 0.399536\n",
      "epoch 31; iter: 0; batch classifier loss: 0.064118; batch adversarial loss: 0.570154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144433; batch adversarial loss: 0.524595\n",
      "epoch 33; iter: 0; batch classifier loss: 0.125490; batch adversarial loss: 0.530316\n",
      "epoch 34; iter: 0; batch classifier loss: 0.094925; batch adversarial loss: 0.584752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118013; batch adversarial loss: 0.556837\n",
      "epoch 36; iter: 0; batch classifier loss: 0.079516; batch adversarial loss: 0.484534\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111264; batch adversarial loss: 0.466199\n",
      "epoch 38; iter: 0; batch classifier loss: 0.110156; batch adversarial loss: 0.525762\n",
      "epoch 39; iter: 0; batch classifier loss: 0.132543; batch adversarial loss: 0.533600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.133791; batch adversarial loss: 0.495242\n",
      "epoch 41; iter: 0; batch classifier loss: 0.140844; batch adversarial loss: 0.497972\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088559; batch adversarial loss: 0.460021\n",
      "epoch 43; iter: 0; batch classifier loss: 0.147643; batch adversarial loss: 0.481575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119896; batch adversarial loss: 0.446453\n",
      "epoch 45; iter: 0; batch classifier loss: 0.156222; batch adversarial loss: 0.533398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.138629; batch adversarial loss: 0.459512\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178104; batch adversarial loss: 0.530472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.210541; batch adversarial loss: 0.583870\n",
      "epoch 49; iter: 0; batch classifier loss: 0.167698; batch adversarial loss: 0.506024\n",
      "epoch 50; iter: 0; batch classifier loss: 0.136361; batch adversarial loss: 0.490157\n",
      "epoch 51; iter: 0; batch classifier loss: 0.158951; batch adversarial loss: 0.478894\n",
      "epoch 52; iter: 0; batch classifier loss: 0.181148; batch adversarial loss: 0.478718\n",
      "epoch 53; iter: 0; batch classifier loss: 0.072075; batch adversarial loss: 0.447048\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065319; batch adversarial loss: 0.516561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.080967; batch adversarial loss: 0.466663\n",
      "epoch 56; iter: 0; batch classifier loss: 0.068864; batch adversarial loss: 0.369264\n",
      "epoch 57; iter: 0; batch classifier loss: 0.027485; batch adversarial loss: 0.406274\n",
      "epoch 58; iter: 0; batch classifier loss: 0.053773; batch adversarial loss: 0.431807\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067717; batch adversarial loss: 0.459107\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060020; batch adversarial loss: 0.536187\n",
      "epoch 61; iter: 0; batch classifier loss: 0.031892; batch adversarial loss: 0.384744\n",
      "epoch 62; iter: 0; batch classifier loss: 0.041705; batch adversarial loss: 0.477270\n",
      "epoch 63; iter: 0; batch classifier loss: 0.058343; batch adversarial loss: 0.538043\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083526; batch adversarial loss: 0.381839\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070245; batch adversarial loss: 0.427711\n",
      "epoch 66; iter: 0; batch classifier loss: 0.035140; batch adversarial loss: 0.448603\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081048; batch adversarial loss: 0.463443\n",
      "epoch 68; iter: 0; batch classifier loss: 0.057716; batch adversarial loss: 0.400138\n",
      "epoch 69; iter: 0; batch classifier loss: 0.046094; batch adversarial loss: 0.414612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.042637; batch adversarial loss: 0.468729\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046713; batch adversarial loss: 0.508652\n",
      "epoch 72; iter: 0; batch classifier loss: 0.059581; batch adversarial loss: 0.488328\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053007; batch adversarial loss: 0.443880\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075144; batch adversarial loss: 0.482625\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063522; batch adversarial loss: 0.478048\n",
      "epoch 76; iter: 0; batch classifier loss: 0.163427; batch adversarial loss: 0.344198\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051933; batch adversarial loss: 0.451475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.103862; batch adversarial loss: 0.484894\n",
      "epoch 79; iter: 0; batch classifier loss: 0.094266; batch adversarial loss: 0.460668\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080862; batch adversarial loss: 0.435139\n",
      "epoch 81; iter: 0; batch classifier loss: 0.051775; batch adversarial loss: 0.440210\n",
      "epoch 82; iter: 0; batch classifier loss: 0.105831; batch adversarial loss: 0.453787\n",
      "epoch 83; iter: 0; batch classifier loss: 0.057135; batch adversarial loss: 0.431040\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095992; batch adversarial loss: 0.368757\n",
      "epoch 85; iter: 0; batch classifier loss: 0.041644; batch adversarial loss: 0.466364\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073422; batch adversarial loss: 0.351932\n",
      "epoch 87; iter: 0; batch classifier loss: 0.029853; batch adversarial loss: 0.542449\n",
      "epoch 88; iter: 0; batch classifier loss: 0.060558; batch adversarial loss: 0.469413\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092064; batch adversarial loss: 0.432626\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076533; batch adversarial loss: 0.453872\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045566; batch adversarial loss: 0.451975\n",
      "epoch 92; iter: 0; batch classifier loss: 0.083415; batch adversarial loss: 0.451773\n",
      "epoch 93; iter: 0; batch classifier loss: 0.068257; batch adversarial loss: 0.455531\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043454; batch adversarial loss: 0.552127\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060870; batch adversarial loss: 0.367044\n",
      "epoch 96; iter: 0; batch classifier loss: 0.033170; batch adversarial loss: 0.499451\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050347; batch adversarial loss: 0.518848\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072989; batch adversarial loss: 0.506747\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046592; batch adversarial loss: 0.527350\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057083; batch adversarial loss: 0.444790\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051894; batch adversarial loss: 0.471619\n",
      "epoch 102; iter: 0; batch classifier loss: 0.054715; batch adversarial loss: 0.493323\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052095; batch adversarial loss: 0.549751\n",
      "epoch 104; iter: 0; batch classifier loss: 0.076949; batch adversarial loss: 0.375720\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045235; batch adversarial loss: 0.532095\n",
      "epoch 106; iter: 0; batch classifier loss: 0.052999; batch adversarial loss: 0.480798\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058884; batch adversarial loss: 0.540991\n",
      "epoch 108; iter: 0; batch classifier loss: 0.105523; batch adversarial loss: 0.506320\n",
      "epoch 109; iter: 0; batch classifier loss: 0.088394; batch adversarial loss: 0.465872\n",
      "epoch 110; iter: 0; batch classifier loss: 0.036154; batch adversarial loss: 0.499909\n",
      "epoch 111; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.506547\n",
      "epoch 112; iter: 0; batch classifier loss: 0.067899; batch adversarial loss: 0.515035\n",
      "epoch 113; iter: 0; batch classifier loss: 0.107313; batch adversarial loss: 0.357502\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048094; batch adversarial loss: 0.384679\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054284; batch adversarial loss: 0.429449\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053492; batch adversarial loss: 0.467009\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056559; batch adversarial loss: 0.484985\n",
      "epoch 118; iter: 0; batch classifier loss: 0.035381; batch adversarial loss: 0.482787\n",
      "epoch 119; iter: 0; batch classifier loss: 0.059401; batch adversarial loss: 0.461045\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040109; batch adversarial loss: 0.512089\n",
      "epoch 121; iter: 0; batch classifier loss: 0.044444; batch adversarial loss: 0.476057\n",
      "epoch 122; iter: 0; batch classifier loss: 0.063158; batch adversarial loss: 0.464178\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050302; batch adversarial loss: 0.439063\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044352; batch adversarial loss: 0.482367\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037833; batch adversarial loss: 0.365955\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037216; batch adversarial loss: 0.457812\n",
      "epoch 127; iter: 0; batch classifier loss: 0.061727; batch adversarial loss: 0.388887\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055915; batch adversarial loss: 0.505820\n",
      "epoch 129; iter: 0; batch classifier loss: 0.040435; batch adversarial loss: 0.506435\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042624; batch adversarial loss: 0.404867\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026431; batch adversarial loss: 0.398516\n",
      "epoch 132; iter: 0; batch classifier loss: 0.053981; batch adversarial loss: 0.446907\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059493; batch adversarial loss: 0.440631\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047166; batch adversarial loss: 0.433537\n",
      "epoch 135; iter: 0; batch classifier loss: 0.038120; batch adversarial loss: 0.447355\n",
      "epoch 136; iter: 0; batch classifier loss: 0.050569; batch adversarial loss: 0.473742\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037058; batch adversarial loss: 0.404722\n",
      "epoch 138; iter: 0; batch classifier loss: 0.046440; batch adversarial loss: 0.449572\n",
      "epoch 139; iter: 0; batch classifier loss: 0.045361; batch adversarial loss: 0.442592\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027700; batch adversarial loss: 0.444172\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040296; batch adversarial loss: 0.570575\n",
      "epoch 142; iter: 0; batch classifier loss: 0.028507; batch adversarial loss: 0.609613\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050105; batch adversarial loss: 0.421346\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016115; batch adversarial loss: 0.492076\n",
      "epoch 145; iter: 0; batch classifier loss: 0.042643; batch adversarial loss: 0.377742\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031263; batch adversarial loss: 0.624414\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041762; batch adversarial loss: 0.384622\n",
      "epoch 148; iter: 0; batch classifier loss: 0.050034; batch adversarial loss: 0.487348\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025936; batch adversarial loss: 0.500651\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036010; batch adversarial loss: 0.430757\n",
      "epoch 151; iter: 0; batch classifier loss: 0.032951; batch adversarial loss: 0.460644\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029962; batch adversarial loss: 0.476784\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027703; batch adversarial loss: 0.394467\n",
      "epoch 154; iter: 0; batch classifier loss: 0.018983; batch adversarial loss: 0.450983\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039395; batch adversarial loss: 0.431357\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.497260\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016969; batch adversarial loss: 0.438560\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034246; batch adversarial loss: 0.369247\n",
      "epoch 159; iter: 0; batch classifier loss: 0.071671; batch adversarial loss: 0.399686\n",
      "epoch 160; iter: 0; batch classifier loss: 0.032261; batch adversarial loss: 0.394387\n",
      "epoch 161; iter: 0; batch classifier loss: 0.009919; batch adversarial loss: 0.386780\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042265; batch adversarial loss: 0.519155\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041711; batch adversarial loss: 0.536503\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011416; batch adversarial loss: 0.487286\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048477; batch adversarial loss: 0.537513\n",
      "epoch 166; iter: 0; batch classifier loss: 0.040008; batch adversarial loss: 0.476863\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029951; batch adversarial loss: 0.424083\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028968; batch adversarial loss: 0.356591\n",
      "epoch 169; iter: 0; batch classifier loss: 0.082287; batch adversarial loss: 0.454618\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028228; batch adversarial loss: 0.430535\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022916; batch adversarial loss: 0.466144\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021039; batch adversarial loss: 0.448423\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008901; batch adversarial loss: 0.488543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.041085; batch adversarial loss: 0.401830\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017744; batch adversarial loss: 0.537477\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027585; batch adversarial loss: 0.321055\n",
      "epoch 177; iter: 0; batch classifier loss: 0.013032; batch adversarial loss: 0.373270\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015249; batch adversarial loss: 0.442788\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032272; batch adversarial loss: 0.393306\n",
      "epoch 180; iter: 0; batch classifier loss: 0.050614; batch adversarial loss: 0.460998\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045502; batch adversarial loss: 0.436980\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020937; batch adversarial loss: 0.492654\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020002; batch adversarial loss: 0.427141\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017818; batch adversarial loss: 0.420470\n",
      "epoch 185; iter: 0; batch classifier loss: 0.031656; batch adversarial loss: 0.496533\n",
      "epoch 186; iter: 0; batch classifier loss: 0.004954; batch adversarial loss: 0.433960\n",
      "epoch 187; iter: 0; batch classifier loss: 0.044104; batch adversarial loss: 0.492225\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008823; batch adversarial loss: 0.467102\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028777; batch adversarial loss: 0.428704\n",
      "epoch 190; iter: 0; batch classifier loss: 0.037168; batch adversarial loss: 0.471210\n",
      "epoch 191; iter: 0; batch classifier loss: 0.006297; batch adversarial loss: 0.378077\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015772; batch adversarial loss: 0.405836\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019348; batch adversarial loss: 0.496718\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016294; batch adversarial loss: 0.461924\n",
      "epoch 195; iter: 0; batch classifier loss: 0.045940; batch adversarial loss: 0.473562\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015927; batch adversarial loss: 0.531678\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026193; batch adversarial loss: 0.438576\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020306; batch adversarial loss: 0.376601\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009539; batch adversarial loss: 0.478775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699744; batch adversarial loss: 0.628306\n",
      "epoch 1; iter: 0; batch classifier loss: 0.473923; batch adversarial loss: 0.620154\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413053; batch adversarial loss: 0.587645\n",
      "epoch 3; iter: 0; batch classifier loss: 0.438193; batch adversarial loss: 0.586835\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298499; batch adversarial loss: 0.613180\n",
      "epoch 5; iter: 0; batch classifier loss: 0.319038; batch adversarial loss: 0.555273\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280679; batch adversarial loss: 0.588976\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308550; batch adversarial loss: 0.512831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295029; batch adversarial loss: 0.553716\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244333; batch adversarial loss: 0.533404\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270159; batch adversarial loss: 0.620026\n",
      "epoch 11; iter: 0; batch classifier loss: 0.250421; batch adversarial loss: 0.486896\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288706; batch adversarial loss: 0.442761\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295949; batch adversarial loss: 0.433044\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287038; batch adversarial loss: 0.498269\n",
      "epoch 15; iter: 0; batch classifier loss: 0.218846; batch adversarial loss: 0.592653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.170868; batch adversarial loss: 0.516863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199098; batch adversarial loss: 0.553625\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290657; batch adversarial loss: 0.453411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.155259; batch adversarial loss: 0.517101\n",
      "epoch 20; iter: 0; batch classifier loss: 0.175171; batch adversarial loss: 0.505715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.204300; batch adversarial loss: 0.461478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201369; batch adversarial loss: 0.415001\n",
      "epoch 23; iter: 0; batch classifier loss: 0.131618; batch adversarial loss: 0.495320\n",
      "epoch 24; iter: 0; batch classifier loss: 0.130757; batch adversarial loss: 0.508104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.145567; batch adversarial loss: 0.409075\n",
      "epoch 26; iter: 0; batch classifier loss: 0.193328; batch adversarial loss: 0.452554\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200580; batch adversarial loss: 0.439243\n",
      "epoch 28; iter: 0; batch classifier loss: 0.214072; batch adversarial loss: 0.497831\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171685; batch adversarial loss: 0.387315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.168350; batch adversarial loss: 0.445553\n",
      "epoch 31; iter: 0; batch classifier loss: 0.145030; batch adversarial loss: 0.441199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108668; batch adversarial loss: 0.456647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.176171; batch adversarial loss: 0.486459\n",
      "epoch 34; iter: 0; batch classifier loss: 0.253211; batch adversarial loss: 0.419391\n",
      "epoch 35; iter: 0; batch classifier loss: 0.265197; batch adversarial loss: 0.443047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.168444; batch adversarial loss: 0.447769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222230; batch adversarial loss: 0.440707\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198854; batch adversarial loss: 0.506715\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243646; batch adversarial loss: 0.462603\n",
      "epoch 40; iter: 0; batch classifier loss: 0.232910; batch adversarial loss: 0.490483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166258; batch adversarial loss: 0.425378\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209663; batch adversarial loss: 0.370799\n",
      "epoch 43; iter: 0; batch classifier loss: 0.277724; batch adversarial loss: 0.449110\n",
      "epoch 44; iter: 0; batch classifier loss: 0.173397; batch adversarial loss: 0.431335\n",
      "epoch 45; iter: 0; batch classifier loss: 0.250823; batch adversarial loss: 0.450490\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159864; batch adversarial loss: 0.444658\n",
      "epoch 47; iter: 0; batch classifier loss: 0.241623; batch adversarial loss: 0.422472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.178529; batch adversarial loss: 0.468945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.205752; batch adversarial loss: 0.515633\n",
      "epoch 50; iter: 0; batch classifier loss: 0.237632; batch adversarial loss: 0.367647\n",
      "epoch 51; iter: 0; batch classifier loss: 0.175843; batch adversarial loss: 0.386383\n",
      "epoch 52; iter: 0; batch classifier loss: 0.249462; batch adversarial loss: 0.448921\n",
      "epoch 53; iter: 0; batch classifier loss: 0.187646; batch adversarial loss: 0.402231\n",
      "epoch 54; iter: 0; batch classifier loss: 0.259052; batch adversarial loss: 0.498786\n",
      "epoch 55; iter: 0; batch classifier loss: 0.236604; batch adversarial loss: 0.497941\n",
      "epoch 56; iter: 0; batch classifier loss: 0.230007; batch adversarial loss: 0.484417\n",
      "epoch 57; iter: 0; batch classifier loss: 0.221800; batch adversarial loss: 0.434078\n",
      "epoch 58; iter: 0; batch classifier loss: 0.246210; batch adversarial loss: 0.361334\n",
      "epoch 59; iter: 0; batch classifier loss: 0.235192; batch adversarial loss: 0.445669\n",
      "epoch 60; iter: 0; batch classifier loss: 0.258796; batch adversarial loss: 0.458257\n",
      "epoch 61; iter: 0; batch classifier loss: 0.251549; batch adversarial loss: 0.398495\n",
      "epoch 62; iter: 0; batch classifier loss: 0.128508; batch adversarial loss: 0.397870\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118593; batch adversarial loss: 0.372158\n",
      "epoch 64; iter: 0; batch classifier loss: 0.101555; batch adversarial loss: 0.495736\n",
      "epoch 65; iter: 0; batch classifier loss: 0.223786; batch adversarial loss: 0.461653\n",
      "epoch 66; iter: 0; batch classifier loss: 0.205376; batch adversarial loss: 0.400565\n",
      "epoch 67; iter: 0; batch classifier loss: 0.172551; batch adversarial loss: 0.430616\n",
      "epoch 68; iter: 0; batch classifier loss: 0.176813; batch adversarial loss: 0.560917\n",
      "epoch 69; iter: 0; batch classifier loss: 0.238887; batch adversarial loss: 0.534518\n",
      "epoch 70; iter: 0; batch classifier loss: 0.238984; batch adversarial loss: 0.558847\n",
      "epoch 71; iter: 0; batch classifier loss: 0.258718; batch adversarial loss: 0.298303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.211957; batch adversarial loss: 0.458507\n",
      "epoch 73; iter: 0; batch classifier loss: 0.175016; batch adversarial loss: 0.422838\n",
      "epoch 74; iter: 0; batch classifier loss: 0.167613; batch adversarial loss: 0.410739\n",
      "epoch 75; iter: 0; batch classifier loss: 0.179879; batch adversarial loss: 0.471226\n",
      "epoch 76; iter: 0; batch classifier loss: 0.159755; batch adversarial loss: 0.422209\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095399; batch adversarial loss: 0.459386\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206802; batch adversarial loss: 0.484277\n",
      "epoch 79; iter: 0; batch classifier loss: 0.161665; batch adversarial loss: 0.447599\n",
      "epoch 80; iter: 0; batch classifier loss: 0.272372; batch adversarial loss: 0.471626\n",
      "epoch 81; iter: 0; batch classifier loss: 0.241911; batch adversarial loss: 0.458546\n",
      "epoch 82; iter: 0; batch classifier loss: 0.162015; batch adversarial loss: 0.458703\n",
      "epoch 83; iter: 0; batch classifier loss: 0.154246; batch adversarial loss: 0.483850\n",
      "epoch 84; iter: 0; batch classifier loss: 0.152488; batch adversarial loss: 0.446045\n",
      "epoch 85; iter: 0; batch classifier loss: 0.173046; batch adversarial loss: 0.544985\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150163; batch adversarial loss: 0.421555\n",
      "epoch 87; iter: 0; batch classifier loss: 0.172764; batch adversarial loss: 0.459625\n",
      "epoch 88; iter: 0; batch classifier loss: 0.221269; batch adversarial loss: 0.509439\n",
      "epoch 89; iter: 0; batch classifier loss: 0.276593; batch adversarial loss: 0.372370\n",
      "epoch 90; iter: 0; batch classifier loss: 0.154108; batch adversarial loss: 0.494903\n",
      "epoch 91; iter: 0; batch classifier loss: 0.261195; batch adversarial loss: 0.385673\n",
      "epoch 92; iter: 0; batch classifier loss: 0.184743; batch adversarial loss: 0.557392\n",
      "epoch 93; iter: 0; batch classifier loss: 0.140758; batch adversarial loss: 0.446571\n",
      "epoch 94; iter: 0; batch classifier loss: 0.114990; batch adversarial loss: 0.470944\n",
      "epoch 95; iter: 0; batch classifier loss: 0.087678; batch adversarial loss: 0.418435\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043383; batch adversarial loss: 0.483984\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046546; batch adversarial loss: 0.511066\n",
      "epoch 98; iter: 0; batch classifier loss: 0.065499; batch adversarial loss: 0.466280\n",
      "epoch 99; iter: 0; batch classifier loss: 0.091703; batch adversarial loss: 0.404946\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043793; batch adversarial loss: 0.407482\n",
      "epoch 101; iter: 0; batch classifier loss: 0.034461; batch adversarial loss: 0.412419\n",
      "epoch 102; iter: 0; batch classifier loss: 0.064574; batch adversarial loss: 0.402229\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043041; batch adversarial loss: 0.446907\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075374; batch adversarial loss: 0.412558\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074215; batch adversarial loss: 0.476450\n",
      "epoch 106; iter: 0; batch classifier loss: 0.078414; batch adversarial loss: 0.480743\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067020; batch adversarial loss: 0.428263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073059; batch adversarial loss: 0.478917\n",
      "epoch 109; iter: 0; batch classifier loss: 0.116375; batch adversarial loss: 0.456636\n",
      "epoch 110; iter: 0; batch classifier loss: 0.082769; batch adversarial loss: 0.416675\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101723; batch adversarial loss: 0.328869\n",
      "epoch 112; iter: 0; batch classifier loss: 0.044939; batch adversarial loss: 0.480957\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049280; batch adversarial loss: 0.398336\n",
      "epoch 114; iter: 0; batch classifier loss: 0.046085; batch adversarial loss: 0.485995\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043489; batch adversarial loss: 0.456585\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049283; batch adversarial loss: 0.409735\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032957; batch adversarial loss: 0.432794\n",
      "epoch 118; iter: 0; batch classifier loss: 0.076516; batch adversarial loss: 0.338922\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057037; batch adversarial loss: 0.413680\n",
      "epoch 120; iter: 0; batch classifier loss: 0.053983; batch adversarial loss: 0.428708\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055897; batch adversarial loss: 0.419520\n",
      "epoch 122; iter: 0; batch classifier loss: 0.041123; batch adversarial loss: 0.468216\n",
      "epoch 123; iter: 0; batch classifier loss: 0.075406; batch adversarial loss: 0.425384\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051215; batch adversarial loss: 0.431888\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046395; batch adversarial loss: 0.428597\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048867; batch adversarial loss: 0.515060\n",
      "epoch 127; iter: 0; batch classifier loss: 0.069577; batch adversarial loss: 0.400560\n",
      "epoch 128; iter: 0; batch classifier loss: 0.066049; batch adversarial loss: 0.432582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.062708; batch adversarial loss: 0.454048\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035896; batch adversarial loss: 0.379477\n",
      "epoch 131; iter: 0; batch classifier loss: 0.061235; batch adversarial loss: 0.470460\n",
      "epoch 132; iter: 0; batch classifier loss: 0.078809; batch adversarial loss: 0.436425\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055899; batch adversarial loss: 0.507753\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032570; batch adversarial loss: 0.416728\n",
      "epoch 135; iter: 0; batch classifier loss: 0.058256; batch adversarial loss: 0.425980\n",
      "epoch 136; iter: 0; batch classifier loss: 0.047937; batch adversarial loss: 0.399075\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070768; batch adversarial loss: 0.374053\n",
      "epoch 138; iter: 0; batch classifier loss: 0.077345; batch adversarial loss: 0.392434\n",
      "epoch 139; iter: 0; batch classifier loss: 0.070073; batch adversarial loss: 0.439790\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043153; batch adversarial loss: 0.421878\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040393; batch adversarial loss: 0.458678\n",
      "epoch 142; iter: 0; batch classifier loss: 0.080593; batch adversarial loss: 0.442025\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033835; batch adversarial loss: 0.418384\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039775; batch adversarial loss: 0.422232\n",
      "epoch 145; iter: 0; batch classifier loss: 0.051047; batch adversarial loss: 0.309567\n",
      "epoch 146; iter: 0; batch classifier loss: 0.069061; batch adversarial loss: 0.384581\n",
      "epoch 147; iter: 0; batch classifier loss: 0.081975; batch adversarial loss: 0.433812\n",
      "epoch 148; iter: 0; batch classifier loss: 0.047403; batch adversarial loss: 0.524987\n",
      "epoch 149; iter: 0; batch classifier loss: 0.043870; batch adversarial loss: 0.517599\n",
      "epoch 150; iter: 0; batch classifier loss: 0.073459; batch adversarial loss: 0.429586\n",
      "epoch 151; iter: 0; batch classifier loss: 0.053762; batch adversarial loss: 0.367750\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056549; batch adversarial loss: 0.328116\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055544; batch adversarial loss: 0.465487\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028235; batch adversarial loss: 0.406017\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050357; batch adversarial loss: 0.387886\n",
      "epoch 156; iter: 0; batch classifier loss: 0.057316; batch adversarial loss: 0.457641\n",
      "epoch 157; iter: 0; batch classifier loss: 0.047567; batch adversarial loss: 0.438597\n",
      "epoch 158; iter: 0; batch classifier loss: 0.070299; batch adversarial loss: 0.361721\n",
      "epoch 159; iter: 0; batch classifier loss: 0.066555; batch adversarial loss: 0.467432\n",
      "epoch 160; iter: 0; batch classifier loss: 0.089141; batch adversarial loss: 0.439220\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024184; batch adversarial loss: 0.435224\n",
      "epoch 162; iter: 0; batch classifier loss: 0.075179; batch adversarial loss: 0.401096\n",
      "epoch 163; iter: 0; batch classifier loss: 0.028797; batch adversarial loss: 0.468877\n",
      "epoch 164; iter: 0; batch classifier loss: 0.082825; batch adversarial loss: 0.422278\n",
      "epoch 165; iter: 0; batch classifier loss: 0.081825; batch adversarial loss: 0.329500\n",
      "epoch 166; iter: 0; batch classifier loss: 0.037754; batch adversarial loss: 0.394442\n",
      "epoch 167; iter: 0; batch classifier loss: 0.048217; batch adversarial loss: 0.494172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.043691; batch adversarial loss: 0.410538\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036905; batch adversarial loss: 0.422658\n",
      "epoch 170; iter: 0; batch classifier loss: 0.057498; batch adversarial loss: 0.421608\n",
      "epoch 171; iter: 0; batch classifier loss: 0.048670; batch adversarial loss: 0.372678\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022109; batch adversarial loss: 0.440856\n",
      "epoch 173; iter: 0; batch classifier loss: 0.065157; batch adversarial loss: 0.380003\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026527; batch adversarial loss: 0.436672\n",
      "epoch 175; iter: 0; batch classifier loss: 0.053980; batch adversarial loss: 0.449653\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050998; batch adversarial loss: 0.377710\n",
      "epoch 177; iter: 0; batch classifier loss: 0.065064; batch adversarial loss: 0.422933\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035085; batch adversarial loss: 0.440102\n",
      "epoch 179; iter: 0; batch classifier loss: 0.056694; batch adversarial loss: 0.468294\n",
      "epoch 180; iter: 0; batch classifier loss: 0.053475; batch adversarial loss: 0.402539\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036879; batch adversarial loss: 0.429836\n",
      "epoch 182; iter: 0; batch classifier loss: 0.051859; batch adversarial loss: 0.398801\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028477; batch adversarial loss: 0.429477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037810; batch adversarial loss: 0.426627\n",
      "epoch 185; iter: 0; batch classifier loss: 0.041756; batch adversarial loss: 0.396555\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041347; batch adversarial loss: 0.417299\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022480; batch adversarial loss: 0.465628\n",
      "epoch 188; iter: 0; batch classifier loss: 0.034914; batch adversarial loss: 0.431617\n",
      "epoch 189; iter: 0; batch classifier loss: 0.035092; batch adversarial loss: 0.414531\n",
      "epoch 190; iter: 0; batch classifier loss: 0.063342; batch adversarial loss: 0.453943\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028229; batch adversarial loss: 0.452885\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038395; batch adversarial loss: 0.470556\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031321; batch adversarial loss: 0.422153\n",
      "epoch 194; iter: 0; batch classifier loss: 0.049513; batch adversarial loss: 0.412436\n",
      "epoch 195; iter: 0; batch classifier loss: 0.031776; batch adversarial loss: 0.455379\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027176; batch adversarial loss: 0.396312\n",
      "epoch 197; iter: 0; batch classifier loss: 0.047106; batch adversarial loss: 0.428703\n",
      "epoch 198; iter: 0; batch classifier loss: 0.030164; batch adversarial loss: 0.387401\n",
      "epoch 199; iter: 0; batch classifier loss: 0.023134; batch adversarial loss: 0.479828\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701850; batch adversarial loss: 0.491938\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409424; batch adversarial loss: 0.617444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.381757; batch adversarial loss: 0.630963\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372395; batch adversarial loss: 0.572421\n",
      "epoch 4; iter: 0; batch classifier loss: 0.511460; batch adversarial loss: 0.538498\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379183; batch adversarial loss: 0.585171\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316815; batch adversarial loss: 0.648474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323307; batch adversarial loss: 0.559135\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301814; batch adversarial loss: 0.550579\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414429; batch adversarial loss: 0.539648\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367188; batch adversarial loss: 0.549155\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366647; batch adversarial loss: 0.539548\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373028; batch adversarial loss: 0.455237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448885; batch adversarial loss: 0.506589\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569992; batch adversarial loss: 0.529276\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513131; batch adversarial loss: 0.528277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323448; batch adversarial loss: 0.524215\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225545; batch adversarial loss: 0.525360\n",
      "epoch 18; iter: 0; batch classifier loss: 0.165238; batch adversarial loss: 0.458709\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237424; batch adversarial loss: 0.458912\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204545; batch adversarial loss: 0.396037\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248000; batch adversarial loss: 0.540946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.193664; batch adversarial loss: 0.447032\n",
      "epoch 23; iter: 0; batch classifier loss: 0.173948; batch adversarial loss: 0.515039\n",
      "epoch 24; iter: 0; batch classifier loss: 0.187530; batch adversarial loss: 0.475518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.157158; batch adversarial loss: 0.456036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.141750; batch adversarial loss: 0.390893\n",
      "epoch 27; iter: 0; batch classifier loss: 0.137966; batch adversarial loss: 0.472520\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119648; batch adversarial loss: 0.443732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.162284; batch adversarial loss: 0.483299\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170894; batch adversarial loss: 0.519967\n",
      "epoch 31; iter: 0; batch classifier loss: 0.108165; batch adversarial loss: 0.494584\n",
      "epoch 32; iter: 0; batch classifier loss: 0.162459; batch adversarial loss: 0.481205\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167727; batch adversarial loss: 0.477497\n",
      "epoch 34; iter: 0; batch classifier loss: 0.168463; batch adversarial loss: 0.527713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.093596; batch adversarial loss: 0.496332\n",
      "epoch 36; iter: 0; batch classifier loss: 0.203948; batch adversarial loss: 0.425312\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162673; batch adversarial loss: 0.378148\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123395; batch adversarial loss: 0.374969\n",
      "epoch 39; iter: 0; batch classifier loss: 0.137899; batch adversarial loss: 0.530993\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124626; batch adversarial loss: 0.472090\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137989; batch adversarial loss: 0.497642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.135256; batch adversarial loss: 0.405368\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116822; batch adversarial loss: 0.506282\n",
      "epoch 44; iter: 0; batch classifier loss: 0.195392; batch adversarial loss: 0.391629\n",
      "epoch 45; iter: 0; batch classifier loss: 0.188319; batch adversarial loss: 0.357306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.138261; batch adversarial loss: 0.406633\n",
      "epoch 47; iter: 0; batch classifier loss: 0.123410; batch adversarial loss: 0.440079\n",
      "epoch 48; iter: 0; batch classifier loss: 0.171915; batch adversarial loss: 0.445307\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118849; batch adversarial loss: 0.521758\n",
      "epoch 50; iter: 0; batch classifier loss: 0.166348; batch adversarial loss: 0.399230\n",
      "epoch 51; iter: 0; batch classifier loss: 0.224343; batch adversarial loss: 0.471074\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113019; batch adversarial loss: 0.522696\n",
      "epoch 53; iter: 0; batch classifier loss: 0.133738; batch adversarial loss: 0.484235\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076382; batch adversarial loss: 0.494224\n",
      "epoch 55; iter: 0; batch classifier loss: 0.182903; batch adversarial loss: 0.381638\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132434; batch adversarial loss: 0.578404\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126648; batch adversarial loss: 0.438680\n",
      "epoch 58; iter: 0; batch classifier loss: 0.132429; batch adversarial loss: 0.436316\n",
      "epoch 59; iter: 0; batch classifier loss: 0.117990; batch adversarial loss: 0.451765\n",
      "epoch 60; iter: 0; batch classifier loss: 0.182118; batch adversarial loss: 0.399888\n",
      "epoch 61; iter: 0; batch classifier loss: 0.095420; batch adversarial loss: 0.432120\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090238; batch adversarial loss: 0.520700\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118724; batch adversarial loss: 0.593062\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122288; batch adversarial loss: 0.430864\n",
      "epoch 65; iter: 0; batch classifier loss: 0.123089; batch adversarial loss: 0.462835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.162306; batch adversarial loss: 0.545974\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134203; batch adversarial loss: 0.430263\n",
      "epoch 68; iter: 0; batch classifier loss: 0.119986; batch adversarial loss: 0.392836\n",
      "epoch 69; iter: 0; batch classifier loss: 0.135831; batch adversarial loss: 0.539018\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158613; batch adversarial loss: 0.469191\n",
      "epoch 71; iter: 0; batch classifier loss: 0.157486; batch adversarial loss: 0.470214\n",
      "epoch 72; iter: 0; batch classifier loss: 0.087896; batch adversarial loss: 0.527355\n",
      "epoch 73; iter: 0; batch classifier loss: 0.166564; batch adversarial loss: 0.387516\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101549; batch adversarial loss: 0.436407\n",
      "epoch 75; iter: 0; batch classifier loss: 0.072100; batch adversarial loss: 0.457832\n",
      "epoch 76; iter: 0; batch classifier loss: 0.116355; batch adversarial loss: 0.488072\n",
      "epoch 77; iter: 0; batch classifier loss: 0.127662; batch adversarial loss: 0.466180\n",
      "epoch 78; iter: 0; batch classifier loss: 0.123885; batch adversarial loss: 0.382652\n",
      "epoch 79; iter: 0; batch classifier loss: 0.135312; batch adversarial loss: 0.418284\n",
      "epoch 80; iter: 0; batch classifier loss: 0.178471; batch adversarial loss: 0.425031\n",
      "epoch 81; iter: 0; batch classifier loss: 0.153591; batch adversarial loss: 0.484258\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096051; batch adversarial loss: 0.494871\n",
      "epoch 83; iter: 0; batch classifier loss: 0.123677; batch adversarial loss: 0.462588\n",
      "epoch 84; iter: 0; batch classifier loss: 0.134202; batch adversarial loss: 0.528350\n",
      "epoch 85; iter: 0; batch classifier loss: 0.142051; batch adversarial loss: 0.395093\n",
      "epoch 86; iter: 0; batch classifier loss: 0.174215; batch adversarial loss: 0.437281\n",
      "epoch 87; iter: 0; batch classifier loss: 0.101986; batch adversarial loss: 0.486096\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124175; batch adversarial loss: 0.483496\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171586; batch adversarial loss: 0.361298\n",
      "epoch 90; iter: 0; batch classifier loss: 0.115306; batch adversarial loss: 0.504950\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071211; batch adversarial loss: 0.530453\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105764; batch adversarial loss: 0.493412\n",
      "epoch 93; iter: 0; batch classifier loss: 0.108898; batch adversarial loss: 0.375190\n",
      "epoch 94; iter: 0; batch classifier loss: 0.124294; batch adversarial loss: 0.471506\n",
      "epoch 95; iter: 0; batch classifier loss: 0.153217; batch adversarial loss: 0.452593\n",
      "epoch 96; iter: 0; batch classifier loss: 0.116496; batch adversarial loss: 0.457661\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090734; batch adversarial loss: 0.434016\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058632; batch adversarial loss: 0.476403\n",
      "epoch 99; iter: 0; batch classifier loss: 0.141729; batch adversarial loss: 0.546563\n",
      "epoch 100; iter: 0; batch classifier loss: 0.092481; batch adversarial loss: 0.475893\n",
      "epoch 101; iter: 0; batch classifier loss: 0.128552; batch adversarial loss: 0.493396\n",
      "epoch 102; iter: 0; batch classifier loss: 0.142358; batch adversarial loss: 0.538902\n",
      "epoch 103; iter: 0; batch classifier loss: 0.097971; batch adversarial loss: 0.450937\n",
      "epoch 104; iter: 0; batch classifier loss: 0.163619; batch adversarial loss: 0.360852\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068451; batch adversarial loss: 0.392962\n",
      "epoch 106; iter: 0; batch classifier loss: 0.097912; batch adversarial loss: 0.399884\n",
      "epoch 107; iter: 0; batch classifier loss: 0.127260; batch adversarial loss: 0.532142\n",
      "epoch 108; iter: 0; batch classifier loss: 0.134682; batch adversarial loss: 0.415611\n",
      "epoch 109; iter: 0; batch classifier loss: 0.062681; batch adversarial loss: 0.486908\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052075; batch adversarial loss: 0.471817\n",
      "epoch 111; iter: 0; batch classifier loss: 0.085924; batch adversarial loss: 0.424833\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066762; batch adversarial loss: 0.433585\n",
      "epoch 113; iter: 0; batch classifier loss: 0.119583; batch adversarial loss: 0.410669\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062943; batch adversarial loss: 0.490687\n",
      "epoch 115; iter: 0; batch classifier loss: 0.071690; batch adversarial loss: 0.481613\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056029; batch adversarial loss: 0.472771\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080650; batch adversarial loss: 0.414147\n",
      "epoch 118; iter: 0; batch classifier loss: 0.060579; batch adversarial loss: 0.409092\n",
      "epoch 119; iter: 0; batch classifier loss: 0.054902; batch adversarial loss: 0.489938\n",
      "epoch 120; iter: 0; batch classifier loss: 0.056991; batch adversarial loss: 0.458126\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025865; batch adversarial loss: 0.463925\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037135; batch adversarial loss: 0.538007\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043673; batch adversarial loss: 0.369424\n",
      "epoch 124; iter: 0; batch classifier loss: 0.067171; batch adversarial loss: 0.436406\n",
      "epoch 125; iter: 0; batch classifier loss: 0.077571; batch adversarial loss: 0.432182\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042840; batch adversarial loss: 0.353999\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039371; batch adversarial loss: 0.451628\n",
      "epoch 128; iter: 0; batch classifier loss: 0.043545; batch adversarial loss: 0.397334\n",
      "epoch 129; iter: 0; batch classifier loss: 0.065550; batch adversarial loss: 0.496487\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071296; batch adversarial loss: 0.496059\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060690; batch adversarial loss: 0.450545\n",
      "epoch 132; iter: 0; batch classifier loss: 0.019475; batch adversarial loss: 0.370411\n",
      "epoch 133; iter: 0; batch classifier loss: 0.042187; batch adversarial loss: 0.475395\n",
      "epoch 134; iter: 0; batch classifier loss: 0.041019; batch adversarial loss: 0.459334\n",
      "epoch 135; iter: 0; batch classifier loss: 0.064323; batch adversarial loss: 0.428307\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053833; batch adversarial loss: 0.374776\n",
      "epoch 137; iter: 0; batch classifier loss: 0.035725; batch adversarial loss: 0.521616\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020660; batch adversarial loss: 0.482476\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029934; batch adversarial loss: 0.396767\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048236; batch adversarial loss: 0.459800\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051062; batch adversarial loss: 0.444362\n",
      "epoch 142; iter: 0; batch classifier loss: 0.045249; batch adversarial loss: 0.335877\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033939; batch adversarial loss: 0.543878\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025876; batch adversarial loss: 0.511973\n",
      "epoch 145; iter: 0; batch classifier loss: 0.055256; batch adversarial loss: 0.490021\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023195; batch adversarial loss: 0.471726\n",
      "epoch 147; iter: 0; batch classifier loss: 0.037285; batch adversarial loss: 0.429051\n",
      "epoch 148; iter: 0; batch classifier loss: 0.059972; batch adversarial loss: 0.354947\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031656; batch adversarial loss: 0.424195\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010713; batch adversarial loss: 0.452647\n",
      "epoch 151; iter: 0; batch classifier loss: 0.075736; batch adversarial loss: 0.449916\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036844; batch adversarial loss: 0.361364\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025058; batch adversarial loss: 0.332383\n",
      "epoch 154; iter: 0; batch classifier loss: 0.049323; batch adversarial loss: 0.441325\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016880; batch adversarial loss: 0.411797\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025001; batch adversarial loss: 0.480766\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010880; batch adversarial loss: 0.492069\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045349; batch adversarial loss: 0.447288\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031018; batch adversarial loss: 0.534830\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046437; batch adversarial loss: 0.448627\n",
      "epoch 161; iter: 0; batch classifier loss: 0.023229; batch adversarial loss: 0.504813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.033510; batch adversarial loss: 0.486308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.014545; batch adversarial loss: 0.442425\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050629; batch adversarial loss: 0.466399\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016407; batch adversarial loss: 0.416266\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020595; batch adversarial loss: 0.453963\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016635; batch adversarial loss: 0.394214\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035837; batch adversarial loss: 0.446441\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046290; batch adversarial loss: 0.464809\n",
      "epoch 170; iter: 0; batch classifier loss: 0.038438; batch adversarial loss: 0.533912\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025792; batch adversarial loss: 0.455412\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004088; batch adversarial loss: 0.469145\n",
      "epoch 173; iter: 0; batch classifier loss: 0.031454; batch adversarial loss: 0.443730\n",
      "epoch 174; iter: 0; batch classifier loss: 0.050869; batch adversarial loss: 0.392491\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011486; batch adversarial loss: 0.463274\n",
      "epoch 176; iter: 0; batch classifier loss: 0.044842; batch adversarial loss: 0.481420\n",
      "epoch 177; iter: 0; batch classifier loss: 0.033461; batch adversarial loss: 0.366586\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030627; batch adversarial loss: 0.427928\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048125; batch adversarial loss: 0.467388\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010198; batch adversarial loss: 0.454434\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020670; batch adversarial loss: 0.501779\n",
      "epoch 182; iter: 0; batch classifier loss: 0.083815; batch adversarial loss: 0.481806\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034884; batch adversarial loss: 0.469172\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044986; batch adversarial loss: 0.463198\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006319; batch adversarial loss: 0.430243\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035029; batch adversarial loss: 0.386048\n",
      "epoch 187; iter: 0; batch classifier loss: 0.040401; batch adversarial loss: 0.384318\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045623; batch adversarial loss: 0.405517\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021959; batch adversarial loss: 0.481311\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024409; batch adversarial loss: 0.435077\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019049; batch adversarial loss: 0.469029\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033029; batch adversarial loss: 0.380234\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031079; batch adversarial loss: 0.387508\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011371; batch adversarial loss: 0.492668\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024564; batch adversarial loss: 0.467549\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023339; batch adversarial loss: 0.493631\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018701; batch adversarial loss: 0.500695\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022345; batch adversarial loss: 0.469473\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013700; batch adversarial loss: 0.495089\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700536; batch adversarial loss: 1.047335\n",
      "epoch 1; iter: 0; batch classifier loss: 0.756785; batch adversarial loss: 1.170506\n",
      "epoch 2; iter: 0; batch classifier loss: 0.996758; batch adversarial loss: 1.232310\n",
      "epoch 3; iter: 0; batch classifier loss: 0.996105; batch adversarial loss: 1.121867\n",
      "epoch 4; iter: 0; batch classifier loss: 1.139678; batch adversarial loss: 1.033132\n",
      "epoch 5; iter: 0; batch classifier loss: 1.169404; batch adversarial loss: 0.929549\n",
      "epoch 6; iter: 0; batch classifier loss: 1.071653; batch adversarial loss: 0.842288\n",
      "epoch 7; iter: 0; batch classifier loss: 1.092760; batch adversarial loss: 0.778883\n",
      "epoch 8; iter: 0; batch classifier loss: 1.156630; batch adversarial loss: 0.698375\n",
      "epoch 9; iter: 0; batch classifier loss: 1.241985; batch adversarial loss: 0.676129\n",
      "epoch 10; iter: 0; batch classifier loss: 1.112543; batch adversarial loss: 0.627939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.944594; batch adversarial loss: 0.592033\n",
      "epoch 12; iter: 0; batch classifier loss: 0.844921; batch adversarial loss: 0.518561\n",
      "epoch 13; iter: 0; batch classifier loss: 0.405496; batch adversarial loss: 0.491581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293513; batch adversarial loss: 0.526363\n",
      "epoch 15; iter: 0; batch classifier loss: 0.312305; batch adversarial loss: 0.531943\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243068; batch adversarial loss: 0.478540\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396429; batch adversarial loss: 0.476756\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273996; batch adversarial loss: 0.500672\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350568; batch adversarial loss: 0.472882\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279939; batch adversarial loss: 0.506130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.281423; batch adversarial loss: 0.523149\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304816; batch adversarial loss: 0.490673\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273023; batch adversarial loss: 0.472395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233536; batch adversarial loss: 0.473942\n",
      "epoch 25; iter: 0; batch classifier loss: 0.281358; batch adversarial loss: 0.495107\n",
      "epoch 26; iter: 0; batch classifier loss: 0.292871; batch adversarial loss: 0.473611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210930; batch adversarial loss: 0.430590\n",
      "epoch 28; iter: 0; batch classifier loss: 0.366519; batch adversarial loss: 0.475324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.237500; batch adversarial loss: 0.484140\n",
      "epoch 30; iter: 0; batch classifier loss: 0.276234; batch adversarial loss: 0.446858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.280957; batch adversarial loss: 0.491351\n",
      "epoch 32; iter: 0; batch classifier loss: 0.203675; batch adversarial loss: 0.499864\n",
      "epoch 33; iter: 0; batch classifier loss: 0.333110; batch adversarial loss: 0.433181\n",
      "epoch 34; iter: 0; batch classifier loss: 0.234913; batch adversarial loss: 0.568525\n",
      "epoch 35; iter: 0; batch classifier loss: 0.289757; batch adversarial loss: 0.500216\n",
      "epoch 36; iter: 0; batch classifier loss: 0.228158; batch adversarial loss: 0.434353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.157099; batch adversarial loss: 0.432317\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225821; batch adversarial loss: 0.488100\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251086; batch adversarial loss: 0.399107\n",
      "epoch 40; iter: 0; batch classifier loss: 0.237301; batch adversarial loss: 0.425384\n",
      "epoch 41; iter: 0; batch classifier loss: 0.278438; batch adversarial loss: 0.412383\n",
      "epoch 42; iter: 0; batch classifier loss: 0.172017; batch adversarial loss: 0.471195\n",
      "epoch 43; iter: 0; batch classifier loss: 0.217145; batch adversarial loss: 0.432961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185603; batch adversarial loss: 0.457768\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140224; batch adversarial loss: 0.463170\n",
      "epoch 46; iter: 0; batch classifier loss: 0.159334; batch adversarial loss: 0.497840\n",
      "epoch 47; iter: 0; batch classifier loss: 0.178139; batch adversarial loss: 0.401593\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258648; batch adversarial loss: 0.352719\n",
      "epoch 49; iter: 0; batch classifier loss: 0.198573; batch adversarial loss: 0.388654\n",
      "epoch 50; iter: 0; batch classifier loss: 0.233143; batch adversarial loss: 0.475161\n",
      "epoch 51; iter: 0; batch classifier loss: 0.167487; batch adversarial loss: 0.475464\n",
      "epoch 52; iter: 0; batch classifier loss: 0.151407; batch adversarial loss: 0.451954\n",
      "epoch 53; iter: 0; batch classifier loss: 0.177231; batch adversarial loss: 0.475593\n",
      "epoch 54; iter: 0; batch classifier loss: 0.174981; batch adversarial loss: 0.476257\n",
      "epoch 55; iter: 0; batch classifier loss: 0.184682; batch adversarial loss: 0.457925\n",
      "epoch 56; iter: 0; batch classifier loss: 0.208565; batch adversarial loss: 0.472366\n",
      "epoch 57; iter: 0; batch classifier loss: 0.201614; batch adversarial loss: 0.361427\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200580; batch adversarial loss: 0.413314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.165416; batch adversarial loss: 0.454639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60; iter: 0; batch classifier loss: 0.142398; batch adversarial loss: 0.401442\n",
      "epoch 61; iter: 0; batch classifier loss: 0.164443; batch adversarial loss: 0.447809\n",
      "epoch 62; iter: 0; batch classifier loss: 0.121331; batch adversarial loss: 0.530458\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187564; batch adversarial loss: 0.505048\n",
      "epoch 64; iter: 0; batch classifier loss: 0.154442; batch adversarial loss: 0.446670\n",
      "epoch 65; iter: 0; batch classifier loss: 0.172118; batch adversarial loss: 0.457543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.164972; batch adversarial loss: 0.480244\n",
      "epoch 67; iter: 0; batch classifier loss: 0.170359; batch adversarial loss: 0.505320\n",
      "epoch 68; iter: 0; batch classifier loss: 0.140764; batch adversarial loss: 0.445443\n",
      "epoch 69; iter: 0; batch classifier loss: 0.147814; batch adversarial loss: 0.426056\n",
      "epoch 70; iter: 0; batch classifier loss: 0.165831; batch adversarial loss: 0.528430\n",
      "epoch 71; iter: 0; batch classifier loss: 0.150619; batch adversarial loss: 0.500419\n",
      "epoch 72; iter: 0; batch classifier loss: 0.138075; batch adversarial loss: 0.493213\n",
      "epoch 73; iter: 0; batch classifier loss: 0.150953; batch adversarial loss: 0.458657\n",
      "epoch 74; iter: 0; batch classifier loss: 0.206443; batch adversarial loss: 0.472415\n",
      "epoch 75; iter: 0; batch classifier loss: 0.132655; batch adversarial loss: 0.553370\n",
      "epoch 76; iter: 0; batch classifier loss: 0.157543; batch adversarial loss: 0.409124\n",
      "epoch 77; iter: 0; batch classifier loss: 0.178450; batch adversarial loss: 0.491488\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167748; batch adversarial loss: 0.519412\n",
      "epoch 79; iter: 0; batch classifier loss: 0.208400; batch adversarial loss: 0.399197\n",
      "epoch 80; iter: 0; batch classifier loss: 0.129744; batch adversarial loss: 0.485101\n",
      "epoch 81; iter: 0; batch classifier loss: 0.169643; batch adversarial loss: 0.493314\n",
      "epoch 82; iter: 0; batch classifier loss: 0.175499; batch adversarial loss: 0.420443\n",
      "epoch 83; iter: 0; batch classifier loss: 0.143325; batch adversarial loss: 0.436385\n",
      "epoch 84; iter: 0; batch classifier loss: 0.152818; batch adversarial loss: 0.557288\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157558; batch adversarial loss: 0.501821\n",
      "epoch 86; iter: 0; batch classifier loss: 0.157147; batch adversarial loss: 0.421059\n",
      "epoch 87; iter: 0; batch classifier loss: 0.190766; batch adversarial loss: 0.418908\n",
      "epoch 88; iter: 0; batch classifier loss: 0.177858; batch adversarial loss: 0.449453\n",
      "epoch 89; iter: 0; batch classifier loss: 0.135615; batch adversarial loss: 0.454739\n",
      "epoch 90; iter: 0; batch classifier loss: 0.170780; batch adversarial loss: 0.456658\n",
      "epoch 91; iter: 0; batch classifier loss: 0.183299; batch adversarial loss: 0.519681\n",
      "epoch 92; iter: 0; batch classifier loss: 0.166651; batch adversarial loss: 0.480262\n",
      "epoch 93; iter: 0; batch classifier loss: 0.184865; batch adversarial loss: 0.407717\n",
      "epoch 94; iter: 0; batch classifier loss: 0.174549; batch adversarial loss: 0.459116\n",
      "epoch 95; iter: 0; batch classifier loss: 0.182192; batch adversarial loss: 0.412763\n",
      "epoch 96; iter: 0; batch classifier loss: 0.158270; batch adversarial loss: 0.457475\n",
      "epoch 97; iter: 0; batch classifier loss: 0.219184; batch adversarial loss: 0.410398\n",
      "epoch 98; iter: 0; batch classifier loss: 0.198023; batch adversarial loss: 0.508467\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187641; batch adversarial loss: 0.399703\n",
      "epoch 100; iter: 0; batch classifier loss: 0.176795; batch adversarial loss: 0.485661\n",
      "epoch 101; iter: 0; batch classifier loss: 0.117654; batch adversarial loss: 0.520575\n",
      "epoch 102; iter: 0; batch classifier loss: 0.152482; batch adversarial loss: 0.495406\n",
      "epoch 103; iter: 0; batch classifier loss: 0.175159; batch adversarial loss: 0.459235\n",
      "epoch 104; iter: 0; batch classifier loss: 0.162034; batch adversarial loss: 0.422004\n",
      "epoch 105; iter: 0; batch classifier loss: 0.120295; batch adversarial loss: 0.420209\n",
      "epoch 106; iter: 0; batch classifier loss: 0.215897; batch adversarial loss: 0.457651\n",
      "epoch 107; iter: 0; batch classifier loss: 0.194235; batch adversarial loss: 0.469265\n",
      "epoch 108; iter: 0; batch classifier loss: 0.168320; batch adversarial loss: 0.397343\n",
      "epoch 109; iter: 0; batch classifier loss: 0.128720; batch adversarial loss: 0.421662\n",
      "epoch 110; iter: 0; batch classifier loss: 0.150954; batch adversarial loss: 0.595355\n",
      "epoch 111; iter: 0; batch classifier loss: 0.151693; batch adversarial loss: 0.446841\n",
      "epoch 112; iter: 0; batch classifier loss: 0.170417; batch adversarial loss: 0.421740\n",
      "epoch 113; iter: 0; batch classifier loss: 0.162127; batch adversarial loss: 0.519967\n",
      "epoch 114; iter: 0; batch classifier loss: 0.195891; batch adversarial loss: 0.409878\n",
      "epoch 115; iter: 0; batch classifier loss: 0.139792; batch adversarial loss: 0.386039\n",
      "epoch 116; iter: 0; batch classifier loss: 0.152084; batch adversarial loss: 0.422830\n",
      "epoch 117; iter: 0; batch classifier loss: 0.233438; batch adversarial loss: 0.519503\n",
      "epoch 118; iter: 0; batch classifier loss: 0.171407; batch adversarial loss: 0.483072\n",
      "epoch 119; iter: 0; batch classifier loss: 0.158641; batch adversarial loss: 0.472438\n",
      "epoch 120; iter: 0; batch classifier loss: 0.198212; batch adversarial loss: 0.508461\n",
      "epoch 121; iter: 0; batch classifier loss: 0.117407; batch adversarial loss: 0.409778\n",
      "epoch 122; iter: 0; batch classifier loss: 0.162286; batch adversarial loss: 0.409986\n",
      "epoch 123; iter: 0; batch classifier loss: 0.194853; batch adversarial loss: 0.520813\n",
      "epoch 124; iter: 0; batch classifier loss: 0.169219; batch adversarial loss: 0.520558\n",
      "epoch 125; iter: 0; batch classifier loss: 0.129662; batch adversarial loss: 0.434252\n",
      "epoch 126; iter: 0; batch classifier loss: 0.182732; batch adversarial loss: 0.496151\n",
      "epoch 127; iter: 0; batch classifier loss: 0.132082; batch adversarial loss: 0.483065\n",
      "epoch 128; iter: 0; batch classifier loss: 0.145310; batch adversarial loss: 0.482693\n",
      "epoch 129; iter: 0; batch classifier loss: 0.216264; batch adversarial loss: 0.409821\n",
      "epoch 130; iter: 0; batch classifier loss: 0.222826; batch adversarial loss: 0.446492\n",
      "epoch 131; iter: 0; batch classifier loss: 0.152145; batch adversarial loss: 0.360691\n",
      "epoch 132; iter: 0; batch classifier loss: 0.220402; batch adversarial loss: 0.373663\n",
      "epoch 133; iter: 0; batch classifier loss: 0.141001; batch adversarial loss: 0.397096\n",
      "epoch 134; iter: 0; batch classifier loss: 0.147713; batch adversarial loss: 0.544378\n",
      "epoch 135; iter: 0; batch classifier loss: 0.184014; batch adversarial loss: 0.483403\n",
      "epoch 136; iter: 0; batch classifier loss: 0.145346; batch adversarial loss: 0.555503\n",
      "epoch 137; iter: 0; batch classifier loss: 0.170122; batch adversarial loss: 0.446112\n",
      "epoch 138; iter: 0; batch classifier loss: 0.179637; batch adversarial loss: 0.433550\n",
      "epoch 139; iter: 0; batch classifier loss: 0.178856; batch adversarial loss: 0.458848\n",
      "epoch 140; iter: 0; batch classifier loss: 0.166416; batch adversarial loss: 0.471858\n",
      "epoch 141; iter: 0; batch classifier loss: 0.157547; batch adversarial loss: 0.483125\n",
      "epoch 142; iter: 0; batch classifier loss: 0.133939; batch adversarial loss: 0.446497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.122689; batch adversarial loss: 0.458908\n",
      "epoch 144; iter: 0; batch classifier loss: 0.149295; batch adversarial loss: 0.519671\n",
      "epoch 145; iter: 0; batch classifier loss: 0.152479; batch adversarial loss: 0.482881\n",
      "epoch 146; iter: 0; batch classifier loss: 0.205341; batch adversarial loss: 0.470607\n",
      "epoch 147; iter: 0; batch classifier loss: 0.208112; batch adversarial loss: 0.458657\n",
      "epoch 148; iter: 0; batch classifier loss: 0.139337; batch adversarial loss: 0.495999\n",
      "epoch 149; iter: 0; batch classifier loss: 0.183581; batch adversarial loss: 0.397221\n",
      "epoch 150; iter: 0; batch classifier loss: 0.182198; batch adversarial loss: 0.556923\n",
      "epoch 151; iter: 0; batch classifier loss: 0.152702; batch adversarial loss: 0.483275\n",
      "epoch 152; iter: 0; batch classifier loss: 0.175574; batch adversarial loss: 0.385852\n",
      "epoch 153; iter: 0; batch classifier loss: 0.191684; batch adversarial loss: 0.532271\n",
      "epoch 154; iter: 0; batch classifier loss: 0.205619; batch adversarial loss: 0.348798\n",
      "epoch 155; iter: 0; batch classifier loss: 0.119583; batch adversarial loss: 0.385524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 156; iter: 0; batch classifier loss: 0.177923; batch adversarial loss: 0.434285\n",
      "epoch 157; iter: 0; batch classifier loss: 0.109001; batch adversarial loss: 0.471424\n",
      "epoch 158; iter: 0; batch classifier loss: 0.151656; batch adversarial loss: 0.556882\n",
      "epoch 159; iter: 0; batch classifier loss: 0.151720; batch adversarial loss: 0.531920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.170588; batch adversarial loss: 0.495915\n",
      "epoch 161; iter: 0; batch classifier loss: 0.150085; batch adversarial loss: 0.447118\n",
      "epoch 162; iter: 0; batch classifier loss: 0.171424; batch adversarial loss: 0.422152\n",
      "epoch 163; iter: 0; batch classifier loss: 0.139874; batch adversarial loss: 0.336308\n",
      "epoch 164; iter: 0; batch classifier loss: 0.135019; batch adversarial loss: 0.434166\n",
      "epoch 165; iter: 0; batch classifier loss: 0.145861; batch adversarial loss: 0.470212\n",
      "epoch 166; iter: 0; batch classifier loss: 0.150808; batch adversarial loss: 0.457476\n",
      "epoch 167; iter: 0; batch classifier loss: 0.167891; batch adversarial loss: 0.531965\n",
      "epoch 168; iter: 0; batch classifier loss: 0.168850; batch adversarial loss: 0.532066\n",
      "epoch 169; iter: 0; batch classifier loss: 0.185856; batch adversarial loss: 0.447216\n",
      "epoch 170; iter: 0; batch classifier loss: 0.195112; batch adversarial loss: 0.409095\n",
      "epoch 171; iter: 0; batch classifier loss: 0.150000; batch adversarial loss: 0.472457\n",
      "epoch 172; iter: 0; batch classifier loss: 0.167471; batch adversarial loss: 0.543361\n",
      "epoch 173; iter: 0; batch classifier loss: 0.155908; batch adversarial loss: 0.459294\n",
      "epoch 174; iter: 0; batch classifier loss: 0.142345; batch adversarial loss: 0.409535\n",
      "epoch 175; iter: 0; batch classifier loss: 0.185180; batch adversarial loss: 0.458868\n",
      "epoch 176; iter: 0; batch classifier loss: 0.171143; batch adversarial loss: 0.385482\n",
      "epoch 177; iter: 0; batch classifier loss: 0.146047; batch adversarial loss: 0.483221\n",
      "epoch 178; iter: 0; batch classifier loss: 0.192026; batch adversarial loss: 0.385225\n",
      "epoch 179; iter: 0; batch classifier loss: 0.152397; batch adversarial loss: 0.397878\n",
      "epoch 180; iter: 0; batch classifier loss: 0.202590; batch adversarial loss: 0.446920\n",
      "epoch 181; iter: 0; batch classifier loss: 0.164370; batch adversarial loss: 0.496285\n",
      "epoch 182; iter: 0; batch classifier loss: 0.123860; batch adversarial loss: 0.532665\n",
      "epoch 183; iter: 0; batch classifier loss: 0.214310; batch adversarial loss: 0.532781\n",
      "epoch 184; iter: 0; batch classifier loss: 0.159654; batch adversarial loss: 0.433740\n",
      "epoch 185; iter: 0; batch classifier loss: 0.205415; batch adversarial loss: 0.447606\n",
      "epoch 186; iter: 0; batch classifier loss: 0.174569; batch adversarial loss: 0.495839\n",
      "epoch 187; iter: 0; batch classifier loss: 0.139186; batch adversarial loss: 0.422775\n",
      "epoch 188; iter: 0; batch classifier loss: 0.183313; batch adversarial loss: 0.495408\n",
      "epoch 189; iter: 0; batch classifier loss: 0.148779; batch adversarial loss: 0.445653\n",
      "epoch 190; iter: 0; batch classifier loss: 0.148075; batch adversarial loss: 0.421989\n",
      "epoch 191; iter: 0; batch classifier loss: 0.187919; batch adversarial loss: 0.447606\n",
      "epoch 192; iter: 0; batch classifier loss: 0.196560; batch adversarial loss: 0.409454\n",
      "epoch 193; iter: 0; batch classifier loss: 0.201472; batch adversarial loss: 0.507477\n",
      "epoch 194; iter: 0; batch classifier loss: 0.087564; batch adversarial loss: 0.507888\n",
      "epoch 195; iter: 0; batch classifier loss: 0.161817; batch adversarial loss: 0.483435\n",
      "epoch 196; iter: 0; batch classifier loss: 0.194529; batch adversarial loss: 0.446281\n",
      "epoch 197; iter: 0; batch classifier loss: 0.144075; batch adversarial loss: 0.434533\n",
      "epoch 198; iter: 0; batch classifier loss: 0.220907; batch adversarial loss: 0.445640\n",
      "epoch 199; iter: 0; batch classifier loss: 0.213529; batch adversarial loss: 0.410228\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700938; batch adversarial loss: 0.668970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.366815; batch adversarial loss: 0.671997\n",
      "epoch 2; iter: 0; batch classifier loss: 0.377434; batch adversarial loss: 0.627046\n",
      "epoch 3; iter: 0; batch classifier loss: 0.309440; batch adversarial loss: 0.597874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435222; batch adversarial loss: 0.573861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369886; batch adversarial loss: 0.534749\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326612; batch adversarial loss: 0.508363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319764; batch adversarial loss: 0.493474\n",
      "epoch 8; iter: 0; batch classifier loss: 0.222756; batch adversarial loss: 0.495606\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244503; batch adversarial loss: 0.489107\n",
      "epoch 10; iter: 0; batch classifier loss: 0.185015; batch adversarial loss: 0.513756\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288896; batch adversarial loss: 0.489429\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227000; batch adversarial loss: 0.473952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.209123; batch adversarial loss: 0.463077\n",
      "epoch 14; iter: 0; batch classifier loss: 0.176266; batch adversarial loss: 0.464782\n",
      "epoch 15; iter: 0; batch classifier loss: 0.154120; batch adversarial loss: 0.428318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.190368; batch adversarial loss: 0.505854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.159919; batch adversarial loss: 0.403030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.173404; batch adversarial loss: 0.497242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.179307; batch adversarial loss: 0.473592\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204199; batch adversarial loss: 0.460292\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171875; batch adversarial loss: 0.473786\n",
      "epoch 22; iter: 0; batch classifier loss: 0.106088; batch adversarial loss: 0.498142\n",
      "epoch 23; iter: 0; batch classifier loss: 0.157222; batch adversarial loss: 0.413641\n",
      "epoch 24; iter: 0; batch classifier loss: 0.155694; batch adversarial loss: 0.497759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.149151; batch adversarial loss: 0.441800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208167; batch adversarial loss: 0.448374\n",
      "epoch 27; iter: 0; batch classifier loss: 0.296102; batch adversarial loss: 0.545645\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186334; batch adversarial loss: 0.403283\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178673; batch adversarial loss: 0.529690\n",
      "epoch 30; iter: 0; batch classifier loss: 0.191768; batch adversarial loss: 0.478985\n",
      "epoch 31; iter: 0; batch classifier loss: 0.206897; batch adversarial loss: 0.445078\n",
      "epoch 32; iter: 0; batch classifier loss: 0.171893; batch adversarial loss: 0.492971\n",
      "epoch 33; iter: 0; batch classifier loss: 0.325937; batch adversarial loss: 0.501059\n",
      "epoch 34; iter: 0; batch classifier loss: 0.275517; batch adversarial loss: 0.431805\n",
      "epoch 35; iter: 0; batch classifier loss: 0.148217; batch adversarial loss: 0.448019\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092849; batch adversarial loss: 0.397211\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111970; batch adversarial loss: 0.376969\n",
      "epoch 38; iter: 0; batch classifier loss: 0.126338; batch adversarial loss: 0.441707\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102917; batch adversarial loss: 0.452507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.072670; batch adversarial loss: 0.483306\n",
      "epoch 41; iter: 0; batch classifier loss: 0.129412; batch adversarial loss: 0.390448\n",
      "epoch 42; iter: 0; batch classifier loss: 0.092826; batch adversarial loss: 0.462785\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078440; batch adversarial loss: 0.549364\n",
      "epoch 44; iter: 0; batch classifier loss: 0.083482; batch adversarial loss: 0.413329\n",
      "epoch 45; iter: 0; batch classifier loss: 0.084940; batch adversarial loss: 0.513833\n",
      "epoch 46; iter: 0; batch classifier loss: 0.112497; batch adversarial loss: 0.402544\n",
      "epoch 47; iter: 0; batch classifier loss: 0.081652; batch adversarial loss: 0.531217\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086257; batch adversarial loss: 0.489630\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080753; batch adversarial loss: 0.355616\n",
      "epoch 50; iter: 0; batch classifier loss: 0.055361; batch adversarial loss: 0.462896\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122305; batch adversarial loss: 0.441813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.101150; batch adversarial loss: 0.402807\n",
      "epoch 53; iter: 0; batch classifier loss: 0.074814; batch adversarial loss: 0.489601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.108051; batch adversarial loss: 0.406947\n",
      "epoch 55; iter: 0; batch classifier loss: 0.075195; batch adversarial loss: 0.515784\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114982; batch adversarial loss: 0.430326\n",
      "epoch 57; iter: 0; batch classifier loss: 0.125281; batch adversarial loss: 0.490607\n",
      "epoch 58; iter: 0; batch classifier loss: 0.079104; batch adversarial loss: 0.444762\n",
      "epoch 59; iter: 0; batch classifier loss: 0.059988; batch adversarial loss: 0.456433\n",
      "epoch 60; iter: 0; batch classifier loss: 0.077503; batch adversarial loss: 0.458979\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051620; batch adversarial loss: 0.417650\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089172; batch adversarial loss: 0.421039\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096243; batch adversarial loss: 0.506935\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072909; batch adversarial loss: 0.432025\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064894; batch adversarial loss: 0.499740\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062506; batch adversarial loss: 0.416921\n",
      "epoch 67; iter: 0; batch classifier loss: 0.105776; batch adversarial loss: 0.466246\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152052; batch adversarial loss: 0.478116\n",
      "epoch 69; iter: 0; batch classifier loss: 0.079170; batch adversarial loss: 0.448795\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065804; batch adversarial loss: 0.442233\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061462; batch adversarial loss: 0.452291\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064370; batch adversarial loss: 0.466135\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092804; batch adversarial loss: 0.468976\n",
      "epoch 74; iter: 0; batch classifier loss: 0.080217; batch adversarial loss: 0.541295\n",
      "epoch 75; iter: 0; batch classifier loss: 0.079770; batch adversarial loss: 0.414772\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089071; batch adversarial loss: 0.413542\n",
      "epoch 77; iter: 0; batch classifier loss: 0.090243; batch adversarial loss: 0.538629\n",
      "epoch 78; iter: 0; batch classifier loss: 0.047394; batch adversarial loss: 0.411636\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080360; batch adversarial loss: 0.538761\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080391; batch adversarial loss: 0.569900\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101576; batch adversarial loss: 0.307358\n",
      "epoch 82; iter: 0; batch classifier loss: 0.116888; batch adversarial loss: 0.432913\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070792; batch adversarial loss: 0.546738\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053685; batch adversarial loss: 0.468327\n",
      "epoch 85; iter: 0; batch classifier loss: 0.027390; batch adversarial loss: 0.369853\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083653; batch adversarial loss: 0.441220\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053390; batch adversarial loss: 0.477524\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077579; batch adversarial loss: 0.416175\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038981; batch adversarial loss: 0.401175\n",
      "epoch 90; iter: 0; batch classifier loss: 0.031354; batch adversarial loss: 0.505186\n",
      "epoch 91; iter: 0; batch classifier loss: 0.075812; batch adversarial loss: 0.425052\n",
      "epoch 92; iter: 0; batch classifier loss: 0.026234; batch adversarial loss: 0.396870\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055127; batch adversarial loss: 0.466919\n",
      "epoch 94; iter: 0; batch classifier loss: 0.073029; batch adversarial loss: 0.508498\n",
      "epoch 95; iter: 0; batch classifier loss: 0.107376; batch adversarial loss: 0.417301\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069477; batch adversarial loss: 0.341506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085400; batch adversarial loss: 0.518993\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040664; batch adversarial loss: 0.473275\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065278; batch adversarial loss: 0.363676\n",
      "epoch 100; iter: 0; batch classifier loss: 0.022790; batch adversarial loss: 0.503846\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074138; batch adversarial loss: 0.436128\n",
      "epoch 102; iter: 0; batch classifier loss: 0.048778; batch adversarial loss: 0.530876\n",
      "epoch 103; iter: 0; batch classifier loss: 0.085867; batch adversarial loss: 0.498089\n",
      "epoch 104; iter: 0; batch classifier loss: 0.035287; batch adversarial loss: 0.484590\n",
      "epoch 105; iter: 0; batch classifier loss: 0.068052; batch adversarial loss: 0.422439\n",
      "epoch 106; iter: 0; batch classifier loss: 0.054141; batch adversarial loss: 0.358836\n",
      "epoch 107; iter: 0; batch classifier loss: 0.118387; batch adversarial loss: 0.348430\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049530; batch adversarial loss: 0.505660\n",
      "epoch 109; iter: 0; batch classifier loss: 0.066872; batch adversarial loss: 0.551437\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027933; batch adversarial loss: 0.307675\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054092; batch adversarial loss: 0.399168\n",
      "epoch 112; iter: 0; batch classifier loss: 0.029351; batch adversarial loss: 0.421089\n",
      "epoch 113; iter: 0; batch classifier loss: 0.073050; batch adversarial loss: 0.474937\n",
      "epoch 114; iter: 0; batch classifier loss: 0.065211; batch adversarial loss: 0.456527\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042588; batch adversarial loss: 0.465977\n",
      "epoch 116; iter: 0; batch classifier loss: 0.072469; batch adversarial loss: 0.426924\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034012; batch adversarial loss: 0.460536\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067006; batch adversarial loss: 0.414774\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041394; batch adversarial loss: 0.425097\n",
      "epoch 120; iter: 0; batch classifier loss: 0.016863; batch adversarial loss: 0.504378\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029521; batch adversarial loss: 0.525557\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025675; batch adversarial loss: 0.512273\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029412; batch adversarial loss: 0.517850\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026277; batch adversarial loss: 0.455354\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026285; batch adversarial loss: 0.427591\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033389; batch adversarial loss: 0.440381\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044067; batch adversarial loss: 0.382595\n",
      "epoch 128; iter: 0; batch classifier loss: 0.056737; batch adversarial loss: 0.415983\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052552; batch adversarial loss: 0.461210\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039715; batch adversarial loss: 0.433669\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031665; batch adversarial loss: 0.382479\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031885; batch adversarial loss: 0.390928\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025026; batch adversarial loss: 0.466892\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030744; batch adversarial loss: 0.450648\n",
      "epoch 135; iter: 0; batch classifier loss: 0.073866; batch adversarial loss: 0.460050\n",
      "epoch 136; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.501635\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026080; batch adversarial loss: 0.342813\n",
      "epoch 138; iter: 0; batch classifier loss: 0.050795; batch adversarial loss: 0.516005\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034617; batch adversarial loss: 0.397165\n",
      "epoch 140; iter: 0; batch classifier loss: 0.033439; batch adversarial loss: 0.399715\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019913; batch adversarial loss: 0.421004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.015159; batch adversarial loss: 0.410550\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042299; batch adversarial loss: 0.422750\n",
      "epoch 144; iter: 0; batch classifier loss: 0.017108; batch adversarial loss: 0.496895\n",
      "epoch 145; iter: 0; batch classifier loss: 0.030998; batch adversarial loss: 0.372293\n",
      "epoch 146; iter: 0; batch classifier loss: 0.020710; batch adversarial loss: 0.413947\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030119; batch adversarial loss: 0.562358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.036818; batch adversarial loss: 0.413581\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024384; batch adversarial loss: 0.421553\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013464; batch adversarial loss: 0.564816\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.437978\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023253; batch adversarial loss: 0.428858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029971; batch adversarial loss: 0.553354\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026625; batch adversarial loss: 0.431731\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044049; batch adversarial loss: 0.452236\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025743; batch adversarial loss: 0.470657\n",
      "epoch 157; iter: 0; batch classifier loss: 0.037847; batch adversarial loss: 0.416840\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024787; batch adversarial loss: 0.391431\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045734; batch adversarial loss: 0.485810\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036238; batch adversarial loss: 0.441948\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022589; batch adversarial loss: 0.459211\n",
      "epoch 162; iter: 0; batch classifier loss: 0.004286; batch adversarial loss: 0.483091\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019424; batch adversarial loss: 0.428451\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041236; batch adversarial loss: 0.425734\n",
      "epoch 165; iter: 0; batch classifier loss: 0.015445; batch adversarial loss: 0.397631\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025383; batch adversarial loss: 0.478730\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029100; batch adversarial loss: 0.456983\n",
      "epoch 168; iter: 0; batch classifier loss: 0.040599; batch adversarial loss: 0.428460\n",
      "epoch 169; iter: 0; batch classifier loss: 0.013520; batch adversarial loss: 0.410563\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026711; batch adversarial loss: 0.415291\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015946; batch adversarial loss: 0.406528\n",
      "epoch 172; iter: 0; batch classifier loss: 0.023829; batch adversarial loss: 0.520520\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026249; batch adversarial loss: 0.418861\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015350; batch adversarial loss: 0.521284\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011987; batch adversarial loss: 0.444462\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016010; batch adversarial loss: 0.475202\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022951; batch adversarial loss: 0.381590\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014289; batch adversarial loss: 0.393077\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029992; batch adversarial loss: 0.483902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.040208; batch adversarial loss: 0.418822\n",
      "epoch 181; iter: 0; batch classifier loss: 0.034320; batch adversarial loss: 0.526248\n",
      "epoch 182; iter: 0; batch classifier loss: 0.063036; batch adversarial loss: 0.459102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.012921; batch adversarial loss: 0.449213\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022203; batch adversarial loss: 0.440137\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015249; batch adversarial loss: 0.505792\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014236; batch adversarial loss: 0.547388\n",
      "epoch 187; iter: 0; batch classifier loss: 0.023171; batch adversarial loss: 0.523329\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012668; batch adversarial loss: 0.444918\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018388; batch adversarial loss: 0.459153\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010308; batch adversarial loss: 0.515550\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011501; batch adversarial loss: 0.466650\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022909; batch adversarial loss: 0.439904\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042984; batch adversarial loss: 0.442795\n",
      "epoch 194; iter: 0; batch classifier loss: 0.042230; batch adversarial loss: 0.408826\n",
      "epoch 195; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.469067\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017692; batch adversarial loss: 0.439377\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008760; batch adversarial loss: 0.453474\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027382; batch adversarial loss: 0.548095\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007637; batch adversarial loss: 0.502152\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725814; batch adversarial loss: 0.647327\n",
      "epoch 1; iter: 0; batch classifier loss: 0.334440; batch adversarial loss: 0.623011\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406469; batch adversarial loss: 0.599337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.418293; batch adversarial loss: 0.598866\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390178; batch adversarial loss: 0.553531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354232; batch adversarial loss: 0.580201\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327571; batch adversarial loss: 0.554211\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298875; batch adversarial loss: 0.573257\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376378; batch adversarial loss: 0.554762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.399960; batch adversarial loss: 0.509569\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348135; batch adversarial loss: 0.537343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349340; batch adversarial loss: 0.594568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489946; batch adversarial loss: 0.501653\n",
      "epoch 13; iter: 0; batch classifier loss: 0.548437; batch adversarial loss: 0.463082\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545570; batch adversarial loss: 0.473726\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292912; batch adversarial loss: 0.472239\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296513; batch adversarial loss: 0.470314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.266035; batch adversarial loss: 0.483502\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243165; batch adversarial loss: 0.464446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.283337; batch adversarial loss: 0.463473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229924; batch adversarial loss: 0.386202\n",
      "epoch 21; iter: 0; batch classifier loss: 0.208793; batch adversarial loss: 0.503532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.249543; batch adversarial loss: 0.421335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.227203; batch adversarial loss: 0.447383\n",
      "epoch 24; iter: 0; batch classifier loss: 0.177358; batch adversarial loss: 0.432275\n",
      "epoch 25; iter: 0; batch classifier loss: 0.199490; batch adversarial loss: 0.539684\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208477; batch adversarial loss: 0.372802\n",
      "epoch 27; iter: 0; batch classifier loss: 0.192045; batch adversarial loss: 0.393496\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213640; batch adversarial loss: 0.397608\n",
      "epoch 29; iter: 0; batch classifier loss: 0.191791; batch adversarial loss: 0.539053\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176001; batch adversarial loss: 0.521560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.098909; batch adversarial loss: 0.480440\n",
      "epoch 32; iter: 0; batch classifier loss: 0.139777; batch adversarial loss: 0.391728\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164061; batch adversarial loss: 0.469039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.162944; batch adversarial loss: 0.498698\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127551; batch adversarial loss: 0.478083\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150958; batch adversarial loss: 0.523388\n",
      "epoch 37; iter: 0; batch classifier loss: 0.141818; batch adversarial loss: 0.439289\n",
      "epoch 38; iter: 0; batch classifier loss: 0.122763; batch adversarial loss: 0.439739\n",
      "epoch 39; iter: 0; batch classifier loss: 0.128183; batch adversarial loss: 0.413187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114451; batch adversarial loss: 0.437093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111836; batch adversarial loss: 0.403622\n",
      "epoch 42; iter: 0; batch classifier loss: 0.097059; batch adversarial loss: 0.452808\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149644; batch adversarial loss: 0.408501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.081034; batch adversarial loss: 0.530873\n",
      "epoch 45; iter: 0; batch classifier loss: 0.131766; batch adversarial loss: 0.499518\n",
      "epoch 46; iter: 0; batch classifier loss: 0.162546; batch adversarial loss: 0.558386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100818; batch adversarial loss: 0.513569\n",
      "epoch 48; iter: 0; batch classifier loss: 0.103645; batch adversarial loss: 0.394616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118967; batch adversarial loss: 0.452406\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089669; batch adversarial loss: 0.491606\n",
      "epoch 51; iter: 0; batch classifier loss: 0.132909; batch adversarial loss: 0.456788\n",
      "epoch 52; iter: 0; batch classifier loss: 0.095122; batch adversarial loss: 0.394860\n",
      "epoch 53; iter: 0; batch classifier loss: 0.082750; batch adversarial loss: 0.441562\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132632; batch adversarial loss: 0.368707\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123531; batch adversarial loss: 0.526280\n",
      "epoch 56; iter: 0; batch classifier loss: 0.146881; batch adversarial loss: 0.445781\n",
      "epoch 57; iter: 0; batch classifier loss: 0.112469; batch adversarial loss: 0.443847\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101464; batch adversarial loss: 0.446983\n",
      "epoch 59; iter: 0; batch classifier loss: 0.103994; batch adversarial loss: 0.369547\n",
      "epoch 60; iter: 0; batch classifier loss: 0.179481; batch adversarial loss: 0.318822\n",
      "epoch 61; iter: 0; batch classifier loss: 0.167231; batch adversarial loss: 0.436196\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127140; batch adversarial loss: 0.469626\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076098; batch adversarial loss: 0.411588\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122188; batch adversarial loss: 0.394965\n",
      "epoch 65; iter: 0; batch classifier loss: 0.140650; batch adversarial loss: 0.414978\n",
      "epoch 66; iter: 0; batch classifier loss: 0.120041; batch adversarial loss: 0.511433\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117086; batch adversarial loss: 0.502900\n",
      "epoch 68; iter: 0; batch classifier loss: 0.128606; batch adversarial loss: 0.468566\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076365; batch adversarial loss: 0.467149\n",
      "epoch 70; iter: 0; batch classifier loss: 0.127955; batch adversarial loss: 0.449899\n",
      "epoch 71; iter: 0; batch classifier loss: 0.124591; batch adversarial loss: 0.506912\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102494; batch adversarial loss: 0.413508\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069597; batch adversarial loss: 0.480927\n",
      "epoch 74; iter: 0; batch classifier loss: 0.129195; batch adversarial loss: 0.496173\n",
      "epoch 75; iter: 0; batch classifier loss: 0.116684; batch adversarial loss: 0.581167\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065270; batch adversarial loss: 0.514760\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114675; batch adversarial loss: 0.444495\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091119; batch adversarial loss: 0.453247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112280; batch adversarial loss: 0.420682\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114310; batch adversarial loss: 0.376336\n",
      "epoch 81; iter: 0; batch classifier loss: 0.101164; batch adversarial loss: 0.489757\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068238; batch adversarial loss: 0.595668\n",
      "epoch 83; iter: 0; batch classifier loss: 0.137691; batch adversarial loss: 0.558529\n",
      "epoch 84; iter: 0; batch classifier loss: 0.105200; batch adversarial loss: 0.429331\n",
      "epoch 85; iter: 0; batch classifier loss: 0.083466; batch adversarial loss: 0.494329\n",
      "epoch 86; iter: 0; batch classifier loss: 0.083392; batch adversarial loss: 0.488297\n",
      "epoch 87; iter: 0; batch classifier loss: 0.127407; batch adversarial loss: 0.374844\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089936; batch adversarial loss: 0.582577\n",
      "epoch 89; iter: 0; batch classifier loss: 0.105372; batch adversarial loss: 0.437415\n",
      "epoch 90; iter: 0; batch classifier loss: 0.090691; batch adversarial loss: 0.470970\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090714; batch adversarial loss: 0.449934\n",
      "epoch 92; iter: 0; batch classifier loss: 0.040735; batch adversarial loss: 0.596481\n",
      "epoch 93; iter: 0; batch classifier loss: 0.066125; batch adversarial loss: 0.545773\n",
      "epoch 94; iter: 0; batch classifier loss: 0.113622; batch adversarial loss: 0.344284\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060140; batch adversarial loss: 0.527182\n",
      "epoch 96; iter: 0; batch classifier loss: 0.080807; batch adversarial loss: 0.427021\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075142; batch adversarial loss: 0.440025\n",
      "epoch 98; iter: 0; batch classifier loss: 0.045851; batch adversarial loss: 0.439288\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071933; batch adversarial loss: 0.446954\n",
      "epoch 100; iter: 0; batch classifier loss: 0.081959; batch adversarial loss: 0.458978\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098771; batch adversarial loss: 0.416576\n",
      "epoch 102; iter: 0; batch classifier loss: 0.091363; batch adversarial loss: 0.449916\n",
      "epoch 103; iter: 0; batch classifier loss: 0.074283; batch adversarial loss: 0.438836\n",
      "epoch 104; iter: 0; batch classifier loss: 0.074691; batch adversarial loss: 0.395575\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054916; batch adversarial loss: 0.434417\n",
      "epoch 106; iter: 0; batch classifier loss: 0.124031; batch adversarial loss: 0.400154\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058604; batch adversarial loss: 0.470754\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045778; batch adversarial loss: 0.558551\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030001; batch adversarial loss: 0.427732\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045348; batch adversarial loss: 0.434335\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047346; batch adversarial loss: 0.501523\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035258; batch adversarial loss: 0.466009\n",
      "epoch 113; iter: 0; batch classifier loss: 0.100203; batch adversarial loss: 0.433224\n",
      "epoch 114; iter: 0; batch classifier loss: 0.071702; batch adversarial loss: 0.494847\n",
      "epoch 115; iter: 0; batch classifier loss: 0.117011; batch adversarial loss: 0.425123\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043217; batch adversarial loss: 0.451025\n",
      "epoch 117; iter: 0; batch classifier loss: 0.094659; batch adversarial loss: 0.390352\n",
      "epoch 118; iter: 0; batch classifier loss: 0.070609; batch adversarial loss: 0.421716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.052599; batch adversarial loss: 0.459340\n",
      "epoch 120; iter: 0; batch classifier loss: 0.054590; batch adversarial loss: 0.468823\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062719; batch adversarial loss: 0.473672\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037399; batch adversarial loss: 0.449205\n",
      "epoch 123; iter: 0; batch classifier loss: 0.072444; batch adversarial loss: 0.445316\n",
      "epoch 124; iter: 0; batch classifier loss: 0.088558; batch adversarial loss: 0.419274\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057161; batch adversarial loss: 0.390306\n",
      "epoch 126; iter: 0; batch classifier loss: 0.066802; batch adversarial loss: 0.399528\n",
      "epoch 127; iter: 0; batch classifier loss: 0.057434; batch adversarial loss: 0.402144\n",
      "epoch 128; iter: 0; batch classifier loss: 0.073323; batch adversarial loss: 0.407229\n",
      "epoch 129; iter: 0; batch classifier loss: 0.069356; batch adversarial loss: 0.525763\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025215; batch adversarial loss: 0.454575\n",
      "epoch 131; iter: 0; batch classifier loss: 0.042608; batch adversarial loss: 0.373402\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044772; batch adversarial loss: 0.435218\n",
      "epoch 133; iter: 0; batch classifier loss: 0.057141; batch adversarial loss: 0.497114\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017123; batch adversarial loss: 0.401410\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024852; batch adversarial loss: 0.357758\n",
      "epoch 136; iter: 0; batch classifier loss: 0.028183; batch adversarial loss: 0.525472\n",
      "epoch 137; iter: 0; batch classifier loss: 0.045547; batch adversarial loss: 0.447686\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035551; batch adversarial loss: 0.434512\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035066; batch adversarial loss: 0.495886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.036837; batch adversarial loss: 0.377511\n",
      "epoch 141; iter: 0; batch classifier loss: 0.053299; batch adversarial loss: 0.422404\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042627; batch adversarial loss: 0.440084\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055330; batch adversarial loss: 0.485676\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036138; batch adversarial loss: 0.464010\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053674; batch adversarial loss: 0.454691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039186; batch adversarial loss: 0.492398\n",
      "epoch 147; iter: 0; batch classifier loss: 0.091048; batch adversarial loss: 0.401142\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027849; batch adversarial loss: 0.396616\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040427; batch adversarial loss: 0.479049\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057156; batch adversarial loss: 0.478776\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023858; batch adversarial loss: 0.483502\n",
      "epoch 152; iter: 0; batch classifier loss: 0.050577; batch adversarial loss: 0.409311\n",
      "epoch 153; iter: 0; batch classifier loss: 0.049626; batch adversarial loss: 0.486768\n",
      "epoch 154; iter: 0; batch classifier loss: 0.053870; batch adversarial loss: 0.501701\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021217; batch adversarial loss: 0.480066\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019294; batch adversarial loss: 0.463131\n",
      "epoch 157; iter: 0; batch classifier loss: 0.083703; batch adversarial loss: 0.446424\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038746; batch adversarial loss: 0.430651\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040690; batch adversarial loss: 0.429456\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023404; batch adversarial loss: 0.530865\n",
      "epoch 161; iter: 0; batch classifier loss: 0.068022; batch adversarial loss: 0.460081\n",
      "epoch 162; iter: 0; batch classifier loss: 0.042573; batch adversarial loss: 0.398435\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034231; batch adversarial loss: 0.469117\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013433; batch adversarial loss: 0.521563\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017127; batch adversarial loss: 0.486367\n",
      "epoch 166; iter: 0; batch classifier loss: 0.042234; batch adversarial loss: 0.374665\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036898; batch adversarial loss: 0.402398\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026448; batch adversarial loss: 0.414457\n",
      "epoch 169; iter: 0; batch classifier loss: 0.029766; batch adversarial loss: 0.481678\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026076; batch adversarial loss: 0.435907\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013166; batch adversarial loss: 0.377081\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012039; batch adversarial loss: 0.554359\n",
      "epoch 173; iter: 0; batch classifier loss: 0.017129; batch adversarial loss: 0.365429\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023074; batch adversarial loss: 0.564107\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013034; batch adversarial loss: 0.425642\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025189; batch adversarial loss: 0.402463\n",
      "epoch 177; iter: 0; batch classifier loss: 0.016758; batch adversarial loss: 0.363531\n",
      "epoch 178; iter: 0; batch classifier loss: 0.049286; batch adversarial loss: 0.509702\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019501; batch adversarial loss: 0.488461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017679; batch adversarial loss: 0.561484\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014715; batch adversarial loss: 0.421881\n",
      "epoch 182; iter: 0; batch classifier loss: 0.050169; batch adversarial loss: 0.376785\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019905; batch adversarial loss: 0.507542\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039335; batch adversarial loss: 0.397799\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022466; batch adversarial loss: 0.503816\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015310; batch adversarial loss: 0.460770\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028563; batch adversarial loss: 0.399450\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011563; batch adversarial loss: 0.388764\n",
      "epoch 189; iter: 0; batch classifier loss: 0.059620; batch adversarial loss: 0.491068\n",
      "epoch 190; iter: 0; batch classifier loss: 0.011175; batch adversarial loss: 0.521829\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020238; batch adversarial loss: 0.459868\n",
      "epoch 192; iter: 0; batch classifier loss: 0.045775; batch adversarial loss: 0.465262\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010569; batch adversarial loss: 0.413363\n",
      "epoch 194; iter: 0; batch classifier loss: 0.036500; batch adversarial loss: 0.428191\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016848; batch adversarial loss: 0.452907\n",
      "epoch 196; iter: 0; batch classifier loss: 0.025344; batch adversarial loss: 0.522163\n",
      "epoch 197; iter: 0; batch classifier loss: 0.043609; batch adversarial loss: 0.531438\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013226; batch adversarial loss: 0.442524\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008537; batch adversarial loss: 0.531822\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675878; batch adversarial loss: 0.581933\n",
      "epoch 1; iter: 0; batch classifier loss: 0.477180; batch adversarial loss: 0.606282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412192; batch adversarial loss: 0.575944\n",
      "epoch 3; iter: 0; batch classifier loss: 0.446222; batch adversarial loss: 0.654785\n",
      "epoch 4; iter: 0; batch classifier loss: 0.428420; batch adversarial loss: 0.628836\n",
      "epoch 5; iter: 0; batch classifier loss: 0.487547; batch adversarial loss: 0.606351\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517370; batch adversarial loss: 0.592072\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508603; batch adversarial loss: 0.609821\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531130; batch adversarial loss: 0.612901\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414369; batch adversarial loss: 0.541466\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409426; batch adversarial loss: 0.546492\n",
      "epoch 11; iter: 0; batch classifier loss: 0.418217; batch adversarial loss: 0.507509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347960; batch adversarial loss: 0.486241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286909; batch adversarial loss: 0.510658\n",
      "epoch 14; iter: 0; batch classifier loss: 0.253761; batch adversarial loss: 0.522343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275893; batch adversarial loss: 0.476225\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314021; batch adversarial loss: 0.571045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311931; batch adversarial loss: 0.399856\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301779; batch adversarial loss: 0.476221\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247135; batch adversarial loss: 0.411039\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245831; batch adversarial loss: 0.500408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.212110; batch adversarial loss: 0.416536\n",
      "epoch 22; iter: 0; batch classifier loss: 0.212398; batch adversarial loss: 0.453374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.219707; batch adversarial loss: 0.434863\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181866; batch adversarial loss: 0.506658\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197401; batch adversarial loss: 0.414936\n",
      "epoch 26; iter: 0; batch classifier loss: 0.207368; batch adversarial loss: 0.424293\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149614; batch adversarial loss: 0.448122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.240244; batch adversarial loss: 0.464240\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163615; batch adversarial loss: 0.415490\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149450; batch adversarial loss: 0.418053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.150861; batch adversarial loss: 0.544948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202561; batch adversarial loss: 0.494674\n",
      "epoch 33; iter: 0; batch classifier loss: 0.127265; batch adversarial loss: 0.535339\n",
      "epoch 34; iter: 0; batch classifier loss: 0.201738; batch adversarial loss: 0.478185\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158823; batch adversarial loss: 0.410640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.164169; batch adversarial loss: 0.382059\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129076; batch adversarial loss: 0.477524\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120070; batch adversarial loss: 0.396806\n",
      "epoch 39; iter: 0; batch classifier loss: 0.170240; batch adversarial loss: 0.496834\n",
      "epoch 40; iter: 0; batch classifier loss: 0.105464; batch adversarial loss: 0.443656\n",
      "epoch 41; iter: 0; batch classifier loss: 0.111606; batch adversarial loss: 0.439401\n",
      "epoch 42; iter: 0; batch classifier loss: 0.199628; batch adversarial loss: 0.460409\n",
      "epoch 43; iter: 0; batch classifier loss: 0.180245; batch adversarial loss: 0.414953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153112; batch adversarial loss: 0.412015\n",
      "epoch 45; iter: 0; batch classifier loss: 0.115750; batch adversarial loss: 0.528270\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132615; batch adversarial loss: 0.433206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.109874; batch adversarial loss: 0.537787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082841; batch adversarial loss: 0.406829\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121505; batch adversarial loss: 0.477210\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131981; batch adversarial loss: 0.439772\n",
      "epoch 51; iter: 0; batch classifier loss: 0.119886; batch adversarial loss: 0.415718\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071939; batch adversarial loss: 0.490921\n",
      "epoch 53; iter: 0; batch classifier loss: 0.126550; batch adversarial loss: 0.501881\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101320; batch adversarial loss: 0.468255\n",
      "epoch 55; iter: 0; batch classifier loss: 0.128533; batch adversarial loss: 0.458184\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104764; batch adversarial loss: 0.430202\n",
      "epoch 57; iter: 0; batch classifier loss: 0.181512; batch adversarial loss: 0.391863\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091085; batch adversarial loss: 0.454085\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162227; batch adversarial loss: 0.442606\n",
      "epoch 60; iter: 0; batch classifier loss: 0.155289; batch adversarial loss: 0.508929\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126305; batch adversarial loss: 0.525923\n",
      "epoch 62; iter: 0; batch classifier loss: 0.088692; batch adversarial loss: 0.392887\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117895; batch adversarial loss: 0.510071\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091133; batch adversarial loss: 0.473838\n",
      "epoch 65; iter: 0; batch classifier loss: 0.115977; batch adversarial loss: 0.431307\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121694; batch adversarial loss: 0.410418\n",
      "epoch 67; iter: 0; batch classifier loss: 0.109529; batch adversarial loss: 0.404333\n",
      "epoch 68; iter: 0; batch classifier loss: 0.175108; batch adversarial loss: 0.447831\n",
      "epoch 69; iter: 0; batch classifier loss: 0.177527; batch adversarial loss: 0.458817\n",
      "epoch 70; iter: 0; batch classifier loss: 0.097338; batch adversarial loss: 0.418898\n",
      "epoch 71; iter: 0; batch classifier loss: 0.100021; batch adversarial loss: 0.466355\n",
      "epoch 72; iter: 0; batch classifier loss: 0.115613; batch adversarial loss: 0.449287\n",
      "epoch 73; iter: 0; batch classifier loss: 0.092235; batch adversarial loss: 0.424134\n",
      "epoch 74; iter: 0; batch classifier loss: 0.095380; batch adversarial loss: 0.459722\n",
      "epoch 75; iter: 0; batch classifier loss: 0.118272; batch adversarial loss: 0.451891\n",
      "epoch 76; iter: 0; batch classifier loss: 0.100157; batch adversarial loss: 0.383699\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103742; batch adversarial loss: 0.450134\n",
      "epoch 78; iter: 0; batch classifier loss: 0.107061; batch adversarial loss: 0.472965\n",
      "epoch 79; iter: 0; batch classifier loss: 0.103128; batch adversarial loss: 0.424119\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164044; batch adversarial loss: 0.311492\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082483; batch adversarial loss: 0.420767\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086472; batch adversarial loss: 0.438174\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091811; batch adversarial loss: 0.404481\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056335; batch adversarial loss: 0.463391\n",
      "epoch 85; iter: 0; batch classifier loss: 0.149243; batch adversarial loss: 0.385767\n",
      "epoch 86; iter: 0; batch classifier loss: 0.116773; batch adversarial loss: 0.418595\n",
      "epoch 87; iter: 0; batch classifier loss: 0.151541; batch adversarial loss: 0.480670\n",
      "epoch 88; iter: 0; batch classifier loss: 0.100573; batch adversarial loss: 0.442871\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080137; batch adversarial loss: 0.528383\n",
      "epoch 90; iter: 0; batch classifier loss: 0.081938; batch adversarial loss: 0.401593\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122636; batch adversarial loss: 0.419297\n",
      "epoch 92; iter: 0; batch classifier loss: 0.071947; batch adversarial loss: 0.533819\n",
      "epoch 93; iter: 0; batch classifier loss: 0.092083; batch adversarial loss: 0.457243\n",
      "epoch 94; iter: 0; batch classifier loss: 0.062927; batch adversarial loss: 0.435277\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079019; batch adversarial loss: 0.415188\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096757; batch adversarial loss: 0.425031\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054115; batch adversarial loss: 0.447002\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057891; batch adversarial loss: 0.356711\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047247; batch adversarial loss: 0.373579\n",
      "epoch 100; iter: 0; batch classifier loss: 0.100829; batch adversarial loss: 0.458040\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058674; batch adversarial loss: 0.514613\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060059; batch adversarial loss: 0.432663\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055312; batch adversarial loss: 0.458063\n",
      "epoch 104; iter: 0; batch classifier loss: 0.075917; batch adversarial loss: 0.583811\n",
      "epoch 105; iter: 0; batch classifier loss: 0.043673; batch adversarial loss: 0.457953\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040166; batch adversarial loss: 0.523165\n",
      "epoch 107; iter: 0; batch classifier loss: 0.058350; batch adversarial loss: 0.508476\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042110; batch adversarial loss: 0.404733\n",
      "epoch 109; iter: 0; batch classifier loss: 0.075416; batch adversarial loss: 0.507598\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061192; batch adversarial loss: 0.449133\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065425; batch adversarial loss: 0.416999\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039767; batch adversarial loss: 0.478039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.075921; batch adversarial loss: 0.376366\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036077; batch adversarial loss: 0.495338\n",
      "epoch 115; iter: 0; batch classifier loss: 0.047608; batch adversarial loss: 0.492494\n",
      "epoch 116; iter: 0; batch classifier loss: 0.045736; batch adversarial loss: 0.443117\n",
      "epoch 117; iter: 0; batch classifier loss: 0.052415; batch adversarial loss: 0.486625\n",
      "epoch 118; iter: 0; batch classifier loss: 0.056196; batch adversarial loss: 0.525113\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.525274\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025793; batch adversarial loss: 0.385146\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025842; batch adversarial loss: 0.374575\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030308; batch adversarial loss: 0.502783\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027574; batch adversarial loss: 0.620889\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032163; batch adversarial loss: 0.374406\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060380; batch adversarial loss: 0.409211\n",
      "epoch 126; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.474456\n",
      "epoch 127; iter: 0; batch classifier loss: 0.019020; batch adversarial loss: 0.544812\n",
      "epoch 128; iter: 0; batch classifier loss: 0.054099; batch adversarial loss: 0.389926\n",
      "epoch 129; iter: 0; batch classifier loss: 0.052790; batch adversarial loss: 0.486483\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036447; batch adversarial loss: 0.384974\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041134; batch adversarial loss: 0.493223\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038040; batch adversarial loss: 0.501853\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045395; batch adversarial loss: 0.454381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.020320; batch adversarial loss: 0.359846\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035733; batch adversarial loss: 0.416800\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018069; batch adversarial loss: 0.446224\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026126; batch adversarial loss: 0.396581\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039325; batch adversarial loss: 0.473464\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018813; batch adversarial loss: 0.462982\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015736; batch adversarial loss: 0.552944\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027314; batch adversarial loss: 0.393580\n",
      "epoch 142; iter: 0; batch classifier loss: 0.020741; batch adversarial loss: 0.396880\n",
      "epoch 143; iter: 0; batch classifier loss: 0.009683; batch adversarial loss: 0.432858\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.464950\n",
      "epoch 145; iter: 0; batch classifier loss: 0.010338; batch adversarial loss: 0.523327\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021310; batch adversarial loss: 0.417851\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051292; batch adversarial loss: 0.428026\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055300; batch adversarial loss: 0.451013\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036959; batch adversarial loss: 0.560640\n",
      "epoch 150; iter: 0; batch classifier loss: 0.010193; batch adversarial loss: 0.385594\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048809; batch adversarial loss: 0.531272\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011312; batch adversarial loss: 0.470203\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012212; batch adversarial loss: 0.459979\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022363; batch adversarial loss: 0.406737\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025849; batch adversarial loss: 0.395159\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034238; batch adversarial loss: 0.362122\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015277; batch adversarial loss: 0.484039\n",
      "epoch 158; iter: 0; batch classifier loss: 0.024706; batch adversarial loss: 0.415273\n",
      "epoch 159; iter: 0; batch classifier loss: 0.007493; batch adversarial loss: 0.489158\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037254; batch adversarial loss: 0.516266\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014871; batch adversarial loss: 0.511782\n",
      "epoch 162; iter: 0; batch classifier loss: 0.047098; batch adversarial loss: 0.474022\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029833; batch adversarial loss: 0.508253\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023679; batch adversarial loss: 0.428951\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012915; batch adversarial loss: 0.434550\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014085; batch adversarial loss: 0.488788\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014212; batch adversarial loss: 0.423124\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026850; batch adversarial loss: 0.443879\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034195; batch adversarial loss: 0.390645\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011762; batch adversarial loss: 0.429205\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022961; batch adversarial loss: 0.371784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045921; batch adversarial loss: 0.422293\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008016; batch adversarial loss: 0.521649\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022276; batch adversarial loss: 0.471974\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026786; batch adversarial loss: 0.438910\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021892; batch adversarial loss: 0.345850\n",
      "epoch 177; iter: 0; batch classifier loss: 0.026623; batch adversarial loss: 0.352848\n",
      "epoch 178; iter: 0; batch classifier loss: 0.019890; batch adversarial loss: 0.379016\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043879; batch adversarial loss: 0.426938\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015169; batch adversarial loss: 0.543532\n",
      "epoch 181; iter: 0; batch classifier loss: 0.006323; batch adversarial loss: 0.421350\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018446; batch adversarial loss: 0.405367\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015161; batch adversarial loss: 0.493180\n",
      "epoch 184; iter: 0; batch classifier loss: 0.014581; batch adversarial loss: 0.471915\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017458; batch adversarial loss: 0.459513\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018674; batch adversarial loss: 0.411023\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013251; batch adversarial loss: 0.422176\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006630; batch adversarial loss: 0.408217\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.494499\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020124; batch adversarial loss: 0.469283\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027908; batch adversarial loss: 0.446706\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015867; batch adversarial loss: 0.429233\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026175; batch adversarial loss: 0.458459\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022130; batch adversarial loss: 0.401615\n",
      "epoch 195; iter: 0; batch classifier loss: 0.006125; batch adversarial loss: 0.454968\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030101; batch adversarial loss: 0.428891\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006444; batch adversarial loss: 0.472685\n",
      "epoch 198; iter: 0; batch classifier loss: 0.017857; batch adversarial loss: 0.570869\n",
      "epoch 199; iter: 0; batch classifier loss: 0.012100; batch adversarial loss: 0.504188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702883; batch adversarial loss: 0.680631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.482636; batch adversarial loss: 0.657722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.485126; batch adversarial loss: 0.634052\n",
      "epoch 3; iter: 0; batch classifier loss: 0.460425; batch adversarial loss: 0.615591\n",
      "epoch 4; iter: 0; batch classifier loss: 0.442494; batch adversarial loss: 0.598349\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526921; batch adversarial loss: 0.575925\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456951; batch adversarial loss: 0.583160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537188; batch adversarial loss: 0.578838\n",
      "epoch 8; iter: 0; batch classifier loss: 0.408472; batch adversarial loss: 0.549580\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354978; batch adversarial loss: 0.525653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451945; batch adversarial loss: 0.501428\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445386; batch adversarial loss: 0.525757\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440711; batch adversarial loss: 0.533812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399035; batch adversarial loss: 0.544026\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333431; batch adversarial loss: 0.502850\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435553; batch adversarial loss: 0.531991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353297; batch adversarial loss: 0.538677\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332602; batch adversarial loss: 0.453516\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345383; batch adversarial loss: 0.449996\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323837; batch adversarial loss: 0.442016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.272207; batch adversarial loss: 0.456325\n",
      "epoch 21; iter: 0; batch classifier loss: 0.225183; batch adversarial loss: 0.524113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.270613; batch adversarial loss: 0.436369\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308886; batch adversarial loss: 0.478860\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323157; batch adversarial loss: 0.521427\n",
      "epoch 25; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.455331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261915; batch adversarial loss: 0.410011\n",
      "epoch 27; iter: 0; batch classifier loss: 0.175786; batch adversarial loss: 0.583760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.240042; batch adversarial loss: 0.432006\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244389; batch adversarial loss: 0.471548\n",
      "epoch 30; iter: 0; batch classifier loss: 0.219446; batch adversarial loss: 0.494253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 0; batch classifier loss: 0.200038; batch adversarial loss: 0.445675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248854; batch adversarial loss: 0.500942\n",
      "epoch 33; iter: 0; batch classifier loss: 0.223395; batch adversarial loss: 0.513382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.257821; batch adversarial loss: 0.512871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.208594; batch adversarial loss: 0.487713\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187989; batch adversarial loss: 0.585258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.197261; batch adversarial loss: 0.436088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241266; batch adversarial loss: 0.396769\n",
      "epoch 39; iter: 0; batch classifier loss: 0.166197; batch adversarial loss: 0.563133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.228998; batch adversarial loss: 0.516504\n",
      "epoch 41; iter: 0; batch classifier loss: 0.237244; batch adversarial loss: 0.475181\n",
      "epoch 42; iter: 0; batch classifier loss: 0.195855; batch adversarial loss: 0.494985\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204724; batch adversarial loss: 0.530569\n",
      "epoch 44; iter: 0; batch classifier loss: 0.286902; batch adversarial loss: 0.320568\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215358; batch adversarial loss: 0.446802\n",
      "epoch 46; iter: 0; batch classifier loss: 0.178322; batch adversarial loss: 0.542124\n",
      "epoch 47; iter: 0; batch classifier loss: 0.227521; batch adversarial loss: 0.507218\n",
      "epoch 48; iter: 0; batch classifier loss: 0.227726; batch adversarial loss: 0.377470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.223168; batch adversarial loss: 0.433923\n",
      "epoch 50; iter: 0; batch classifier loss: 0.246656; batch adversarial loss: 0.541456\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146604; batch adversarial loss: 0.458213\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103043; batch adversarial loss: 0.407871\n",
      "epoch 53; iter: 0; batch classifier loss: 0.077006; batch adversarial loss: 0.455871\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085037; batch adversarial loss: 0.453779\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091342; batch adversarial loss: 0.489139\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132161; batch adversarial loss: 0.530226\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078667; batch adversarial loss: 0.415638\n",
      "epoch 58; iter: 0; batch classifier loss: 0.083545; batch adversarial loss: 0.425917\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075230; batch adversarial loss: 0.511054\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134494; batch adversarial loss: 0.377110\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100967; batch adversarial loss: 0.439755\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101490; batch adversarial loss: 0.448472\n",
      "epoch 63; iter: 0; batch classifier loss: 0.075045; batch adversarial loss: 0.412240\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081887; batch adversarial loss: 0.566369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074465; batch adversarial loss: 0.395504\n",
      "epoch 66; iter: 0; batch classifier loss: 0.071176; batch adversarial loss: 0.450127\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091583; batch adversarial loss: 0.401218\n",
      "epoch 68; iter: 0; batch classifier loss: 0.056388; batch adversarial loss: 0.508773\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110576; batch adversarial loss: 0.439790\n",
      "epoch 70; iter: 0; batch classifier loss: 0.080235; batch adversarial loss: 0.454629\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081290; batch adversarial loss: 0.370877\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055840; batch adversarial loss: 0.395483\n",
      "epoch 73; iter: 0; batch classifier loss: 0.067102; batch adversarial loss: 0.432495\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055561; batch adversarial loss: 0.492547\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077393; batch adversarial loss: 0.411440\n",
      "epoch 76; iter: 0; batch classifier loss: 0.053673; batch adversarial loss: 0.411274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104430; batch adversarial loss: 0.399132\n",
      "epoch 78; iter: 0; batch classifier loss: 0.056945; batch adversarial loss: 0.473190\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099998; batch adversarial loss: 0.486787\n",
      "epoch 80; iter: 0; batch classifier loss: 0.099933; batch adversarial loss: 0.430381\n",
      "epoch 81; iter: 0; batch classifier loss: 0.097196; batch adversarial loss: 0.446159\n",
      "epoch 82; iter: 0; batch classifier loss: 0.053522; batch adversarial loss: 0.557708\n",
      "epoch 83; iter: 0; batch classifier loss: 0.043268; batch adversarial loss: 0.525627\n",
      "epoch 84; iter: 0; batch classifier loss: 0.078592; batch adversarial loss: 0.418121\n",
      "epoch 85; iter: 0; batch classifier loss: 0.078970; batch adversarial loss: 0.476928\n",
      "epoch 86; iter: 0; batch classifier loss: 0.111256; batch adversarial loss: 0.438557\n",
      "epoch 87; iter: 0; batch classifier loss: 0.105421; batch adversarial loss: 0.489093\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038094; batch adversarial loss: 0.470363\n",
      "epoch 89; iter: 0; batch classifier loss: 0.077322; batch adversarial loss: 0.534306\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054601; batch adversarial loss: 0.538816\n",
      "epoch 91; iter: 0; batch classifier loss: 0.036217; batch adversarial loss: 0.481791\n",
      "epoch 92; iter: 0; batch classifier loss: 0.088131; batch adversarial loss: 0.357496\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060929; batch adversarial loss: 0.466285\n",
      "epoch 94; iter: 0; batch classifier loss: 0.034720; batch adversarial loss: 0.347274\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042300; batch adversarial loss: 0.459383\n",
      "epoch 96; iter: 0; batch classifier loss: 0.048501; batch adversarial loss: 0.506202\n",
      "epoch 97; iter: 0; batch classifier loss: 0.063702; batch adversarial loss: 0.517885\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055094; batch adversarial loss: 0.513728\n",
      "epoch 99; iter: 0; batch classifier loss: 0.024008; batch adversarial loss: 0.444540\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058387; batch adversarial loss: 0.569638\n",
      "epoch 101; iter: 0; batch classifier loss: 0.035037; batch adversarial loss: 0.483694\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032933; batch adversarial loss: 0.478798\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035794; batch adversarial loss: 0.444200\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043282; batch adversarial loss: 0.411484\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027716; batch adversarial loss: 0.483548\n",
      "epoch 106; iter: 0; batch classifier loss: 0.045222; batch adversarial loss: 0.436885\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053286; batch adversarial loss: 0.469799\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024879; batch adversarial loss: 0.426498\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029760; batch adversarial loss: 0.482738\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063745; batch adversarial loss: 0.491432\n",
      "epoch 111; iter: 0; batch classifier loss: 0.021635; batch adversarial loss: 0.437615\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033582; batch adversarial loss: 0.500616\n",
      "epoch 113; iter: 0; batch classifier loss: 0.031412; batch adversarial loss: 0.513310\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060166; batch adversarial loss: 0.436769\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034059; batch adversarial loss: 0.432846\n",
      "epoch 116; iter: 0; batch classifier loss: 0.044684; batch adversarial loss: 0.467229\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067399; batch adversarial loss: 0.418700\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040060; batch adversarial loss: 0.424033\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057101; batch adversarial loss: 0.399542\n",
      "epoch 120; iter: 0; batch classifier loss: 0.042271; batch adversarial loss: 0.442057\n",
      "epoch 121; iter: 0; batch classifier loss: 0.048542; batch adversarial loss: 0.502406\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049072; batch adversarial loss: 0.504655\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053706; batch adversarial loss: 0.351521\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026978; batch adversarial loss: 0.461147\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018000; batch adversarial loss: 0.405503\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063314; batch adversarial loss: 0.394137\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052878; batch adversarial loss: 0.431329\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047166; batch adversarial loss: 0.426353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129; iter: 0; batch classifier loss: 0.036154; batch adversarial loss: 0.396777\n",
      "epoch 130; iter: 0; batch classifier loss: 0.020954; batch adversarial loss: 0.528482\n",
      "epoch 131; iter: 0; batch classifier loss: 0.051471; batch adversarial loss: 0.423818\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025627; batch adversarial loss: 0.407233\n",
      "epoch 133; iter: 0; batch classifier loss: 0.044889; batch adversarial loss: 0.470613\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028801; batch adversarial loss: 0.437933\n",
      "epoch 135; iter: 0; batch classifier loss: 0.023589; batch adversarial loss: 0.444597\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014997; batch adversarial loss: 0.445724\n",
      "epoch 137; iter: 0; batch classifier loss: 0.009683; batch adversarial loss: 0.432525\n",
      "epoch 138; iter: 0; batch classifier loss: 0.027531; batch adversarial loss: 0.450454\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043491; batch adversarial loss: 0.411206\n",
      "epoch 140; iter: 0; batch classifier loss: 0.032802; batch adversarial loss: 0.438391\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032248; batch adversarial loss: 0.468757\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021077; batch adversarial loss: 0.495573\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044201; batch adversarial loss: 0.473057\n",
      "epoch 144; iter: 0; batch classifier loss: 0.064603; batch adversarial loss: 0.457404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020915; batch adversarial loss: 0.528223\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037322; batch adversarial loss: 0.510141\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038755; batch adversarial loss: 0.410007\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013502; batch adversarial loss: 0.448873\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018930; batch adversarial loss: 0.463322\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025696; batch adversarial loss: 0.392604\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016688; batch adversarial loss: 0.407248\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015577; batch adversarial loss: 0.545929\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022802; batch adversarial loss: 0.486939\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015340; batch adversarial loss: 0.468266\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016999; batch adversarial loss: 0.403100\n",
      "epoch 156; iter: 0; batch classifier loss: 0.008125; batch adversarial loss: 0.399887\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031436; batch adversarial loss: 0.520579\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033075; batch adversarial loss: 0.402268\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014080; batch adversarial loss: 0.446864\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037679; batch adversarial loss: 0.523190\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022675; batch adversarial loss: 0.486489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.011594; batch adversarial loss: 0.474427\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007575; batch adversarial loss: 0.400830\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017396; batch adversarial loss: 0.439829\n",
      "epoch 165; iter: 0; batch classifier loss: 0.022774; batch adversarial loss: 0.445843\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011188; batch adversarial loss: 0.558868\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010580; batch adversarial loss: 0.485887\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007225; batch adversarial loss: 0.516359\n",
      "epoch 169; iter: 0; batch classifier loss: 0.071467; batch adversarial loss: 0.456939\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032430; batch adversarial loss: 0.473357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.013218; batch adversarial loss: 0.550621\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039877; batch adversarial loss: 0.556430\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008603; batch adversarial loss: 0.435500\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004865; batch adversarial loss: 0.438760\n",
      "epoch 175; iter: 0; batch classifier loss: 0.011582; batch adversarial loss: 0.552205\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027579; batch adversarial loss: 0.343384\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011017; batch adversarial loss: 0.518990\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035273; batch adversarial loss: 0.466997\n",
      "epoch 179; iter: 0; batch classifier loss: 0.032659; batch adversarial loss: 0.452373\n",
      "epoch 180; iter: 0; batch classifier loss: 0.058920; batch adversarial loss: 0.466341\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016154; batch adversarial loss: 0.486901\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022430; batch adversarial loss: 0.468978\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011532; batch adversarial loss: 0.505276\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004914; batch adversarial loss: 0.532999\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015413; batch adversarial loss: 0.493596\n",
      "epoch 186; iter: 0; batch classifier loss: 0.018913; batch adversarial loss: 0.467304\n",
      "epoch 187; iter: 0; batch classifier loss: 0.004484; batch adversarial loss: 0.460699\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012501; batch adversarial loss: 0.501960\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015537; batch adversarial loss: 0.417245\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030908; batch adversarial loss: 0.461254\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015949; batch adversarial loss: 0.494867\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035323; batch adversarial loss: 0.499671\n",
      "epoch 193; iter: 0; batch classifier loss: 0.018802; batch adversarial loss: 0.509444\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033602; batch adversarial loss: 0.488137\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011529; batch adversarial loss: 0.494671\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041533; batch adversarial loss: 0.381250\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006836; batch adversarial loss: 0.443711\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024216; batch adversarial loss: 0.414027\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010740; batch adversarial loss: 0.572039\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696153; batch adversarial loss: 0.659665\n",
      "epoch 1; iter: 0; batch classifier loss: 0.522533; batch adversarial loss: 0.609817\n",
      "epoch 2; iter: 0; batch classifier loss: 0.448704; batch adversarial loss: 0.587768\n",
      "epoch 3; iter: 0; batch classifier loss: 0.321567; batch adversarial loss: 0.576293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379992; batch adversarial loss: 0.573376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355595; batch adversarial loss: 0.545841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.264632; batch adversarial loss: 0.506210\n",
      "epoch 7; iter: 0; batch classifier loss: 0.276947; batch adversarial loss: 0.508159\n",
      "epoch 8; iter: 0; batch classifier loss: 0.246524; batch adversarial loss: 0.491369\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254951; batch adversarial loss: 0.493022\n",
      "epoch 10; iter: 0; batch classifier loss: 0.211102; batch adversarial loss: 0.423733\n",
      "epoch 11; iter: 0; batch classifier loss: 0.212911; batch adversarial loss: 0.508085\n",
      "epoch 12; iter: 0; batch classifier loss: 0.201303; batch adversarial loss: 0.418777\n",
      "epoch 13; iter: 0; batch classifier loss: 0.163331; batch adversarial loss: 0.461597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166058; batch adversarial loss: 0.489718\n",
      "epoch 15; iter: 0; batch classifier loss: 0.189070; batch adversarial loss: 0.468199\n",
      "epoch 16; iter: 0; batch classifier loss: 0.210256; batch adversarial loss: 0.437770\n",
      "epoch 17; iter: 0; batch classifier loss: 0.172902; batch adversarial loss: 0.519017\n",
      "epoch 18; iter: 0; batch classifier loss: 0.156836; batch adversarial loss: 0.455988\n",
      "epoch 19; iter: 0; batch classifier loss: 0.171456; batch adversarial loss: 0.492738\n",
      "epoch 20; iter: 0; batch classifier loss: 0.186681; batch adversarial loss: 0.529804\n",
      "epoch 21; iter: 0; batch classifier loss: 0.171871; batch adversarial loss: 0.490109\n",
      "epoch 22; iter: 0; batch classifier loss: 0.162707; batch adversarial loss: 0.467606\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178561; batch adversarial loss: 0.483161\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209609; batch adversarial loss: 0.449959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.175796; batch adversarial loss: 0.468648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.224177; batch adversarial loss: 0.535652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237040; batch adversarial loss: 0.509056\n",
      "epoch 28; iter: 0; batch classifier loss: 0.253408; batch adversarial loss: 0.563010\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227842; batch adversarial loss: 0.509398\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237808; batch adversarial loss: 0.469353\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191837; batch adversarial loss: 0.527200\n",
      "epoch 32; iter: 0; batch classifier loss: 0.149509; batch adversarial loss: 0.379969\n",
      "epoch 33; iter: 0; batch classifier loss: 0.190524; batch adversarial loss: 0.466385\n",
      "epoch 34; iter: 0; batch classifier loss: 0.234081; batch adversarial loss: 0.544096\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239371; batch adversarial loss: 0.481185\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148644; batch adversarial loss: 0.418506\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102586; batch adversarial loss: 0.496251\n",
      "epoch 38; iter: 0; batch classifier loss: 0.098819; batch adversarial loss: 0.564726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094740; batch adversarial loss: 0.459897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096280; batch adversarial loss: 0.466838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119762; batch adversarial loss: 0.425234\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127463; batch adversarial loss: 0.520125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.086031; batch adversarial loss: 0.568099\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096623; batch adversarial loss: 0.461385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.127167; batch adversarial loss: 0.454033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.070488; batch adversarial loss: 0.468665\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075980; batch adversarial loss: 0.449059\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097540; batch adversarial loss: 0.374086\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098963; batch adversarial loss: 0.433237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089741; batch adversarial loss: 0.366889\n",
      "epoch 51; iter: 0; batch classifier loss: 0.097739; batch adversarial loss: 0.476336\n",
      "epoch 52; iter: 0; batch classifier loss: 0.053065; batch adversarial loss: 0.490541\n",
      "epoch 53; iter: 0; batch classifier loss: 0.068649; batch adversarial loss: 0.470614\n",
      "epoch 54; iter: 0; batch classifier loss: 0.159867; batch adversarial loss: 0.440214\n",
      "epoch 55; iter: 0; batch classifier loss: 0.063073; batch adversarial loss: 0.439440\n",
      "epoch 56; iter: 0; batch classifier loss: 0.069561; batch adversarial loss: 0.466664\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079819; batch adversarial loss: 0.463794\n",
      "epoch 58; iter: 0; batch classifier loss: 0.037625; batch adversarial loss: 0.459492\n",
      "epoch 59; iter: 0; batch classifier loss: 0.061846; batch adversarial loss: 0.424863\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059048; batch adversarial loss: 0.461749\n",
      "epoch 61; iter: 0; batch classifier loss: 0.073740; batch adversarial loss: 0.456648\n",
      "epoch 62; iter: 0; batch classifier loss: 0.063440; batch adversarial loss: 0.421124\n",
      "epoch 63; iter: 0; batch classifier loss: 0.061283; batch adversarial loss: 0.503765\n",
      "epoch 64; iter: 0; batch classifier loss: 0.067474; batch adversarial loss: 0.459539\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077982; batch adversarial loss: 0.493291\n",
      "epoch 66; iter: 0; batch classifier loss: 0.061088; batch adversarial loss: 0.506004\n",
      "epoch 67; iter: 0; batch classifier loss: 0.043351; batch adversarial loss: 0.470414\n",
      "epoch 68; iter: 0; batch classifier loss: 0.089044; batch adversarial loss: 0.476471\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055938; batch adversarial loss: 0.473990\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076151; batch adversarial loss: 0.357197\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081020; batch adversarial loss: 0.564032\n",
      "epoch 72; iter: 0; batch classifier loss: 0.068795; batch adversarial loss: 0.415767\n",
      "epoch 73; iter: 0; batch classifier loss: 0.070323; batch adversarial loss: 0.423119\n",
      "epoch 74; iter: 0; batch classifier loss: 0.061837; batch adversarial loss: 0.416799\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077948; batch adversarial loss: 0.475935\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055414; batch adversarial loss: 0.461352\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047685; batch adversarial loss: 0.512867\n",
      "epoch 78; iter: 0; batch classifier loss: 0.098436; batch adversarial loss: 0.469540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.051386; batch adversarial loss: 0.452409\n",
      "epoch 80; iter: 0; batch classifier loss: 0.084334; batch adversarial loss: 0.446630\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057849; batch adversarial loss: 0.484088\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047387; batch adversarial loss: 0.430790\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090688; batch adversarial loss: 0.433252\n",
      "epoch 84; iter: 0; batch classifier loss: 0.085229; batch adversarial loss: 0.419424\n",
      "epoch 85; iter: 0; batch classifier loss: 0.091728; batch adversarial loss: 0.460864\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040756; batch adversarial loss: 0.459501\n",
      "epoch 87; iter: 0; batch classifier loss: 0.054274; batch adversarial loss: 0.409207\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089575; batch adversarial loss: 0.363406\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038880; batch adversarial loss: 0.454683\n",
      "epoch 90; iter: 0; batch classifier loss: 0.030516; batch adversarial loss: 0.454241\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039238; batch adversarial loss: 0.414023\n",
      "epoch 92; iter: 0; batch classifier loss: 0.117984; batch adversarial loss: 0.435966\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063627; batch adversarial loss: 0.437244\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038065; batch adversarial loss: 0.383552\n",
      "epoch 95; iter: 0; batch classifier loss: 0.036538; batch adversarial loss: 0.505291\n",
      "epoch 96; iter: 0; batch classifier loss: 0.078197; batch adversarial loss: 0.439219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050298; batch adversarial loss: 0.383225\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056342; batch adversarial loss: 0.525025\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065921; batch adversarial loss: 0.453841\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050433; batch adversarial loss: 0.537065\n",
      "epoch 101; iter: 0; batch classifier loss: 0.098868; batch adversarial loss: 0.455212\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035143; batch adversarial loss: 0.481089\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078953; batch adversarial loss: 0.470085\n",
      "epoch 104; iter: 0; batch classifier loss: 0.087964; batch adversarial loss: 0.383182\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055090; batch adversarial loss: 0.537965\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043172; batch adversarial loss: 0.421373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.053809; batch adversarial loss: 0.534566\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081874; batch adversarial loss: 0.487122\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047744; batch adversarial loss: 0.501306\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033546; batch adversarial loss: 0.433626\n",
      "epoch 111; iter: 0; batch classifier loss: 0.103703; batch adversarial loss: 0.397498\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037193; batch adversarial loss: 0.511263\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033524; batch adversarial loss: 0.566875\n",
      "epoch 114; iter: 0; batch classifier loss: 0.053490; batch adversarial loss: 0.504636\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056211; batch adversarial loss: 0.517923\n",
      "epoch 116; iter: 0; batch classifier loss: 0.021774; batch adversarial loss: 0.472285\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036739; batch adversarial loss: 0.510184\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024720; batch adversarial loss: 0.388995\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038031; batch adversarial loss: 0.458143\n",
      "epoch 120; iter: 0; batch classifier loss: 0.082183; batch adversarial loss: 0.436648\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054119; batch adversarial loss: 0.401600\n",
      "epoch 122; iter: 0; batch classifier loss: 0.067735; batch adversarial loss: 0.418577\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052372; batch adversarial loss: 0.475607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 124; iter: 0; batch classifier loss: 0.068193; batch adversarial loss: 0.495470\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049581; batch adversarial loss: 0.335134\n",
      "epoch 126; iter: 0; batch classifier loss: 0.023977; batch adversarial loss: 0.449002\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028311; batch adversarial loss: 0.390319\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052689; batch adversarial loss: 0.373060\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022188; batch adversarial loss: 0.462651\n",
      "epoch 130; iter: 0; batch classifier loss: 0.071197; batch adversarial loss: 0.424952\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052224; batch adversarial loss: 0.423454\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023327; batch adversarial loss: 0.431690\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026611; batch adversarial loss: 0.533260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046785; batch adversarial loss: 0.482181\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035128; batch adversarial loss: 0.444704\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.439592\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025545; batch adversarial loss: 0.394720\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032624; batch adversarial loss: 0.408945\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025230; batch adversarial loss: 0.540422\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026640; batch adversarial loss: 0.431402\n",
      "epoch 141; iter: 0; batch classifier loss: 0.030099; batch adversarial loss: 0.362990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.016430; batch adversarial loss: 0.361614\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026969; batch adversarial loss: 0.485925\n",
      "epoch 144; iter: 0; batch classifier loss: 0.011813; batch adversarial loss: 0.422773\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024649; batch adversarial loss: 0.476580\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042233; batch adversarial loss: 0.385365\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010589; batch adversarial loss: 0.450202\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015574; batch adversarial loss: 0.449056\n",
      "epoch 149; iter: 0; batch classifier loss: 0.010652; batch adversarial loss: 0.449149\n",
      "epoch 150; iter: 0; batch classifier loss: 0.019624; batch adversarial loss: 0.455565\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029864; batch adversarial loss: 0.389517\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.444294\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038659; batch adversarial loss: 0.477679\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025125; batch adversarial loss: 0.447396\n",
      "epoch 155; iter: 0; batch classifier loss: 0.059985; batch adversarial loss: 0.396309\n",
      "epoch 156; iter: 0; batch classifier loss: 0.020212; batch adversarial loss: 0.559413\n",
      "epoch 157; iter: 0; batch classifier loss: 0.051547; batch adversarial loss: 0.477585\n",
      "epoch 158; iter: 0; batch classifier loss: 0.019908; batch adversarial loss: 0.459463\n",
      "epoch 159; iter: 0; batch classifier loss: 0.062184; batch adversarial loss: 0.416992\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010081; batch adversarial loss: 0.414764\n",
      "epoch 161; iter: 0; batch classifier loss: 0.026703; batch adversarial loss: 0.369240\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039881; batch adversarial loss: 0.415034\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033913; batch adversarial loss: 0.428763\n",
      "epoch 164; iter: 0; batch classifier loss: 0.019885; batch adversarial loss: 0.412948\n",
      "epoch 165; iter: 0; batch classifier loss: 0.057551; batch adversarial loss: 0.458449\n",
      "epoch 166; iter: 0; batch classifier loss: 0.039757; batch adversarial loss: 0.490668\n",
      "epoch 167; iter: 0; batch classifier loss: 0.031492; batch adversarial loss: 0.514229\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025777; batch adversarial loss: 0.410818\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012990; batch adversarial loss: 0.412592\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021227; batch adversarial loss: 0.454540\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025068; batch adversarial loss: 0.525626\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035795; batch adversarial loss: 0.426173\n",
      "epoch 173; iter: 0; batch classifier loss: 0.029610; batch adversarial loss: 0.520120\n",
      "epoch 174; iter: 0; batch classifier loss: 0.040106; batch adversarial loss: 0.372305\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038351; batch adversarial loss: 0.465495\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022339; batch adversarial loss: 0.457451\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022529; batch adversarial loss: 0.517775\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017052; batch adversarial loss: 0.460098\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023223; batch adversarial loss: 0.438353\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035866; batch adversarial loss: 0.509588\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029937; batch adversarial loss: 0.437829\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021797; batch adversarial loss: 0.490143\n",
      "epoch 183; iter: 0; batch classifier loss: 0.051212; batch adversarial loss: 0.429717\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019404; batch adversarial loss: 0.485628\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035760; batch adversarial loss: 0.368115\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013970; batch adversarial loss: 0.473590\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007630; batch adversarial loss: 0.428221\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010290; batch adversarial loss: 0.489415\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031812; batch adversarial loss: 0.499221\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006052; batch adversarial loss: 0.444304\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021283; batch adversarial loss: 0.380484\n",
      "epoch 192; iter: 0; batch classifier loss: 0.029761; batch adversarial loss: 0.442505\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008981; batch adversarial loss: 0.544645\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021127; batch adversarial loss: 0.501267\n",
      "epoch 195; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.462960\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017831; batch adversarial loss: 0.417423\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028697; batch adversarial loss: 0.529896\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037053; batch adversarial loss: 0.312408\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017205; batch adversarial loss: 0.484791\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692260; batch adversarial loss: 0.631176\n",
      "epoch 1; iter: 0; batch classifier loss: 0.364803; batch adversarial loss: 0.626253\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411780; batch adversarial loss: 0.573234\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341814; batch adversarial loss: 0.586086\n",
      "epoch 4; iter: 0; batch classifier loss: 0.310961; batch adversarial loss: 0.586725\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418178; batch adversarial loss: 0.548569\n",
      "epoch 6; iter: 0; batch classifier loss: 0.221113; batch adversarial loss: 0.481092\n",
      "epoch 7; iter: 0; batch classifier loss: 0.423734; batch adversarial loss: 0.539105\n",
      "epoch 8; iter: 0; batch classifier loss: 0.230099; batch adversarial loss: 0.546151\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238814; batch adversarial loss: 0.555803\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245058; batch adversarial loss: 0.478277\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309028; batch adversarial loss: 0.533219\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217798; batch adversarial loss: 0.534524\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197872; batch adversarial loss: 0.505702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233710; batch adversarial loss: 0.484010\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236756; batch adversarial loss: 0.547333\n",
      "epoch 16; iter: 0; batch classifier loss: 0.259763; batch adversarial loss: 0.513316\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216825; batch adversarial loss: 0.577727\n",
      "epoch 18; iter: 0; batch classifier loss: 0.195591; batch adversarial loss: 0.436391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260450; batch adversarial loss: 0.528113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.189703; batch adversarial loss: 0.520242\n",
      "epoch 21; iter: 0; batch classifier loss: 0.209179; batch adversarial loss: 0.534906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262404; batch adversarial loss: 0.518652\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217595; batch adversarial loss: 0.538180\n",
      "epoch 24; iter: 0; batch classifier loss: 0.229307; batch adversarial loss: 0.423229\n",
      "epoch 25; iter: 0; batch classifier loss: 0.207933; batch adversarial loss: 0.477020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.282724; batch adversarial loss: 0.424160\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269580; batch adversarial loss: 0.429585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.218311; batch adversarial loss: 0.479785\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157898; batch adversarial loss: 0.463950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116597; batch adversarial loss: 0.450611\n",
      "epoch 31; iter: 0; batch classifier loss: 0.151012; batch adversarial loss: 0.457362\n",
      "epoch 32; iter: 0; batch classifier loss: 0.100364; batch adversarial loss: 0.425376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126026; batch adversarial loss: 0.477124\n",
      "epoch 34; iter: 0; batch classifier loss: 0.087442; batch adversarial loss: 0.429299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.091142; batch adversarial loss: 0.425476\n",
      "epoch 36; iter: 0; batch classifier loss: 0.081422; batch adversarial loss: 0.471418\n",
      "epoch 37; iter: 0; batch classifier loss: 0.120627; batch adversarial loss: 0.445992\n",
      "epoch 38; iter: 0; batch classifier loss: 0.083250; batch adversarial loss: 0.401792\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125116; batch adversarial loss: 0.602330\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091401; batch adversarial loss: 0.421474\n",
      "epoch 41; iter: 0; batch classifier loss: 0.091927; batch adversarial loss: 0.507670\n",
      "epoch 42; iter: 0; batch classifier loss: 0.102215; batch adversarial loss: 0.409537\n",
      "epoch 43; iter: 0; batch classifier loss: 0.100356; batch adversarial loss: 0.417742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.082662; batch adversarial loss: 0.413269\n",
      "epoch 45; iter: 0; batch classifier loss: 0.085689; batch adversarial loss: 0.485585\n",
      "epoch 46; iter: 0; batch classifier loss: 0.095383; batch adversarial loss: 0.485244\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085318; batch adversarial loss: 0.370456\n",
      "epoch 48; iter: 0; batch classifier loss: 0.109109; batch adversarial loss: 0.519244\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098312; batch adversarial loss: 0.488571\n",
      "epoch 50; iter: 0; batch classifier loss: 0.108362; batch adversarial loss: 0.441334\n",
      "epoch 51; iter: 0; batch classifier loss: 0.070495; batch adversarial loss: 0.394426\n",
      "epoch 52; iter: 0; batch classifier loss: 0.061598; batch adversarial loss: 0.466823\n",
      "epoch 53; iter: 0; batch classifier loss: 0.107912; batch adversarial loss: 0.412829\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101597; batch adversarial loss: 0.569447\n",
      "epoch 55; iter: 0; batch classifier loss: 0.050753; batch adversarial loss: 0.440051\n",
      "epoch 56; iter: 0; batch classifier loss: 0.067012; batch adversarial loss: 0.427964\n",
      "epoch 57; iter: 0; batch classifier loss: 0.063474; batch adversarial loss: 0.506022\n",
      "epoch 58; iter: 0; batch classifier loss: 0.074674; batch adversarial loss: 0.449791\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088476; batch adversarial loss: 0.437678\n",
      "epoch 60; iter: 0; batch classifier loss: 0.100588; batch adversarial loss: 0.523004\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078892; batch adversarial loss: 0.438282\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131292; batch adversarial loss: 0.567796\n",
      "epoch 63; iter: 0; batch classifier loss: 0.057423; batch adversarial loss: 0.395582\n",
      "epoch 64; iter: 0; batch classifier loss: 0.039114; batch adversarial loss: 0.553572\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061816; batch adversarial loss: 0.486658\n",
      "epoch 66; iter: 0; batch classifier loss: 0.134923; batch adversarial loss: 0.496127\n",
      "epoch 67; iter: 0; batch classifier loss: 0.049546; batch adversarial loss: 0.482217\n",
      "epoch 68; iter: 0; batch classifier loss: 0.046593; batch adversarial loss: 0.486708\n",
      "epoch 69; iter: 0; batch classifier loss: 0.055484; batch adversarial loss: 0.442473\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194444; batch adversarial loss: 0.487015\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061066; batch adversarial loss: 0.521280\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062914; batch adversarial loss: 0.436171\n",
      "epoch 73; iter: 0; batch classifier loss: 0.103677; batch adversarial loss: 0.438727\n",
      "epoch 74; iter: 0; batch classifier loss: 0.114407; batch adversarial loss: 0.378025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082852; batch adversarial loss: 0.450502\n",
      "epoch 76; iter: 0; batch classifier loss: 0.034827; batch adversarial loss: 0.441829\n",
      "epoch 77; iter: 0; batch classifier loss: 0.063460; batch adversarial loss: 0.400588\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074360; batch adversarial loss: 0.593540\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074795; batch adversarial loss: 0.425460\n",
      "epoch 80; iter: 0; batch classifier loss: 0.076341; batch adversarial loss: 0.527882\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083693; batch adversarial loss: 0.406999\n",
      "epoch 82; iter: 0; batch classifier loss: 0.079226; batch adversarial loss: 0.391824\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100159; batch adversarial loss: 0.443409\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069996; batch adversarial loss: 0.511111\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062403; batch adversarial loss: 0.449455\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065214; batch adversarial loss: 0.405225\n",
      "epoch 87; iter: 0; batch classifier loss: 0.049826; batch adversarial loss: 0.414219\n",
      "epoch 88; iter: 0; batch classifier loss: 0.047083; batch adversarial loss: 0.544202\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067795; batch adversarial loss: 0.463879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066966; batch adversarial loss: 0.408284\n",
      "epoch 91; iter: 0; batch classifier loss: 0.046228; batch adversarial loss: 0.512313\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057116; batch adversarial loss: 0.500774\n",
      "epoch 93; iter: 0; batch classifier loss: 0.102712; batch adversarial loss: 0.414567\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037034; batch adversarial loss: 0.486045\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064397; batch adversarial loss: 0.499919\n",
      "epoch 96; iter: 0; batch classifier loss: 0.097349; batch adversarial loss: 0.477202\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051127; batch adversarial loss: 0.458965\n",
      "epoch 98; iter: 0; batch classifier loss: 0.072944; batch adversarial loss: 0.458674\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046553; batch adversarial loss: 0.435505\n",
      "epoch 100; iter: 0; batch classifier loss: 0.054471; batch adversarial loss: 0.418442\n",
      "epoch 101; iter: 0; batch classifier loss: 0.107724; batch adversarial loss: 0.398532\n",
      "epoch 102; iter: 0; batch classifier loss: 0.094104; batch adversarial loss: 0.527375\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046455; batch adversarial loss: 0.404388\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089214; batch adversarial loss: 0.400527\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056337; batch adversarial loss: 0.532656\n",
      "epoch 106; iter: 0; batch classifier loss: 0.081560; batch adversarial loss: 0.463014\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.510216\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069240; batch adversarial loss: 0.424639\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025816; batch adversarial loss: 0.424373\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041116; batch adversarial loss: 0.447622\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074117; batch adversarial loss: 0.504729\n",
      "epoch 112; iter: 0; batch classifier loss: 0.060480; batch adversarial loss: 0.476538\n",
      "epoch 113; iter: 0; batch classifier loss: 0.036780; batch adversarial loss: 0.437021\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037861; batch adversarial loss: 0.494487\n",
      "epoch 115; iter: 0; batch classifier loss: 0.055081; batch adversarial loss: 0.500265\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061476; batch adversarial loss: 0.375347\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032329; batch adversarial loss: 0.476824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.034284; batch adversarial loss: 0.580215\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021656; batch adversarial loss: 0.499344\n",
      "epoch 120; iter: 0; batch classifier loss: 0.075263; batch adversarial loss: 0.385155\n",
      "epoch 121; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.486307\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062046; batch adversarial loss: 0.450767\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026207; batch adversarial loss: 0.393267\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041082; batch adversarial loss: 0.503196\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040282; batch adversarial loss: 0.456433\n",
      "epoch 126; iter: 0; batch classifier loss: 0.101387; batch adversarial loss: 0.499701\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037614; batch adversarial loss: 0.460736\n",
      "epoch 128; iter: 0; batch classifier loss: 0.048920; batch adversarial loss: 0.410318\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041534; batch adversarial loss: 0.417279\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067033; batch adversarial loss: 0.400797\n",
      "epoch 131; iter: 0; batch classifier loss: 0.040776; batch adversarial loss: 0.403254\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031736; batch adversarial loss: 0.547293\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013311; batch adversarial loss: 0.462973\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019605; batch adversarial loss: 0.496302\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021013; batch adversarial loss: 0.439378\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019162; batch adversarial loss: 0.452650\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025048; batch adversarial loss: 0.333417\n",
      "epoch 138; iter: 0; batch classifier loss: 0.051503; batch adversarial loss: 0.359110\n",
      "epoch 139; iter: 0; batch classifier loss: 0.051265; batch adversarial loss: 0.478146\n",
      "epoch 140; iter: 0; batch classifier loss: 0.036630; batch adversarial loss: 0.556472\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018695; batch adversarial loss: 0.516943\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037392; batch adversarial loss: 0.368118\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016162; batch adversarial loss: 0.510825\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038442; batch adversarial loss: 0.519877\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025832; batch adversarial loss: 0.494172\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029328; batch adversarial loss: 0.452443\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027821; batch adversarial loss: 0.495850\n",
      "epoch 148; iter: 0; batch classifier loss: 0.008241; batch adversarial loss: 0.475727\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020842; batch adversarial loss: 0.453504\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043335; batch adversarial loss: 0.428737\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026640; batch adversarial loss: 0.528565\n",
      "epoch 152; iter: 0; batch classifier loss: 0.063751; batch adversarial loss: 0.355890\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031225; batch adversarial loss: 0.467737\n",
      "epoch 154; iter: 0; batch classifier loss: 0.065443; batch adversarial loss: 0.380298\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027025; batch adversarial loss: 0.473015\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030163; batch adversarial loss: 0.435384\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013894; batch adversarial loss: 0.479708\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029307; batch adversarial loss: 0.534666\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014568; batch adversarial loss: 0.423285\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030474; batch adversarial loss: 0.440627\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025485; batch adversarial loss: 0.487330\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035518; batch adversarial loss: 0.431485\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030856; batch adversarial loss: 0.469666\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028195; batch adversarial loss: 0.424223\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037204; batch adversarial loss: 0.388037\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023385; batch adversarial loss: 0.526460\n",
      "epoch 167; iter: 0; batch classifier loss: 0.010521; batch adversarial loss: 0.449611\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032339; batch adversarial loss: 0.396624\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016885; batch adversarial loss: 0.460053\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029716; batch adversarial loss: 0.403965\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040335; batch adversarial loss: 0.415091\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016946; batch adversarial loss: 0.490529\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018782; batch adversarial loss: 0.375910\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.409651\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039503; batch adversarial loss: 0.426076\n",
      "epoch 176; iter: 0; batch classifier loss: 0.043842; batch adversarial loss: 0.469968\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011787; batch adversarial loss: 0.530480\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026566; batch adversarial loss: 0.417321\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017111; batch adversarial loss: 0.443277\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012613; batch adversarial loss: 0.393231\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032910; batch adversarial loss: 0.524222\n",
      "epoch 182; iter: 0; batch classifier loss: 0.020459; batch adversarial loss: 0.337550\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013057; batch adversarial loss: 0.496712\n",
      "epoch 184; iter: 0; batch classifier loss: 0.042146; batch adversarial loss: 0.401410\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039288; batch adversarial loss: 0.461713\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021281; batch adversarial loss: 0.470035\n",
      "epoch 187; iter: 0; batch classifier loss: 0.011921; batch adversarial loss: 0.475576\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058693; batch adversarial loss: 0.455921\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036487; batch adversarial loss: 0.413680\n",
      "epoch 190; iter: 0; batch classifier loss: 0.007817; batch adversarial loss: 0.495237\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015074; batch adversarial loss: 0.441405\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024015; batch adversarial loss: 0.428671\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031378; batch adversarial loss: 0.484211\n",
      "epoch 194; iter: 0; batch classifier loss: 0.059557; batch adversarial loss: 0.494440\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011164; batch adversarial loss: 0.519956\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017429; batch adversarial loss: 0.437094\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009961; batch adversarial loss: 0.430016\n",
      "epoch 198; iter: 0; batch classifier loss: 0.005322; batch adversarial loss: 0.389803\n",
      "epoch 199; iter: 0; batch classifier loss: 0.046946; batch adversarial loss: 0.481690\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701683; batch adversarial loss: 0.668226\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496266; batch adversarial loss: 0.693731\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425644; batch adversarial loss: 0.603633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.349344; batch adversarial loss: 0.600341\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343456; batch adversarial loss: 0.571531\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336598; batch adversarial loss: 0.563206\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336762; batch adversarial loss: 0.522842\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311019; batch adversarial loss: 0.529705\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259078; batch adversarial loss: 0.492621\n",
      "epoch 9; iter: 0; batch classifier loss: 0.278422; batch adversarial loss: 0.508878\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231741; batch adversarial loss: 0.462805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.184117; batch adversarial loss: 0.515290\n",
      "epoch 12; iter: 0; batch classifier loss: 0.149174; batch adversarial loss: 0.472940\n",
      "epoch 13; iter: 0; batch classifier loss: 0.246672; batch adversarial loss: 0.473712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.156494; batch adversarial loss: 0.482817\n",
      "epoch 15; iter: 0; batch classifier loss: 0.203326; batch adversarial loss: 0.416086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182369; batch adversarial loss: 0.511405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.146907; batch adversarial loss: 0.486564\n",
      "epoch 18; iter: 0; batch classifier loss: 0.176499; batch adversarial loss: 0.457983\n",
      "epoch 19; iter: 0; batch classifier loss: 0.139177; batch adversarial loss: 0.426412\n",
      "epoch 20; iter: 0; batch classifier loss: 0.153568; batch adversarial loss: 0.523508\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216910; batch adversarial loss: 0.402808\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171035; batch adversarial loss: 0.477542\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145365; batch adversarial loss: 0.512207\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181682; batch adversarial loss: 0.470799\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146832; batch adversarial loss: 0.483741\n",
      "epoch 26; iter: 0; batch classifier loss: 0.162023; batch adversarial loss: 0.412583\n",
      "epoch 27; iter: 0; batch classifier loss: 0.211202; batch adversarial loss: 0.567098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206741; batch adversarial loss: 0.502685\n",
      "epoch 29; iter: 0; batch classifier loss: 0.209529; batch adversarial loss: 0.473967\n",
      "epoch 30; iter: 0; batch classifier loss: 0.163697; batch adversarial loss: 0.482086\n",
      "epoch 31; iter: 0; batch classifier loss: 0.164714; batch adversarial loss: 0.462836\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126021; batch adversarial loss: 0.451717\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149298; batch adversarial loss: 0.447797\n",
      "epoch 34; iter: 0; batch classifier loss: 0.175136; batch adversarial loss: 0.439410\n",
      "epoch 35; iter: 0; batch classifier loss: 0.161507; batch adversarial loss: 0.439046\n",
      "epoch 36; iter: 0; batch classifier loss: 0.278400; batch adversarial loss: 0.499638\n",
      "epoch 37; iter: 0; batch classifier loss: 0.169358; batch adversarial loss: 0.443475\n",
      "epoch 38; iter: 0; batch classifier loss: 0.159289; batch adversarial loss: 0.404966\n",
      "epoch 39; iter: 0; batch classifier loss: 0.303771; batch adversarial loss: 0.386177\n",
      "epoch 40; iter: 0; batch classifier loss: 0.220525; batch adversarial loss: 0.475689\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147540; batch adversarial loss: 0.417602\n",
      "epoch 42; iter: 0; batch classifier loss: 0.057704; batch adversarial loss: 0.456763\n",
      "epoch 43; iter: 0; batch classifier loss: 0.062057; batch adversarial loss: 0.359210\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104011; batch adversarial loss: 0.483338\n",
      "epoch 45; iter: 0; batch classifier loss: 0.087035; batch adversarial loss: 0.433012\n",
      "epoch 46; iter: 0; batch classifier loss: 0.092378; batch adversarial loss: 0.460297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.079983; batch adversarial loss: 0.521390\n",
      "epoch 48; iter: 0; batch classifier loss: 0.052424; batch adversarial loss: 0.395507\n",
      "epoch 49; iter: 0; batch classifier loss: 0.047987; batch adversarial loss: 0.456644\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094973; batch adversarial loss: 0.386699\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083354; batch adversarial loss: 0.388588\n",
      "epoch 52; iter: 0; batch classifier loss: 0.036166; batch adversarial loss: 0.639362\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062163; batch adversarial loss: 0.523953\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072395; batch adversarial loss: 0.424669\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096861; batch adversarial loss: 0.366112\n",
      "epoch 56; iter: 0; batch classifier loss: 0.080780; batch adversarial loss: 0.439797\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080145; batch adversarial loss: 0.417827\n",
      "epoch 58; iter: 0; batch classifier loss: 0.072463; batch adversarial loss: 0.426148\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088620; batch adversarial loss: 0.452947\n",
      "epoch 60; iter: 0; batch classifier loss: 0.048855; batch adversarial loss: 0.371916\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068281; batch adversarial loss: 0.477455\n",
      "epoch 62; iter: 0; batch classifier loss: 0.134312; batch adversarial loss: 0.435874\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067134; batch adversarial loss: 0.486698\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064677; batch adversarial loss: 0.460193\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083500; batch adversarial loss: 0.432072\n",
      "epoch 66; iter: 0; batch classifier loss: 0.039383; batch adversarial loss: 0.371689\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063170; batch adversarial loss: 0.416924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065867; batch adversarial loss: 0.445272\n",
      "epoch 69; iter: 0; batch classifier loss: 0.044665; batch adversarial loss: 0.431526\n",
      "epoch 70; iter: 0; batch classifier loss: 0.043214; batch adversarial loss: 0.458323\n",
      "epoch 71; iter: 0; batch classifier loss: 0.068833; batch adversarial loss: 0.517703\n",
      "epoch 72; iter: 0; batch classifier loss: 0.104685; batch adversarial loss: 0.404984\n",
      "epoch 73; iter: 0; batch classifier loss: 0.053933; batch adversarial loss: 0.414263\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053038; batch adversarial loss: 0.552619\n",
      "epoch 75; iter: 0; batch classifier loss: 0.112246; batch adversarial loss: 0.419969\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078416; batch adversarial loss: 0.410366\n",
      "epoch 77; iter: 0; batch classifier loss: 0.095871; batch adversarial loss: 0.460776\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115475; batch adversarial loss: 0.384919\n",
      "epoch 79; iter: 0; batch classifier loss: 0.092192; batch adversarial loss: 0.503882\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072485; batch adversarial loss: 0.394786\n",
      "epoch 81; iter: 0; batch classifier loss: 0.056514; batch adversarial loss: 0.367519\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050942; batch adversarial loss: 0.499729\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065833; batch adversarial loss: 0.533725\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058474; batch adversarial loss: 0.417649\n",
      "epoch 85; iter: 0; batch classifier loss: 0.107565; batch adversarial loss: 0.452422\n",
      "epoch 86; iter: 0; batch classifier loss: 0.065712; batch adversarial loss: 0.412400\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095790; batch adversarial loss: 0.476746\n",
      "epoch 88; iter: 0; batch classifier loss: 0.082661; batch adversarial loss: 0.418336\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048643; batch adversarial loss: 0.520870\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060738; batch adversarial loss: 0.470105\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097662; batch adversarial loss: 0.444494\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059422; batch adversarial loss: 0.410866\n",
      "epoch 93; iter: 0; batch classifier loss: 0.076089; batch adversarial loss: 0.480210\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050573; batch adversarial loss: 0.429726\n",
      "epoch 95; iter: 0; batch classifier loss: 0.061364; batch adversarial loss: 0.421079\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082165; batch adversarial loss: 0.454875\n",
      "epoch 97; iter: 0; batch classifier loss: 0.101234; batch adversarial loss: 0.430107\n",
      "epoch 98; iter: 0; batch classifier loss: 0.092383; batch adversarial loss: 0.427528\n",
      "epoch 99; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.504583\n",
      "epoch 100; iter: 0; batch classifier loss: 0.055368; batch adversarial loss: 0.462530\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075096; batch adversarial loss: 0.570493\n",
      "epoch 102; iter: 0; batch classifier loss: 0.075178; batch adversarial loss: 0.550199\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066352; batch adversarial loss: 0.573970\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041465; batch adversarial loss: 0.424528\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076340; batch adversarial loss: 0.411930\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075623; batch adversarial loss: 0.413970\n",
      "epoch 107; iter: 0; batch classifier loss: 0.074284; batch adversarial loss: 0.422730\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037923; batch adversarial loss: 0.471920\n",
      "epoch 109; iter: 0; batch classifier loss: 0.074897; batch adversarial loss: 0.474295\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.408872\n",
      "epoch 111; iter: 0; batch classifier loss: 0.036844; batch adversarial loss: 0.418497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.038951; batch adversarial loss: 0.440023\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042611; batch adversarial loss: 0.484813\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048821; batch adversarial loss: 0.539535\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044422; batch adversarial loss: 0.345046\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027074; batch adversarial loss: 0.577745\n",
      "epoch 117; iter: 0; batch classifier loss: 0.043790; batch adversarial loss: 0.519720\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046398; batch adversarial loss: 0.450495\n",
      "epoch 119; iter: 0; batch classifier loss: 0.066546; batch adversarial loss: 0.456754\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044884; batch adversarial loss: 0.525006\n",
      "epoch 121; iter: 0; batch classifier loss: 0.062595; batch adversarial loss: 0.391172\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034757; batch adversarial loss: 0.453085\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051473; batch adversarial loss: 0.433887\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057092; batch adversarial loss: 0.520703\n",
      "epoch 125; iter: 0; batch classifier loss: 0.088169; batch adversarial loss: 0.408454\n",
      "epoch 126; iter: 0; batch classifier loss: 0.030621; batch adversarial loss: 0.463411\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036294; batch adversarial loss: 0.480206\n",
      "epoch 128; iter: 0; batch classifier loss: 0.082252; batch adversarial loss: 0.479720\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041631; batch adversarial loss: 0.506019\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045986; batch adversarial loss: 0.564243\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029150; batch adversarial loss: 0.357662\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047954; batch adversarial loss: 0.489054\n",
      "epoch 133; iter: 0; batch classifier loss: 0.038506; batch adversarial loss: 0.424512\n",
      "epoch 134; iter: 0; batch classifier loss: 0.049554; batch adversarial loss: 0.518307\n",
      "epoch 135; iter: 0; batch classifier loss: 0.061210; batch adversarial loss: 0.434506\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032367; batch adversarial loss: 0.447405\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038193; batch adversarial loss: 0.460357\n",
      "epoch 138; iter: 0; batch classifier loss: 0.030078; batch adversarial loss: 0.457319\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020666; batch adversarial loss: 0.414148\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045146; batch adversarial loss: 0.498842\n",
      "epoch 141; iter: 0; batch classifier loss: 0.072588; batch adversarial loss: 0.439308\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032665; batch adversarial loss: 0.402534\n",
      "epoch 143; iter: 0; batch classifier loss: 0.082627; batch adversarial loss: 0.363954\n",
      "epoch 144; iter: 0; batch classifier loss: 0.047726; batch adversarial loss: 0.503049\n",
      "epoch 145; iter: 0; batch classifier loss: 0.038676; batch adversarial loss: 0.490185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044700; batch adversarial loss: 0.411358\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023266; batch adversarial loss: 0.351844\n",
      "epoch 148; iter: 0; batch classifier loss: 0.037664; batch adversarial loss: 0.507587\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026279; batch adversarial loss: 0.328862\n",
      "epoch 150; iter: 0; batch classifier loss: 0.026393; batch adversarial loss: 0.479367\n",
      "epoch 151; iter: 0; batch classifier loss: 0.086944; batch adversarial loss: 0.494377\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038525; batch adversarial loss: 0.412351\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038253; batch adversarial loss: 0.380806\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019218; batch adversarial loss: 0.464795\n",
      "epoch 155; iter: 0; batch classifier loss: 0.050496; batch adversarial loss: 0.477147\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045517; batch adversarial loss: 0.514122\n",
      "epoch 157; iter: 0; batch classifier loss: 0.030310; batch adversarial loss: 0.375972\n",
      "epoch 158; iter: 0; batch classifier loss: 0.038806; batch adversarial loss: 0.470050\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025862; batch adversarial loss: 0.533403\n",
      "epoch 160; iter: 0; batch classifier loss: 0.079933; batch adversarial loss: 0.414930\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012936; batch adversarial loss: 0.516201\n",
      "epoch 162; iter: 0; batch classifier loss: 0.028555; batch adversarial loss: 0.367525\n",
      "epoch 163; iter: 0; batch classifier loss: 0.070962; batch adversarial loss: 0.438678\n",
      "epoch 164; iter: 0; batch classifier loss: 0.049758; batch adversarial loss: 0.491989\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024572; batch adversarial loss: 0.571161\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026810; batch adversarial loss: 0.346956\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016517; batch adversarial loss: 0.457358\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027995; batch adversarial loss: 0.343904\n",
      "epoch 169; iter: 0; batch classifier loss: 0.067222; batch adversarial loss: 0.426111\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029185; batch adversarial loss: 0.518295\n",
      "epoch 171; iter: 0; batch classifier loss: 0.051727; batch adversarial loss: 0.392121\n",
      "epoch 172; iter: 0; batch classifier loss: 0.016307; batch adversarial loss: 0.483615\n",
      "epoch 173; iter: 0; batch classifier loss: 0.030315; batch adversarial loss: 0.449057\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048407; batch adversarial loss: 0.356780\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049619; batch adversarial loss: 0.343868\n",
      "epoch 176; iter: 0; batch classifier loss: 0.045363; batch adversarial loss: 0.403196\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021330; batch adversarial loss: 0.443606\n",
      "epoch 178; iter: 0; batch classifier loss: 0.051788; batch adversarial loss: 0.401136\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025017; batch adversarial loss: 0.428047\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016146; batch adversarial loss: 0.401276\n",
      "epoch 181; iter: 0; batch classifier loss: 0.014876; batch adversarial loss: 0.468450\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021315; batch adversarial loss: 0.484156\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031227; batch adversarial loss: 0.445164\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020369; batch adversarial loss: 0.457684\n",
      "epoch 185; iter: 0; batch classifier loss: 0.051477; batch adversarial loss: 0.461803\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019128; batch adversarial loss: 0.407218\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014863; batch adversarial loss: 0.471058\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007423; batch adversarial loss: 0.427220\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030106; batch adversarial loss: 0.450318\n",
      "epoch 190; iter: 0; batch classifier loss: 0.014662; batch adversarial loss: 0.472948\n",
      "epoch 191; iter: 0; batch classifier loss: 0.047367; batch adversarial loss: 0.423829\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024932; batch adversarial loss: 0.459460\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035471; batch adversarial loss: 0.361349\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013971; batch adversarial loss: 0.419640\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010518; batch adversarial loss: 0.454694\n",
      "epoch 196; iter: 0; batch classifier loss: 0.052891; batch adversarial loss: 0.433465\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012583; batch adversarial loss: 0.529975\n",
      "epoch 198; iter: 0; batch classifier loss: 0.038177; batch adversarial loss: 0.492751\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013908; batch adversarial loss: 0.557711\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711516; batch adversarial loss: 0.618511\n",
      "epoch 1; iter: 0; batch classifier loss: 0.380709; batch adversarial loss: 0.627014\n",
      "epoch 2; iter: 0; batch classifier loss: 0.340856; batch adversarial loss: 0.575758\n",
      "epoch 3; iter: 0; batch classifier loss: 0.468347; batch adversarial loss: 0.646060\n",
      "epoch 4; iter: 0; batch classifier loss: 0.493966; batch adversarial loss: 0.636665\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496639; batch adversarial loss: 0.582174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.488765; batch adversarial loss: 0.597418\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547382; batch adversarial loss: 0.590445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.555938\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453400; batch adversarial loss: 0.493871\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370539; batch adversarial loss: 0.517583\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391171; batch adversarial loss: 0.516666\n",
      "epoch 12; iter: 0; batch classifier loss: 0.450952; batch adversarial loss: 0.452265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381176; batch adversarial loss: 0.517770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284642; batch adversarial loss: 0.525729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324741; batch adversarial loss: 0.529040\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336714; batch adversarial loss: 0.425876\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225706; batch adversarial loss: 0.468312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310892; batch adversarial loss: 0.467145\n",
      "epoch 19; iter: 0; batch classifier loss: 0.289137; batch adversarial loss: 0.496209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.229018; batch adversarial loss: 0.477813\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252863; batch adversarial loss: 0.524493\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250394; batch adversarial loss: 0.450761\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233155; batch adversarial loss: 0.428241\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293096; batch adversarial loss: 0.433815\n",
      "epoch 25; iter: 0; batch classifier loss: 0.232973; batch adversarial loss: 0.498947\n",
      "epoch 26; iter: 0; batch classifier loss: 0.248583; batch adversarial loss: 0.458797\n",
      "epoch 27; iter: 0; batch classifier loss: 0.249664; batch adversarial loss: 0.462139\n",
      "epoch 28; iter: 0; batch classifier loss: 0.208907; batch adversarial loss: 0.487575\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270872; batch adversarial loss: 0.444606\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200194; batch adversarial loss: 0.502637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168087; batch adversarial loss: 0.585557\n",
      "epoch 32; iter: 0; batch classifier loss: 0.241406; batch adversarial loss: 0.493599\n",
      "epoch 33; iter: 0; batch classifier loss: 0.251660; batch adversarial loss: 0.412228\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222530; batch adversarial loss: 0.396840\n",
      "epoch 35; iter: 0; batch classifier loss: 0.243193; batch adversarial loss: 0.407512\n",
      "epoch 36; iter: 0; batch classifier loss: 0.212249; batch adversarial loss: 0.414555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170710; batch adversarial loss: 0.436025\n",
      "epoch 38; iter: 0; batch classifier loss: 0.264503; batch adversarial loss: 0.423845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.163502; batch adversarial loss: 0.508992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.204508; batch adversarial loss: 0.421670\n",
      "epoch 41; iter: 0; batch classifier loss: 0.205805; batch adversarial loss: 0.447737\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152008; batch adversarial loss: 0.432926\n",
      "epoch 43; iter: 0; batch classifier loss: 0.268490; batch adversarial loss: 0.411349\n",
      "epoch 44; iter: 0; batch classifier loss: 0.178183; batch adversarial loss: 0.448966\n",
      "epoch 45; iter: 0; batch classifier loss: 0.172430; batch adversarial loss: 0.437509\n",
      "epoch 46; iter: 0; batch classifier loss: 0.202506; batch adversarial loss: 0.408213\n",
      "epoch 47; iter: 0; batch classifier loss: 0.225730; batch adversarial loss: 0.421815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194104; batch adversarial loss: 0.375342\n",
      "epoch 49; iter: 0; batch classifier loss: 0.197092; batch adversarial loss: 0.447145\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177925; batch adversarial loss: 0.495958\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178985; batch adversarial loss: 0.509769\n",
      "epoch 52; iter: 0; batch classifier loss: 0.191646; batch adversarial loss: 0.447315\n",
      "epoch 53; iter: 0; batch classifier loss: 0.171638; batch adversarial loss: 0.434831\n",
      "epoch 54; iter: 0; batch classifier loss: 0.209050; batch adversarial loss: 0.409950\n",
      "epoch 55; iter: 0; batch classifier loss: 0.283874; batch adversarial loss: 0.422182\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102151; batch adversarial loss: 0.471761\n",
      "epoch 57; iter: 0; batch classifier loss: 0.106072; batch adversarial loss: 0.469747\n",
      "epoch 58; iter: 0; batch classifier loss: 0.073896; batch adversarial loss: 0.425255\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099640; batch adversarial loss: 0.446126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.088497; batch adversarial loss: 0.418791\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071352; batch adversarial loss: 0.328047\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080210; batch adversarial loss: 0.502045\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063095; batch adversarial loss: 0.525598\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085896; batch adversarial loss: 0.433447\n",
      "epoch 65; iter: 0; batch classifier loss: 0.074982; batch adversarial loss: 0.424544\n",
      "epoch 66; iter: 0; batch classifier loss: 0.081516; batch adversarial loss: 0.411114\n",
      "epoch 67; iter: 0; batch classifier loss: 0.068445; batch adversarial loss: 0.424506\n",
      "epoch 68; iter: 0; batch classifier loss: 0.110373; batch adversarial loss: 0.457684\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052231; batch adversarial loss: 0.451122\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073002; batch adversarial loss: 0.483021\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055998; batch adversarial loss: 0.523816\n",
      "epoch 72; iter: 0; batch classifier loss: 0.055544; batch adversarial loss: 0.445382\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084242; batch adversarial loss: 0.371592\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066004; batch adversarial loss: 0.488849\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076233; batch adversarial loss: 0.398153\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059076; batch adversarial loss: 0.422037\n",
      "epoch 77; iter: 0; batch classifier loss: 0.046490; batch adversarial loss: 0.359253\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102980; batch adversarial loss: 0.407473\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064895; batch adversarial loss: 0.432895\n",
      "epoch 80; iter: 0; batch classifier loss: 0.092213; batch adversarial loss: 0.493510\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074110; batch adversarial loss: 0.330609\n",
      "epoch 82; iter: 0; batch classifier loss: 0.045890; batch adversarial loss: 0.385527\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.392825\n",
      "epoch 84; iter: 0; batch classifier loss: 0.087677; batch adversarial loss: 0.493620\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052277; batch adversarial loss: 0.460764\n",
      "epoch 86; iter: 0; batch classifier loss: 0.072862; batch adversarial loss: 0.435004\n",
      "epoch 87; iter: 0; batch classifier loss: 0.048197; batch adversarial loss: 0.364150\n",
      "epoch 88; iter: 0; batch classifier loss: 0.046047; batch adversarial loss: 0.440203\n",
      "epoch 89; iter: 0; batch classifier loss: 0.067700; batch adversarial loss: 0.341210\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052045; batch adversarial loss: 0.438387\n",
      "epoch 91; iter: 0; batch classifier loss: 0.068021; batch adversarial loss: 0.355722\n",
      "epoch 92; iter: 0; batch classifier loss: 0.072746; batch adversarial loss: 0.508910\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044775; batch adversarial loss: 0.388153\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082057; batch adversarial loss: 0.478114\n",
      "epoch 95; iter: 0; batch classifier loss: 0.110109; batch adversarial loss: 0.399742\n",
      "epoch 96; iter: 0; batch classifier loss: 0.085845; batch adversarial loss: 0.474687\n",
      "epoch 97; iter: 0; batch classifier loss: 0.087142; batch adversarial loss: 0.386663\n",
      "epoch 98; iter: 0; batch classifier loss: 0.109552; batch adversarial loss: 0.556468\n",
      "epoch 99; iter: 0; batch classifier loss: 0.071011; batch adversarial loss: 0.469894\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093070; batch adversarial loss: 0.395666\n",
      "epoch 101; iter: 0; batch classifier loss: 0.079817; batch adversarial loss: 0.462763\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060693; batch adversarial loss: 0.373062\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050036; batch adversarial loss: 0.384513\n",
      "epoch 104; iter: 0; batch classifier loss: 0.099873; batch adversarial loss: 0.408658\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082188; batch adversarial loss: 0.373293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.060399; batch adversarial loss: 0.493156\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031162; batch adversarial loss: 0.314532\n",
      "epoch 108; iter: 0; batch classifier loss: 0.046245; batch adversarial loss: 0.427476\n",
      "epoch 109; iter: 0; batch classifier loss: 0.101294; batch adversarial loss: 0.394004\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057121; batch adversarial loss: 0.484916\n",
      "epoch 111; iter: 0; batch classifier loss: 0.058505; batch adversarial loss: 0.380234\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071914; batch adversarial loss: 0.383085\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053585; batch adversarial loss: 0.472985\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078760; batch adversarial loss: 0.433978\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041455; batch adversarial loss: 0.403093\n",
      "epoch 116; iter: 0; batch classifier loss: 0.086923; batch adversarial loss: 0.428832\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048703; batch adversarial loss: 0.444388\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078463; batch adversarial loss: 0.397677\n",
      "epoch 119; iter: 0; batch classifier loss: 0.091182; batch adversarial loss: 0.372704\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045193; batch adversarial loss: 0.455059\n",
      "epoch 121; iter: 0; batch classifier loss: 0.074383; batch adversarial loss: 0.467638\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055333; batch adversarial loss: 0.375438\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059147; batch adversarial loss: 0.472178\n",
      "epoch 124; iter: 0; batch classifier loss: 0.077881; batch adversarial loss: 0.507822\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047504; batch adversarial loss: 0.538766\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048431; batch adversarial loss: 0.383724\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056213; batch adversarial loss: 0.508907\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037446; batch adversarial loss: 0.358666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.071276; batch adversarial loss: 0.312432\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053559; batch adversarial loss: 0.422175\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050373; batch adversarial loss: 0.425109\n",
      "epoch 132; iter: 0; batch classifier loss: 0.078391; batch adversarial loss: 0.506059\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043741; batch adversarial loss: 0.467393\n",
      "epoch 134; iter: 0; batch classifier loss: 0.074213; batch adversarial loss: 0.513836\n",
      "epoch 135; iter: 0; batch classifier loss: 0.065083; batch adversarial loss: 0.438598\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057678; batch adversarial loss: 0.375162\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039311; batch adversarial loss: 0.377542\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055511; batch adversarial loss: 0.335612\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042481; batch adversarial loss: 0.342903\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040029; batch adversarial loss: 0.381377\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045662; batch adversarial loss: 0.407024\n",
      "epoch 142; iter: 0; batch classifier loss: 0.047056; batch adversarial loss: 0.370829\n",
      "epoch 143; iter: 0; batch classifier loss: 0.044730; batch adversarial loss: 0.540712\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050474; batch adversarial loss: 0.428390\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064614; batch adversarial loss: 0.498057\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040346; batch adversarial loss: 0.457687\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027416; batch adversarial loss: 0.457407\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019798; batch adversarial loss: 0.365104\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025638; batch adversarial loss: 0.581070\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029106; batch adversarial loss: 0.417565\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029938; batch adversarial loss: 0.487347\n",
      "epoch 152; iter: 0; batch classifier loss: 0.020911; batch adversarial loss: 0.400110\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037188; batch adversarial loss: 0.450861\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028692; batch adversarial loss: 0.462437\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021196; batch adversarial loss: 0.444914\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030533; batch adversarial loss: 0.396791\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.457596\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035800; batch adversarial loss: 0.436119\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047862; batch adversarial loss: 0.548938\n",
      "epoch 160; iter: 0; batch classifier loss: 0.042085; batch adversarial loss: 0.419619\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022858; batch adversarial loss: 0.354841\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030468; batch adversarial loss: 0.494422\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.435585\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032306; batch adversarial loss: 0.394247\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027829; batch adversarial loss: 0.549994\n",
      "epoch 166; iter: 0; batch classifier loss: 0.016007; batch adversarial loss: 0.547242\n",
      "epoch 167; iter: 0; batch classifier loss: 0.030955; batch adversarial loss: 0.473484\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023896; batch adversarial loss: 0.422881\n",
      "epoch 169; iter: 0; batch classifier loss: 0.024631; batch adversarial loss: 0.382997\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027610; batch adversarial loss: 0.402815\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029191; batch adversarial loss: 0.507820\n",
      "epoch 172; iter: 0; batch classifier loss: 0.047341; batch adversarial loss: 0.366652\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025561; batch adversarial loss: 0.525472\n",
      "epoch 174; iter: 0; batch classifier loss: 0.016010; batch adversarial loss: 0.427322\n",
      "epoch 175; iter: 0; batch classifier loss: 0.036772; batch adversarial loss: 0.488690\n",
      "epoch 176; iter: 0; batch classifier loss: 0.015295; batch adversarial loss: 0.481463\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029211; batch adversarial loss: 0.374588\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025544; batch adversarial loss: 0.430247\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017571; batch adversarial loss: 0.418663\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015691; batch adversarial loss: 0.395392\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009904; batch adversarial loss: 0.499893\n",
      "epoch 182; iter: 0; batch classifier loss: 0.060376; batch adversarial loss: 0.537704\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009535; batch adversarial loss: 0.387930\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013005; batch adversarial loss: 0.453432\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029224; batch adversarial loss: 0.450842\n",
      "epoch 186; iter: 0; batch classifier loss: 0.011400; batch adversarial loss: 0.413040\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013678; batch adversarial loss: 0.406331\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033385; batch adversarial loss: 0.469316\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007845; batch adversarial loss: 0.460354\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013726; batch adversarial loss: 0.406452\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009351; batch adversarial loss: 0.330507\n",
      "epoch 192; iter: 0; batch classifier loss: 0.015330; batch adversarial loss: 0.490903\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019029; batch adversarial loss: 0.439870\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031007; batch adversarial loss: 0.360865\n",
      "epoch 195; iter: 0; batch classifier loss: 0.017962; batch adversarial loss: 0.512759\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007389; batch adversarial loss: 0.368517\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017785; batch adversarial loss: 0.421998\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013904; batch adversarial loss: 0.451391\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016878; batch adversarial loss: 0.412541\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699333; batch adversarial loss: 1.058844\n",
      "epoch 1; iter: 0; batch classifier loss: 0.499832; batch adversarial loss: 1.228720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.461995; batch adversarial loss: 1.207702\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464703; batch adversarial loss: 1.034912\n",
      "epoch 4; iter: 0; batch classifier loss: 0.427413; batch adversarial loss: 0.988732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.359570; batch adversarial loss: 0.940381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.352527; batch adversarial loss: 0.783757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300494; batch adversarial loss: 0.749142\n",
      "epoch 8; iter: 0; batch classifier loss: 0.220940; batch adversarial loss: 0.686304\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321571; batch adversarial loss: 0.662871\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268627; batch adversarial loss: 0.619728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.215884; batch adversarial loss: 0.584582\n",
      "epoch 12; iter: 0; batch classifier loss: 0.296518; batch adversarial loss: 0.608468\n",
      "epoch 13; iter: 0; batch classifier loss: 0.218515; batch adversarial loss: 0.592750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.186488; batch adversarial loss: 0.552117\n",
      "epoch 15; iter: 0; batch classifier loss: 0.239241; batch adversarial loss: 0.573586\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229926; batch adversarial loss: 0.556197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.230112; batch adversarial loss: 0.543016\n",
      "epoch 18; iter: 0; batch classifier loss: 0.239584; batch adversarial loss: 0.519283\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261470; batch adversarial loss: 0.513681\n",
      "epoch 20; iter: 0; batch classifier loss: 0.198129; batch adversarial loss: 0.529933\n",
      "epoch 21; iter: 0; batch classifier loss: 0.162718; batch adversarial loss: 0.553722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.203036; batch adversarial loss: 0.490143\n",
      "epoch 23; iter: 0; batch classifier loss: 0.175406; batch adversarial loss: 0.492320\n",
      "epoch 24; iter: 0; batch classifier loss: 0.168321; batch adversarial loss: 0.531140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159637; batch adversarial loss: 0.491683\n",
      "epoch 26; iter: 0; batch classifier loss: 0.135477; batch adversarial loss: 0.466928\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149433; batch adversarial loss: 0.440862\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173650; batch adversarial loss: 0.518474\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150860; batch adversarial loss: 0.460458\n",
      "epoch 30; iter: 0; batch classifier loss: 0.210429; batch adversarial loss: 0.393836\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222062; batch adversarial loss: 0.378247\n",
      "epoch 32; iter: 0; batch classifier loss: 0.281890; batch adversarial loss: 0.462860\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213898; batch adversarial loss: 0.464102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.216091; batch adversarial loss: 0.497489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299982; batch adversarial loss: 0.414955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.256760; batch adversarial loss: 0.378350\n",
      "epoch 37; iter: 0; batch classifier loss: 0.293081; batch adversarial loss: 0.429501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.265676; batch adversarial loss: 0.416783\n",
      "epoch 39; iter: 0; batch classifier loss: 0.227910; batch adversarial loss: 0.406443\n",
      "epoch 40; iter: 0; batch classifier loss: 0.267506; batch adversarial loss: 0.465544\n",
      "epoch 41; iter: 0; batch classifier loss: 0.218340; batch adversarial loss: 0.420779\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205040; batch adversarial loss: 0.374474\n",
      "epoch 43; iter: 0; batch classifier loss: 0.215954; batch adversarial loss: 0.300651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211391; batch adversarial loss: 0.435065\n",
      "epoch 45; iter: 0; batch classifier loss: 0.201823; batch adversarial loss: 0.376187\n",
      "epoch 46; iter: 0; batch classifier loss: 0.158196; batch adversarial loss: 0.447493\n",
      "epoch 47; iter: 0; batch classifier loss: 0.158629; batch adversarial loss: 0.402929\n",
      "epoch 48; iter: 0; batch classifier loss: 0.154917; batch adversarial loss: 0.507693\n",
      "epoch 49; iter: 0; batch classifier loss: 0.128247; batch adversarial loss: 0.390290\n",
      "epoch 50; iter: 0; batch classifier loss: 0.161011; batch adversarial loss: 0.493328\n",
      "epoch 51; iter: 0; batch classifier loss: 0.177609; batch adversarial loss: 0.388852\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155753; batch adversarial loss: 0.445472\n",
      "epoch 53; iter: 0; batch classifier loss: 0.091538; batch adversarial loss: 0.330479\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099903; batch adversarial loss: 0.491704\n",
      "epoch 55; iter: 0; batch classifier loss: 0.140373; batch adversarial loss: 0.441307\n",
      "epoch 56; iter: 0; batch classifier loss: 0.108041; batch adversarial loss: 0.458953\n",
      "epoch 57; iter: 0; batch classifier loss: 0.164021; batch adversarial loss: 0.381967\n",
      "epoch 58; iter: 0; batch classifier loss: 0.135744; batch adversarial loss: 0.385752\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122394; batch adversarial loss: 0.422042\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091022; batch adversarial loss: 0.396556\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093948; batch adversarial loss: 0.479448\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076684; batch adversarial loss: 0.415701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.117213; batch adversarial loss: 0.471315\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081243; batch adversarial loss: 0.339403\n",
      "epoch 65; iter: 0; batch classifier loss: 0.081576; batch adversarial loss: 0.407813\n",
      "epoch 66; iter: 0; batch classifier loss: 0.075236; batch adversarial loss: 0.375370\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096263; batch adversarial loss: 0.305964\n",
      "epoch 68; iter: 0; batch classifier loss: 0.126720; batch adversarial loss: 0.472549\n",
      "epoch 69; iter: 0; batch classifier loss: 0.097443; batch adversarial loss: 0.503713\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090137; batch adversarial loss: 0.429587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.129441; batch adversarial loss: 0.412555\n",
      "epoch 72; iter: 0; batch classifier loss: 0.071748; batch adversarial loss: 0.318877\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066188; batch adversarial loss: 0.409008\n",
      "epoch 74; iter: 0; batch classifier loss: 0.126336; batch adversarial loss: 0.423849\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096073; batch adversarial loss: 0.408364\n",
      "epoch 76; iter: 0; batch classifier loss: 0.076370; batch adversarial loss: 0.362985\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071963; batch adversarial loss: 0.343992\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096830; batch adversarial loss: 0.495527\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065631; batch adversarial loss: 0.355688\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079112; batch adversarial loss: 0.369462\n",
      "epoch 81; iter: 0; batch classifier loss: 0.109232; batch adversarial loss: 0.450331\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067667; batch adversarial loss: 0.406627\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054604; batch adversarial loss: 0.343110\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066253; batch adversarial loss: 0.342951\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045963; batch adversarial loss: 0.390544\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052760; batch adversarial loss: 0.349078\n",
      "epoch 87; iter: 0; batch classifier loss: 0.114548; batch adversarial loss: 0.405907\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062217; batch adversarial loss: 0.461216\n",
      "epoch 89; iter: 0; batch classifier loss: 0.073963; batch adversarial loss: 0.534234\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048605; batch adversarial loss: 0.385516\n",
      "epoch 91; iter: 0; batch classifier loss: 0.072588; batch adversarial loss: 0.452556\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074872; batch adversarial loss: 0.451867\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053773; batch adversarial loss: 0.364059\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078352; batch adversarial loss: 0.467871\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060403; batch adversarial loss: 0.373120\n",
      "epoch 96; iter: 0; batch classifier loss: 0.112106; batch adversarial loss: 0.484583\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058101; batch adversarial loss: 0.377924\n",
      "epoch 98; iter: 0; batch classifier loss: 0.063943; batch adversarial loss: 0.392300\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043053; batch adversarial loss: 0.453687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100; iter: 0; batch classifier loss: 0.074043; batch adversarial loss: 0.385962\n",
      "epoch 101; iter: 0; batch classifier loss: 0.092947; batch adversarial loss: 0.480290\n",
      "epoch 102; iter: 0; batch classifier loss: 0.067851; batch adversarial loss: 0.438319\n",
      "epoch 103; iter: 0; batch classifier loss: 0.115254; batch adversarial loss: 0.411100\n",
      "epoch 104; iter: 0; batch classifier loss: 0.061337; batch adversarial loss: 0.294826\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074100; batch adversarial loss: 0.397569\n",
      "epoch 106; iter: 0; batch classifier loss: 0.036600; batch adversarial loss: 0.347362\n",
      "epoch 107; iter: 0; batch classifier loss: 0.056052; batch adversarial loss: 0.386275\n",
      "epoch 108; iter: 0; batch classifier loss: 0.064550; batch adversarial loss: 0.454497\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044026; batch adversarial loss: 0.436876\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059251; batch adversarial loss: 0.367770\n",
      "epoch 111; iter: 0; batch classifier loss: 0.094403; batch adversarial loss: 0.405377\n",
      "epoch 112; iter: 0; batch classifier loss: 0.076990; batch adversarial loss: 0.413390\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055072; batch adversarial loss: 0.414728\n",
      "epoch 114; iter: 0; batch classifier loss: 0.082794; batch adversarial loss: 0.395620\n",
      "epoch 115; iter: 0; batch classifier loss: 0.079688; batch adversarial loss: 0.388223\n",
      "epoch 116; iter: 0; batch classifier loss: 0.089147; batch adversarial loss: 0.483390\n",
      "epoch 117; iter: 0; batch classifier loss: 0.102598; batch adversarial loss: 0.356029\n",
      "epoch 118; iter: 0; batch classifier loss: 0.081217; batch adversarial loss: 0.479587\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056639; batch adversarial loss: 0.421935\n",
      "epoch 120; iter: 0; batch classifier loss: 0.047779; batch adversarial loss: 0.389374\n",
      "epoch 121; iter: 0; batch classifier loss: 0.075969; batch adversarial loss: 0.485205\n",
      "epoch 122; iter: 0; batch classifier loss: 0.076624; batch adversarial loss: 0.392923\n",
      "epoch 123; iter: 0; batch classifier loss: 0.067082; batch adversarial loss: 0.348504\n",
      "epoch 124; iter: 0; batch classifier loss: 0.068864; batch adversarial loss: 0.396117\n",
      "epoch 125; iter: 0; batch classifier loss: 0.052568; batch adversarial loss: 0.427067\n",
      "epoch 126; iter: 0; batch classifier loss: 0.047800; batch adversarial loss: 0.444154\n",
      "epoch 127; iter: 0; batch classifier loss: 0.065456; batch adversarial loss: 0.397130\n",
      "epoch 128; iter: 0; batch classifier loss: 0.087681; batch adversarial loss: 0.514357\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057221; batch adversarial loss: 0.352429\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060176; batch adversarial loss: 0.423701\n",
      "epoch 131; iter: 0; batch classifier loss: 0.059691; batch adversarial loss: 0.387076\n",
      "epoch 132; iter: 0; batch classifier loss: 0.047254; batch adversarial loss: 0.423496\n",
      "epoch 133; iter: 0; batch classifier loss: 0.046667; batch adversarial loss: 0.426260\n",
      "epoch 134; iter: 0; batch classifier loss: 0.050956; batch adversarial loss: 0.362979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069265; batch adversarial loss: 0.442590\n",
      "epoch 136; iter: 0; batch classifier loss: 0.079416; batch adversarial loss: 0.409650\n",
      "epoch 137; iter: 0; batch classifier loss: 0.071005; batch adversarial loss: 0.459044\n",
      "epoch 138; iter: 0; batch classifier loss: 0.055205; batch adversarial loss: 0.434177\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042824; batch adversarial loss: 0.410382\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067542; batch adversarial loss: 0.447461\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061952; batch adversarial loss: 0.351194\n",
      "epoch 142; iter: 0; batch classifier loss: 0.053580; batch adversarial loss: 0.427902\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040210; batch adversarial loss: 0.358214\n",
      "epoch 144; iter: 0; batch classifier loss: 0.043307; batch adversarial loss: 0.460459\n",
      "epoch 145; iter: 0; batch classifier loss: 0.056567; batch adversarial loss: 0.399431\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048671; batch adversarial loss: 0.414517\n",
      "epoch 147; iter: 0; batch classifier loss: 0.041930; batch adversarial loss: 0.410234\n",
      "epoch 148; iter: 0; batch classifier loss: 0.064158; batch adversarial loss: 0.403252\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063914; batch adversarial loss: 0.382115\n",
      "epoch 150; iter: 0; batch classifier loss: 0.034768; batch adversarial loss: 0.302327\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021303; batch adversarial loss: 0.389473\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037536; batch adversarial loss: 0.419004\n",
      "epoch 153; iter: 0; batch classifier loss: 0.028734; batch adversarial loss: 0.476934\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045439; batch adversarial loss: 0.397875\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038345; batch adversarial loss: 0.444138\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043075; batch adversarial loss: 0.450221\n",
      "epoch 157; iter: 0; batch classifier loss: 0.064548; batch adversarial loss: 0.414464\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033757; batch adversarial loss: 0.362411\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029014; batch adversarial loss: 0.402281\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029749; batch adversarial loss: 0.377862\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027786; batch adversarial loss: 0.413489\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014913; batch adversarial loss: 0.501520\n",
      "epoch 163; iter: 0; batch classifier loss: 0.033863; batch adversarial loss: 0.394312\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016356; batch adversarial loss: 0.415180\n",
      "epoch 165; iter: 0; batch classifier loss: 0.048325; batch adversarial loss: 0.410268\n",
      "epoch 166; iter: 0; batch classifier loss: 0.015185; batch adversarial loss: 0.410028\n",
      "epoch 167; iter: 0; batch classifier loss: 0.037619; batch adversarial loss: 0.341332\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036141; batch adversarial loss: 0.425411\n",
      "epoch 169; iter: 0; batch classifier loss: 0.051896; batch adversarial loss: 0.464006\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021175; batch adversarial loss: 0.455740\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017832; batch adversarial loss: 0.394818\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021787; batch adversarial loss: 0.399223\n",
      "epoch 173; iter: 0; batch classifier loss: 0.028459; batch adversarial loss: 0.478063\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029085; batch adversarial loss: 0.457584\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026570; batch adversarial loss: 0.507010\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037889; batch adversarial loss: 0.412576\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014947; batch adversarial loss: 0.407771\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037866; batch adversarial loss: 0.425308\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023331; batch adversarial loss: 0.459307\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031922; batch adversarial loss: 0.520116\n",
      "epoch 181; iter: 0; batch classifier loss: 0.049021; batch adversarial loss: 0.463786\n",
      "epoch 182; iter: 0; batch classifier loss: 0.046302; batch adversarial loss: 0.466191\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015487; batch adversarial loss: 0.522615\n",
      "epoch 184; iter: 0; batch classifier loss: 0.069068; batch adversarial loss: 0.585133\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018560; batch adversarial loss: 0.433815\n",
      "epoch 186; iter: 0; batch classifier loss: 0.036969; batch adversarial loss: 0.473603\n",
      "epoch 187; iter: 0; batch classifier loss: 0.097705; batch adversarial loss: 0.597698\n",
      "epoch 188; iter: 0; batch classifier loss: 0.035166; batch adversarial loss: 0.478009\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063457; batch adversarial loss: 0.610441\n",
      "epoch 190; iter: 0; batch classifier loss: 0.126486; batch adversarial loss: 0.668944\n",
      "epoch 191; iter: 0; batch classifier loss: 0.070896; batch adversarial loss: 0.450870\n",
      "epoch 192; iter: 0; batch classifier loss: 0.126300; batch adversarial loss: 0.596792\n",
      "epoch 193; iter: 0; batch classifier loss: 0.157492; batch adversarial loss: 0.727235\n",
      "epoch 194; iter: 0; batch classifier loss: 0.146530; batch adversarial loss: 0.730261\n",
      "epoch 195; iter: 0; batch classifier loss: 0.094680; batch adversarial loss: 0.507317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 196; iter: 0; batch classifier loss: 0.120324; batch adversarial loss: 0.719273\n",
      "epoch 197; iter: 0; batch classifier loss: 0.122571; batch adversarial loss: 0.545287\n",
      "epoch 198; iter: 0; batch classifier loss: 0.108577; batch adversarial loss: 0.598309\n",
      "epoch 199; iter: 0; batch classifier loss: 0.104270; batch adversarial loss: 0.700015\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695065; batch adversarial loss: 0.613587\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400959; batch adversarial loss: 0.614331\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395248; batch adversarial loss: 0.598282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.365431; batch adversarial loss: 0.578701\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333090; batch adversarial loss: 0.551033\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420053; batch adversarial loss: 0.591798\n",
      "epoch 6; iter: 0; batch classifier loss: 0.354142; batch adversarial loss: 0.599155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.402551; batch adversarial loss: 0.583335\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355194; batch adversarial loss: 0.565504\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548847; batch adversarial loss: 0.550952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602653; batch adversarial loss: 0.553786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.664076; batch adversarial loss: 0.512843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.425211; batch adversarial loss: 0.526585\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278091; batch adversarial loss: 0.523147\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298649; batch adversarial loss: 0.574116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.279278; batch adversarial loss: 0.490722\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287643; batch adversarial loss: 0.494941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296870; batch adversarial loss: 0.519236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183430; batch adversarial loss: 0.495843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248314; batch adversarial loss: 0.520185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245930; batch adversarial loss: 0.401010\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263565; batch adversarial loss: 0.356630\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242364; batch adversarial loss: 0.498051\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236948; batch adversarial loss: 0.478481\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211224; batch adversarial loss: 0.524711\n",
      "epoch 25; iter: 0; batch classifier loss: 0.188239; batch adversarial loss: 0.463711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.208443; batch adversarial loss: 0.411585\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164065; batch adversarial loss: 0.514272\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175883; batch adversarial loss: 0.437382\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227765; batch adversarial loss: 0.404742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.178491; batch adversarial loss: 0.423692\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162846; batch adversarial loss: 0.428211\n",
      "epoch 32; iter: 0; batch classifier loss: 0.184597; batch adversarial loss: 0.473631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202692; batch adversarial loss: 0.442712\n",
      "epoch 34; iter: 0; batch classifier loss: 0.154405; batch adversarial loss: 0.562809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197657; batch adversarial loss: 0.417641\n",
      "epoch 36; iter: 0; batch classifier loss: 0.188130; batch adversarial loss: 0.519734\n",
      "epoch 37; iter: 0; batch classifier loss: 0.207794; batch adversarial loss: 0.453141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121104; batch adversarial loss: 0.500714\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162387; batch adversarial loss: 0.419955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.227772; batch adversarial loss: 0.351645\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168215; batch adversarial loss: 0.391130\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105056; batch adversarial loss: 0.501883\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134673; batch adversarial loss: 0.442767\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214336; batch adversarial loss: 0.451277\n",
      "epoch 45; iter: 0; batch classifier loss: 0.158742; batch adversarial loss: 0.409187\n",
      "epoch 46; iter: 0; batch classifier loss: 0.131809; batch adversarial loss: 0.538333\n",
      "epoch 47; iter: 0; batch classifier loss: 0.146988; batch adversarial loss: 0.459382\n",
      "epoch 48; iter: 0; batch classifier loss: 0.147662; batch adversarial loss: 0.487730\n",
      "epoch 49; iter: 0; batch classifier loss: 0.250154; batch adversarial loss: 0.345535\n",
      "epoch 50; iter: 0; batch classifier loss: 0.138904; batch adversarial loss: 0.357160\n",
      "epoch 51; iter: 0; batch classifier loss: 0.165351; batch adversarial loss: 0.488061\n",
      "epoch 52; iter: 0; batch classifier loss: 0.183885; batch adversarial loss: 0.431432\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169500; batch adversarial loss: 0.422982\n",
      "epoch 54; iter: 0; batch classifier loss: 0.223879; batch adversarial loss: 0.411802\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118075; batch adversarial loss: 0.530299\n",
      "epoch 56; iter: 0; batch classifier loss: 0.201298; batch adversarial loss: 0.548246\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170200; batch adversarial loss: 0.506856\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145597; batch adversarial loss: 0.491373\n",
      "epoch 59; iter: 0; batch classifier loss: 0.196584; batch adversarial loss: 0.431065\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189660; batch adversarial loss: 0.499397\n",
      "epoch 61; iter: 0; batch classifier loss: 0.150009; batch adversarial loss: 0.385493\n",
      "epoch 62; iter: 0; batch classifier loss: 0.198437; batch adversarial loss: 0.319959\n",
      "epoch 63; iter: 0; batch classifier loss: 0.248284; batch adversarial loss: 0.393985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.219486; batch adversarial loss: 0.444719\n",
      "epoch 65; iter: 0; batch classifier loss: 0.172372; batch adversarial loss: 0.436374\n",
      "epoch 66; iter: 0; batch classifier loss: 0.280004; batch adversarial loss: 0.382483\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122732; batch adversarial loss: 0.424954\n",
      "epoch 68; iter: 0; batch classifier loss: 0.180316; batch adversarial loss: 0.448951\n",
      "epoch 69; iter: 0; batch classifier loss: 0.152286; batch adversarial loss: 0.451864\n",
      "epoch 70; iter: 0; batch classifier loss: 0.152095; batch adversarial loss: 0.493381\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116807; batch adversarial loss: 0.458900\n",
      "epoch 72; iter: 0; batch classifier loss: 0.150919; batch adversarial loss: 0.413325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.182941; batch adversarial loss: 0.459330\n",
      "epoch 74; iter: 0; batch classifier loss: 0.164809; batch adversarial loss: 0.521516\n",
      "epoch 75; iter: 0; batch classifier loss: 0.170376; batch adversarial loss: 0.508047\n",
      "epoch 76; iter: 0; batch classifier loss: 0.098568; batch adversarial loss: 0.358388\n",
      "epoch 77; iter: 0; batch classifier loss: 0.222283; batch adversarial loss: 0.484716\n",
      "epoch 78; iter: 0; batch classifier loss: 0.168013; batch adversarial loss: 0.397252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.140998; batch adversarial loss: 0.506715\n",
      "epoch 80; iter: 0; batch classifier loss: 0.251275; batch adversarial loss: 0.397579\n",
      "epoch 81; iter: 0; batch classifier loss: 0.171065; batch adversarial loss: 0.332786\n",
      "epoch 82; iter: 0; batch classifier loss: 0.181222; batch adversarial loss: 0.420604\n",
      "epoch 83; iter: 0; batch classifier loss: 0.132541; batch adversarial loss: 0.433275\n",
      "epoch 84; iter: 0; batch classifier loss: 0.166803; batch adversarial loss: 0.395344\n",
      "epoch 85; iter: 0; batch classifier loss: 0.207725; batch adversarial loss: 0.446488\n",
      "epoch 86; iter: 0; batch classifier loss: 0.116571; batch adversarial loss: 0.383337\n",
      "epoch 87; iter: 0; batch classifier loss: 0.110610; batch adversarial loss: 0.509218\n",
      "epoch 88; iter: 0; batch classifier loss: 0.211897; batch adversarial loss: 0.471490\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121168; batch adversarial loss: 0.421126\n",
      "epoch 90; iter: 0; batch classifier loss: 0.217980; batch adversarial loss: 0.509174\n",
      "epoch 91; iter: 0; batch classifier loss: 0.139397; batch adversarial loss: 0.483674\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144038; batch adversarial loss: 0.484877\n",
      "epoch 93; iter: 0; batch classifier loss: 0.160854; batch adversarial loss: 0.420339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94; iter: 0; batch classifier loss: 0.164849; batch adversarial loss: 0.510616\n",
      "epoch 95; iter: 0; batch classifier loss: 0.178008; batch adversarial loss: 0.370968\n",
      "epoch 96; iter: 0; batch classifier loss: 0.169176; batch adversarial loss: 0.520984\n",
      "epoch 97; iter: 0; batch classifier loss: 0.139087; batch adversarial loss: 0.409257\n",
      "epoch 98; iter: 0; batch classifier loss: 0.166167; batch adversarial loss: 0.395270\n",
      "epoch 99; iter: 0; batch classifier loss: 0.172150; batch adversarial loss: 0.332712\n",
      "epoch 100; iter: 0; batch classifier loss: 0.155939; batch adversarial loss: 0.473572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.126917; batch adversarial loss: 0.371142\n",
      "epoch 102; iter: 0; batch classifier loss: 0.151130; batch adversarial loss: 0.434410\n",
      "epoch 103; iter: 0; batch classifier loss: 0.216985; batch adversarial loss: 0.371794\n",
      "epoch 104; iter: 0; batch classifier loss: 0.165696; batch adversarial loss: 0.383613\n",
      "epoch 105; iter: 0; batch classifier loss: 0.146072; batch adversarial loss: 0.496724\n",
      "epoch 106; iter: 0; batch classifier loss: 0.208444; batch adversarial loss: 0.456863\n",
      "epoch 107; iter: 0; batch classifier loss: 0.125742; batch adversarial loss: 0.509488\n",
      "epoch 108; iter: 0; batch classifier loss: 0.137175; batch adversarial loss: 0.522790\n",
      "epoch 109; iter: 0; batch classifier loss: 0.207376; batch adversarial loss: 0.459916\n",
      "epoch 110; iter: 0; batch classifier loss: 0.159663; batch adversarial loss: 0.459213\n",
      "epoch 111; iter: 0; batch classifier loss: 0.160352; batch adversarial loss: 0.408494\n",
      "epoch 112; iter: 0; batch classifier loss: 0.140386; batch adversarial loss: 0.433175\n",
      "epoch 113; iter: 0; batch classifier loss: 0.169459; batch adversarial loss: 0.421713\n",
      "epoch 114; iter: 0; batch classifier loss: 0.180287; batch adversarial loss: 0.483990\n",
      "epoch 115; iter: 0; batch classifier loss: 0.128641; batch adversarial loss: 0.394665\n",
      "epoch 116; iter: 0; batch classifier loss: 0.129391; batch adversarial loss: 0.534127\n",
      "epoch 117; iter: 0; batch classifier loss: 0.147408; batch adversarial loss: 0.472782\n",
      "epoch 118; iter: 0; batch classifier loss: 0.151451; batch adversarial loss: 0.383130\n",
      "epoch 119; iter: 0; batch classifier loss: 0.152009; batch adversarial loss: 0.483705\n",
      "epoch 120; iter: 0; batch classifier loss: 0.127292; batch adversarial loss: 0.519045\n",
      "epoch 121; iter: 0; batch classifier loss: 0.140254; batch adversarial loss: 0.509565\n",
      "epoch 122; iter: 0; batch classifier loss: 0.149319; batch adversarial loss: 0.522720\n",
      "epoch 123; iter: 0; batch classifier loss: 0.147589; batch adversarial loss: 0.394810\n",
      "epoch 124; iter: 0; batch classifier loss: 0.131407; batch adversarial loss: 0.406844\n",
      "epoch 125; iter: 0; batch classifier loss: 0.135219; batch adversarial loss: 0.319549\n",
      "epoch 126; iter: 0; batch classifier loss: 0.110836; batch adversarial loss: 0.573648\n",
      "epoch 127; iter: 0; batch classifier loss: 0.127834; batch adversarial loss: 0.485559\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065517; batch adversarial loss: 0.442945\n",
      "epoch 129; iter: 0; batch classifier loss: 0.090627; batch adversarial loss: 0.392906\n",
      "epoch 130; iter: 0; batch classifier loss: 0.070425; batch adversarial loss: 0.531340\n",
      "epoch 131; iter: 0; batch classifier loss: 0.050093; batch adversarial loss: 0.469383\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073203; batch adversarial loss: 0.513652\n",
      "epoch 133; iter: 0; batch classifier loss: 0.096829; batch adversarial loss: 0.414253\n",
      "epoch 134; iter: 0; batch classifier loss: 0.046854; batch adversarial loss: 0.444939\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039563; batch adversarial loss: 0.397255\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061600; batch adversarial loss: 0.411597\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066684; batch adversarial loss: 0.453107\n",
      "epoch 138; iter: 0; batch classifier loss: 0.063065; batch adversarial loss: 0.494518\n",
      "epoch 139; iter: 0; batch classifier loss: 0.044478; batch adversarial loss: 0.428086\n",
      "epoch 140; iter: 0; batch classifier loss: 0.042613; batch adversarial loss: 0.413081\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048984; batch adversarial loss: 0.475256\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041133; batch adversarial loss: 0.419749\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016604; batch adversarial loss: 0.471068\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016040; batch adversarial loss: 0.532183\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048789; batch adversarial loss: 0.404879\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015685; batch adversarial loss: 0.484161\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029208; batch adversarial loss: 0.386141\n",
      "epoch 148; iter: 0; batch classifier loss: 0.049638; batch adversarial loss: 0.593990\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036216; batch adversarial loss: 0.445546\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028973; batch adversarial loss: 0.467063\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034113; batch adversarial loss: 0.370499\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023903; batch adversarial loss: 0.485007\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037442; batch adversarial loss: 0.405518\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033711; batch adversarial loss: 0.437750\n",
      "epoch 155; iter: 0; batch classifier loss: 0.026739; batch adversarial loss: 0.409330\n",
      "epoch 156; iter: 0; batch classifier loss: 0.041169; batch adversarial loss: 0.392925\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036243; batch adversarial loss: 0.470911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025568; batch adversarial loss: 0.408086\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018237; batch adversarial loss: 0.430985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022442; batch adversarial loss: 0.409592\n",
      "epoch 161; iter: 0; batch classifier loss: 0.019376; batch adversarial loss: 0.484893\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025671; batch adversarial loss: 0.480393\n",
      "epoch 163; iter: 0; batch classifier loss: 0.049598; batch adversarial loss: 0.460240\n",
      "epoch 164; iter: 0; batch classifier loss: 0.023798; batch adversarial loss: 0.452306\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023735; batch adversarial loss: 0.516084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028692; batch adversarial loss: 0.462544\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020555; batch adversarial loss: 0.397654\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013814; batch adversarial loss: 0.432695\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033056; batch adversarial loss: 0.428394\n",
      "epoch 170; iter: 0; batch classifier loss: 0.039824; batch adversarial loss: 0.476086\n",
      "epoch 171; iter: 0; batch classifier loss: 0.029393; batch adversarial loss: 0.424301\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005298; batch adversarial loss: 0.493562\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041291; batch adversarial loss: 0.389771\n",
      "epoch 174; iter: 0; batch classifier loss: 0.054864; batch adversarial loss: 0.390174\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025533; batch adversarial loss: 0.446617\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016209; batch adversarial loss: 0.328972\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025429; batch adversarial loss: 0.493028\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017614; batch adversarial loss: 0.413421\n",
      "epoch 179; iter: 0; batch classifier loss: 0.025044; batch adversarial loss: 0.440277\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009705; batch adversarial loss: 0.390293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028410; batch adversarial loss: 0.388772\n",
      "epoch 182; iter: 0; batch classifier loss: 0.055868; batch adversarial loss: 0.438907\n",
      "epoch 183; iter: 0; batch classifier loss: 0.034064; batch adversarial loss: 0.413772\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035968; batch adversarial loss: 0.463183\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016442; batch adversarial loss: 0.443389\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013603; batch adversarial loss: 0.358628\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034523; batch adversarial loss: 0.344753\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033651; batch adversarial loss: 0.384843\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010692; batch adversarial loss: 0.421533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 190; iter: 0; batch classifier loss: 0.009507; batch adversarial loss: 0.433621\n",
      "epoch 191; iter: 0; batch classifier loss: 0.009354; batch adversarial loss: 0.447946\n",
      "epoch 192; iter: 0; batch classifier loss: 0.045146; batch adversarial loss: 0.453643\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035450; batch adversarial loss: 0.451099\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017794; batch adversarial loss: 0.402501\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011027; batch adversarial loss: 0.554915\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018285; batch adversarial loss: 0.494040\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028122; batch adversarial loss: 0.428769\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012065; batch adversarial loss: 0.363142\n",
      "epoch 199; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.510712\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708024; batch adversarial loss: 0.709683\n",
      "epoch 1; iter: 0; batch classifier loss: 0.509899; batch adversarial loss: 0.661918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433209; batch adversarial loss: 0.630367\n",
      "epoch 3; iter: 0; batch classifier loss: 0.437037; batch adversarial loss: 0.630275\n",
      "epoch 4; iter: 0; batch classifier loss: 0.480082; batch adversarial loss: 0.580309\n",
      "epoch 5; iter: 0; batch classifier loss: 0.436136; batch adversarial loss: 0.592314\n",
      "epoch 6; iter: 0; batch classifier loss: 0.449034; batch adversarial loss: 0.562044\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313946; batch adversarial loss: 0.579066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420763; batch adversarial loss: 0.543126\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392477; batch adversarial loss: 0.559181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.411379; batch adversarial loss: 0.529297\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378566; batch adversarial loss: 0.504756\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366046; batch adversarial loss: 0.516866\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312742; batch adversarial loss: 0.560239\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442488; batch adversarial loss: 0.496740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323244; batch adversarial loss: 0.496584\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356318; batch adversarial loss: 0.489107\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346269; batch adversarial loss: 0.469496\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345477; batch adversarial loss: 0.452594\n",
      "epoch 19; iter: 0; batch classifier loss: 0.368117; batch adversarial loss: 0.480462\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288536; batch adversarial loss: 0.463180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.317413; batch adversarial loss: 0.498722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282771; batch adversarial loss: 0.512669\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323722; batch adversarial loss: 0.505760\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232039; batch adversarial loss: 0.511160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.267008; batch adversarial loss: 0.413709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.429050\n",
      "epoch 27; iter: 0; batch classifier loss: 0.262277; batch adversarial loss: 0.474764\n",
      "epoch 28; iter: 0; batch classifier loss: 0.272237; batch adversarial loss: 0.455392\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244643; batch adversarial loss: 0.449315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.228581; batch adversarial loss: 0.450090\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270139; batch adversarial loss: 0.536936\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248276; batch adversarial loss: 0.424245\n",
      "epoch 33; iter: 0; batch classifier loss: 0.229668; batch adversarial loss: 0.465155\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198415; batch adversarial loss: 0.430010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.214090; batch adversarial loss: 0.491318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248404; batch adversarial loss: 0.418585\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255246; batch adversarial loss: 0.470700\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241005; batch adversarial loss: 0.425846\n",
      "epoch 39; iter: 0; batch classifier loss: 0.263006; batch adversarial loss: 0.492837\n",
      "epoch 40; iter: 0; batch classifier loss: 0.292384; batch adversarial loss: 0.437335\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145100; batch adversarial loss: 0.543940\n",
      "epoch 42; iter: 0; batch classifier loss: 0.259044; batch adversarial loss: 0.391028\n",
      "epoch 43; iter: 0; batch classifier loss: 0.207203; batch adversarial loss: 0.459488\n",
      "epoch 44; iter: 0; batch classifier loss: 0.220802; batch adversarial loss: 0.470765\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125809; batch adversarial loss: 0.411610\n",
      "epoch 46; iter: 0; batch classifier loss: 0.107906; batch adversarial loss: 0.455754\n",
      "epoch 47; iter: 0; batch classifier loss: 0.133245; batch adversarial loss: 0.546972\n",
      "epoch 48; iter: 0; batch classifier loss: 0.086268; batch adversarial loss: 0.468381\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107321; batch adversarial loss: 0.369268\n",
      "epoch 50; iter: 0; batch classifier loss: 0.058531; batch adversarial loss: 0.460451\n",
      "epoch 51; iter: 0; batch classifier loss: 0.066571; batch adversarial loss: 0.466754\n",
      "epoch 52; iter: 0; batch classifier loss: 0.059552; batch adversarial loss: 0.525152\n",
      "epoch 53; iter: 0; batch classifier loss: 0.056628; batch adversarial loss: 0.455284\n",
      "epoch 54; iter: 0; batch classifier loss: 0.069294; batch adversarial loss: 0.395522\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062025; batch adversarial loss: 0.638064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.049534; batch adversarial loss: 0.401011\n",
      "epoch 57; iter: 0; batch classifier loss: 0.068084; batch adversarial loss: 0.419641\n",
      "epoch 58; iter: 0; batch classifier loss: 0.052828; batch adversarial loss: 0.408151\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057746; batch adversarial loss: 0.367660\n",
      "epoch 60; iter: 0; batch classifier loss: 0.079360; batch adversarial loss: 0.393068\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059790; batch adversarial loss: 0.475867\n",
      "epoch 62; iter: 0; batch classifier loss: 0.094428; batch adversarial loss: 0.507927\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088515; batch adversarial loss: 0.506257\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069058; batch adversarial loss: 0.469292\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082307; batch adversarial loss: 0.427409\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082033; batch adversarial loss: 0.529320\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100311; batch adversarial loss: 0.493963\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061258; batch adversarial loss: 0.368863\n",
      "epoch 69; iter: 0; batch classifier loss: 0.049615; batch adversarial loss: 0.329168\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066532; batch adversarial loss: 0.456096\n",
      "epoch 71; iter: 0; batch classifier loss: 0.049283; batch adversarial loss: 0.430957\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084484; batch adversarial loss: 0.422211\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066822; batch adversarial loss: 0.437695\n",
      "epoch 74; iter: 0; batch classifier loss: 0.029142; batch adversarial loss: 0.514671\n",
      "epoch 75; iter: 0; batch classifier loss: 0.117892; batch adversarial loss: 0.411461\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075659; batch adversarial loss: 0.404168\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067807; batch adversarial loss: 0.415484\n",
      "epoch 78; iter: 0; batch classifier loss: 0.049050; batch adversarial loss: 0.370265\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044431; batch adversarial loss: 0.436491\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066331; batch adversarial loss: 0.436815\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079968; batch adversarial loss: 0.514952\n",
      "epoch 82; iter: 0; batch classifier loss: 0.098145; batch adversarial loss: 0.503336\n",
      "epoch 83; iter: 0; batch classifier loss: 0.066933; batch adversarial loss: 0.529001\n",
      "epoch 84; iter: 0; batch classifier loss: 0.062923; batch adversarial loss: 0.356586\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060237; batch adversarial loss: 0.477680\n",
      "epoch 86; iter: 0; batch classifier loss: 0.035993; batch adversarial loss: 0.408932\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078217; batch adversarial loss: 0.332021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88; iter: 0; batch classifier loss: 0.039673; batch adversarial loss: 0.447625\n",
      "epoch 89; iter: 0; batch classifier loss: 0.087305; batch adversarial loss: 0.502989\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047858; batch adversarial loss: 0.427782\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076672; batch adversarial loss: 0.490514\n",
      "epoch 92; iter: 0; batch classifier loss: 0.032982; batch adversarial loss: 0.434329\n",
      "epoch 93; iter: 0; batch classifier loss: 0.054786; batch adversarial loss: 0.396448\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057422; batch adversarial loss: 0.300070\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070956; batch adversarial loss: 0.415510\n",
      "epoch 96; iter: 0; batch classifier loss: 0.075888; batch adversarial loss: 0.358688\n",
      "epoch 97; iter: 0; batch classifier loss: 0.069179; batch adversarial loss: 0.413984\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067767; batch adversarial loss: 0.442197\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041894; batch adversarial loss: 0.371696\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058777; batch adversarial loss: 0.472611\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076871; batch adversarial loss: 0.317622\n",
      "epoch 102; iter: 0; batch classifier loss: 0.089511; batch adversarial loss: 0.453387\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072494; batch adversarial loss: 0.397732\n",
      "epoch 104; iter: 0; batch classifier loss: 0.069922; batch adversarial loss: 0.526925\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047840; batch adversarial loss: 0.418541\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033536; batch adversarial loss: 0.506937\n",
      "epoch 107; iter: 0; batch classifier loss: 0.066669; batch adversarial loss: 0.421354\n",
      "epoch 108; iter: 0; batch classifier loss: 0.044712; batch adversarial loss: 0.406171\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061063; batch adversarial loss: 0.443481\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065604; batch adversarial loss: 0.371689\n",
      "epoch 111; iter: 0; batch classifier loss: 0.060726; batch adversarial loss: 0.369541\n",
      "epoch 112; iter: 0; batch classifier loss: 0.041541; batch adversarial loss: 0.437171\n",
      "epoch 113; iter: 0; batch classifier loss: 0.066728; batch adversarial loss: 0.316969\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054466; batch adversarial loss: 0.413322\n",
      "epoch 115; iter: 0; batch classifier loss: 0.075954; batch adversarial loss: 0.463468\n",
      "epoch 116; iter: 0; batch classifier loss: 0.082758; batch adversarial loss: 0.341434\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048566; batch adversarial loss: 0.402185\n",
      "epoch 118; iter: 0; batch classifier loss: 0.059042; batch adversarial loss: 0.460700\n",
      "epoch 119; iter: 0; batch classifier loss: 0.064424; batch adversarial loss: 0.410888\n",
      "epoch 120; iter: 0; batch classifier loss: 0.077464; batch adversarial loss: 0.510967\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049214; batch adversarial loss: 0.383800\n",
      "epoch 122; iter: 0; batch classifier loss: 0.069507; batch adversarial loss: 0.374071\n",
      "epoch 123; iter: 0; batch classifier loss: 0.059813; batch adversarial loss: 0.551910\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051548; batch adversarial loss: 0.436523\n",
      "epoch 125; iter: 0; batch classifier loss: 0.067301; batch adversarial loss: 0.494323\n",
      "epoch 126; iter: 0; batch classifier loss: 0.064673; batch adversarial loss: 0.360601\n",
      "epoch 127; iter: 0; batch classifier loss: 0.042724; batch adversarial loss: 0.327722\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062166; batch adversarial loss: 0.357929\n",
      "epoch 129; iter: 0; batch classifier loss: 0.077650; batch adversarial loss: 0.446046\n",
      "epoch 130; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.398117\n",
      "epoch 131; iter: 0; batch classifier loss: 0.045318; batch adversarial loss: 0.539853\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040042; batch adversarial loss: 0.480778\n",
      "epoch 133; iter: 0; batch classifier loss: 0.043431; batch adversarial loss: 0.393550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034023; batch adversarial loss: 0.503000\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046010; batch adversarial loss: 0.427233\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026335; batch adversarial loss: 0.393690\n",
      "epoch 137; iter: 0; batch classifier loss: 0.019755; batch adversarial loss: 0.490053\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033646; batch adversarial loss: 0.424270\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023906; batch adversarial loss: 0.395182\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046018; batch adversarial loss: 0.494319\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049789; batch adversarial loss: 0.387571\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018685; batch adversarial loss: 0.396278\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035691; batch adversarial loss: 0.419973\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025871; batch adversarial loss: 0.435414\n",
      "epoch 145; iter: 0; batch classifier loss: 0.027146; batch adversarial loss: 0.372691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028293; batch adversarial loss: 0.375722\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023298; batch adversarial loss: 0.543616\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027830; batch adversarial loss: 0.488851\n",
      "epoch 149; iter: 0; batch classifier loss: 0.014338; batch adversarial loss: 0.340725\n",
      "epoch 150; iter: 0; batch classifier loss: 0.082724; batch adversarial loss: 0.433947\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040377; batch adversarial loss: 0.475442\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040912; batch adversarial loss: 0.394910\n",
      "epoch 153; iter: 0; batch classifier loss: 0.052278; batch adversarial loss: 0.462107\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032275; batch adversarial loss: 0.337636\n",
      "epoch 155; iter: 0; batch classifier loss: 0.035519; batch adversarial loss: 0.578313\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024951; batch adversarial loss: 0.432066\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028582; batch adversarial loss: 0.490313\n",
      "epoch 158; iter: 0; batch classifier loss: 0.033324; batch adversarial loss: 0.469738\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031009; batch adversarial loss: 0.421933\n",
      "epoch 160; iter: 0; batch classifier loss: 0.044174; batch adversarial loss: 0.498840\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042431; batch adversarial loss: 0.455848\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025092; batch adversarial loss: 0.456512\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023929; batch adversarial loss: 0.375700\n",
      "epoch 164; iter: 0; batch classifier loss: 0.021918; batch adversarial loss: 0.427397\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013341; batch adversarial loss: 0.426635\n",
      "epoch 166; iter: 0; batch classifier loss: 0.022988; batch adversarial loss: 0.381134\n",
      "epoch 167; iter: 0; batch classifier loss: 0.005114; batch adversarial loss: 0.465208\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034257; batch adversarial loss: 0.506489\n",
      "epoch 169; iter: 0; batch classifier loss: 0.027034; batch adversarial loss: 0.378991\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028064; batch adversarial loss: 0.541653\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020862; batch adversarial loss: 0.484413\n",
      "epoch 172; iter: 0; batch classifier loss: 0.031006; batch adversarial loss: 0.404565\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046185; batch adversarial loss: 0.466568\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011951; batch adversarial loss: 0.413133\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017218; batch adversarial loss: 0.400718\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019681; batch adversarial loss: 0.429550\n",
      "epoch 177; iter: 0; batch classifier loss: 0.087730; batch adversarial loss: 0.439239\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030738; batch adversarial loss: 0.397952\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021734; batch adversarial loss: 0.381611\n",
      "epoch 180; iter: 0; batch classifier loss: 0.020302; batch adversarial loss: 0.444255\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015926; batch adversarial loss: 0.448326\n",
      "epoch 182; iter: 0; batch classifier loss: 0.038426; batch adversarial loss: 0.468270\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014146; batch adversarial loss: 0.453273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 184; iter: 0; batch classifier loss: 0.022197; batch adversarial loss: 0.469224\n",
      "epoch 185; iter: 0; batch classifier loss: 0.008229; batch adversarial loss: 0.484585\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044895; batch adversarial loss: 0.354933\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014153; batch adversarial loss: 0.511546\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020997; batch adversarial loss: 0.514956\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007238; batch adversarial loss: 0.498631\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026258; batch adversarial loss: 0.463438\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016216; batch adversarial loss: 0.430406\n",
      "epoch 192; iter: 0; batch classifier loss: 0.011814; batch adversarial loss: 0.414140\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016751; batch adversarial loss: 0.454897\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029533; batch adversarial loss: 0.411836\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012668; batch adversarial loss: 0.397205\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007476; batch adversarial loss: 0.440797\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012415; batch adversarial loss: 0.439101\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037298; batch adversarial loss: 0.453196\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042352; batch adversarial loss: 0.420545\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696223; batch adversarial loss: 0.806157\n",
      "epoch 1; iter: 0; batch classifier loss: 0.440958; batch adversarial loss: 0.844238\n",
      "epoch 2; iter: 0; batch classifier loss: 0.407439; batch adversarial loss: 0.767463\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331794; batch adversarial loss: 0.700169\n",
      "epoch 4; iter: 0; batch classifier loss: 0.315879; batch adversarial loss: 0.667674\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363762; batch adversarial loss: 0.647178\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321469; batch adversarial loss: 0.602707\n",
      "epoch 7; iter: 0; batch classifier loss: 0.299747; batch adversarial loss: 0.618678\n",
      "epoch 8; iter: 0; batch classifier loss: 0.265599; batch adversarial loss: 0.574959\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320963; batch adversarial loss: 0.558527\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354665; batch adversarial loss: 0.519944\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261847; batch adversarial loss: 0.497249\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269959; batch adversarial loss: 0.496190\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238519; batch adversarial loss: 0.493427\n",
      "epoch 14; iter: 0; batch classifier loss: 0.234357; batch adversarial loss: 0.447551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.236008; batch adversarial loss: 0.510702\n",
      "epoch 16; iter: 0; batch classifier loss: 0.200819; batch adversarial loss: 0.433057\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287831; batch adversarial loss: 0.458110\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240602; batch adversarial loss: 0.456809\n",
      "epoch 19; iter: 0; batch classifier loss: 0.207988; batch adversarial loss: 0.436334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162428; batch adversarial loss: 0.387494\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248645; batch adversarial loss: 0.401038\n",
      "epoch 22; iter: 0; batch classifier loss: 0.267357; batch adversarial loss: 0.446903\n",
      "epoch 23; iter: 0; batch classifier loss: 0.140447; batch adversarial loss: 0.371864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.169330; batch adversarial loss: 0.417473\n",
      "epoch 25; iter: 0; batch classifier loss: 0.236786; batch adversarial loss: 0.396983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146527; batch adversarial loss: 0.391377\n",
      "epoch 27; iter: 0; batch classifier loss: 0.196939; batch adversarial loss: 0.452303\n",
      "epoch 28; iter: 0; batch classifier loss: 0.186710; batch adversarial loss: 0.428808\n",
      "epoch 29; iter: 0; batch classifier loss: 0.200913; batch adversarial loss: 0.345016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.140298; batch adversarial loss: 0.391491\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177646; batch adversarial loss: 0.410919\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159868; batch adversarial loss: 0.440298\n",
      "epoch 33; iter: 0; batch classifier loss: 0.167195; batch adversarial loss: 0.399536\n",
      "epoch 34; iter: 0; batch classifier loss: 0.166228; batch adversarial loss: 0.450314\n",
      "epoch 35; iter: 0; batch classifier loss: 0.123726; batch adversarial loss: 0.476353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.151638; batch adversarial loss: 0.346961\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136136; batch adversarial loss: 0.387523\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129603; batch adversarial loss: 0.357834\n",
      "epoch 39; iter: 0; batch classifier loss: 0.125669; batch adversarial loss: 0.386896\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154362; batch adversarial loss: 0.471617\n",
      "epoch 41; iter: 0; batch classifier loss: 0.206116; batch adversarial loss: 0.468752\n",
      "epoch 42; iter: 0; batch classifier loss: 0.117012; batch adversarial loss: 0.401214\n",
      "epoch 43; iter: 0; batch classifier loss: 0.091802; batch adversarial loss: 0.514715\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108837; batch adversarial loss: 0.381867\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102731; batch adversarial loss: 0.310229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.129621; batch adversarial loss: 0.363636\n",
      "epoch 47; iter: 0; batch classifier loss: 0.159231; batch adversarial loss: 0.562060\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111696; batch adversarial loss: 0.441656\n",
      "epoch 49; iter: 0; batch classifier loss: 0.115638; batch adversarial loss: 0.378685\n",
      "epoch 50; iter: 0; batch classifier loss: 0.099885; batch adversarial loss: 0.420558\n",
      "epoch 51; iter: 0; batch classifier loss: 0.134116; batch adversarial loss: 0.443421\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105793; batch adversarial loss: 0.363422\n",
      "epoch 53; iter: 0; batch classifier loss: 0.120650; batch adversarial loss: 0.461388\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089514; batch adversarial loss: 0.390741\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093299; batch adversarial loss: 0.471551\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159785; batch adversarial loss: 0.493257\n",
      "epoch 57; iter: 0; batch classifier loss: 0.087987; batch adversarial loss: 0.425233\n",
      "epoch 58; iter: 0; batch classifier loss: 0.110552; batch adversarial loss: 0.396488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070008; batch adversarial loss: 0.365255\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095916; batch adversarial loss: 0.468952\n",
      "epoch 61; iter: 0; batch classifier loss: 0.124190; batch adversarial loss: 0.432341\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073686; batch adversarial loss: 0.383807\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076652; batch adversarial loss: 0.440483\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063616; batch adversarial loss: 0.412169\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079173; batch adversarial loss: 0.423486\n",
      "epoch 66; iter: 0; batch classifier loss: 0.078587; batch adversarial loss: 0.531221\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063654; batch adversarial loss: 0.415503\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111568; batch adversarial loss: 0.465445\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086213; batch adversarial loss: 0.384132\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053636; batch adversarial loss: 0.408556\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067534; batch adversarial loss: 0.424384\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056999; batch adversarial loss: 0.442527\n",
      "epoch 73; iter: 0; batch classifier loss: 0.129132; batch adversarial loss: 0.407848\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059540; batch adversarial loss: 0.412927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076807; batch adversarial loss: 0.474827\n",
      "epoch 76; iter: 0; batch classifier loss: 0.082867; batch adversarial loss: 0.411615\n",
      "epoch 77; iter: 0; batch classifier loss: 0.061845; batch adversarial loss: 0.435603\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071283; batch adversarial loss: 0.457505\n",
      "epoch 79; iter: 0; batch classifier loss: 0.075858; batch adversarial loss: 0.439647\n",
      "epoch 80; iter: 0; batch classifier loss: 0.079716; batch adversarial loss: 0.413306\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114212; batch adversarial loss: 0.525073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.081934; batch adversarial loss: 0.472465\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061127; batch adversarial loss: 0.352786\n",
      "epoch 84; iter: 0; batch classifier loss: 0.126945; batch adversarial loss: 0.411277\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059490; batch adversarial loss: 0.423515\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104726; batch adversarial loss: 0.425590\n",
      "epoch 87; iter: 0; batch classifier loss: 0.121698; batch adversarial loss: 0.417865\n",
      "epoch 88; iter: 0; batch classifier loss: 0.084843; batch adversarial loss: 0.336357\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075890; batch adversarial loss: 0.455870\n",
      "epoch 90; iter: 0; batch classifier loss: 0.080536; batch adversarial loss: 0.421786\n",
      "epoch 91; iter: 0; batch classifier loss: 0.095563; batch adversarial loss: 0.439256\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054995; batch adversarial loss: 0.457416\n",
      "epoch 93; iter: 0; batch classifier loss: 0.096277; batch adversarial loss: 0.466915\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076240; batch adversarial loss: 0.494075\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069101; batch adversarial loss: 0.442801\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056845; batch adversarial loss: 0.429733\n",
      "epoch 97; iter: 0; batch classifier loss: 0.035807; batch adversarial loss: 0.369342\n",
      "epoch 98; iter: 0; batch classifier loss: 0.084096; batch adversarial loss: 0.421913\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039371; batch adversarial loss: 0.410301\n",
      "epoch 100; iter: 0; batch classifier loss: 0.101077; batch adversarial loss: 0.445294\n",
      "epoch 101; iter: 0; batch classifier loss: 0.081383; batch adversarial loss: 0.453510\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047201; batch adversarial loss: 0.510980\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061341; batch adversarial loss: 0.427682\n",
      "epoch 104; iter: 0; batch classifier loss: 0.064669; batch adversarial loss: 0.352444\n",
      "epoch 105; iter: 0; batch classifier loss: 0.084795; batch adversarial loss: 0.370293\n",
      "epoch 106; iter: 0; batch classifier loss: 0.057516; batch adversarial loss: 0.437107\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052535; batch adversarial loss: 0.342327\n",
      "epoch 108; iter: 0; batch classifier loss: 0.101229; batch adversarial loss: 0.412630\n",
      "epoch 109; iter: 0; batch classifier loss: 0.060595; batch adversarial loss: 0.401498\n",
      "epoch 110; iter: 0; batch classifier loss: 0.065415; batch adversarial loss: 0.394010\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069741; batch adversarial loss: 0.359418\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069997; batch adversarial loss: 0.413346\n",
      "epoch 113; iter: 0; batch classifier loss: 0.085322; batch adversarial loss: 0.420386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.085629; batch adversarial loss: 0.475100\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039674; batch adversarial loss: 0.427301\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059951; batch adversarial loss: 0.438677\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028696; batch adversarial loss: 0.383547\n",
      "epoch 118; iter: 0; batch classifier loss: 0.073185; batch adversarial loss: 0.403965\n",
      "epoch 119; iter: 0; batch classifier loss: 0.051224; batch adversarial loss: 0.452549\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048797; batch adversarial loss: 0.436939\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056026; batch adversarial loss: 0.370244\n",
      "epoch 122; iter: 0; batch classifier loss: 0.090120; batch adversarial loss: 0.426693\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052200; batch adversarial loss: 0.490945\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052616; batch adversarial loss: 0.411787\n",
      "epoch 125; iter: 0; batch classifier loss: 0.057929; batch adversarial loss: 0.489598\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055206; batch adversarial loss: 0.402606\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039113; batch adversarial loss: 0.391899\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053827; batch adversarial loss: 0.401628\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048006; batch adversarial loss: 0.343184\n",
      "epoch 130; iter: 0; batch classifier loss: 0.024948; batch adversarial loss: 0.355881\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033132; batch adversarial loss: 0.470668\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068062; batch adversarial loss: 0.423476\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034096; batch adversarial loss: 0.410261\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047350; batch adversarial loss: 0.404226\n",
      "epoch 135; iter: 0; batch classifier loss: 0.026149; batch adversarial loss: 0.360287\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032927; batch adversarial loss: 0.460670\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042057; batch adversarial loss: 0.486675\n",
      "epoch 138; iter: 0; batch classifier loss: 0.014179; batch adversarial loss: 0.395124\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025992; batch adversarial loss: 0.544752\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023029; batch adversarial loss: 0.417405\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038414; batch adversarial loss: 0.465194\n",
      "epoch 142; iter: 0; batch classifier loss: 0.043914; batch adversarial loss: 0.380497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.054269; batch adversarial loss: 0.481491\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025383; batch adversarial loss: 0.413943\n",
      "epoch 145; iter: 0; batch classifier loss: 0.047178; batch adversarial loss: 0.375286\n",
      "epoch 146; iter: 0; batch classifier loss: 0.029379; batch adversarial loss: 0.495205\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031119; batch adversarial loss: 0.478335\n",
      "epoch 148; iter: 0; batch classifier loss: 0.066262; batch adversarial loss: 0.370203\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023988; batch adversarial loss: 0.487666\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016299; batch adversarial loss: 0.514903\n",
      "epoch 151; iter: 0; batch classifier loss: 0.040784; batch adversarial loss: 0.450370\n",
      "epoch 152; iter: 0; batch classifier loss: 0.033744; batch adversarial loss: 0.429565\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018781; batch adversarial loss: 0.390812\n",
      "epoch 154; iter: 0; batch classifier loss: 0.031594; batch adversarial loss: 0.487523\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016462; batch adversarial loss: 0.479256\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016248; batch adversarial loss: 0.389288\n",
      "epoch 157; iter: 0; batch classifier loss: 0.010753; batch adversarial loss: 0.488075\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017543; batch adversarial loss: 0.538745\n",
      "epoch 159; iter: 0; batch classifier loss: 0.079859; batch adversarial loss: 0.492034\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016432; batch adversarial loss: 0.472075\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016442; batch adversarial loss: 0.389132\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019415; batch adversarial loss: 0.537811\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029366; batch adversarial loss: 0.492444\n",
      "epoch 164; iter: 0; batch classifier loss: 0.046161; batch adversarial loss: 0.459558\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037517; batch adversarial loss: 0.434871\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030536; batch adversarial loss: 0.546605\n",
      "epoch 167; iter: 0; batch classifier loss: 0.062256; batch adversarial loss: 0.630842\n",
      "epoch 168; iter: 0; batch classifier loss: 0.034460; batch adversarial loss: 0.508986\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046558; batch adversarial loss: 0.457918\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037316; batch adversarial loss: 0.485671\n",
      "epoch 171; iter: 0; batch classifier loss: 0.018228; batch adversarial loss: 0.518661\n",
      "epoch 172; iter: 0; batch classifier loss: 0.004830; batch adversarial loss: 0.479115\n",
      "epoch 173; iter: 0; batch classifier loss: 0.056009; batch adversarial loss: 0.570436\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.389778\n",
      "epoch 175; iter: 0; batch classifier loss: 0.047768; batch adversarial loss: 0.477457\n",
      "epoch 176; iter: 0; batch classifier loss: 0.086181; batch adversarial loss: 0.678791\n",
      "epoch 177; iter: 0; batch classifier loss: 0.093389; batch adversarial loss: 0.588047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.127193; batch adversarial loss: 0.696519\n",
      "epoch 179; iter: 0; batch classifier loss: 0.092432; batch adversarial loss: 0.670911\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038394; batch adversarial loss: 0.520224\n",
      "epoch 181; iter: 0; batch classifier loss: 0.064211; batch adversarial loss: 0.580329\n",
      "epoch 182; iter: 0; batch classifier loss: 0.098807; batch adversarial loss: 0.590007\n",
      "epoch 183; iter: 0; batch classifier loss: 0.099804; batch adversarial loss: 0.719146\n",
      "epoch 184; iter: 0; batch classifier loss: 0.090515; batch adversarial loss: 0.544340\n",
      "epoch 185; iter: 0; batch classifier loss: 0.127439; batch adversarial loss: 0.702635\n",
      "epoch 186; iter: 0; batch classifier loss: 0.129053; batch adversarial loss: 0.743632\n",
      "epoch 187; iter: 0; batch classifier loss: 0.097849; batch adversarial loss: 0.655172\n",
      "epoch 188; iter: 0; batch classifier loss: 0.198181; batch adversarial loss: 0.677567\n",
      "epoch 189; iter: 0; batch classifier loss: 0.147229; batch adversarial loss: 0.753428\n",
      "epoch 190; iter: 0; batch classifier loss: 0.120105; batch adversarial loss: 0.571079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.135294; batch adversarial loss: 0.623829\n",
      "epoch 192; iter: 0; batch classifier loss: 0.164610; batch adversarial loss: 0.694316\n",
      "epoch 193; iter: 0; batch classifier loss: 0.153485; batch adversarial loss: 0.683954\n",
      "epoch 194; iter: 0; batch classifier loss: 0.123598; batch adversarial loss: 0.661157\n",
      "epoch 195; iter: 0; batch classifier loss: 0.171215; batch adversarial loss: 0.711573\n",
      "epoch 196; iter: 0; batch classifier loss: 0.215153; batch adversarial loss: 0.742403\n",
      "epoch 197; iter: 0; batch classifier loss: 0.171877; batch adversarial loss: 0.625509\n",
      "epoch 198; iter: 0; batch classifier loss: 0.137831; batch adversarial loss: 0.628617\n",
      "epoch 199; iter: 0; batch classifier loss: 0.153680; batch adversarial loss: 0.611082\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676232; batch adversarial loss: 0.726098\n",
      "epoch 1; iter: 0; batch classifier loss: 0.484399; batch adversarial loss: 0.707362\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392394; batch adversarial loss: 0.674923\n",
      "epoch 3; iter: 0; batch classifier loss: 0.340565; batch adversarial loss: 0.618049\n",
      "epoch 4; iter: 0; batch classifier loss: 0.384758; batch adversarial loss: 0.580690\n",
      "epoch 5; iter: 0; batch classifier loss: 0.367825; batch adversarial loss: 0.566303\n",
      "epoch 6; iter: 0; batch classifier loss: 0.283792; batch adversarial loss: 0.521202\n",
      "epoch 7; iter: 0; batch classifier loss: 0.239078; batch adversarial loss: 0.510149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299160; batch adversarial loss: 0.496333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284344; batch adversarial loss: 0.503975\n",
      "epoch 10; iter: 0; batch classifier loss: 0.199688; batch adversarial loss: 0.472154\n",
      "epoch 11; iter: 0; batch classifier loss: 0.213113; batch adversarial loss: 0.437474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.175041; batch adversarial loss: 0.400161\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255776; batch adversarial loss: 0.461996\n",
      "epoch 14; iter: 0; batch classifier loss: 0.206526; batch adversarial loss: 0.445574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.145254; batch adversarial loss: 0.492593\n",
      "epoch 16; iter: 0; batch classifier loss: 0.193396; batch adversarial loss: 0.422364\n",
      "epoch 17; iter: 0; batch classifier loss: 0.153895; batch adversarial loss: 0.473841\n",
      "epoch 18; iter: 0; batch classifier loss: 0.122742; batch adversarial loss: 0.470901\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185058; batch adversarial loss: 0.487403\n",
      "epoch 20; iter: 0; batch classifier loss: 0.155176; batch adversarial loss: 0.504684\n",
      "epoch 21; iter: 0; batch classifier loss: 0.134831; batch adversarial loss: 0.453240\n",
      "epoch 22; iter: 0; batch classifier loss: 0.166525; batch adversarial loss: 0.562016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.166675; batch adversarial loss: 0.512355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147948; batch adversarial loss: 0.448152\n",
      "epoch 25; iter: 0; batch classifier loss: 0.141206; batch adversarial loss: 0.452929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.147681; batch adversarial loss: 0.436280\n",
      "epoch 27; iter: 0; batch classifier loss: 0.131224; batch adversarial loss: 0.481000\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210935; batch adversarial loss: 0.493140\n",
      "epoch 29; iter: 0; batch classifier loss: 0.133691; batch adversarial loss: 0.548358\n",
      "epoch 30; iter: 0; batch classifier loss: 0.162120; batch adversarial loss: 0.468744\n",
      "epoch 31; iter: 0; batch classifier loss: 0.146605; batch adversarial loss: 0.505495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.148899; batch adversarial loss: 0.447529\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152898; batch adversarial loss: 0.574375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.097868; batch adversarial loss: 0.490284\n",
      "epoch 35; iter: 0; batch classifier loss: 0.105502; batch adversarial loss: 0.457992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.158118; batch adversarial loss: 0.572961\n",
      "epoch 37; iter: 0; batch classifier loss: 0.163485; batch adversarial loss: 0.432201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090912; batch adversarial loss: 0.376932\n",
      "epoch 39; iter: 0; batch classifier loss: 0.108414; batch adversarial loss: 0.436188\n",
      "epoch 40; iter: 0; batch classifier loss: 0.140914; batch adversarial loss: 0.453457\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217831; batch adversarial loss: 0.429726\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147998; batch adversarial loss: 0.416935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.226661; batch adversarial loss: 0.521903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.172593; batch adversarial loss: 0.443281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.080209; batch adversarial loss: 0.361929\n",
      "epoch 46; iter: 0; batch classifier loss: 0.101659; batch adversarial loss: 0.463533\n",
      "epoch 47; iter: 0; batch classifier loss: 0.055848; batch adversarial loss: 0.395305\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077624; batch adversarial loss: 0.554324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.046353; batch adversarial loss: 0.384047\n",
      "epoch 50; iter: 0; batch classifier loss: 0.048790; batch adversarial loss: 0.404158\n",
      "epoch 51; iter: 0; batch classifier loss: 0.078674; batch adversarial loss: 0.384560\n",
      "epoch 52; iter: 0; batch classifier loss: 0.046902; batch adversarial loss: 0.491647\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076936; batch adversarial loss: 0.401611\n",
      "epoch 54; iter: 0; batch classifier loss: 0.075979; batch adversarial loss: 0.478247\n",
      "epoch 55; iter: 0; batch classifier loss: 0.049618; batch adversarial loss: 0.416365\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074628; batch adversarial loss: 0.461121\n",
      "epoch 57; iter: 0; batch classifier loss: 0.084237; batch adversarial loss: 0.425969\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091296; batch adversarial loss: 0.339703\n",
      "epoch 59; iter: 0; batch classifier loss: 0.066648; batch adversarial loss: 0.500118\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070161; batch adversarial loss: 0.475720\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089508; batch adversarial loss: 0.421083\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072406; batch adversarial loss: 0.494891\n",
      "epoch 63; iter: 0; batch classifier loss: 0.091666; batch adversarial loss: 0.385065\n",
      "epoch 64; iter: 0; batch classifier loss: 0.073534; batch adversarial loss: 0.423610\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058382; batch adversarial loss: 0.370625\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106883; batch adversarial loss: 0.433882\n",
      "epoch 67; iter: 0; batch classifier loss: 0.098424; batch adversarial loss: 0.372470\n",
      "epoch 68; iter: 0; batch classifier loss: 0.077965; batch adversarial loss: 0.434197\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072491; batch adversarial loss: 0.439203\n",
      "epoch 70; iter: 0; batch classifier loss: 0.040186; batch adversarial loss: 0.444458\n",
      "epoch 71; iter: 0; batch classifier loss: 0.042773; batch adversarial loss: 0.352899\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062025; batch adversarial loss: 0.446785\n",
      "epoch 73; iter: 0; batch classifier loss: 0.083406; batch adversarial loss: 0.390490\n",
      "epoch 74; iter: 0; batch classifier loss: 0.146573; batch adversarial loss: 0.503593\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060877; batch adversarial loss: 0.379266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.044849; batch adversarial loss: 0.468006\n",
      "epoch 77; iter: 0; batch classifier loss: 0.104175; batch adversarial loss: 0.465660\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080882; batch adversarial loss: 0.390812\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099586; batch adversarial loss: 0.357446\n",
      "epoch 80; iter: 0; batch classifier loss: 0.101562; batch adversarial loss: 0.341926\n",
      "epoch 81; iter: 0; batch classifier loss: 0.106333; batch adversarial loss: 0.391204\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047281; batch adversarial loss: 0.331842\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086211; batch adversarial loss: 0.577175\n",
      "epoch 84; iter: 0; batch classifier loss: 0.107275; batch adversarial loss: 0.461418\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068301; batch adversarial loss: 0.428691\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048121; batch adversarial loss: 0.491519\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050155; batch adversarial loss: 0.435356\n",
      "epoch 88; iter: 0; batch classifier loss: 0.038874; batch adversarial loss: 0.446346\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059919; batch adversarial loss: 0.421546\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059851; batch adversarial loss: 0.459017\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085158; batch adversarial loss: 0.447310\n",
      "epoch 92; iter: 0; batch classifier loss: 0.045424; batch adversarial loss: 0.490751\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047718; batch adversarial loss: 0.471922\n",
      "epoch 94; iter: 0; batch classifier loss: 0.093241; batch adversarial loss: 0.376841\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079265; batch adversarial loss: 0.493609\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064634; batch adversarial loss: 0.418936\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059445; batch adversarial loss: 0.395010\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087084; batch adversarial loss: 0.418261\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046359; batch adversarial loss: 0.376123\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063186; batch adversarial loss: 0.384366\n",
      "epoch 101; iter: 0; batch classifier loss: 0.075819; batch adversarial loss: 0.449851\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071939; batch adversarial loss: 0.453038\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033520; batch adversarial loss: 0.579157\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071743; batch adversarial loss: 0.463813\n",
      "epoch 105; iter: 0; batch classifier loss: 0.085587; batch adversarial loss: 0.418080\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040896; batch adversarial loss: 0.497945\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.433214\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077492; batch adversarial loss: 0.419492\n",
      "epoch 109; iter: 0; batch classifier loss: 0.083455; batch adversarial loss: 0.410906\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030547; batch adversarial loss: 0.496795\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048993; batch adversarial loss: 0.419935\n",
      "epoch 112; iter: 0; batch classifier loss: 0.063426; batch adversarial loss: 0.350130\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046564; batch adversarial loss: 0.483368\n",
      "epoch 114; iter: 0; batch classifier loss: 0.100485; batch adversarial loss: 0.464996\n",
      "epoch 115; iter: 0; batch classifier loss: 0.050159; batch adversarial loss: 0.508237\n",
      "epoch 116; iter: 0; batch classifier loss: 0.075217; batch adversarial loss: 0.334713\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026634; batch adversarial loss: 0.417142\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052707; batch adversarial loss: 0.363041\n",
      "epoch 119; iter: 0; batch classifier loss: 0.049558; batch adversarial loss: 0.419087\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034232; batch adversarial loss: 0.481441\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053283; batch adversarial loss: 0.441652\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033820; batch adversarial loss: 0.435338\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032942; batch adversarial loss: 0.389919\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053611; batch adversarial loss: 0.435582\n",
      "epoch 125; iter: 0; batch classifier loss: 0.030907; batch adversarial loss: 0.446663\n",
      "epoch 126; iter: 0; batch classifier loss: 0.026763; batch adversarial loss: 0.300670\n",
      "epoch 127; iter: 0; batch classifier loss: 0.023249; batch adversarial loss: 0.449760\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042400; batch adversarial loss: 0.353986\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035670; batch adversarial loss: 0.524030\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056089; batch adversarial loss: 0.374800\n",
      "epoch 131; iter: 0; batch classifier loss: 0.058673; batch adversarial loss: 0.332938\n",
      "epoch 132; iter: 0; batch classifier loss: 0.020489; batch adversarial loss: 0.494746\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045854; batch adversarial loss: 0.412537\n",
      "epoch 134; iter: 0; batch classifier loss: 0.030363; batch adversarial loss: 0.387982\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043232; batch adversarial loss: 0.417716\n",
      "epoch 136; iter: 0; batch classifier loss: 0.034105; batch adversarial loss: 0.455188\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034927; batch adversarial loss: 0.496934\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018357; batch adversarial loss: 0.459852\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031237; batch adversarial loss: 0.438473\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015585; batch adversarial loss: 0.511933\n",
      "epoch 141; iter: 0; batch classifier loss: 0.029564; batch adversarial loss: 0.484187\n",
      "epoch 142; iter: 0; batch classifier loss: 0.041141; batch adversarial loss: 0.349711\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037187; batch adversarial loss: 0.372009\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025103; batch adversarial loss: 0.410016\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036446; batch adversarial loss: 0.367844\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030512; batch adversarial loss: 0.472189\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029506; batch adversarial loss: 0.526994\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033863; batch adversarial loss: 0.461772\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040533; batch adversarial loss: 0.315065\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011092; batch adversarial loss: 0.514748\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026009; batch adversarial loss: 0.387734\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047459; batch adversarial loss: 0.381406\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027436; batch adversarial loss: 0.452181\n",
      "epoch 154; iter: 0; batch classifier loss: 0.044094; batch adversarial loss: 0.415283\n",
      "epoch 155; iter: 0; batch classifier loss: 0.024688; batch adversarial loss: 0.466344\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024217; batch adversarial loss: 0.410186\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023311; batch adversarial loss: 0.583316\n",
      "epoch 158; iter: 0; batch classifier loss: 0.015663; batch adversarial loss: 0.379413\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018150; batch adversarial loss: 0.405192\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030622; batch adversarial loss: 0.428703\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030942; batch adversarial loss: 0.483926\n",
      "epoch 162; iter: 0; batch classifier loss: 0.062640; batch adversarial loss: 0.483843\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027759; batch adversarial loss: 0.359305\n",
      "epoch 164; iter: 0; batch classifier loss: 0.091137; batch adversarial loss: 0.428789\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046060; batch adversarial loss: 0.464711\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014885; batch adversarial loss: 0.352816\n",
      "epoch 167; iter: 0; batch classifier loss: 0.046559; batch adversarial loss: 0.338974\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007968; batch adversarial loss: 0.470240\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017477; batch adversarial loss: 0.413565\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016356; batch adversarial loss: 0.414111\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015789; batch adversarial loss: 0.439863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.032024; batch adversarial loss: 0.469920\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024714; batch adversarial loss: 0.391501\n",
      "epoch 174; iter: 0; batch classifier loss: 0.011569; batch adversarial loss: 0.425457\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030898; batch adversarial loss: 0.442986\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009681; batch adversarial loss: 0.435321\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024158; batch adversarial loss: 0.478058\n",
      "epoch 178; iter: 0; batch classifier loss: 0.030944; batch adversarial loss: 0.361201\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008984; batch adversarial loss: 0.454677\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019485; batch adversarial loss: 0.530018\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044336; batch adversarial loss: 0.525423\n",
      "epoch 182; iter: 0; batch classifier loss: 0.019881; batch adversarial loss: 0.457660\n",
      "epoch 183; iter: 0; batch classifier loss: 0.038344; batch adversarial loss: 0.376289\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012055; batch adversarial loss: 0.511187\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024361; batch adversarial loss: 0.501048\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008156; batch adversarial loss: 0.430801\n",
      "epoch 187; iter: 0; batch classifier loss: 0.059558; batch adversarial loss: 0.416115\n",
      "epoch 188; iter: 0; batch classifier loss: 0.008769; batch adversarial loss: 0.441858\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015008; batch adversarial loss: 0.356584\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006303; batch adversarial loss: 0.342396\n",
      "epoch 191; iter: 0; batch classifier loss: 0.010090; batch adversarial loss: 0.397164\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009539; batch adversarial loss: 0.406484\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009156; batch adversarial loss: 0.435796\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032951; batch adversarial loss: 0.414909\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015218; batch adversarial loss: 0.517787\n",
      "epoch 196; iter: 0; batch classifier loss: 0.008684; batch adversarial loss: 0.440748\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024851; batch adversarial loss: 0.489924\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010708; batch adversarial loss: 0.415985\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026713; batch adversarial loss: 0.530225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.724997; batch adversarial loss: 0.639323\n",
      "epoch 1; iter: 0; batch classifier loss: 0.374726; batch adversarial loss: 0.636016\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402768; batch adversarial loss: 0.622824\n",
      "epoch 3; iter: 0; batch classifier loss: 0.260636; batch adversarial loss: 0.583503\n",
      "epoch 4; iter: 0; batch classifier loss: 0.259705; batch adversarial loss: 0.545161\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291602; batch adversarial loss: 0.580999\n",
      "epoch 6; iter: 0; batch classifier loss: 0.293284; batch adversarial loss: 0.576862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394718; batch adversarial loss: 0.578549\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286279; batch adversarial loss: 0.543566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.274648; batch adversarial loss: 0.531317\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282245; batch adversarial loss: 0.531155\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368318; batch adversarial loss: 0.568206\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331178; batch adversarial loss: 0.555019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295717; batch adversarial loss: 0.528620\n",
      "epoch 14; iter: 0; batch classifier loss: 0.424704; batch adversarial loss: 0.455960\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540537; batch adversarial loss: 0.526671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505510; batch adversarial loss: 0.566586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316173; batch adversarial loss: 0.513346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211052; batch adversarial loss: 0.479720\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174784; batch adversarial loss: 0.499688\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204193; batch adversarial loss: 0.459121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.157684; batch adversarial loss: 0.483400\n",
      "epoch 22; iter: 0; batch classifier loss: 0.171228; batch adversarial loss: 0.501161\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193517; batch adversarial loss: 0.471184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.113503; batch adversarial loss: 0.455969\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205417; batch adversarial loss: 0.403301\n",
      "epoch 26; iter: 0; batch classifier loss: 0.143302; batch adversarial loss: 0.530923\n",
      "epoch 27; iter: 0; batch classifier loss: 0.146558; batch adversarial loss: 0.507451\n",
      "epoch 28; iter: 0; batch classifier loss: 0.134698; batch adversarial loss: 0.498469\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143081; batch adversarial loss: 0.455539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.164104; batch adversarial loss: 0.419390\n",
      "epoch 31; iter: 0; batch classifier loss: 0.232277; batch adversarial loss: 0.473389\n",
      "epoch 32; iter: 0; batch classifier loss: 0.097253; batch adversarial loss: 0.446006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098678; batch adversarial loss: 0.486512\n",
      "epoch 34; iter: 0; batch classifier loss: 0.131610; batch adversarial loss: 0.513984\n",
      "epoch 35; iter: 0; batch classifier loss: 0.109589; batch adversarial loss: 0.587783\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125702; batch adversarial loss: 0.443849\n",
      "epoch 37; iter: 0; batch classifier loss: 0.056754; batch adversarial loss: 0.481971\n",
      "epoch 38; iter: 0; batch classifier loss: 0.197026; batch adversarial loss: 0.385313\n",
      "epoch 39; iter: 0; batch classifier loss: 0.071785; batch adversarial loss: 0.454118\n",
      "epoch 40; iter: 0; batch classifier loss: 0.083167; batch adversarial loss: 0.438357\n",
      "epoch 41; iter: 0; batch classifier loss: 0.137253; batch adversarial loss: 0.489398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.139228; batch adversarial loss: 0.437821\n",
      "epoch 43; iter: 0; batch classifier loss: 0.090935; batch adversarial loss: 0.494978\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130233; batch adversarial loss: 0.439483\n",
      "epoch 45; iter: 0; batch classifier loss: 0.109103; batch adversarial loss: 0.450489\n",
      "epoch 46; iter: 0; batch classifier loss: 0.098852; batch adversarial loss: 0.434045\n",
      "epoch 47; iter: 0; batch classifier loss: 0.047472; batch adversarial loss: 0.519254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.072107; batch adversarial loss: 0.462442\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072334; batch adversarial loss: 0.452152\n",
      "epoch 50; iter: 0; batch classifier loss: 0.052148; batch adversarial loss: 0.584982\n",
      "epoch 51; iter: 0; batch classifier loss: 0.098925; batch adversarial loss: 0.396350\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077527; batch adversarial loss: 0.471409\n",
      "epoch 53; iter: 0; batch classifier loss: 0.080889; batch adversarial loss: 0.517529\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117644; batch adversarial loss: 0.466615\n",
      "epoch 55; iter: 0; batch classifier loss: 0.093505; batch adversarial loss: 0.508015\n",
      "epoch 56; iter: 0; batch classifier loss: 0.119371; batch adversarial loss: 0.405830\n",
      "epoch 57; iter: 0; batch classifier loss: 0.110555; batch adversarial loss: 0.463394\n",
      "epoch 58; iter: 0; batch classifier loss: 0.065477; batch adversarial loss: 0.480597\n",
      "epoch 59; iter: 0; batch classifier loss: 0.127159; batch adversarial loss: 0.462119\n",
      "epoch 60; iter: 0; batch classifier loss: 0.113625; batch adversarial loss: 0.491823\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084652; batch adversarial loss: 0.500317\n",
      "epoch 62; iter: 0; batch classifier loss: 0.076915; batch adversarial loss: 0.447871\n",
      "epoch 63; iter: 0; batch classifier loss: 0.092834; batch adversarial loss: 0.465772\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063170; batch adversarial loss: 0.514358\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079734; batch adversarial loss: 0.371989\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105473; batch adversarial loss: 0.380555\n",
      "epoch 67; iter: 0; batch classifier loss: 0.127218; batch adversarial loss: 0.461823\n",
      "epoch 68; iter: 0; batch classifier loss: 0.158753; batch adversarial loss: 0.402129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.085718; batch adversarial loss: 0.404559\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069650; batch adversarial loss: 0.421424\n",
      "epoch 71; iter: 0; batch classifier loss: 0.112643; batch adversarial loss: 0.449518\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097050; batch adversarial loss: 0.412602\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111131; batch adversarial loss: 0.432400\n",
      "epoch 74; iter: 0; batch classifier loss: 0.125787; batch adversarial loss: 0.452645\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134771; batch adversarial loss: 0.469964\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074612; batch adversarial loss: 0.519449\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170722; batch adversarial loss: 0.409902\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075805; batch adversarial loss: 0.551553\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107851; batch adversarial loss: 0.462213\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087938; batch adversarial loss: 0.423422\n",
      "epoch 81; iter: 0; batch classifier loss: 0.119970; batch adversarial loss: 0.508850\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054436; batch adversarial loss: 0.382380\n",
      "epoch 83; iter: 0; batch classifier loss: 0.079298; batch adversarial loss: 0.431602\n",
      "epoch 84; iter: 0; batch classifier loss: 0.108338; batch adversarial loss: 0.489485\n",
      "epoch 85; iter: 0; batch classifier loss: 0.093423; batch adversarial loss: 0.475106\n",
      "epoch 86; iter: 0; batch classifier loss: 0.088975; batch adversarial loss: 0.391124\n",
      "epoch 87; iter: 0; batch classifier loss: 0.063522; batch adversarial loss: 0.455948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093214; batch adversarial loss: 0.502488\n",
      "epoch 89; iter: 0; batch classifier loss: 0.107664; batch adversarial loss: 0.464553\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037710; batch adversarial loss: 0.407567\n",
      "epoch 91; iter: 0; batch classifier loss: 0.122249; batch adversarial loss: 0.442363\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077425; batch adversarial loss: 0.376117\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051582; batch adversarial loss: 0.514716\n",
      "epoch 94; iter: 0; batch classifier loss: 0.085142; batch adversarial loss: 0.477010\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053740; batch adversarial loss: 0.392572\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062581; batch adversarial loss: 0.523926\n",
      "epoch 97; iter: 0; batch classifier loss: 0.131450; batch adversarial loss: 0.389344\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090088; batch adversarial loss: 0.373475\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050719; batch adversarial loss: 0.497299\n",
      "epoch 100; iter: 0; batch classifier loss: 0.069042; batch adversarial loss: 0.374125\n",
      "epoch 101; iter: 0; batch classifier loss: 0.074425; batch adversarial loss: 0.422365\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059423; batch adversarial loss: 0.409649\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077232; batch adversarial loss: 0.548103\n",
      "epoch 104; iter: 0; batch classifier loss: 0.055769; batch adversarial loss: 0.517747\n",
      "epoch 105; iter: 0; batch classifier loss: 0.095819; batch adversarial loss: 0.434207\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086300; batch adversarial loss: 0.465299\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040141; batch adversarial loss: 0.434417\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069466; batch adversarial loss: 0.395208\n",
      "epoch 109; iter: 0; batch classifier loss: 0.058376; batch adversarial loss: 0.471050\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048036; batch adversarial loss: 0.539317\n",
      "epoch 111; iter: 0; batch classifier loss: 0.023347; batch adversarial loss: 0.442696\n",
      "epoch 112; iter: 0; batch classifier loss: 0.065704; batch adversarial loss: 0.470742\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030707; batch adversarial loss: 0.407676\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073584; batch adversarial loss: 0.506411\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061774; batch adversarial loss: 0.503987\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058849; batch adversarial loss: 0.439422\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051065; batch adversarial loss: 0.489498\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041736; batch adversarial loss: 0.394056\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039029; batch adversarial loss: 0.527552\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050450; batch adversarial loss: 0.437624\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049947; batch adversarial loss: 0.406822\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036969; batch adversarial loss: 0.501886\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040296; batch adversarial loss: 0.424381\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039927; batch adversarial loss: 0.396191\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024212; batch adversarial loss: 0.371812\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042773; batch adversarial loss: 0.437484\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029171; batch adversarial loss: 0.447865\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026305; batch adversarial loss: 0.440761\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024998; batch adversarial loss: 0.486733\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042955; batch adversarial loss: 0.480458\n",
      "epoch 131; iter: 0; batch classifier loss: 0.048240; batch adversarial loss: 0.409996\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025700; batch adversarial loss: 0.499727\n",
      "epoch 133; iter: 0; batch classifier loss: 0.030164; batch adversarial loss: 0.505404\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.447646\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020835; batch adversarial loss: 0.402437\n",
      "epoch 136; iter: 0; batch classifier loss: 0.037251; batch adversarial loss: 0.549006\n",
      "epoch 137; iter: 0; batch classifier loss: 0.029867; batch adversarial loss: 0.509521\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036793; batch adversarial loss: 0.418125\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042708; batch adversarial loss: 0.404972\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013777; batch adversarial loss: 0.474638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.083076; batch adversarial loss: 0.368108\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025184; batch adversarial loss: 0.537535\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025116; batch adversarial loss: 0.455185\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046824; batch adversarial loss: 0.408591\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037049; batch adversarial loss: 0.554185\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019830; batch adversarial loss: 0.395787\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033149; batch adversarial loss: 0.424227\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039342; batch adversarial loss: 0.507733\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.448290\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015096; batch adversarial loss: 0.403488\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026434; batch adversarial loss: 0.429984\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024081; batch adversarial loss: 0.497121\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032420; batch adversarial loss: 0.525379\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027293; batch adversarial loss: 0.392359\n",
      "epoch 155; iter: 0; batch classifier loss: 0.040294; batch adversarial loss: 0.440788\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014326; batch adversarial loss: 0.470894\n",
      "epoch 157; iter: 0; batch classifier loss: 0.006183; batch adversarial loss: 0.446304\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032222; batch adversarial loss: 0.418050\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031165; batch adversarial loss: 0.423092\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024126; batch adversarial loss: 0.447999\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027333; batch adversarial loss: 0.507574\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035082; batch adversarial loss: 0.524249\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038676; batch adversarial loss: 0.420960\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034461; batch adversarial loss: 0.493613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.029939; batch adversarial loss: 0.485223\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033455; batch adversarial loss: 0.506936\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023427; batch adversarial loss: 0.458019\n",
      "epoch 168; iter: 0; batch classifier loss: 0.027685; batch adversarial loss: 0.457795\n",
      "epoch 169; iter: 0; batch classifier loss: 0.011885; batch adversarial loss: 0.427581\n",
      "epoch 170; iter: 0; batch classifier loss: 0.048334; batch adversarial loss: 0.556758\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028029; batch adversarial loss: 0.382791\n",
      "epoch 172; iter: 0; batch classifier loss: 0.041783; batch adversarial loss: 0.481559\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018005; batch adversarial loss: 0.440584\n",
      "epoch 174; iter: 0; batch classifier loss: 0.020713; batch adversarial loss: 0.417169\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041598; batch adversarial loss: 0.495919\n",
      "epoch 176; iter: 0; batch classifier loss: 0.005130; batch adversarial loss: 0.413177\n",
      "epoch 177; iter: 0; batch classifier loss: 0.029341; batch adversarial loss: 0.537000\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008735; batch adversarial loss: 0.437056\n",
      "epoch 179; iter: 0; batch classifier loss: 0.027098; batch adversarial loss: 0.389599\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026357; batch adversarial loss: 0.459689\n",
      "epoch 181; iter: 0; batch classifier loss: 0.003273; batch adversarial loss: 0.378215\n",
      "epoch 182; iter: 0; batch classifier loss: 0.025435; batch adversarial loss: 0.433342\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025909; batch adversarial loss: 0.411836\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018373; batch adversarial loss: 0.551717\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018465; batch adversarial loss: 0.535593\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005941; batch adversarial loss: 0.459582\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018134; batch adversarial loss: 0.469369\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005373; batch adversarial loss: 0.440804\n",
      "epoch 189; iter: 0; batch classifier loss: 0.031075; batch adversarial loss: 0.457449\n",
      "epoch 190; iter: 0; batch classifier loss: 0.012652; batch adversarial loss: 0.449730\n",
      "epoch 191; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.399982\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.473900\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024338; batch adversarial loss: 0.473969\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041670; batch adversarial loss: 0.454580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033975; batch adversarial loss: 0.362229\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020594; batch adversarial loss: 0.461286\n",
      "epoch 197; iter: 0; batch classifier loss: 0.017289; batch adversarial loss: 0.467440\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019030; batch adversarial loss: 0.484794\n",
      "epoch 199; iter: 0; batch classifier loss: 0.016195; batch adversarial loss: 0.478637\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705149; batch adversarial loss: 0.707223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.427779; batch adversarial loss: 0.670445\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391765; batch adversarial loss: 0.619131\n",
      "epoch 3; iter: 0; batch classifier loss: 0.386788; batch adversarial loss: 0.586701\n",
      "epoch 4; iter: 0; batch classifier loss: 0.327097; batch adversarial loss: 0.584217\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326454; batch adversarial loss: 0.547377\n",
      "epoch 6; iter: 0; batch classifier loss: 0.301641; batch adversarial loss: 0.536653\n",
      "epoch 7; iter: 0; batch classifier loss: 0.229380; batch adversarial loss: 0.538388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.205625; batch adversarial loss: 0.528817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.225273; batch adversarial loss: 0.530587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.218398; batch adversarial loss: 0.501599\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247633; batch adversarial loss: 0.521252\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205347; batch adversarial loss: 0.494918\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272905; batch adversarial loss: 0.513601\n",
      "epoch 14; iter: 0; batch classifier loss: 0.147355; batch adversarial loss: 0.531764\n",
      "epoch 15; iter: 0; batch classifier loss: 0.196349; batch adversarial loss: 0.464437\n",
      "epoch 16; iter: 0; batch classifier loss: 0.250748; batch adversarial loss: 0.514443\n",
      "epoch 17; iter: 0; batch classifier loss: 0.219812; batch adversarial loss: 0.466935\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282655; batch adversarial loss: 0.520482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.303517; batch adversarial loss: 0.483670\n",
      "epoch 20; iter: 0; batch classifier loss: 0.371146; batch adversarial loss: 0.455768\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502666; batch adversarial loss: 0.468827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389343; batch adversarial loss: 0.442731\n",
      "epoch 23; iter: 0; batch classifier loss: 0.207939; batch adversarial loss: 0.493653\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159888; batch adversarial loss: 0.572181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.144733; batch adversarial loss: 0.488362\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172921; batch adversarial loss: 0.458999\n",
      "epoch 27; iter: 0; batch classifier loss: 0.149103; batch adversarial loss: 0.464601\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140045; batch adversarial loss: 0.476751\n",
      "epoch 29; iter: 0; batch classifier loss: 0.185086; batch adversarial loss: 0.498549\n",
      "epoch 30; iter: 0; batch classifier loss: 0.130000; batch adversarial loss: 0.508129\n",
      "epoch 31; iter: 0; batch classifier loss: 0.177353; batch adversarial loss: 0.437052\n",
      "epoch 32; iter: 0; batch classifier loss: 0.107012; batch adversarial loss: 0.405249\n",
      "epoch 33; iter: 0; batch classifier loss: 0.153605; batch adversarial loss: 0.469844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.125845; batch adversarial loss: 0.435248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134272; batch adversarial loss: 0.459604\n",
      "epoch 36; iter: 0; batch classifier loss: 0.085546; batch adversarial loss: 0.517446\n",
      "epoch 37; iter: 0; batch classifier loss: 0.102835; batch adversarial loss: 0.485591\n",
      "epoch 38; iter: 0; batch classifier loss: 0.168773; batch adversarial loss: 0.449386\n",
      "epoch 39; iter: 0; batch classifier loss: 0.109920; batch adversarial loss: 0.393925\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135135; batch adversarial loss: 0.424582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.104386; batch adversarial loss: 0.490904\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106245; batch adversarial loss: 0.479438\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105383; batch adversarial loss: 0.392398\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106042; batch adversarial loss: 0.560695\n",
      "epoch 45; iter: 0; batch classifier loss: 0.086356; batch adversarial loss: 0.499025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.162365; batch adversarial loss: 0.444368\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102220; batch adversarial loss: 0.419132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.160450; batch adversarial loss: 0.399458\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076699; batch adversarial loss: 0.453005\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098157; batch adversarial loss: 0.520114\n",
      "epoch 51; iter: 0; batch classifier loss: 0.145754; batch adversarial loss: 0.468922\n",
      "epoch 52; iter: 0; batch classifier loss: 0.109740; batch adversarial loss: 0.452748\n",
      "epoch 53; iter: 0; batch classifier loss: 0.169606; batch adversarial loss: 0.556656\n",
      "epoch 54; iter: 0; batch classifier loss: 0.085025; batch adversarial loss: 0.461058\n",
      "epoch 55; iter: 0; batch classifier loss: 0.082140; batch adversarial loss: 0.410072\n",
      "epoch 56; iter: 0; batch classifier loss: 0.096431; batch adversarial loss: 0.444864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.118421; batch adversarial loss: 0.392008\n",
      "epoch 58; iter: 0; batch classifier loss: 0.084004; batch adversarial loss: 0.502677\n",
      "epoch 59; iter: 0; batch classifier loss: 0.142201; batch adversarial loss: 0.375820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.094891; batch adversarial loss: 0.416047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.112661; batch adversarial loss: 0.442185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.086164; batch adversarial loss: 0.447989\n",
      "epoch 63; iter: 0; batch classifier loss: 0.086137; batch adversarial loss: 0.400490\n",
      "epoch 64; iter: 0; batch classifier loss: 0.091554; batch adversarial loss: 0.486458\n",
      "epoch 65; iter: 0; batch classifier loss: 0.103433; batch adversarial loss: 0.502971\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092388; batch adversarial loss: 0.459443\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096429; batch adversarial loss: 0.481892\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079581; batch adversarial loss: 0.448084\n",
      "epoch 69; iter: 0; batch classifier loss: 0.123069; batch adversarial loss: 0.485612\n",
      "epoch 70; iter: 0; batch classifier loss: 0.117522; batch adversarial loss: 0.572675\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105647; batch adversarial loss: 0.466890\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082933; batch adversarial loss: 0.561769\n",
      "epoch 73; iter: 0; batch classifier loss: 0.075758; batch adversarial loss: 0.493014\n",
      "epoch 74; iter: 0; batch classifier loss: 0.111548; batch adversarial loss: 0.411816\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066376; batch adversarial loss: 0.445849\n",
      "epoch 76; iter: 0; batch classifier loss: 0.119845; batch adversarial loss: 0.473428\n",
      "epoch 77; iter: 0; batch classifier loss: 0.123346; batch adversarial loss: 0.486307\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099961; batch adversarial loss: 0.420273\n",
      "epoch 79; iter: 0; batch classifier loss: 0.172594; batch adversarial loss: 0.431650\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090059; batch adversarial loss: 0.480252\n",
      "epoch 81; iter: 0; batch classifier loss: 0.086383; batch adversarial loss: 0.407077\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076283; batch adversarial loss: 0.377986\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078883; batch adversarial loss: 0.454484\n",
      "epoch 84; iter: 0; batch classifier loss: 0.095136; batch adversarial loss: 0.471142\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069093; batch adversarial loss: 0.471441\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040591; batch adversarial loss: 0.540476\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057596; batch adversarial loss: 0.479022\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063251; batch adversarial loss: 0.509872\n",
      "epoch 89; iter: 0; batch classifier loss: 0.097059; batch adversarial loss: 0.420968\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078114; batch adversarial loss: 0.477387\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081620; batch adversarial loss: 0.423218\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080793; batch adversarial loss: 0.464517\n",
      "epoch 93; iter: 0; batch classifier loss: 0.062408; batch adversarial loss: 0.502681\n",
      "epoch 94; iter: 0; batch classifier loss: 0.080645; batch adversarial loss: 0.516018\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096833; batch adversarial loss: 0.527105\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063550; batch adversarial loss: 0.434491\n",
      "epoch 97; iter: 0; batch classifier loss: 0.074293; batch adversarial loss: 0.435282\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034871; batch adversarial loss: 0.518948\n",
      "epoch 99; iter: 0; batch classifier loss: 0.045371; batch adversarial loss: 0.529938\n",
      "epoch 100; iter: 0; batch classifier loss: 0.067791; batch adversarial loss: 0.427810\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087171; batch adversarial loss: 0.407798\n",
      "epoch 102; iter: 0; batch classifier loss: 0.065872; batch adversarial loss: 0.418277\n",
      "epoch 103; iter: 0; batch classifier loss: 0.062079; batch adversarial loss: 0.449208\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058708; batch adversarial loss: 0.466338\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087871; batch adversarial loss: 0.458527\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047236; batch adversarial loss: 0.463559\n",
      "epoch 107; iter: 0; batch classifier loss: 0.085390; batch adversarial loss: 0.456236\n",
      "epoch 108; iter: 0; batch classifier loss: 0.084323; batch adversarial loss: 0.385129\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038671; batch adversarial loss: 0.444292\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066652; batch adversarial loss: 0.438063\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062503; batch adversarial loss: 0.446953\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045635; batch adversarial loss: 0.576334\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044384; batch adversarial loss: 0.422385\n",
      "epoch 114; iter: 0; batch classifier loss: 0.086995; batch adversarial loss: 0.589185\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029923; batch adversarial loss: 0.440898\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026422; batch adversarial loss: 0.432609\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038874; batch adversarial loss: 0.392439\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045556; batch adversarial loss: 0.480268\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.525216\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058121; batch adversarial loss: 0.390741\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049046; batch adversarial loss: 0.470375\n",
      "epoch 122; iter: 0; batch classifier loss: 0.040150; batch adversarial loss: 0.456574\n",
      "epoch 123; iter: 0; batch classifier loss: 0.021381; batch adversarial loss: 0.520365\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031807; batch adversarial loss: 0.552129\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060549; batch adversarial loss: 0.453913\n",
      "epoch 126; iter: 0; batch classifier loss: 0.078018; batch adversarial loss: 0.453908\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029195; batch adversarial loss: 0.473549\n",
      "epoch 128; iter: 0; batch classifier loss: 0.017998; batch adversarial loss: 0.496594\n",
      "epoch 129; iter: 0; batch classifier loss: 0.021274; batch adversarial loss: 0.363445\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031508; batch adversarial loss: 0.444120\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029553; batch adversarial loss: 0.451220\n",
      "epoch 132; iter: 0; batch classifier loss: 0.056685; batch adversarial loss: 0.407063\n",
      "epoch 133; iter: 0; batch classifier loss: 0.024656; batch adversarial loss: 0.449162\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038352; batch adversarial loss: 0.416296\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013358; batch adversarial loss: 0.385101\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039676; batch adversarial loss: 0.416407\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.487255\n",
      "epoch 138; iter: 0; batch classifier loss: 0.061226; batch adversarial loss: 0.425485\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046020; batch adversarial loss: 0.448051\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026631; batch adversarial loss: 0.399387\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044849; batch adversarial loss: 0.464111\n",
      "epoch 142; iter: 0; batch classifier loss: 0.024984; batch adversarial loss: 0.476842\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014315; batch adversarial loss: 0.420061\n",
      "epoch 144; iter: 0; batch classifier loss: 0.041942; batch adversarial loss: 0.471404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013284; batch adversarial loss: 0.419260\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044210; batch adversarial loss: 0.513572\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018329; batch adversarial loss: 0.425593\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014307; batch adversarial loss: 0.407588\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030338; batch adversarial loss: 0.543187\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013701; batch adversarial loss: 0.493321\n",
      "epoch 151; iter: 0; batch classifier loss: 0.039042; batch adversarial loss: 0.385140\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043288; batch adversarial loss: 0.420113\n",
      "epoch 153; iter: 0; batch classifier loss: 0.029873; batch adversarial loss: 0.539492\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010340; batch adversarial loss: 0.345536\n",
      "epoch 155; iter: 0; batch classifier loss: 0.036617; batch adversarial loss: 0.358781\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023519; batch adversarial loss: 0.476668\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022649; batch adversarial loss: 0.495955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.032127; batch adversarial loss: 0.451089\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033575; batch adversarial loss: 0.475612\n",
      "epoch 160; iter: 0; batch classifier loss: 0.023331; batch adversarial loss: 0.443569\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049864; batch adversarial loss: 0.347335\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034947; batch adversarial loss: 0.478156\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015017; batch adversarial loss: 0.431094\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.527501\n",
      "epoch 165; iter: 0; batch classifier loss: 0.038453; batch adversarial loss: 0.498957\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014586; batch adversarial loss: 0.469467\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023588; batch adversarial loss: 0.436256\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029127; batch adversarial loss: 0.455966\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031055; batch adversarial loss: 0.429162\n",
      "epoch 170; iter: 0; batch classifier loss: 0.042061; batch adversarial loss: 0.442159\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035271; batch adversarial loss: 0.585064\n",
      "epoch 172; iter: 0; batch classifier loss: 0.008319; batch adversarial loss: 0.434558\n",
      "epoch 173; iter: 0; batch classifier loss: 0.023260; batch adversarial loss: 0.443171\n",
      "epoch 174; iter: 0; batch classifier loss: 0.024886; batch adversarial loss: 0.445565\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012803; batch adversarial loss: 0.527763\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031196; batch adversarial loss: 0.426662\n",
      "epoch 177; iter: 0; batch classifier loss: 0.018138; batch adversarial loss: 0.437589\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029653; batch adversarial loss: 0.482469\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023198; batch adversarial loss: 0.538709\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019488; batch adversarial loss: 0.564446\n",
      "epoch 181; iter: 0; batch classifier loss: 0.022396; batch adversarial loss: 0.437369\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007454; batch adversarial loss: 0.452342\n",
      "epoch 183; iter: 0; batch classifier loss: 0.088850; batch adversarial loss: 0.537818\n",
      "epoch 184; iter: 0; batch classifier loss: 0.040256; batch adversarial loss: 0.409269\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022125; batch adversarial loss: 0.467621\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013528; batch adversarial loss: 0.478286\n",
      "epoch 187; iter: 0; batch classifier loss: 0.041441; batch adversarial loss: 0.529821\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012272; batch adversarial loss: 0.378489\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005616; batch adversarial loss: 0.405117\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010740; batch adversarial loss: 0.487853\n",
      "epoch 191; iter: 0; batch classifier loss: 0.016668; batch adversarial loss: 0.542223\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026446; batch adversarial loss: 0.429596\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017692; batch adversarial loss: 0.399865\n",
      "epoch 194; iter: 0; batch classifier loss: 0.027098; batch adversarial loss: 0.443182\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035418; batch adversarial loss: 0.470735\n",
      "epoch 196; iter: 0; batch classifier loss: 0.028489; batch adversarial loss: 0.377948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009690; batch adversarial loss: 0.461341\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018513; batch adversarial loss: 0.485164\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021369; batch adversarial loss: 0.398488\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712008; batch adversarial loss: 0.562173\n",
      "epoch 1; iter: 0; batch classifier loss: 0.422360; batch adversarial loss: 0.597846\n",
      "epoch 2; iter: 0; batch classifier loss: 0.387449; batch adversarial loss: 0.604783\n",
      "epoch 3; iter: 0; batch classifier loss: 0.352505; batch adversarial loss: 0.547032\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364431; batch adversarial loss: 0.578964\n",
      "epoch 5; iter: 0; batch classifier loss: 0.299516; batch adversarial loss: 0.558627\n",
      "epoch 6; iter: 0; batch classifier loss: 0.343427; batch adversarial loss: 0.629484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335434; batch adversarial loss: 0.513839\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370188; batch adversarial loss: 0.646382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350716; batch adversarial loss: 0.456405\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389723; batch adversarial loss: 0.533336\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419002; batch adversarial loss: 0.517544\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353847; batch adversarial loss: 0.498196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.601544; batch adversarial loss: 0.507926\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506243; batch adversarial loss: 0.493828\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401752; batch adversarial loss: 0.433788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263132; batch adversarial loss: 0.508910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.252350; batch adversarial loss: 0.476273\n",
      "epoch 18; iter: 0; batch classifier loss: 0.221307; batch adversarial loss: 0.531485\n",
      "epoch 19; iter: 0; batch classifier loss: 0.181144; batch adversarial loss: 0.519897\n",
      "epoch 20; iter: 0; batch classifier loss: 0.213400; batch adversarial loss: 0.459286\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202754; batch adversarial loss: 0.350872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.232202; batch adversarial loss: 0.356138\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184873; batch adversarial loss: 0.400101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.145774; batch adversarial loss: 0.467524\n",
      "epoch 25; iter: 0; batch classifier loss: 0.215343; batch adversarial loss: 0.413301\n",
      "epoch 26; iter: 0; batch classifier loss: 0.188573; batch adversarial loss: 0.468052\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154760; batch adversarial loss: 0.421079\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124667; batch adversarial loss: 0.456585\n",
      "epoch 29; iter: 0; batch classifier loss: 0.112380; batch adversarial loss: 0.474799\n",
      "epoch 30; iter: 0; batch classifier loss: 0.186319; batch adversarial loss: 0.514361\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132238; batch adversarial loss: 0.437536\n",
      "epoch 32; iter: 0; batch classifier loss: 0.118979; batch adversarial loss: 0.444447\n",
      "epoch 33; iter: 0; batch classifier loss: 0.092859; batch adversarial loss: 0.437835\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208930; batch adversarial loss: 0.424338\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121887; batch adversarial loss: 0.372901\n",
      "epoch 36; iter: 0; batch classifier loss: 0.110800; batch adversarial loss: 0.449913\n",
      "epoch 37; iter: 0; batch classifier loss: 0.114994; batch adversarial loss: 0.329788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.085118; batch adversarial loss: 0.500317\n",
      "epoch 39; iter: 0; batch classifier loss: 0.084827; batch adversarial loss: 0.485105\n",
      "epoch 40; iter: 0; batch classifier loss: 0.108765; batch adversarial loss: 0.426261\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118267; batch adversarial loss: 0.440816\n",
      "epoch 42; iter: 0; batch classifier loss: 0.085589; batch adversarial loss: 0.367920\n",
      "epoch 43; iter: 0; batch classifier loss: 0.168162; batch adversarial loss: 0.472500\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087932; batch adversarial loss: 0.418513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106420; batch adversarial loss: 0.511967\n",
      "epoch 46; iter: 0; batch classifier loss: 0.173128; batch adversarial loss: 0.425687\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093620; batch adversarial loss: 0.405390\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102634; batch adversarial loss: 0.461698\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099051; batch adversarial loss: 0.377072\n",
      "epoch 50; iter: 0; batch classifier loss: 0.070424; batch adversarial loss: 0.394727\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115655; batch adversarial loss: 0.455894\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092332; batch adversarial loss: 0.462631\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094645; batch adversarial loss: 0.373201\n",
      "epoch 54; iter: 0; batch classifier loss: 0.087777; batch adversarial loss: 0.410928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55; iter: 0; batch classifier loss: 0.145185; batch adversarial loss: 0.441810\n",
      "epoch 56; iter: 0; batch classifier loss: 0.082804; batch adversarial loss: 0.407302\n",
      "epoch 57; iter: 0; batch classifier loss: 0.067370; batch adversarial loss: 0.399504\n",
      "epoch 58; iter: 0; batch classifier loss: 0.075011; batch adversarial loss: 0.383562\n",
      "epoch 59; iter: 0; batch classifier loss: 0.082000; batch adversarial loss: 0.475889\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082716; batch adversarial loss: 0.421639\n",
      "epoch 61; iter: 0; batch classifier loss: 0.122354; batch adversarial loss: 0.450996\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081220; batch adversarial loss: 0.494702\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099265; batch adversarial loss: 0.427336\n",
      "epoch 64; iter: 0; batch classifier loss: 0.080558; batch adversarial loss: 0.356057\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110375; batch adversarial loss: 0.414022\n",
      "epoch 66; iter: 0; batch classifier loss: 0.090673; batch adversarial loss: 0.536585\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089020; batch adversarial loss: 0.439047\n",
      "epoch 68; iter: 0; batch classifier loss: 0.090223; batch adversarial loss: 0.409986\n",
      "epoch 69; iter: 0; batch classifier loss: 0.115032; batch adversarial loss: 0.451079\n",
      "epoch 70; iter: 0; batch classifier loss: 0.066244; batch adversarial loss: 0.514665\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101614; batch adversarial loss: 0.529920\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080136; batch adversarial loss: 0.456795\n",
      "epoch 73; iter: 0; batch classifier loss: 0.114146; batch adversarial loss: 0.547959\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083651; batch adversarial loss: 0.493242\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055226; batch adversarial loss: 0.480391\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110179; batch adversarial loss: 0.406533\n",
      "epoch 77; iter: 0; batch classifier loss: 0.087854; batch adversarial loss: 0.369465\n",
      "epoch 78; iter: 0; batch classifier loss: 0.078243; batch adversarial loss: 0.436553\n",
      "epoch 79; iter: 0; batch classifier loss: 0.087378; batch adversarial loss: 0.356375\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075358; batch adversarial loss: 0.439314\n",
      "epoch 81; iter: 0; batch classifier loss: 0.065158; batch adversarial loss: 0.349655\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125058; batch adversarial loss: 0.396973\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078824; batch adversarial loss: 0.380188\n",
      "epoch 84; iter: 0; batch classifier loss: 0.053919; batch adversarial loss: 0.537052\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052444; batch adversarial loss: 0.481620\n",
      "epoch 86; iter: 0; batch classifier loss: 0.084679; batch adversarial loss: 0.434139\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072469; batch adversarial loss: 0.427700\n",
      "epoch 88; iter: 0; batch classifier loss: 0.071894; batch adversarial loss: 0.397973\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074264; batch adversarial loss: 0.434360\n",
      "epoch 90; iter: 0; batch classifier loss: 0.120928; batch adversarial loss: 0.421123\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077932; batch adversarial loss: 0.423271\n",
      "epoch 92; iter: 0; batch classifier loss: 0.144271; batch adversarial loss: 0.449006\n",
      "epoch 93; iter: 0; batch classifier loss: 0.070134; batch adversarial loss: 0.460356\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057644; batch adversarial loss: 0.465896\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051061; batch adversarial loss: 0.474462\n",
      "epoch 96; iter: 0; batch classifier loss: 0.059006; batch adversarial loss: 0.484377\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051279; batch adversarial loss: 0.445651\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096403; batch adversarial loss: 0.456741\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077719; batch adversarial loss: 0.358161\n",
      "epoch 100; iter: 0; batch classifier loss: 0.118457; batch adversarial loss: 0.376349\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053742; batch adversarial loss: 0.351537\n",
      "epoch 102; iter: 0; batch classifier loss: 0.099762; batch adversarial loss: 0.383237\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082557; batch adversarial loss: 0.365277\n",
      "epoch 104; iter: 0; batch classifier loss: 0.083978; batch adversarial loss: 0.516760\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053721; batch adversarial loss: 0.511005\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050923; batch adversarial loss: 0.480240\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052233; batch adversarial loss: 0.509499\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033650; batch adversarial loss: 0.426702\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046687; batch adversarial loss: 0.384673\n",
      "epoch 110; iter: 0; batch classifier loss: 0.054719; batch adversarial loss: 0.492336\n",
      "epoch 111; iter: 0; batch classifier loss: 0.031286; batch adversarial loss: 0.468177\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052119; batch adversarial loss: 0.384783\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057900; batch adversarial loss: 0.464416\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037101; batch adversarial loss: 0.363093\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023406; batch adversarial loss: 0.380904\n",
      "epoch 116; iter: 0; batch classifier loss: 0.031051; batch adversarial loss: 0.516333\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022737; batch adversarial loss: 0.416759\n",
      "epoch 118; iter: 0; batch classifier loss: 0.046122; batch adversarial loss: 0.483719\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063381; batch adversarial loss: 0.390642\n",
      "epoch 120; iter: 0; batch classifier loss: 0.074948; batch adversarial loss: 0.400265\n",
      "epoch 121; iter: 0; batch classifier loss: 0.038455; batch adversarial loss: 0.435745\n",
      "epoch 122; iter: 0; batch classifier loss: 0.048644; batch adversarial loss: 0.510657\n",
      "epoch 123; iter: 0; batch classifier loss: 0.063969; batch adversarial loss: 0.538335\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059117; batch adversarial loss: 0.520881\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047773; batch adversarial loss: 0.388902\n",
      "epoch 126; iter: 0; batch classifier loss: 0.061687; batch adversarial loss: 0.452622\n",
      "epoch 127; iter: 0; batch classifier loss: 0.022747; batch adversarial loss: 0.420060\n",
      "epoch 128; iter: 0; batch classifier loss: 0.022446; batch adversarial loss: 0.433425\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042835; batch adversarial loss: 0.372061\n",
      "epoch 130; iter: 0; batch classifier loss: 0.033449; batch adversarial loss: 0.503790\n",
      "epoch 131; iter: 0; batch classifier loss: 0.039232; batch adversarial loss: 0.449888\n",
      "epoch 132; iter: 0; batch classifier loss: 0.027365; batch adversarial loss: 0.332202\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018406; batch adversarial loss: 0.440684\n",
      "epoch 134; iter: 0; batch classifier loss: 0.052288; batch adversarial loss: 0.475059\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040416; batch adversarial loss: 0.359940\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052812; batch adversarial loss: 0.504677\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034812; batch adversarial loss: 0.415557\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033625; batch adversarial loss: 0.439757\n",
      "epoch 139; iter: 0; batch classifier loss: 0.043717; batch adversarial loss: 0.384256\n",
      "epoch 140; iter: 0; batch classifier loss: 0.024844; batch adversarial loss: 0.378941\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016452; batch adversarial loss: 0.472916\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039724; batch adversarial loss: 0.373396\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049361; batch adversarial loss: 0.360454\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038376; batch adversarial loss: 0.452605\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025967; batch adversarial loss: 0.428628\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046192; batch adversarial loss: 0.405684\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024297; batch adversarial loss: 0.466605\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031935; batch adversarial loss: 0.472700\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027432; batch adversarial loss: 0.333284\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015270; batch adversarial loss: 0.376134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 151; iter: 0; batch classifier loss: 0.018252; batch adversarial loss: 0.516097\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018140; batch adversarial loss: 0.511331\n",
      "epoch 153; iter: 0; batch classifier loss: 0.060428; batch adversarial loss: 0.435790\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013434; batch adversarial loss: 0.389856\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037376; batch adversarial loss: 0.404536\n",
      "epoch 156; iter: 0; batch classifier loss: 0.077273; batch adversarial loss: 0.524156\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018773; batch adversarial loss: 0.497855\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014254; batch adversarial loss: 0.453185\n",
      "epoch 159; iter: 0; batch classifier loss: 0.020433; batch adversarial loss: 0.386493\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017578; batch adversarial loss: 0.410552\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006735; batch adversarial loss: 0.416495\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021235; batch adversarial loss: 0.399905\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034269; batch adversarial loss: 0.440278\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015504; batch adversarial loss: 0.409796\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013013; batch adversarial loss: 0.487539\n",
      "epoch 166; iter: 0; batch classifier loss: 0.025959; batch adversarial loss: 0.417114\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039877; batch adversarial loss: 0.492624\n",
      "epoch 168; iter: 0; batch classifier loss: 0.060203; batch adversarial loss: 0.529368\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017097; batch adversarial loss: 0.487541\n",
      "epoch 170; iter: 0; batch classifier loss: 0.009523; batch adversarial loss: 0.480823\n",
      "epoch 171; iter: 0; batch classifier loss: 0.039719; batch adversarial loss: 0.572062\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020799; batch adversarial loss: 0.487623\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035837; batch adversarial loss: 0.446013\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019249; batch adversarial loss: 0.478687\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018482; batch adversarial loss: 0.373075\n",
      "epoch 176; iter: 0; batch classifier loss: 0.013346; batch adversarial loss: 0.498825\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025418; batch adversarial loss: 0.466713\n",
      "epoch 178; iter: 0; batch classifier loss: 0.018480; batch adversarial loss: 0.409062\n",
      "epoch 179; iter: 0; batch classifier loss: 0.016762; batch adversarial loss: 0.429896\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009812; batch adversarial loss: 0.419641\n",
      "epoch 181; iter: 0; batch classifier loss: 0.026811; batch adversarial loss: 0.376599\n",
      "epoch 182; iter: 0; batch classifier loss: 0.035899; batch adversarial loss: 0.505676\n",
      "epoch 183; iter: 0; batch classifier loss: 0.014375; batch adversarial loss: 0.507682\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010826; batch adversarial loss: 0.506267\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011904; batch adversarial loss: 0.383387\n",
      "epoch 186; iter: 0; batch classifier loss: 0.062970; batch adversarial loss: 0.448678\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016870; batch adversarial loss: 0.434706\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.438998\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025869; batch adversarial loss: 0.400921\n",
      "epoch 190; iter: 0; batch classifier loss: 0.033155; batch adversarial loss: 0.434431\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019526; batch adversarial loss: 0.375120\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031481; batch adversarial loss: 0.463790\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015070; batch adversarial loss: 0.391480\n",
      "epoch 194; iter: 0; batch classifier loss: 0.031072; batch adversarial loss: 0.432173\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013064; batch adversarial loss: 0.498519\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013494; batch adversarial loss: 0.498826\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006973; batch adversarial loss: 0.571253\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013824; batch adversarial loss: 0.354736\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010045; batch adversarial loss: 0.498800\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701750; batch adversarial loss: 0.640531\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461071; batch adversarial loss: 0.626899\n",
      "epoch 2; iter: 0; batch classifier loss: 0.523608; batch adversarial loss: 0.615487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.430505; batch adversarial loss: 0.629011\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412974; batch adversarial loss: 0.617462\n",
      "epoch 5; iter: 0; batch classifier loss: 0.426415; batch adversarial loss: 0.589403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506285; batch adversarial loss: 0.567706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458775; batch adversarial loss: 0.591830\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418453; batch adversarial loss: 0.560296\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383706; batch adversarial loss: 0.503641\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380534; batch adversarial loss: 0.519367\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389209; batch adversarial loss: 0.489117\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325218; batch adversarial loss: 0.482841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431516; batch adversarial loss: 0.519361\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403234; batch adversarial loss: 0.502007\n",
      "epoch 15; iter: 0; batch classifier loss: 0.354893; batch adversarial loss: 0.482231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301387; batch adversarial loss: 0.470096\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321934; batch adversarial loss: 0.510513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290110; batch adversarial loss: 0.478336\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341377; batch adversarial loss: 0.483330\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315092; batch adversarial loss: 0.544998\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329331; batch adversarial loss: 0.472052\n",
      "epoch 22; iter: 0; batch classifier loss: 0.266208; batch adversarial loss: 0.496847\n",
      "epoch 23; iter: 0; batch classifier loss: 0.225044; batch adversarial loss: 0.436027\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343208; batch adversarial loss: 0.449939\n",
      "epoch 25; iter: 0; batch classifier loss: 0.285380; batch adversarial loss: 0.488354\n",
      "epoch 26; iter: 0; batch classifier loss: 0.250054; batch adversarial loss: 0.479665\n",
      "epoch 27; iter: 0; batch classifier loss: 0.257611; batch adversarial loss: 0.524521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.200025; batch adversarial loss: 0.483122\n",
      "epoch 29; iter: 0; batch classifier loss: 0.221907; batch adversarial loss: 0.435782\n",
      "epoch 30; iter: 0; batch classifier loss: 0.266870; batch adversarial loss: 0.474314\n",
      "epoch 31; iter: 0; batch classifier loss: 0.271360; batch adversarial loss: 0.457412\n",
      "epoch 32; iter: 0; batch classifier loss: 0.264829; batch adversarial loss: 0.444522\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159170; batch adversarial loss: 0.589895\n",
      "epoch 34; iter: 0; batch classifier loss: 0.273583; batch adversarial loss: 0.428310\n",
      "epoch 35; iter: 0; batch classifier loss: 0.233283; batch adversarial loss: 0.409241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.260407; batch adversarial loss: 0.506509\n",
      "epoch 37; iter: 0; batch classifier loss: 0.233431; batch adversarial loss: 0.458546\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214197; batch adversarial loss: 0.459968\n",
      "epoch 39; iter: 0; batch classifier loss: 0.149905; batch adversarial loss: 0.358757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233280; batch adversarial loss: 0.473739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.198156; batch adversarial loss: 0.450264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.242442; batch adversarial loss: 0.403623\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204452; batch adversarial loss: 0.437290\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250758; batch adversarial loss: 0.436592\n",
      "epoch 45; iter: 0; batch classifier loss: 0.275607; batch adversarial loss: 0.482853\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090980; batch adversarial loss: 0.399422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.110041; batch adversarial loss: 0.468863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.123124; batch adversarial loss: 0.467524\n",
      "epoch 49; iter: 0; batch classifier loss: 0.074836; batch adversarial loss: 0.482456\n",
      "epoch 50; iter: 0; batch classifier loss: 0.066847; batch adversarial loss: 0.458344\n",
      "epoch 51; iter: 0; batch classifier loss: 0.116468; batch adversarial loss: 0.505390\n",
      "epoch 52; iter: 0; batch classifier loss: 0.111305; batch adversarial loss: 0.415270\n",
      "epoch 53; iter: 0; batch classifier loss: 0.103448; batch adversarial loss: 0.428846\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212539; batch adversarial loss: 0.494517\n",
      "epoch 55; iter: 0; batch classifier loss: 0.137096; batch adversarial loss: 0.429825\n",
      "epoch 56; iter: 0; batch classifier loss: 0.114790; batch adversarial loss: 0.463951\n",
      "epoch 57; iter: 0; batch classifier loss: 0.107888; batch adversarial loss: 0.489203\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101435; batch adversarial loss: 0.495283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.122442; batch adversarial loss: 0.442237\n",
      "epoch 60; iter: 0; batch classifier loss: 0.075255; batch adversarial loss: 0.404112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.108470; batch adversarial loss: 0.427403\n",
      "epoch 62; iter: 0; batch classifier loss: 0.106454; batch adversarial loss: 0.541675\n",
      "epoch 63; iter: 0; batch classifier loss: 0.081814; batch adversarial loss: 0.515172\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063496; batch adversarial loss: 0.496348\n",
      "epoch 65; iter: 0; batch classifier loss: 0.059470; batch adversarial loss: 0.484661\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072576; batch adversarial loss: 0.441447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073807; batch adversarial loss: 0.467491\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061375; batch adversarial loss: 0.451637\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068988; batch adversarial loss: 0.556813\n",
      "epoch 70; iter: 0; batch classifier loss: 0.053771; batch adversarial loss: 0.447884\n",
      "epoch 71; iter: 0; batch classifier loss: 0.059608; batch adversarial loss: 0.476010\n",
      "epoch 72; iter: 0; batch classifier loss: 0.113217; batch adversarial loss: 0.441389\n",
      "epoch 73; iter: 0; batch classifier loss: 0.073335; batch adversarial loss: 0.459484\n",
      "epoch 74; iter: 0; batch classifier loss: 0.094295; batch adversarial loss: 0.504157\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106070; batch adversarial loss: 0.455525\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114067; batch adversarial loss: 0.466559\n",
      "epoch 77; iter: 0; batch classifier loss: 0.068252; batch adversarial loss: 0.391186\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064529; batch adversarial loss: 0.454795\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062905; batch adversarial loss: 0.508255\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075218; batch adversarial loss: 0.484362\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070262; batch adversarial loss: 0.457694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.124115; batch adversarial loss: 0.467210\n",
      "epoch 83; iter: 0; batch classifier loss: 0.093697; batch adversarial loss: 0.476248\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055825; batch adversarial loss: 0.545278\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057857; batch adversarial loss: 0.390609\n",
      "epoch 86; iter: 0; batch classifier loss: 0.041467; batch adversarial loss: 0.390534\n",
      "epoch 87; iter: 0; batch classifier loss: 0.055980; batch adversarial loss: 0.445755\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068937; batch adversarial loss: 0.385829\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065278; batch adversarial loss: 0.429299\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072039; batch adversarial loss: 0.502018\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096797; batch adversarial loss: 0.462132\n",
      "epoch 92; iter: 0; batch classifier loss: 0.105528; batch adversarial loss: 0.475650\n",
      "epoch 93; iter: 0; batch classifier loss: 0.043634; batch adversarial loss: 0.426170\n",
      "epoch 94; iter: 0; batch classifier loss: 0.072701; batch adversarial loss: 0.510831\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093325; batch adversarial loss: 0.379854\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036623; batch adversarial loss: 0.499008\n",
      "epoch 97; iter: 0; batch classifier loss: 0.054674; batch adversarial loss: 0.421631\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042533; batch adversarial loss: 0.486377\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038179; batch adversarial loss: 0.416561\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053094; batch adversarial loss: 0.484322\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049931; batch adversarial loss: 0.500210\n",
      "epoch 102; iter: 0; batch classifier loss: 0.023031; batch adversarial loss: 0.380205\n",
      "epoch 103; iter: 0; batch classifier loss: 0.035636; batch adversarial loss: 0.413470\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072557; batch adversarial loss: 0.417727\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060249; batch adversarial loss: 0.395899\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061364; batch adversarial loss: 0.457595\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.413676\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033983; batch adversarial loss: 0.454522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030778; batch adversarial loss: 0.449838\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026038; batch adversarial loss: 0.538890\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028415; batch adversarial loss: 0.408636\n",
      "epoch 112; iter: 0; batch classifier loss: 0.066457; batch adversarial loss: 0.390357\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039953; batch adversarial loss: 0.466146\n",
      "epoch 114; iter: 0; batch classifier loss: 0.077108; batch adversarial loss: 0.415050\n",
      "epoch 115; iter: 0; batch classifier loss: 0.032700; batch adversarial loss: 0.457421\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033292; batch adversarial loss: 0.441326\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036644; batch adversarial loss: 0.495143\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022568; batch adversarial loss: 0.348952\n",
      "epoch 119; iter: 0; batch classifier loss: 0.028544; batch adversarial loss: 0.448048\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051410; batch adversarial loss: 0.420753\n",
      "epoch 121; iter: 0; batch classifier loss: 0.037202; batch adversarial loss: 0.339611\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030900; batch adversarial loss: 0.396036\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037411; batch adversarial loss: 0.516302\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017326; batch adversarial loss: 0.591323\n",
      "epoch 125; iter: 0; batch classifier loss: 0.015440; batch adversarial loss: 0.542680\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037485; batch adversarial loss: 0.383272\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048937; batch adversarial loss: 0.475709\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062509; batch adversarial loss: 0.478391\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024366; batch adversarial loss: 0.390096\n",
      "epoch 130; iter: 0; batch classifier loss: 0.056010; batch adversarial loss: 0.441686\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019380; batch adversarial loss: 0.486989\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013176; batch adversarial loss: 0.520255\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013548; batch adversarial loss: 0.489686\n",
      "epoch 134; iter: 0; batch classifier loss: 0.026588; batch adversarial loss: 0.395481\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021525; batch adversarial loss: 0.477080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.029225; batch adversarial loss: 0.458292\n",
      "epoch 137; iter: 0; batch classifier loss: 0.034107; batch adversarial loss: 0.395065\n",
      "epoch 138; iter: 0; batch classifier loss: 0.038693; batch adversarial loss: 0.479104\n",
      "epoch 139; iter: 0; batch classifier loss: 0.016140; batch adversarial loss: 0.483900\n",
      "epoch 140; iter: 0; batch classifier loss: 0.006339; batch adversarial loss: 0.395751\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032202; batch adversarial loss: 0.499948\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056641; batch adversarial loss: 0.461884\n",
      "epoch 143; iter: 0; batch classifier loss: 0.013830; batch adversarial loss: 0.488725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 144; iter: 0; batch classifier loss: 0.014358; batch adversarial loss: 0.439650\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025455; batch adversarial loss: 0.449446\n",
      "epoch 146; iter: 0; batch classifier loss: 0.007673; batch adversarial loss: 0.399849\n",
      "epoch 147; iter: 0; batch classifier loss: 0.047581; batch adversarial loss: 0.466595\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026004; batch adversarial loss: 0.456384\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036389; batch adversarial loss: 0.455820\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015367; batch adversarial loss: 0.431503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012379; batch adversarial loss: 0.497546\n",
      "epoch 152; iter: 0; batch classifier loss: 0.036561; batch adversarial loss: 0.549127\n",
      "epoch 153; iter: 0; batch classifier loss: 0.008640; batch adversarial loss: 0.481874\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032713; batch adversarial loss: 0.416323\n",
      "epoch 155; iter: 0; batch classifier loss: 0.007905; batch adversarial loss: 0.451621\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024653; batch adversarial loss: 0.433722\n",
      "epoch 157; iter: 0; batch classifier loss: 0.011662; batch adversarial loss: 0.446794\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044876; batch adversarial loss: 0.538894\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024208; batch adversarial loss: 0.498347\n",
      "epoch 160; iter: 0; batch classifier loss: 0.059953; batch adversarial loss: 0.376361\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017487; batch adversarial loss: 0.463235\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031095; batch adversarial loss: 0.438775\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030257; batch adversarial loss: 0.425037\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024753; batch adversarial loss: 0.520813\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016357; batch adversarial loss: 0.458097\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020586; batch adversarial loss: 0.448405\n",
      "epoch 167; iter: 0; batch classifier loss: 0.017964; batch adversarial loss: 0.479651\n",
      "epoch 168; iter: 0; batch classifier loss: 0.042312; batch adversarial loss: 0.466932\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033620; batch adversarial loss: 0.427739\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035742; batch adversarial loss: 0.424381\n",
      "epoch 171; iter: 0; batch classifier loss: 0.027544; batch adversarial loss: 0.538655\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021728; batch adversarial loss: 0.443275\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033655; batch adversarial loss: 0.498484\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023777; batch adversarial loss: 0.467924\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033599; batch adversarial loss: 0.482040\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032271; batch adversarial loss: 0.549947\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030070; batch adversarial loss: 0.494611\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012710; batch adversarial loss: 0.488844\n",
      "epoch 179; iter: 0; batch classifier loss: 0.029031; batch adversarial loss: 0.483798\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025797; batch adversarial loss: 0.408196\n",
      "epoch 181; iter: 0; batch classifier loss: 0.024613; batch adversarial loss: 0.454106\n",
      "epoch 182; iter: 0; batch classifier loss: 0.066697; batch adversarial loss: 0.467846\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019860; batch adversarial loss: 0.531700\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012288; batch adversarial loss: 0.421904\n",
      "epoch 185; iter: 0; batch classifier loss: 0.049749; batch adversarial loss: 0.482268\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024762; batch adversarial loss: 0.490803\n",
      "epoch 187; iter: 0; batch classifier loss: 0.034879; batch adversarial loss: 0.460976\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017235; batch adversarial loss: 0.525378\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011751; batch adversarial loss: 0.403467\n",
      "epoch 190; iter: 0; batch classifier loss: 0.022112; batch adversarial loss: 0.527019\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022125; batch adversarial loss: 0.516201\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014622; batch adversarial loss: 0.416078\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028111; batch adversarial loss: 0.462920\n",
      "epoch 194; iter: 0; batch classifier loss: 0.021719; batch adversarial loss: 0.481937\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026211; batch adversarial loss: 0.491693\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026180; batch adversarial loss: 0.557792\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028815; batch adversarial loss: 0.567735\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015637; batch adversarial loss: 0.419312\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026426; batch adversarial loss: 0.417949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690615; batch adversarial loss: 0.718607\n",
      "epoch 1; iter: 0; batch classifier loss: 0.514956; batch adversarial loss: 0.647469\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433243; batch adversarial loss: 0.629803\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382810; batch adversarial loss: 0.590360\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333266; batch adversarial loss: 0.573051\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513224; batch adversarial loss: 0.556541\n",
      "epoch 6; iter: 0; batch classifier loss: 0.299781; batch adversarial loss: 0.607813\n",
      "epoch 7; iter: 0; batch classifier loss: 0.308876; batch adversarial loss: 0.603837\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356874; batch adversarial loss: 0.550983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.310738; batch adversarial loss: 0.525228\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274003; batch adversarial loss: 0.576567\n",
      "epoch 11; iter: 0; batch classifier loss: 0.310677; batch adversarial loss: 0.505165\n",
      "epoch 12; iter: 0; batch classifier loss: 0.260023; batch adversarial loss: 0.491175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235560; batch adversarial loss: 0.470011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.235807; batch adversarial loss: 0.497719\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266732; batch adversarial loss: 0.512006\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227806; batch adversarial loss: 0.472928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222460; batch adversarial loss: 0.512630\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183532; batch adversarial loss: 0.529397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206767; batch adversarial loss: 0.462183\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250020; batch adversarial loss: 0.451142\n",
      "epoch 21; iter: 0; batch classifier loss: 0.270727; batch adversarial loss: 0.467991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.245278; batch adversarial loss: 0.453080\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167951; batch adversarial loss: 0.478616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.175916; batch adversarial loss: 0.480825\n",
      "epoch 25; iter: 0; batch classifier loss: 0.187086; batch adversarial loss: 0.406608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.175062; batch adversarial loss: 0.485159\n",
      "epoch 27; iter: 0; batch classifier loss: 0.176764; batch adversarial loss: 0.440339\n",
      "epoch 28; iter: 0; batch classifier loss: 0.204504; batch adversarial loss: 0.494827\n",
      "epoch 29; iter: 0; batch classifier loss: 0.202993; batch adversarial loss: 0.527694\n",
      "epoch 30; iter: 0; batch classifier loss: 0.155008; batch adversarial loss: 0.439519\n",
      "epoch 31; iter: 0; batch classifier loss: 0.118537; batch adversarial loss: 0.394004\n",
      "epoch 32; iter: 0; batch classifier loss: 0.121367; batch adversarial loss: 0.435708\n",
      "epoch 33; iter: 0; batch classifier loss: 0.145500; batch adversarial loss: 0.480694\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136839; batch adversarial loss: 0.594220\n",
      "epoch 35; iter: 0; batch classifier loss: 0.191128; batch adversarial loss: 0.446554\n",
      "epoch 36; iter: 0; batch classifier loss: 0.208568; batch adversarial loss: 0.479270\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216578; batch adversarial loss: 0.359842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.176271; batch adversarial loss: 0.496182\n",
      "epoch 39; iter: 0; batch classifier loss: 0.218856; batch adversarial loss: 0.441751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 0; batch classifier loss: 0.189800; batch adversarial loss: 0.465143\n",
      "epoch 41; iter: 0; batch classifier loss: 0.173881; batch adversarial loss: 0.378368\n",
      "epoch 42; iter: 0; batch classifier loss: 0.148620; batch adversarial loss: 0.429155\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302758; batch adversarial loss: 0.386965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147939; batch adversarial loss: 0.490759\n",
      "epoch 45; iter: 0; batch classifier loss: 0.237795; batch adversarial loss: 0.452485\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210768; batch adversarial loss: 0.409068\n",
      "epoch 47; iter: 0; batch classifier loss: 0.148313; batch adversarial loss: 0.582045\n",
      "epoch 48; iter: 0; batch classifier loss: 0.231480; batch adversarial loss: 0.434757\n",
      "epoch 49; iter: 0; batch classifier loss: 0.214603; batch adversarial loss: 0.392111\n",
      "epoch 50; iter: 0; batch classifier loss: 0.170258; batch adversarial loss: 0.500819\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186653; batch adversarial loss: 0.478172\n",
      "epoch 52; iter: 0; batch classifier loss: 0.235522; batch adversarial loss: 0.493737\n",
      "epoch 53; iter: 0; batch classifier loss: 0.140525; batch adversarial loss: 0.525147\n",
      "epoch 54; iter: 0; batch classifier loss: 0.114752; batch adversarial loss: 0.511715\n",
      "epoch 55; iter: 0; batch classifier loss: 0.160044; batch adversarial loss: 0.470762\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092918; batch adversarial loss: 0.502065\n",
      "epoch 57; iter: 0; batch classifier loss: 0.158760; batch adversarial loss: 0.501554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.190455; batch adversarial loss: 0.406442\n",
      "epoch 59; iter: 0; batch classifier loss: 0.163606; batch adversarial loss: 0.374845\n",
      "epoch 60; iter: 0; batch classifier loss: 0.204046; batch adversarial loss: 0.445014\n",
      "epoch 61; iter: 0; batch classifier loss: 0.135535; batch adversarial loss: 0.466505\n",
      "epoch 62; iter: 0; batch classifier loss: 0.149546; batch adversarial loss: 0.491316\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097885; batch adversarial loss: 0.424719\n",
      "epoch 64; iter: 0; batch classifier loss: 0.195990; batch adversarial loss: 0.518349\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134477; batch adversarial loss: 0.507314\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149816; batch adversarial loss: 0.554886\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122915; batch adversarial loss: 0.470147\n",
      "epoch 68; iter: 0; batch classifier loss: 0.161302; batch adversarial loss: 0.420125\n",
      "epoch 69; iter: 0; batch classifier loss: 0.187219; batch adversarial loss: 0.446139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.115794; batch adversarial loss: 0.422902\n",
      "epoch 71; iter: 0; batch classifier loss: 0.156631; batch adversarial loss: 0.446024\n",
      "epoch 72; iter: 0; batch classifier loss: 0.099636; batch adversarial loss: 0.431602\n",
      "epoch 73; iter: 0; batch classifier loss: 0.123086; batch adversarial loss: 0.468544\n",
      "epoch 74; iter: 0; batch classifier loss: 0.130958; batch adversarial loss: 0.396013\n",
      "epoch 75; iter: 0; batch classifier loss: 0.132759; batch adversarial loss: 0.448025\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096749; batch adversarial loss: 0.402519\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114315; batch adversarial loss: 0.472737\n",
      "epoch 78; iter: 0; batch classifier loss: 0.118293; batch adversarial loss: 0.437205\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099689; batch adversarial loss: 0.418942\n",
      "epoch 80; iter: 0; batch classifier loss: 0.069298; batch adversarial loss: 0.532674\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120340; batch adversarial loss: 0.397317\n",
      "epoch 82; iter: 0; batch classifier loss: 0.076300; batch adversarial loss: 0.503490\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072333; batch adversarial loss: 0.399933\n",
      "epoch 84; iter: 0; batch classifier loss: 0.091744; batch adversarial loss: 0.560877\n",
      "epoch 85; iter: 0; batch classifier loss: 0.143700; batch adversarial loss: 0.554308\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061189; batch adversarial loss: 0.526275\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073863; batch adversarial loss: 0.440598\n",
      "epoch 88; iter: 0; batch classifier loss: 0.067972; batch adversarial loss: 0.498379\n",
      "epoch 89; iter: 0; batch classifier loss: 0.065307; batch adversarial loss: 0.484139\n",
      "epoch 90; iter: 0; batch classifier loss: 0.115885; batch adversarial loss: 0.408068\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067225; batch adversarial loss: 0.437108\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070929; batch adversarial loss: 0.434095\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039061; batch adversarial loss: 0.559565\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040273; batch adversarial loss: 0.486992\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042788; batch adversarial loss: 0.456405\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053140; batch adversarial loss: 0.467264\n",
      "epoch 97; iter: 0; batch classifier loss: 0.070989; batch adversarial loss: 0.406093\n",
      "epoch 98; iter: 0; batch classifier loss: 0.077890; batch adversarial loss: 0.432431\n",
      "epoch 99; iter: 0; batch classifier loss: 0.055057; batch adversarial loss: 0.447169\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062859; batch adversarial loss: 0.446448\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057063; batch adversarial loss: 0.401354\n",
      "epoch 102; iter: 0; batch classifier loss: 0.100453; batch adversarial loss: 0.422909\n",
      "epoch 103; iter: 0; batch classifier loss: 0.041972; batch adversarial loss: 0.476616\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073319; batch adversarial loss: 0.523462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060979; batch adversarial loss: 0.465916\n",
      "epoch 106; iter: 0; batch classifier loss: 0.047569; batch adversarial loss: 0.569249\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037734; batch adversarial loss: 0.443607\n",
      "epoch 108; iter: 0; batch classifier loss: 0.014795; batch adversarial loss: 0.531541\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039900; batch adversarial loss: 0.436856\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063666; batch adversarial loss: 0.496545\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047278; batch adversarial loss: 0.442296\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031190; batch adversarial loss: 0.430779\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042767; batch adversarial loss: 0.484653\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047687; batch adversarial loss: 0.471122\n",
      "epoch 115; iter: 0; batch classifier loss: 0.104406; batch adversarial loss: 0.407438\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025664; batch adversarial loss: 0.455524\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026740; batch adversarial loss: 0.378679\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043888; batch adversarial loss: 0.492753\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031085; batch adversarial loss: 0.457155\n",
      "epoch 120; iter: 0; batch classifier loss: 0.026700; batch adversarial loss: 0.459033\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032357; batch adversarial loss: 0.482202\n",
      "epoch 122; iter: 0; batch classifier loss: 0.029476; batch adversarial loss: 0.455694\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041731; batch adversarial loss: 0.410660\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045469; batch adversarial loss: 0.438308\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035619; batch adversarial loss: 0.460923\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038188; batch adversarial loss: 0.433563\n",
      "epoch 127; iter: 0; batch classifier loss: 0.029520; batch adversarial loss: 0.479662\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040442; batch adversarial loss: 0.401037\n",
      "epoch 129; iter: 0; batch classifier loss: 0.016016; batch adversarial loss: 0.476368\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050995; batch adversarial loss: 0.442956\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031269; batch adversarial loss: 0.467804\n",
      "epoch 132; iter: 0; batch classifier loss: 0.031921; batch adversarial loss: 0.555011\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032969; batch adversarial loss: 0.520498\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034041; batch adversarial loss: 0.504045\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011010; batch adversarial loss: 0.405888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 136; iter: 0; batch classifier loss: 0.039362; batch adversarial loss: 0.408566\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023521; batch adversarial loss: 0.469487\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029886; batch adversarial loss: 0.535877\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.446608\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027813; batch adversarial loss: 0.476165\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037038; batch adversarial loss: 0.441105\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044981; batch adversarial loss: 0.467942\n",
      "epoch 143; iter: 0; batch classifier loss: 0.022035; batch adversarial loss: 0.465951\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029351; batch adversarial loss: 0.451489\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025087; batch adversarial loss: 0.422907\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028461; batch adversarial loss: 0.460951\n",
      "epoch 147; iter: 0; batch classifier loss: 0.060648; batch adversarial loss: 0.426863\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042047; batch adversarial loss: 0.385716\n",
      "epoch 149; iter: 0; batch classifier loss: 0.021622; batch adversarial loss: 0.414809\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029159; batch adversarial loss: 0.464211\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023419; batch adversarial loss: 0.361520\n",
      "epoch 152; iter: 0; batch classifier loss: 0.031719; batch adversarial loss: 0.526187\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035756; batch adversarial loss: 0.420597\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011806; batch adversarial loss: 0.474425\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012445; batch adversarial loss: 0.452637\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030538; batch adversarial loss: 0.548710\n",
      "epoch 157; iter: 0; batch classifier loss: 0.059869; batch adversarial loss: 0.434446\n",
      "epoch 158; iter: 0; batch classifier loss: 0.022484; batch adversarial loss: 0.430998\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016987; batch adversarial loss: 0.502109\n",
      "epoch 160; iter: 0; batch classifier loss: 0.013639; batch adversarial loss: 0.517131\n",
      "epoch 161; iter: 0; batch classifier loss: 0.012336; batch adversarial loss: 0.490684\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016683; batch adversarial loss: 0.341513\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013416; batch adversarial loss: 0.469703\n",
      "epoch 164; iter: 0; batch classifier loss: 0.018672; batch adversarial loss: 0.631689\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016910; batch adversarial loss: 0.430457\n",
      "epoch 166; iter: 0; batch classifier loss: 0.019989; batch adversarial loss: 0.421564\n",
      "epoch 167; iter: 0; batch classifier loss: 0.045216; batch adversarial loss: 0.490011\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029114; batch adversarial loss: 0.487801\n",
      "epoch 169; iter: 0; batch classifier loss: 0.009325; batch adversarial loss: 0.459151\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031060; batch adversarial loss: 0.469782\n",
      "epoch 171; iter: 0; batch classifier loss: 0.015575; batch adversarial loss: 0.450826\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020080; batch adversarial loss: 0.421474\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033585; batch adversarial loss: 0.456740\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042719; batch adversarial loss: 0.442243\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007114; batch adversarial loss: 0.386340\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025128; batch adversarial loss: 0.497150\n",
      "epoch 177; iter: 0; batch classifier loss: 0.002245; batch adversarial loss: 0.523847\n",
      "epoch 178; iter: 0; batch classifier loss: 0.006422; batch adversarial loss: 0.485777\n",
      "epoch 179; iter: 0; batch classifier loss: 0.024730; batch adversarial loss: 0.350477\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030981; batch adversarial loss: 0.580451\n",
      "epoch 181; iter: 0; batch classifier loss: 0.045623; batch adversarial loss: 0.433503\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011025; batch adversarial loss: 0.415283\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017629; batch adversarial loss: 0.452833\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021373; batch adversarial loss: 0.490748\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010274; batch adversarial loss: 0.494766\n",
      "epoch 186; iter: 0; batch classifier loss: 0.033092; batch adversarial loss: 0.473855\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014073; batch adversarial loss: 0.439646\n",
      "epoch 188; iter: 0; batch classifier loss: 0.030938; batch adversarial loss: 0.460115\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012124; batch adversarial loss: 0.446456\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010455; batch adversarial loss: 0.500168\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018693; batch adversarial loss: 0.379561\n",
      "epoch 192; iter: 0; batch classifier loss: 0.004207; batch adversarial loss: 0.416362\n",
      "epoch 193; iter: 0; batch classifier loss: 0.007449; batch adversarial loss: 0.459880\n",
      "epoch 194; iter: 0; batch classifier loss: 0.005865; batch adversarial loss: 0.485020\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018781; batch adversarial loss: 0.635494\n",
      "epoch 196; iter: 0; batch classifier loss: 0.018993; batch adversarial loss: 0.568966\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009840; batch adversarial loss: 0.448323\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037452; batch adversarial loss: 0.441474\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029274; batch adversarial loss: 0.427175\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683246; batch adversarial loss: 0.839719\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423788; batch adversarial loss: 0.860611\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391010; batch adversarial loss: 0.762263\n",
      "epoch 3; iter: 0; batch classifier loss: 0.298559; batch adversarial loss: 0.726785\n",
      "epoch 4; iter: 0; batch classifier loss: 0.408630; batch adversarial loss: 0.688287\n",
      "epoch 5; iter: 0; batch classifier loss: 0.312354; batch adversarial loss: 0.651934\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314440; batch adversarial loss: 0.633007\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326551; batch adversarial loss: 0.623826\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281680; batch adversarial loss: 0.604957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.351380; batch adversarial loss: 0.561680\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307106; batch adversarial loss: 0.533354\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315802; batch adversarial loss: 0.520070\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264680; batch adversarial loss: 0.475583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.254023; batch adversarial loss: 0.471182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.282882; batch adversarial loss: 0.438981\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302955; batch adversarial loss: 0.410341\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279939; batch adversarial loss: 0.444815\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233663; batch adversarial loss: 0.396958\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241764; batch adversarial loss: 0.412011\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258714; batch adversarial loss: 0.465473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282102; batch adversarial loss: 0.386465\n",
      "epoch 21; iter: 0; batch classifier loss: 0.284841; batch adversarial loss: 0.346637\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286718; batch adversarial loss: 0.386864\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261654; batch adversarial loss: 0.374459\n",
      "epoch 24; iter: 0; batch classifier loss: 0.165042; batch adversarial loss: 0.393332\n",
      "epoch 25; iter: 0; batch classifier loss: 0.240689; batch adversarial loss: 0.346589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.204955; batch adversarial loss: 0.373272\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154538; batch adversarial loss: 0.358887\n",
      "epoch 28; iter: 0; batch classifier loss: 0.166602; batch adversarial loss: 0.369442\n",
      "epoch 29; iter: 0; batch classifier loss: 0.216566; batch adversarial loss: 0.381330\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172083; batch adversarial loss: 0.382003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160342; batch adversarial loss: 0.367519\n",
      "epoch 32; iter: 0; batch classifier loss: 0.186754; batch adversarial loss: 0.434354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.200356; batch adversarial loss: 0.433216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.118073; batch adversarial loss: 0.383529\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138353; batch adversarial loss: 0.496272\n",
      "epoch 36; iter: 0; batch classifier loss: 0.148837; batch adversarial loss: 0.433467\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187081; batch adversarial loss: 0.411412\n",
      "epoch 38; iter: 0; batch classifier loss: 0.151747; batch adversarial loss: 0.331884\n",
      "epoch 39; iter: 0; batch classifier loss: 0.134305; batch adversarial loss: 0.394818\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134721; batch adversarial loss: 0.346863\n",
      "epoch 41; iter: 0; batch classifier loss: 0.156731; batch adversarial loss: 0.404974\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106507; batch adversarial loss: 0.427138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.127737; batch adversarial loss: 0.446282\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144106; batch adversarial loss: 0.382709\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101167; batch adversarial loss: 0.402714\n",
      "epoch 46; iter: 0; batch classifier loss: 0.124393; batch adversarial loss: 0.395505\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106613; batch adversarial loss: 0.465056\n",
      "epoch 48; iter: 0; batch classifier loss: 0.107761; batch adversarial loss: 0.377426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.090063; batch adversarial loss: 0.381286\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085076; batch adversarial loss: 0.379840\n",
      "epoch 51; iter: 0; batch classifier loss: 0.103551; batch adversarial loss: 0.349195\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072540; batch adversarial loss: 0.390457\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094440; batch adversarial loss: 0.408026\n",
      "epoch 54; iter: 0; batch classifier loss: 0.143530; batch adversarial loss: 0.384876\n",
      "epoch 55; iter: 0; batch classifier loss: 0.108380; batch adversarial loss: 0.365386\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094007; batch adversarial loss: 0.374238\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097938; batch adversarial loss: 0.345785\n",
      "epoch 58; iter: 0; batch classifier loss: 0.113688; batch adversarial loss: 0.394731\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077179; batch adversarial loss: 0.390392\n",
      "epoch 60; iter: 0; batch classifier loss: 0.052555; batch adversarial loss: 0.432453\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064387; batch adversarial loss: 0.289302\n",
      "epoch 62; iter: 0; batch classifier loss: 0.127921; batch adversarial loss: 0.471895\n",
      "epoch 63; iter: 0; batch classifier loss: 0.094679; batch adversarial loss: 0.427093\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084390; batch adversarial loss: 0.403825\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092576; batch adversarial loss: 0.423034\n",
      "epoch 66; iter: 0; batch classifier loss: 0.079978; batch adversarial loss: 0.509064\n",
      "epoch 67; iter: 0; batch classifier loss: 0.111901; batch adversarial loss: 0.305755\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071779; batch adversarial loss: 0.497491\n",
      "epoch 69; iter: 0; batch classifier loss: 0.110562; batch adversarial loss: 0.413016\n",
      "epoch 70; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.421499\n",
      "epoch 71; iter: 0; batch classifier loss: 0.067105; batch adversarial loss: 0.518927\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080828; batch adversarial loss: 0.401818\n",
      "epoch 73; iter: 0; batch classifier loss: 0.071761; batch adversarial loss: 0.364750\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063802; batch adversarial loss: 0.510919\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073803; batch adversarial loss: 0.395804\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055952; batch adversarial loss: 0.351215\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072041; batch adversarial loss: 0.336389\n",
      "epoch 78; iter: 0; batch classifier loss: 0.048893; batch adversarial loss: 0.371229\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060291; batch adversarial loss: 0.463082\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083748; batch adversarial loss: 0.397321\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044230; batch adversarial loss: 0.435275\n",
      "epoch 82; iter: 0; batch classifier loss: 0.047221; batch adversarial loss: 0.430512\n",
      "epoch 83; iter: 0; batch classifier loss: 0.091962; batch adversarial loss: 0.433865\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039897; batch adversarial loss: 0.467310\n",
      "epoch 85; iter: 0; batch classifier loss: 0.056048; batch adversarial loss: 0.418598\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052711; batch adversarial loss: 0.409634\n",
      "epoch 87; iter: 0; batch classifier loss: 0.053157; batch adversarial loss: 0.404934\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054011; batch adversarial loss: 0.390381\n",
      "epoch 89; iter: 0; batch classifier loss: 0.055024; batch adversarial loss: 0.399401\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042539; batch adversarial loss: 0.397098\n",
      "epoch 91; iter: 0; batch classifier loss: 0.050558; batch adversarial loss: 0.460918\n",
      "epoch 92; iter: 0; batch classifier loss: 0.062481; batch adversarial loss: 0.418051\n",
      "epoch 93; iter: 0; batch classifier loss: 0.020463; batch adversarial loss: 0.413503\n",
      "epoch 94; iter: 0; batch classifier loss: 0.036935; batch adversarial loss: 0.401211\n",
      "epoch 95; iter: 0; batch classifier loss: 0.030088; batch adversarial loss: 0.420592\n",
      "epoch 96; iter: 0; batch classifier loss: 0.058749; batch adversarial loss: 0.442082\n",
      "epoch 97; iter: 0; batch classifier loss: 0.044166; batch adversarial loss: 0.471749\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030554; batch adversarial loss: 0.439205\n",
      "epoch 99; iter: 0; batch classifier loss: 0.035285; batch adversarial loss: 0.426352\n",
      "epoch 100; iter: 0; batch classifier loss: 0.027307; batch adversarial loss: 0.426741\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031783; batch adversarial loss: 0.427389\n",
      "epoch 102; iter: 0; batch classifier loss: 0.041037; batch adversarial loss: 0.521585\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039508; batch adversarial loss: 0.355104\n",
      "epoch 104; iter: 0; batch classifier loss: 0.047757; batch adversarial loss: 0.546807\n",
      "epoch 105; iter: 0; batch classifier loss: 0.044176; batch adversarial loss: 0.415161\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043845; batch adversarial loss: 0.480373\n",
      "epoch 107; iter: 0; batch classifier loss: 0.048510; batch adversarial loss: 0.413853\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053410; batch adversarial loss: 0.439127\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031128; batch adversarial loss: 0.420531\n",
      "epoch 110; iter: 0; batch classifier loss: 0.091188; batch adversarial loss: 0.502670\n",
      "epoch 111; iter: 0; batch classifier loss: 0.074225; batch adversarial loss: 0.544861\n",
      "epoch 112; iter: 0; batch classifier loss: 0.092992; batch adversarial loss: 0.553856\n",
      "epoch 113; iter: 0; batch classifier loss: 0.111429; batch adversarial loss: 0.623583\n",
      "epoch 114; iter: 0; batch classifier loss: 0.134145; batch adversarial loss: 0.591319\n",
      "epoch 115; iter: 0; batch classifier loss: 0.096009; batch adversarial loss: 0.593390\n",
      "epoch 116; iter: 0; batch classifier loss: 0.100882; batch adversarial loss: 0.568758\n",
      "epoch 117; iter: 0; batch classifier loss: 0.106515; batch adversarial loss: 0.562206\n",
      "epoch 118; iter: 0; batch classifier loss: 0.134305; batch adversarial loss: 0.519983\n",
      "epoch 119; iter: 0; batch classifier loss: 0.120559; batch adversarial loss: 0.545200\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083070; batch adversarial loss: 0.558955\n",
      "epoch 121; iter: 0; batch classifier loss: 0.116409; batch adversarial loss: 0.598582\n",
      "epoch 122; iter: 0; batch classifier loss: 0.164391; batch adversarial loss: 0.590073\n",
      "epoch 123; iter: 0; batch classifier loss: 0.144022; batch adversarial loss: 0.653674\n",
      "epoch 124; iter: 0; batch classifier loss: 0.149326; batch adversarial loss: 0.648547\n",
      "epoch 125; iter: 0; batch classifier loss: 0.206069; batch adversarial loss: 0.635190\n",
      "epoch 126; iter: 0; batch classifier loss: 0.144639; batch adversarial loss: 0.518392\n",
      "epoch 127; iter: 0; batch classifier loss: 0.169374; batch adversarial loss: 0.572166\n",
      "epoch 128; iter: 0; batch classifier loss: 0.135487; batch adversarial loss: 0.574159\n",
      "epoch 129; iter: 0; batch classifier loss: 0.169748; batch adversarial loss: 0.486432\n",
      "epoch 130; iter: 0; batch classifier loss: 0.118137; batch adversarial loss: 0.409988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 131; iter: 0; batch classifier loss: 0.131086; batch adversarial loss: 0.490310\n",
      "epoch 132; iter: 0; batch classifier loss: 0.140104; batch adversarial loss: 0.560145\n",
      "epoch 133; iter: 0; batch classifier loss: 0.141639; batch adversarial loss: 0.529160\n",
      "epoch 134; iter: 0; batch classifier loss: 0.102359; batch adversarial loss: 0.476145\n",
      "epoch 135; iter: 0; batch classifier loss: 0.128097; batch adversarial loss: 0.505492\n",
      "epoch 136; iter: 0; batch classifier loss: 0.126324; batch adversarial loss: 0.589539\n",
      "epoch 137; iter: 0; batch classifier loss: 0.097984; batch adversarial loss: 0.488888\n",
      "epoch 138; iter: 0; batch classifier loss: 0.100129; batch adversarial loss: 0.474951\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057026; batch adversarial loss: 0.373263\n",
      "epoch 140; iter: 0; batch classifier loss: 0.126928; batch adversarial loss: 0.458712\n",
      "epoch 141; iter: 0; batch classifier loss: 0.052970; batch adversarial loss: 0.370076\n",
      "epoch 142; iter: 0; batch classifier loss: 0.170698; batch adversarial loss: 0.590511\n",
      "epoch 143; iter: 0; batch classifier loss: 0.115673; batch adversarial loss: 0.457549\n",
      "epoch 144; iter: 0; batch classifier loss: 0.092766; batch adversarial loss: 0.467184\n",
      "epoch 145; iter: 0; batch classifier loss: 0.091275; batch adversarial loss: 0.451691\n",
      "epoch 146; iter: 0; batch classifier loss: 0.139336; batch adversarial loss: 0.561512\n",
      "epoch 147; iter: 0; batch classifier loss: 0.089380; batch adversarial loss: 0.470873\n",
      "epoch 148; iter: 0; batch classifier loss: 0.127066; batch adversarial loss: 0.456492\n",
      "epoch 149; iter: 0; batch classifier loss: 0.046555; batch adversarial loss: 0.470538\n",
      "epoch 150; iter: 0; batch classifier loss: 0.040700; batch adversarial loss: 0.476163\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024160; batch adversarial loss: 0.455710\n",
      "epoch 152; iter: 0; batch classifier loss: 0.068444; batch adversarial loss: 0.486005\n",
      "epoch 153; iter: 0; batch classifier loss: 0.058290; batch adversarial loss: 0.409247\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023426; batch adversarial loss: 0.416714\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018517; batch adversarial loss: 0.499604\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035259; batch adversarial loss: 0.325382\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046935; batch adversarial loss: 0.469458\n",
      "epoch 158; iter: 0; batch classifier loss: 0.037972; batch adversarial loss: 0.441928\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041946; batch adversarial loss: 0.349200\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030906; batch adversarial loss: 0.413637\n",
      "epoch 161; iter: 0; batch classifier loss: 0.107969; batch adversarial loss: 0.425350\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027957; batch adversarial loss: 0.467476\n",
      "epoch 163; iter: 0; batch classifier loss: 0.068401; batch adversarial loss: 0.497544\n",
      "epoch 164; iter: 0; batch classifier loss: 0.086369; batch adversarial loss: 0.365587\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030730; batch adversarial loss: 0.404995\n",
      "epoch 166; iter: 0; batch classifier loss: 0.044005; batch adversarial loss: 0.428955\n",
      "epoch 167; iter: 0; batch classifier loss: 0.057215; batch adversarial loss: 0.519499\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035864; batch adversarial loss: 0.517308\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043156; batch adversarial loss: 0.420367\n",
      "epoch 170; iter: 0; batch classifier loss: 0.047635; batch adversarial loss: 0.453791\n",
      "epoch 171; iter: 0; batch classifier loss: 0.052455; batch adversarial loss: 0.348234\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019154; batch adversarial loss: 0.454818\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032786; batch adversarial loss: 0.445992\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039909; batch adversarial loss: 0.457603\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038200; batch adversarial loss: 0.396377\n",
      "epoch 176; iter: 0; batch classifier loss: 0.081713; batch adversarial loss: 0.374154\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041701; batch adversarial loss: 0.381475\n",
      "epoch 178; iter: 0; batch classifier loss: 0.093280; batch adversarial loss: 0.371145\n",
      "epoch 179; iter: 0; batch classifier loss: 0.048734; batch adversarial loss: 0.432983\n",
      "epoch 180; iter: 0; batch classifier loss: 0.053784; batch adversarial loss: 0.447470\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029944; batch adversarial loss: 0.468877\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034503; batch adversarial loss: 0.492388\n",
      "epoch 183; iter: 0; batch classifier loss: 0.087739; batch adversarial loss: 0.489623\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050217; batch adversarial loss: 0.362540\n",
      "epoch 185; iter: 0; batch classifier loss: 0.082315; batch adversarial loss: 0.480737\n",
      "epoch 186; iter: 0; batch classifier loss: 0.070016; batch adversarial loss: 0.436187\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024733; batch adversarial loss: 0.394541\n",
      "epoch 188; iter: 0; batch classifier loss: 0.071769; batch adversarial loss: 0.441210\n",
      "epoch 189; iter: 0; batch classifier loss: 0.080087; batch adversarial loss: 0.414290\n",
      "epoch 190; iter: 0; batch classifier loss: 0.080970; batch adversarial loss: 0.531733\n",
      "epoch 191; iter: 0; batch classifier loss: 0.082050; batch adversarial loss: 0.375160\n",
      "epoch 192; iter: 0; batch classifier loss: 0.031401; batch adversarial loss: 0.471658\n",
      "epoch 193; iter: 0; batch classifier loss: 0.048006; batch adversarial loss: 0.420056\n",
      "epoch 194; iter: 0; batch classifier loss: 0.052854; batch adversarial loss: 0.411057\n",
      "epoch 195; iter: 0; batch classifier loss: 0.081937; batch adversarial loss: 0.433322\n",
      "epoch 196; iter: 0; batch classifier loss: 0.085780; batch adversarial loss: 0.403800\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033366; batch adversarial loss: 0.437137\n",
      "epoch 198; iter: 0; batch classifier loss: 0.043765; batch adversarial loss: 0.376728\n",
      "epoch 199; iter: 0; batch classifier loss: 0.058322; batch adversarial loss: 0.569043\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669238; batch adversarial loss: 0.766048\n",
      "epoch 1; iter: 0; batch classifier loss: 0.418896; batch adversarial loss: 0.764725\n",
      "epoch 2; iter: 0; batch classifier loss: 0.398005; batch adversarial loss: 0.705118\n",
      "epoch 3; iter: 0; batch classifier loss: 0.307566; batch adversarial loss: 0.671301\n",
      "epoch 4; iter: 0; batch classifier loss: 0.436345; batch adversarial loss: 0.632892\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368468; batch adversarial loss: 0.626338\n",
      "epoch 6; iter: 0; batch classifier loss: 0.336452; batch adversarial loss: 0.588218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354364; batch adversarial loss: 0.554521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285835; batch adversarial loss: 0.503825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284735; batch adversarial loss: 0.504923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317267; batch adversarial loss: 0.471353\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312208; batch adversarial loss: 0.431257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299561; batch adversarial loss: 0.428279\n",
      "epoch 13; iter: 0; batch classifier loss: 0.202718; batch adversarial loss: 0.462246\n",
      "epoch 14; iter: 0; batch classifier loss: 0.231383; batch adversarial loss: 0.477478\n",
      "epoch 15; iter: 0; batch classifier loss: 0.235792; batch adversarial loss: 0.465252\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228497; batch adversarial loss: 0.444634\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192782; batch adversarial loss: 0.391508\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186382; batch adversarial loss: 0.415405\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228119; batch adversarial loss: 0.444664\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178829; batch adversarial loss: 0.439057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272881; batch adversarial loss: 0.494519\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163185; batch adversarial loss: 0.477558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164351; batch adversarial loss: 0.423175\n",
      "epoch 24; iter: 0; batch classifier loss: 0.201043; batch adversarial loss: 0.488487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.153469; batch adversarial loss: 0.336076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134411; batch adversarial loss: 0.406178\n",
      "epoch 27; iter: 0; batch classifier loss: 0.154233; batch adversarial loss: 0.383383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.169988; batch adversarial loss: 0.324917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.176896; batch adversarial loss: 0.378382\n",
      "epoch 30; iter: 0; batch classifier loss: 0.151642; batch adversarial loss: 0.287678\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166348; batch adversarial loss: 0.504396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.122329; batch adversarial loss: 0.486081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159075; batch adversarial loss: 0.465546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104524; batch adversarial loss: 0.429811\n",
      "epoch 35; iter: 0; batch classifier loss: 0.138390; batch adversarial loss: 0.347382\n",
      "epoch 36; iter: 0; batch classifier loss: 0.125713; batch adversarial loss: 0.370890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116965; batch adversarial loss: 0.410362\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123443; batch adversarial loss: 0.457457\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094032; batch adversarial loss: 0.387476\n",
      "epoch 40; iter: 0; batch classifier loss: 0.128037; batch adversarial loss: 0.436810\n",
      "epoch 41; iter: 0; batch classifier loss: 0.097238; batch adversarial loss: 0.348462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088779; batch adversarial loss: 0.447432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.114349; batch adversarial loss: 0.333303\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125893; batch adversarial loss: 0.394770\n",
      "epoch 45; iter: 0; batch classifier loss: 0.173273; batch adversarial loss: 0.428521\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106162; batch adversarial loss: 0.426387\n",
      "epoch 47; iter: 0; batch classifier loss: 0.075158; batch adversarial loss: 0.367429\n",
      "epoch 48; iter: 0; batch classifier loss: 0.102075; batch adversarial loss: 0.441288\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113803; batch adversarial loss: 0.422648\n",
      "epoch 50; iter: 0; batch classifier loss: 0.112246; batch adversarial loss: 0.395419\n",
      "epoch 51; iter: 0; batch classifier loss: 0.138492; batch adversarial loss: 0.402150\n",
      "epoch 52; iter: 0; batch classifier loss: 0.106092; batch adversarial loss: 0.426685\n",
      "epoch 53; iter: 0; batch classifier loss: 0.136728; batch adversarial loss: 0.440139\n",
      "epoch 54; iter: 0; batch classifier loss: 0.064062; batch adversarial loss: 0.400897\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086709; batch adversarial loss: 0.458159\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095896; batch adversarial loss: 0.465282\n",
      "epoch 57; iter: 0; batch classifier loss: 0.093941; batch adversarial loss: 0.419727\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064378; batch adversarial loss: 0.513391\n",
      "epoch 59; iter: 0; batch classifier loss: 0.141129; batch adversarial loss: 0.347868\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064650; batch adversarial loss: 0.384999\n",
      "epoch 61; iter: 0; batch classifier loss: 0.131236; batch adversarial loss: 0.491801\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081509; batch adversarial loss: 0.401580\n",
      "epoch 63; iter: 0; batch classifier loss: 0.063593; batch adversarial loss: 0.410967\n",
      "epoch 64; iter: 0; batch classifier loss: 0.087900; batch adversarial loss: 0.387001\n",
      "epoch 65; iter: 0; batch classifier loss: 0.111979; batch adversarial loss: 0.365534\n",
      "epoch 66; iter: 0; batch classifier loss: 0.107917; batch adversarial loss: 0.483837\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056290; batch adversarial loss: 0.430559\n",
      "epoch 68; iter: 0; batch classifier loss: 0.083881; batch adversarial loss: 0.417975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.085910; batch adversarial loss: 0.316515\n",
      "epoch 70; iter: 0; batch classifier loss: 0.061611; batch adversarial loss: 0.452817\n",
      "epoch 71; iter: 0; batch classifier loss: 0.066189; batch adversarial loss: 0.384992\n",
      "epoch 72; iter: 0; batch classifier loss: 0.062721; batch adversarial loss: 0.377390\n",
      "epoch 73; iter: 0; batch classifier loss: 0.066046; batch adversarial loss: 0.437363\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075118; batch adversarial loss: 0.490927\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063342; batch adversarial loss: 0.414394\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078776; batch adversarial loss: 0.513874\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067791; batch adversarial loss: 0.332285\n",
      "epoch 78; iter: 0; batch classifier loss: 0.071923; batch adversarial loss: 0.431859\n",
      "epoch 79; iter: 0; batch classifier loss: 0.150916; batch adversarial loss: 0.374304\n",
      "epoch 80; iter: 0; batch classifier loss: 0.114718; batch adversarial loss: 0.469697\n",
      "epoch 81; iter: 0; batch classifier loss: 0.125205; batch adversarial loss: 0.471775\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066800; batch adversarial loss: 0.423213\n",
      "epoch 83; iter: 0; batch classifier loss: 0.076628; batch adversarial loss: 0.462275\n",
      "epoch 84; iter: 0; batch classifier loss: 0.063618; batch adversarial loss: 0.424043\n",
      "epoch 85; iter: 0; batch classifier loss: 0.054612; batch adversarial loss: 0.437188\n",
      "epoch 86; iter: 0; batch classifier loss: 0.109157; batch adversarial loss: 0.478788\n",
      "epoch 87; iter: 0; batch classifier loss: 0.081365; batch adversarial loss: 0.465336\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062176; batch adversarial loss: 0.459086\n",
      "epoch 89; iter: 0; batch classifier loss: 0.062633; batch adversarial loss: 0.424683\n",
      "epoch 90; iter: 0; batch classifier loss: 0.056384; batch adversarial loss: 0.440749\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040117; batch adversarial loss: 0.427465\n",
      "epoch 92; iter: 0; batch classifier loss: 0.048650; batch adversarial loss: 0.452309\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079708; batch adversarial loss: 0.376465\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049963; batch adversarial loss: 0.417028\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066615; batch adversarial loss: 0.445164\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066501; batch adversarial loss: 0.354476\n",
      "epoch 97; iter: 0; batch classifier loss: 0.045015; batch adversarial loss: 0.433333\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059837; batch adversarial loss: 0.440553\n",
      "epoch 99; iter: 0; batch classifier loss: 0.058443; batch adversarial loss: 0.431746\n",
      "epoch 100; iter: 0; batch classifier loss: 0.048953; batch adversarial loss: 0.425949\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085582; batch adversarial loss: 0.359148\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059154; batch adversarial loss: 0.411107\n",
      "epoch 103; iter: 0; batch classifier loss: 0.101034; batch adversarial loss: 0.353611\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095699; batch adversarial loss: 0.435857\n",
      "epoch 105; iter: 0; batch classifier loss: 0.053470; batch adversarial loss: 0.331131\n",
      "epoch 106; iter: 0; batch classifier loss: 0.076886; batch adversarial loss: 0.536564\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044593; batch adversarial loss: 0.377566\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056477; batch adversarial loss: 0.454227\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053029; batch adversarial loss: 0.390360\n",
      "epoch 110; iter: 0; batch classifier loss: 0.069005; batch adversarial loss: 0.315723\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050116; batch adversarial loss: 0.395112\n",
      "epoch 112; iter: 0; batch classifier loss: 0.053137; batch adversarial loss: 0.442220\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038584; batch adversarial loss: 0.362653\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041005; batch adversarial loss: 0.422889\n",
      "epoch 115; iter: 0; batch classifier loss: 0.051243; batch adversarial loss: 0.405666\n",
      "epoch 116; iter: 0; batch classifier loss: 0.032319; batch adversarial loss: 0.407081\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032831; batch adversarial loss: 0.362683\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042793; batch adversarial loss: 0.438343\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027768; batch adversarial loss: 0.348235\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039927; batch adversarial loss: 0.282232\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068538; batch adversarial loss: 0.435186\n",
      "epoch 122; iter: 0; batch classifier loss: 0.051122; batch adversarial loss: 0.478256\n",
      "epoch 123; iter: 0; batch classifier loss: 0.026409; batch adversarial loss: 0.431040\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036612; batch adversarial loss: 0.372668\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037225; batch adversarial loss: 0.448061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 126; iter: 0; batch classifier loss: 0.025223; batch adversarial loss: 0.461684\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021944; batch adversarial loss: 0.475834\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034567; batch adversarial loss: 0.443964\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031886; batch adversarial loss: 0.433812\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053999; batch adversarial loss: 0.429602\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026078; batch adversarial loss: 0.460821\n",
      "epoch 132; iter: 0; batch classifier loss: 0.032583; batch adversarial loss: 0.407613\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029661; batch adversarial loss: 0.439902\n",
      "epoch 134; iter: 0; batch classifier loss: 0.039900; batch adversarial loss: 0.425385\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037392; batch adversarial loss: 0.411978\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049471; batch adversarial loss: 0.462597\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.464945\n",
      "epoch 138; iter: 0; batch classifier loss: 0.123529; batch adversarial loss: 0.728332\n",
      "epoch 139; iter: 0; batch classifier loss: 0.046422; batch adversarial loss: 0.461495\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053478; batch adversarial loss: 0.532396\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045048; batch adversarial loss: 0.476133\n",
      "epoch 142; iter: 0; batch classifier loss: 0.085348; batch adversarial loss: 0.600754\n",
      "epoch 143; iter: 0; batch classifier loss: 0.040916; batch adversarial loss: 0.502084\n",
      "epoch 144; iter: 0; batch classifier loss: 0.088896; batch adversarial loss: 0.598893\n",
      "epoch 145; iter: 0; batch classifier loss: 0.111121; batch adversarial loss: 0.722402\n",
      "epoch 146; iter: 0; batch classifier loss: 0.184399; batch adversarial loss: 0.790975\n",
      "epoch 147; iter: 0; batch classifier loss: 0.098220; batch adversarial loss: 0.617738\n",
      "epoch 148; iter: 0; batch classifier loss: 0.137550; batch adversarial loss: 0.527740\n",
      "epoch 149; iter: 0; batch classifier loss: 0.136409; batch adversarial loss: 0.624399\n",
      "epoch 150; iter: 0; batch classifier loss: 0.186915; batch adversarial loss: 0.775019\n",
      "epoch 151; iter: 0; batch classifier loss: 0.091487; batch adversarial loss: 0.558751\n",
      "epoch 152; iter: 0; batch classifier loss: 0.200079; batch adversarial loss: 0.674193\n",
      "epoch 153; iter: 0; batch classifier loss: 0.087660; batch adversarial loss: 0.570166\n",
      "epoch 154; iter: 0; batch classifier loss: 0.177491; batch adversarial loss: 0.627553\n",
      "epoch 155; iter: 0; batch classifier loss: 0.104532; batch adversarial loss: 0.570747\n",
      "epoch 156; iter: 0; batch classifier loss: 0.105671; batch adversarial loss: 0.522737\n",
      "epoch 157; iter: 0; batch classifier loss: 0.064167; batch adversarial loss: 0.483951\n",
      "epoch 158; iter: 0; batch classifier loss: 0.164872; batch adversarial loss: 0.636668\n",
      "epoch 159; iter: 0; batch classifier loss: 0.125150; batch adversarial loss: 0.602000\n",
      "epoch 160; iter: 0; batch classifier loss: 0.135019; batch adversarial loss: 0.643820\n",
      "epoch 161; iter: 0; batch classifier loss: 0.090744; batch adversarial loss: 0.518970\n",
      "epoch 162; iter: 0; batch classifier loss: 0.119328; batch adversarial loss: 0.492011\n",
      "epoch 163; iter: 0; batch classifier loss: 0.187548; batch adversarial loss: 0.639924\n",
      "epoch 164; iter: 0; batch classifier loss: 0.106941; batch adversarial loss: 0.548933\n",
      "epoch 165; iter: 0; batch classifier loss: 0.170916; batch adversarial loss: 0.584716\n",
      "epoch 166; iter: 0; batch classifier loss: 0.168299; batch adversarial loss: 0.492890\n",
      "epoch 167; iter: 0; batch classifier loss: 0.166266; batch adversarial loss: 0.687695\n",
      "epoch 168; iter: 0; batch classifier loss: 0.124723; batch adversarial loss: 0.503517\n",
      "epoch 169; iter: 0; batch classifier loss: 0.108070; batch adversarial loss: 0.525468\n",
      "epoch 170; iter: 0; batch classifier loss: 0.143225; batch adversarial loss: 0.557088\n",
      "epoch 171; iter: 0; batch classifier loss: 0.132668; batch adversarial loss: 0.478784\n",
      "epoch 172; iter: 0; batch classifier loss: 0.151367; batch adversarial loss: 0.553169\n",
      "epoch 173; iter: 0; batch classifier loss: 0.164618; batch adversarial loss: 0.581830\n",
      "epoch 174; iter: 0; batch classifier loss: 0.136741; batch adversarial loss: 0.507789\n",
      "epoch 175; iter: 0; batch classifier loss: 0.108289; batch adversarial loss: 0.477080\n",
      "epoch 176; iter: 0; batch classifier loss: 0.165119; batch adversarial loss: 0.543965\n",
      "epoch 177; iter: 0; batch classifier loss: 0.131169; batch adversarial loss: 0.468008\n",
      "epoch 178; iter: 0; batch classifier loss: 0.117286; batch adversarial loss: 0.470814\n",
      "epoch 179; iter: 0; batch classifier loss: 0.151957; batch adversarial loss: 0.532286\n",
      "epoch 180; iter: 0; batch classifier loss: 0.108730; batch adversarial loss: 0.473139\n",
      "epoch 181; iter: 0; batch classifier loss: 0.083709; batch adversarial loss: 0.494743\n",
      "epoch 182; iter: 0; batch classifier loss: 0.081392; batch adversarial loss: 0.464717\n",
      "epoch 183; iter: 0; batch classifier loss: 0.075715; batch adversarial loss: 0.496575\n",
      "epoch 184; iter: 0; batch classifier loss: 0.088128; batch adversarial loss: 0.435221\n",
      "epoch 185; iter: 0; batch classifier loss: 0.178150; batch adversarial loss: 0.558673\n",
      "epoch 186; iter: 0; batch classifier loss: 0.128607; batch adversarial loss: 0.490162\n",
      "epoch 187; iter: 0; batch classifier loss: 0.155587; batch adversarial loss: 0.501393\n",
      "epoch 188; iter: 0; batch classifier loss: 0.118953; batch adversarial loss: 0.411807\n",
      "epoch 189; iter: 0; batch classifier loss: 0.115583; batch adversarial loss: 0.515751\n",
      "epoch 190; iter: 0; batch classifier loss: 0.043917; batch adversarial loss: 0.418355\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.482047\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025278; batch adversarial loss: 0.462334\n",
      "epoch 193; iter: 0; batch classifier loss: 0.038013; batch adversarial loss: 0.460013\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011833; batch adversarial loss: 0.468374\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026355; batch adversarial loss: 0.524164\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038963; batch adversarial loss: 0.457451\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022955; batch adversarial loss: 0.366636\n",
      "epoch 198; iter: 0; batch classifier loss: 0.023370; batch adversarial loss: 0.354984\n",
      "epoch 199; iter: 0; batch classifier loss: 0.047028; batch adversarial loss: 0.418029\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689149; batch adversarial loss: 0.850060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.419778; batch adversarial loss: 0.845423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.399962; batch adversarial loss: 0.796848\n",
      "epoch 3; iter: 0; batch classifier loss: 0.454901; batch adversarial loss: 0.761614\n",
      "epoch 4; iter: 0; batch classifier loss: 0.335791; batch adversarial loss: 0.690116\n",
      "epoch 5; iter: 0; batch classifier loss: 0.283679; batch adversarial loss: 0.632434\n",
      "epoch 6; iter: 0; batch classifier loss: 0.260260; batch adversarial loss: 0.613662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280373; batch adversarial loss: 0.567571\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253346; batch adversarial loss: 0.574189\n",
      "epoch 9; iter: 0; batch classifier loss: 0.289124; batch adversarial loss: 0.560644\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314653; batch adversarial loss: 0.547325\n",
      "epoch 11; iter: 0; batch classifier loss: 0.208571; batch adversarial loss: 0.511919\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275714; batch adversarial loss: 0.524881\n",
      "epoch 13; iter: 0; batch classifier loss: 0.181098; batch adversarial loss: 0.469445\n",
      "epoch 14; iter: 0; batch classifier loss: 0.255206; batch adversarial loss: 0.499403\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248858; batch adversarial loss: 0.478446\n",
      "epoch 16; iter: 0; batch classifier loss: 0.215820; batch adversarial loss: 0.459997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192750; batch adversarial loss: 0.467429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.166013; batch adversarial loss: 0.454080\n",
      "epoch 19; iter: 0; batch classifier loss: 0.176041; batch adversarial loss: 0.448131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189245; batch adversarial loss: 0.425386\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213577; batch adversarial loss: 0.463534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 0; batch classifier loss: 0.125057; batch adversarial loss: 0.515168\n",
      "epoch 23; iter: 0; batch classifier loss: 0.145495; batch adversarial loss: 0.424564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159360; batch adversarial loss: 0.584007\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146883; batch adversarial loss: 0.414621\n",
      "epoch 26; iter: 0; batch classifier loss: 0.143924; batch adversarial loss: 0.421033\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162370; batch adversarial loss: 0.428731\n",
      "epoch 28; iter: 0; batch classifier loss: 0.153297; batch adversarial loss: 0.362256\n",
      "epoch 29; iter: 0; batch classifier loss: 0.116685; batch adversarial loss: 0.456072\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134580; batch adversarial loss: 0.417542\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109795; batch adversarial loss: 0.412235\n",
      "epoch 32; iter: 0; batch classifier loss: 0.135971; batch adversarial loss: 0.422553\n",
      "epoch 33; iter: 0; batch classifier loss: 0.094707; batch adversarial loss: 0.467417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106578; batch adversarial loss: 0.379850\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100137; batch adversarial loss: 0.376885\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140907; batch adversarial loss: 0.337130\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133195; batch adversarial loss: 0.384548\n",
      "epoch 38; iter: 0; batch classifier loss: 0.134854; batch adversarial loss: 0.375401\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085300; batch adversarial loss: 0.356027\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157264; batch adversarial loss: 0.393791\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136747; batch adversarial loss: 0.481711\n",
      "epoch 42; iter: 0; batch classifier loss: 0.142850; batch adversarial loss: 0.509718\n",
      "epoch 43; iter: 0; batch classifier loss: 0.065307; batch adversarial loss: 0.437537\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087001; batch adversarial loss: 0.423111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.130928; batch adversarial loss: 0.326675\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069354; batch adversarial loss: 0.461173\n",
      "epoch 47; iter: 0; batch classifier loss: 0.100171; batch adversarial loss: 0.404645\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111399; batch adversarial loss: 0.354610\n",
      "epoch 49; iter: 0; batch classifier loss: 0.159265; batch adversarial loss: 0.390001\n",
      "epoch 50; iter: 0; batch classifier loss: 0.086263; batch adversarial loss: 0.433894\n",
      "epoch 51; iter: 0; batch classifier loss: 0.100757; batch adversarial loss: 0.298553\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071522; batch adversarial loss: 0.496887\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122131; batch adversarial loss: 0.393966\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079928; batch adversarial loss: 0.439237\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083440; batch adversarial loss: 0.465128\n",
      "epoch 56; iter: 0; batch classifier loss: 0.092790; batch adversarial loss: 0.372510\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088102; batch adversarial loss: 0.437926\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060585; batch adversarial loss: 0.384783\n",
      "epoch 59; iter: 0; batch classifier loss: 0.081712; batch adversarial loss: 0.441270\n",
      "epoch 60; iter: 0; batch classifier loss: 0.070950; batch adversarial loss: 0.384617\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093948; batch adversarial loss: 0.425824\n",
      "epoch 62; iter: 0; batch classifier loss: 0.073258; batch adversarial loss: 0.354778\n",
      "epoch 63; iter: 0; batch classifier loss: 0.112308; batch adversarial loss: 0.417990\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081388; batch adversarial loss: 0.355837\n",
      "epoch 65; iter: 0; batch classifier loss: 0.135746; batch adversarial loss: 0.390185\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054675; batch adversarial loss: 0.407973\n",
      "epoch 67; iter: 0; batch classifier loss: 0.089393; batch adversarial loss: 0.527414\n",
      "epoch 68; iter: 0; batch classifier loss: 0.034984; batch adversarial loss: 0.318816\n",
      "epoch 69; iter: 0; batch classifier loss: 0.086171; batch adversarial loss: 0.462344\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086252; batch adversarial loss: 0.481966\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071869; batch adversarial loss: 0.414097\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065939; batch adversarial loss: 0.431446\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084128; batch adversarial loss: 0.401049\n",
      "epoch 74; iter: 0; batch classifier loss: 0.090324; batch adversarial loss: 0.429280\n",
      "epoch 75; iter: 0; batch classifier loss: 0.067374; batch adversarial loss: 0.451002\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061360; batch adversarial loss: 0.360021\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067327; batch adversarial loss: 0.411641\n",
      "epoch 78; iter: 0; batch classifier loss: 0.055478; batch adversarial loss: 0.350162\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064356; batch adversarial loss: 0.412221\n",
      "epoch 80; iter: 0; batch classifier loss: 0.066706; batch adversarial loss: 0.444104\n",
      "epoch 81; iter: 0; batch classifier loss: 0.120222; batch adversarial loss: 0.378726\n",
      "epoch 82; iter: 0; batch classifier loss: 0.096935; batch adversarial loss: 0.460938\n",
      "epoch 83; iter: 0; batch classifier loss: 0.078655; batch adversarial loss: 0.403197\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058579; batch adversarial loss: 0.472302\n",
      "epoch 85; iter: 0; batch classifier loss: 0.060774; batch adversarial loss: 0.364315\n",
      "epoch 86; iter: 0; batch classifier loss: 0.137299; batch adversarial loss: 0.544378\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076697; batch adversarial loss: 0.371720\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077974; batch adversarial loss: 0.395866\n",
      "epoch 89; iter: 0; batch classifier loss: 0.051570; batch adversarial loss: 0.487607\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060655; batch adversarial loss: 0.461593\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.401616\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101547; batch adversarial loss: 0.370976\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056886; batch adversarial loss: 0.455420\n",
      "epoch 94; iter: 0; batch classifier loss: 0.037330; batch adversarial loss: 0.413465\n",
      "epoch 95; iter: 0; batch classifier loss: 0.044181; batch adversarial loss: 0.391463\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062996; batch adversarial loss: 0.375204\n",
      "epoch 97; iter: 0; batch classifier loss: 0.065933; batch adversarial loss: 0.457205\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074624; batch adversarial loss: 0.438961\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053481; batch adversarial loss: 0.373879\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075585; batch adversarial loss: 0.433578\n",
      "epoch 101; iter: 0; batch classifier loss: 0.038163; batch adversarial loss: 0.471686\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056588; batch adversarial loss: 0.449590\n",
      "epoch 103; iter: 0; batch classifier loss: 0.073667; batch adversarial loss: 0.456919\n",
      "epoch 104; iter: 0; batch classifier loss: 0.098531; batch adversarial loss: 0.476463\n",
      "epoch 105; iter: 0; batch classifier loss: 0.116912; batch adversarial loss: 0.417377\n",
      "epoch 106; iter: 0; batch classifier loss: 0.121147; batch adversarial loss: 0.471723\n",
      "epoch 107; iter: 0; batch classifier loss: 0.079123; batch adversarial loss: 0.485835\n",
      "epoch 108; iter: 0; batch classifier loss: 0.056642; batch adversarial loss: 0.436762\n",
      "epoch 109; iter: 0; batch classifier loss: 0.040031; batch adversarial loss: 0.358972\n",
      "epoch 110; iter: 0; batch classifier loss: 0.032595; batch adversarial loss: 0.473187\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065964; batch adversarial loss: 0.481360\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039286; batch adversarial loss: 0.472927\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058318; batch adversarial loss: 0.432782\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080763; batch adversarial loss: 0.408252\n",
      "epoch 115; iter: 0; batch classifier loss: 0.090225; batch adversarial loss: 0.450497\n",
      "epoch 116; iter: 0; batch classifier loss: 0.080712; batch adversarial loss: 0.369181\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054920; batch adversarial loss: 0.415109\n",
      "epoch 118; iter: 0; batch classifier loss: 0.042549; batch adversarial loss: 0.351499\n",
      "epoch 119; iter: 0; batch classifier loss: 0.038250; batch adversarial loss: 0.388121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 120; iter: 0; batch classifier loss: 0.056627; batch adversarial loss: 0.352514\n",
      "epoch 121; iter: 0; batch classifier loss: 0.084550; batch adversarial loss: 0.360863\n",
      "epoch 122; iter: 0; batch classifier loss: 0.073424; batch adversarial loss: 0.475441\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051860; batch adversarial loss: 0.398647\n",
      "epoch 124; iter: 0; batch classifier loss: 0.056060; batch adversarial loss: 0.416842\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036382; batch adversarial loss: 0.425908\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057321; batch adversarial loss: 0.441324\n",
      "epoch 127; iter: 0; batch classifier loss: 0.059021; batch adversarial loss: 0.437833\n",
      "epoch 128; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.479952\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041956; batch adversarial loss: 0.376247\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034276; batch adversarial loss: 0.413479\n",
      "epoch 131; iter: 0; batch classifier loss: 0.062976; batch adversarial loss: 0.487365\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059516; batch adversarial loss: 0.429478\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056662; batch adversarial loss: 0.346646\n",
      "epoch 134; iter: 0; batch classifier loss: 0.047728; batch adversarial loss: 0.446359\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050728; batch adversarial loss: 0.341840\n",
      "epoch 136; iter: 0; batch classifier loss: 0.087576; batch adversarial loss: 0.429747\n",
      "epoch 137; iter: 0; batch classifier loss: 0.040867; batch adversarial loss: 0.425457\n",
      "epoch 138; iter: 0; batch classifier loss: 0.078019; batch adversarial loss: 0.444823\n",
      "epoch 139; iter: 0; batch classifier loss: 0.076507; batch adversarial loss: 0.364019\n",
      "epoch 140; iter: 0; batch classifier loss: 0.065931; batch adversarial loss: 0.422599\n",
      "epoch 141; iter: 0; batch classifier loss: 0.048698; batch adversarial loss: 0.458319\n",
      "epoch 142; iter: 0; batch classifier loss: 0.049193; batch adversarial loss: 0.429603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.046049; batch adversarial loss: 0.395334\n",
      "epoch 144; iter: 0; batch classifier loss: 0.057255; batch adversarial loss: 0.394436\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061414; batch adversarial loss: 0.342195\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.474404\n",
      "epoch 147; iter: 0; batch classifier loss: 0.076745; batch adversarial loss: 0.423098\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035695; batch adversarial loss: 0.329002\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063457; batch adversarial loss: 0.440099\n",
      "epoch 150; iter: 0; batch classifier loss: 0.057359; batch adversarial loss: 0.416051\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031170; batch adversarial loss: 0.418439\n",
      "epoch 152; iter: 0; batch classifier loss: 0.070223; batch adversarial loss: 0.432897\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035130; batch adversarial loss: 0.352830\n",
      "epoch 154; iter: 0; batch classifier loss: 0.061001; batch adversarial loss: 0.412576\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030174; batch adversarial loss: 0.465791\n",
      "epoch 156; iter: 0; batch classifier loss: 0.035704; batch adversarial loss: 0.421170\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029798; batch adversarial loss: 0.467786\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057843; batch adversarial loss: 0.572413\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037464; batch adversarial loss: 0.479741\n",
      "epoch 160; iter: 0; batch classifier loss: 0.063801; batch adversarial loss: 0.424582\n",
      "epoch 161; iter: 0; batch classifier loss: 0.062967; batch adversarial loss: 0.384232\n",
      "epoch 162; iter: 0; batch classifier loss: 0.060576; batch adversarial loss: 0.429555\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052316; batch adversarial loss: 0.488124\n",
      "epoch 164; iter: 0; batch classifier loss: 0.044858; batch adversarial loss: 0.427660\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036337; batch adversarial loss: 0.437596\n",
      "epoch 166; iter: 0; batch classifier loss: 0.055644; batch adversarial loss: 0.299702\n",
      "epoch 167; iter: 0; batch classifier loss: 0.068705; batch adversarial loss: 0.405878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.041332; batch adversarial loss: 0.493455\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043863; batch adversarial loss: 0.484735\n",
      "epoch 170; iter: 0; batch classifier loss: 0.036828; batch adversarial loss: 0.376911\n",
      "epoch 171; iter: 0; batch classifier loss: 0.022371; batch adversarial loss: 0.427626\n",
      "epoch 172; iter: 0; batch classifier loss: 0.060875; batch adversarial loss: 0.337327\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026887; batch adversarial loss: 0.389801\n",
      "epoch 174; iter: 0; batch classifier loss: 0.042346; batch adversarial loss: 0.373420\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014549; batch adversarial loss: 0.382409\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031571; batch adversarial loss: 0.458065\n",
      "epoch 177; iter: 0; batch classifier loss: 0.038460; batch adversarial loss: 0.379627\n",
      "epoch 178; iter: 0; batch classifier loss: 0.040317; batch adversarial loss: 0.433027\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020911; batch adversarial loss: 0.373902\n",
      "epoch 180; iter: 0; batch classifier loss: 0.033148; batch adversarial loss: 0.385776\n",
      "epoch 181; iter: 0; batch classifier loss: 0.016661; batch adversarial loss: 0.461000\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033321; batch adversarial loss: 0.516121\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046812; batch adversarial loss: 0.522403\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021442; batch adversarial loss: 0.349895\n",
      "epoch 185; iter: 0; batch classifier loss: 0.019382; batch adversarial loss: 0.406969\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025888; batch adversarial loss: 0.398413\n",
      "epoch 187; iter: 0; batch classifier loss: 0.033278; batch adversarial loss: 0.480360\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022933; batch adversarial loss: 0.392675\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011355; batch adversarial loss: 0.373756\n",
      "epoch 190; iter: 0; batch classifier loss: 0.028070; batch adversarial loss: 0.478550\n",
      "epoch 191; iter: 0; batch classifier loss: 0.031462; batch adversarial loss: 0.507084\n",
      "epoch 192; iter: 0; batch classifier loss: 0.020337; batch adversarial loss: 0.347795\n",
      "epoch 193; iter: 0; batch classifier loss: 0.039153; batch adversarial loss: 0.388806\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026306; batch adversarial loss: 0.417351\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019860; batch adversarial loss: 0.449979\n",
      "epoch 196; iter: 0; batch classifier loss: 0.070433; batch adversarial loss: 0.361406\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013230; batch adversarial loss: 0.397050\n",
      "epoch 198; iter: 0; batch classifier loss: 0.012379; batch adversarial loss: 0.466108\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049304; batch adversarial loss: 0.480934\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683743; batch adversarial loss: 0.734181\n",
      "epoch 1; iter: 0; batch classifier loss: 0.520751; batch adversarial loss: 0.703572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.439813; batch adversarial loss: 0.684337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343135; batch adversarial loss: 0.641356\n",
      "epoch 4; iter: 0; batch classifier loss: 0.290708; batch adversarial loss: 0.600329\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337118; batch adversarial loss: 0.566533\n",
      "epoch 6; iter: 0; batch classifier loss: 0.337032; batch adversarial loss: 0.534388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.328555; batch adversarial loss: 0.525341\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294442; batch adversarial loss: 0.475875\n",
      "epoch 9; iter: 0; batch classifier loss: 0.255177; batch adversarial loss: 0.478469\n",
      "epoch 10; iter: 0; batch classifier loss: 0.265787; batch adversarial loss: 0.467848\n",
      "epoch 11; iter: 0; batch classifier loss: 0.247147; batch adversarial loss: 0.479271\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234980; batch adversarial loss: 0.471638\n",
      "epoch 13; iter: 0; batch classifier loss: 0.173984; batch adversarial loss: 0.473092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.146870; batch adversarial loss: 0.456223\n",
      "epoch 15; iter: 0; batch classifier loss: 0.172543; batch adversarial loss: 0.467228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 0; batch classifier loss: 0.216294; batch adversarial loss: 0.451920\n",
      "epoch 17; iter: 0; batch classifier loss: 0.149211; batch adversarial loss: 0.416399\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233026; batch adversarial loss: 0.478460\n",
      "epoch 19; iter: 0; batch classifier loss: 0.193830; batch adversarial loss: 0.465378\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157541; batch adversarial loss: 0.403898\n",
      "epoch 21; iter: 0; batch classifier loss: 0.159365; batch adversarial loss: 0.481395\n",
      "epoch 22; iter: 0; batch classifier loss: 0.142831; batch adversarial loss: 0.435801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.133281; batch adversarial loss: 0.428569\n",
      "epoch 24; iter: 0; batch classifier loss: 0.181131; batch adversarial loss: 0.422464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.137672; batch adversarial loss: 0.445870\n",
      "epoch 26; iter: 0; batch classifier loss: 0.151327; batch adversarial loss: 0.365217\n",
      "epoch 27; iter: 0; batch classifier loss: 0.152669; batch adversarial loss: 0.494479\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161737; batch adversarial loss: 0.425233\n",
      "epoch 29; iter: 0; batch classifier loss: 0.178149; batch adversarial loss: 0.387928\n",
      "epoch 30; iter: 0; batch classifier loss: 0.174488; batch adversarial loss: 0.382740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.133251; batch adversarial loss: 0.424225\n",
      "epoch 32; iter: 0; batch classifier loss: 0.124859; batch adversarial loss: 0.449007\n",
      "epoch 33; iter: 0; batch classifier loss: 0.158007; batch adversarial loss: 0.378194\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132303; batch adversarial loss: 0.429197\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102831; batch adversarial loss: 0.406328\n",
      "epoch 36; iter: 0; batch classifier loss: 0.098824; batch adversarial loss: 0.329324\n",
      "epoch 37; iter: 0; batch classifier loss: 0.154209; batch adversarial loss: 0.366981\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109091; batch adversarial loss: 0.377343\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107378; batch adversarial loss: 0.418806\n",
      "epoch 40; iter: 0; batch classifier loss: 0.134531; batch adversarial loss: 0.371332\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125807; batch adversarial loss: 0.480893\n",
      "epoch 42; iter: 0; batch classifier loss: 0.084738; batch adversarial loss: 0.425334\n",
      "epoch 43; iter: 0; batch classifier loss: 0.116875; batch adversarial loss: 0.456517\n",
      "epoch 44; iter: 0; batch classifier loss: 0.087406; batch adversarial loss: 0.391356\n",
      "epoch 45; iter: 0; batch classifier loss: 0.096125; batch adversarial loss: 0.510305\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096841; batch adversarial loss: 0.401433\n",
      "epoch 47; iter: 0; batch classifier loss: 0.067395; batch adversarial loss: 0.377621\n",
      "epoch 48; iter: 0; batch classifier loss: 0.058557; batch adversarial loss: 0.501955\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059474; batch adversarial loss: 0.333945\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110531; batch adversarial loss: 0.375388\n",
      "epoch 51; iter: 0; batch classifier loss: 0.186125; batch adversarial loss: 0.426571\n",
      "epoch 52; iter: 0; batch classifier loss: 0.092666; batch adversarial loss: 0.540184\n",
      "epoch 53; iter: 0; batch classifier loss: 0.130527; batch adversarial loss: 0.425922\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065728; batch adversarial loss: 0.303508\n",
      "epoch 55; iter: 0; batch classifier loss: 0.083513; batch adversarial loss: 0.395527\n",
      "epoch 56; iter: 0; batch classifier loss: 0.103146; batch adversarial loss: 0.403480\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136988; batch adversarial loss: 0.442649\n",
      "epoch 58; iter: 0; batch classifier loss: 0.112830; batch adversarial loss: 0.368000\n",
      "epoch 59; iter: 0; batch classifier loss: 0.077173; batch adversarial loss: 0.394948\n",
      "epoch 60; iter: 0; batch classifier loss: 0.111698; batch adversarial loss: 0.426019\n",
      "epoch 61; iter: 0; batch classifier loss: 0.120167; batch adversarial loss: 0.580510\n",
      "epoch 62; iter: 0; batch classifier loss: 0.093206; batch adversarial loss: 0.383380\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054701; batch adversarial loss: 0.382861\n",
      "epoch 64; iter: 0; batch classifier loss: 0.059396; batch adversarial loss: 0.386333\n",
      "epoch 65; iter: 0; batch classifier loss: 0.075268; batch adversarial loss: 0.426615\n",
      "epoch 66; iter: 0; batch classifier loss: 0.098717; batch adversarial loss: 0.416723\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101101; batch adversarial loss: 0.398126\n",
      "epoch 68; iter: 0; batch classifier loss: 0.074023; batch adversarial loss: 0.458330\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087805; batch adversarial loss: 0.433097\n",
      "epoch 70; iter: 0; batch classifier loss: 0.135180; batch adversarial loss: 0.389460\n",
      "epoch 71; iter: 0; batch classifier loss: 0.125716; batch adversarial loss: 0.472296\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066234; batch adversarial loss: 0.497328\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065333; batch adversarial loss: 0.434369\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059941; batch adversarial loss: 0.310095\n",
      "epoch 75; iter: 0; batch classifier loss: 0.073186; batch adversarial loss: 0.422061\n",
      "epoch 76; iter: 0; batch classifier loss: 0.077731; batch adversarial loss: 0.395625\n",
      "epoch 77; iter: 0; batch classifier loss: 0.099535; batch adversarial loss: 0.392568\n",
      "epoch 78; iter: 0; batch classifier loss: 0.064744; batch adversarial loss: 0.386195\n",
      "epoch 79; iter: 0; batch classifier loss: 0.084613; batch adversarial loss: 0.405433\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054922; batch adversarial loss: 0.407436\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059642; batch adversarial loss: 0.383540\n",
      "epoch 82; iter: 0; batch classifier loss: 0.048063; batch adversarial loss: 0.347392\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070010; batch adversarial loss: 0.508383\n",
      "epoch 84; iter: 0; batch classifier loss: 0.058228; batch adversarial loss: 0.521347\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075882; batch adversarial loss: 0.392838\n",
      "epoch 86; iter: 0; batch classifier loss: 0.079647; batch adversarial loss: 0.389066\n",
      "epoch 87; iter: 0; batch classifier loss: 0.046512; batch adversarial loss: 0.384803\n",
      "epoch 88; iter: 0; batch classifier loss: 0.059716; batch adversarial loss: 0.357286\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068471; batch adversarial loss: 0.506037\n",
      "epoch 90; iter: 0; batch classifier loss: 0.062967; batch adversarial loss: 0.445815\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057424; batch adversarial loss: 0.461162\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063436; batch adversarial loss: 0.494898\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047637; batch adversarial loss: 0.365114\n",
      "epoch 94; iter: 0; batch classifier loss: 0.046044; batch adversarial loss: 0.320187\n",
      "epoch 95; iter: 0; batch classifier loss: 0.077732; batch adversarial loss: 0.486240\n",
      "epoch 96; iter: 0; batch classifier loss: 0.043968; batch adversarial loss: 0.448383\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059390; batch adversarial loss: 0.395630\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050033; batch adversarial loss: 0.467346\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047140; batch adversarial loss: 0.475232\n",
      "epoch 100; iter: 0; batch classifier loss: 0.047597; batch adversarial loss: 0.384655\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065062; batch adversarial loss: 0.447377\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049203; batch adversarial loss: 0.438336\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046258; batch adversarial loss: 0.418688\n",
      "epoch 104; iter: 0; batch classifier loss: 0.029920; batch adversarial loss: 0.361587\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041780; batch adversarial loss: 0.475527\n",
      "epoch 106; iter: 0; batch classifier loss: 0.048846; batch adversarial loss: 0.426323\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067833; batch adversarial loss: 0.313704\n",
      "epoch 108; iter: 0; batch classifier loss: 0.053218; batch adversarial loss: 0.379601\n",
      "epoch 109; iter: 0; batch classifier loss: 0.048461; batch adversarial loss: 0.414454\n",
      "epoch 110; iter: 0; batch classifier loss: 0.026559; batch adversarial loss: 0.532304\n",
      "epoch 111; iter: 0; batch classifier loss: 0.055223; batch adversarial loss: 0.399695\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027480; batch adversarial loss: 0.397929\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037576; batch adversarial loss: 0.426275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114; iter: 0; batch classifier loss: 0.020895; batch adversarial loss: 0.423419\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035876; batch adversarial loss: 0.470832\n",
      "epoch 116; iter: 0; batch classifier loss: 0.028193; batch adversarial loss: 0.476876\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026686; batch adversarial loss: 0.382014\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021469; batch adversarial loss: 0.608958\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024857; batch adversarial loss: 0.508376\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035797; batch adversarial loss: 0.467159\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021898; batch adversarial loss: 0.425492\n",
      "epoch 122; iter: 0; batch classifier loss: 0.058024; batch adversarial loss: 0.501308\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029879; batch adversarial loss: 0.546580\n",
      "epoch 124; iter: 0; batch classifier loss: 0.017761; batch adversarial loss: 0.412914\n",
      "epoch 125; iter: 0; batch classifier loss: 0.009530; batch adversarial loss: 0.426893\n",
      "epoch 126; iter: 0; batch classifier loss: 0.072065; batch adversarial loss: 0.425841\n",
      "epoch 127; iter: 0; batch classifier loss: 0.038512; batch adversarial loss: 0.472057\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058424; batch adversarial loss: 0.493565\n",
      "epoch 129; iter: 0; batch classifier loss: 0.009764; batch adversarial loss: 0.391020\n",
      "epoch 130; iter: 0; batch classifier loss: 0.034674; batch adversarial loss: 0.467988\n",
      "epoch 131; iter: 0; batch classifier loss: 0.047066; batch adversarial loss: 0.538853\n",
      "epoch 132; iter: 0; batch classifier loss: 0.084557; batch adversarial loss: 0.576449\n",
      "epoch 133; iter: 0; batch classifier loss: 0.029829; batch adversarial loss: 0.424796\n",
      "epoch 134; iter: 0; batch classifier loss: 0.079606; batch adversarial loss: 0.644364\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020852; batch adversarial loss: 0.429507\n",
      "epoch 136; iter: 0; batch classifier loss: 0.074462; batch adversarial loss: 0.565001\n",
      "epoch 137; iter: 0; batch classifier loss: 0.082940; batch adversarial loss: 0.597536\n",
      "epoch 138; iter: 0; batch classifier loss: 0.110375; batch adversarial loss: 0.556817\n",
      "epoch 139; iter: 0; batch classifier loss: 0.130079; batch adversarial loss: 0.688601\n",
      "epoch 140; iter: 0; batch classifier loss: 0.093863; batch adversarial loss: 0.579676\n",
      "epoch 141; iter: 0; batch classifier loss: 0.105539; batch adversarial loss: 0.591229\n",
      "epoch 142; iter: 0; batch classifier loss: 0.175531; batch adversarial loss: 0.678663\n",
      "epoch 143; iter: 0; batch classifier loss: 0.099166; batch adversarial loss: 0.588739\n",
      "epoch 144; iter: 0; batch classifier loss: 0.101458; batch adversarial loss: 0.558738\n",
      "epoch 145; iter: 0; batch classifier loss: 0.057348; batch adversarial loss: 0.480817\n",
      "epoch 146; iter: 0; batch classifier loss: 0.096927; batch adversarial loss: 0.602976\n",
      "epoch 147; iter: 0; batch classifier loss: 0.126473; batch adversarial loss: 0.582066\n",
      "epoch 148; iter: 0; batch classifier loss: 0.094552; batch adversarial loss: 0.570830\n",
      "epoch 149; iter: 0; batch classifier loss: 0.076640; batch adversarial loss: 0.524579\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038373; batch adversarial loss: 0.369399\n",
      "epoch 151; iter: 0; batch classifier loss: 0.143280; batch adversarial loss: 0.541187\n",
      "epoch 152; iter: 0; batch classifier loss: 0.111484; batch adversarial loss: 0.575818\n",
      "epoch 153; iter: 0; batch classifier loss: 0.096130; batch adversarial loss: 0.466422\n",
      "epoch 154; iter: 0; batch classifier loss: 0.161015; batch adversarial loss: 0.528498\n",
      "epoch 155; iter: 0; batch classifier loss: 0.141361; batch adversarial loss: 0.620788\n",
      "epoch 156; iter: 0; batch classifier loss: 0.097084; batch adversarial loss: 0.411241\n",
      "epoch 157; iter: 0; batch classifier loss: 0.161373; batch adversarial loss: 0.575981\n",
      "epoch 158; iter: 0; batch classifier loss: 0.077806; batch adversarial loss: 0.408717\n",
      "epoch 159; iter: 0; batch classifier loss: 0.072665; batch adversarial loss: 0.436012\n",
      "epoch 160; iter: 0; batch classifier loss: 0.076639; batch adversarial loss: 0.470770\n",
      "epoch 161; iter: 0; batch classifier loss: 0.119602; batch adversarial loss: 0.566419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.085055; batch adversarial loss: 0.471551\n",
      "epoch 163; iter: 0; batch classifier loss: 0.128045; batch adversarial loss: 0.532723\n",
      "epoch 164; iter: 0; batch classifier loss: 0.108279; batch adversarial loss: 0.614842\n",
      "epoch 165; iter: 0; batch classifier loss: 0.122017; batch adversarial loss: 0.551900\n",
      "epoch 166; iter: 0; batch classifier loss: 0.110888; batch adversarial loss: 0.478031\n",
      "epoch 167; iter: 0; batch classifier loss: 0.133020; batch adversarial loss: 0.557448\n",
      "epoch 168; iter: 0; batch classifier loss: 0.082015; batch adversarial loss: 0.439626\n",
      "epoch 169; iter: 0; batch classifier loss: 0.134549; batch adversarial loss: 0.507242\n",
      "epoch 170; iter: 0; batch classifier loss: 0.045688; batch adversarial loss: 0.375477\n",
      "epoch 171; iter: 0; batch classifier loss: 0.105566; batch adversarial loss: 0.475101\n",
      "epoch 172; iter: 0; batch classifier loss: 0.123039; batch adversarial loss: 0.501666\n",
      "epoch 173; iter: 0; batch classifier loss: 0.143458; batch adversarial loss: 0.517069\n",
      "epoch 174; iter: 0; batch classifier loss: 0.153944; batch adversarial loss: 0.485368\n",
      "epoch 175; iter: 0; batch classifier loss: 0.103240; batch adversarial loss: 0.425181\n",
      "epoch 176; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.405127\n",
      "epoch 177; iter: 0; batch classifier loss: 0.092205; batch adversarial loss: 0.471377\n",
      "epoch 178; iter: 0; batch classifier loss: 0.078737; batch adversarial loss: 0.456335\n",
      "epoch 179; iter: 0; batch classifier loss: 0.043857; batch adversarial loss: 0.387553\n",
      "epoch 180; iter: 0; batch classifier loss: 0.112573; batch adversarial loss: 0.475327\n",
      "epoch 181; iter: 0; batch classifier loss: 0.099916; batch adversarial loss: 0.473840\n",
      "epoch 182; iter: 0; batch classifier loss: 0.073094; batch adversarial loss: 0.446524\n",
      "epoch 183; iter: 0; batch classifier loss: 0.100325; batch adversarial loss: 0.530464\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.434796\n",
      "epoch 185; iter: 0; batch classifier loss: 0.039644; batch adversarial loss: 0.393796\n",
      "epoch 186; iter: 0; batch classifier loss: 0.045701; batch adversarial loss: 0.469716\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026920; batch adversarial loss: 0.430542\n",
      "epoch 188; iter: 0; batch classifier loss: 0.026221; batch adversarial loss: 0.479583\n",
      "epoch 189; iter: 0; batch classifier loss: 0.023584; batch adversarial loss: 0.396316\n",
      "epoch 190; iter: 0; batch classifier loss: 0.032339; batch adversarial loss: 0.509296\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028426; batch adversarial loss: 0.456818\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024995; batch adversarial loss: 0.396716\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037691; batch adversarial loss: 0.487460\n",
      "epoch 194; iter: 0; batch classifier loss: 0.045779; batch adversarial loss: 0.421653\n",
      "epoch 195; iter: 0; batch classifier loss: 0.061914; batch adversarial loss: 0.464649\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024971; batch adversarial loss: 0.415474\n",
      "epoch 197; iter: 0; batch classifier loss: 0.052323; batch adversarial loss: 0.383834\n",
      "epoch 198; iter: 0; batch classifier loss: 0.052575; batch adversarial loss: 0.444697\n",
      "epoch 199; iter: 0; batch classifier loss: 0.053781; batch adversarial loss: 0.380436\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679098; batch adversarial loss: 0.819774\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403763; batch adversarial loss: 0.805312\n",
      "epoch 2; iter: 0; batch classifier loss: 0.328086; batch adversarial loss: 0.750224\n",
      "epoch 3; iter: 0; batch classifier loss: 0.320897; batch adversarial loss: 0.701255\n",
      "epoch 4; iter: 0; batch classifier loss: 0.269103; batch adversarial loss: 0.669449\n",
      "epoch 5; iter: 0; batch classifier loss: 0.321938; batch adversarial loss: 0.625696\n",
      "epoch 6; iter: 0; batch classifier loss: 0.241304; batch adversarial loss: 0.591614\n",
      "epoch 7; iter: 0; batch classifier loss: 0.271015; batch adversarial loss: 0.596532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256549; batch adversarial loss: 0.587219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266688; batch adversarial loss: 0.538026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 0; batch classifier loss: 0.283815; batch adversarial loss: 0.519399\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235300; batch adversarial loss: 0.525840\n",
      "epoch 12; iter: 0; batch classifier loss: 0.206478; batch adversarial loss: 0.478166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.233216; batch adversarial loss: 0.511402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.192572; batch adversarial loss: 0.477905\n",
      "epoch 15; iter: 0; batch classifier loss: 0.182001; batch adversarial loss: 0.454753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274723; batch adversarial loss: 0.470861\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310389; batch adversarial loss: 0.440202\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219491; batch adversarial loss: 0.446642\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160528; batch adversarial loss: 0.561257\n",
      "epoch 20; iter: 0; batch classifier loss: 0.169871; batch adversarial loss: 0.450931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216982; batch adversarial loss: 0.368381\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175137; batch adversarial loss: 0.413278\n",
      "epoch 23; iter: 0; batch classifier loss: 0.153321; batch adversarial loss: 0.405495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159021; batch adversarial loss: 0.430490\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185240; batch adversarial loss: 0.480954\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172322; batch adversarial loss: 0.424840\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159595; batch adversarial loss: 0.405495\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168212; batch adversarial loss: 0.426051\n",
      "epoch 29; iter: 0; batch classifier loss: 0.159159; batch adversarial loss: 0.364118\n",
      "epoch 30; iter: 0; batch classifier loss: 0.169597; batch adversarial loss: 0.451883\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172444; batch adversarial loss: 0.514085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.159368; batch adversarial loss: 0.380585\n",
      "epoch 33; iter: 0; batch classifier loss: 0.112868; batch adversarial loss: 0.402717\n",
      "epoch 34; iter: 0; batch classifier loss: 0.176508; batch adversarial loss: 0.425811\n",
      "epoch 35; iter: 0; batch classifier loss: 0.134107; batch adversarial loss: 0.385528\n",
      "epoch 36; iter: 0; batch classifier loss: 0.145597; batch adversarial loss: 0.333867\n",
      "epoch 37; iter: 0; batch classifier loss: 0.143000; batch adversarial loss: 0.398623\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125810; batch adversarial loss: 0.394883\n",
      "epoch 39; iter: 0; batch classifier loss: 0.164717; batch adversarial loss: 0.416656\n",
      "epoch 40; iter: 0; batch classifier loss: 0.078169; batch adversarial loss: 0.413524\n",
      "epoch 41; iter: 0; batch classifier loss: 0.120967; batch adversarial loss: 0.391702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.077062; batch adversarial loss: 0.424407\n",
      "epoch 43; iter: 0; batch classifier loss: 0.126293; batch adversarial loss: 0.472234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.088143; batch adversarial loss: 0.375348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104409; batch adversarial loss: 0.403804\n",
      "epoch 46; iter: 0; batch classifier loss: 0.039586; batch adversarial loss: 0.397319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.082589; batch adversarial loss: 0.467891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.108726; batch adversarial loss: 0.439088\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092347; batch adversarial loss: 0.395532\n",
      "epoch 50; iter: 0; batch classifier loss: 0.103026; batch adversarial loss: 0.369491\n",
      "epoch 51; iter: 0; batch classifier loss: 0.129649; batch adversarial loss: 0.391933\n",
      "epoch 52; iter: 0; batch classifier loss: 0.068082; batch adversarial loss: 0.417292\n",
      "epoch 53; iter: 0; batch classifier loss: 0.089796; batch adversarial loss: 0.418732\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127585; batch adversarial loss: 0.380400\n",
      "epoch 55; iter: 0; batch classifier loss: 0.072119; batch adversarial loss: 0.386648\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077229; batch adversarial loss: 0.471769\n",
      "epoch 57; iter: 0; batch classifier loss: 0.086693; batch adversarial loss: 0.423127\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085387; batch adversarial loss: 0.373974\n",
      "epoch 59; iter: 0; batch classifier loss: 0.116777; batch adversarial loss: 0.411526\n",
      "epoch 60; iter: 0; batch classifier loss: 0.110163; batch adversarial loss: 0.387015\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087244; batch adversarial loss: 0.405304\n",
      "epoch 62; iter: 0; batch classifier loss: 0.069090; batch adversarial loss: 0.475605\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074213; batch adversarial loss: 0.377862\n",
      "epoch 64; iter: 0; batch classifier loss: 0.083963; batch adversarial loss: 0.407351\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066717; batch adversarial loss: 0.391647\n",
      "epoch 66; iter: 0; batch classifier loss: 0.054528; batch adversarial loss: 0.397324\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059558; batch adversarial loss: 0.409904\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113991; batch adversarial loss: 0.481572\n",
      "epoch 69; iter: 0; batch classifier loss: 0.096675; batch adversarial loss: 0.546994\n",
      "epoch 70; iter: 0; batch classifier loss: 0.060086; batch adversarial loss: 0.345981\n",
      "epoch 71; iter: 0; batch classifier loss: 0.078924; batch adversarial loss: 0.409047\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053271; batch adversarial loss: 0.471517\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062463; batch adversarial loss: 0.397311\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064835; batch adversarial loss: 0.365610\n",
      "epoch 75; iter: 0; batch classifier loss: 0.080403; batch adversarial loss: 0.549674\n",
      "epoch 76; iter: 0; batch classifier loss: 0.079257; batch adversarial loss: 0.368381\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069365; batch adversarial loss: 0.461934\n",
      "epoch 78; iter: 0; batch classifier loss: 0.059769; batch adversarial loss: 0.456062\n",
      "epoch 79; iter: 0; batch classifier loss: 0.065791; batch adversarial loss: 0.421572\n",
      "epoch 80; iter: 0; batch classifier loss: 0.077131; batch adversarial loss: 0.441706\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092690; batch adversarial loss: 0.366867\n",
      "epoch 82; iter: 0; batch classifier loss: 0.058492; batch adversarial loss: 0.448434\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072240; batch adversarial loss: 0.409076\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106263; batch adversarial loss: 0.493145\n",
      "epoch 85; iter: 0; batch classifier loss: 0.088567; batch adversarial loss: 0.404830\n",
      "epoch 86; iter: 0; batch classifier loss: 0.089938; batch adversarial loss: 0.444474\n",
      "epoch 87; iter: 0; batch classifier loss: 0.070662; batch adversarial loss: 0.377627\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063528; batch adversarial loss: 0.404549\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050136; batch adversarial loss: 0.375396\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055314; batch adversarial loss: 0.337269\n",
      "epoch 91; iter: 0; batch classifier loss: 0.097948; batch adversarial loss: 0.391324\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044325; batch adversarial loss: 0.417953\n",
      "epoch 93; iter: 0; batch classifier loss: 0.078642; batch adversarial loss: 0.330754\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077404; batch adversarial loss: 0.447882\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070958; batch adversarial loss: 0.458850\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072193; batch adversarial loss: 0.312421\n",
      "epoch 97; iter: 0; batch classifier loss: 0.094504; batch adversarial loss: 0.416646\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035165; batch adversarial loss: 0.476100\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069077; batch adversarial loss: 0.510066\n",
      "epoch 100; iter: 0; batch classifier loss: 0.065219; batch adversarial loss: 0.470610\n",
      "epoch 101; iter: 0; batch classifier loss: 0.105126; batch adversarial loss: 0.393187\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071920; batch adversarial loss: 0.457221\n",
      "epoch 103; iter: 0; batch classifier loss: 0.048885; batch adversarial loss: 0.325722\n",
      "epoch 104; iter: 0; batch classifier loss: 0.089837; batch adversarial loss: 0.507192\n",
      "epoch 105; iter: 0; batch classifier loss: 0.074319; batch adversarial loss: 0.430368\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053936; batch adversarial loss: 0.392279\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062253; batch adversarial loss: 0.398208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 108; iter: 0; batch classifier loss: 0.057911; batch adversarial loss: 0.514699\n",
      "epoch 109; iter: 0; batch classifier loss: 0.090711; batch adversarial loss: 0.431152\n",
      "epoch 110; iter: 0; batch classifier loss: 0.039028; batch adversarial loss: 0.426303\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061783; batch adversarial loss: 0.406389\n",
      "epoch 112; iter: 0; batch classifier loss: 0.083200; batch adversarial loss: 0.399335\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047321; batch adversarial loss: 0.398943\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060905; batch adversarial loss: 0.408377\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070089; batch adversarial loss: 0.383371\n",
      "epoch 116; iter: 0; batch classifier loss: 0.055877; batch adversarial loss: 0.379193\n",
      "epoch 117; iter: 0; batch classifier loss: 0.078487; batch adversarial loss: 0.542290\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053035; batch adversarial loss: 0.465664\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044986; batch adversarial loss: 0.457472\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045866; batch adversarial loss: 0.372119\n",
      "epoch 121; iter: 0; batch classifier loss: 0.051854; batch adversarial loss: 0.386845\n",
      "epoch 122; iter: 0; batch classifier loss: 0.079526; batch adversarial loss: 0.448076\n",
      "epoch 123; iter: 0; batch classifier loss: 0.052400; batch adversarial loss: 0.386353\n",
      "epoch 124; iter: 0; batch classifier loss: 0.053007; batch adversarial loss: 0.397642\n",
      "epoch 125; iter: 0; batch classifier loss: 0.058134; batch adversarial loss: 0.406420\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062183; batch adversarial loss: 0.421737\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062518; batch adversarial loss: 0.381474\n",
      "epoch 128; iter: 0; batch classifier loss: 0.063952; batch adversarial loss: 0.421671\n",
      "epoch 129; iter: 0; batch classifier loss: 0.075820; batch adversarial loss: 0.417827\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057136; batch adversarial loss: 0.443915\n",
      "epoch 131; iter: 0; batch classifier loss: 0.093558; batch adversarial loss: 0.370775\n",
      "epoch 132; iter: 0; batch classifier loss: 0.072819; batch adversarial loss: 0.453309\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049056; batch adversarial loss: 0.370636\n",
      "epoch 134; iter: 0; batch classifier loss: 0.044142; batch adversarial loss: 0.482275\n",
      "epoch 135; iter: 0; batch classifier loss: 0.050102; batch adversarial loss: 0.341568\n",
      "epoch 136; iter: 0; batch classifier loss: 0.101166; batch adversarial loss: 0.467801\n",
      "epoch 137; iter: 0; batch classifier loss: 0.078571; batch adversarial loss: 0.322371\n",
      "epoch 138; iter: 0; batch classifier loss: 0.070495; batch adversarial loss: 0.400343\n",
      "epoch 139; iter: 0; batch classifier loss: 0.078747; batch adversarial loss: 0.489082\n",
      "epoch 140; iter: 0; batch classifier loss: 0.057539; batch adversarial loss: 0.460817\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043055; batch adversarial loss: 0.411797\n",
      "epoch 142; iter: 0; batch classifier loss: 0.057107; batch adversarial loss: 0.379420\n",
      "epoch 143; iter: 0; batch classifier loss: 0.055618; batch adversarial loss: 0.353250\n",
      "epoch 144; iter: 0; batch classifier loss: 0.044777; batch adversarial loss: 0.437786\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036153; batch adversarial loss: 0.395080\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040956; batch adversarial loss: 0.394043\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027001; batch adversarial loss: 0.360793\n",
      "epoch 148; iter: 0; batch classifier loss: 0.040892; batch adversarial loss: 0.484136\n",
      "epoch 149; iter: 0; batch classifier loss: 0.103426; batch adversarial loss: 0.399033\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047441; batch adversarial loss: 0.356034\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037717; batch adversarial loss: 0.438317\n",
      "epoch 152; iter: 0; batch classifier loss: 0.029303; batch adversarial loss: 0.366421\n",
      "epoch 153; iter: 0; batch classifier loss: 0.054788; batch adversarial loss: 0.334199\n",
      "epoch 154; iter: 0; batch classifier loss: 0.035539; batch adversarial loss: 0.427946\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023229; batch adversarial loss: 0.472053\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023865; batch adversarial loss: 0.395664\n",
      "epoch 157; iter: 0; batch classifier loss: 0.026240; batch adversarial loss: 0.432952\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045250; batch adversarial loss: 0.431336\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026301; batch adversarial loss: 0.567357\n",
      "epoch 160; iter: 0; batch classifier loss: 0.014648; batch adversarial loss: 0.458050\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016039; batch adversarial loss: 0.507576\n",
      "epoch 162; iter: 0; batch classifier loss: 0.054343; batch adversarial loss: 0.536008\n",
      "epoch 163; iter: 0; batch classifier loss: 0.034116; batch adversarial loss: 0.364341\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033095; batch adversarial loss: 0.470333\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025030; batch adversarial loss: 0.388886\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023552; batch adversarial loss: 0.498048\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032309; batch adversarial loss: 0.460247\n",
      "epoch 168; iter: 0; batch classifier loss: 0.020810; batch adversarial loss: 0.481170\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030675; batch adversarial loss: 0.370199\n",
      "epoch 170; iter: 0; batch classifier loss: 0.029192; batch adversarial loss: 0.400288\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058968; batch adversarial loss: 0.438428\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019674; batch adversarial loss: 0.461321\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032900; batch adversarial loss: 0.420280\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022273; batch adversarial loss: 0.406454\n",
      "epoch 175; iter: 0; batch classifier loss: 0.030762; batch adversarial loss: 0.503860\n",
      "epoch 176; iter: 0; batch classifier loss: 0.056960; batch adversarial loss: 0.488176\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019510; batch adversarial loss: 0.455491\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055219; batch adversarial loss: 0.459956\n",
      "epoch 179; iter: 0; batch classifier loss: 0.017432; batch adversarial loss: 0.499824\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014919; batch adversarial loss: 0.321291\n",
      "epoch 181; iter: 0; batch classifier loss: 0.036694; batch adversarial loss: 0.426212\n",
      "epoch 182; iter: 0; batch classifier loss: 0.034979; batch adversarial loss: 0.582218\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017519; batch adversarial loss: 0.465931\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021362; batch adversarial loss: 0.448375\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028735; batch adversarial loss: 0.482155\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022975; batch adversarial loss: 0.455259\n",
      "epoch 187; iter: 0; batch classifier loss: 0.014578; batch adversarial loss: 0.436914\n",
      "epoch 188; iter: 0; batch classifier loss: 0.050060; batch adversarial loss: 0.455249\n",
      "epoch 189; iter: 0; batch classifier loss: 0.045976; batch adversarial loss: 0.571470\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034447; batch adversarial loss: 0.474228\n",
      "epoch 191; iter: 0; batch classifier loss: 0.053867; batch adversarial loss: 0.446354\n",
      "epoch 192; iter: 0; batch classifier loss: 0.098840; batch adversarial loss: 0.558897\n",
      "epoch 193; iter: 0; batch classifier loss: 0.112126; batch adversarial loss: 0.670340\n",
      "epoch 194; iter: 0; batch classifier loss: 0.067431; batch adversarial loss: 0.569944\n",
      "epoch 195; iter: 0; batch classifier loss: 0.119687; batch adversarial loss: 0.680046\n",
      "epoch 196; iter: 0; batch classifier loss: 0.082381; batch adversarial loss: 0.498063\n",
      "epoch 197; iter: 0; batch classifier loss: 0.128400; batch adversarial loss: 0.603714\n",
      "epoch 198; iter: 0; batch classifier loss: 0.075011; batch adversarial loss: 0.499128\n",
      "epoch 199; iter: 0; batch classifier loss: 0.146354; batch adversarial loss: 0.738497\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710267; batch adversarial loss: 0.825369\n",
      "epoch 1; iter: 0; batch classifier loss: 0.516643; batch adversarial loss: 0.808358\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544396; batch adversarial loss: 0.770292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.403613; batch adversarial loss: 0.721511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.440322; batch adversarial loss: 0.670317\n",
      "epoch 5; iter: 0; batch classifier loss: 0.313779; batch adversarial loss: 0.633409\n",
      "epoch 6; iter: 0; batch classifier loss: 0.306620; batch adversarial loss: 0.599439\n",
      "epoch 7; iter: 0; batch classifier loss: 0.177848; batch adversarial loss: 0.593103\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270404; batch adversarial loss: 0.575311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.265289; batch adversarial loss: 0.526765\n",
      "epoch 10; iter: 0; batch classifier loss: 0.301596; batch adversarial loss: 0.549385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.269904; batch adversarial loss: 0.513421\n",
      "epoch 12; iter: 0; batch classifier loss: 0.220935; batch adversarial loss: 0.551828\n",
      "epoch 13; iter: 0; batch classifier loss: 0.215656; batch adversarial loss: 0.503317\n",
      "epoch 14; iter: 0; batch classifier loss: 0.166124; batch adversarial loss: 0.508703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.229963; batch adversarial loss: 0.433612\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242083; batch adversarial loss: 0.467115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.131070; batch adversarial loss: 0.481454\n",
      "epoch 18; iter: 0; batch classifier loss: 0.206010; batch adversarial loss: 0.472195\n",
      "epoch 19; iter: 0; batch classifier loss: 0.164534; batch adversarial loss: 0.441219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.163448; batch adversarial loss: 0.525942\n",
      "epoch 21; iter: 0; batch classifier loss: 0.104728; batch adversarial loss: 0.514701\n",
      "epoch 22; iter: 0; batch classifier loss: 0.132890; batch adversarial loss: 0.499532\n",
      "epoch 23; iter: 0; batch classifier loss: 0.114814; batch adversarial loss: 0.538335\n",
      "epoch 24; iter: 0; batch classifier loss: 0.116471; batch adversarial loss: 0.481679\n",
      "epoch 25; iter: 0; batch classifier loss: 0.151218; batch adversarial loss: 0.471482\n",
      "epoch 26; iter: 0; batch classifier loss: 0.126284; batch adversarial loss: 0.411020\n",
      "epoch 27; iter: 0; batch classifier loss: 0.119105; batch adversarial loss: 0.477573\n",
      "epoch 28; iter: 0; batch classifier loss: 0.112666; batch adversarial loss: 0.458184\n",
      "epoch 29; iter: 0; batch classifier loss: 0.125014; batch adversarial loss: 0.466418\n",
      "epoch 30; iter: 0; batch classifier loss: 0.111964; batch adversarial loss: 0.443512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.132814; batch adversarial loss: 0.485364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.105246; batch adversarial loss: 0.442200\n",
      "epoch 33; iter: 0; batch classifier loss: 0.144420; batch adversarial loss: 0.500887\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159212; batch adversarial loss: 0.463201\n",
      "epoch 35; iter: 0; batch classifier loss: 0.197696; batch adversarial loss: 0.393808\n",
      "epoch 36; iter: 0; batch classifier loss: 0.099977; batch adversarial loss: 0.499610\n",
      "epoch 37; iter: 0; batch classifier loss: 0.126794; batch adversarial loss: 0.425052\n",
      "epoch 38; iter: 0; batch classifier loss: 0.172329; batch adversarial loss: 0.509061\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133010; batch adversarial loss: 0.469069\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114408; batch adversarial loss: 0.416969\n",
      "epoch 41; iter: 0; batch classifier loss: 0.171903; batch adversarial loss: 0.551227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123849; batch adversarial loss: 0.457239\n",
      "epoch 43; iter: 0; batch classifier loss: 0.096719; batch adversarial loss: 0.451903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.143398; batch adversarial loss: 0.454796\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106133; batch adversarial loss: 0.381906\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088530; batch adversarial loss: 0.397289\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086241; batch adversarial loss: 0.360837\n",
      "epoch 48; iter: 0; batch classifier loss: 0.111371; batch adversarial loss: 0.427564\n",
      "epoch 49; iter: 0; batch classifier loss: 0.124766; batch adversarial loss: 0.507073\n",
      "epoch 50; iter: 0; batch classifier loss: 0.117855; batch adversarial loss: 0.427755\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099581; batch adversarial loss: 0.517296\n",
      "epoch 52; iter: 0; batch classifier loss: 0.098913; batch adversarial loss: 0.434309\n",
      "epoch 53; iter: 0; batch classifier loss: 0.093699; batch adversarial loss: 0.307903\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113299; batch adversarial loss: 0.439516\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068949; batch adversarial loss: 0.529519\n",
      "epoch 56; iter: 0; batch classifier loss: 0.104498; batch adversarial loss: 0.362399\n",
      "epoch 57; iter: 0; batch classifier loss: 0.104717; batch adversarial loss: 0.478104\n",
      "epoch 58; iter: 0; batch classifier loss: 0.127242; batch adversarial loss: 0.447318\n",
      "epoch 59; iter: 0; batch classifier loss: 0.052029; batch adversarial loss: 0.380269\n",
      "epoch 60; iter: 0; batch classifier loss: 0.114591; batch adversarial loss: 0.575800\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191902; batch adversarial loss: 0.483757\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108935; batch adversarial loss: 0.426020\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076815; batch adversarial loss: 0.441926\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092837; batch adversarial loss: 0.462333\n",
      "epoch 65; iter: 0; batch classifier loss: 0.065458; batch adversarial loss: 0.491339\n",
      "epoch 66; iter: 0; batch classifier loss: 0.083133; batch adversarial loss: 0.479834\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066668; batch adversarial loss: 0.375547\n",
      "epoch 68; iter: 0; batch classifier loss: 0.070996; batch adversarial loss: 0.450678\n",
      "epoch 69; iter: 0; batch classifier loss: 0.057872; batch adversarial loss: 0.436308\n",
      "epoch 70; iter: 0; batch classifier loss: 0.063420; batch adversarial loss: 0.383484\n",
      "epoch 71; iter: 0; batch classifier loss: 0.091653; batch adversarial loss: 0.564200\n",
      "epoch 72; iter: 0; batch classifier loss: 0.097443; batch adversarial loss: 0.373379\n",
      "epoch 73; iter: 0; batch classifier loss: 0.105853; batch adversarial loss: 0.450058\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068304; batch adversarial loss: 0.363390\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093662; batch adversarial loss: 0.431788\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101339; batch adversarial loss: 0.357831\n",
      "epoch 77; iter: 0; batch classifier loss: 0.082666; batch adversarial loss: 0.470683\n",
      "epoch 78; iter: 0; batch classifier loss: 0.060344; batch adversarial loss: 0.438699\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085461; batch adversarial loss: 0.408545\n",
      "epoch 80; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.504483\n",
      "epoch 81; iter: 0; batch classifier loss: 0.079591; batch adversarial loss: 0.411028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.088526; batch adversarial loss: 0.395193\n",
      "epoch 83; iter: 0; batch classifier loss: 0.104487; batch adversarial loss: 0.443502\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076048; batch adversarial loss: 0.386480\n",
      "epoch 85; iter: 0; batch classifier loss: 0.095777; batch adversarial loss: 0.471771\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053005; batch adversarial loss: 0.467169\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100568; batch adversarial loss: 0.420264\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055279; batch adversarial loss: 0.480531\n",
      "epoch 89; iter: 0; batch classifier loss: 0.081546; batch adversarial loss: 0.500696\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055735; batch adversarial loss: 0.359891\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067448; batch adversarial loss: 0.522653\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069689; batch adversarial loss: 0.429934\n",
      "epoch 93; iter: 0; batch classifier loss: 0.058295; batch adversarial loss: 0.481706\n",
      "epoch 94; iter: 0; batch classifier loss: 0.039449; batch adversarial loss: 0.455712\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081295; batch adversarial loss: 0.336937\n",
      "epoch 96; iter: 0; batch classifier loss: 0.050119; batch adversarial loss: 0.480732\n",
      "epoch 97; iter: 0; batch classifier loss: 0.080010; batch adversarial loss: 0.364263\n",
      "epoch 98; iter: 0; batch classifier loss: 0.086517; batch adversarial loss: 0.424893\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062986; batch adversarial loss: 0.415275\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075693; batch adversarial loss: 0.386938\n",
      "epoch 101; iter: 0; batch classifier loss: 0.119103; batch adversarial loss: 0.509501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102; iter: 0; batch classifier loss: 0.072592; batch adversarial loss: 0.483325\n",
      "epoch 103; iter: 0; batch classifier loss: 0.065824; batch adversarial loss: 0.419965\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056992; batch adversarial loss: 0.354732\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072959; batch adversarial loss: 0.402727\n",
      "epoch 106; iter: 0; batch classifier loss: 0.035908; batch adversarial loss: 0.432606\n",
      "epoch 107; iter: 0; batch classifier loss: 0.040059; batch adversarial loss: 0.425794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.095183; batch adversarial loss: 0.460447\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045142; batch adversarial loss: 0.344380\n",
      "epoch 110; iter: 0; batch classifier loss: 0.066224; batch adversarial loss: 0.348393\n",
      "epoch 111; iter: 0; batch classifier loss: 0.096801; batch adversarial loss: 0.465140\n",
      "epoch 112; iter: 0; batch classifier loss: 0.099035; batch adversarial loss: 0.489360\n",
      "epoch 113; iter: 0; batch classifier loss: 0.076865; batch adversarial loss: 0.383220\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062982; batch adversarial loss: 0.417097\n",
      "epoch 115; iter: 0; batch classifier loss: 0.065958; batch adversarial loss: 0.472686\n",
      "epoch 116; iter: 0; batch classifier loss: 0.042336; batch adversarial loss: 0.398973\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079690; batch adversarial loss: 0.436500\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085029; batch adversarial loss: 0.354902\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044201; batch adversarial loss: 0.419551\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055685; batch adversarial loss: 0.460025\n",
      "epoch 121; iter: 0; batch classifier loss: 0.071936; batch adversarial loss: 0.465109\n",
      "epoch 122; iter: 0; batch classifier loss: 0.106309; batch adversarial loss: 0.480932\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047104; batch adversarial loss: 0.427673\n",
      "epoch 124; iter: 0; batch classifier loss: 0.103454; batch adversarial loss: 0.470924\n",
      "epoch 125; iter: 0; batch classifier loss: 0.100261; batch adversarial loss: 0.408715\n",
      "epoch 126; iter: 0; batch classifier loss: 0.037695; batch adversarial loss: 0.364675\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028651; batch adversarial loss: 0.427079\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041181; batch adversarial loss: 0.404878\n",
      "epoch 129; iter: 0; batch classifier loss: 0.051725; batch adversarial loss: 0.344067\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051503; batch adversarial loss: 0.436124\n",
      "epoch 131; iter: 0; batch classifier loss: 0.107474; batch adversarial loss: 0.460562\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057518; batch adversarial loss: 0.368847\n",
      "epoch 133; iter: 0; batch classifier loss: 0.051413; batch adversarial loss: 0.379667\n",
      "epoch 134; iter: 0; batch classifier loss: 0.069527; batch adversarial loss: 0.470455\n",
      "epoch 135; iter: 0; batch classifier loss: 0.043046; batch adversarial loss: 0.392957\n",
      "epoch 136; iter: 0; batch classifier loss: 0.055986; batch adversarial loss: 0.463386\n",
      "epoch 137; iter: 0; batch classifier loss: 0.070964; batch adversarial loss: 0.425756\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040233; batch adversarial loss: 0.447203\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031163; batch adversarial loss: 0.428765\n",
      "epoch 140; iter: 0; batch classifier loss: 0.078753; batch adversarial loss: 0.540534\n",
      "epoch 141; iter: 0; batch classifier loss: 0.075804; batch adversarial loss: 0.381554\n",
      "epoch 142; iter: 0; batch classifier loss: 0.076218; batch adversarial loss: 0.422010\n",
      "epoch 143; iter: 0; batch classifier loss: 0.062306; batch adversarial loss: 0.449836\n",
      "epoch 144; iter: 0; batch classifier loss: 0.046917; batch adversarial loss: 0.466585\n",
      "epoch 145; iter: 0; batch classifier loss: 0.071304; batch adversarial loss: 0.420136\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046758; batch adversarial loss: 0.482489\n",
      "epoch 147; iter: 0; batch classifier loss: 0.035768; batch adversarial loss: 0.388944\n",
      "epoch 148; iter: 0; batch classifier loss: 0.054393; batch adversarial loss: 0.445493\n",
      "epoch 149; iter: 0; batch classifier loss: 0.045123; batch adversarial loss: 0.569089\n",
      "epoch 150; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.406308\n",
      "epoch 151; iter: 0; batch classifier loss: 0.077779; batch adversarial loss: 0.485922\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038271; batch adversarial loss: 0.428584\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037123; batch adversarial loss: 0.493282\n",
      "epoch 154; iter: 0; batch classifier loss: 0.045350; batch adversarial loss: 0.375123\n",
      "epoch 155; iter: 0; batch classifier loss: 0.052262; batch adversarial loss: 0.485517\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036305; batch adversarial loss: 0.477773\n",
      "epoch 157; iter: 0; batch classifier loss: 0.065073; batch adversarial loss: 0.506643\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054744; batch adversarial loss: 0.558143\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029463; batch adversarial loss: 0.465008\n",
      "epoch 160; iter: 0; batch classifier loss: 0.045898; batch adversarial loss: 0.434925\n",
      "epoch 161; iter: 0; batch classifier loss: 0.034397; batch adversarial loss: 0.382335\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038359; batch adversarial loss: 0.411403\n",
      "epoch 163; iter: 0; batch classifier loss: 0.066108; batch adversarial loss: 0.372852\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020928; batch adversarial loss: 0.477537\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041432; batch adversarial loss: 0.546269\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030759; batch adversarial loss: 0.435694\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018619; batch adversarial loss: 0.416937\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033711; batch adversarial loss: 0.455701\n",
      "epoch 169; iter: 0; batch classifier loss: 0.056603; batch adversarial loss: 0.499503\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023177; batch adversarial loss: 0.467861\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025693; batch adversarial loss: 0.420025\n",
      "epoch 172; iter: 0; batch classifier loss: 0.027960; batch adversarial loss: 0.457799\n",
      "epoch 173; iter: 0; batch classifier loss: 0.035935; batch adversarial loss: 0.334893\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027031; batch adversarial loss: 0.460851\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019146; batch adversarial loss: 0.415214\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033466; batch adversarial loss: 0.409105\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024744; batch adversarial loss: 0.441402\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014396; batch adversarial loss: 0.471419\n",
      "epoch 179; iter: 0; batch classifier loss: 0.031532; batch adversarial loss: 0.473364\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031510; batch adversarial loss: 0.456364\n",
      "epoch 181; iter: 0; batch classifier loss: 0.023633; batch adversarial loss: 0.502125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024238; batch adversarial loss: 0.428462\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019579; batch adversarial loss: 0.464789\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030113; batch adversarial loss: 0.497077\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037366; batch adversarial loss: 0.520490\n",
      "epoch 186; iter: 0; batch classifier loss: 0.067943; batch adversarial loss: 0.639558\n",
      "epoch 187; iter: 0; batch classifier loss: 0.088364; batch adversarial loss: 0.639122\n",
      "epoch 188; iter: 0; batch classifier loss: 0.074098; batch adversarial loss: 0.520540\n",
      "epoch 189; iter: 0; batch classifier loss: 0.069478; batch adversarial loss: 0.567426\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041000; batch adversarial loss: 0.460042\n",
      "epoch 191; iter: 0; batch classifier loss: 0.078009; batch adversarial loss: 0.568289\n",
      "epoch 192; iter: 0; batch classifier loss: 0.148214; batch adversarial loss: 0.624948\n",
      "epoch 193; iter: 0; batch classifier loss: 0.107512; batch adversarial loss: 0.703413\n",
      "epoch 194; iter: 0; batch classifier loss: 0.187044; batch adversarial loss: 0.799360\n",
      "epoch 195; iter: 0; batch classifier loss: 0.166855; batch adversarial loss: 0.769654\n",
      "epoch 196; iter: 0; batch classifier loss: 0.162693; batch adversarial loss: 0.697998\n",
      "epoch 197; iter: 0; batch classifier loss: 0.208434; batch adversarial loss: 0.822770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 0; batch classifier loss: 0.170223; batch adversarial loss: 0.682835\n",
      "epoch 199; iter: 0; batch classifier loss: 0.209619; batch adversarial loss: 0.741865\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698138; batch adversarial loss: 0.996030\n",
      "epoch 1; iter: 0; batch classifier loss: 0.550593; batch adversarial loss: 1.062135\n",
      "epoch 2; iter: 0; batch classifier loss: 0.455263; batch adversarial loss: 0.944623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.699345; batch adversarial loss: 0.920343\n",
      "epoch 4; iter: 0; batch classifier loss: 0.536615; batch adversarial loss: 0.879643\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508841; batch adversarial loss: 0.799893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451248; batch adversarial loss: 0.691670\n",
      "epoch 7; iter: 0; batch classifier loss: 0.267703; batch adversarial loss: 0.659162\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261961; batch adversarial loss: 0.610343\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286096; batch adversarial loss: 0.593917\n",
      "epoch 10; iter: 0; batch classifier loss: 0.222963; batch adversarial loss: 0.588898\n",
      "epoch 11; iter: 0; batch classifier loss: 0.265383; batch adversarial loss: 0.589282\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293460; batch adversarial loss: 0.547155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.300935; batch adversarial loss: 0.556179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249595; batch adversarial loss: 0.511503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304226; batch adversarial loss: 0.499528\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332392; batch adversarial loss: 0.513406\n",
      "epoch 17; iter: 0; batch classifier loss: 0.212783; batch adversarial loss: 0.499551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.186427; batch adversarial loss: 0.466755\n",
      "epoch 19; iter: 0; batch classifier loss: 0.209320; batch adversarial loss: 0.520785\n",
      "epoch 20; iter: 0; batch classifier loss: 0.181214; batch adversarial loss: 0.484490\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213091; batch adversarial loss: 0.452372\n",
      "epoch 22; iter: 0; batch classifier loss: 0.222351; batch adversarial loss: 0.501064\n",
      "epoch 23; iter: 0; batch classifier loss: 0.258424; batch adversarial loss: 0.432687\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178370; batch adversarial loss: 0.472018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209771; batch adversarial loss: 0.413885\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177954; batch adversarial loss: 0.454137\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171338; batch adversarial loss: 0.498643\n",
      "epoch 28; iter: 0; batch classifier loss: 0.135751; batch adversarial loss: 0.462352\n",
      "epoch 29; iter: 0; batch classifier loss: 0.170727; batch adversarial loss: 0.461994\n",
      "epoch 30; iter: 0; batch classifier loss: 0.132285; batch adversarial loss: 0.451109\n",
      "epoch 31; iter: 0; batch classifier loss: 0.123471; batch adversarial loss: 0.402071\n",
      "epoch 32; iter: 0; batch classifier loss: 0.127768; batch adversarial loss: 0.419265\n",
      "epoch 33; iter: 0; batch classifier loss: 0.118843; batch adversarial loss: 0.486319\n",
      "epoch 34; iter: 0; batch classifier loss: 0.093522; batch adversarial loss: 0.425173\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153817; batch adversarial loss: 0.487493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.121517; batch adversarial loss: 0.570360\n",
      "epoch 37; iter: 0; batch classifier loss: 0.083941; batch adversarial loss: 0.427141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101582; batch adversarial loss: 0.344865\n",
      "epoch 39; iter: 0; batch classifier loss: 0.133820; batch adversarial loss: 0.425898\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137300; batch adversarial loss: 0.511229\n",
      "epoch 41; iter: 0; batch classifier loss: 0.085553; batch adversarial loss: 0.388821\n",
      "epoch 42; iter: 0; batch classifier loss: 0.091361; batch adversarial loss: 0.501153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098745; batch adversarial loss: 0.478016\n",
      "epoch 44; iter: 0; batch classifier loss: 0.092945; batch adversarial loss: 0.383024\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091235; batch adversarial loss: 0.405463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.074084; batch adversarial loss: 0.340088\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092281; batch adversarial loss: 0.392099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.081048; batch adversarial loss: 0.498485\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080997; batch adversarial loss: 0.394761\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077002; batch adversarial loss: 0.460340\n",
      "epoch 51; iter: 0; batch classifier loss: 0.095108; batch adversarial loss: 0.472176\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072363; batch adversarial loss: 0.449962\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087144; batch adversarial loss: 0.372425\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079873; batch adversarial loss: 0.419990\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123098; batch adversarial loss: 0.527354\n",
      "epoch 56; iter: 0; batch classifier loss: 0.110255; batch adversarial loss: 0.363249\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066289; batch adversarial loss: 0.377142\n",
      "epoch 58; iter: 0; batch classifier loss: 0.059105; batch adversarial loss: 0.336023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.053228; batch adversarial loss: 0.393791\n",
      "epoch 60; iter: 0; batch classifier loss: 0.129526; batch adversarial loss: 0.383271\n",
      "epoch 61; iter: 0; batch classifier loss: 0.075007; batch adversarial loss: 0.402540\n",
      "epoch 62; iter: 0; batch classifier loss: 0.077420; batch adversarial loss: 0.469471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.052155; batch adversarial loss: 0.412173\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084874; batch adversarial loss: 0.456896\n",
      "epoch 65; iter: 0; batch classifier loss: 0.110955; batch adversarial loss: 0.483367\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106731; batch adversarial loss: 0.536178\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081118; batch adversarial loss: 0.415771\n",
      "epoch 68; iter: 0; batch classifier loss: 0.067610; batch adversarial loss: 0.396731\n",
      "epoch 69; iter: 0; batch classifier loss: 0.076592; batch adversarial loss: 0.490220\n",
      "epoch 70; iter: 0; batch classifier loss: 0.090604; batch adversarial loss: 0.363883\n",
      "epoch 71; iter: 0; batch classifier loss: 0.056260; batch adversarial loss: 0.363324\n",
      "epoch 72; iter: 0; batch classifier loss: 0.084666; batch adversarial loss: 0.414549\n",
      "epoch 73; iter: 0; batch classifier loss: 0.063501; batch adversarial loss: 0.401620\n",
      "epoch 74; iter: 0; batch classifier loss: 0.103639; batch adversarial loss: 0.405503\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055512; batch adversarial loss: 0.481230\n",
      "epoch 76; iter: 0; batch classifier loss: 0.104711; batch adversarial loss: 0.430459\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072445; batch adversarial loss: 0.402447\n",
      "epoch 78; iter: 0; batch classifier loss: 0.054926; batch adversarial loss: 0.448930\n",
      "epoch 79; iter: 0; batch classifier loss: 0.055576; batch adversarial loss: 0.383352\n",
      "epoch 80; iter: 0; batch classifier loss: 0.064627; batch adversarial loss: 0.455502\n",
      "epoch 81; iter: 0; batch classifier loss: 0.116422; batch adversarial loss: 0.531748\n",
      "epoch 82; iter: 0; batch classifier loss: 0.080890; batch adversarial loss: 0.441562\n",
      "epoch 83; iter: 0; batch classifier loss: 0.077579; batch adversarial loss: 0.466190\n",
      "epoch 84; iter: 0; batch classifier loss: 0.079636; batch adversarial loss: 0.458207\n",
      "epoch 85; iter: 0; batch classifier loss: 0.045864; batch adversarial loss: 0.493841\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049601; batch adversarial loss: 0.419682\n",
      "epoch 87; iter: 0; batch classifier loss: 0.032781; batch adversarial loss: 0.405420\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073341; batch adversarial loss: 0.384601\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066920; batch adversarial loss: 0.353560\n",
      "epoch 90; iter: 0; batch classifier loss: 0.078156; batch adversarial loss: 0.484770\n",
      "epoch 91; iter: 0; batch classifier loss: 0.066691; batch adversarial loss: 0.382009\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053174; batch adversarial loss: 0.410794\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047558; batch adversarial loss: 0.454781\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050821; batch adversarial loss: 0.501971\n",
      "epoch 95; iter: 0; batch classifier loss: 0.053289; batch adversarial loss: 0.418891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96; iter: 0; batch classifier loss: 0.051433; batch adversarial loss: 0.446211\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048757; batch adversarial loss: 0.419549\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051532; batch adversarial loss: 0.432480\n",
      "epoch 99; iter: 0; batch classifier loss: 0.050571; batch adversarial loss: 0.466144\n",
      "epoch 100; iter: 0; batch classifier loss: 0.085532; batch adversarial loss: 0.437366\n",
      "epoch 101; iter: 0; batch classifier loss: 0.095701; batch adversarial loss: 0.449705\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058933; batch adversarial loss: 0.483667\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038430; batch adversarial loss: 0.389972\n",
      "epoch 104; iter: 0; batch classifier loss: 0.100330; batch adversarial loss: 0.489510\n",
      "epoch 105; iter: 0; batch classifier loss: 0.056870; batch adversarial loss: 0.407120\n",
      "epoch 106; iter: 0; batch classifier loss: 0.046762; batch adversarial loss: 0.362937\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072626; batch adversarial loss: 0.499510\n",
      "epoch 108; iter: 0; batch classifier loss: 0.070331; batch adversarial loss: 0.546075\n",
      "epoch 109; iter: 0; batch classifier loss: 0.069133; batch adversarial loss: 0.452996\n",
      "epoch 110; iter: 0; batch classifier loss: 0.068727; batch adversarial loss: 0.457147\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042631; batch adversarial loss: 0.425996\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059250; batch adversarial loss: 0.447680\n",
      "epoch 113; iter: 0; batch classifier loss: 0.070769; batch adversarial loss: 0.437490\n",
      "epoch 114; iter: 0; batch classifier loss: 0.078524; batch adversarial loss: 0.460909\n",
      "epoch 115; iter: 0; batch classifier loss: 0.070254; batch adversarial loss: 0.501955\n",
      "epoch 116; iter: 0; batch classifier loss: 0.066530; batch adversarial loss: 0.426744\n",
      "epoch 117; iter: 0; batch classifier loss: 0.060453; batch adversarial loss: 0.443883\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032185; batch adversarial loss: 0.415450\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037626; batch adversarial loss: 0.508007\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031591; batch adversarial loss: 0.338168\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070383; batch adversarial loss: 0.366322\n",
      "epoch 122; iter: 0; batch classifier loss: 0.066974; batch adversarial loss: 0.501981\n",
      "epoch 123; iter: 0; batch classifier loss: 0.051779; batch adversarial loss: 0.444877\n",
      "epoch 124; iter: 0; batch classifier loss: 0.057622; batch adversarial loss: 0.430470\n",
      "epoch 125; iter: 0; batch classifier loss: 0.103858; batch adversarial loss: 0.458121\n",
      "epoch 126; iter: 0; batch classifier loss: 0.076869; batch adversarial loss: 0.471722\n",
      "epoch 127; iter: 0; batch classifier loss: 0.060058; batch adversarial loss: 0.445388\n",
      "epoch 128; iter: 0; batch classifier loss: 0.061184; batch adversarial loss: 0.413787\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028353; batch adversarial loss: 0.364232\n",
      "epoch 130; iter: 0; batch classifier loss: 0.044296; batch adversarial loss: 0.450329\n",
      "epoch 131; iter: 0; batch classifier loss: 0.053022; batch adversarial loss: 0.433217\n",
      "epoch 132; iter: 0; batch classifier loss: 0.061644; batch adversarial loss: 0.485060\n",
      "epoch 133; iter: 0; batch classifier loss: 0.062302; batch adversarial loss: 0.443367\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040298; batch adversarial loss: 0.507859\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037674; batch adversarial loss: 0.448210\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056432; batch adversarial loss: 0.396690\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058939; batch adversarial loss: 0.422502\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048930; batch adversarial loss: 0.355290\n",
      "epoch 139; iter: 0; batch classifier loss: 0.061906; batch adversarial loss: 0.502420\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062162; batch adversarial loss: 0.395606\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057545; batch adversarial loss: 0.427113\n",
      "epoch 142; iter: 0; batch classifier loss: 0.062443; batch adversarial loss: 0.482370\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049455; batch adversarial loss: 0.423064\n",
      "epoch 144; iter: 0; batch classifier loss: 0.077341; batch adversarial loss: 0.370391\n",
      "epoch 145; iter: 0; batch classifier loss: 0.068348; batch adversarial loss: 0.408638\n",
      "epoch 146; iter: 0; batch classifier loss: 0.059712; batch adversarial loss: 0.465889\n",
      "epoch 147; iter: 0; batch classifier loss: 0.094282; batch adversarial loss: 0.473966\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036897; batch adversarial loss: 0.426604\n",
      "epoch 149; iter: 0; batch classifier loss: 0.054836; batch adversarial loss: 0.405136\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039818; batch adversarial loss: 0.395349\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048242; batch adversarial loss: 0.441769\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053970; batch adversarial loss: 0.430317\n",
      "epoch 153; iter: 0; batch classifier loss: 0.068158; batch adversarial loss: 0.446779\n",
      "epoch 154; iter: 0; batch classifier loss: 0.033913; batch adversarial loss: 0.399806\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042301; batch adversarial loss: 0.437512\n",
      "epoch 156; iter: 0; batch classifier loss: 0.048129; batch adversarial loss: 0.336069\n",
      "epoch 157; iter: 0; batch classifier loss: 0.058961; batch adversarial loss: 0.507865\n",
      "epoch 158; iter: 0; batch classifier loss: 0.059553; batch adversarial loss: 0.327323\n",
      "epoch 159; iter: 0; batch classifier loss: 0.088620; batch adversarial loss: 0.448661\n",
      "epoch 160; iter: 0; batch classifier loss: 0.058440; batch adversarial loss: 0.410124\n",
      "epoch 161; iter: 0; batch classifier loss: 0.086979; batch adversarial loss: 0.398785\n",
      "epoch 162; iter: 0; batch classifier loss: 0.050247; batch adversarial loss: 0.494932\n",
      "epoch 163; iter: 0; batch classifier loss: 0.075070; batch adversarial loss: 0.550272\n",
      "epoch 164; iter: 0; batch classifier loss: 0.059441; batch adversarial loss: 0.462035\n",
      "epoch 165; iter: 0; batch classifier loss: 0.063799; batch adversarial loss: 0.369428\n",
      "epoch 166; iter: 0; batch classifier loss: 0.057753; batch adversarial loss: 0.412479\n",
      "epoch 167; iter: 0; batch classifier loss: 0.053499; batch adversarial loss: 0.454878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.054915; batch adversarial loss: 0.436780\n",
      "epoch 169; iter: 0; batch classifier loss: 0.048400; batch adversarial loss: 0.416132\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049750; batch adversarial loss: 0.465587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040734; batch adversarial loss: 0.506281\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044185; batch adversarial loss: 0.403571\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040455; batch adversarial loss: 0.360314\n",
      "epoch 174; iter: 0; batch classifier loss: 0.066482; batch adversarial loss: 0.453440\n",
      "epoch 175; iter: 0; batch classifier loss: 0.049997; batch adversarial loss: 0.348323\n",
      "epoch 176; iter: 0; batch classifier loss: 0.055661; batch adversarial loss: 0.364203\n",
      "epoch 177; iter: 0; batch classifier loss: 0.042365; batch adversarial loss: 0.421807\n",
      "epoch 178; iter: 0; batch classifier loss: 0.064286; batch adversarial loss: 0.417636\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038414; batch adversarial loss: 0.342119\n",
      "epoch 180; iter: 0; batch classifier loss: 0.051292; batch adversarial loss: 0.328293\n",
      "epoch 181; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.444507\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023571; batch adversarial loss: 0.453884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039854; batch adversarial loss: 0.435443\n",
      "epoch 184; iter: 0; batch classifier loss: 0.049172; batch adversarial loss: 0.384148\n",
      "epoch 185; iter: 0; batch classifier loss: 0.043235; batch adversarial loss: 0.443337\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044831; batch adversarial loss: 0.504774\n",
      "epoch 187; iter: 0; batch classifier loss: 0.037736; batch adversarial loss: 0.397232\n",
      "epoch 188; iter: 0; batch classifier loss: 0.063947; batch adversarial loss: 0.440197\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034461; batch adversarial loss: 0.487413\n",
      "epoch 190; iter: 0; batch classifier loss: 0.031560; batch adversarial loss: 0.455719\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032272; batch adversarial loss: 0.386022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 192; iter: 0; batch classifier loss: 0.042511; batch adversarial loss: 0.399309\n",
      "epoch 193; iter: 0; batch classifier loss: 0.050896; batch adversarial loss: 0.435597\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041729; batch adversarial loss: 0.378929\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016019; batch adversarial loss: 0.439641\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020455; batch adversarial loss: 0.398490\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012518; batch adversarial loss: 0.528731\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018066; batch adversarial loss: 0.396548\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027660; batch adversarial loss: 0.470870\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730438; batch adversarial loss: 0.598007\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424498; batch adversarial loss: 0.607250\n",
      "epoch 2; iter: 0; batch classifier loss: 0.356396; batch adversarial loss: 0.592056\n",
      "epoch 3; iter: 0; batch classifier loss: 0.294175; batch adversarial loss: 0.587156\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345633; batch adversarial loss: 0.538331\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315529; batch adversarial loss: 0.542686\n",
      "epoch 6; iter: 0; batch classifier loss: 0.391087; batch adversarial loss: 0.507867\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259621; batch adversarial loss: 0.510660\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315744; batch adversarial loss: 0.491050\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306655; batch adversarial loss: 0.466924\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314088; batch adversarial loss: 0.467655\n",
      "epoch 11; iter: 0; batch classifier loss: 0.233059; batch adversarial loss: 0.534287\n",
      "epoch 12; iter: 0; batch classifier loss: 0.204436; batch adversarial loss: 0.451867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241426; batch adversarial loss: 0.448275\n",
      "epoch 14; iter: 0; batch classifier loss: 0.214442; batch adversarial loss: 0.578068\n",
      "epoch 15; iter: 0; batch classifier loss: 0.250021; batch adversarial loss: 0.451303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.187096; batch adversarial loss: 0.522017\n",
      "epoch 17; iter: 0; batch classifier loss: 0.200133; batch adversarial loss: 0.525618\n",
      "epoch 18; iter: 0; batch classifier loss: 0.180581; batch adversarial loss: 0.467391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.174332; batch adversarial loss: 0.474979\n",
      "epoch 20; iter: 0; batch classifier loss: 0.185885; batch adversarial loss: 0.513079\n",
      "epoch 21; iter: 0; batch classifier loss: 0.138420; batch adversarial loss: 0.465608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.182983; batch adversarial loss: 0.561916\n",
      "epoch 23; iter: 0; batch classifier loss: 0.203628; batch adversarial loss: 0.547757\n",
      "epoch 24; iter: 0; batch classifier loss: 0.230313; batch adversarial loss: 0.520357\n",
      "epoch 25; iter: 0; batch classifier loss: 0.231567; batch adversarial loss: 0.509497\n",
      "epoch 26; iter: 0; batch classifier loss: 0.235624; batch adversarial loss: 0.498724\n",
      "epoch 27; iter: 0; batch classifier loss: 0.213362; batch adversarial loss: 0.447432\n",
      "epoch 28; iter: 0; batch classifier loss: 0.261237; batch adversarial loss: 0.561790\n",
      "epoch 29; iter: 0; batch classifier loss: 0.297575; batch adversarial loss: 0.416908\n",
      "epoch 30; iter: 0; batch classifier loss: 0.263905; batch adversarial loss: 0.495335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.143352; batch adversarial loss: 0.481866\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108903; batch adversarial loss: 0.485065\n",
      "epoch 33; iter: 0; batch classifier loss: 0.086353; batch adversarial loss: 0.415463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.106411; batch adversarial loss: 0.435347\n",
      "epoch 35; iter: 0; batch classifier loss: 0.053190; batch adversarial loss: 0.413987\n",
      "epoch 36; iter: 0; batch classifier loss: 0.104692; batch adversarial loss: 0.536022\n",
      "epoch 37; iter: 0; batch classifier loss: 0.058851; batch adversarial loss: 0.472808\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136795; batch adversarial loss: 0.565030\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105462; batch adversarial loss: 0.418184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.118837; batch adversarial loss: 0.494255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084473; batch adversarial loss: 0.476841\n",
      "epoch 42; iter: 0; batch classifier loss: 0.060419; batch adversarial loss: 0.461989\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109087; batch adversarial loss: 0.444108\n",
      "epoch 44; iter: 0; batch classifier loss: 0.062625; batch adversarial loss: 0.500502\n",
      "epoch 45; iter: 0; batch classifier loss: 0.041444; batch adversarial loss: 0.410638\n",
      "epoch 46; iter: 0; batch classifier loss: 0.056979; batch adversarial loss: 0.525959\n",
      "epoch 47; iter: 0; batch classifier loss: 0.054824; batch adversarial loss: 0.389476\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080889; batch adversarial loss: 0.319900\n",
      "epoch 49; iter: 0; batch classifier loss: 0.121257; batch adversarial loss: 0.542990\n",
      "epoch 50; iter: 0; batch classifier loss: 0.077170; batch adversarial loss: 0.430029\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059814; batch adversarial loss: 0.383912\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076970; batch adversarial loss: 0.416598\n",
      "epoch 53; iter: 0; batch classifier loss: 0.051527; batch adversarial loss: 0.478326\n",
      "epoch 54; iter: 0; batch classifier loss: 0.133612; batch adversarial loss: 0.402705\n",
      "epoch 55; iter: 0; batch classifier loss: 0.090261; batch adversarial loss: 0.394290\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064305; batch adversarial loss: 0.435284\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082347; batch adversarial loss: 0.419315\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066479; batch adversarial loss: 0.427364\n",
      "epoch 59; iter: 0; batch classifier loss: 0.054015; batch adversarial loss: 0.417991\n",
      "epoch 60; iter: 0; batch classifier loss: 0.038290; batch adversarial loss: 0.459797\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064773; batch adversarial loss: 0.437957\n",
      "epoch 62; iter: 0; batch classifier loss: 0.030302; batch adversarial loss: 0.389629\n",
      "epoch 63; iter: 0; batch classifier loss: 0.053436; batch adversarial loss: 0.461732\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084283; batch adversarial loss: 0.386955\n",
      "epoch 65; iter: 0; batch classifier loss: 0.055747; batch adversarial loss: 0.414752\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058283; batch adversarial loss: 0.392966\n",
      "epoch 67; iter: 0; batch classifier loss: 0.072302; batch adversarial loss: 0.409783\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068841; batch adversarial loss: 0.508069\n",
      "epoch 69; iter: 0; batch classifier loss: 0.041933; batch adversarial loss: 0.433477\n",
      "epoch 70; iter: 0; batch classifier loss: 0.068010; batch adversarial loss: 0.489380\n",
      "epoch 71; iter: 0; batch classifier loss: 0.105159; batch adversarial loss: 0.480691\n",
      "epoch 72; iter: 0; batch classifier loss: 0.053229; batch adversarial loss: 0.455502\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076095; batch adversarial loss: 0.438996\n",
      "epoch 74; iter: 0; batch classifier loss: 0.100544; batch adversarial loss: 0.539334\n",
      "epoch 75; iter: 0; batch classifier loss: 0.044549; batch adversarial loss: 0.410401\n",
      "epoch 76; iter: 0; batch classifier loss: 0.064200; batch adversarial loss: 0.451999\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088098; batch adversarial loss: 0.492100\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037971; batch adversarial loss: 0.469233\n",
      "epoch 79; iter: 0; batch classifier loss: 0.028917; batch adversarial loss: 0.486114\n",
      "epoch 80; iter: 0; batch classifier loss: 0.075742; batch adversarial loss: 0.441396\n",
      "epoch 81; iter: 0; batch classifier loss: 0.092265; batch adversarial loss: 0.475535\n",
      "epoch 82; iter: 0; batch classifier loss: 0.041779; batch adversarial loss: 0.371596\n",
      "epoch 83; iter: 0; batch classifier loss: 0.044759; batch adversarial loss: 0.394877\n",
      "epoch 84; iter: 0; batch classifier loss: 0.069844; batch adversarial loss: 0.487563\n",
      "epoch 85; iter: 0; batch classifier loss: 0.089154; batch adversarial loss: 0.448725\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043470; batch adversarial loss: 0.383439\n",
      "epoch 87; iter: 0; batch classifier loss: 0.041846; batch adversarial loss: 0.430221\n",
      "epoch 88; iter: 0; batch classifier loss: 0.043410; batch adversarial loss: 0.421413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.051266; batch adversarial loss: 0.420551\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073676; batch adversarial loss: 0.467094\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035096; batch adversarial loss: 0.459607\n",
      "epoch 92; iter: 0; batch classifier loss: 0.030572; batch adversarial loss: 0.415197\n",
      "epoch 93; iter: 0; batch classifier loss: 0.041836; batch adversarial loss: 0.338435\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084217; batch adversarial loss: 0.471629\n",
      "epoch 95; iter: 0; batch classifier loss: 0.031182; batch adversarial loss: 0.553912\n",
      "epoch 96; iter: 0; batch classifier loss: 0.039415; batch adversarial loss: 0.395426\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046106; batch adversarial loss: 0.396067\n",
      "epoch 98; iter: 0; batch classifier loss: 0.035403; batch adversarial loss: 0.437299\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053450; batch adversarial loss: 0.518896\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043217; batch adversarial loss: 0.496542\n",
      "epoch 101; iter: 0; batch classifier loss: 0.027244; batch adversarial loss: 0.339723\n",
      "epoch 102; iter: 0; batch classifier loss: 0.046196; batch adversarial loss: 0.518623\n",
      "epoch 103; iter: 0; batch classifier loss: 0.040051; batch adversarial loss: 0.457932\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031153; batch adversarial loss: 0.454430\n",
      "epoch 105; iter: 0; batch classifier loss: 0.082626; batch adversarial loss: 0.463163\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044992; batch adversarial loss: 0.430419\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033183; batch adversarial loss: 0.401616\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034063; batch adversarial loss: 0.452079\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070834; batch adversarial loss: 0.336329\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050054; batch adversarial loss: 0.508683\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054262; batch adversarial loss: 0.468522\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059935; batch adversarial loss: 0.523000\n",
      "epoch 113; iter: 0; batch classifier loss: 0.086329; batch adversarial loss: 0.394570\n",
      "epoch 114; iter: 0; batch classifier loss: 0.074467; batch adversarial loss: 0.405467\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074965; batch adversarial loss: 0.405890\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036834; batch adversarial loss: 0.444652\n",
      "epoch 117; iter: 0; batch classifier loss: 0.036536; batch adversarial loss: 0.436740\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029375; batch adversarial loss: 0.414810\n",
      "epoch 119; iter: 0; batch classifier loss: 0.034183; batch adversarial loss: 0.404755\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041502; batch adversarial loss: 0.503148\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028741; batch adversarial loss: 0.446479\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017318; batch adversarial loss: 0.521337\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030053; batch adversarial loss: 0.479134\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052792; batch adversarial loss: 0.474475\n",
      "epoch 125; iter: 0; batch classifier loss: 0.036588; batch adversarial loss: 0.467276\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051492; batch adversarial loss: 0.368526\n",
      "epoch 127; iter: 0; batch classifier loss: 0.082943; batch adversarial loss: 0.378251\n",
      "epoch 128; iter: 0; batch classifier loss: 0.053730; batch adversarial loss: 0.376884\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045943; batch adversarial loss: 0.483994\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041810; batch adversarial loss: 0.582092\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038352; batch adversarial loss: 0.477906\n",
      "epoch 132; iter: 0; batch classifier loss: 0.018145; batch adversarial loss: 0.472406\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039800; batch adversarial loss: 0.467202\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053170; batch adversarial loss: 0.408593\n",
      "epoch 135; iter: 0; batch classifier loss: 0.071728; batch adversarial loss: 0.433551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025002; batch adversarial loss: 0.528345\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031524; batch adversarial loss: 0.481762\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023502; batch adversarial loss: 0.422230\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019204; batch adversarial loss: 0.463774\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045816; batch adversarial loss: 0.448637\n",
      "epoch 141; iter: 0; batch classifier loss: 0.038648; batch adversarial loss: 0.513190\n",
      "epoch 142; iter: 0; batch classifier loss: 0.021104; batch adversarial loss: 0.437336\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035888; batch adversarial loss: 0.450263\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040508; batch adversarial loss: 0.414948\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024350; batch adversarial loss: 0.451335\n",
      "epoch 146; iter: 0; batch classifier loss: 0.039823; batch adversarial loss: 0.504792\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042564; batch adversarial loss: 0.454729\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011964; batch adversarial loss: 0.380267\n",
      "epoch 149; iter: 0; batch classifier loss: 0.018780; batch adversarial loss: 0.510226\n",
      "epoch 150; iter: 0; batch classifier loss: 0.035516; batch adversarial loss: 0.366545\n",
      "epoch 151; iter: 0; batch classifier loss: 0.026225; batch adversarial loss: 0.463475\n",
      "epoch 152; iter: 0; batch classifier loss: 0.040720; batch adversarial loss: 0.449034\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020112; batch adversarial loss: 0.415696\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027759; batch adversarial loss: 0.514149\n",
      "epoch 155; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.368909\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025378; batch adversarial loss: 0.498197\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022565; batch adversarial loss: 0.426272\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025613; batch adversarial loss: 0.420720\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013573; batch adversarial loss: 0.406275\n",
      "epoch 160; iter: 0; batch classifier loss: 0.052210; batch adversarial loss: 0.453408\n",
      "epoch 161; iter: 0; batch classifier loss: 0.014417; batch adversarial loss: 0.481839\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052313; batch adversarial loss: 0.458205\n",
      "epoch 163; iter: 0; batch classifier loss: 0.016548; batch adversarial loss: 0.439920\n",
      "epoch 164; iter: 0; batch classifier loss: 0.033050; batch adversarial loss: 0.439268\n",
      "epoch 165; iter: 0; batch classifier loss: 0.017769; batch adversarial loss: 0.397744\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024834; batch adversarial loss: 0.427570\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021158; batch adversarial loss: 0.448635\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026602; batch adversarial loss: 0.386278\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039725; batch adversarial loss: 0.473396\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031657; batch adversarial loss: 0.419714\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011729; batch adversarial loss: 0.523500\n",
      "epoch 172; iter: 0; batch classifier loss: 0.083069; batch adversarial loss: 0.417454\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016501; batch adversarial loss: 0.483120\n",
      "epoch 174; iter: 0; batch classifier loss: 0.023881; batch adversarial loss: 0.485952\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013130; batch adversarial loss: 0.404580\n",
      "epoch 176; iter: 0; batch classifier loss: 0.021785; batch adversarial loss: 0.453078\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020106; batch adversarial loss: 0.570992\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029688; batch adversarial loss: 0.438423\n",
      "epoch 179; iter: 0; batch classifier loss: 0.009845; batch adversarial loss: 0.480259\n",
      "epoch 180; iter: 0; batch classifier loss: 0.011675; batch adversarial loss: 0.330544\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025223; batch adversarial loss: 0.343151\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032790; batch adversarial loss: 0.531279\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029767; batch adversarial loss: 0.504178\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034755; batch adversarial loss: 0.435797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.019817; batch adversarial loss: 0.395072\n",
      "epoch 186; iter: 0; batch classifier loss: 0.017839; batch adversarial loss: 0.373648\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045914; batch adversarial loss: 0.436521\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006867; batch adversarial loss: 0.367320\n",
      "epoch 189; iter: 0; batch classifier loss: 0.010143; batch adversarial loss: 0.504041\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021954; batch adversarial loss: 0.401850\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021162; batch adversarial loss: 0.364235\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026968; batch adversarial loss: 0.429938\n",
      "epoch 193; iter: 0; batch classifier loss: 0.032619; batch adversarial loss: 0.523063\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024196; batch adversarial loss: 0.461980\n",
      "epoch 195; iter: 0; batch classifier loss: 0.041547; batch adversarial loss: 0.430756\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004830; batch adversarial loss: 0.459294\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013534; batch adversarial loss: 0.460257\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008715; batch adversarial loss: 0.469528\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015157; batch adversarial loss: 0.539225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674971; batch adversarial loss: 0.687964\n",
      "epoch 1; iter: 0; batch classifier loss: 0.531357; batch adversarial loss: 0.648423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.435200; batch adversarial loss: 0.644945\n",
      "epoch 3; iter: 0; batch classifier loss: 0.409294; batch adversarial loss: 0.622733\n",
      "epoch 4; iter: 0; batch classifier loss: 0.433737; batch adversarial loss: 0.613005\n",
      "epoch 5; iter: 0; batch classifier loss: 0.400521; batch adversarial loss: 0.580116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497693; batch adversarial loss: 0.594371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513118; batch adversarial loss: 0.542267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507705; batch adversarial loss: 0.549391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357831; batch adversarial loss: 0.558701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406410; batch adversarial loss: 0.543296\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409595; batch adversarial loss: 0.552994\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412975; batch adversarial loss: 0.531633\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379947; batch adversarial loss: 0.485970\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348241; batch adversarial loss: 0.543473\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347314; batch adversarial loss: 0.468977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334245; batch adversarial loss: 0.441676\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329601; batch adversarial loss: 0.504737\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359609; batch adversarial loss: 0.502587\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312325; batch adversarial loss: 0.487750\n",
      "epoch 20; iter: 0; batch classifier loss: 0.274690; batch adversarial loss: 0.464221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308875; batch adversarial loss: 0.450652\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291225; batch adversarial loss: 0.474312\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288960; batch adversarial loss: 0.496903\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253135; batch adversarial loss: 0.494629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288515; batch adversarial loss: 0.487112\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209256; batch adversarial loss: 0.418017\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241601; batch adversarial loss: 0.552269\n",
      "epoch 28; iter: 0; batch classifier loss: 0.229697; batch adversarial loss: 0.537407\n",
      "epoch 29; iter: 0; batch classifier loss: 0.233421; batch adversarial loss: 0.450362\n",
      "epoch 30; iter: 0; batch classifier loss: 0.215620; batch adversarial loss: 0.487608\n",
      "epoch 31; iter: 0; batch classifier loss: 0.236528; batch adversarial loss: 0.452906\n",
      "epoch 32; iter: 0; batch classifier loss: 0.202371; batch adversarial loss: 0.372457\n",
      "epoch 33; iter: 0; batch classifier loss: 0.256691; batch adversarial loss: 0.469104\n",
      "epoch 34; iter: 0; batch classifier loss: 0.281237; batch adversarial loss: 0.438963\n",
      "epoch 35; iter: 0; batch classifier loss: 0.255740; batch adversarial loss: 0.470862\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279983; batch adversarial loss: 0.440814\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210994; batch adversarial loss: 0.428151\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232756; batch adversarial loss: 0.507842\n",
      "epoch 39; iter: 0; batch classifier loss: 0.222538; batch adversarial loss: 0.482698\n",
      "epoch 40; iter: 0; batch classifier loss: 0.234044; batch adversarial loss: 0.494580\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358060; batch adversarial loss: 0.368384\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137907; batch adversarial loss: 0.436088\n",
      "epoch 43; iter: 0; batch classifier loss: 0.131226; batch adversarial loss: 0.447338\n",
      "epoch 44; iter: 0; batch classifier loss: 0.118109; batch adversarial loss: 0.482401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.220713; batch adversarial loss: 0.426700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.137930; batch adversarial loss: 0.435242\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169388; batch adversarial loss: 0.411768\n",
      "epoch 48; iter: 0; batch classifier loss: 0.158126; batch adversarial loss: 0.506853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162600; batch adversarial loss: 0.412541\n",
      "epoch 50; iter: 0; batch classifier loss: 0.291107; batch adversarial loss: 0.387335\n",
      "epoch 51; iter: 0; batch classifier loss: 0.146477; batch adversarial loss: 0.398632\n",
      "epoch 52; iter: 0; batch classifier loss: 0.168390; batch adversarial loss: 0.470859\n",
      "epoch 53; iter: 0; batch classifier loss: 0.224374; batch adversarial loss: 0.483216\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099708; batch adversarial loss: 0.531755\n",
      "epoch 55; iter: 0; batch classifier loss: 0.122737; batch adversarial loss: 0.310241\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091213; batch adversarial loss: 0.429569\n",
      "epoch 57; iter: 0; batch classifier loss: 0.078654; batch adversarial loss: 0.495640\n",
      "epoch 58; iter: 0; batch classifier loss: 0.091003; batch adversarial loss: 0.445650\n",
      "epoch 59; iter: 0; batch classifier loss: 0.163330; batch adversarial loss: 0.442752\n",
      "epoch 60; iter: 0; batch classifier loss: 0.185988; batch adversarial loss: 0.408254\n",
      "epoch 61; iter: 0; batch classifier loss: 0.186905; batch adversarial loss: 0.508136\n",
      "epoch 62; iter: 0; batch classifier loss: 0.091946; batch adversarial loss: 0.457322\n",
      "epoch 63; iter: 0; batch classifier loss: 0.115024; batch adversarial loss: 0.519082\n",
      "epoch 64; iter: 0; batch classifier loss: 0.142129; batch adversarial loss: 0.434627\n",
      "epoch 65; iter: 0; batch classifier loss: 0.214154; batch adversarial loss: 0.461133\n",
      "epoch 66; iter: 0; batch classifier loss: 0.175469; batch adversarial loss: 0.620703\n",
      "epoch 67; iter: 0; batch classifier loss: 0.214284; batch adversarial loss: 0.384244\n",
      "epoch 68; iter: 0; batch classifier loss: 0.096647; batch adversarial loss: 0.458473\n",
      "epoch 69; iter: 0; batch classifier loss: 0.227701; batch adversarial loss: 0.348828\n",
      "epoch 70; iter: 0; batch classifier loss: 0.137664; batch adversarial loss: 0.531524\n",
      "epoch 71; iter: 0; batch classifier loss: 0.186254; batch adversarial loss: 0.496022\n",
      "epoch 72; iter: 0; batch classifier loss: 0.066135; batch adversarial loss: 0.544540\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065356; batch adversarial loss: 0.482736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054820; batch adversarial loss: 0.426205\n",
      "epoch 75; iter: 0; batch classifier loss: 0.068460; batch adversarial loss: 0.517630\n",
      "epoch 76; iter: 0; batch classifier loss: 0.040027; batch adversarial loss: 0.478425\n",
      "epoch 77; iter: 0; batch classifier loss: 0.052414; batch adversarial loss: 0.473327\n",
      "epoch 78; iter: 0; batch classifier loss: 0.030832; batch adversarial loss: 0.511625\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053824; batch adversarial loss: 0.361486\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045317; batch adversarial loss: 0.477907\n",
      "epoch 81; iter: 0; batch classifier loss: 0.041760; batch adversarial loss: 0.536859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.051311; batch adversarial loss: 0.312576\n",
      "epoch 83; iter: 0; batch classifier loss: 0.050469; batch adversarial loss: 0.526756\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056017; batch adversarial loss: 0.543159\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092435; batch adversarial loss: 0.374556\n",
      "epoch 86; iter: 0; batch classifier loss: 0.040409; batch adversarial loss: 0.384899\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047781; batch adversarial loss: 0.600452\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057349; batch adversarial loss: 0.497904\n",
      "epoch 89; iter: 0; batch classifier loss: 0.092153; batch adversarial loss: 0.406150\n",
      "epoch 90; iter: 0; batch classifier loss: 0.074425; batch adversarial loss: 0.342977\n",
      "epoch 91; iter: 0; batch classifier loss: 0.060984; batch adversarial loss: 0.333945\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084407; batch adversarial loss: 0.465138\n",
      "epoch 93; iter: 0; batch classifier loss: 0.052821; batch adversarial loss: 0.391219\n",
      "epoch 94; iter: 0; batch classifier loss: 0.056503; batch adversarial loss: 0.443611\n",
      "epoch 95; iter: 0; batch classifier loss: 0.094830; batch adversarial loss: 0.397554\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060312; batch adversarial loss: 0.512224\n",
      "epoch 97; iter: 0; batch classifier loss: 0.102272; batch adversarial loss: 0.437214\n",
      "epoch 98; iter: 0; batch classifier loss: 0.047737; batch adversarial loss: 0.434653\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070269; batch adversarial loss: 0.468656\n",
      "epoch 100; iter: 0; batch classifier loss: 0.063338; batch adversarial loss: 0.563331\n",
      "epoch 101; iter: 0; batch classifier loss: 0.056992; batch adversarial loss: 0.393035\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051284; batch adversarial loss: 0.450926\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042739; batch adversarial loss: 0.491903\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072711; batch adversarial loss: 0.476282\n",
      "epoch 105; iter: 0; batch classifier loss: 0.046054; batch adversarial loss: 0.453957\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034480; batch adversarial loss: 0.511627\n",
      "epoch 107; iter: 0; batch classifier loss: 0.047974; batch adversarial loss: 0.440832\n",
      "epoch 108; iter: 0; batch classifier loss: 0.086059; batch adversarial loss: 0.505514\n",
      "epoch 109; iter: 0; batch classifier loss: 0.056621; batch adversarial loss: 0.439999\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056954; batch adversarial loss: 0.524912\n",
      "epoch 111; iter: 0; batch classifier loss: 0.061838; batch adversarial loss: 0.457308\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043551; batch adversarial loss: 0.426642\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081846; batch adversarial loss: 0.418218\n",
      "epoch 114; iter: 0; batch classifier loss: 0.066043; batch adversarial loss: 0.435541\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039158; batch adversarial loss: 0.483920\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071065; batch adversarial loss: 0.378184\n",
      "epoch 117; iter: 0; batch classifier loss: 0.081830; batch adversarial loss: 0.420885\n",
      "epoch 118; iter: 0; batch classifier loss: 0.048829; batch adversarial loss: 0.406673\n",
      "epoch 119; iter: 0; batch classifier loss: 0.043458; batch adversarial loss: 0.457341\n",
      "epoch 120; iter: 0; batch classifier loss: 0.085071; batch adversarial loss: 0.448413\n",
      "epoch 121; iter: 0; batch classifier loss: 0.079493; batch adversarial loss: 0.384223\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055510; batch adversarial loss: 0.472691\n",
      "epoch 123; iter: 0; batch classifier loss: 0.040436; batch adversarial loss: 0.343388\n",
      "epoch 124; iter: 0; batch classifier loss: 0.073680; batch adversarial loss: 0.398701\n",
      "epoch 125; iter: 0; batch classifier loss: 0.075008; batch adversarial loss: 0.366324\n",
      "epoch 126; iter: 0; batch classifier loss: 0.057954; batch adversarial loss: 0.434941\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056911; batch adversarial loss: 0.420983\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036787; batch adversarial loss: 0.470690\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029549; batch adversarial loss: 0.448736\n",
      "epoch 130; iter: 0; batch classifier loss: 0.065015; batch adversarial loss: 0.463929\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043383; batch adversarial loss: 0.425359\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062680; batch adversarial loss: 0.402387\n",
      "epoch 133; iter: 0; batch classifier loss: 0.074099; batch adversarial loss: 0.440755\n",
      "epoch 134; iter: 0; batch classifier loss: 0.053702; batch adversarial loss: 0.373850\n",
      "epoch 135; iter: 0; batch classifier loss: 0.066578; batch adversarial loss: 0.452324\n",
      "epoch 136; iter: 0; batch classifier loss: 0.064742; batch adversarial loss: 0.427013\n",
      "epoch 137; iter: 0; batch classifier loss: 0.063275; batch adversarial loss: 0.400764\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043818; batch adversarial loss: 0.466198\n",
      "epoch 139; iter: 0; batch classifier loss: 0.056696; batch adversarial loss: 0.466307\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.504092\n",
      "epoch 141; iter: 0; batch classifier loss: 0.067971; batch adversarial loss: 0.433169\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027988; batch adversarial loss: 0.454839\n",
      "epoch 143; iter: 0; batch classifier loss: 0.051852; batch adversarial loss: 0.435943\n",
      "epoch 144; iter: 0; batch classifier loss: 0.053809; batch adversarial loss: 0.423954\n",
      "epoch 145; iter: 0; batch classifier loss: 0.069645; batch adversarial loss: 0.349249\n",
      "epoch 146; iter: 0; batch classifier loss: 0.088294; batch adversarial loss: 0.491284\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039675; batch adversarial loss: 0.405685\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043964; batch adversarial loss: 0.493776\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044446; batch adversarial loss: 0.540415\n",
      "epoch 150; iter: 0; batch classifier loss: 0.074689; batch adversarial loss: 0.466676\n",
      "epoch 151; iter: 0; batch classifier loss: 0.055089; batch adversarial loss: 0.447397\n",
      "epoch 152; iter: 0; batch classifier loss: 0.072071; batch adversarial loss: 0.347010\n",
      "epoch 153; iter: 0; batch classifier loss: 0.074734; batch adversarial loss: 0.339756\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026864; batch adversarial loss: 0.466812\n",
      "epoch 155; iter: 0; batch classifier loss: 0.042098; batch adversarial loss: 0.375548\n",
      "epoch 156; iter: 0; batch classifier loss: 0.071016; batch adversarial loss: 0.364678\n",
      "epoch 157; iter: 0; batch classifier loss: 0.035534; batch adversarial loss: 0.401542\n",
      "epoch 158; iter: 0; batch classifier loss: 0.059145; batch adversarial loss: 0.459845\n",
      "epoch 159; iter: 0; batch classifier loss: 0.075956; batch adversarial loss: 0.393926\n",
      "epoch 160; iter: 0; batch classifier loss: 0.068594; batch adversarial loss: 0.333839\n",
      "epoch 161; iter: 0; batch classifier loss: 0.039449; batch adversarial loss: 0.432966\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031505; batch adversarial loss: 0.455718\n",
      "epoch 163; iter: 0; batch classifier loss: 0.055213; batch adversarial loss: 0.523126\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031792; batch adversarial loss: 0.335737\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037377; batch adversarial loss: 0.475894\n",
      "epoch 166; iter: 0; batch classifier loss: 0.074621; batch adversarial loss: 0.434545\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026416; batch adversarial loss: 0.522931\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025988; batch adversarial loss: 0.405324\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049089; batch adversarial loss: 0.473800\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028177; batch adversarial loss: 0.461352\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021845; batch adversarial loss: 0.517649\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026302; batch adversarial loss: 0.476128\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039979; batch adversarial loss: 0.455353\n",
      "epoch 174; iter: 0; batch classifier loss: 0.046559; batch adversarial loss: 0.388931\n",
      "epoch 175; iter: 0; batch classifier loss: 0.034462; batch adversarial loss: 0.373437\n",
      "epoch 176; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.406083\n",
      "epoch 177; iter: 0; batch classifier loss: 0.040495; batch adversarial loss: 0.414903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.041255; batch adversarial loss: 0.434188\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023398; batch adversarial loss: 0.494344\n",
      "epoch 180; iter: 0; batch classifier loss: 0.057851; batch adversarial loss: 0.523309\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028293; batch adversarial loss: 0.547859\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029333; batch adversarial loss: 0.440320\n",
      "epoch 183; iter: 0; batch classifier loss: 0.033200; batch adversarial loss: 0.439142\n",
      "epoch 184; iter: 0; batch classifier loss: 0.022835; batch adversarial loss: 0.459465\n",
      "epoch 185; iter: 0; batch classifier loss: 0.045145; batch adversarial loss: 0.417386\n",
      "epoch 186; iter: 0; batch classifier loss: 0.044142; batch adversarial loss: 0.445815\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031296; batch adversarial loss: 0.258898\n",
      "epoch 188; iter: 0; batch classifier loss: 0.039158; batch adversarial loss: 0.497882\n",
      "epoch 189; iter: 0; batch classifier loss: 0.062341; batch adversarial loss: 0.399457\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023425; batch adversarial loss: 0.391632\n",
      "epoch 191; iter: 0; batch classifier loss: 0.030656; batch adversarial loss: 0.461213\n",
      "epoch 192; iter: 0; batch classifier loss: 0.025605; batch adversarial loss: 0.502142\n",
      "epoch 193; iter: 0; batch classifier loss: 0.046211; batch adversarial loss: 0.476426\n",
      "epoch 194; iter: 0; batch classifier loss: 0.016985; batch adversarial loss: 0.520126\n",
      "epoch 195; iter: 0; batch classifier loss: 0.043952; batch adversarial loss: 0.469001\n",
      "epoch 196; iter: 0; batch classifier loss: 0.062282; batch adversarial loss: 0.394517\n",
      "epoch 197; iter: 0; batch classifier loss: 0.025405; batch adversarial loss: 0.423317\n",
      "epoch 198; iter: 0; batch classifier loss: 0.029415; batch adversarial loss: 0.468114\n",
      "epoch 199; iter: 0; batch classifier loss: 0.013040; batch adversarial loss: 0.456094\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693262; batch adversarial loss: 0.629396\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476809; batch adversarial loss: 0.619954\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467436; batch adversarial loss: 0.622778\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381395; batch adversarial loss: 0.605743\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498668; batch adversarial loss: 0.587390\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541930; batch adversarial loss: 0.595282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574191; batch adversarial loss: 0.590529\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507584; batch adversarial loss: 0.560820\n",
      "epoch 8; iter: 0; batch classifier loss: 0.427804; batch adversarial loss: 0.569150\n",
      "epoch 9; iter: 0; batch classifier loss: 0.427867; batch adversarial loss: 0.545036\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400302; batch adversarial loss: 0.490527\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345313; batch adversarial loss: 0.475785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447773; batch adversarial loss: 0.454478\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358916; batch adversarial loss: 0.462706\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370668; batch adversarial loss: 0.486360\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385408; batch adversarial loss: 0.508491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325101; batch adversarial loss: 0.525142\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409189; batch adversarial loss: 0.488565\n",
      "epoch 18; iter: 0; batch classifier loss: 0.283334; batch adversarial loss: 0.530608\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311642; batch adversarial loss: 0.449201\n",
      "epoch 20; iter: 0; batch classifier loss: 0.263179; batch adversarial loss: 0.500674\n",
      "epoch 21; iter: 0; batch classifier loss: 0.299759; batch adversarial loss: 0.530332\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297693; batch adversarial loss: 0.421331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248515; batch adversarial loss: 0.408682\n",
      "epoch 24; iter: 0; batch classifier loss: 0.277871; batch adversarial loss: 0.458656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.289464; batch adversarial loss: 0.446432\n",
      "epoch 26; iter: 0; batch classifier loss: 0.294098; batch adversarial loss: 0.490531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254969; batch adversarial loss: 0.458032\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300951; batch adversarial loss: 0.389161\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210662; batch adversarial loss: 0.418553\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180177; batch adversarial loss: 0.469361\n",
      "epoch 31; iter: 0; batch classifier loss: 0.235907; batch adversarial loss: 0.489118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197671; batch adversarial loss: 0.419125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.285584; batch adversarial loss: 0.431094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184420; batch adversarial loss: 0.464889\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278523; batch adversarial loss: 0.417819\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182739; batch adversarial loss: 0.507425\n",
      "epoch 37; iter: 0; batch classifier loss: 0.225293; batch adversarial loss: 0.412483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.212349; batch adversarial loss: 0.466170\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200036; batch adversarial loss: 0.454854\n",
      "epoch 40; iter: 0; batch classifier loss: 0.207873; batch adversarial loss: 0.460642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148784; batch adversarial loss: 0.493988\n",
      "epoch 42; iter: 0; batch classifier loss: 0.209616; batch adversarial loss: 0.501432\n",
      "epoch 43; iter: 0; batch classifier loss: 0.245874; batch adversarial loss: 0.462365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.257082; batch adversarial loss: 0.447764\n",
      "epoch 45; iter: 0; batch classifier loss: 0.230701; batch adversarial loss: 0.399398\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256387; batch adversarial loss: 0.470931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.169742; batch adversarial loss: 0.447591\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170220; batch adversarial loss: 0.434871\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220366; batch adversarial loss: 0.496161\n",
      "epoch 50; iter: 0; batch classifier loss: 0.246048; batch adversarial loss: 0.531600\n",
      "epoch 51; iter: 0; batch classifier loss: 0.252437; batch adversarial loss: 0.372051\n",
      "epoch 52; iter: 0; batch classifier loss: 0.110759; batch adversarial loss: 0.520176\n",
      "epoch 53; iter: 0; batch classifier loss: 0.153103; batch adversarial loss: 0.558172\n",
      "epoch 54; iter: 0; batch classifier loss: 0.257789; batch adversarial loss: 0.472921\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125265; batch adversarial loss: 0.446394\n",
      "epoch 56; iter: 0; batch classifier loss: 0.134695; batch adversarial loss: 0.496289\n",
      "epoch 57; iter: 0; batch classifier loss: 0.251061; batch adversarial loss: 0.409532\n",
      "epoch 58; iter: 0; batch classifier loss: 0.137109; batch adversarial loss: 0.396635\n",
      "epoch 59; iter: 0; batch classifier loss: 0.136603; batch adversarial loss: 0.508820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.232028; batch adversarial loss: 0.471018\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114178; batch adversarial loss: 0.370464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.122397; batch adversarial loss: 0.409266\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138293; batch adversarial loss: 0.546584\n",
      "epoch 64; iter: 0; batch classifier loss: 0.233187; batch adversarial loss: 0.484805\n",
      "epoch 65; iter: 0; batch classifier loss: 0.144844; batch adversarial loss: 0.421284\n",
      "epoch 66; iter: 0; batch classifier loss: 0.105855; batch adversarial loss: 0.525200\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142771; batch adversarial loss: 0.369255\n",
      "epoch 68; iter: 0; batch classifier loss: 0.235910; batch adversarial loss: 0.395455\n",
      "epoch 69; iter: 0; batch classifier loss: 0.168470; batch adversarial loss: 0.409488\n",
      "epoch 70; iter: 0; batch classifier loss: 0.167965; batch adversarial loss: 0.471246\n",
      "epoch 71; iter: 0; batch classifier loss: 0.234672; batch adversarial loss: 0.471060\n",
      "epoch 72; iter: 0; batch classifier loss: 0.229522; batch adversarial loss: 0.460375\n",
      "epoch 73; iter: 0; batch classifier loss: 0.126226; batch adversarial loss: 0.545952\n",
      "epoch 74; iter: 0; batch classifier loss: 0.106628; batch adversarial loss: 0.419316\n",
      "epoch 75; iter: 0; batch classifier loss: 0.106523; batch adversarial loss: 0.559219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76; iter: 0; batch classifier loss: 0.137485; batch adversarial loss: 0.373168\n",
      "epoch 77; iter: 0; batch classifier loss: 0.103021; batch adversarial loss: 0.366591\n",
      "epoch 78; iter: 0; batch classifier loss: 0.182422; batch adversarial loss: 0.382352\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115330; batch adversarial loss: 0.526452\n",
      "epoch 80; iter: 0; batch classifier loss: 0.117840; batch adversarial loss: 0.497960\n",
      "epoch 81; iter: 0; batch classifier loss: 0.133195; batch adversarial loss: 0.443044\n",
      "epoch 82; iter: 0; batch classifier loss: 0.090515; batch adversarial loss: 0.516570\n",
      "epoch 83; iter: 0; batch classifier loss: 0.104139; batch adversarial loss: 0.378968\n",
      "epoch 84; iter: 0; batch classifier loss: 0.066969; batch adversarial loss: 0.441498\n",
      "epoch 85; iter: 0; batch classifier loss: 0.062429; batch adversarial loss: 0.354437\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102156; batch adversarial loss: 0.430989\n",
      "epoch 87; iter: 0; batch classifier loss: 0.095788; batch adversarial loss: 0.397026\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070508; batch adversarial loss: 0.436123\n",
      "epoch 89; iter: 0; batch classifier loss: 0.106221; batch adversarial loss: 0.369504\n",
      "epoch 90; iter: 0; batch classifier loss: 0.060278; batch adversarial loss: 0.448628\n",
      "epoch 91; iter: 0; batch classifier loss: 0.061905; batch adversarial loss: 0.407396\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084687; batch adversarial loss: 0.527800\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119745; batch adversarial loss: 0.387877\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075729; batch adversarial loss: 0.495447\n",
      "epoch 95; iter: 0; batch classifier loss: 0.073599; batch adversarial loss: 0.359246\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064303; batch adversarial loss: 0.438318\n",
      "epoch 97; iter: 0; batch classifier loss: 0.064633; batch adversarial loss: 0.525067\n",
      "epoch 98; iter: 0; batch classifier loss: 0.048453; batch adversarial loss: 0.597970\n",
      "epoch 99; iter: 0; batch classifier loss: 0.119566; batch adversarial loss: 0.401914\n",
      "epoch 100; iter: 0; batch classifier loss: 0.085698; batch adversarial loss: 0.363200\n",
      "epoch 101; iter: 0; batch classifier loss: 0.064455; batch adversarial loss: 0.422465\n",
      "epoch 102; iter: 0; batch classifier loss: 0.073134; batch adversarial loss: 0.460386\n",
      "epoch 103; iter: 0; batch classifier loss: 0.083980; batch adversarial loss: 0.391928\n",
      "epoch 104; iter: 0; batch classifier loss: 0.072787; batch adversarial loss: 0.353190\n",
      "epoch 105; iter: 0; batch classifier loss: 0.031132; batch adversarial loss: 0.475236\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061636; batch adversarial loss: 0.357720\n",
      "epoch 107; iter: 0; batch classifier loss: 0.038504; batch adversarial loss: 0.491791\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.380745\n",
      "epoch 109; iter: 0; batch classifier loss: 0.046563; batch adversarial loss: 0.404526\n",
      "epoch 110; iter: 0; batch classifier loss: 0.025469; batch adversarial loss: 0.378684\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029255; batch adversarial loss: 0.452648\n",
      "epoch 112; iter: 0; batch classifier loss: 0.078597; batch adversarial loss: 0.488528\n",
      "epoch 113; iter: 0; batch classifier loss: 0.018472; batch adversarial loss: 0.458655\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045471; batch adversarial loss: 0.459030\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054088; batch adversarial loss: 0.452009\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034395; batch adversarial loss: 0.425587\n",
      "epoch 117; iter: 0; batch classifier loss: 0.058171; batch adversarial loss: 0.380472\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045344; batch adversarial loss: 0.487307\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033227; batch adversarial loss: 0.432601\n",
      "epoch 120; iter: 0; batch classifier loss: 0.057132; batch adversarial loss: 0.452879\n",
      "epoch 121; iter: 0; batch classifier loss: 0.043318; batch adversarial loss: 0.483823\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031322; batch adversarial loss: 0.424364\n",
      "epoch 123; iter: 0; batch classifier loss: 0.035723; batch adversarial loss: 0.409060\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031751; batch adversarial loss: 0.330713\n",
      "epoch 125; iter: 0; batch classifier loss: 0.016031; batch adversarial loss: 0.438484\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050618; batch adversarial loss: 0.518085\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048018; batch adversarial loss: 0.430872\n",
      "epoch 128; iter: 0; batch classifier loss: 0.031443; batch adversarial loss: 0.486039\n",
      "epoch 129; iter: 0; batch classifier loss: 0.015088; batch adversarial loss: 0.380359\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048885; batch adversarial loss: 0.472118\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033220; batch adversarial loss: 0.415215\n",
      "epoch 132; iter: 0; batch classifier loss: 0.025915; batch adversarial loss: 0.525003\n",
      "epoch 133; iter: 0; batch classifier loss: 0.014214; batch adversarial loss: 0.557487\n",
      "epoch 134; iter: 0; batch classifier loss: 0.028333; batch adversarial loss: 0.442256\n",
      "epoch 135; iter: 0; batch classifier loss: 0.018139; batch adversarial loss: 0.466160\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039044; batch adversarial loss: 0.431569\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015521; batch adversarial loss: 0.324276\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040165; batch adversarial loss: 0.503359\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017718; batch adversarial loss: 0.432438\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041228; batch adversarial loss: 0.497248\n",
      "epoch 141; iter: 0; batch classifier loss: 0.039777; batch adversarial loss: 0.424436\n",
      "epoch 142; iter: 0; batch classifier loss: 0.059676; batch adversarial loss: 0.465521\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025245; batch adversarial loss: 0.474005\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031369; batch adversarial loss: 0.429829\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023778; batch adversarial loss: 0.437962\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018381; batch adversarial loss: 0.441127\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014717; batch adversarial loss: 0.454787\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038909; batch adversarial loss: 0.499654\n",
      "epoch 149; iter: 0; batch classifier loss: 0.033448; batch adversarial loss: 0.389080\n",
      "epoch 150; iter: 0; batch classifier loss: 0.055714; batch adversarial loss: 0.424822\n",
      "epoch 151; iter: 0; batch classifier loss: 0.078820; batch adversarial loss: 0.454140\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038238; batch adversarial loss: 0.375172\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031614; batch adversarial loss: 0.428078\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030442; batch adversarial loss: 0.388958\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012192; batch adversarial loss: 0.541398\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039158; batch adversarial loss: 0.460010\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015985; batch adversarial loss: 0.383814\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027209; batch adversarial loss: 0.468483\n",
      "epoch 159; iter: 0; batch classifier loss: 0.034317; batch adversarial loss: 0.513843\n",
      "epoch 160; iter: 0; batch classifier loss: 0.029935; batch adversarial loss: 0.406477\n",
      "epoch 161; iter: 0; batch classifier loss: 0.086888; batch adversarial loss: 0.434335\n",
      "epoch 162; iter: 0; batch classifier loss: 0.034666; batch adversarial loss: 0.515962\n",
      "epoch 163; iter: 0; batch classifier loss: 0.025021; batch adversarial loss: 0.424325\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009203; batch adversarial loss: 0.475174\n",
      "epoch 165; iter: 0; batch classifier loss: 0.020280; batch adversarial loss: 0.397842\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035395; batch adversarial loss: 0.303880\n",
      "epoch 167; iter: 0; batch classifier loss: 0.018614; batch adversarial loss: 0.386615\n",
      "epoch 168; iter: 0; batch classifier loss: 0.066470; batch adversarial loss: 0.360451\n",
      "epoch 169; iter: 0; batch classifier loss: 0.047552; batch adversarial loss: 0.432316\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032707; batch adversarial loss: 0.340626\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011881; batch adversarial loss: 0.500223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 172; iter: 0; batch classifier loss: 0.015569; batch adversarial loss: 0.377284\n",
      "epoch 173; iter: 0; batch classifier loss: 0.075253; batch adversarial loss: 0.542564\n",
      "epoch 174; iter: 0; batch classifier loss: 0.037356; batch adversarial loss: 0.434157\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013826; batch adversarial loss: 0.527546\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012869; batch adversarial loss: 0.477016\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017166; batch adversarial loss: 0.405011\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037001; batch adversarial loss: 0.350582\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012860; batch adversarial loss: 0.392894\n",
      "epoch 180; iter: 0; batch classifier loss: 0.012597; batch adversarial loss: 0.558186\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020559; batch adversarial loss: 0.518964\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016550; batch adversarial loss: 0.368421\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028510; batch adversarial loss: 0.419428\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034111; batch adversarial loss: 0.467202\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006968; batch adversarial loss: 0.459541\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014965; batch adversarial loss: 0.396050\n",
      "epoch 187; iter: 0; batch classifier loss: 0.015910; batch adversarial loss: 0.455723\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014986; batch adversarial loss: 0.371803\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011374; batch adversarial loss: 0.432937\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023793; batch adversarial loss: 0.426987\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022500; batch adversarial loss: 0.436113\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033708; batch adversarial loss: 0.474760\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017161; batch adversarial loss: 0.427540\n",
      "epoch 194; iter: 0; batch classifier loss: 0.020859; batch adversarial loss: 0.436428\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014769; batch adversarial loss: 0.338152\n",
      "epoch 196; iter: 0; batch classifier loss: 0.012601; batch adversarial loss: 0.466250\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012453; batch adversarial loss: 0.490626\n",
      "epoch 198; iter: 0; batch classifier loss: 0.049912; batch adversarial loss: 0.471004\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026383; batch adversarial loss: 0.374795\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673261; batch adversarial loss: 0.884050\n",
      "epoch 1; iter: 0; batch classifier loss: 0.530069; batch adversarial loss: 0.918807\n",
      "epoch 2; iter: 0; batch classifier loss: 0.531349; batch adversarial loss: 0.843185\n",
      "epoch 3; iter: 0; batch classifier loss: 0.701873; batch adversarial loss: 0.803166\n",
      "epoch 4; iter: 0; batch classifier loss: 0.683511; batch adversarial loss: 0.755253\n",
      "epoch 5; iter: 0; batch classifier loss: 0.834645; batch adversarial loss: 0.677667\n",
      "epoch 6; iter: 0; batch classifier loss: 0.664276; batch adversarial loss: 0.624905\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318862; batch adversarial loss: 0.588343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.300652; batch adversarial loss: 0.568501\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250294; batch adversarial loss: 0.571015\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267297; batch adversarial loss: 0.551483\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316013; batch adversarial loss: 0.519649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342214; batch adversarial loss: 0.511994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.190976; batch adversarial loss: 0.472140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.241356; batch adversarial loss: 0.514855\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257328; batch adversarial loss: 0.461214\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217941; batch adversarial loss: 0.488654\n",
      "epoch 17; iter: 0; batch classifier loss: 0.187510; batch adversarial loss: 0.505481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238782; batch adversarial loss: 0.429689\n",
      "epoch 19; iter: 0; batch classifier loss: 0.194295; batch adversarial loss: 0.457210\n",
      "epoch 20; iter: 0; batch classifier loss: 0.237671; batch adversarial loss: 0.479267\n",
      "epoch 21; iter: 0; batch classifier loss: 0.124932; batch adversarial loss: 0.441648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175596; batch adversarial loss: 0.466232\n",
      "epoch 23; iter: 0; batch classifier loss: 0.134321; batch adversarial loss: 0.395215\n",
      "epoch 24; iter: 0; batch classifier loss: 0.113517; batch adversarial loss: 0.423864\n",
      "epoch 25; iter: 0; batch classifier loss: 0.125644; batch adversarial loss: 0.410409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.165672; batch adversarial loss: 0.466354\n",
      "epoch 27; iter: 0; batch classifier loss: 0.117218; batch adversarial loss: 0.436870\n",
      "epoch 28; iter: 0; batch classifier loss: 0.195671; batch adversarial loss: 0.468596\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143383; batch adversarial loss: 0.417813\n",
      "epoch 30; iter: 0; batch classifier loss: 0.101797; batch adversarial loss: 0.433952\n",
      "epoch 31; iter: 0; batch classifier loss: 0.114815; batch adversarial loss: 0.409170\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117369; batch adversarial loss: 0.410168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.087096; batch adversarial loss: 0.522880\n",
      "epoch 34; iter: 0; batch classifier loss: 0.088843; batch adversarial loss: 0.459998\n",
      "epoch 35; iter: 0; batch classifier loss: 0.082054; batch adversarial loss: 0.413471\n",
      "epoch 36; iter: 0; batch classifier loss: 0.124982; batch adversarial loss: 0.429183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.116072; batch adversarial loss: 0.543972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103181; batch adversarial loss: 0.437596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078071; batch adversarial loss: 0.461982\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099470; batch adversarial loss: 0.441335\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076745; batch adversarial loss: 0.424015\n",
      "epoch 42; iter: 0; batch classifier loss: 0.105470; batch adversarial loss: 0.444527\n",
      "epoch 43; iter: 0; batch classifier loss: 0.058520; batch adversarial loss: 0.432154\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086513; batch adversarial loss: 0.389055\n",
      "epoch 45; iter: 0; batch classifier loss: 0.082417; batch adversarial loss: 0.444551\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084420; batch adversarial loss: 0.449802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.080839; batch adversarial loss: 0.388035\n",
      "epoch 48; iter: 0; batch classifier loss: 0.070197; batch adversarial loss: 0.395306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.107216; batch adversarial loss: 0.462010\n",
      "epoch 50; iter: 0; batch classifier loss: 0.071062; batch adversarial loss: 0.472987\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087188; batch adversarial loss: 0.498182\n",
      "epoch 52; iter: 0; batch classifier loss: 0.056183; batch adversarial loss: 0.338870\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151127; batch adversarial loss: 0.520562\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072989; batch adversarial loss: 0.403075\n",
      "epoch 55; iter: 0; batch classifier loss: 0.094527; batch adversarial loss: 0.501132\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113148; batch adversarial loss: 0.444357\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066389; batch adversarial loss: 0.260789\n",
      "epoch 58; iter: 0; batch classifier loss: 0.114793; batch adversarial loss: 0.458175\n",
      "epoch 59; iter: 0; batch classifier loss: 0.070028; batch adversarial loss: 0.355530\n",
      "epoch 60; iter: 0; batch classifier loss: 0.063640; batch adversarial loss: 0.397278\n",
      "epoch 61; iter: 0; batch classifier loss: 0.071905; batch adversarial loss: 0.420849\n",
      "epoch 62; iter: 0; batch classifier loss: 0.049872; batch adversarial loss: 0.472411\n",
      "epoch 63; iter: 0; batch classifier loss: 0.067759; batch adversarial loss: 0.504979\n",
      "epoch 64; iter: 0; batch classifier loss: 0.041610; batch adversarial loss: 0.513007\n",
      "epoch 65; iter: 0; batch classifier loss: 0.078399; batch adversarial loss: 0.497227\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087966; batch adversarial loss: 0.416743\n",
      "epoch 67; iter: 0; batch classifier loss: 0.059114; batch adversarial loss: 0.462231\n",
      "epoch 68; iter: 0; batch classifier loss: 0.068274; batch adversarial loss: 0.437585\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070982; batch adversarial loss: 0.458113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70; iter: 0; batch classifier loss: 0.042110; batch adversarial loss: 0.459472\n",
      "epoch 71; iter: 0; batch classifier loss: 0.069821; batch adversarial loss: 0.410650\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061425; batch adversarial loss: 0.410724\n",
      "epoch 73; iter: 0; batch classifier loss: 0.048213; batch adversarial loss: 0.411782\n",
      "epoch 74; iter: 0; batch classifier loss: 0.038357; batch adversarial loss: 0.319397\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063473; batch adversarial loss: 0.325682\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073175; batch adversarial loss: 0.397706\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071228; batch adversarial loss: 0.467960\n",
      "epoch 78; iter: 0; batch classifier loss: 0.061719; batch adversarial loss: 0.584252\n",
      "epoch 79; iter: 0; batch classifier loss: 0.061778; batch adversarial loss: 0.409672\n",
      "epoch 80; iter: 0; batch classifier loss: 0.100990; batch adversarial loss: 0.437410\n",
      "epoch 81; iter: 0; batch classifier loss: 0.075430; batch adversarial loss: 0.554263\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071863; batch adversarial loss: 0.393660\n",
      "epoch 83; iter: 0; batch classifier loss: 0.068701; batch adversarial loss: 0.382350\n",
      "epoch 84; iter: 0; batch classifier loss: 0.065989; batch adversarial loss: 0.454419\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066910; batch adversarial loss: 0.444128\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075700; batch adversarial loss: 0.386448\n",
      "epoch 87; iter: 0; batch classifier loss: 0.088709; batch adversarial loss: 0.437695\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055697; batch adversarial loss: 0.419062\n",
      "epoch 89; iter: 0; batch classifier loss: 0.059119; batch adversarial loss: 0.377522\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079703; batch adversarial loss: 0.533538\n",
      "epoch 91; iter: 0; batch classifier loss: 0.077420; batch adversarial loss: 0.442046\n",
      "epoch 92; iter: 0; batch classifier loss: 0.067957; batch adversarial loss: 0.434772\n",
      "epoch 93; iter: 0; batch classifier loss: 0.055540; batch adversarial loss: 0.400248\n",
      "epoch 94; iter: 0; batch classifier loss: 0.089811; batch adversarial loss: 0.408684\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049282; batch adversarial loss: 0.369838\n",
      "epoch 96; iter: 0; batch classifier loss: 0.061533; batch adversarial loss: 0.451068\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047116; batch adversarial loss: 0.491835\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053116; batch adversarial loss: 0.440767\n",
      "epoch 99; iter: 0; batch classifier loss: 0.044973; batch adversarial loss: 0.409672\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062329; batch adversarial loss: 0.376643\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044613; batch adversarial loss: 0.333937\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061637; batch adversarial loss: 0.560414\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061988; batch adversarial loss: 0.464433\n",
      "epoch 104; iter: 0; batch classifier loss: 0.038401; batch adversarial loss: 0.457002\n",
      "epoch 105; iter: 0; batch classifier loss: 0.048367; batch adversarial loss: 0.433808\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071196; batch adversarial loss: 0.495358\n",
      "epoch 107; iter: 0; batch classifier loss: 0.051491; batch adversarial loss: 0.423845\n",
      "epoch 108; iter: 0; batch classifier loss: 0.081404; batch adversarial loss: 0.400255\n",
      "epoch 109; iter: 0; batch classifier loss: 0.078716; batch adversarial loss: 0.481798\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067729; batch adversarial loss: 0.394451\n",
      "epoch 111; iter: 0; batch classifier loss: 0.049100; batch adversarial loss: 0.446468\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038751; batch adversarial loss: 0.373725\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040570; batch adversarial loss: 0.384825\n",
      "epoch 114; iter: 0; batch classifier loss: 0.056626; batch adversarial loss: 0.443159\n",
      "epoch 115; iter: 0; batch classifier loss: 0.042266; batch adversarial loss: 0.390814\n",
      "epoch 116; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.428565\n",
      "epoch 117; iter: 0; batch classifier loss: 0.062826; batch adversarial loss: 0.463252\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043454; batch adversarial loss: 0.464733\n",
      "epoch 119; iter: 0; batch classifier loss: 0.025649; batch adversarial loss: 0.364600\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051674; batch adversarial loss: 0.518729\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045263; batch adversarial loss: 0.451365\n",
      "epoch 122; iter: 0; batch classifier loss: 0.083083; batch adversarial loss: 0.414022\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053005; batch adversarial loss: 0.371164\n",
      "epoch 124; iter: 0; batch classifier loss: 0.045868; batch adversarial loss: 0.377355\n",
      "epoch 125; iter: 0; batch classifier loss: 0.123119; batch adversarial loss: 0.515411\n",
      "epoch 126; iter: 0; batch classifier loss: 0.051195; batch adversarial loss: 0.443045\n",
      "epoch 127; iter: 0; batch classifier loss: 0.080357; batch adversarial loss: 0.395575\n",
      "epoch 128; iter: 0; batch classifier loss: 0.071999; batch adversarial loss: 0.407015\n",
      "epoch 129; iter: 0; batch classifier loss: 0.108623; batch adversarial loss: 0.437446\n",
      "epoch 130; iter: 0; batch classifier loss: 0.050582; batch adversarial loss: 0.531114\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070867; batch adversarial loss: 0.394906\n",
      "epoch 132; iter: 0; batch classifier loss: 0.052009; batch adversarial loss: 0.493378\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045622; batch adversarial loss: 0.375550\n",
      "epoch 134; iter: 0; batch classifier loss: 0.092233; batch adversarial loss: 0.457365\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051760; batch adversarial loss: 0.396565\n",
      "epoch 136; iter: 0; batch classifier loss: 0.082833; batch adversarial loss: 0.468284\n",
      "epoch 137; iter: 0; batch classifier loss: 0.042733; batch adversarial loss: 0.400683\n",
      "epoch 138; iter: 0; batch classifier loss: 0.039076; batch adversarial loss: 0.405110\n",
      "epoch 139; iter: 0; batch classifier loss: 0.065187; batch adversarial loss: 0.354771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038036; batch adversarial loss: 0.409279\n",
      "epoch 141; iter: 0; batch classifier loss: 0.049927; batch adversarial loss: 0.334783\n",
      "epoch 142; iter: 0; batch classifier loss: 0.098252; batch adversarial loss: 0.402175\n",
      "epoch 143; iter: 0; batch classifier loss: 0.057027; batch adversarial loss: 0.358089\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051156; batch adversarial loss: 0.427630\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024489; batch adversarial loss: 0.458214\n",
      "epoch 146; iter: 0; batch classifier loss: 0.048229; batch adversarial loss: 0.404342\n",
      "epoch 147; iter: 0; batch classifier loss: 0.023486; batch adversarial loss: 0.444226\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034356; batch adversarial loss: 0.396437\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044920; batch adversarial loss: 0.377864\n",
      "epoch 150; iter: 0; batch classifier loss: 0.084288; batch adversarial loss: 0.457328\n",
      "epoch 151; iter: 0; batch classifier loss: 0.070658; batch adversarial loss: 0.510264\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021085; batch adversarial loss: 0.375321\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048257; batch adversarial loss: 0.544790\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041590; batch adversarial loss: 0.443344\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.377094\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036886; batch adversarial loss: 0.308585\n",
      "epoch 157; iter: 0; batch classifier loss: 0.052804; batch adversarial loss: 0.485391\n",
      "epoch 158; iter: 0; batch classifier loss: 0.051544; batch adversarial loss: 0.471615\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050469; batch adversarial loss: 0.518103\n",
      "epoch 160; iter: 0; batch classifier loss: 0.055050; batch adversarial loss: 0.459530\n",
      "epoch 161; iter: 0; batch classifier loss: 0.084484; batch adversarial loss: 0.384833\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037142; batch adversarial loss: 0.467821\n",
      "epoch 163; iter: 0; batch classifier loss: 0.059907; batch adversarial loss: 0.409660\n",
      "epoch 164; iter: 0; batch classifier loss: 0.050418; batch adversarial loss: 0.437767\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021501; batch adversarial loss: 0.400089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 166; iter: 0; batch classifier loss: 0.060159; batch adversarial loss: 0.418946\n",
      "epoch 167; iter: 0; batch classifier loss: 0.054251; batch adversarial loss: 0.460967\n",
      "epoch 168; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.423011\n",
      "epoch 169; iter: 0; batch classifier loss: 0.080273; batch adversarial loss: 0.418270\n",
      "epoch 170; iter: 0; batch classifier loss: 0.049810; batch adversarial loss: 0.455591\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049872; batch adversarial loss: 0.410302\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029639; batch adversarial loss: 0.464522\n",
      "epoch 173; iter: 0; batch classifier loss: 0.062845; batch adversarial loss: 0.484958\n",
      "epoch 174; iter: 0; batch classifier loss: 0.079040; batch adversarial loss: 0.443445\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037050; batch adversarial loss: 0.424393\n",
      "epoch 176; iter: 0; batch classifier loss: 0.050556; batch adversarial loss: 0.456326\n",
      "epoch 177; iter: 0; batch classifier loss: 0.051456; batch adversarial loss: 0.353459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055384; batch adversarial loss: 0.436669\n",
      "epoch 179; iter: 0; batch classifier loss: 0.066103; batch adversarial loss: 0.441550\n",
      "epoch 180; iter: 0; batch classifier loss: 0.046774; batch adversarial loss: 0.424443\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029884; batch adversarial loss: 0.393289\n",
      "epoch 182; iter: 0; batch classifier loss: 0.067439; batch adversarial loss: 0.466565\n",
      "epoch 183; iter: 0; batch classifier loss: 0.042080; batch adversarial loss: 0.470211\n",
      "epoch 184; iter: 0; batch classifier loss: 0.039489; batch adversarial loss: 0.477123\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053422; batch adversarial loss: 0.422695\n",
      "epoch 186; iter: 0; batch classifier loss: 0.035462; batch adversarial loss: 0.451766\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029924; batch adversarial loss: 0.537302\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027615; batch adversarial loss: 0.467325\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050343; batch adversarial loss: 0.356870\n",
      "epoch 190; iter: 0; batch classifier loss: 0.046513; batch adversarial loss: 0.404921\n",
      "epoch 191; iter: 0; batch classifier loss: 0.045933; batch adversarial loss: 0.434501\n",
      "epoch 192; iter: 0; batch classifier loss: 0.043205; batch adversarial loss: 0.504253\n",
      "epoch 193; iter: 0; batch classifier loss: 0.063023; batch adversarial loss: 0.588372\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032150; batch adversarial loss: 0.427805\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036349; batch adversarial loss: 0.439096\n",
      "epoch 196; iter: 0; batch classifier loss: 0.043633; batch adversarial loss: 0.413705\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037983; batch adversarial loss: 0.559953\n",
      "epoch 198; iter: 0; batch classifier loss: 0.027875; batch adversarial loss: 0.451833\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027576; batch adversarial loss: 0.431349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695239; batch adversarial loss: 0.761382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.432039; batch adversarial loss: 0.734256\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382090; batch adversarial loss: 0.679493\n",
      "epoch 3; iter: 0; batch classifier loss: 0.318361; batch adversarial loss: 0.644581\n",
      "epoch 4; iter: 0; batch classifier loss: 0.321955; batch adversarial loss: 0.613951\n",
      "epoch 5; iter: 0; batch classifier loss: 0.258185; batch adversarial loss: 0.590999\n",
      "epoch 6; iter: 0; batch classifier loss: 0.332256; batch adversarial loss: 0.547668\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353597; batch adversarial loss: 0.527455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256337; batch adversarial loss: 0.502846\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327680; batch adversarial loss: 0.576644\n",
      "epoch 10; iter: 0; batch classifier loss: 0.229722; batch adversarial loss: 0.479696\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223314; batch adversarial loss: 0.508337\n",
      "epoch 12; iter: 0; batch classifier loss: 0.190432; batch adversarial loss: 0.454111\n",
      "epoch 13; iter: 0; batch classifier loss: 0.216936; batch adversarial loss: 0.521729\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249174; batch adversarial loss: 0.525270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.199909; batch adversarial loss: 0.515068\n",
      "epoch 16; iter: 0; batch classifier loss: 0.227879; batch adversarial loss: 0.465322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220016; batch adversarial loss: 0.481847\n",
      "epoch 18; iter: 0; batch classifier loss: 0.185383; batch adversarial loss: 0.385151\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.466015\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368122; batch adversarial loss: 0.522888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.393439; batch adversarial loss: 0.486746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.279394; batch adversarial loss: 0.544056\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279549; batch adversarial loss: 0.509626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.232904; batch adversarial loss: 0.428646\n",
      "epoch 25; iter: 0; batch classifier loss: 0.171436; batch adversarial loss: 0.430044\n",
      "epoch 26; iter: 0; batch classifier loss: 0.172252; batch adversarial loss: 0.494206\n",
      "epoch 27; iter: 0; batch classifier loss: 0.142280; batch adversarial loss: 0.533966\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159020; batch adversarial loss: 0.410465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.173284; batch adversarial loss: 0.467898\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180466; batch adversarial loss: 0.528468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.125970; batch adversarial loss: 0.501115\n",
      "epoch 32; iter: 0; batch classifier loss: 0.126269; batch adversarial loss: 0.487942\n",
      "epoch 33; iter: 0; batch classifier loss: 0.113836; batch adversarial loss: 0.459071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159803; batch adversarial loss: 0.400903\n",
      "epoch 35; iter: 0; batch classifier loss: 0.129990; batch adversarial loss: 0.467177\n",
      "epoch 36; iter: 0; batch classifier loss: 0.141727; batch adversarial loss: 0.491454\n",
      "epoch 37; iter: 0; batch classifier loss: 0.130112; batch adversarial loss: 0.527066\n",
      "epoch 38; iter: 0; batch classifier loss: 0.129825; batch adversarial loss: 0.386680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.100498; batch adversarial loss: 0.417884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.124310; batch adversarial loss: 0.431169\n",
      "epoch 41; iter: 0; batch classifier loss: 0.145097; batch adversarial loss: 0.530745\n",
      "epoch 42; iter: 0; batch classifier loss: 0.112907; batch adversarial loss: 0.546940\n",
      "epoch 43; iter: 0; batch classifier loss: 0.112313; batch adversarial loss: 0.426994\n",
      "epoch 44; iter: 0; batch classifier loss: 0.125231; batch adversarial loss: 0.395093\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093542; batch adversarial loss: 0.365785\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104043; batch adversarial loss: 0.433594\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112820; batch adversarial loss: 0.483379\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130283; batch adversarial loss: 0.463015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.148507; batch adversarial loss: 0.455730\n",
      "epoch 50; iter: 0; batch classifier loss: 0.096409; batch adversarial loss: 0.529956\n",
      "epoch 51; iter: 0; batch classifier loss: 0.102798; batch adversarial loss: 0.430344\n",
      "epoch 52; iter: 0; batch classifier loss: 0.096739; batch adversarial loss: 0.493683\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165871; batch adversarial loss: 0.415328\n",
      "epoch 54; iter: 0; batch classifier loss: 0.099800; batch adversarial loss: 0.461399\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087141; batch adversarial loss: 0.395109\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085060; batch adversarial loss: 0.389704\n",
      "epoch 57; iter: 0; batch classifier loss: 0.108687; batch adversarial loss: 0.297170\n",
      "epoch 58; iter: 0; batch classifier loss: 0.100759; batch adversarial loss: 0.338490\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057030; batch adversarial loss: 0.414001\n",
      "epoch 60; iter: 0; batch classifier loss: 0.059244; batch adversarial loss: 0.484322\n",
      "epoch 61; iter: 0; batch classifier loss: 0.053502; batch adversarial loss: 0.487171\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087258; batch adversarial loss: 0.502568\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066201; batch adversarial loss: 0.443726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64; iter: 0; batch classifier loss: 0.073776; batch adversarial loss: 0.418504\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070338; batch adversarial loss: 0.423439\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095892; batch adversarial loss: 0.472135\n",
      "epoch 67; iter: 0; batch classifier loss: 0.054411; batch adversarial loss: 0.366239\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111668; batch adversarial loss: 0.434908\n",
      "epoch 69; iter: 0; batch classifier loss: 0.050395; batch adversarial loss: 0.471347\n",
      "epoch 70; iter: 0; batch classifier loss: 0.107014; batch adversarial loss: 0.486784\n",
      "epoch 71; iter: 0; batch classifier loss: 0.110422; batch adversarial loss: 0.393821\n",
      "epoch 72; iter: 0; batch classifier loss: 0.052958; batch adversarial loss: 0.507879\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084918; batch adversarial loss: 0.420906\n",
      "epoch 74; iter: 0; batch classifier loss: 0.053384; batch adversarial loss: 0.472025\n",
      "epoch 75; iter: 0; batch classifier loss: 0.096564; batch adversarial loss: 0.320592\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081484; batch adversarial loss: 0.440641\n",
      "epoch 77; iter: 0; batch classifier loss: 0.042850; batch adversarial loss: 0.400915\n",
      "epoch 78; iter: 0; batch classifier loss: 0.065350; batch adversarial loss: 0.432153\n",
      "epoch 79; iter: 0; batch classifier loss: 0.042087; batch adversarial loss: 0.536946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.062958; batch adversarial loss: 0.390193\n",
      "epoch 81; iter: 0; batch classifier loss: 0.061746; batch adversarial loss: 0.404028\n",
      "epoch 82; iter: 0; batch classifier loss: 0.085700; batch adversarial loss: 0.440925\n",
      "epoch 83; iter: 0; batch classifier loss: 0.065392; batch adversarial loss: 0.370123\n",
      "epoch 84; iter: 0; batch classifier loss: 0.056046; batch adversarial loss: 0.408611\n",
      "epoch 85; iter: 0; batch classifier loss: 0.109350; batch adversarial loss: 0.404299\n",
      "epoch 86; iter: 0; batch classifier loss: 0.048704; batch adversarial loss: 0.463270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050939; batch adversarial loss: 0.558377\n",
      "epoch 88; iter: 0; batch classifier loss: 0.055427; batch adversarial loss: 0.478272\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079262; batch adversarial loss: 0.446952\n",
      "epoch 90; iter: 0; batch classifier loss: 0.035851; batch adversarial loss: 0.518377\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039567; batch adversarial loss: 0.479038\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060434; batch adversarial loss: 0.446220\n",
      "epoch 93; iter: 0; batch classifier loss: 0.024799; batch adversarial loss: 0.479660\n",
      "epoch 94; iter: 0; batch classifier loss: 0.069022; batch adversarial loss: 0.403030\n",
      "epoch 95; iter: 0; batch classifier loss: 0.023661; batch adversarial loss: 0.404769\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062494; batch adversarial loss: 0.423054\n",
      "epoch 97; iter: 0; batch classifier loss: 0.040588; batch adversarial loss: 0.492334\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058476; batch adversarial loss: 0.486456\n",
      "epoch 99; iter: 0; batch classifier loss: 0.062106; batch adversarial loss: 0.399291\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041181; batch adversarial loss: 0.412659\n",
      "epoch 101; iter: 0; batch classifier loss: 0.051221; batch adversarial loss: 0.439758\n",
      "epoch 102; iter: 0; batch classifier loss: 0.085389; batch adversarial loss: 0.399636\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082307; batch adversarial loss: 0.442161\n",
      "epoch 104; iter: 0; batch classifier loss: 0.014144; batch adversarial loss: 0.392868\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076431; batch adversarial loss: 0.360204\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033936; batch adversarial loss: 0.454201\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031352; batch adversarial loss: 0.501877\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033284; batch adversarial loss: 0.453120\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051605; batch adversarial loss: 0.339894\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037681; batch adversarial loss: 0.400937\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053564; batch adversarial loss: 0.547783\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030924; batch adversarial loss: 0.444478\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046569; batch adversarial loss: 0.526221\n",
      "epoch 114; iter: 0; batch classifier loss: 0.043846; batch adversarial loss: 0.503693\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060947; batch adversarial loss: 0.366174\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053828; batch adversarial loss: 0.359548\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080044; batch adversarial loss: 0.356640\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062834; batch adversarial loss: 0.498407\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041000; batch adversarial loss: 0.365895\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040688; batch adversarial loss: 0.438068\n",
      "epoch 121; iter: 0; batch classifier loss: 0.027987; batch adversarial loss: 0.477010\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049732; batch adversarial loss: 0.385140\n",
      "epoch 123; iter: 0; batch classifier loss: 0.012418; batch adversarial loss: 0.431969\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027527; batch adversarial loss: 0.398211\n",
      "epoch 125; iter: 0; batch classifier loss: 0.047034; batch adversarial loss: 0.412589\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044008; batch adversarial loss: 0.388616\n",
      "epoch 127; iter: 0; batch classifier loss: 0.032029; batch adversarial loss: 0.447246\n",
      "epoch 128; iter: 0; batch classifier loss: 0.028501; batch adversarial loss: 0.459127\n",
      "epoch 129; iter: 0; batch classifier loss: 0.011367; batch adversarial loss: 0.396495\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049781; batch adversarial loss: 0.393424\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041551; batch adversarial loss: 0.471963\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022784; batch adversarial loss: 0.502574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.036358; batch adversarial loss: 0.466793\n",
      "epoch 134; iter: 0; batch classifier loss: 0.019996; batch adversarial loss: 0.539692\n",
      "epoch 135; iter: 0; batch classifier loss: 0.031513; batch adversarial loss: 0.459876\n",
      "epoch 136; iter: 0; batch classifier loss: 0.026701; batch adversarial loss: 0.372414\n",
      "epoch 137; iter: 0; batch classifier loss: 0.010554; batch adversarial loss: 0.401584\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020784; batch adversarial loss: 0.415298\n",
      "epoch 139; iter: 0; batch classifier loss: 0.029986; batch adversarial loss: 0.421645\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026046; batch adversarial loss: 0.397965\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021644; batch adversarial loss: 0.346116\n",
      "epoch 142; iter: 0; batch classifier loss: 0.013238; batch adversarial loss: 0.535991\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028238; batch adversarial loss: 0.464632\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027356; batch adversarial loss: 0.500229\n",
      "epoch 145; iter: 0; batch classifier loss: 0.024091; batch adversarial loss: 0.437821\n",
      "epoch 146; iter: 0; batch classifier loss: 0.026268; batch adversarial loss: 0.519382\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018152; batch adversarial loss: 0.431995\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045121; batch adversarial loss: 0.444635\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036886; batch adversarial loss: 0.338738\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028554; batch adversarial loss: 0.462911\n",
      "epoch 151; iter: 0; batch classifier loss: 0.046894; batch adversarial loss: 0.481002\n",
      "epoch 152; iter: 0; batch classifier loss: 0.015309; batch adversarial loss: 0.480243\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011642; batch adversarial loss: 0.499919\n",
      "epoch 154; iter: 0; batch classifier loss: 0.076534; batch adversarial loss: 0.458368\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030602; batch adversarial loss: 0.454686\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039832; batch adversarial loss: 0.494905\n",
      "epoch 157; iter: 0; batch classifier loss: 0.040368; batch adversarial loss: 0.472183\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027526; batch adversarial loss: 0.383737\n",
      "epoch 159; iter: 0; batch classifier loss: 0.003112; batch adversarial loss: 0.426171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160; iter: 0; batch classifier loss: 0.010698; batch adversarial loss: 0.416223\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018404; batch adversarial loss: 0.444512\n",
      "epoch 162; iter: 0; batch classifier loss: 0.007774; batch adversarial loss: 0.515394\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035649; batch adversarial loss: 0.441204\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009767; batch adversarial loss: 0.491280\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018156; batch adversarial loss: 0.440001\n",
      "epoch 166; iter: 0; batch classifier loss: 0.035712; batch adversarial loss: 0.472509\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026086; batch adversarial loss: 0.410228\n",
      "epoch 168; iter: 0; batch classifier loss: 0.025069; batch adversarial loss: 0.460636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.014716; batch adversarial loss: 0.453045\n",
      "epoch 170; iter: 0; batch classifier loss: 0.040876; batch adversarial loss: 0.468294\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017108; batch adversarial loss: 0.416201\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014845; batch adversarial loss: 0.475958\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012196; batch adversarial loss: 0.462800\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036219; batch adversarial loss: 0.386070\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013288; batch adversarial loss: 0.406061\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018378; batch adversarial loss: 0.473882\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025076; batch adversarial loss: 0.404657\n",
      "epoch 178; iter: 0; batch classifier loss: 0.035105; batch adversarial loss: 0.497051\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019750; batch adversarial loss: 0.355661\n",
      "epoch 180; iter: 0; batch classifier loss: 0.009642; batch adversarial loss: 0.464334\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017691; batch adversarial loss: 0.405738\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023441; batch adversarial loss: 0.483378\n",
      "epoch 183; iter: 0; batch classifier loss: 0.028320; batch adversarial loss: 0.532253\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016542; batch adversarial loss: 0.511461\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013796; batch adversarial loss: 0.418513\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007089; batch adversarial loss: 0.442575\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031327; batch adversarial loss: 0.502020\n",
      "epoch 188; iter: 0; batch classifier loss: 0.024221; batch adversarial loss: 0.491939\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013531; batch adversarial loss: 0.543737\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015164; batch adversarial loss: 0.433875\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019636; batch adversarial loss: 0.464647\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012136; batch adversarial loss: 0.521019\n",
      "epoch 193; iter: 0; batch classifier loss: 0.016596; batch adversarial loss: 0.356605\n",
      "epoch 194; iter: 0; batch classifier loss: 0.023382; batch adversarial loss: 0.496580\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035231; batch adversarial loss: 0.451857\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017947; batch adversarial loss: 0.378174\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013648; batch adversarial loss: 0.435368\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015219; batch adversarial loss: 0.396854\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008352; batch adversarial loss: 0.422145\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685994; batch adversarial loss: 0.802267\n",
      "epoch 1; iter: 0; batch classifier loss: 0.415699; batch adversarial loss: 0.799089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366608; batch adversarial loss: 0.731860\n",
      "epoch 3; iter: 0; batch classifier loss: 0.419294; batch adversarial loss: 0.692097\n",
      "epoch 4; iter: 0; batch classifier loss: 0.375654; batch adversarial loss: 0.642710\n",
      "epoch 5; iter: 0; batch classifier loss: 0.233097; batch adversarial loss: 0.602870\n",
      "epoch 6; iter: 0; batch classifier loss: 0.254791; batch adversarial loss: 0.598001\n",
      "epoch 7; iter: 0; batch classifier loss: 0.287764; batch adversarial loss: 0.577032\n",
      "epoch 8; iter: 0; batch classifier loss: 0.205991; batch adversarial loss: 0.568730\n",
      "epoch 9; iter: 0; batch classifier loss: 0.276258; batch adversarial loss: 0.560305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.224139; batch adversarial loss: 0.521476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.357295; batch adversarial loss: 0.448488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266382; batch adversarial loss: 0.499501\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225083; batch adversarial loss: 0.427304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.209402; batch adversarial loss: 0.484842\n",
      "epoch 15; iter: 0; batch classifier loss: 0.228373; batch adversarial loss: 0.460029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.175633; batch adversarial loss: 0.474740\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255469; batch adversarial loss: 0.481688\n",
      "epoch 18; iter: 0; batch classifier loss: 0.227124; batch adversarial loss: 0.388991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.168646; batch adversarial loss: 0.475408\n",
      "epoch 20; iter: 0; batch classifier loss: 0.179753; batch adversarial loss: 0.451371\n",
      "epoch 21; iter: 0; batch classifier loss: 0.190600; batch adversarial loss: 0.508946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.178539; batch adversarial loss: 0.430555\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165834; batch adversarial loss: 0.436879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166999; batch adversarial loss: 0.465569\n",
      "epoch 25; iter: 0; batch classifier loss: 0.129822; batch adversarial loss: 0.376277\n",
      "epoch 26; iter: 0; batch classifier loss: 0.117805; batch adversarial loss: 0.362563\n",
      "epoch 27; iter: 0; batch classifier loss: 0.099158; batch adversarial loss: 0.457761\n",
      "epoch 28; iter: 0; batch classifier loss: 0.101590; batch adversarial loss: 0.434807\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210933; batch adversarial loss: 0.460372\n",
      "epoch 30; iter: 0; batch classifier loss: 0.167877; batch adversarial loss: 0.364390\n",
      "epoch 31; iter: 0; batch classifier loss: 0.196482; batch adversarial loss: 0.332678\n",
      "epoch 32; iter: 0; batch classifier loss: 0.166430; batch adversarial loss: 0.393067\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181153; batch adversarial loss: 0.443321\n",
      "epoch 34; iter: 0; batch classifier loss: 0.153548; batch adversarial loss: 0.408870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.236484; batch adversarial loss: 0.453148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.149102; batch adversarial loss: 0.367330\n",
      "epoch 37; iter: 0; batch classifier loss: 0.197403; batch adversarial loss: 0.444935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.165334; batch adversarial loss: 0.462745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.122901; batch adversarial loss: 0.419430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096703; batch adversarial loss: 0.344532\n",
      "epoch 41; iter: 0; batch classifier loss: 0.084422; batch adversarial loss: 0.358973\n",
      "epoch 42; iter: 0; batch classifier loss: 0.130498; batch adversarial loss: 0.391776\n",
      "epoch 43; iter: 0; batch classifier loss: 0.109539; batch adversarial loss: 0.482025\n",
      "epoch 44; iter: 0; batch classifier loss: 0.126345; batch adversarial loss: 0.322832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099861; batch adversarial loss: 0.505411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.122317; batch adversarial loss: 0.478711\n",
      "epoch 47; iter: 0; batch classifier loss: 0.128938; batch adversarial loss: 0.399746\n",
      "epoch 48; iter: 0; batch classifier loss: 0.097131; batch adversarial loss: 0.350254\n",
      "epoch 49; iter: 0; batch classifier loss: 0.092275; batch adversarial loss: 0.366073\n",
      "epoch 50; iter: 0; batch classifier loss: 0.151509; batch adversarial loss: 0.390903\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084087; batch adversarial loss: 0.424631\n",
      "epoch 52; iter: 0; batch classifier loss: 0.064063; batch adversarial loss: 0.397087\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.441118\n",
      "epoch 54; iter: 0; batch classifier loss: 0.076784; batch adversarial loss: 0.345192\n",
      "epoch 55; iter: 0; batch classifier loss: 0.103681; batch adversarial loss: 0.436644\n",
      "epoch 56; iter: 0; batch classifier loss: 0.113846; batch adversarial loss: 0.439529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57; iter: 0; batch classifier loss: 0.057193; batch adversarial loss: 0.389312\n",
      "epoch 58; iter: 0; batch classifier loss: 0.124675; batch adversarial loss: 0.350924\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098626; batch adversarial loss: 0.424153\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146353; batch adversarial loss: 0.462568\n",
      "epoch 61; iter: 0; batch classifier loss: 0.126202; batch adversarial loss: 0.418481\n",
      "epoch 62; iter: 0; batch classifier loss: 0.081991; batch adversarial loss: 0.423002\n",
      "epoch 63; iter: 0; batch classifier loss: 0.137754; batch adversarial loss: 0.488813\n",
      "epoch 64; iter: 0; batch classifier loss: 0.108678; batch adversarial loss: 0.486997\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079046; batch adversarial loss: 0.467457\n",
      "epoch 66; iter: 0; batch classifier loss: 0.062031; batch adversarial loss: 0.368865\n",
      "epoch 67; iter: 0; batch classifier loss: 0.100040; batch adversarial loss: 0.404694\n",
      "epoch 68; iter: 0; batch classifier loss: 0.110366; batch adversarial loss: 0.350012\n",
      "epoch 69; iter: 0; batch classifier loss: 0.113009; batch adversarial loss: 0.405200\n",
      "epoch 70; iter: 0; batch classifier loss: 0.070893; batch adversarial loss: 0.419349\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079149; batch adversarial loss: 0.463658\n",
      "epoch 72; iter: 0; batch classifier loss: 0.065254; batch adversarial loss: 0.442325\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058771; batch adversarial loss: 0.407392\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109295; batch adversarial loss: 0.478641\n",
      "epoch 75; iter: 0; batch classifier loss: 0.055604; batch adversarial loss: 0.424266\n",
      "epoch 76; iter: 0; batch classifier loss: 0.096347; batch adversarial loss: 0.380038\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122962; batch adversarial loss: 0.435337\n",
      "epoch 78; iter: 0; batch classifier loss: 0.097401; batch adversarial loss: 0.516018\n",
      "epoch 79; iter: 0; batch classifier loss: 0.086559; batch adversarial loss: 0.340349\n",
      "epoch 80; iter: 0; batch classifier loss: 0.070679; batch adversarial loss: 0.390967\n",
      "epoch 81; iter: 0; batch classifier loss: 0.081256; batch adversarial loss: 0.387251\n",
      "epoch 82; iter: 0; batch classifier loss: 0.055443; batch adversarial loss: 0.416754\n",
      "epoch 83; iter: 0; batch classifier loss: 0.118398; batch adversarial loss: 0.511275\n",
      "epoch 84; iter: 0; batch classifier loss: 0.127584; batch adversarial loss: 0.475410\n",
      "epoch 85; iter: 0; batch classifier loss: 0.090861; batch adversarial loss: 0.447149\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100277; batch adversarial loss: 0.414206\n",
      "epoch 87; iter: 0; batch classifier loss: 0.078965; batch adversarial loss: 0.365863\n",
      "epoch 88; iter: 0; batch classifier loss: 0.081537; batch adversarial loss: 0.467522\n",
      "epoch 89; iter: 0; batch classifier loss: 0.080300; batch adversarial loss: 0.396516\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067500; batch adversarial loss: 0.396586\n",
      "epoch 91; iter: 0; batch classifier loss: 0.051499; batch adversarial loss: 0.424537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065276; batch adversarial loss: 0.341743\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093930; batch adversarial loss: 0.466493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.092965; batch adversarial loss: 0.433693\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079089; batch adversarial loss: 0.497673\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056356; batch adversarial loss: 0.432798\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085538; batch adversarial loss: 0.360901\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044083; batch adversarial loss: 0.368229\n",
      "epoch 99; iter: 0; batch classifier loss: 0.110635; batch adversarial loss: 0.403195\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049843; batch adversarial loss: 0.417551\n",
      "epoch 101; iter: 0; batch classifier loss: 0.078833; batch adversarial loss: 0.429659\n",
      "epoch 102; iter: 0; batch classifier loss: 0.105401; batch adversarial loss: 0.511619\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084172; batch adversarial loss: 0.380705\n",
      "epoch 104; iter: 0; batch classifier loss: 0.122996; batch adversarial loss: 0.367936\n",
      "epoch 105; iter: 0; batch classifier loss: 0.072440; batch adversarial loss: 0.470085\n",
      "epoch 106; iter: 0; batch classifier loss: 0.090115; batch adversarial loss: 0.388587\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063852; batch adversarial loss: 0.459647\n",
      "epoch 108; iter: 0; batch classifier loss: 0.069800; batch adversarial loss: 0.359287\n",
      "epoch 109; iter: 0; batch classifier loss: 0.067616; batch adversarial loss: 0.392461\n",
      "epoch 110; iter: 0; batch classifier loss: 0.063721; batch adversarial loss: 0.398958\n",
      "epoch 111; iter: 0; batch classifier loss: 0.051104; batch adversarial loss: 0.376458\n",
      "epoch 112; iter: 0; batch classifier loss: 0.087598; batch adversarial loss: 0.474033\n",
      "epoch 113; iter: 0; batch classifier loss: 0.093555; batch adversarial loss: 0.387128\n",
      "epoch 114; iter: 0; batch classifier loss: 0.084917; batch adversarial loss: 0.372289\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041034; batch adversarial loss: 0.386270\n",
      "epoch 116; iter: 0; batch classifier loss: 0.083977; batch adversarial loss: 0.430192\n",
      "epoch 117; iter: 0; batch classifier loss: 0.071986; batch adversarial loss: 0.380779\n",
      "epoch 118; iter: 0; batch classifier loss: 0.068956; batch adversarial loss: 0.374876\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036937; batch adversarial loss: 0.341185\n",
      "epoch 120; iter: 0; batch classifier loss: 0.069838; batch adversarial loss: 0.422468\n",
      "epoch 121; iter: 0; batch classifier loss: 0.087015; batch adversarial loss: 0.389358\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062725; batch adversarial loss: 0.441473\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055690; batch adversarial loss: 0.404508\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044004; batch adversarial loss: 0.447539\n",
      "epoch 125; iter: 0; batch classifier loss: 0.087422; batch adversarial loss: 0.460413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067128; batch adversarial loss: 0.439473\n",
      "epoch 127; iter: 0; batch classifier loss: 0.067149; batch adversarial loss: 0.504006\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058748; batch adversarial loss: 0.344483\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045001; batch adversarial loss: 0.357347\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041601; batch adversarial loss: 0.433027\n",
      "epoch 131; iter: 0; batch classifier loss: 0.046058; batch adversarial loss: 0.489083\n",
      "epoch 132; iter: 0; batch classifier loss: 0.070346; batch adversarial loss: 0.427169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.082200; batch adversarial loss: 0.487160\n",
      "epoch 134; iter: 0; batch classifier loss: 0.045924; batch adversarial loss: 0.399559\n",
      "epoch 135; iter: 0; batch classifier loss: 0.046289; batch adversarial loss: 0.446066\n",
      "epoch 136; iter: 0; batch classifier loss: 0.052786; batch adversarial loss: 0.413076\n",
      "epoch 137; iter: 0; batch classifier loss: 0.058228; batch adversarial loss: 0.383621\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045076; batch adversarial loss: 0.383416\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036796; batch adversarial loss: 0.412566\n",
      "epoch 140; iter: 0; batch classifier loss: 0.030802; batch adversarial loss: 0.427408\n",
      "epoch 141; iter: 0; batch classifier loss: 0.040058; batch adversarial loss: 0.419515\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038600; batch adversarial loss: 0.545044\n",
      "epoch 143; iter: 0; batch classifier loss: 0.059127; batch adversarial loss: 0.449857\n",
      "epoch 144; iter: 0; batch classifier loss: 0.063371; batch adversarial loss: 0.393402\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045544; batch adversarial loss: 0.399499\n",
      "epoch 146; iter: 0; batch classifier loss: 0.044290; batch adversarial loss: 0.471697\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039641; batch adversarial loss: 0.415363\n",
      "epoch 148; iter: 0; batch classifier loss: 0.038579; batch adversarial loss: 0.546155\n",
      "epoch 149; iter: 0; batch classifier loss: 0.036057; batch adversarial loss: 0.421686\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025921; batch adversarial loss: 0.420569\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033469; batch adversarial loss: 0.399008\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021675; batch adversarial loss: 0.406373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 153; iter: 0; batch classifier loss: 0.015967; batch adversarial loss: 0.430827\n",
      "epoch 154; iter: 0; batch classifier loss: 0.022022; batch adversarial loss: 0.366812\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041591; batch adversarial loss: 0.436202\n",
      "epoch 156; iter: 0; batch classifier loss: 0.019306; batch adversarial loss: 0.464548\n",
      "epoch 157; iter: 0; batch classifier loss: 0.023613; batch adversarial loss: 0.403935\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057668; batch adversarial loss: 0.423414\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027184; batch adversarial loss: 0.338591\n",
      "epoch 160; iter: 0; batch classifier loss: 0.036604; batch adversarial loss: 0.439699\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038230; batch adversarial loss: 0.461661\n",
      "epoch 162; iter: 0; batch classifier loss: 0.030836; batch adversarial loss: 0.476553\n",
      "epoch 163; iter: 0; batch classifier loss: 0.044629; batch adversarial loss: 0.365535\n",
      "epoch 164; iter: 0; batch classifier loss: 0.034116; batch adversarial loss: 0.446203\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026300; batch adversarial loss: 0.509857\n",
      "epoch 166; iter: 0; batch classifier loss: 0.077841; batch adversarial loss: 0.416346\n",
      "epoch 167; iter: 0; batch classifier loss: 0.052167; batch adversarial loss: 0.466234\n",
      "epoch 168; iter: 0; batch classifier loss: 0.023711; batch adversarial loss: 0.504252\n",
      "epoch 169; iter: 0; batch classifier loss: 0.025101; batch adversarial loss: 0.503161\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017562; batch adversarial loss: 0.393802\n",
      "epoch 171; iter: 0; batch classifier loss: 0.047886; batch adversarial loss: 0.493297\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039086; batch adversarial loss: 0.508043\n",
      "epoch 173; iter: 0; batch classifier loss: 0.082892; batch adversarial loss: 0.509054\n",
      "epoch 174; iter: 0; batch classifier loss: 0.097298; batch adversarial loss: 0.592409\n",
      "epoch 175; iter: 0; batch classifier loss: 0.116686; batch adversarial loss: 0.576619\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040039; batch adversarial loss: 0.501465\n",
      "epoch 177; iter: 0; batch classifier loss: 0.107073; batch adversarial loss: 0.690931\n",
      "epoch 178; iter: 0; batch classifier loss: 0.068003; batch adversarial loss: 0.558600\n",
      "epoch 179; iter: 0; batch classifier loss: 0.061806; batch adversarial loss: 0.629859\n",
      "epoch 180; iter: 0; batch classifier loss: 0.081412; batch adversarial loss: 0.507521\n",
      "epoch 181; iter: 0; batch classifier loss: 0.125051; batch adversarial loss: 0.684199\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053741; batch adversarial loss: 0.599061\n",
      "epoch 183; iter: 0; batch classifier loss: 0.122850; batch adversarial loss: 0.670996\n",
      "epoch 184; iter: 0; batch classifier loss: 0.126388; batch adversarial loss: 0.616757\n",
      "epoch 185; iter: 0; batch classifier loss: 0.120634; batch adversarial loss: 0.578982\n",
      "epoch 186; iter: 0; batch classifier loss: 0.175261; batch adversarial loss: 0.634179\n",
      "epoch 187; iter: 0; batch classifier loss: 0.110312; batch adversarial loss: 0.625704\n",
      "epoch 188; iter: 0; batch classifier loss: 0.076736; batch adversarial loss: 0.540690\n",
      "epoch 189; iter: 0; batch classifier loss: 0.116979; batch adversarial loss: 0.597827\n",
      "epoch 190; iter: 0; batch classifier loss: 0.091454; batch adversarial loss: 0.407091\n",
      "epoch 191; iter: 0; batch classifier loss: 0.249423; batch adversarial loss: 0.717652\n",
      "epoch 192; iter: 0; batch classifier loss: 0.222978; batch adversarial loss: 0.702883\n",
      "epoch 193; iter: 0; batch classifier loss: 0.132011; batch adversarial loss: 0.552606\n",
      "epoch 194; iter: 0; batch classifier loss: 0.071520; batch adversarial loss: 0.467188\n",
      "epoch 195; iter: 0; batch classifier loss: 0.142212; batch adversarial loss: 0.559012\n",
      "epoch 196; iter: 0; batch classifier loss: 0.130219; batch adversarial loss: 0.521012\n",
      "epoch 197; iter: 0; batch classifier loss: 0.126817; batch adversarial loss: 0.540449\n",
      "epoch 198; iter: 0; batch classifier loss: 0.145174; batch adversarial loss: 0.538607\n",
      "epoch 199; iter: 0; batch classifier loss: 0.120538; batch adversarial loss: 0.528730\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683737; batch adversarial loss: 0.630058\n",
      "epoch 1; iter: 0; batch classifier loss: 0.455617; batch adversarial loss: 0.626502\n",
      "epoch 2; iter: 0; batch classifier loss: 0.414281; batch adversarial loss: 0.622592\n",
      "epoch 3; iter: 0; batch classifier loss: 0.424445; batch adversarial loss: 0.588229\n",
      "epoch 4; iter: 0; batch classifier loss: 0.430243; batch adversarial loss: 0.609749\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496060; batch adversarial loss: 0.591193\n",
      "epoch 6; iter: 0; batch classifier loss: 0.478403; batch adversarial loss: 0.572902\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454457; batch adversarial loss: 0.518470\n",
      "epoch 8; iter: 0; batch classifier loss: 0.385634; batch adversarial loss: 0.561811\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407533; batch adversarial loss: 0.545708\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366775; batch adversarial loss: 0.560070\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345161; batch adversarial loss: 0.467182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295609; batch adversarial loss: 0.467729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343406; batch adversarial loss: 0.490707\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348948; batch adversarial loss: 0.471270\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246115; batch adversarial loss: 0.446789\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233868; batch adversarial loss: 0.507012\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260113; batch adversarial loss: 0.459458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214555; batch adversarial loss: 0.397950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.217681; batch adversarial loss: 0.446888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.202512; batch adversarial loss: 0.505976\n",
      "epoch 21; iter: 0; batch classifier loss: 0.202262; batch adversarial loss: 0.474939\n",
      "epoch 22; iter: 0; batch classifier loss: 0.235243; batch adversarial loss: 0.466150\n",
      "epoch 23; iter: 0; batch classifier loss: 0.193724; batch adversarial loss: 0.553854\n",
      "epoch 24; iter: 0; batch classifier loss: 0.138317; batch adversarial loss: 0.491479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.146545; batch adversarial loss: 0.562625\n",
      "epoch 26; iter: 0; batch classifier loss: 0.179020; batch adversarial loss: 0.381799\n",
      "epoch 27; iter: 0; batch classifier loss: 0.161077; batch adversarial loss: 0.483098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170508; batch adversarial loss: 0.501057\n",
      "epoch 29; iter: 0; batch classifier loss: 0.179666; batch adversarial loss: 0.439509\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172653; batch adversarial loss: 0.561222\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162998; batch adversarial loss: 0.446237\n",
      "epoch 32; iter: 0; batch classifier loss: 0.211114; batch adversarial loss: 0.435922\n",
      "epoch 33; iter: 0; batch classifier loss: 0.101017; batch adversarial loss: 0.526312\n",
      "epoch 34; iter: 0; batch classifier loss: 0.171142; batch adversarial loss: 0.447519\n",
      "epoch 35; iter: 0; batch classifier loss: 0.191934; batch adversarial loss: 0.414433\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150972; batch adversarial loss: 0.476720\n",
      "epoch 37; iter: 0; batch classifier loss: 0.219984; batch adversarial loss: 0.418120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.109796; batch adversarial loss: 0.449520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.115369; batch adversarial loss: 0.471053\n",
      "epoch 40; iter: 0; batch classifier loss: 0.147030; batch adversarial loss: 0.375694\n",
      "epoch 41; iter: 0; batch classifier loss: 0.118474; batch adversarial loss: 0.401319\n",
      "epoch 42; iter: 0; batch classifier loss: 0.128030; batch adversarial loss: 0.393336\n",
      "epoch 43; iter: 0; batch classifier loss: 0.139519; batch adversarial loss: 0.442210\n",
      "epoch 44; iter: 0; batch classifier loss: 0.121470; batch adversarial loss: 0.419078\n",
      "epoch 45; iter: 0; batch classifier loss: 0.166867; batch adversarial loss: 0.524356\n",
      "epoch 46; iter: 0; batch classifier loss: 0.132997; batch adversarial loss: 0.393894\n",
      "epoch 47; iter: 0; batch classifier loss: 0.135153; batch adversarial loss: 0.477882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.098387; batch adversarial loss: 0.471207\n",
      "epoch 49; iter: 0; batch classifier loss: 0.134673; batch adversarial loss: 0.491832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50; iter: 0; batch classifier loss: 0.092154; batch adversarial loss: 0.444937\n",
      "epoch 51; iter: 0; batch classifier loss: 0.126515; batch adversarial loss: 0.521045\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093200; batch adversarial loss: 0.440944\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106118; batch adversarial loss: 0.425524\n",
      "epoch 54; iter: 0; batch classifier loss: 0.064491; batch adversarial loss: 0.377388\n",
      "epoch 55; iter: 0; batch classifier loss: 0.096898; batch adversarial loss: 0.420269\n",
      "epoch 56; iter: 0; batch classifier loss: 0.142582; batch adversarial loss: 0.389313\n",
      "epoch 57; iter: 0; batch classifier loss: 0.122124; batch adversarial loss: 0.420994\n",
      "epoch 58; iter: 0; batch classifier loss: 0.150232; batch adversarial loss: 0.495564\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147191; batch adversarial loss: 0.416897\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089268; batch adversarial loss: 0.438848\n",
      "epoch 61; iter: 0; batch classifier loss: 0.076970; batch adversarial loss: 0.492644\n",
      "epoch 62; iter: 0; batch classifier loss: 0.099733; batch adversarial loss: 0.490065\n",
      "epoch 63; iter: 0; batch classifier loss: 0.095465; batch adversarial loss: 0.460338\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072079; batch adversarial loss: 0.467727\n",
      "epoch 65; iter: 0; batch classifier loss: 0.097238; batch adversarial loss: 0.463792\n",
      "epoch 66; iter: 0; batch classifier loss: 0.116122; batch adversarial loss: 0.450444\n",
      "epoch 67; iter: 0; batch classifier loss: 0.096163; batch adversarial loss: 0.391880\n",
      "epoch 68; iter: 0; batch classifier loss: 0.113952; batch adversarial loss: 0.451507\n",
      "epoch 69; iter: 0; batch classifier loss: 0.141135; batch adversarial loss: 0.411607\n",
      "epoch 70; iter: 0; batch classifier loss: 0.055042; batch adversarial loss: 0.448589\n",
      "epoch 71; iter: 0; batch classifier loss: 0.092181; batch adversarial loss: 0.492472\n",
      "epoch 72; iter: 0; batch classifier loss: 0.067401; batch adversarial loss: 0.492591\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069785; batch adversarial loss: 0.506353\n",
      "epoch 74; iter: 0; batch classifier loss: 0.101713; batch adversarial loss: 0.555611\n",
      "epoch 75; iter: 0; batch classifier loss: 0.052342; batch adversarial loss: 0.381928\n",
      "epoch 76; iter: 0; batch classifier loss: 0.110055; batch adversarial loss: 0.516031\n",
      "epoch 77; iter: 0; batch classifier loss: 0.140605; batch adversarial loss: 0.490084\n",
      "epoch 78; iter: 0; batch classifier loss: 0.136105; batch adversarial loss: 0.417711\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093819; batch adversarial loss: 0.487880\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087634; batch adversarial loss: 0.532698\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108460; batch adversarial loss: 0.380084\n",
      "epoch 82; iter: 0; batch classifier loss: 0.104721; batch adversarial loss: 0.526663\n",
      "epoch 83; iter: 0; batch classifier loss: 0.092948; batch adversarial loss: 0.457875\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071957; batch adversarial loss: 0.517700\n",
      "epoch 85; iter: 0; batch classifier loss: 0.072986; batch adversarial loss: 0.399520\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074011; batch adversarial loss: 0.489401\n",
      "epoch 87; iter: 0; batch classifier loss: 0.086196; batch adversarial loss: 0.446058\n",
      "epoch 88; iter: 0; batch classifier loss: 0.089067; batch adversarial loss: 0.384512\n",
      "epoch 89; iter: 0; batch classifier loss: 0.098316; batch adversarial loss: 0.443904\n",
      "epoch 90; iter: 0; batch classifier loss: 0.085349; batch adversarial loss: 0.479569\n",
      "epoch 91; iter: 0; batch classifier loss: 0.091222; batch adversarial loss: 0.447222\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079235; batch adversarial loss: 0.439497\n",
      "epoch 93; iter: 0; batch classifier loss: 0.065165; batch adversarial loss: 0.483353\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053434; batch adversarial loss: 0.467238\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066199; batch adversarial loss: 0.357522\n",
      "epoch 96; iter: 0; batch classifier loss: 0.066299; batch adversarial loss: 0.427895\n",
      "epoch 97; iter: 0; batch classifier loss: 0.084099; batch adversarial loss: 0.376278\n",
      "epoch 98; iter: 0; batch classifier loss: 0.058221; batch adversarial loss: 0.485700\n",
      "epoch 99; iter: 0; batch classifier loss: 0.082720; batch adversarial loss: 0.402804\n",
      "epoch 100; iter: 0; batch classifier loss: 0.043178; batch adversarial loss: 0.426549\n",
      "epoch 101; iter: 0; batch classifier loss: 0.040758; batch adversarial loss: 0.438489\n",
      "epoch 102; iter: 0; batch classifier loss: 0.051477; batch adversarial loss: 0.439188\n",
      "epoch 103; iter: 0; batch classifier loss: 0.063458; batch adversarial loss: 0.361443\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033065; batch adversarial loss: 0.528311\n",
      "epoch 105; iter: 0; batch classifier loss: 0.083318; batch adversarial loss: 0.503589\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044337; batch adversarial loss: 0.416228\n",
      "epoch 107; iter: 0; batch classifier loss: 0.059000; batch adversarial loss: 0.446099\n",
      "epoch 108; iter: 0; batch classifier loss: 0.034017; batch adversarial loss: 0.524554\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032336; batch adversarial loss: 0.446927\n",
      "epoch 110; iter: 0; batch classifier loss: 0.040004; batch adversarial loss: 0.431327\n",
      "epoch 111; iter: 0; batch classifier loss: 0.043694; batch adversarial loss: 0.551286\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033770; batch adversarial loss: 0.418901\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049002; batch adversarial loss: 0.527262\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068330; batch adversarial loss: 0.406270\n",
      "epoch 115; iter: 0; batch classifier loss: 0.038041; batch adversarial loss: 0.459011\n",
      "epoch 116; iter: 0; batch classifier loss: 0.061486; batch adversarial loss: 0.414261\n",
      "epoch 117; iter: 0; batch classifier loss: 0.041171; batch adversarial loss: 0.466411\n",
      "epoch 118; iter: 0; batch classifier loss: 0.067578; batch adversarial loss: 0.411365\n",
      "epoch 119; iter: 0; batch classifier loss: 0.044354; batch adversarial loss: 0.473109\n",
      "epoch 120; iter: 0; batch classifier loss: 0.052981; batch adversarial loss: 0.515785\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029959; batch adversarial loss: 0.462785\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062832; batch adversarial loss: 0.317195\n",
      "epoch 123; iter: 0; batch classifier loss: 0.068697; batch adversarial loss: 0.401141\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040731; batch adversarial loss: 0.489218\n",
      "epoch 125; iter: 0; batch classifier loss: 0.029732; batch adversarial loss: 0.445844\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042978; batch adversarial loss: 0.435962\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044605; batch adversarial loss: 0.470470\n",
      "epoch 128; iter: 0; batch classifier loss: 0.038363; batch adversarial loss: 0.442349\n",
      "epoch 129; iter: 0; batch classifier loss: 0.037317; batch adversarial loss: 0.444140\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048188; batch adversarial loss: 0.424986\n",
      "epoch 131; iter: 0; batch classifier loss: 0.049122; batch adversarial loss: 0.406643\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046949; batch adversarial loss: 0.402218\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047419; batch adversarial loss: 0.383719\n",
      "epoch 134; iter: 0; batch classifier loss: 0.033115; batch adversarial loss: 0.379999\n",
      "epoch 135; iter: 0; batch classifier loss: 0.036262; batch adversarial loss: 0.447869\n",
      "epoch 136; iter: 0; batch classifier loss: 0.058802; batch adversarial loss: 0.465710\n",
      "epoch 137; iter: 0; batch classifier loss: 0.017874; batch adversarial loss: 0.547834\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041123; batch adversarial loss: 0.438170\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028733; batch adversarial loss: 0.405763\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027699; batch adversarial loss: 0.424120\n",
      "epoch 141; iter: 0; batch classifier loss: 0.013893; batch adversarial loss: 0.460044\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035230; batch adversarial loss: 0.454302\n",
      "epoch 143; iter: 0; batch classifier loss: 0.026381; batch adversarial loss: 0.440231\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026710; batch adversarial loss: 0.393002\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.454151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 146; iter: 0; batch classifier loss: 0.033843; batch adversarial loss: 0.415202\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026343; batch adversarial loss: 0.461552\n",
      "epoch 148; iter: 0; batch classifier loss: 0.055857; batch adversarial loss: 0.440571\n",
      "epoch 149; iter: 0; batch classifier loss: 0.063468; batch adversarial loss: 0.440848\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052262; batch adversarial loss: 0.358962\n",
      "epoch 151; iter: 0; batch classifier loss: 0.045683; batch adversarial loss: 0.506444\n",
      "epoch 152; iter: 0; batch classifier loss: 0.061526; batch adversarial loss: 0.387731\n",
      "epoch 153; iter: 0; batch classifier loss: 0.043151; batch adversarial loss: 0.544086\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014759; batch adversarial loss: 0.592541\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031657; batch adversarial loss: 0.521433\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028954; batch adversarial loss: 0.479737\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022461; batch adversarial loss: 0.496180\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032197; batch adversarial loss: 0.478296\n",
      "epoch 159; iter: 0; batch classifier loss: 0.014014; batch adversarial loss: 0.496453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.500124\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017716; batch adversarial loss: 0.502003\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013259; batch adversarial loss: 0.479664\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019418; batch adversarial loss: 0.494781\n",
      "epoch 164; iter: 0; batch classifier loss: 0.014122; batch adversarial loss: 0.458085\n",
      "epoch 165; iter: 0; batch classifier loss: 0.028195; batch adversarial loss: 0.454904\n",
      "epoch 166; iter: 0; batch classifier loss: 0.034427; batch adversarial loss: 0.484828\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058540; batch adversarial loss: 0.398616\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012542; batch adversarial loss: 0.402829\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016302; batch adversarial loss: 0.494524\n",
      "epoch 170; iter: 0; batch classifier loss: 0.013320; batch adversarial loss: 0.423299\n",
      "epoch 171; iter: 0; batch classifier loss: 0.014498; batch adversarial loss: 0.474930\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013931; batch adversarial loss: 0.492810\n",
      "epoch 173; iter: 0; batch classifier loss: 0.012903; batch adversarial loss: 0.535527\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026458; batch adversarial loss: 0.425164\n",
      "epoch 175; iter: 0; batch classifier loss: 0.016827; batch adversarial loss: 0.362664\n",
      "epoch 176; iter: 0; batch classifier loss: 0.008667; batch adversarial loss: 0.427232\n",
      "epoch 177; iter: 0; batch classifier loss: 0.031833; batch adversarial loss: 0.400775\n",
      "epoch 178; iter: 0; batch classifier loss: 0.008084; batch adversarial loss: 0.483970\n",
      "epoch 179; iter: 0; batch classifier loss: 0.030623; batch adversarial loss: 0.363541\n",
      "epoch 180; iter: 0; batch classifier loss: 0.036810; batch adversarial loss: 0.436503\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013917; batch adversarial loss: 0.429388\n",
      "epoch 182; iter: 0; batch classifier loss: 0.015845; batch adversarial loss: 0.475004\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011900; batch adversarial loss: 0.406374\n",
      "epoch 184; iter: 0; batch classifier loss: 0.043341; batch adversarial loss: 0.447241\n",
      "epoch 185; iter: 0; batch classifier loss: 0.006054; batch adversarial loss: 0.499130\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016151; batch adversarial loss: 0.417486\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025195; batch adversarial loss: 0.468893\n",
      "epoch 188; iter: 0; batch classifier loss: 0.020352; batch adversarial loss: 0.481269\n",
      "epoch 189; iter: 0; batch classifier loss: 0.046776; batch adversarial loss: 0.417374\n",
      "epoch 190; iter: 0; batch classifier loss: 0.017646; batch adversarial loss: 0.513464\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019008; batch adversarial loss: 0.487809\n",
      "epoch 192; iter: 0; batch classifier loss: 0.024483; batch adversarial loss: 0.403103\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006144; batch adversarial loss: 0.431491\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011197; batch adversarial loss: 0.433525\n",
      "epoch 195; iter: 0; batch classifier loss: 0.037652; batch adversarial loss: 0.449081\n",
      "epoch 196; iter: 0; batch classifier loss: 0.024947; batch adversarial loss: 0.503548\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010348; batch adversarial loss: 0.422259\n",
      "epoch 198; iter: 0; batch classifier loss: 0.057586; batch adversarial loss: 0.481564\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034009; batch adversarial loss: 0.502888\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692643; batch adversarial loss: 0.702714\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471766; batch adversarial loss: 0.674659\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447175; batch adversarial loss: 0.633351\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344997; batch adversarial loss: 0.606017\n",
      "epoch 4; iter: 0; batch classifier loss: 0.379304; batch adversarial loss: 0.570343\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378887; batch adversarial loss: 0.556144\n",
      "epoch 6; iter: 0; batch classifier loss: 0.361975; batch adversarial loss: 0.547368\n",
      "epoch 7; iter: 0; batch classifier loss: 0.279802; batch adversarial loss: 0.547686\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271503; batch adversarial loss: 0.524507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.246798; batch adversarial loss: 0.502496\n",
      "epoch 10; iter: 0; batch classifier loss: 0.284626; batch adversarial loss: 0.520576\n",
      "epoch 11; iter: 0; batch classifier loss: 0.151904; batch adversarial loss: 0.560182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.186358; batch adversarial loss: 0.499797\n",
      "epoch 13; iter: 0; batch classifier loss: 0.186694; batch adversarial loss: 0.428245\n",
      "epoch 14; iter: 0; batch classifier loss: 0.167559; batch adversarial loss: 0.456495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.190345; batch adversarial loss: 0.413316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.172707; batch adversarial loss: 0.459593\n",
      "epoch 17; iter: 0; batch classifier loss: 0.137609; batch adversarial loss: 0.418223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.166871; batch adversarial loss: 0.428385\n",
      "epoch 19; iter: 0; batch classifier loss: 0.200482; batch adversarial loss: 0.461209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.193107; batch adversarial loss: 0.415994\n",
      "epoch 21; iter: 0; batch classifier loss: 0.121936; batch adversarial loss: 0.480021\n",
      "epoch 22; iter: 0; batch classifier loss: 0.129283; batch adversarial loss: 0.389891\n",
      "epoch 23; iter: 0; batch classifier loss: 0.151354; batch adversarial loss: 0.439523\n",
      "epoch 24; iter: 0; batch classifier loss: 0.194806; batch adversarial loss: 0.472753\n",
      "epoch 25; iter: 0; batch classifier loss: 0.185915; batch adversarial loss: 0.443195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170433; batch adversarial loss: 0.371444\n",
      "epoch 27; iter: 0; batch classifier loss: 0.130923; batch adversarial loss: 0.377850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.189819; batch adversarial loss: 0.356341\n",
      "epoch 29; iter: 0; batch classifier loss: 0.120809; batch adversarial loss: 0.418925\n",
      "epoch 30; iter: 0; batch classifier loss: 0.175810; batch adversarial loss: 0.434826\n",
      "epoch 31; iter: 0; batch classifier loss: 0.168862; batch adversarial loss: 0.360202\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129902; batch adversarial loss: 0.413872\n",
      "epoch 33; iter: 0; batch classifier loss: 0.181420; batch adversarial loss: 0.449427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.162412; batch adversarial loss: 0.397911\n",
      "epoch 35; iter: 0; batch classifier loss: 0.162125; batch adversarial loss: 0.466524\n",
      "epoch 36; iter: 0; batch classifier loss: 0.150552; batch adversarial loss: 0.398161\n",
      "epoch 37; iter: 0; batch classifier loss: 0.167231; batch adversarial loss: 0.384299\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140094; batch adversarial loss: 0.421298\n",
      "epoch 39; iter: 0; batch classifier loss: 0.094156; batch adversarial loss: 0.419532\n",
      "epoch 40; iter: 0; batch classifier loss: 0.099118; batch adversarial loss: 0.388184\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098989; batch adversarial loss: 0.456976\n",
      "epoch 42; iter: 0; batch classifier loss: 0.123346; batch adversarial loss: 0.466757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 0; batch classifier loss: 0.092396; batch adversarial loss: 0.493321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.074059; batch adversarial loss: 0.332542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.092863; batch adversarial loss: 0.511705\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099225; batch adversarial loss: 0.376103\n",
      "epoch 47; iter: 0; batch classifier loss: 0.122431; batch adversarial loss: 0.435024\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132810; batch adversarial loss: 0.496805\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136700; batch adversarial loss: 0.362074\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059826; batch adversarial loss: 0.411132\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117576; batch adversarial loss: 0.385594\n",
      "epoch 52; iter: 0; batch classifier loss: 0.079637; batch adversarial loss: 0.445313\n",
      "epoch 53; iter: 0; batch classifier loss: 0.102137; batch adversarial loss: 0.464093\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127078; batch adversarial loss: 0.409885\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087240; batch adversarial loss: 0.434173\n",
      "epoch 56; iter: 0; batch classifier loss: 0.091712; batch adversarial loss: 0.445537\n",
      "epoch 57; iter: 0; batch classifier loss: 0.138567; batch adversarial loss: 0.441429\n",
      "epoch 58; iter: 0; batch classifier loss: 0.076254; batch adversarial loss: 0.452418\n",
      "epoch 59; iter: 0; batch classifier loss: 0.099832; batch adversarial loss: 0.408790\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078680; batch adversarial loss: 0.430205\n",
      "epoch 61; iter: 0; batch classifier loss: 0.079544; batch adversarial loss: 0.433580\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102245; batch adversarial loss: 0.394379\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088311; batch adversarial loss: 0.445142\n",
      "epoch 64; iter: 0; batch classifier loss: 0.074554; batch adversarial loss: 0.385135\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077208; batch adversarial loss: 0.451652\n",
      "epoch 66; iter: 0; batch classifier loss: 0.110218; batch adversarial loss: 0.456892\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060876; batch adversarial loss: 0.456370\n",
      "epoch 68; iter: 0; batch classifier loss: 0.048376; batch adversarial loss: 0.438850\n",
      "epoch 69; iter: 0; batch classifier loss: 0.084489; batch adversarial loss: 0.477525\n",
      "epoch 70; iter: 0; batch classifier loss: 0.111865; batch adversarial loss: 0.410172\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095428; batch adversarial loss: 0.432176\n",
      "epoch 72; iter: 0; batch classifier loss: 0.114729; batch adversarial loss: 0.455365\n",
      "epoch 73; iter: 0; batch classifier loss: 0.082415; batch adversarial loss: 0.400626\n",
      "epoch 74; iter: 0; batch classifier loss: 0.065135; batch adversarial loss: 0.371587\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100858; batch adversarial loss: 0.415479\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088476; batch adversarial loss: 0.453230\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086620; batch adversarial loss: 0.377887\n",
      "epoch 78; iter: 0; batch classifier loss: 0.096792; batch adversarial loss: 0.418511\n",
      "epoch 79; iter: 0; batch classifier loss: 0.107790; batch adversarial loss: 0.402969\n",
      "epoch 80; iter: 0; batch classifier loss: 0.056415; batch adversarial loss: 0.436981\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113134; batch adversarial loss: 0.486803\n",
      "epoch 82; iter: 0; batch classifier loss: 0.107698; batch adversarial loss: 0.476013\n",
      "epoch 83; iter: 0; batch classifier loss: 0.069950; batch adversarial loss: 0.480672\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076616; batch adversarial loss: 0.431004\n",
      "epoch 85; iter: 0; batch classifier loss: 0.097111; batch adversarial loss: 0.494006\n",
      "epoch 86; iter: 0; batch classifier loss: 0.073747; batch adversarial loss: 0.451801\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062895; batch adversarial loss: 0.463615\n",
      "epoch 88; iter: 0; batch classifier loss: 0.068073; batch adversarial loss: 0.534669\n",
      "epoch 89; iter: 0; batch classifier loss: 0.048584; batch adversarial loss: 0.403034\n",
      "epoch 90; iter: 0; batch classifier loss: 0.100008; batch adversarial loss: 0.396550\n",
      "epoch 91; iter: 0; batch classifier loss: 0.086250; batch adversarial loss: 0.504667\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068180; batch adversarial loss: 0.405615\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044867; batch adversarial loss: 0.404233\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049893; batch adversarial loss: 0.401213\n",
      "epoch 95; iter: 0; batch classifier loss: 0.060561; batch adversarial loss: 0.335813\n",
      "epoch 96; iter: 0; batch classifier loss: 0.086278; batch adversarial loss: 0.369096\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060727; batch adversarial loss: 0.440738\n",
      "epoch 98; iter: 0; batch classifier loss: 0.050558; batch adversarial loss: 0.386548\n",
      "epoch 99; iter: 0; batch classifier loss: 0.031587; batch adversarial loss: 0.487321\n",
      "epoch 100; iter: 0; batch classifier loss: 0.068828; batch adversarial loss: 0.523837\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047891; batch adversarial loss: 0.369431\n",
      "epoch 102; iter: 0; batch classifier loss: 0.027255; batch adversarial loss: 0.516679\n",
      "epoch 103; iter: 0; batch classifier loss: 0.059368; batch adversarial loss: 0.388768\n",
      "epoch 104; iter: 0; batch classifier loss: 0.033976; batch adversarial loss: 0.484462\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037597; batch adversarial loss: 0.523125\n",
      "epoch 106; iter: 0; batch classifier loss: 0.050150; batch adversarial loss: 0.456066\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046902; batch adversarial loss: 0.360363\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049875; batch adversarial loss: 0.495775\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029754; batch adversarial loss: 0.454138\n",
      "epoch 110; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.463374\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050444; batch adversarial loss: 0.566330\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030727; batch adversarial loss: 0.456421\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037417; batch adversarial loss: 0.489016\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037138; batch adversarial loss: 0.488381\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048765; batch adversarial loss: 0.436825\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078396; batch adversarial loss: 0.447473\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039963; batch adversarial loss: 0.557979\n",
      "epoch 118; iter: 0; batch classifier loss: 0.011919; batch adversarial loss: 0.423963\n",
      "epoch 119; iter: 0; batch classifier loss: 0.060392; batch adversarial loss: 0.445923\n",
      "epoch 120; iter: 0; batch classifier loss: 0.040071; batch adversarial loss: 0.514513\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055808; batch adversarial loss: 0.524015\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034674; batch adversarial loss: 0.519153\n",
      "epoch 123; iter: 0; batch classifier loss: 0.071080; batch adversarial loss: 0.577721\n",
      "epoch 124; iter: 0; batch classifier loss: 0.090233; batch adversarial loss: 0.580684\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060204; batch adversarial loss: 0.539730\n",
      "epoch 126; iter: 0; batch classifier loss: 0.071641; batch adversarial loss: 0.528668\n",
      "epoch 127; iter: 0; batch classifier loss: 0.130585; batch adversarial loss: 0.722058\n",
      "epoch 128; iter: 0; batch classifier loss: 0.068311; batch adversarial loss: 0.461441\n",
      "epoch 129; iter: 0; batch classifier loss: 0.140193; batch adversarial loss: 0.650111\n",
      "epoch 130; iter: 0; batch classifier loss: 0.142737; batch adversarial loss: 0.615420\n",
      "epoch 131; iter: 0; batch classifier loss: 0.147742; batch adversarial loss: 0.641201\n",
      "epoch 132; iter: 0; batch classifier loss: 0.113355; batch adversarial loss: 0.561343\n",
      "epoch 133; iter: 0; batch classifier loss: 0.194040; batch adversarial loss: 0.714274\n",
      "epoch 134; iter: 0; batch classifier loss: 0.136545; batch adversarial loss: 0.691437\n",
      "epoch 135; iter: 0; batch classifier loss: 0.149719; batch adversarial loss: 0.639801\n",
      "epoch 136; iter: 0; batch classifier loss: 0.203958; batch adversarial loss: 0.771853\n",
      "epoch 137; iter: 0; batch classifier loss: 0.153073; batch adversarial loss: 0.585292\n",
      "epoch 138; iter: 0; batch classifier loss: 0.154172; batch adversarial loss: 0.636943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 139; iter: 0; batch classifier loss: 0.141409; batch adversarial loss: 0.565123\n",
      "epoch 140; iter: 0; batch classifier loss: 0.215331; batch adversarial loss: 0.674996\n",
      "epoch 141; iter: 0; batch classifier loss: 0.223450; batch adversarial loss: 0.578574\n",
      "epoch 142; iter: 0; batch classifier loss: 0.139477; batch adversarial loss: 0.503919\n",
      "epoch 143; iter: 0; batch classifier loss: 0.106594; batch adversarial loss: 0.558301\n",
      "epoch 144; iter: 0; batch classifier loss: 0.234297; batch adversarial loss: 0.663120\n",
      "epoch 145; iter: 0; batch classifier loss: 0.204408; batch adversarial loss: 0.600144\n",
      "epoch 146; iter: 0; batch classifier loss: 0.198414; batch adversarial loss: 0.685409\n",
      "epoch 147; iter: 0; batch classifier loss: 0.057694; batch adversarial loss: 0.397040\n",
      "epoch 148; iter: 0; batch classifier loss: 0.152383; batch adversarial loss: 0.494189\n",
      "epoch 149; iter: 0; batch classifier loss: 0.176024; batch adversarial loss: 0.615518\n",
      "epoch 150; iter: 0; batch classifier loss: 0.174183; batch adversarial loss: 0.514322\n",
      "epoch 151; iter: 0; batch classifier loss: 0.160977; batch adversarial loss: 0.430567\n",
      "epoch 152; iter: 0; batch classifier loss: 0.197736; batch adversarial loss: 0.499800\n",
      "epoch 153; iter: 0; batch classifier loss: 0.141557; batch adversarial loss: 0.505709\n",
      "epoch 154; iter: 0; batch classifier loss: 0.099516; batch adversarial loss: 0.549281\n",
      "epoch 155; iter: 0; batch classifier loss: 0.091073; batch adversarial loss: 0.457674\n",
      "epoch 156; iter: 0; batch classifier loss: 0.066872; batch adversarial loss: 0.470774\n",
      "epoch 157; iter: 0; batch classifier loss: 0.119976; batch adversarial loss: 0.515275\n",
      "epoch 158; iter: 0; batch classifier loss: 0.110394; batch adversarial loss: 0.473733\n",
      "epoch 159; iter: 0; batch classifier loss: 0.082944; batch adversarial loss: 0.369880\n",
      "epoch 160; iter: 0; batch classifier loss: 0.111337; batch adversarial loss: 0.418105\n",
      "epoch 161; iter: 0; batch classifier loss: 0.133742; batch adversarial loss: 0.478680\n",
      "epoch 162; iter: 0; batch classifier loss: 0.133491; batch adversarial loss: 0.575148\n",
      "epoch 163; iter: 0; batch classifier loss: 0.069245; batch adversarial loss: 0.467095\n",
      "epoch 164; iter: 0; batch classifier loss: 0.140064; batch adversarial loss: 0.578756\n",
      "epoch 165; iter: 0; batch classifier loss: 0.064997; batch adversarial loss: 0.401701\n",
      "epoch 166; iter: 0; batch classifier loss: 0.095367; batch adversarial loss: 0.410931\n",
      "epoch 167; iter: 0; batch classifier loss: 0.111102; batch adversarial loss: 0.457878\n",
      "epoch 168; iter: 0; batch classifier loss: 0.062570; batch adversarial loss: 0.445524\n",
      "epoch 169; iter: 0; batch classifier loss: 0.058821; batch adversarial loss: 0.382265\n",
      "epoch 170; iter: 0; batch classifier loss: 0.046859; batch adversarial loss: 0.530525\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040214; batch adversarial loss: 0.443363\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022377; batch adversarial loss: 0.488224\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027297; batch adversarial loss: 0.468708\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012834; batch adversarial loss: 0.509541\n",
      "epoch 175; iter: 0; batch classifier loss: 0.028451; batch adversarial loss: 0.518694\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031613; batch adversarial loss: 0.470451\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037012; batch adversarial loss: 0.357504\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052203; batch adversarial loss: 0.444436\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040845; batch adversarial loss: 0.445289\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034901; batch adversarial loss: 0.387622\n",
      "epoch 181; iter: 0; batch classifier loss: 0.069399; batch adversarial loss: 0.407050\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053915; batch adversarial loss: 0.506510\n",
      "epoch 183; iter: 0; batch classifier loss: 0.039470; batch adversarial loss: 0.515043\n",
      "epoch 184; iter: 0; batch classifier loss: 0.045407; batch adversarial loss: 0.453088\n",
      "epoch 185; iter: 0; batch classifier loss: 0.048696; batch adversarial loss: 0.478531\n",
      "epoch 186; iter: 0; batch classifier loss: 0.089930; batch adversarial loss: 0.439813\n",
      "epoch 187; iter: 0; batch classifier loss: 0.091900; batch adversarial loss: 0.405437\n",
      "epoch 188; iter: 0; batch classifier loss: 0.098547; batch adversarial loss: 0.473560\n",
      "epoch 189; iter: 0; batch classifier loss: 0.091138; batch adversarial loss: 0.413843\n",
      "epoch 190; iter: 0; batch classifier loss: 0.074135; batch adversarial loss: 0.495309\n",
      "epoch 191; iter: 0; batch classifier loss: 0.067655; batch adversarial loss: 0.369127\n",
      "epoch 192; iter: 0; batch classifier loss: 0.062785; batch adversarial loss: 0.430851\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037016; batch adversarial loss: 0.561911\n",
      "epoch 194; iter: 0; batch classifier loss: 0.075529; batch adversarial loss: 0.520545\n",
      "epoch 195; iter: 0; batch classifier loss: 0.070226; batch adversarial loss: 0.553556\n",
      "epoch 196; iter: 0; batch classifier loss: 0.126118; batch adversarial loss: 0.467654\n",
      "epoch 197; iter: 0; batch classifier loss: 0.079477; batch adversarial loss: 0.515389\n",
      "epoch 198; iter: 0; batch classifier loss: 0.092565; batch adversarial loss: 0.437494\n",
      "epoch 199; iter: 0; batch classifier loss: 0.164039; batch adversarial loss: 0.487043\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701096; batch adversarial loss: 0.695306\n",
      "epoch 1; iter: 0; batch classifier loss: 0.471900; batch adversarial loss: 0.667777\n",
      "epoch 2; iter: 0; batch classifier loss: 0.471300; batch adversarial loss: 0.650318\n",
      "epoch 3; iter: 0; batch classifier loss: 0.494524; batch adversarial loss: 0.615891\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535754; batch adversarial loss: 0.595554\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588721; batch adversarial loss: 0.590159\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548131; batch adversarial loss: 0.578578\n",
      "epoch 7; iter: 0; batch classifier loss: 0.395026; batch adversarial loss: 0.583660\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417814; batch adversarial loss: 0.533143\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340153; batch adversarial loss: 0.564147\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405150; batch adversarial loss: 0.524410\n",
      "epoch 11; iter: 0; batch classifier loss: 0.436583; batch adversarial loss: 0.519837\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494151; batch adversarial loss: 0.536991\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435756; batch adversarial loss: 0.525760\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294896; batch adversarial loss: 0.484828\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326865; batch adversarial loss: 0.524713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298243; batch adversarial loss: 0.562924\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267579; batch adversarial loss: 0.548191\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305522; batch adversarial loss: 0.502437\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355006; batch adversarial loss: 0.413746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285710; batch adversarial loss: 0.530340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290895; batch adversarial loss: 0.470648\n",
      "epoch 22; iter: 0; batch classifier loss: 0.301676; batch adversarial loss: 0.487529\n",
      "epoch 23; iter: 0; batch classifier loss: 0.251753; batch adversarial loss: 0.494238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266828; batch adversarial loss: 0.461050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.263427; batch adversarial loss: 0.506099\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298563; batch adversarial loss: 0.448956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.249814; batch adversarial loss: 0.447967\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267298; batch adversarial loss: 0.421935\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301926; batch adversarial loss: 0.455038\n",
      "epoch 30; iter: 0; batch classifier loss: 0.207760; batch adversarial loss: 0.441970\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317317; batch adversarial loss: 0.445443\n",
      "epoch 32; iter: 0; batch classifier loss: 0.224855; batch adversarial loss: 0.421215\n",
      "epoch 33; iter: 0; batch classifier loss: 0.239985; batch adversarial loss: 0.429797\n",
      "epoch 34; iter: 0; batch classifier loss: 0.184688; batch adversarial loss: 0.529876\n",
      "epoch 35; iter: 0; batch classifier loss: 0.308031; batch adversarial loss: 0.395784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.188675; batch adversarial loss: 0.471344\n",
      "epoch 37; iter: 0; batch classifier loss: 0.254020; batch adversarial loss: 0.493507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.222261; batch adversarial loss: 0.470099\n",
      "epoch 39; iter: 0; batch classifier loss: 0.242129; batch adversarial loss: 0.470753\n",
      "epoch 40; iter: 0; batch classifier loss: 0.174467; batch adversarial loss: 0.472715\n",
      "epoch 41; iter: 0; batch classifier loss: 0.308052; batch adversarial loss: 0.367721\n",
      "epoch 42; iter: 0; batch classifier loss: 0.223856; batch adversarial loss: 0.425022\n",
      "epoch 43; iter: 0; batch classifier loss: 0.164008; batch adversarial loss: 0.481751\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108566; batch adversarial loss: 0.408342\n",
      "epoch 45; iter: 0; batch classifier loss: 0.073360; batch adversarial loss: 0.380794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.096918; batch adversarial loss: 0.460535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.064182; batch adversarial loss: 0.435060\n",
      "epoch 48; iter: 0; batch classifier loss: 0.066053; batch adversarial loss: 0.537389\n",
      "epoch 49; iter: 0; batch classifier loss: 0.063032; batch adversarial loss: 0.453969\n",
      "epoch 50; iter: 0; batch classifier loss: 0.085773; batch adversarial loss: 0.530862\n",
      "epoch 51; iter: 0; batch classifier loss: 0.069503; batch adversarial loss: 0.476932\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071191; batch adversarial loss: 0.473887\n",
      "epoch 53; iter: 0; batch classifier loss: 0.094464; batch adversarial loss: 0.399189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.044656; batch adversarial loss: 0.458817\n",
      "epoch 55; iter: 0; batch classifier loss: 0.055071; batch adversarial loss: 0.423685\n",
      "epoch 56; iter: 0; batch classifier loss: 0.109044; batch adversarial loss: 0.457784\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113082; batch adversarial loss: 0.484286\n",
      "epoch 58; iter: 0; batch classifier loss: 0.133891; batch adversarial loss: 0.436378\n",
      "epoch 59; iter: 0; batch classifier loss: 0.060873; batch adversarial loss: 0.477375\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089524; batch adversarial loss: 0.463347\n",
      "epoch 61; iter: 0; batch classifier loss: 0.094947; batch adversarial loss: 0.427704\n",
      "epoch 62; iter: 0; batch classifier loss: 0.060581; batch adversarial loss: 0.489617\n",
      "epoch 63; iter: 0; batch classifier loss: 0.083355; batch adversarial loss: 0.452115\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092130; batch adversarial loss: 0.354253\n",
      "epoch 65; iter: 0; batch classifier loss: 0.064593; batch adversarial loss: 0.404590\n",
      "epoch 66; iter: 0; batch classifier loss: 0.057846; batch adversarial loss: 0.427018\n",
      "epoch 67; iter: 0; batch classifier loss: 0.031779; batch adversarial loss: 0.543385\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081340; batch adversarial loss: 0.410989\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052971; batch adversarial loss: 0.435220\n",
      "epoch 70; iter: 0; batch classifier loss: 0.072992; batch adversarial loss: 0.391889\n",
      "epoch 71; iter: 0; batch classifier loss: 0.086112; batch adversarial loss: 0.502511\n",
      "epoch 72; iter: 0; batch classifier loss: 0.047392; batch adversarial loss: 0.502432\n",
      "epoch 73; iter: 0; batch classifier loss: 0.040544; batch adversarial loss: 0.427490\n",
      "epoch 74; iter: 0; batch classifier loss: 0.062225; batch adversarial loss: 0.458292\n",
      "epoch 75; iter: 0; batch classifier loss: 0.056285; batch adversarial loss: 0.360969\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089709; batch adversarial loss: 0.518194\n",
      "epoch 77; iter: 0; batch classifier loss: 0.044336; batch adversarial loss: 0.480689\n",
      "epoch 78; iter: 0; batch classifier loss: 0.067279; batch adversarial loss: 0.433814\n",
      "epoch 79; iter: 0; batch classifier loss: 0.044137; batch adversarial loss: 0.509607\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087584; batch adversarial loss: 0.422273\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054595; batch adversarial loss: 0.516184\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066797; batch adversarial loss: 0.504304\n",
      "epoch 83; iter: 0; batch classifier loss: 0.090077; batch adversarial loss: 0.477961\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077998; batch adversarial loss: 0.436126\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070388; batch adversarial loss: 0.495573\n",
      "epoch 86; iter: 0; batch classifier loss: 0.070522; batch adversarial loss: 0.406558\n",
      "epoch 87; iter: 0; batch classifier loss: 0.076227; batch adversarial loss: 0.454863\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073117; batch adversarial loss: 0.496431\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050911; batch adversarial loss: 0.487917\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036927; batch adversarial loss: 0.408513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057059; batch adversarial loss: 0.580376\n",
      "epoch 92; iter: 0; batch classifier loss: 0.030522; batch adversarial loss: 0.439862\n",
      "epoch 93; iter: 0; batch classifier loss: 0.044018; batch adversarial loss: 0.451608\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090771; batch adversarial loss: 0.475269\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038923; batch adversarial loss: 0.536450\n",
      "epoch 96; iter: 0; batch classifier loss: 0.049234; batch adversarial loss: 0.386867\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033676; batch adversarial loss: 0.441346\n",
      "epoch 98; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.397476\n",
      "epoch 99; iter: 0; batch classifier loss: 0.040615; batch adversarial loss: 0.434942\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032751; batch adversarial loss: 0.431238\n",
      "epoch 101; iter: 0; batch classifier loss: 0.115634; batch adversarial loss: 0.374590\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062238; batch adversarial loss: 0.452097\n",
      "epoch 103; iter: 0; batch classifier loss: 0.042310; batch adversarial loss: 0.480138\n",
      "epoch 104; iter: 0; batch classifier loss: 0.026303; batch adversarial loss: 0.519500\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071596; batch adversarial loss: 0.433110\n",
      "epoch 106; iter: 0; batch classifier loss: 0.068690; batch adversarial loss: 0.474058\n",
      "epoch 107; iter: 0; batch classifier loss: 0.044111; batch adversarial loss: 0.390086\n",
      "epoch 108; iter: 0; batch classifier loss: 0.026143; batch adversarial loss: 0.419587\n",
      "epoch 109; iter: 0; batch classifier loss: 0.032400; batch adversarial loss: 0.380771\n",
      "epoch 110; iter: 0; batch classifier loss: 0.037034; batch adversarial loss: 0.432418\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069734; batch adversarial loss: 0.408642\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030674; batch adversarial loss: 0.565160\n",
      "epoch 113; iter: 0; batch classifier loss: 0.044190; batch adversarial loss: 0.364437\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022315; batch adversarial loss: 0.459429\n",
      "epoch 115; iter: 0; batch classifier loss: 0.023169; batch adversarial loss: 0.394976\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058813; batch adversarial loss: 0.370333\n",
      "epoch 117; iter: 0; batch classifier loss: 0.051585; batch adversarial loss: 0.461440\n",
      "epoch 118; iter: 0; batch classifier loss: 0.022475; batch adversarial loss: 0.407716\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024713; batch adversarial loss: 0.424025\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046261; batch adversarial loss: 0.526169\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021833; batch adversarial loss: 0.493278\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.554931\n",
      "epoch 123; iter: 0; batch classifier loss: 0.025376; batch adversarial loss: 0.422753\n",
      "epoch 124; iter: 0; batch classifier loss: 0.023201; batch adversarial loss: 0.481575\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017400; batch adversarial loss: 0.441787\n",
      "epoch 126; iter: 0; batch classifier loss: 0.016205; batch adversarial loss: 0.460564\n",
      "epoch 127; iter: 0; batch classifier loss: 0.013972; batch adversarial loss: 0.390100\n",
      "epoch 128; iter: 0; batch classifier loss: 0.066818; batch adversarial loss: 0.517977\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026886; batch adversarial loss: 0.487617\n",
      "epoch 130; iter: 0; batch classifier loss: 0.041013; batch adversarial loss: 0.438350\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026724; batch adversarial loss: 0.436098\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044594; batch adversarial loss: 0.454802\n",
      "epoch 133; iter: 0; batch classifier loss: 0.017115; batch adversarial loss: 0.482177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.026025; batch adversarial loss: 0.492752\n",
      "epoch 135; iter: 0; batch classifier loss: 0.021170; batch adversarial loss: 0.480883\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025828; batch adversarial loss: 0.394895\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036102; batch adversarial loss: 0.435055\n",
      "epoch 138; iter: 0; batch classifier loss: 0.033875; batch adversarial loss: 0.525526\n",
      "epoch 139; iter: 0; batch classifier loss: 0.023165; batch adversarial loss: 0.444269\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053293; batch adversarial loss: 0.515749\n",
      "epoch 141; iter: 0; batch classifier loss: 0.012550; batch adversarial loss: 0.582428\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019698; batch adversarial loss: 0.393129\n",
      "epoch 143; iter: 0; batch classifier loss: 0.067212; batch adversarial loss: 0.379980\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050459; batch adversarial loss: 0.430516\n",
      "epoch 145; iter: 0; batch classifier loss: 0.023352; batch adversarial loss: 0.420730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024942; batch adversarial loss: 0.451930\n",
      "epoch 147; iter: 0; batch classifier loss: 0.038148; batch adversarial loss: 0.492479\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013179; batch adversarial loss: 0.568466\n",
      "epoch 149; iter: 0; batch classifier loss: 0.027609; batch adversarial loss: 0.434391\n",
      "epoch 150; iter: 0; batch classifier loss: 0.052299; batch adversarial loss: 0.453256\n",
      "epoch 151; iter: 0; batch classifier loss: 0.019439; batch adversarial loss: 0.425866\n",
      "epoch 152; iter: 0; batch classifier loss: 0.042430; batch adversarial loss: 0.487544\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017734; batch adversarial loss: 0.452353\n",
      "epoch 154; iter: 0; batch classifier loss: 0.019333; batch adversarial loss: 0.403107\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021897; batch adversarial loss: 0.413029\n",
      "epoch 156; iter: 0; batch classifier loss: 0.006380; batch adversarial loss: 0.566576\n",
      "epoch 157; iter: 0; batch classifier loss: 0.005388; batch adversarial loss: 0.438879\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023534; batch adversarial loss: 0.442379\n",
      "epoch 159; iter: 0; batch classifier loss: 0.012946; batch adversarial loss: 0.465958\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035621; batch adversarial loss: 0.585259\n",
      "epoch 161; iter: 0; batch classifier loss: 0.025451; batch adversarial loss: 0.477445\n",
      "epoch 162; iter: 0; batch classifier loss: 0.022589; batch adversarial loss: 0.490757\n",
      "epoch 163; iter: 0; batch classifier loss: 0.013241; batch adversarial loss: 0.387154\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027386; batch adversarial loss: 0.476943\n",
      "epoch 165; iter: 0; batch classifier loss: 0.001487; batch adversarial loss: 0.401943\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023135; batch adversarial loss: 0.470013\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015115; batch adversarial loss: 0.461067\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013487; batch adversarial loss: 0.599564\n",
      "epoch 169; iter: 0; batch classifier loss: 0.015568; batch adversarial loss: 0.556531\n",
      "epoch 170; iter: 0; batch classifier loss: 0.014411; batch adversarial loss: 0.536409\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035208; batch adversarial loss: 0.447457\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015224; batch adversarial loss: 0.477214\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009895; batch adversarial loss: 0.526572\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013858; batch adversarial loss: 0.380427\n",
      "epoch 175; iter: 0; batch classifier loss: 0.017608; batch adversarial loss: 0.380746\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037060; batch adversarial loss: 0.532759\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014380; batch adversarial loss: 0.428010\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.409239\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019532; batch adversarial loss: 0.479635\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022483; batch adversarial loss: 0.523516\n",
      "epoch 181; iter: 0; batch classifier loss: 0.020800; batch adversarial loss: 0.406745\n",
      "epoch 182; iter: 0; batch classifier loss: 0.006169; batch adversarial loss: 0.507155\n",
      "epoch 183; iter: 0; batch classifier loss: 0.040585; batch adversarial loss: 0.429111\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019775; batch adversarial loss: 0.399030\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029785; batch adversarial loss: 0.351519\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025435; batch adversarial loss: 0.430571\n",
      "epoch 187; iter: 0; batch classifier loss: 0.012511; batch adversarial loss: 0.437116\n",
      "epoch 188; iter: 0; batch classifier loss: 0.022748; batch adversarial loss: 0.408787\n",
      "epoch 189; iter: 0; batch classifier loss: 0.032860; batch adversarial loss: 0.373594\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023236; batch adversarial loss: 0.435861\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015167; batch adversarial loss: 0.433054\n",
      "epoch 192; iter: 0; batch classifier loss: 0.005590; batch adversarial loss: 0.479574\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010726; batch adversarial loss: 0.429823\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028375; batch adversarial loss: 0.402430\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023535; batch adversarial loss: 0.460036\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015698; batch adversarial loss: 0.439964\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019794; batch adversarial loss: 0.412906\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039865; batch adversarial loss: 0.474398\n",
      "epoch 199; iter: 0; batch classifier loss: 0.007577; batch adversarial loss: 0.451591\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703440; batch adversarial loss: 0.510304\n",
      "epoch 1; iter: 0; batch classifier loss: 0.409669; batch adversarial loss: 0.601705\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375134; batch adversarial loss: 0.604920\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423402; batch adversarial loss: 0.673224\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385957; batch adversarial loss: 0.582797\n",
      "epoch 5; iter: 0; batch classifier loss: 0.295814; batch adversarial loss: 0.557821\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362979; batch adversarial loss: 0.594950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367094; batch adversarial loss: 0.591361\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354442; batch adversarial loss: 0.527608\n",
      "epoch 9; iter: 0; batch classifier loss: 0.395390; batch adversarial loss: 0.595950\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433638; batch adversarial loss: 0.563362\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522141; batch adversarial loss: 0.576488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.663463; batch adversarial loss: 0.485626\n",
      "epoch 13; iter: 0; batch classifier loss: 0.605587; batch adversarial loss: 0.516746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343122; batch adversarial loss: 0.502438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374193; batch adversarial loss: 0.476045\n",
      "epoch 16; iter: 0; batch classifier loss: 0.295678; batch adversarial loss: 0.475856\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255180; batch adversarial loss: 0.529613\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241685; batch adversarial loss: 0.397676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270789; batch adversarial loss: 0.470112\n",
      "epoch 20; iter: 0; batch classifier loss: 0.211047; batch adversarial loss: 0.429299\n",
      "epoch 21; iter: 0; batch classifier loss: 0.216928; batch adversarial loss: 0.423579\n",
      "epoch 22; iter: 0; batch classifier loss: 0.214227; batch adversarial loss: 0.456274\n",
      "epoch 23; iter: 0; batch classifier loss: 0.191263; batch adversarial loss: 0.496869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184127; batch adversarial loss: 0.422941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192437; batch adversarial loss: 0.501629\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176997; batch adversarial loss: 0.505870\n",
      "epoch 27; iter: 0; batch classifier loss: 0.166632; batch adversarial loss: 0.539382\n",
      "epoch 28; iter: 0; batch classifier loss: 0.161484; batch adversarial loss: 0.458868\n",
      "epoch 29; iter: 0; batch classifier loss: 0.157728; batch adversarial loss: 0.454345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.167036; batch adversarial loss: 0.400550\n",
      "epoch 31; iter: 0; batch classifier loss: 0.104182; batch adversarial loss: 0.428236\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154890; batch adversarial loss: 0.560557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.137686; batch adversarial loss: 0.493417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.159100; batch adversarial loss: 0.377400\n",
      "epoch 35; iter: 0; batch classifier loss: 0.157358; batch adversarial loss: 0.445981\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162786; batch adversarial loss: 0.428619\n",
      "epoch 37; iter: 0; batch classifier loss: 0.101175; batch adversarial loss: 0.402516\n",
      "epoch 38; iter: 0; batch classifier loss: 0.157940; batch adversarial loss: 0.458450\n",
      "epoch 39; iter: 0; batch classifier loss: 0.078828; batch adversarial loss: 0.567181\n",
      "epoch 40; iter: 0; batch classifier loss: 0.143851; batch adversarial loss: 0.418107\n",
      "epoch 41; iter: 0; batch classifier loss: 0.113518; batch adversarial loss: 0.424145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120235; batch adversarial loss: 0.388128\n",
      "epoch 43; iter: 0; batch classifier loss: 0.186272; batch adversarial loss: 0.493779\n",
      "epoch 44; iter: 0; batch classifier loss: 0.101720; batch adversarial loss: 0.423654\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140935; batch adversarial loss: 0.467791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094518; batch adversarial loss: 0.425920\n",
      "epoch 47; iter: 0; batch classifier loss: 0.101524; batch adversarial loss: 0.435402\n",
      "epoch 48; iter: 0; batch classifier loss: 0.110892; batch adversarial loss: 0.378050\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098120; batch adversarial loss: 0.530237\n",
      "epoch 50; iter: 0; batch classifier loss: 0.119814; batch adversarial loss: 0.408830\n",
      "epoch 51; iter: 0; batch classifier loss: 0.122970; batch adversarial loss: 0.401280\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141110; batch adversarial loss: 0.535094\n",
      "epoch 53; iter: 0; batch classifier loss: 0.096645; batch adversarial loss: 0.437389\n",
      "epoch 54; iter: 0; batch classifier loss: 0.096319; batch adversarial loss: 0.491900\n",
      "epoch 55; iter: 0; batch classifier loss: 0.087859; batch adversarial loss: 0.455060\n",
      "epoch 56; iter: 0; batch classifier loss: 0.176857; batch adversarial loss: 0.402818\n",
      "epoch 57; iter: 0; batch classifier loss: 0.099691; batch adversarial loss: 0.439339\n",
      "epoch 58; iter: 0; batch classifier loss: 0.098779; batch adversarial loss: 0.522202\n",
      "epoch 59; iter: 0; batch classifier loss: 0.110259; batch adversarial loss: 0.503802\n",
      "epoch 60; iter: 0; batch classifier loss: 0.117067; batch adversarial loss: 0.455328\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089855; batch adversarial loss: 0.498213\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089744; batch adversarial loss: 0.402848\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089020; batch adversarial loss: 0.499980\n",
      "epoch 64; iter: 0; batch classifier loss: 0.117812; batch adversarial loss: 0.381235\n",
      "epoch 65; iter: 0; batch classifier loss: 0.153741; batch adversarial loss: 0.405899\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092678; batch adversarial loss: 0.462185\n",
      "epoch 67; iter: 0; batch classifier loss: 0.061056; batch adversarial loss: 0.532917\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122494; batch adversarial loss: 0.422731\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087813; batch adversarial loss: 0.486411\n",
      "epoch 70; iter: 0; batch classifier loss: 0.094248; batch adversarial loss: 0.437595\n",
      "epoch 71; iter: 0; batch classifier loss: 0.116303; batch adversarial loss: 0.449556\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076620; batch adversarial loss: 0.452422\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116089; batch adversarial loss: 0.391999\n",
      "epoch 74; iter: 0; batch classifier loss: 0.085534; batch adversarial loss: 0.402517\n",
      "epoch 75; iter: 0; batch classifier loss: 0.101013; batch adversarial loss: 0.454617\n",
      "epoch 76; iter: 0; batch classifier loss: 0.094278; batch adversarial loss: 0.462105\n",
      "epoch 77; iter: 0; batch classifier loss: 0.096633; batch adversarial loss: 0.435956\n",
      "epoch 78; iter: 0; batch classifier loss: 0.105225; batch adversarial loss: 0.577410\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066414; batch adversarial loss: 0.432314\n",
      "epoch 80; iter: 0; batch classifier loss: 0.115000; batch adversarial loss: 0.371048\n",
      "epoch 81; iter: 0; batch classifier loss: 0.100101; batch adversarial loss: 0.503658\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084090; batch adversarial loss: 0.474465\n",
      "epoch 83; iter: 0; batch classifier loss: 0.100865; batch adversarial loss: 0.474742\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081998; batch adversarial loss: 0.492188\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075787; batch adversarial loss: 0.469428\n",
      "epoch 86; iter: 0; batch classifier loss: 0.102851; batch adversarial loss: 0.490104\n",
      "epoch 87; iter: 0; batch classifier loss: 0.075025; batch adversarial loss: 0.431582\n",
      "epoch 88; iter: 0; batch classifier loss: 0.070533; batch adversarial loss: 0.531188\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056722; batch adversarial loss: 0.489841\n",
      "epoch 90; iter: 0; batch classifier loss: 0.144005; batch adversarial loss: 0.465710\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087860; batch adversarial loss: 0.446602\n",
      "epoch 92; iter: 0; batch classifier loss: 0.077092; batch adversarial loss: 0.489304\n",
      "epoch 93; iter: 0; batch classifier loss: 0.098762; batch adversarial loss: 0.497490\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081695; batch adversarial loss: 0.429175\n",
      "epoch 95; iter: 0; batch classifier loss: 0.083793; batch adversarial loss: 0.419412\n",
      "epoch 96; iter: 0; batch classifier loss: 0.036000; batch adversarial loss: 0.468429\n",
      "epoch 97; iter: 0; batch classifier loss: 0.086363; batch adversarial loss: 0.404000\n",
      "epoch 98; iter: 0; batch classifier loss: 0.061012; batch adversarial loss: 0.450354\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051206; batch adversarial loss: 0.449624\n",
      "epoch 100; iter: 0; batch classifier loss: 0.088229; batch adversarial loss: 0.485149\n",
      "epoch 101; iter: 0; batch classifier loss: 0.089590; batch adversarial loss: 0.472670\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056428; batch adversarial loss: 0.542724\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050765; batch adversarial loss: 0.528908\n",
      "epoch 104; iter: 0; batch classifier loss: 0.082239; batch adversarial loss: 0.495029\n",
      "epoch 105; iter: 0; batch classifier loss: 0.050615; batch adversarial loss: 0.432892\n",
      "epoch 106; iter: 0; batch classifier loss: 0.017354; batch adversarial loss: 0.409649\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063332; batch adversarial loss: 0.439531\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045913; batch adversarial loss: 0.457282\n",
      "epoch 109; iter: 0; batch classifier loss: 0.047546; batch adversarial loss: 0.472387\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035465; batch adversarial loss: 0.420867\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056161; batch adversarial loss: 0.469257\n",
      "epoch 112; iter: 0; batch classifier loss: 0.096698; batch adversarial loss: 0.463571\n",
      "epoch 113; iter: 0; batch classifier loss: 0.051340; batch adversarial loss: 0.386225\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060767; batch adversarial loss: 0.502038\n",
      "epoch 115; iter: 0; batch classifier loss: 0.058527; batch adversarial loss: 0.471153\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025791; batch adversarial loss: 0.385416\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089212; batch adversarial loss: 0.456082\n",
      "epoch 118; iter: 0; batch classifier loss: 0.079382; batch adversarial loss: 0.371240\n",
      "epoch 119; iter: 0; batch classifier loss: 0.047438; batch adversarial loss: 0.396195\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044552; batch adversarial loss: 0.480623\n",
      "epoch 121; iter: 0; batch classifier loss: 0.029875; batch adversarial loss: 0.386511\n",
      "epoch 122; iter: 0; batch classifier loss: 0.046421; batch adversarial loss: 0.490552\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030719; batch adversarial loss: 0.448258\n",
      "epoch 124; iter: 0; batch classifier loss: 0.059559; batch adversarial loss: 0.468724\n",
      "epoch 125; iter: 0; batch classifier loss: 0.062755; batch adversarial loss: 0.504077\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028250; batch adversarial loss: 0.413258\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044590; batch adversarial loss: 0.466192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.404219\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025098; batch adversarial loss: 0.423059\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045536; batch adversarial loss: 0.467100\n",
      "epoch 131; iter: 0; batch classifier loss: 0.044493; batch adversarial loss: 0.491511\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073424; batch adversarial loss: 0.490946\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041382; batch adversarial loss: 0.434262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.451248\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037152; batch adversarial loss: 0.465051\n",
      "epoch 136; iter: 0; batch classifier loss: 0.061072; batch adversarial loss: 0.427662\n",
      "epoch 137; iter: 0; batch classifier loss: 0.057130; batch adversarial loss: 0.459706\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043277; batch adversarial loss: 0.360179\n",
      "epoch 139; iter: 0; batch classifier loss: 0.035354; batch adversarial loss: 0.409684\n",
      "epoch 140; iter: 0; batch classifier loss: 0.052711; batch adversarial loss: 0.511940\n",
      "epoch 141; iter: 0; batch classifier loss: 0.019019; batch adversarial loss: 0.525909\n",
      "epoch 142; iter: 0; batch classifier loss: 0.063762; batch adversarial loss: 0.435057\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050111; batch adversarial loss: 0.427447\n",
      "epoch 144; iter: 0; batch classifier loss: 0.082934; batch adversarial loss: 0.455759\n",
      "epoch 145; iter: 0; batch classifier loss: 0.058599; batch adversarial loss: 0.529801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024423; batch adversarial loss: 0.483445\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020516; batch adversarial loss: 0.369687\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072010; batch adversarial loss: 0.430442\n",
      "epoch 149; iter: 0; batch classifier loss: 0.024123; batch adversarial loss: 0.460321\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030166; batch adversarial loss: 0.410307\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028754; batch adversarial loss: 0.501617\n",
      "epoch 152; iter: 0; batch classifier loss: 0.038747; batch adversarial loss: 0.399987\n",
      "epoch 153; iter: 0; batch classifier loss: 0.062759; batch adversarial loss: 0.363529\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043071; batch adversarial loss: 0.498739\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031888; batch adversarial loss: 0.519721\n",
      "epoch 156; iter: 0; batch classifier loss: 0.018099; batch adversarial loss: 0.406715\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024097; batch adversarial loss: 0.525295\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025868; batch adversarial loss: 0.544707\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024535; batch adversarial loss: 0.446819\n",
      "epoch 160; iter: 0; batch classifier loss: 0.046314; batch adversarial loss: 0.385913\n",
      "epoch 161; iter: 0; batch classifier loss: 0.028526; batch adversarial loss: 0.485043\n",
      "epoch 162; iter: 0; batch classifier loss: 0.018515; batch adversarial loss: 0.417540\n",
      "epoch 163; iter: 0; batch classifier loss: 0.043474; batch adversarial loss: 0.478844\n",
      "epoch 164; iter: 0; batch classifier loss: 0.032977; batch adversarial loss: 0.507885\n",
      "epoch 165; iter: 0; batch classifier loss: 0.037677; batch adversarial loss: 0.356918\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023333; batch adversarial loss: 0.542422\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014200; batch adversarial loss: 0.378883\n",
      "epoch 168; iter: 0; batch classifier loss: 0.019731; batch adversarial loss: 0.450837\n",
      "epoch 169; iter: 0; batch classifier loss: 0.030764; batch adversarial loss: 0.535954\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021357; batch adversarial loss: 0.394263\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017301; batch adversarial loss: 0.440984\n",
      "epoch 172; iter: 0; batch classifier loss: 0.019169; batch adversarial loss: 0.390916\n",
      "epoch 173; iter: 0; batch classifier loss: 0.038131; batch adversarial loss: 0.406054\n",
      "epoch 174; iter: 0; batch classifier loss: 0.010539; batch adversarial loss: 0.530114\n",
      "epoch 175; iter: 0; batch classifier loss: 0.033866; batch adversarial loss: 0.428350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.052652; batch adversarial loss: 0.425813\n",
      "epoch 177; iter: 0; batch classifier loss: 0.017936; batch adversarial loss: 0.499293\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017696; batch adversarial loss: 0.550316\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026573; batch adversarial loss: 0.397017\n",
      "epoch 180; iter: 0; batch classifier loss: 0.039276; batch adversarial loss: 0.403415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.028919; batch adversarial loss: 0.408793\n",
      "epoch 182; iter: 0; batch classifier loss: 0.024504; batch adversarial loss: 0.410404\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022217; batch adversarial loss: 0.447696\n",
      "epoch 184; iter: 0; batch classifier loss: 0.031162; batch adversarial loss: 0.412420\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034676; batch adversarial loss: 0.588197\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015745; batch adversarial loss: 0.480834\n",
      "epoch 187; iter: 0; batch classifier loss: 0.022552; batch adversarial loss: 0.470644\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027258; batch adversarial loss: 0.415532\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028945; batch adversarial loss: 0.408365\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030141; batch adversarial loss: 0.441327\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018802; batch adversarial loss: 0.472496\n",
      "epoch 192; iter: 0; batch classifier loss: 0.008199; batch adversarial loss: 0.543952\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015711; batch adversarial loss: 0.462946\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013753; batch adversarial loss: 0.476321\n",
      "epoch 195; iter: 0; batch classifier loss: 0.025946; batch adversarial loss: 0.513526\n",
      "epoch 196; iter: 0; batch classifier loss: 0.022449; batch adversarial loss: 0.469791\n",
      "epoch 197; iter: 0; batch classifier loss: 0.026073; batch adversarial loss: 0.459529\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010731; batch adversarial loss: 0.510299\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015440; batch adversarial loss: 0.442196\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660783; batch adversarial loss: 0.600361\n",
      "epoch 1; iter: 0; batch classifier loss: 0.496193; batch adversarial loss: 0.613998\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400006; batch adversarial loss: 0.584898\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404469; batch adversarial loss: 0.652486\n",
      "epoch 4; iter: 0; batch classifier loss: 0.493340; batch adversarial loss: 0.605490\n",
      "epoch 5; iter: 0; batch classifier loss: 0.468810; batch adversarial loss: 0.597213\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595887; batch adversarial loss: 0.629369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607651; batch adversarial loss: 0.570086\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541672; batch adversarial loss: 0.563281\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579204; batch adversarial loss: 0.557841\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402026; batch adversarial loss: 0.550915\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343787; batch adversarial loss: 0.496727\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346516; batch adversarial loss: 0.477340\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276904; batch adversarial loss: 0.532957\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301183; batch adversarial loss: 0.482667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329473; batch adversarial loss: 0.452473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.213106; batch adversarial loss: 0.482451\n",
      "epoch 17; iter: 0; batch classifier loss: 0.201840; batch adversarial loss: 0.540965\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309776; batch adversarial loss: 0.436596\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212252; batch adversarial loss: 0.503993\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294128; batch adversarial loss: 0.455289\n",
      "epoch 21; iter: 0; batch classifier loss: 0.299512; batch adversarial loss: 0.460529\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277348; batch adversarial loss: 0.503487\n",
      "epoch 23; iter: 0; batch classifier loss: 0.249077; batch adversarial loss: 0.449590\n",
      "epoch 24; iter: 0; batch classifier loss: 0.218672; batch adversarial loss: 0.438926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.165300; batch adversarial loss: 0.459986\n",
      "epoch 26; iter: 0; batch classifier loss: 0.182043; batch adversarial loss: 0.384274\n",
      "epoch 27; iter: 0; batch classifier loss: 0.204531; batch adversarial loss: 0.399200\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167398; batch adversarial loss: 0.414817\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213326; batch adversarial loss: 0.445324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.147392; batch adversarial loss: 0.420711\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160364; batch adversarial loss: 0.454103\n",
      "epoch 32; iter: 0; batch classifier loss: 0.156352; batch adversarial loss: 0.443066\n",
      "epoch 33; iter: 0; batch classifier loss: 0.159578; batch adversarial loss: 0.461358\n",
      "epoch 34; iter: 0; batch classifier loss: 0.136459; batch adversarial loss: 0.460910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.120973; batch adversarial loss: 0.532086\n",
      "epoch 36; iter: 0; batch classifier loss: 0.172350; batch adversarial loss: 0.412450\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129295; batch adversarial loss: 0.503212\n",
      "epoch 38; iter: 0; batch classifier loss: 0.125345; batch adversarial loss: 0.492498\n",
      "epoch 39; iter: 0; batch classifier loss: 0.138735; batch adversarial loss: 0.493509\n",
      "epoch 40; iter: 0; batch classifier loss: 0.089101; batch adversarial loss: 0.458643\n",
      "epoch 41; iter: 0; batch classifier loss: 0.108323; batch adversarial loss: 0.438854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.127994; batch adversarial loss: 0.501468\n",
      "epoch 43; iter: 0; batch classifier loss: 0.105988; batch adversarial loss: 0.624266\n",
      "epoch 44; iter: 0; batch classifier loss: 0.085890; batch adversarial loss: 0.422221\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095982; batch adversarial loss: 0.439876\n",
      "epoch 46; iter: 0; batch classifier loss: 0.065393; batch adversarial loss: 0.452749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.121490; batch adversarial loss: 0.492687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.130176; batch adversarial loss: 0.450122\n",
      "epoch 49; iter: 0; batch classifier loss: 0.103442; batch adversarial loss: 0.440791\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082668; batch adversarial loss: 0.376069\n",
      "epoch 51; iter: 0; batch classifier loss: 0.067266; batch adversarial loss: 0.545269\n",
      "epoch 52; iter: 0; batch classifier loss: 0.059700; batch adversarial loss: 0.492422\n",
      "epoch 53; iter: 0; batch classifier loss: 0.155037; batch adversarial loss: 0.399898\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097510; batch adversarial loss: 0.429252\n",
      "epoch 55; iter: 0; batch classifier loss: 0.089254; batch adversarial loss: 0.518192\n",
      "epoch 56; iter: 0; batch classifier loss: 0.054874; batch adversarial loss: 0.425212\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113774; batch adversarial loss: 0.450629\n",
      "epoch 58; iter: 0; batch classifier loss: 0.097685; batch adversarial loss: 0.487904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.074626; batch adversarial loss: 0.473342\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065159; batch adversarial loss: 0.396781\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051635; batch adversarial loss: 0.432169\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082857; batch adversarial loss: 0.512513\n",
      "epoch 63; iter: 0; batch classifier loss: 0.077827; batch adversarial loss: 0.493845\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085089; batch adversarial loss: 0.500921\n",
      "epoch 65; iter: 0; batch classifier loss: 0.122929; batch adversarial loss: 0.401227\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082878; batch adversarial loss: 0.402456\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085634; batch adversarial loss: 0.493248\n",
      "epoch 68; iter: 0; batch classifier loss: 0.075863; batch adversarial loss: 0.509902\n",
      "epoch 69; iter: 0; batch classifier loss: 0.038206; batch adversarial loss: 0.346125\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088337; batch adversarial loss: 0.496405\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075024; batch adversarial loss: 0.409683\n",
      "epoch 72; iter: 0; batch classifier loss: 0.057926; batch adversarial loss: 0.401160\n",
      "epoch 73; iter: 0; batch classifier loss: 0.135750; batch adversarial loss: 0.429038\n",
      "epoch 74; iter: 0; batch classifier loss: 0.060794; batch adversarial loss: 0.354741\n",
      "epoch 75; iter: 0; batch classifier loss: 0.077331; batch adversarial loss: 0.421439\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088787; batch adversarial loss: 0.427819\n",
      "epoch 77; iter: 0; batch classifier loss: 0.086856; batch adversarial loss: 0.522070\n",
      "epoch 78; iter: 0; batch classifier loss: 0.058238; batch adversarial loss: 0.463940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.085688; batch adversarial loss: 0.495043\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090814; batch adversarial loss: 0.417600\n",
      "epoch 81; iter: 0; batch classifier loss: 0.054773; batch adversarial loss: 0.386064\n",
      "epoch 82; iter: 0; batch classifier loss: 0.078858; batch adversarial loss: 0.408969\n",
      "epoch 83; iter: 0; batch classifier loss: 0.111610; batch adversarial loss: 0.400780\n",
      "epoch 84; iter: 0; batch classifier loss: 0.042721; batch adversarial loss: 0.531643\n",
      "epoch 85; iter: 0; batch classifier loss: 0.029030; batch adversarial loss: 0.500322\n",
      "epoch 86; iter: 0; batch classifier loss: 0.088373; batch adversarial loss: 0.521315\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069828; batch adversarial loss: 0.442133\n",
      "epoch 88; iter: 0; batch classifier loss: 0.062005; batch adversarial loss: 0.416891\n",
      "epoch 89; iter: 0; batch classifier loss: 0.063098; batch adversarial loss: 0.469402\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066006; batch adversarial loss: 0.466434\n",
      "epoch 91; iter: 0; batch classifier loss: 0.028158; batch adversarial loss: 0.410541\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060286; batch adversarial loss: 0.506721\n",
      "epoch 93; iter: 0; batch classifier loss: 0.047652; batch adversarial loss: 0.483633\n",
      "epoch 94; iter: 0; batch classifier loss: 0.026509; batch adversarial loss: 0.422883\n",
      "epoch 95; iter: 0; batch classifier loss: 0.046424; batch adversarial loss: 0.482649\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093723; batch adversarial loss: 0.467468\n",
      "epoch 97; iter: 0; batch classifier loss: 0.026958; batch adversarial loss: 0.437205\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090048; batch adversarial loss: 0.451249\n",
      "epoch 99; iter: 0; batch classifier loss: 0.051775; batch adversarial loss: 0.434406\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049095; batch adversarial loss: 0.554154\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055308; batch adversarial loss: 0.412023\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049861; batch adversarial loss: 0.478945\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033301; batch adversarial loss: 0.528788\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037285; batch adversarial loss: 0.486091\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076178; batch adversarial loss: 0.415286\n",
      "epoch 106; iter: 0; batch classifier loss: 0.030492; batch adversarial loss: 0.442181\n",
      "epoch 107; iter: 0; batch classifier loss: 0.027565; batch adversarial loss: 0.348703\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024841; batch adversarial loss: 0.432469\n",
      "epoch 109; iter: 0; batch classifier loss: 0.077588; batch adversarial loss: 0.516856\n",
      "epoch 110; iter: 0; batch classifier loss: 0.033258; batch adversarial loss: 0.410103\n",
      "epoch 111; iter: 0; batch classifier loss: 0.065277; batch adversarial loss: 0.446889\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046234; batch adversarial loss: 0.488379\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033876; batch adversarial loss: 0.510317\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048388; batch adversarial loss: 0.494767\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034297; batch adversarial loss: 0.451374\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025085; batch adversarial loss: 0.465018\n",
      "epoch 117; iter: 0; batch classifier loss: 0.067729; batch adversarial loss: 0.434084\n",
      "epoch 118; iter: 0; batch classifier loss: 0.030036; batch adversarial loss: 0.471573\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029828; batch adversarial loss: 0.401141\n",
      "epoch 120; iter: 0; batch classifier loss: 0.062766; batch adversarial loss: 0.443475\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035732; batch adversarial loss: 0.444799\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025594; batch adversarial loss: 0.549754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.005662; batch adversarial loss: 0.489777\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036433; batch adversarial loss: 0.402899\n",
      "epoch 125; iter: 0; batch classifier loss: 0.024943; batch adversarial loss: 0.583571\n",
      "epoch 126; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.439061\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030721; batch adversarial loss: 0.411411\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018474; batch adversarial loss: 0.482997\n",
      "epoch 129; iter: 0; batch classifier loss: 0.032956; batch adversarial loss: 0.402843\n",
      "epoch 130; iter: 0; batch classifier loss: 0.048515; batch adversarial loss: 0.386619\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020671; batch adversarial loss: 0.492042\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036881; batch adversarial loss: 0.413196\n",
      "epoch 133; iter: 0; batch classifier loss: 0.056680; batch adversarial loss: 0.422359\n",
      "epoch 134; iter: 0; batch classifier loss: 0.042113; batch adversarial loss: 0.558246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.032969; batch adversarial loss: 0.525059\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014095; batch adversarial loss: 0.389781\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030046; batch adversarial loss: 0.414935\n",
      "epoch 138; iter: 0; batch classifier loss: 0.045471; batch adversarial loss: 0.395163\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024654; batch adversarial loss: 0.397453\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051178; batch adversarial loss: 0.519233\n",
      "epoch 141; iter: 0; batch classifier loss: 0.024879; batch adversarial loss: 0.406771\n",
      "epoch 142; iter: 0; batch classifier loss: 0.056975; batch adversarial loss: 0.528332\n",
      "epoch 143; iter: 0; batch classifier loss: 0.014847; batch adversarial loss: 0.560011\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014992; batch adversarial loss: 0.494320\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019276; batch adversarial loss: 0.456213\n",
      "epoch 146; iter: 0; batch classifier loss: 0.021855; batch adversarial loss: 0.422965\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011262; batch adversarial loss: 0.417979\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019086; batch adversarial loss: 0.499634\n",
      "epoch 149; iter: 0; batch classifier loss: 0.017359; batch adversarial loss: 0.422868\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016868; batch adversarial loss: 0.457958\n",
      "epoch 151; iter: 0; batch classifier loss: 0.020096; batch adversarial loss: 0.396548\n",
      "epoch 152; iter: 0; batch classifier loss: 0.010196; batch adversarial loss: 0.524237\n",
      "epoch 153; iter: 0; batch classifier loss: 0.038662; batch adversarial loss: 0.484918\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012109; batch adversarial loss: 0.444774\n",
      "epoch 155; iter: 0; batch classifier loss: 0.030738; batch adversarial loss: 0.439988\n",
      "epoch 156; iter: 0; batch classifier loss: 0.016803; batch adversarial loss: 0.406633\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017272; batch adversarial loss: 0.460749\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040915; batch adversarial loss: 0.394040\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022298; batch adversarial loss: 0.469592\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012909; batch adversarial loss: 0.547225\n",
      "epoch 161; iter: 0; batch classifier loss: 0.018976; batch adversarial loss: 0.447461\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020948; batch adversarial loss: 0.494155\n",
      "epoch 163; iter: 0; batch classifier loss: 0.042474; batch adversarial loss: 0.546173\n",
      "epoch 164; iter: 0; batch classifier loss: 0.006765; batch adversarial loss: 0.498231\n",
      "epoch 165; iter: 0; batch classifier loss: 0.044651; batch adversarial loss: 0.449443\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011269; batch adversarial loss: 0.460724\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020657; batch adversarial loss: 0.479080\n",
      "epoch 168; iter: 0; batch classifier loss: 0.024349; batch adversarial loss: 0.451842\n",
      "epoch 169; iter: 0; batch classifier loss: 0.023343; batch adversarial loss: 0.467914\n",
      "epoch 170; iter: 0; batch classifier loss: 0.030526; batch adversarial loss: 0.488522\n",
      "epoch 171; iter: 0; batch classifier loss: 0.011319; batch adversarial loss: 0.474754\n",
      "epoch 172; iter: 0; batch classifier loss: 0.009648; batch adversarial loss: 0.463813\n",
      "epoch 173; iter: 0; batch classifier loss: 0.037381; batch adversarial loss: 0.480385\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021783; batch adversarial loss: 0.541708\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026512; batch adversarial loss: 0.438839\n",
      "epoch 176; iter: 0; batch classifier loss: 0.014779; batch adversarial loss: 0.377208\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014701; batch adversarial loss: 0.441214\n",
      "epoch 178; iter: 0; batch classifier loss: 0.014283; batch adversarial loss: 0.393268\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005729; batch adversarial loss: 0.380648\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013913; batch adversarial loss: 0.415415\n",
      "epoch 181; iter: 0; batch classifier loss: 0.031488; batch adversarial loss: 0.495936\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026184; batch adversarial loss: 0.548222\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030039; batch adversarial loss: 0.504958\n",
      "epoch 184; iter: 0; batch classifier loss: 0.021144; batch adversarial loss: 0.515456\n",
      "epoch 185; iter: 0; batch classifier loss: 0.029092; batch adversarial loss: 0.474125\n",
      "epoch 186; iter: 0; batch classifier loss: 0.024406; batch adversarial loss: 0.531565\n",
      "epoch 187; iter: 0; batch classifier loss: 0.048898; batch adversarial loss: 0.477091\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012023; batch adversarial loss: 0.605192\n",
      "epoch 189; iter: 0; batch classifier loss: 0.037556; batch adversarial loss: 0.497541\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008862; batch adversarial loss: 0.431689\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012775; batch adversarial loss: 0.441399\n",
      "epoch 192; iter: 0; batch classifier loss: 0.010803; batch adversarial loss: 0.487591\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020152; batch adversarial loss: 0.503278\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011746; batch adversarial loss: 0.380587\n",
      "epoch 195; iter: 0; batch classifier loss: 0.026723; batch adversarial loss: 0.522954\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021577; batch adversarial loss: 0.396083\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024883; batch adversarial loss: 0.527905\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019680; batch adversarial loss: 0.410018\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017655; batch adversarial loss: 0.483132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722156; batch adversarial loss: 0.867640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474775; batch adversarial loss: 0.814814\n",
      "epoch 2; iter: 0; batch classifier loss: 0.476642; batch adversarial loss: 0.778658\n",
      "epoch 3; iter: 0; batch classifier loss: 0.743991; batch adversarial loss: 0.756054\n",
      "epoch 4; iter: 0; batch classifier loss: 0.807512; batch adversarial loss: 0.675383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.739658; batch adversarial loss: 0.631449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393627; batch adversarial loss: 0.588748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.399845; batch adversarial loss: 0.575770\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396224; batch adversarial loss: 0.554611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.375651; batch adversarial loss: 0.576457\n",
      "epoch 10; iter: 0; batch classifier loss: 0.336633; batch adversarial loss: 0.520541\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291029; batch adversarial loss: 0.502861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374569; batch adversarial loss: 0.558554\n",
      "epoch 13; iter: 0; batch classifier loss: 0.300286; batch adversarial loss: 0.458087\n",
      "epoch 14; iter: 0; batch classifier loss: 0.381228; batch adversarial loss: 0.499137\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359862; batch adversarial loss: 0.529918\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387824; batch adversarial loss: 0.518115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399784; batch adversarial loss: 0.524213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329079; batch adversarial loss: 0.467216\n",
      "epoch 19; iter: 0; batch classifier loss: 0.248663; batch adversarial loss: 0.455243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.259231; batch adversarial loss: 0.535102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215509; batch adversarial loss: 0.522621\n",
      "epoch 22; iter: 0; batch classifier loss: 0.251606; batch adversarial loss: 0.512165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285444; batch adversarial loss: 0.491906\n",
      "epoch 24; iter: 0; batch classifier loss: 0.287316; batch adversarial loss: 0.481702\n",
      "epoch 25; iter: 0; batch classifier loss: 0.318791; batch adversarial loss: 0.465569\n",
      "epoch 26; iter: 0; batch classifier loss: 0.290384; batch adversarial loss: 0.453988\n",
      "epoch 27; iter: 0; batch classifier loss: 0.230503; batch adversarial loss: 0.532813\n",
      "epoch 28; iter: 0; batch classifier loss: 0.211804; batch adversarial loss: 0.453574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241591; batch adversarial loss: 0.482328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239132; batch adversarial loss: 0.529749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.173123; batch adversarial loss: 0.439251\n",
      "epoch 32; iter: 0; batch classifier loss: 0.183754; batch adversarial loss: 0.517230\n",
      "epoch 33; iter: 0; batch classifier loss: 0.152440; batch adversarial loss: 0.432142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.193469; batch adversarial loss: 0.469777\n",
      "epoch 35; iter: 0; batch classifier loss: 0.158840; batch adversarial loss: 0.457966\n",
      "epoch 36; iter: 0; batch classifier loss: 0.178559; batch adversarial loss: 0.497875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226407; batch adversarial loss: 0.495869\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138654; batch adversarial loss: 0.466158\n",
      "epoch 39; iter: 0; batch classifier loss: 0.141462; batch adversarial loss: 0.412565\n",
      "epoch 40; iter: 0; batch classifier loss: 0.157273; batch adversarial loss: 0.519064\n",
      "epoch 41; iter: 0; batch classifier loss: 0.153931; batch adversarial loss: 0.513112\n",
      "epoch 42; iter: 0; batch classifier loss: 0.120361; batch adversarial loss: 0.485585\n",
      "epoch 43; iter: 0; batch classifier loss: 0.098635; batch adversarial loss: 0.521656\n",
      "epoch 44; iter: 0; batch classifier loss: 0.104727; batch adversarial loss: 0.530852\n",
      "epoch 45; iter: 0; batch classifier loss: 0.141503; batch adversarial loss: 0.436249\n",
      "epoch 46; iter: 0; batch classifier loss: 0.076669; batch adversarial loss: 0.462789\n",
      "epoch 47; iter: 0; batch classifier loss: 0.086845; batch adversarial loss: 0.453885\n",
      "epoch 48; iter: 0; batch classifier loss: 0.201106; batch adversarial loss: 0.396448\n",
      "epoch 49; iter: 0; batch classifier loss: 0.066883; batch adversarial loss: 0.444658\n",
      "epoch 50; iter: 0; batch classifier loss: 0.084024; batch adversarial loss: 0.455320\n",
      "epoch 51; iter: 0; batch classifier loss: 0.113214; batch adversarial loss: 0.422364\n",
      "epoch 52; iter: 0; batch classifier loss: 0.080296; batch adversarial loss: 0.466439\n",
      "epoch 53; iter: 0; batch classifier loss: 0.157961; batch adversarial loss: 0.470599\n",
      "epoch 54; iter: 0; batch classifier loss: 0.135322; batch adversarial loss: 0.435170\n",
      "epoch 55; iter: 0; batch classifier loss: 0.109996; batch adversarial loss: 0.411192\n",
      "epoch 56; iter: 0; batch classifier loss: 0.136116; batch adversarial loss: 0.419130\n",
      "epoch 57; iter: 0; batch classifier loss: 0.057994; batch adversarial loss: 0.486609\n",
      "epoch 58; iter: 0; batch classifier loss: 0.105864; batch adversarial loss: 0.491505\n",
      "epoch 59; iter: 0; batch classifier loss: 0.057070; batch adversarial loss: 0.436312\n",
      "epoch 60; iter: 0; batch classifier loss: 0.089302; batch adversarial loss: 0.407728\n",
      "epoch 61; iter: 0; batch classifier loss: 0.066731; batch adversarial loss: 0.534378\n",
      "epoch 62; iter: 0; batch classifier loss: 0.107443; batch adversarial loss: 0.527640\n",
      "epoch 63; iter: 0; batch classifier loss: 0.039865; batch adversarial loss: 0.440522\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082268; batch adversarial loss: 0.481701\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125777; batch adversarial loss: 0.489351\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058938; batch adversarial loss: 0.504233\n",
      "epoch 67; iter: 0; batch classifier loss: 0.060272; batch adversarial loss: 0.514996\n",
      "epoch 68; iter: 0; batch classifier loss: 0.116097; batch adversarial loss: 0.424373\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100665; batch adversarial loss: 0.485367\n",
      "epoch 70; iter: 0; batch classifier loss: 0.062228; batch adversarial loss: 0.439548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.079601; batch adversarial loss: 0.540729\n",
      "epoch 72; iter: 0; batch classifier loss: 0.056323; batch adversarial loss: 0.425823\n",
      "epoch 73; iter: 0; batch classifier loss: 0.065985; batch adversarial loss: 0.476730\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068377; batch adversarial loss: 0.466977\n",
      "epoch 75; iter: 0; batch classifier loss: 0.093508; batch adversarial loss: 0.421430\n",
      "epoch 76; iter: 0; batch classifier loss: 0.049712; batch adversarial loss: 0.463761\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071975; batch adversarial loss: 0.420799\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099212; batch adversarial loss: 0.492586\n",
      "epoch 79; iter: 0; batch classifier loss: 0.057895; batch adversarial loss: 0.415946\n",
      "epoch 80; iter: 0; batch classifier loss: 0.040217; batch adversarial loss: 0.468133\n",
      "epoch 81; iter: 0; batch classifier loss: 0.066342; batch adversarial loss: 0.484375\n",
      "epoch 82; iter: 0; batch classifier loss: 0.049552; batch adversarial loss: 0.431344\n",
      "epoch 83; iter: 0; batch classifier loss: 0.063839; batch adversarial loss: 0.488420\n",
      "epoch 84; iter: 0; batch classifier loss: 0.055211; batch adversarial loss: 0.479728\n",
      "epoch 85; iter: 0; batch classifier loss: 0.073330; batch adversarial loss: 0.423507\n",
      "epoch 86; iter: 0; batch classifier loss: 0.052144; batch adversarial loss: 0.416757\n",
      "epoch 87; iter: 0; batch classifier loss: 0.066372; batch adversarial loss: 0.475435\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063078; batch adversarial loss: 0.524049\n",
      "epoch 89; iter: 0; batch classifier loss: 0.038436; batch adversarial loss: 0.484318\n",
      "epoch 90; iter: 0; batch classifier loss: 0.075038; batch adversarial loss: 0.456470\n",
      "epoch 91; iter: 0; batch classifier loss: 0.040337; batch adversarial loss: 0.463121\n",
      "epoch 92; iter: 0; batch classifier loss: 0.068830; batch adversarial loss: 0.437943\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035568; batch adversarial loss: 0.420394\n",
      "epoch 94; iter: 0; batch classifier loss: 0.049231; batch adversarial loss: 0.442401\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065811; batch adversarial loss: 0.410322\n",
      "epoch 96; iter: 0; batch classifier loss: 0.065413; batch adversarial loss: 0.445499\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078987; batch adversarial loss: 0.449941\n",
      "epoch 98; iter: 0; batch classifier loss: 0.034744; batch adversarial loss: 0.434773\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041510; batch adversarial loss: 0.419245\n",
      "epoch 100; iter: 0; batch classifier loss: 0.024603; batch adversarial loss: 0.414876\n",
      "epoch 101; iter: 0; batch classifier loss: 0.058416; batch adversarial loss: 0.442627\n",
      "epoch 102; iter: 0; batch classifier loss: 0.047918; batch adversarial loss: 0.440266\n",
      "epoch 103; iter: 0; batch classifier loss: 0.052657; batch adversarial loss: 0.405402\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031431; batch adversarial loss: 0.580910\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045797; batch adversarial loss: 0.383302\n",
      "epoch 106; iter: 0; batch classifier loss: 0.020967; batch adversarial loss: 0.480405\n",
      "epoch 107; iter: 0; batch classifier loss: 0.031486; batch adversarial loss: 0.457637\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052324; batch adversarial loss: 0.399522\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045039; batch adversarial loss: 0.505551\n",
      "epoch 110; iter: 0; batch classifier loss: 0.061895; batch adversarial loss: 0.447604\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037606; batch adversarial loss: 0.533401\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045551; batch adversarial loss: 0.410883\n",
      "epoch 113; iter: 0; batch classifier loss: 0.042807; batch adversarial loss: 0.521296\n",
      "epoch 114; iter: 0; batch classifier loss: 0.032413; batch adversarial loss: 0.531911\n",
      "epoch 115; iter: 0; batch classifier loss: 0.035808; batch adversarial loss: 0.440204\n",
      "epoch 116; iter: 0; batch classifier loss: 0.048605; batch adversarial loss: 0.420358\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031743; batch adversarial loss: 0.378418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.492333\n",
      "epoch 119; iter: 0; batch classifier loss: 0.037043; batch adversarial loss: 0.415709\n",
      "epoch 120; iter: 0; batch classifier loss: 0.012237; batch adversarial loss: 0.431574\n",
      "epoch 121; iter: 0; batch classifier loss: 0.056889; batch adversarial loss: 0.502313\n",
      "epoch 122; iter: 0; batch classifier loss: 0.033365; batch adversarial loss: 0.530472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.031400; batch adversarial loss: 0.410376\n",
      "epoch 124; iter: 0; batch classifier loss: 0.058912; batch adversarial loss: 0.555820\n",
      "epoch 125; iter: 0; batch classifier loss: 0.044867; batch adversarial loss: 0.427002\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022617; batch adversarial loss: 0.473363\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024385; batch adversarial loss: 0.493826\n",
      "epoch 128; iter: 0; batch classifier loss: 0.018417; batch adversarial loss: 0.550657\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027068; batch adversarial loss: 0.478368\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030265; batch adversarial loss: 0.442595\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025259; batch adversarial loss: 0.397533\n",
      "epoch 132; iter: 0; batch classifier loss: 0.044440; batch adversarial loss: 0.449117\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021083; batch adversarial loss: 0.498136\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027744; batch adversarial loss: 0.368727\n",
      "epoch 135; iter: 0; batch classifier loss: 0.069818; batch adversarial loss: 0.476200\n",
      "epoch 136; iter: 0; batch classifier loss: 0.009176; batch adversarial loss: 0.465361\n",
      "epoch 137; iter: 0; batch classifier loss: 0.046039; batch adversarial loss: 0.407203\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023625; batch adversarial loss: 0.509779\n",
      "epoch 139; iter: 0; batch classifier loss: 0.010558; batch adversarial loss: 0.474583\n",
      "epoch 140; iter: 0; batch classifier loss: 0.013347; batch adversarial loss: 0.491584\n",
      "epoch 141; iter: 0; batch classifier loss: 0.041400; batch adversarial loss: 0.522957\n",
      "epoch 142; iter: 0; batch classifier loss: 0.030613; batch adversarial loss: 0.540175\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033703; batch adversarial loss: 0.423163\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029518; batch adversarial loss: 0.489281\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035739; batch adversarial loss: 0.418623\n",
      "epoch 146; iter: 0; batch classifier loss: 0.022708; batch adversarial loss: 0.495254\n",
      "epoch 147; iter: 0; batch classifier loss: 0.015894; batch adversarial loss: 0.537571\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016561; batch adversarial loss: 0.429872\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012765; batch adversarial loss: 0.476681\n",
      "epoch 150; iter: 0; batch classifier loss: 0.014525; batch adversarial loss: 0.479964\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022131; batch adversarial loss: 0.493890\n",
      "epoch 152; iter: 0; batch classifier loss: 0.008324; batch adversarial loss: 0.437886\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011420; batch adversarial loss: 0.422364\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017378; batch adversarial loss: 0.438773\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037052; batch adversarial loss: 0.352552\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036386; batch adversarial loss: 0.422852\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019227; batch adversarial loss: 0.469921\n",
      "epoch 158; iter: 0; batch classifier loss: 0.009940; batch adversarial loss: 0.433158\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017634; batch adversarial loss: 0.382759\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019842; batch adversarial loss: 0.358546\n",
      "epoch 161; iter: 0; batch classifier loss: 0.006239; batch adversarial loss: 0.557170\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020091; batch adversarial loss: 0.400916\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024136; batch adversarial loss: 0.416688\n",
      "epoch 164; iter: 0; batch classifier loss: 0.055005; batch adversarial loss: 0.494625\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011158; batch adversarial loss: 0.562227\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028056; batch adversarial loss: 0.433624\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011873; batch adversarial loss: 0.527821\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015143; batch adversarial loss: 0.509870\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026546; batch adversarial loss: 0.447045\n",
      "epoch 170; iter: 0; batch classifier loss: 0.017976; batch adversarial loss: 0.471471\n",
      "epoch 171; iter: 0; batch classifier loss: 0.008552; batch adversarial loss: 0.442325\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017809; batch adversarial loss: 0.441039\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040112; batch adversarial loss: 0.412115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012227; batch adversarial loss: 0.501357\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013624; batch adversarial loss: 0.517921\n",
      "epoch 176; iter: 0; batch classifier loss: 0.024692; batch adversarial loss: 0.385371\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008642; batch adversarial loss: 0.456081\n",
      "epoch 178; iter: 0; batch classifier loss: 0.017384; batch adversarial loss: 0.365544\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019875; batch adversarial loss: 0.356453\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010127; batch adversarial loss: 0.381575\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025067; batch adversarial loss: 0.370903\n",
      "epoch 182; iter: 0; batch classifier loss: 0.016762; batch adversarial loss: 0.475648\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019065; batch adversarial loss: 0.453190\n",
      "epoch 184; iter: 0; batch classifier loss: 0.017632; batch adversarial loss: 0.560924\n",
      "epoch 185; iter: 0; batch classifier loss: 0.017334; batch adversarial loss: 0.460648\n",
      "epoch 186; iter: 0; batch classifier loss: 0.016679; batch adversarial loss: 0.466488\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016162; batch adversarial loss: 0.565794\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005972; batch adversarial loss: 0.481880\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006055; batch adversarial loss: 0.405577\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024979; batch adversarial loss: 0.415972\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014915; batch adversarial loss: 0.503218\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016571; batch adversarial loss: 0.531983\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015392; batch adversarial loss: 0.490379\n",
      "epoch 194; iter: 0; batch classifier loss: 0.015004; batch adversarial loss: 0.473974\n",
      "epoch 195; iter: 0; batch classifier loss: 0.010129; batch adversarial loss: 0.432226\n",
      "epoch 196; iter: 0; batch classifier loss: 0.001082; batch adversarial loss: 0.398924\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015806; batch adversarial loss: 0.492227\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011724; batch adversarial loss: 0.497727\n",
      "epoch 199; iter: 0; batch classifier loss: 0.008857; batch adversarial loss: 0.525565\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711113; batch adversarial loss: 0.689651\n",
      "epoch 1; iter: 0; batch classifier loss: 0.421785; batch adversarial loss: 0.654926\n",
      "epoch 2; iter: 0; batch classifier loss: 0.400702; batch adversarial loss: 0.615563\n",
      "epoch 3; iter: 0; batch classifier loss: 0.423085; batch adversarial loss: 0.579374\n",
      "epoch 4; iter: 0; batch classifier loss: 0.351634; batch adversarial loss: 0.592431\n",
      "epoch 5; iter: 0; batch classifier loss: 0.306305; batch adversarial loss: 0.539781\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288549; batch adversarial loss: 0.522473\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313987; batch adversarial loss: 0.530823\n",
      "epoch 8; iter: 0; batch classifier loss: 0.191117; batch adversarial loss: 0.523878\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260092; batch adversarial loss: 0.466883\n",
      "epoch 10; iter: 0; batch classifier loss: 0.159811; batch adversarial loss: 0.536691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209614; batch adversarial loss: 0.496338\n",
      "epoch 12; iter: 0; batch classifier loss: 0.196687; batch adversarial loss: 0.452274\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266730; batch adversarial loss: 0.533767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 0; batch classifier loss: 0.157957; batch adversarial loss: 0.504935\n",
      "epoch 15; iter: 0; batch classifier loss: 0.150646; batch adversarial loss: 0.454959\n",
      "epoch 16; iter: 0; batch classifier loss: 0.162449; batch adversarial loss: 0.462015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.186713; batch adversarial loss: 0.535076\n",
      "epoch 18; iter: 0; batch classifier loss: 0.171175; batch adversarial loss: 0.454330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.244779; batch adversarial loss: 0.518265\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252940; batch adversarial loss: 0.525253\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266223; batch adversarial loss: 0.495254\n",
      "epoch 22; iter: 0; batch classifier loss: 0.247334; batch adversarial loss: 0.425507\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340932; batch adversarial loss: 0.485044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.368286; batch adversarial loss: 0.441218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349561; batch adversarial loss: 0.511119\n",
      "epoch 26; iter: 0; batch classifier loss: 0.282180; batch adversarial loss: 0.461171\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162322; batch adversarial loss: 0.470185\n",
      "epoch 28; iter: 0; batch classifier loss: 0.160956; batch adversarial loss: 0.390737\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143159; batch adversarial loss: 0.467692\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131258; batch adversarial loss: 0.456320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.089191; batch adversarial loss: 0.445301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.154137; batch adversarial loss: 0.389513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.139208; batch adversarial loss: 0.519713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.100183; batch adversarial loss: 0.454227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.088335; batch adversarial loss: 0.419089\n",
      "epoch 36; iter: 0; batch classifier loss: 0.113591; batch adversarial loss: 0.473308\n",
      "epoch 37; iter: 0; batch classifier loss: 0.097177; batch adversarial loss: 0.508927\n",
      "epoch 38; iter: 0; batch classifier loss: 0.106357; batch adversarial loss: 0.476034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.123908; batch adversarial loss: 0.426727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.113054; batch adversarial loss: 0.406967\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115083; batch adversarial loss: 0.443987\n",
      "epoch 42; iter: 0; batch classifier loss: 0.106459; batch adversarial loss: 0.471645\n",
      "epoch 43; iter: 0; batch classifier loss: 0.070433; batch adversarial loss: 0.494553\n",
      "epoch 44; iter: 0; batch classifier loss: 0.076598; batch adversarial loss: 0.480840\n",
      "epoch 45; iter: 0; batch classifier loss: 0.112204; batch adversarial loss: 0.435311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082890; batch adversarial loss: 0.536685\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164977; batch adversarial loss: 0.478014\n",
      "epoch 48; iter: 0; batch classifier loss: 0.125088; batch adversarial loss: 0.441946\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162656; batch adversarial loss: 0.408098\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083793; batch adversarial loss: 0.431907\n",
      "epoch 51; iter: 0; batch classifier loss: 0.115823; batch adversarial loss: 0.439409\n",
      "epoch 52; iter: 0; batch classifier loss: 0.102505; batch adversarial loss: 0.404257\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146062; batch adversarial loss: 0.502809\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113306; batch adversarial loss: 0.364211\n",
      "epoch 55; iter: 0; batch classifier loss: 0.085552; batch adversarial loss: 0.348106\n",
      "epoch 56; iter: 0; batch classifier loss: 0.049347; batch adversarial loss: 0.450854\n",
      "epoch 57; iter: 0; batch classifier loss: 0.079920; batch adversarial loss: 0.555129\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087851; batch adversarial loss: 0.513278\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158009; batch adversarial loss: 0.452732\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095281; batch adversarial loss: 0.524350\n",
      "epoch 61; iter: 0; batch classifier loss: 0.070264; batch adversarial loss: 0.412134\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080078; batch adversarial loss: 0.461795\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114226; batch adversarial loss: 0.412586\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064459; batch adversarial loss: 0.489394\n",
      "epoch 65; iter: 0; batch classifier loss: 0.116267; batch adversarial loss: 0.378574\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056068; batch adversarial loss: 0.438286\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082308; batch adversarial loss: 0.453144\n",
      "epoch 68; iter: 0; batch classifier loss: 0.092631; batch adversarial loss: 0.404187\n",
      "epoch 69; iter: 0; batch classifier loss: 0.062435; batch adversarial loss: 0.495267\n",
      "epoch 70; iter: 0; batch classifier loss: 0.112176; batch adversarial loss: 0.405615\n",
      "epoch 71; iter: 0; batch classifier loss: 0.060563; batch adversarial loss: 0.369120\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092810; batch adversarial loss: 0.481256\n",
      "epoch 73; iter: 0; batch classifier loss: 0.119658; batch adversarial loss: 0.430163\n",
      "epoch 74; iter: 0; batch classifier loss: 0.082403; batch adversarial loss: 0.431873\n",
      "epoch 75; iter: 0; batch classifier loss: 0.076057; batch adversarial loss: 0.449702\n",
      "epoch 76; iter: 0; batch classifier loss: 0.061440; batch adversarial loss: 0.422615\n",
      "epoch 77; iter: 0; batch classifier loss: 0.085686; batch adversarial loss: 0.506425\n",
      "epoch 78; iter: 0; batch classifier loss: 0.092096; batch adversarial loss: 0.459930\n",
      "epoch 79; iter: 0; batch classifier loss: 0.053715; batch adversarial loss: 0.487160\n",
      "epoch 80; iter: 0; batch classifier loss: 0.087177; batch adversarial loss: 0.412019\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052059; batch adversarial loss: 0.399183\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063679; batch adversarial loss: 0.498650\n",
      "epoch 83; iter: 0; batch classifier loss: 0.054442; batch adversarial loss: 0.545528\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059734; batch adversarial loss: 0.436065\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075470; batch adversarial loss: 0.474242\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112304; batch adversarial loss: 0.487190\n",
      "epoch 87; iter: 0; batch classifier loss: 0.098982; batch adversarial loss: 0.503671\n",
      "epoch 88; iter: 0; batch classifier loss: 0.078748; batch adversarial loss: 0.464257\n",
      "epoch 89; iter: 0; batch classifier loss: 0.075423; batch adversarial loss: 0.443685\n",
      "epoch 90; iter: 0; batch classifier loss: 0.047690; batch adversarial loss: 0.389409\n",
      "epoch 91; iter: 0; batch classifier loss: 0.099886; batch adversarial loss: 0.425080\n",
      "epoch 92; iter: 0; batch classifier loss: 0.063376; batch adversarial loss: 0.370707\n",
      "epoch 93; iter: 0; batch classifier loss: 0.063164; batch adversarial loss: 0.483389\n",
      "epoch 94; iter: 0; batch classifier loss: 0.043530; batch adversarial loss: 0.319652\n",
      "epoch 95; iter: 0; batch classifier loss: 0.062557; batch adversarial loss: 0.382594\n",
      "epoch 96; iter: 0; batch classifier loss: 0.069705; batch adversarial loss: 0.505663\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058025; batch adversarial loss: 0.329027\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067017; batch adversarial loss: 0.388036\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054509; batch adversarial loss: 0.497165\n",
      "epoch 100; iter: 0; batch classifier loss: 0.058694; batch adversarial loss: 0.444572\n",
      "epoch 101; iter: 0; batch classifier loss: 0.067467; batch adversarial loss: 0.400711\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056476; batch adversarial loss: 0.486819\n",
      "epoch 103; iter: 0; batch classifier loss: 0.024777; batch adversarial loss: 0.396564\n",
      "epoch 104; iter: 0; batch classifier loss: 0.115774; batch adversarial loss: 0.469443\n",
      "epoch 105; iter: 0; batch classifier loss: 0.016405; batch adversarial loss: 0.390089\n",
      "epoch 106; iter: 0; batch classifier loss: 0.071753; batch adversarial loss: 0.466118\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039350; batch adversarial loss: 0.483985\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036773; batch adversarial loss: 0.391992\n",
      "epoch 109; iter: 0; batch classifier loss: 0.052084; batch adversarial loss: 0.342150\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030778; batch adversarial loss: 0.346351\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040246; batch adversarial loss: 0.410066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 112; iter: 0; batch classifier loss: 0.049548; batch adversarial loss: 0.474471\n",
      "epoch 113; iter: 0; batch classifier loss: 0.058412; batch adversarial loss: 0.562460\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039915; batch adversarial loss: 0.387027\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045765; batch adversarial loss: 0.430289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.022452; batch adversarial loss: 0.426947\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025795; batch adversarial loss: 0.435296\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044720; batch adversarial loss: 0.557821\n",
      "epoch 119; iter: 0; batch classifier loss: 0.021965; batch adversarial loss: 0.429436\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027852; batch adversarial loss: 0.562960\n",
      "epoch 121; iter: 0; batch classifier loss: 0.039306; batch adversarial loss: 0.469326\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062720; batch adversarial loss: 0.338298\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041764; batch adversarial loss: 0.394105\n",
      "epoch 124; iter: 0; batch classifier loss: 0.029120; batch adversarial loss: 0.450902\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068553; batch adversarial loss: 0.400237\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027208; batch adversarial loss: 0.436520\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036024; batch adversarial loss: 0.499658\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074490; batch adversarial loss: 0.491231\n",
      "epoch 129; iter: 0; batch classifier loss: 0.024427; batch adversarial loss: 0.405942\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051559; batch adversarial loss: 0.312834\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023200; batch adversarial loss: 0.475131\n",
      "epoch 132; iter: 0; batch classifier loss: 0.017878; batch adversarial loss: 0.493736\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027049; batch adversarial loss: 0.543246\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020011; batch adversarial loss: 0.405958\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012516; batch adversarial loss: 0.435012\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039599; batch adversarial loss: 0.486584\n",
      "epoch 137; iter: 0; batch classifier loss: 0.056675; batch adversarial loss: 0.445382\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035244; batch adversarial loss: 0.475149\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034357; batch adversarial loss: 0.397405\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023502; batch adversarial loss: 0.445611\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032057; batch adversarial loss: 0.506088\n",
      "epoch 142; iter: 0; batch classifier loss: 0.011491; batch adversarial loss: 0.394497\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016513; batch adversarial loss: 0.481307\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026285; batch adversarial loss: 0.441696\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025012; batch adversarial loss: 0.470073\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019386; batch adversarial loss: 0.406843\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024924; batch adversarial loss: 0.416436\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019998; batch adversarial loss: 0.404914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020862; batch adversarial loss: 0.418096\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029368; batch adversarial loss: 0.506048\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021153; batch adversarial loss: 0.388403\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034915; batch adversarial loss: 0.526714\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019510; batch adversarial loss: 0.424756\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017817; batch adversarial loss: 0.439093\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022239; batch adversarial loss: 0.439880\n",
      "epoch 156; iter: 0; batch classifier loss: 0.027201; batch adversarial loss: 0.384083\n",
      "epoch 157; iter: 0; batch classifier loss: 0.029046; batch adversarial loss: 0.467262\n",
      "epoch 158; iter: 0; batch classifier loss: 0.023064; batch adversarial loss: 0.401710\n",
      "epoch 159; iter: 0; batch classifier loss: 0.033838; batch adversarial loss: 0.521571\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047515; batch adversarial loss: 0.432280\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029224; batch adversarial loss: 0.510579\n",
      "epoch 162; iter: 0; batch classifier loss: 0.039118; batch adversarial loss: 0.494690\n",
      "epoch 163; iter: 0; batch classifier loss: 0.030314; batch adversarial loss: 0.485617\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017270; batch adversarial loss: 0.443374\n",
      "epoch 165; iter: 0; batch classifier loss: 0.034900; batch adversarial loss: 0.461856\n",
      "epoch 166; iter: 0; batch classifier loss: 0.011925; batch adversarial loss: 0.493035\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021224; batch adversarial loss: 0.547749\n",
      "epoch 168; iter: 0; batch classifier loss: 0.033388; batch adversarial loss: 0.426623\n",
      "epoch 169; iter: 0; batch classifier loss: 0.038168; batch adversarial loss: 0.369707\n",
      "epoch 170; iter: 0; batch classifier loss: 0.008867; batch adversarial loss: 0.433031\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050089; batch adversarial loss: 0.436407\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033154; batch adversarial loss: 0.416248\n",
      "epoch 173; iter: 0; batch classifier loss: 0.054812; batch adversarial loss: 0.389115\n",
      "epoch 174; iter: 0; batch classifier loss: 0.021775; batch adversarial loss: 0.442670\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037098; batch adversarial loss: 0.486488\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010095; batch adversarial loss: 0.495260\n",
      "epoch 177; iter: 0; batch classifier loss: 0.027081; batch adversarial loss: 0.450486\n",
      "epoch 178; iter: 0; batch classifier loss: 0.024053; batch adversarial loss: 0.472240\n",
      "epoch 179; iter: 0; batch classifier loss: 0.006666; batch adversarial loss: 0.490104\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016355; batch adversarial loss: 0.506076\n",
      "epoch 181; iter: 0; batch classifier loss: 0.010851; batch adversarial loss: 0.531485\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011472; batch adversarial loss: 0.519884\n",
      "epoch 183; iter: 0; batch classifier loss: 0.041493; batch adversarial loss: 0.471189\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029403; batch adversarial loss: 0.441698\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027140; batch adversarial loss: 0.406728\n",
      "epoch 186; iter: 0; batch classifier loss: 0.015572; batch adversarial loss: 0.449169\n",
      "epoch 187; iter: 0; batch classifier loss: 0.030798; batch adversarial loss: 0.478832\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043641; batch adversarial loss: 0.519424\n",
      "epoch 189; iter: 0; batch classifier loss: 0.025432; batch adversarial loss: 0.448187\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008227; batch adversarial loss: 0.439048\n",
      "epoch 191; iter: 0; batch classifier loss: 0.024801; batch adversarial loss: 0.415056\n",
      "epoch 192; iter: 0; batch classifier loss: 0.016551; batch adversarial loss: 0.417000\n",
      "epoch 193; iter: 0; batch classifier loss: 0.017154; batch adversarial loss: 0.378009\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014228; batch adversarial loss: 0.492108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012391; batch adversarial loss: 0.439860\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021685; batch adversarial loss: 0.346225\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013383; batch adversarial loss: 0.463455\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010806; batch adversarial loss: 0.496651\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009141; batch adversarial loss: 0.474012\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688484; batch adversarial loss: 0.946279\n",
      "epoch 1; iter: 0; batch classifier loss: 0.508747; batch adversarial loss: 0.891436\n",
      "epoch 2; iter: 0; batch classifier loss: 0.533184; batch adversarial loss: 0.894314\n",
      "epoch 3; iter: 0; batch classifier loss: 0.662894; batch adversarial loss: 0.837707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572247; batch adversarial loss: 0.773672\n",
      "epoch 5; iter: 0; batch classifier loss: 0.452849; batch adversarial loss: 0.699067\n",
      "epoch 6; iter: 0; batch classifier loss: 0.378725; batch adversarial loss: 0.665337\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344215; batch adversarial loss: 0.629359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 0; batch classifier loss: 0.332065; batch adversarial loss: 0.591808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.266766; batch adversarial loss: 0.567613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302738; batch adversarial loss: 0.550110\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228299; batch adversarial loss: 0.530004\n",
      "epoch 12; iter: 0; batch classifier loss: 0.220942; batch adversarial loss: 0.524856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.281599; batch adversarial loss: 0.519159\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302794; batch adversarial loss: 0.541824\n",
      "epoch 15; iter: 0; batch classifier loss: 0.201085; batch adversarial loss: 0.514572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.220651; batch adversarial loss: 0.496155\n",
      "epoch 17; iter: 0; batch classifier loss: 0.206100; batch adversarial loss: 0.450860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.203073; batch adversarial loss: 0.505038\n",
      "epoch 19; iter: 0; batch classifier loss: 0.222386; batch adversarial loss: 0.491960\n",
      "epoch 20; iter: 0; batch classifier loss: 0.143015; batch adversarial loss: 0.459650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.219176; batch adversarial loss: 0.431494\n",
      "epoch 22; iter: 0; batch classifier loss: 0.201265; batch adversarial loss: 0.415329\n",
      "epoch 23; iter: 0; batch classifier loss: 0.196269; batch adversarial loss: 0.562085\n",
      "epoch 24; iter: 0; batch classifier loss: 0.139718; batch adversarial loss: 0.394344\n",
      "epoch 25; iter: 0; batch classifier loss: 0.124406; batch adversarial loss: 0.480372\n",
      "epoch 26; iter: 0; batch classifier loss: 0.134669; batch adversarial loss: 0.437068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.101298; batch adversarial loss: 0.383228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.120748; batch adversarial loss: 0.432957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.174758; batch adversarial loss: 0.329689\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124002; batch adversarial loss: 0.434870\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124910; batch adversarial loss: 0.461262\n",
      "epoch 32; iter: 0; batch classifier loss: 0.079037; batch adversarial loss: 0.347785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.090777; batch adversarial loss: 0.409343\n",
      "epoch 34; iter: 0; batch classifier loss: 0.081797; batch adversarial loss: 0.453289\n",
      "epoch 35; iter: 0; batch classifier loss: 0.084639; batch adversarial loss: 0.428789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.093789; batch adversarial loss: 0.501956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.074675; batch adversarial loss: 0.434858\n",
      "epoch 38; iter: 0; batch classifier loss: 0.104392; batch adversarial loss: 0.487712\n",
      "epoch 39; iter: 0; batch classifier loss: 0.081418; batch adversarial loss: 0.343108\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116080; batch adversarial loss: 0.462224\n",
      "epoch 41; iter: 0; batch classifier loss: 0.138318; batch adversarial loss: 0.413598\n",
      "epoch 42; iter: 0; batch classifier loss: 0.068831; batch adversarial loss: 0.446299\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135200; batch adversarial loss: 0.438508\n",
      "epoch 44; iter: 0; batch classifier loss: 0.108662; batch adversarial loss: 0.429378\n",
      "epoch 45; iter: 0; batch classifier loss: 0.110117; batch adversarial loss: 0.360780\n",
      "epoch 46; iter: 0; batch classifier loss: 0.099380; batch adversarial loss: 0.389352\n",
      "epoch 47; iter: 0; batch classifier loss: 0.090657; batch adversarial loss: 0.469628\n",
      "epoch 48; iter: 0; batch classifier loss: 0.137483; batch adversarial loss: 0.466152\n",
      "epoch 49; iter: 0; batch classifier loss: 0.053175; batch adversarial loss: 0.377021\n",
      "epoch 50; iter: 0; batch classifier loss: 0.129002; batch adversarial loss: 0.420812\n",
      "epoch 51; iter: 0; batch classifier loss: 0.120554; batch adversarial loss: 0.471454\n",
      "epoch 52; iter: 0; batch classifier loss: 0.123301; batch adversarial loss: 0.468227\n",
      "epoch 53; iter: 0; batch classifier loss: 0.067367; batch adversarial loss: 0.436684\n",
      "epoch 54; iter: 0; batch classifier loss: 0.063096; batch adversarial loss: 0.394616\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178503; batch adversarial loss: 0.446241\n",
      "epoch 56; iter: 0; batch classifier loss: 0.065874; batch adversarial loss: 0.439595\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097214; batch adversarial loss: 0.428263\n",
      "epoch 58; iter: 0; batch classifier loss: 0.064214; batch adversarial loss: 0.432405\n",
      "epoch 59; iter: 0; batch classifier loss: 0.078421; batch adversarial loss: 0.420819\n",
      "epoch 60; iter: 0; batch classifier loss: 0.085810; batch adversarial loss: 0.560701\n",
      "epoch 61; iter: 0; batch classifier loss: 0.057176; batch adversarial loss: 0.380903\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066348; batch adversarial loss: 0.428310\n",
      "epoch 63; iter: 0; batch classifier loss: 0.060446; batch adversarial loss: 0.335018\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076351; batch adversarial loss: 0.397182\n",
      "epoch 65; iter: 0; batch classifier loss: 0.057198; batch adversarial loss: 0.428671\n",
      "epoch 66; iter: 0; batch classifier loss: 0.066142; batch adversarial loss: 0.367852\n",
      "epoch 67; iter: 0; batch classifier loss: 0.091899; batch adversarial loss: 0.513612\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076559; batch adversarial loss: 0.408810\n",
      "epoch 69; iter: 0; batch classifier loss: 0.109424; batch adversarial loss: 0.405632\n",
      "epoch 70; iter: 0; batch classifier loss: 0.130921; batch adversarial loss: 0.384530\n",
      "epoch 71; iter: 0; batch classifier loss: 0.070918; batch adversarial loss: 0.467168\n",
      "epoch 72; iter: 0; batch classifier loss: 0.038643; batch adversarial loss: 0.422357\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085018; batch adversarial loss: 0.414741\n",
      "epoch 74; iter: 0; batch classifier loss: 0.083354; batch adversarial loss: 0.394498\n",
      "epoch 75; iter: 0; batch classifier loss: 0.109471; batch adversarial loss: 0.441456\n",
      "epoch 76; iter: 0; batch classifier loss: 0.059828; batch adversarial loss: 0.470438\n",
      "epoch 77; iter: 0; batch classifier loss: 0.062145; batch adversarial loss: 0.414656\n",
      "epoch 78; iter: 0; batch classifier loss: 0.074641; batch adversarial loss: 0.427184\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077107; batch adversarial loss: 0.420398\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085561; batch adversarial loss: 0.421365\n",
      "epoch 81; iter: 0; batch classifier loss: 0.067514; batch adversarial loss: 0.473313\n",
      "epoch 82; iter: 0; batch classifier loss: 0.077830; batch adversarial loss: 0.418829\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055116; batch adversarial loss: 0.364021\n",
      "epoch 84; iter: 0; batch classifier loss: 0.070927; batch adversarial loss: 0.407102\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069744; batch adversarial loss: 0.426532\n",
      "epoch 86; iter: 0; batch classifier loss: 0.075952; batch adversarial loss: 0.422338\n",
      "epoch 87; iter: 0; batch classifier loss: 0.118947; batch adversarial loss: 0.463590\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074583; batch adversarial loss: 0.351028\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056379; batch adversarial loss: 0.344090\n",
      "epoch 90; iter: 0; batch classifier loss: 0.093452; batch adversarial loss: 0.382663\n",
      "epoch 91; iter: 0; batch classifier loss: 0.104442; batch adversarial loss: 0.447184\n",
      "epoch 92; iter: 0; batch classifier loss: 0.080583; batch adversarial loss: 0.442764\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.324564\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048056; batch adversarial loss: 0.425193\n",
      "epoch 95; iter: 0; batch classifier loss: 0.066953; batch adversarial loss: 0.503974\n",
      "epoch 96; iter: 0; batch classifier loss: 0.096988; batch adversarial loss: 0.524927\n",
      "epoch 97; iter: 0; batch classifier loss: 0.075904; batch adversarial loss: 0.475333\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053485; batch adversarial loss: 0.499600\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067898; batch adversarial loss: 0.497538\n",
      "epoch 100; iter: 0; batch classifier loss: 0.129606; batch adversarial loss: 0.483906\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053614; batch adversarial loss: 0.324552\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044252; batch adversarial loss: 0.451116\n",
      "epoch 103; iter: 0; batch classifier loss: 0.050818; batch adversarial loss: 0.465674\n",
      "epoch 104; iter: 0; batch classifier loss: 0.048134; batch adversarial loss: 0.356679\n",
      "epoch 105; iter: 0; batch classifier loss: 0.051173; batch adversarial loss: 0.524330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 106; iter: 0; batch classifier loss: 0.058623; batch adversarial loss: 0.453736\n",
      "epoch 107; iter: 0; batch classifier loss: 0.085390; batch adversarial loss: 0.484532\n",
      "epoch 108; iter: 0; batch classifier loss: 0.078481; batch adversarial loss: 0.417102\n",
      "epoch 109; iter: 0; batch classifier loss: 0.093187; batch adversarial loss: 0.449542\n",
      "epoch 110; iter: 0; batch classifier loss: 0.092768; batch adversarial loss: 0.404317\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062949; batch adversarial loss: 0.376627\n",
      "epoch 112; iter: 0; batch classifier loss: 0.064263; batch adversarial loss: 0.456617\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054716; batch adversarial loss: 0.370586\n",
      "epoch 114; iter: 0; batch classifier loss: 0.073740; batch adversarial loss: 0.425205\n",
      "epoch 115; iter: 0; batch classifier loss: 0.073008; batch adversarial loss: 0.492703\n",
      "epoch 116; iter: 0; batch classifier loss: 0.093979; batch adversarial loss: 0.426070\n",
      "epoch 117; iter: 0; batch classifier loss: 0.084902; batch adversarial loss: 0.416780\n",
      "epoch 118; iter: 0; batch classifier loss: 0.078951; batch adversarial loss: 0.380886\n",
      "epoch 119; iter: 0; batch classifier loss: 0.098694; batch adversarial loss: 0.455843\n",
      "epoch 120; iter: 0; batch classifier loss: 0.085460; batch adversarial loss: 0.419773\n",
      "epoch 121; iter: 0; batch classifier loss: 0.082187; batch adversarial loss: 0.421844\n",
      "epoch 122; iter: 0; batch classifier loss: 0.056038; batch adversarial loss: 0.440634\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033614; batch adversarial loss: 0.518173\n",
      "epoch 124; iter: 0; batch classifier loss: 0.040310; batch adversarial loss: 0.445599\n",
      "epoch 125; iter: 0; batch classifier loss: 0.104084; batch adversarial loss: 0.494188\n",
      "epoch 126; iter: 0; batch classifier loss: 0.046696; batch adversarial loss: 0.426640\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063645; batch adversarial loss: 0.483242\n",
      "epoch 128; iter: 0; batch classifier loss: 0.081110; batch adversarial loss: 0.482533\n",
      "epoch 129; iter: 0; batch classifier loss: 0.048974; batch adversarial loss: 0.478533\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046665; batch adversarial loss: 0.431045\n",
      "epoch 131; iter: 0; batch classifier loss: 0.119886; batch adversarial loss: 0.504687\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062385; batch adversarial loss: 0.448955\n",
      "epoch 133; iter: 0; batch classifier loss: 0.071491; batch adversarial loss: 0.403502\n",
      "epoch 134; iter: 0; batch classifier loss: 0.054463; batch adversarial loss: 0.501433\n",
      "epoch 135; iter: 0; batch classifier loss: 0.083630; batch adversarial loss: 0.452371\n",
      "epoch 136; iter: 0; batch classifier loss: 0.044441; batch adversarial loss: 0.385480\n",
      "epoch 137; iter: 0; batch classifier loss: 0.043110; batch adversarial loss: 0.343282\n",
      "epoch 138; iter: 0; batch classifier loss: 0.084248; batch adversarial loss: 0.412803\n",
      "epoch 139; iter: 0; batch classifier loss: 0.076150; batch adversarial loss: 0.431926\n",
      "epoch 140; iter: 0; batch classifier loss: 0.090963; batch adversarial loss: 0.445564\n",
      "epoch 141; iter: 0; batch classifier loss: 0.076060; batch adversarial loss: 0.452602\n",
      "epoch 142; iter: 0; batch classifier loss: 0.046666; batch adversarial loss: 0.455046\n",
      "epoch 143; iter: 0; batch classifier loss: 0.077524; batch adversarial loss: 0.416844\n",
      "epoch 144; iter: 0; batch classifier loss: 0.059173; batch adversarial loss: 0.342626\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053225; batch adversarial loss: 0.446775\n",
      "epoch 146; iter: 0; batch classifier loss: 0.072292; batch adversarial loss: 0.379520\n",
      "epoch 147; iter: 0; batch classifier loss: 0.076227; batch adversarial loss: 0.419715\n",
      "epoch 148; iter: 0; batch classifier loss: 0.067245; batch adversarial loss: 0.390755\n",
      "epoch 149; iter: 0; batch classifier loss: 0.092050; batch adversarial loss: 0.452283\n",
      "epoch 150; iter: 0; batch classifier loss: 0.067702; batch adversarial loss: 0.421152\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041661; batch adversarial loss: 0.306682\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027054; batch adversarial loss: 0.460365\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073923; batch adversarial loss: 0.405619\n",
      "epoch 154; iter: 0; batch classifier loss: 0.064258; batch adversarial loss: 0.421758\n",
      "epoch 155; iter: 0; batch classifier loss: 0.041525; batch adversarial loss: 0.473270\n",
      "epoch 156; iter: 0; batch classifier loss: 0.079419; batch adversarial loss: 0.425267\n",
      "epoch 157; iter: 0; batch classifier loss: 0.088774; batch adversarial loss: 0.458854\n",
      "epoch 158; iter: 0; batch classifier loss: 0.043996; batch adversarial loss: 0.338882\n",
      "epoch 159; iter: 0; batch classifier loss: 0.057690; batch adversarial loss: 0.499390\n",
      "epoch 160; iter: 0; batch classifier loss: 0.051604; batch adversarial loss: 0.433758\n",
      "epoch 161; iter: 0; batch classifier loss: 0.032758; batch adversarial loss: 0.519099\n",
      "epoch 162; iter: 0; batch classifier loss: 0.076152; batch adversarial loss: 0.442106\n",
      "epoch 163; iter: 0; batch classifier loss: 0.067939; batch adversarial loss: 0.467316\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043165; batch adversarial loss: 0.418258\n",
      "epoch 165; iter: 0; batch classifier loss: 0.060439; batch adversarial loss: 0.479016\n",
      "epoch 166; iter: 0; batch classifier loss: 0.077004; batch adversarial loss: 0.480236\n",
      "epoch 167; iter: 0; batch classifier loss: 0.034105; batch adversarial loss: 0.446675\n",
      "epoch 168; iter: 0; batch classifier loss: 0.051264; batch adversarial loss: 0.462917\n",
      "epoch 169; iter: 0; batch classifier loss: 0.045915; batch adversarial loss: 0.384025\n",
      "epoch 170; iter: 0; batch classifier loss: 0.065052; batch adversarial loss: 0.419848\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030398; batch adversarial loss: 0.352435\n",
      "epoch 172; iter: 0; batch classifier loss: 0.057208; batch adversarial loss: 0.382080\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039959; batch adversarial loss: 0.401390\n",
      "epoch 174; iter: 0; batch classifier loss: 0.045350; batch adversarial loss: 0.454847\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041286; batch adversarial loss: 0.470778\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030311; batch adversarial loss: 0.397958\n",
      "epoch 177; iter: 0; batch classifier loss: 0.052251; batch adversarial loss: 0.519054\n",
      "epoch 178; iter: 0; batch classifier loss: 0.050516; batch adversarial loss: 0.313633\n",
      "epoch 179; iter: 0; batch classifier loss: 0.034623; batch adversarial loss: 0.387739\n",
      "epoch 180; iter: 0; batch classifier loss: 0.034294; batch adversarial loss: 0.477540\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046808; batch adversarial loss: 0.433550\n",
      "epoch 182; iter: 0; batch classifier loss: 0.066011; batch adversarial loss: 0.388161\n",
      "epoch 183; iter: 0; batch classifier loss: 0.095431; batch adversarial loss: 0.451976\n",
      "epoch 184; iter: 0; batch classifier loss: 0.037244; batch adversarial loss: 0.393240\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033165; batch adversarial loss: 0.436831\n",
      "epoch 186; iter: 0; batch classifier loss: 0.030880; batch adversarial loss: 0.365319\n",
      "epoch 187; iter: 0; batch classifier loss: 0.046635; batch adversarial loss: 0.399920\n",
      "epoch 188; iter: 0; batch classifier loss: 0.029224; batch adversarial loss: 0.387867\n",
      "epoch 189; iter: 0; batch classifier loss: 0.058260; batch adversarial loss: 0.409033\n",
      "epoch 190; iter: 0; batch classifier loss: 0.059148; batch adversarial loss: 0.461391\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028836; batch adversarial loss: 0.502310\n",
      "epoch 192; iter: 0; batch classifier loss: 0.034230; batch adversarial loss: 0.421727\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031677; batch adversarial loss: 0.461107\n",
      "epoch 194; iter: 0; batch classifier loss: 0.019463; batch adversarial loss: 0.470848\n",
      "epoch 195; iter: 0; batch classifier loss: 0.042910; batch adversarial loss: 0.431034\n",
      "epoch 196; iter: 0; batch classifier loss: 0.032981; batch adversarial loss: 0.428960\n",
      "epoch 197; iter: 0; batch classifier loss: 0.044312; batch adversarial loss: 0.448786\n",
      "epoch 198; iter: 0; batch classifier loss: 0.011153; batch adversarial loss: 0.403439\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020002; batch adversarial loss: 0.384239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685734; batch adversarial loss: 0.736993\n",
      "epoch 1; iter: 0; batch classifier loss: 0.537658; batch adversarial loss: 0.678965\n",
      "epoch 2; iter: 0; batch classifier loss: 0.347500; batch adversarial loss: 0.627738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.355853; batch adversarial loss: 0.575068\n",
      "epoch 4; iter: 0; batch classifier loss: 0.439590; batch adversarial loss: 0.601527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.359076; batch adversarial loss: 0.588482\n",
      "epoch 6; iter: 0; batch classifier loss: 0.301804; batch adversarial loss: 0.572085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.286499; batch adversarial loss: 0.517562\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301765; batch adversarial loss: 0.553748\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342698; batch adversarial loss: 0.485354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.246083; batch adversarial loss: 0.501607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271481; batch adversarial loss: 0.554011\n",
      "epoch 12; iter: 0; batch classifier loss: 0.228640; batch adversarial loss: 0.535942\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203830; batch adversarial loss: 0.526557\n",
      "epoch 14; iter: 0; batch classifier loss: 0.187562; batch adversarial loss: 0.440169\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281846; batch adversarial loss: 0.421503\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253380; batch adversarial loss: 0.456942\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282507; batch adversarial loss: 0.458946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.196169; batch adversarial loss: 0.476450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.168028; batch adversarial loss: 0.508602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.162890; batch adversarial loss: 0.530258\n",
      "epoch 21; iter: 0; batch classifier loss: 0.197693; batch adversarial loss: 0.398440\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174570; batch adversarial loss: 0.491972\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171125; batch adversarial loss: 0.530778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.197785; batch adversarial loss: 0.403936\n",
      "epoch 25; iter: 0; batch classifier loss: 0.140868; batch adversarial loss: 0.557411\n",
      "epoch 26; iter: 0; batch classifier loss: 0.142425; batch adversarial loss: 0.397460\n",
      "epoch 27; iter: 0; batch classifier loss: 0.118247; batch adversarial loss: 0.522472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.158109; batch adversarial loss: 0.427878\n",
      "epoch 29; iter: 0; batch classifier loss: 0.111040; batch adversarial loss: 0.510617\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144444; batch adversarial loss: 0.495438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.184403; batch adversarial loss: 0.450330\n",
      "epoch 32; iter: 0; batch classifier loss: 0.146297; batch adversarial loss: 0.418848\n",
      "epoch 33; iter: 0; batch classifier loss: 0.134455; batch adversarial loss: 0.457683\n",
      "epoch 34; iter: 0; batch classifier loss: 0.104304; batch adversarial loss: 0.543147\n",
      "epoch 35; iter: 0; batch classifier loss: 0.118261; batch adversarial loss: 0.390944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.116355; batch adversarial loss: 0.494434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132829; batch adversarial loss: 0.430652\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117221; batch adversarial loss: 0.497443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.103438; batch adversarial loss: 0.434361\n",
      "epoch 40; iter: 0; batch classifier loss: 0.159304; batch adversarial loss: 0.426512\n",
      "epoch 41; iter: 0; batch classifier loss: 0.124143; batch adversarial loss: 0.415959\n",
      "epoch 42; iter: 0; batch classifier loss: 0.131166; batch adversarial loss: 0.389513\n",
      "epoch 43; iter: 0; batch classifier loss: 0.145680; batch adversarial loss: 0.474502\n",
      "epoch 44; iter: 0; batch classifier loss: 0.103542; batch adversarial loss: 0.486349\n",
      "epoch 45; iter: 0; batch classifier loss: 0.111512; batch adversarial loss: 0.384612\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090095; batch adversarial loss: 0.461418\n",
      "epoch 47; iter: 0; batch classifier loss: 0.099761; batch adversarial loss: 0.478962\n",
      "epoch 48; iter: 0; batch classifier loss: 0.119671; batch adversarial loss: 0.447376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.123794; batch adversarial loss: 0.467231\n",
      "epoch 50; iter: 0; batch classifier loss: 0.059552; batch adversarial loss: 0.435245\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077525; batch adversarial loss: 0.355786\n",
      "epoch 52; iter: 0; batch classifier loss: 0.138724; batch adversarial loss: 0.443437\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098042; batch adversarial loss: 0.563680\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127715; batch adversarial loss: 0.447576\n",
      "epoch 55; iter: 0; batch classifier loss: 0.067924; batch adversarial loss: 0.510015\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095612; batch adversarial loss: 0.418354\n",
      "epoch 57; iter: 0; batch classifier loss: 0.066754; batch adversarial loss: 0.447766\n",
      "epoch 58; iter: 0; batch classifier loss: 0.141612; batch adversarial loss: 0.400322\n",
      "epoch 59; iter: 0; batch classifier loss: 0.076259; batch adversarial loss: 0.455081\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122170; batch adversarial loss: 0.438632\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109574; batch adversarial loss: 0.395909\n",
      "epoch 62; iter: 0; batch classifier loss: 0.114828; batch adversarial loss: 0.422598\n",
      "epoch 63; iter: 0; batch classifier loss: 0.070315; batch adversarial loss: 0.383185\n",
      "epoch 64; iter: 0; batch classifier loss: 0.086086; batch adversarial loss: 0.474423\n",
      "epoch 65; iter: 0; batch classifier loss: 0.086617; batch adversarial loss: 0.498739\n",
      "epoch 66; iter: 0; batch classifier loss: 0.099584; batch adversarial loss: 0.423604\n",
      "epoch 67; iter: 0; batch classifier loss: 0.124332; batch adversarial loss: 0.346250\n",
      "epoch 68; iter: 0; batch classifier loss: 0.086119; batch adversarial loss: 0.485830\n",
      "epoch 69; iter: 0; batch classifier loss: 0.056408; batch adversarial loss: 0.458205\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076860; batch adversarial loss: 0.442561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134863; batch adversarial loss: 0.444446\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111732; batch adversarial loss: 0.442200\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110874; batch adversarial loss: 0.409370\n",
      "epoch 74; iter: 0; batch classifier loss: 0.068421; batch adversarial loss: 0.438155\n",
      "epoch 75; iter: 0; batch classifier loss: 0.137143; batch adversarial loss: 0.475897\n",
      "epoch 76; iter: 0; batch classifier loss: 0.068624; batch adversarial loss: 0.520779\n",
      "epoch 77; iter: 0; batch classifier loss: 0.079473; batch adversarial loss: 0.444540\n",
      "epoch 78; iter: 0; batch classifier loss: 0.113259; batch adversarial loss: 0.490320\n",
      "epoch 79; iter: 0; batch classifier loss: 0.074428; batch adversarial loss: 0.445304\n",
      "epoch 80; iter: 0; batch classifier loss: 0.071122; batch adversarial loss: 0.465539\n",
      "epoch 81; iter: 0; batch classifier loss: 0.068520; batch adversarial loss: 0.437914\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067924; batch adversarial loss: 0.452765\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144340; batch adversarial loss: 0.434584\n",
      "epoch 84; iter: 0; batch classifier loss: 0.068368; batch adversarial loss: 0.397283\n",
      "epoch 85; iter: 0; batch classifier loss: 0.052577; batch adversarial loss: 0.461138\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049391; batch adversarial loss: 0.473152\n",
      "epoch 87; iter: 0; batch classifier loss: 0.071338; batch adversarial loss: 0.448023\n",
      "epoch 88; iter: 0; batch classifier loss: 0.066735; batch adversarial loss: 0.390972\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066404; batch adversarial loss: 0.471904\n",
      "epoch 90; iter: 0; batch classifier loss: 0.036370; batch adversarial loss: 0.415094\n",
      "epoch 91; iter: 0; batch classifier loss: 0.073259; batch adversarial loss: 0.489219\n",
      "epoch 92; iter: 0; batch classifier loss: 0.041753; batch adversarial loss: 0.400630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056055; batch adversarial loss: 0.436935\n",
      "epoch 94; iter: 0; batch classifier loss: 0.074670; batch adversarial loss: 0.395403\n",
      "epoch 95; iter: 0; batch classifier loss: 0.037235; batch adversarial loss: 0.437744\n",
      "epoch 96; iter: 0; batch classifier loss: 0.068167; batch adversarial loss: 0.397754\n",
      "epoch 97; iter: 0; batch classifier loss: 0.043051; batch adversarial loss: 0.470908\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067354; batch adversarial loss: 0.495475\n",
      "epoch 99; iter: 0; batch classifier loss: 0.049823; batch adversarial loss: 0.576254\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053288; batch adversarial loss: 0.511178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 101; iter: 0; batch classifier loss: 0.030417; batch adversarial loss: 0.429548\n",
      "epoch 102; iter: 0; batch classifier loss: 0.030074; batch adversarial loss: 0.512256\n",
      "epoch 103; iter: 0; batch classifier loss: 0.025675; batch adversarial loss: 0.474529\n",
      "epoch 104; iter: 0; batch classifier loss: 0.041955; batch adversarial loss: 0.420365\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025111; batch adversarial loss: 0.405768\n",
      "epoch 106; iter: 0; batch classifier loss: 0.059711; batch adversarial loss: 0.379782\n",
      "epoch 107; iter: 0; batch classifier loss: 0.046828; batch adversarial loss: 0.472734\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028949; batch adversarial loss: 0.444570\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039372; batch adversarial loss: 0.438234\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044155; batch adversarial loss: 0.372589\n",
      "epoch 111; iter: 0; batch classifier loss: 0.083818; batch adversarial loss: 0.400538\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070108; batch adversarial loss: 0.356491\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054000; batch adversarial loss: 0.459796\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057373; batch adversarial loss: 0.483020\n",
      "epoch 115; iter: 0; batch classifier loss: 0.076406; batch adversarial loss: 0.361401\n",
      "epoch 116; iter: 0; batch classifier loss: 0.071954; batch adversarial loss: 0.377363\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038718; batch adversarial loss: 0.423569\n",
      "epoch 118; iter: 0; batch classifier loss: 0.032847; batch adversarial loss: 0.474669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.039160; batch adversarial loss: 0.419601\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051755; batch adversarial loss: 0.364302\n",
      "epoch 121; iter: 0; batch classifier loss: 0.011344; batch adversarial loss: 0.514118\n",
      "epoch 122; iter: 0; batch classifier loss: 0.027788; batch adversarial loss: 0.498240\n",
      "epoch 123; iter: 0; batch classifier loss: 0.041524; batch adversarial loss: 0.497486\n",
      "epoch 124; iter: 0; batch classifier loss: 0.016931; batch adversarial loss: 0.474880\n",
      "epoch 125; iter: 0; batch classifier loss: 0.033524; batch adversarial loss: 0.424232\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022697; batch adversarial loss: 0.441782\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036765; batch adversarial loss: 0.386122\n",
      "epoch 128; iter: 0; batch classifier loss: 0.020070; batch adversarial loss: 0.510096\n",
      "epoch 129; iter: 0; batch classifier loss: 0.027473; batch adversarial loss: 0.511395\n",
      "epoch 130; iter: 0; batch classifier loss: 0.047412; batch adversarial loss: 0.532193\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026851; batch adversarial loss: 0.463940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038189; batch adversarial loss: 0.517716\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028969; batch adversarial loss: 0.445262\n",
      "epoch 134; iter: 0; batch classifier loss: 0.029005; batch adversarial loss: 0.397383\n",
      "epoch 135; iter: 0; batch classifier loss: 0.022025; batch adversarial loss: 0.487721\n",
      "epoch 136; iter: 0; batch classifier loss: 0.053644; batch adversarial loss: 0.467929\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028155; batch adversarial loss: 0.379486\n",
      "epoch 138; iter: 0; batch classifier loss: 0.043070; batch adversarial loss: 0.432004\n",
      "epoch 139; iter: 0; batch classifier loss: 0.039354; batch adversarial loss: 0.346723\n",
      "epoch 140; iter: 0; batch classifier loss: 0.008945; batch adversarial loss: 0.471822\n",
      "epoch 141; iter: 0; batch classifier loss: 0.057958; batch adversarial loss: 0.500880\n",
      "epoch 142; iter: 0; batch classifier loss: 0.064437; batch adversarial loss: 0.436062\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035655; batch adversarial loss: 0.407052\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039232; batch adversarial loss: 0.506110\n",
      "epoch 145; iter: 0; batch classifier loss: 0.061854; batch adversarial loss: 0.407561\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051720; batch adversarial loss: 0.536925\n",
      "epoch 147; iter: 0; batch classifier loss: 0.034202; batch adversarial loss: 0.415535\n",
      "epoch 148; iter: 0; batch classifier loss: 0.021216; batch adversarial loss: 0.523129\n",
      "epoch 149; iter: 0; batch classifier loss: 0.012359; batch adversarial loss: 0.568626\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048132; batch adversarial loss: 0.495440\n",
      "epoch 151; iter: 0; batch classifier loss: 0.033385; batch adversarial loss: 0.355864\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013883; batch adversarial loss: 0.446638\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011303; batch adversarial loss: 0.559934\n",
      "epoch 154; iter: 0; batch classifier loss: 0.013335; batch adversarial loss: 0.458649\n",
      "epoch 155; iter: 0; batch classifier loss: 0.028770; batch adversarial loss: 0.415118\n",
      "epoch 156; iter: 0; batch classifier loss: 0.009158; batch adversarial loss: 0.446371\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022335; batch adversarial loss: 0.478124\n",
      "epoch 158; iter: 0; batch classifier loss: 0.005596; batch adversarial loss: 0.444218\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013131; batch adversarial loss: 0.469479\n",
      "epoch 160; iter: 0; batch classifier loss: 0.016136; batch adversarial loss: 0.431344\n",
      "epoch 161; iter: 0; batch classifier loss: 0.052996; batch adversarial loss: 0.367696\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019221; batch adversarial loss: 0.321113\n",
      "epoch 163; iter: 0; batch classifier loss: 0.041246; batch adversarial loss: 0.402605\n",
      "epoch 164; iter: 0; batch classifier loss: 0.017878; batch adversarial loss: 0.423298\n",
      "epoch 165; iter: 0; batch classifier loss: 0.066442; batch adversarial loss: 0.450913\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046498; batch adversarial loss: 0.485367\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023196; batch adversarial loss: 0.469560\n",
      "epoch 168; iter: 0; batch classifier loss: 0.052749; batch adversarial loss: 0.394554\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026516; batch adversarial loss: 0.463568\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032515; batch adversarial loss: 0.449512\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021382; batch adversarial loss: 0.499163\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.505357\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016118; batch adversarial loss: 0.422599\n",
      "epoch 174; iter: 0; batch classifier loss: 0.039378; batch adversarial loss: 0.452326\n",
      "epoch 175; iter: 0; batch classifier loss: 0.022866; batch adversarial loss: 0.447004\n",
      "epoch 176; iter: 0; batch classifier loss: 0.032561; batch adversarial loss: 0.466149\n",
      "epoch 177; iter: 0; batch classifier loss: 0.047284; batch adversarial loss: 0.405507\n",
      "epoch 178; iter: 0; batch classifier loss: 0.022431; batch adversarial loss: 0.453262\n",
      "epoch 179; iter: 0; batch classifier loss: 0.020865; batch adversarial loss: 0.440807\n",
      "epoch 180; iter: 0; batch classifier loss: 0.013803; batch adversarial loss: 0.538750\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015821; batch adversarial loss: 0.456808\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033216; batch adversarial loss: 0.471066\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018836; batch adversarial loss: 0.478936\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029113; batch adversarial loss: 0.386746\n",
      "epoch 185; iter: 0; batch classifier loss: 0.035785; batch adversarial loss: 0.413978\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010308; batch adversarial loss: 0.476401\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029991; batch adversarial loss: 0.428714\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045355; batch adversarial loss: 0.390456\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.418187\n",
      "epoch 190; iter: 0; batch classifier loss: 0.061161; batch adversarial loss: 0.438222\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035816; batch adversarial loss: 0.428189\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030375; batch adversarial loss: 0.390064\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015589; batch adversarial loss: 0.462099\n",
      "epoch 194; iter: 0; batch classifier loss: 0.037102; batch adversarial loss: 0.413903\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034263; batch adversarial loss: 0.401503\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019225; batch adversarial loss: 0.514729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197; iter: 0; batch classifier loss: 0.024606; batch adversarial loss: 0.409635\n",
      "epoch 198; iter: 0; batch classifier loss: 0.021692; batch adversarial loss: 0.430681\n",
      "epoch 199; iter: 0; batch classifier loss: 0.034151; batch adversarial loss: 0.409525\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679819; batch adversarial loss: 0.822486\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417752; batch adversarial loss: 0.786593\n",
      "epoch 2; iter: 0; batch classifier loss: 0.480935; batch adversarial loss: 0.742845\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516077; batch adversarial loss: 0.686881\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596453; batch adversarial loss: 0.640378\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517704; batch adversarial loss: 0.589974\n",
      "epoch 6; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.580564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384315; batch adversarial loss: 0.569451\n",
      "epoch 8; iter: 0; batch classifier loss: 0.341049; batch adversarial loss: 0.556154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372249; batch adversarial loss: 0.542729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397859; batch adversarial loss: 0.538727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.350819; batch adversarial loss: 0.533924\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388379; batch adversarial loss: 0.521466\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378244; batch adversarial loss: 0.504857\n",
      "epoch 14; iter: 0; batch classifier loss: 0.424147; batch adversarial loss: 0.507201\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406760; batch adversarial loss: 0.499616\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357238; batch adversarial loss: 0.538480\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317120; batch adversarial loss: 0.469767\n",
      "epoch 18; iter: 0; batch classifier loss: 0.321268; batch adversarial loss: 0.449656\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311294; batch adversarial loss: 0.490760\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315145; batch adversarial loss: 0.509759\n",
      "epoch 21; iter: 0; batch classifier loss: 0.258586; batch adversarial loss: 0.487377\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276115; batch adversarial loss: 0.444353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342903; batch adversarial loss: 0.419044\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258397; batch adversarial loss: 0.535656\n",
      "epoch 25; iter: 0; batch classifier loss: 0.210470; batch adversarial loss: 0.449607\n",
      "epoch 26; iter: 0; batch classifier loss: 0.292975; batch adversarial loss: 0.516164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310409; batch adversarial loss: 0.449627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.312016; batch adversarial loss: 0.441998\n",
      "epoch 29; iter: 0; batch classifier loss: 0.197220; batch adversarial loss: 0.520851\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281565; batch adversarial loss: 0.500065\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269885; batch adversarial loss: 0.463698\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222085; batch adversarial loss: 0.526692\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233139; batch adversarial loss: 0.470568\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224278; batch adversarial loss: 0.447356\n",
      "epoch 35; iter: 0; batch classifier loss: 0.240119; batch adversarial loss: 0.531303\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249566; batch adversarial loss: 0.499869\n",
      "epoch 37; iter: 0; batch classifier loss: 0.221801; batch adversarial loss: 0.367685\n",
      "epoch 38; iter: 0; batch classifier loss: 0.267222; batch adversarial loss: 0.379204\n",
      "epoch 39; iter: 0; batch classifier loss: 0.212097; batch adversarial loss: 0.401916\n",
      "epoch 40; iter: 0; batch classifier loss: 0.218776; batch adversarial loss: 0.487723\n",
      "epoch 41; iter: 0; batch classifier loss: 0.249960; batch adversarial loss: 0.481351\n",
      "epoch 42; iter: 0; batch classifier loss: 0.208303; batch adversarial loss: 0.453991\n",
      "epoch 43; iter: 0; batch classifier loss: 0.205854; batch adversarial loss: 0.434035\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247014; batch adversarial loss: 0.362876\n",
      "epoch 45; iter: 0; batch classifier loss: 0.194269; batch adversarial loss: 0.458990\n",
      "epoch 46; iter: 0; batch classifier loss: 0.213917; batch adversarial loss: 0.444636\n",
      "epoch 47; iter: 0; batch classifier loss: 0.241709; batch adversarial loss: 0.444075\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223776; batch adversarial loss: 0.457269\n",
      "epoch 49; iter: 0; batch classifier loss: 0.225663; batch adversarial loss: 0.395567\n",
      "epoch 50; iter: 0; batch classifier loss: 0.177244; batch adversarial loss: 0.421324\n",
      "epoch 51; iter: 0; batch classifier loss: 0.219627; batch adversarial loss: 0.534305\n",
      "epoch 52; iter: 0; batch classifier loss: 0.196932; batch adversarial loss: 0.398420\n",
      "epoch 53; iter: 0; batch classifier loss: 0.220146; batch adversarial loss: 0.485434\n",
      "epoch 54; iter: 0; batch classifier loss: 0.198437; batch adversarial loss: 0.422017\n",
      "epoch 55; iter: 0; batch classifier loss: 0.189840; batch adversarial loss: 0.436783\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194439; batch adversarial loss: 0.408162\n",
      "epoch 57; iter: 0; batch classifier loss: 0.231709; batch adversarial loss: 0.424375\n",
      "epoch 58; iter: 0; batch classifier loss: 0.221823; batch adversarial loss: 0.484955\n",
      "epoch 59; iter: 0; batch classifier loss: 0.180821; batch adversarial loss: 0.433203\n",
      "epoch 60; iter: 0; batch classifier loss: 0.187064; batch adversarial loss: 0.471597\n",
      "epoch 61; iter: 0; batch classifier loss: 0.170926; batch adversarial loss: 0.384217\n",
      "epoch 62; iter: 0; batch classifier loss: 0.208798; batch adversarial loss: 0.433398\n",
      "epoch 63; iter: 0; batch classifier loss: 0.125745; batch adversarial loss: 0.499636\n",
      "epoch 64; iter: 0; batch classifier loss: 0.167160; batch adversarial loss: 0.496189\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138319; batch adversarial loss: 0.409436\n",
      "epoch 66; iter: 0; batch classifier loss: 0.192831; batch adversarial loss: 0.459607\n",
      "epoch 67; iter: 0; batch classifier loss: 0.188925; batch adversarial loss: 0.522857\n",
      "epoch 68; iter: 0; batch classifier loss: 0.233684; batch adversarial loss: 0.420795\n",
      "epoch 69; iter: 0; batch classifier loss: 0.229990; batch adversarial loss: 0.396130\n",
      "epoch 70; iter: 0; batch classifier loss: 0.158505; batch adversarial loss: 0.395965\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209859; batch adversarial loss: 0.421021\n",
      "epoch 72; iter: 0; batch classifier loss: 0.186079; batch adversarial loss: 0.471500\n",
      "epoch 73; iter: 0; batch classifier loss: 0.240193; batch adversarial loss: 0.408646\n",
      "epoch 74; iter: 0; batch classifier loss: 0.227749; batch adversarial loss: 0.458940\n",
      "epoch 75; iter: 0; batch classifier loss: 0.059955; batch adversarial loss: 0.432099\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075583; batch adversarial loss: 0.472147\n",
      "epoch 77; iter: 0; batch classifier loss: 0.056077; batch adversarial loss: 0.468428\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072730; batch adversarial loss: 0.414218\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077913; batch adversarial loss: 0.389029\n",
      "epoch 80; iter: 0; batch classifier loss: 0.053872; batch adversarial loss: 0.417686\n",
      "epoch 81; iter: 0; batch classifier loss: 0.035904; batch adversarial loss: 0.451696\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067822; batch adversarial loss: 0.391964\n",
      "epoch 83; iter: 0; batch classifier loss: 0.037961; batch adversarial loss: 0.370638\n",
      "epoch 84; iter: 0; batch classifier loss: 0.054560; batch adversarial loss: 0.414090\n",
      "epoch 85; iter: 0; batch classifier loss: 0.065132; batch adversarial loss: 0.478797\n",
      "epoch 86; iter: 0; batch classifier loss: 0.053878; batch adversarial loss: 0.484107\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069115; batch adversarial loss: 0.408364\n",
      "epoch 88; iter: 0; batch classifier loss: 0.065089; batch adversarial loss: 0.389664\n",
      "epoch 89; iter: 0; batch classifier loss: 0.083100; batch adversarial loss: 0.407269\n",
      "epoch 90; iter: 0; batch classifier loss: 0.050455; batch adversarial loss: 0.364567\n",
      "epoch 91; iter: 0; batch classifier loss: 0.043419; batch adversarial loss: 0.399125\n",
      "epoch 92; iter: 0; batch classifier loss: 0.020528; batch adversarial loss: 0.378108\n",
      "epoch 93; iter: 0; batch classifier loss: 0.033107; batch adversarial loss: 0.489768\n",
      "epoch 94; iter: 0; batch classifier loss: 0.017088; batch adversarial loss: 0.491858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95; iter: 0; batch classifier loss: 0.052074; batch adversarial loss: 0.389855\n",
      "epoch 96; iter: 0; batch classifier loss: 0.055701; batch adversarial loss: 0.388210\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055682; batch adversarial loss: 0.472678\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036415; batch adversarial loss: 0.535269\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053008; batch adversarial loss: 0.504437\n",
      "epoch 100; iter: 0; batch classifier loss: 0.032970; batch adversarial loss: 0.454771\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050750; batch adversarial loss: 0.452929\n",
      "epoch 102; iter: 0; batch classifier loss: 0.057064; batch adversarial loss: 0.388358\n",
      "epoch 103; iter: 0; batch classifier loss: 0.044690; batch adversarial loss: 0.374875\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043145; batch adversarial loss: 0.450881\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041678; batch adversarial loss: 0.503304\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037920; batch adversarial loss: 0.347033\n",
      "epoch 107; iter: 0; batch classifier loss: 0.035628; batch adversarial loss: 0.464094\n",
      "epoch 108; iter: 0; batch classifier loss: 0.021300; batch adversarial loss: 0.443085\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038844; batch adversarial loss: 0.407701\n",
      "epoch 110; iter: 0; batch classifier loss: 0.019270; batch adversarial loss: 0.552480\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029198; batch adversarial loss: 0.487601\n",
      "epoch 112; iter: 0; batch classifier loss: 0.008747; batch adversarial loss: 0.521039\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027695; batch adversarial loss: 0.400196\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039734; batch adversarial loss: 0.491215\n",
      "epoch 115; iter: 0; batch classifier loss: 0.031517; batch adversarial loss: 0.473289\n",
      "epoch 116; iter: 0; batch classifier loss: 0.029976; batch adversarial loss: 0.480086\n",
      "epoch 117; iter: 0; batch classifier loss: 0.030182; batch adversarial loss: 0.424003\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015472; batch adversarial loss: 0.470937\n",
      "epoch 119; iter: 0; batch classifier loss: 0.019442; batch adversarial loss: 0.456530\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027083; batch adversarial loss: 0.440631\n",
      "epoch 121; iter: 0; batch classifier loss: 0.055124; batch adversarial loss: 0.529788\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022095; batch adversarial loss: 0.364125\n",
      "epoch 123; iter: 0; batch classifier loss: 0.055877; batch adversarial loss: 0.379866\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021811; batch adversarial loss: 0.456442\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046628; batch adversarial loss: 0.454005\n",
      "epoch 126; iter: 0; batch classifier loss: 0.011765; batch adversarial loss: 0.455288\n",
      "epoch 127; iter: 0; batch classifier loss: 0.011733; batch adversarial loss: 0.458705\n",
      "epoch 128; iter: 0; batch classifier loss: 0.040050; batch adversarial loss: 0.468972\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019944; batch adversarial loss: 0.415643\n",
      "epoch 130; iter: 0; batch classifier loss: 0.067745; batch adversarial loss: 0.453124\n",
      "epoch 131; iter: 0; batch classifier loss: 0.008164; batch adversarial loss: 0.387674\n",
      "epoch 132; iter: 0; batch classifier loss: 0.013927; batch adversarial loss: 0.373655\n",
      "epoch 133; iter: 0; batch classifier loss: 0.039820; batch adversarial loss: 0.382761\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031643; batch adversarial loss: 0.390178\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017787; batch adversarial loss: 0.436701\n",
      "epoch 136; iter: 0; batch classifier loss: 0.016415; batch adversarial loss: 0.468854\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036584; batch adversarial loss: 0.445208\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018805; batch adversarial loss: 0.434867\n",
      "epoch 139; iter: 0; batch classifier loss: 0.009739; batch adversarial loss: 0.432599\n",
      "epoch 140; iter: 0; batch classifier loss: 0.046811; batch adversarial loss: 0.355294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022409; batch adversarial loss: 0.410700\n",
      "epoch 142; iter: 0; batch classifier loss: 0.014820; batch adversarial loss: 0.561898\n",
      "epoch 143; iter: 0; batch classifier loss: 0.042625; batch adversarial loss: 0.338194\n",
      "epoch 144; iter: 0; batch classifier loss: 0.024900; batch adversarial loss: 0.438965\n",
      "epoch 145; iter: 0; batch classifier loss: 0.019496; batch adversarial loss: 0.381557\n",
      "epoch 146; iter: 0; batch classifier loss: 0.019078; batch adversarial loss: 0.373403\n",
      "epoch 147; iter: 0; batch classifier loss: 0.030770; batch adversarial loss: 0.558716\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027485; batch adversarial loss: 0.379518\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025484; batch adversarial loss: 0.449213\n",
      "epoch 150; iter: 0; batch classifier loss: 0.012077; batch adversarial loss: 0.475913\n",
      "epoch 151; iter: 0; batch classifier loss: 0.006963; batch adversarial loss: 0.471921\n",
      "epoch 152; iter: 0; batch classifier loss: 0.014752; batch adversarial loss: 0.454514\n",
      "epoch 153; iter: 0; batch classifier loss: 0.009899; batch adversarial loss: 0.449951\n",
      "epoch 154; iter: 0; batch classifier loss: 0.010625; batch adversarial loss: 0.499780\n",
      "epoch 155; iter: 0; batch classifier loss: 0.008423; batch adversarial loss: 0.452387\n",
      "epoch 156; iter: 0; batch classifier loss: 0.017469; batch adversarial loss: 0.414821\n",
      "epoch 157; iter: 0; batch classifier loss: 0.018231; batch adversarial loss: 0.349294\n",
      "epoch 158; iter: 0; batch classifier loss: 0.029173; batch adversarial loss: 0.442280\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018770; batch adversarial loss: 0.397445\n",
      "epoch 160; iter: 0; batch classifier loss: 0.020869; batch adversarial loss: 0.416697\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050953; batch adversarial loss: 0.431346\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014054; batch adversarial loss: 0.402157\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023114; batch adversarial loss: 0.507307\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010510; batch adversarial loss: 0.428001\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012680; batch adversarial loss: 0.428978\n",
      "epoch 166; iter: 0; batch classifier loss: 0.009574; batch adversarial loss: 0.401469\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023582; batch adversarial loss: 0.356324\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016957; batch adversarial loss: 0.365208\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008810; batch adversarial loss: 0.420809\n",
      "epoch 170; iter: 0; batch classifier loss: 0.041129; batch adversarial loss: 0.483767\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012271; batch adversarial loss: 0.436630\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022629; batch adversarial loss: 0.426827\n",
      "epoch 173; iter: 0; batch classifier loss: 0.009926; batch adversarial loss: 0.390961\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014193; batch adversarial loss: 0.384524\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004388; batch adversarial loss: 0.379330\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018267; batch adversarial loss: 0.438184\n",
      "epoch 177; iter: 0; batch classifier loss: 0.024152; batch adversarial loss: 0.404284\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013408; batch adversarial loss: 0.434462\n",
      "epoch 179; iter: 0; batch classifier loss: 0.018990; batch adversarial loss: 0.368707\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025236; batch adversarial loss: 0.497332\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007888; batch adversarial loss: 0.470928\n",
      "epoch 182; iter: 0; batch classifier loss: 0.022346; batch adversarial loss: 0.412933\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011690; batch adversarial loss: 0.355873\n",
      "epoch 184; iter: 0; batch classifier loss: 0.005020; batch adversarial loss: 0.486406\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021694; batch adversarial loss: 0.414642\n",
      "epoch 186; iter: 0; batch classifier loss: 0.010552; batch adversarial loss: 0.380784\n",
      "epoch 187; iter: 0; batch classifier loss: 0.020703; batch adversarial loss: 0.486199\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011035; batch adversarial loss: 0.350016\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020880; batch adversarial loss: 0.352106\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025056; batch adversarial loss: 0.535071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 191; iter: 0; batch classifier loss: 0.021355; batch adversarial loss: 0.497228\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006616; batch adversarial loss: 0.442781\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009944; batch adversarial loss: 0.488003\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030136; batch adversarial loss: 0.516632\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015430; batch adversarial loss: 0.413821\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015242; batch adversarial loss: 0.534234\n",
      "epoch 197; iter: 0; batch classifier loss: 0.020552; batch adversarial loss: 0.436162\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010545; batch adversarial loss: 0.411994\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009959; batch adversarial loss: 0.439289\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679748; batch adversarial loss: 0.811531\n",
      "epoch 1; iter: 0; batch classifier loss: 0.516542; batch adversarial loss: 0.796238\n",
      "epoch 2; iter: 0; batch classifier loss: 0.670348; batch adversarial loss: 0.789955\n",
      "epoch 3; iter: 0; batch classifier loss: 0.760319; batch adversarial loss: 0.724467\n",
      "epoch 4; iter: 0; batch classifier loss: 0.795291; batch adversarial loss: 0.643887\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517702; batch adversarial loss: 0.589666\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389696; batch adversarial loss: 0.579657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.333304; batch adversarial loss: 0.554791\n",
      "epoch 8; iter: 0; batch classifier loss: 0.332516; batch adversarial loss: 0.529197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363863; batch adversarial loss: 0.536402\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302084; batch adversarial loss: 0.563110\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344040; batch adversarial loss: 0.530264\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326488; batch adversarial loss: 0.500006\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378864; batch adversarial loss: 0.524081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373037; batch adversarial loss: 0.482729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346980; batch adversarial loss: 0.532169\n",
      "epoch 16; iter: 0; batch classifier loss: 0.288408; batch adversarial loss: 0.497058\n",
      "epoch 17; iter: 0; batch classifier loss: 0.264557; batch adversarial loss: 0.540248\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214684; batch adversarial loss: 0.486584\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295110; batch adversarial loss: 0.578311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313545; batch adversarial loss: 0.425418\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265328; batch adversarial loss: 0.495915\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282292; batch adversarial loss: 0.431158\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187099; batch adversarial loss: 0.569814\n",
      "epoch 24; iter: 0; batch classifier loss: 0.288433; batch adversarial loss: 0.433347\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301981; batch adversarial loss: 0.488937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.269409; batch adversarial loss: 0.444747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.279727; batch adversarial loss: 0.431687\n",
      "epoch 28; iter: 0; batch classifier loss: 0.316944; batch adversarial loss: 0.444850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.360778; batch adversarial loss: 0.395427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257312; batch adversarial loss: 0.441829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277902; batch adversarial loss: 0.439669\n",
      "epoch 32; iter: 0; batch classifier loss: 0.255470; batch adversarial loss: 0.470842\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244009; batch adversarial loss: 0.502545\n",
      "epoch 34; iter: 0; batch classifier loss: 0.227902; batch adversarial loss: 0.477130\n",
      "epoch 35; iter: 0; batch classifier loss: 0.205121; batch adversarial loss: 0.448183\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263883; batch adversarial loss: 0.441981\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185045; batch adversarial loss: 0.441261\n",
      "epoch 38; iter: 0; batch classifier loss: 0.260661; batch adversarial loss: 0.433276\n",
      "epoch 39; iter: 0; batch classifier loss: 0.323064; batch adversarial loss: 0.396213\n",
      "epoch 40; iter: 0; batch classifier loss: 0.331000; batch adversarial loss: 0.537170\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293011; batch adversarial loss: 0.431561\n",
      "epoch 42; iter: 0; batch classifier loss: 0.227778; batch adversarial loss: 0.458506\n",
      "epoch 43; iter: 0; batch classifier loss: 0.189009; batch adversarial loss: 0.502802\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383628; batch adversarial loss: 0.449016\n",
      "epoch 45; iter: 0; batch classifier loss: 0.203676; batch adversarial loss: 0.385055\n",
      "epoch 46; iter: 0; batch classifier loss: 0.187360; batch adversarial loss: 0.553958\n",
      "epoch 47; iter: 0; batch classifier loss: 0.225857; batch adversarial loss: 0.393922\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228167; batch adversarial loss: 0.469597\n",
      "epoch 49; iter: 0; batch classifier loss: 0.153471; batch adversarial loss: 0.446220\n",
      "epoch 50; iter: 0; batch classifier loss: 0.237976; batch adversarial loss: 0.467966\n",
      "epoch 51; iter: 0; batch classifier loss: 0.193444; batch adversarial loss: 0.460085\n",
      "epoch 52; iter: 0; batch classifier loss: 0.232817; batch adversarial loss: 0.313518\n",
      "epoch 53; iter: 0; batch classifier loss: 0.216453; batch adversarial loss: 0.488853\n",
      "epoch 54; iter: 0; batch classifier loss: 0.219361; batch adversarial loss: 0.373343\n",
      "epoch 55; iter: 0; batch classifier loss: 0.208163; batch adversarial loss: 0.455980\n",
      "epoch 56; iter: 0; batch classifier loss: 0.226410; batch adversarial loss: 0.386749\n",
      "epoch 57; iter: 0; batch classifier loss: 0.209682; batch adversarial loss: 0.459636\n",
      "epoch 58; iter: 0; batch classifier loss: 0.219575; batch adversarial loss: 0.397512\n",
      "epoch 59; iter: 0; batch classifier loss: 0.194788; batch adversarial loss: 0.433835\n",
      "epoch 60; iter: 0; batch classifier loss: 0.207073; batch adversarial loss: 0.470999\n",
      "epoch 61; iter: 0; batch classifier loss: 0.183189; batch adversarial loss: 0.421080\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216844; batch adversarial loss: 0.434429\n",
      "epoch 63; iter: 0; batch classifier loss: 0.198701; batch adversarial loss: 0.521667\n",
      "epoch 64; iter: 0; batch classifier loss: 0.224480; batch adversarial loss: 0.471857\n",
      "epoch 65; iter: 0; batch classifier loss: 0.275039; batch adversarial loss: 0.446405\n",
      "epoch 66; iter: 0; batch classifier loss: 0.253005; batch adversarial loss: 0.409150\n",
      "epoch 67; iter: 0; batch classifier loss: 0.289454; batch adversarial loss: 0.458588\n",
      "epoch 68; iter: 0; batch classifier loss: 0.168378; batch adversarial loss: 0.484580\n",
      "epoch 69; iter: 0; batch classifier loss: 0.157737; batch adversarial loss: 0.422213\n",
      "epoch 70; iter: 0; batch classifier loss: 0.103125; batch adversarial loss: 0.457715\n",
      "epoch 71; iter: 0; batch classifier loss: 0.087938; batch adversarial loss: 0.421044\n",
      "epoch 72; iter: 0; batch classifier loss: 0.108032; batch adversarial loss: 0.395651\n",
      "epoch 73; iter: 0; batch classifier loss: 0.058551; batch adversarial loss: 0.434923\n",
      "epoch 74; iter: 0; batch classifier loss: 0.122897; batch adversarial loss: 0.432199\n",
      "epoch 75; iter: 0; batch classifier loss: 0.145801; batch adversarial loss: 0.485335\n",
      "epoch 76; iter: 0; batch classifier loss: 0.150182; batch adversarial loss: 0.509675\n",
      "epoch 77; iter: 0; batch classifier loss: 0.181739; batch adversarial loss: 0.423389\n",
      "epoch 78; iter: 0; batch classifier loss: 0.265685; batch adversarial loss: 0.447221\n",
      "epoch 79; iter: 0; batch classifier loss: 0.120674; batch adversarial loss: 0.497279\n",
      "epoch 80; iter: 0; batch classifier loss: 0.166054; batch adversarial loss: 0.396523\n",
      "epoch 81; iter: 0; batch classifier loss: 0.198790; batch adversarial loss: 0.420274\n",
      "epoch 82; iter: 0; batch classifier loss: 0.196675; batch adversarial loss: 0.446458\n",
      "epoch 83; iter: 0; batch classifier loss: 0.254610; batch adversarial loss: 0.420897\n",
      "epoch 84; iter: 0; batch classifier loss: 0.114531; batch adversarial loss: 0.509132\n",
      "epoch 85; iter: 0; batch classifier loss: 0.157269; batch adversarial loss: 0.434657\n",
      "epoch 86; iter: 0; batch classifier loss: 0.292061; batch adversarial loss: 0.320002\n",
      "epoch 87; iter: 0; batch classifier loss: 0.182625; batch adversarial loss: 0.433625\n",
      "epoch 88; iter: 0; batch classifier loss: 0.221869; batch adversarial loss: 0.357862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89; iter: 0; batch classifier loss: 0.081332; batch adversarial loss: 0.432916\n",
      "epoch 90; iter: 0; batch classifier loss: 0.053174; batch adversarial loss: 0.432520\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055179; batch adversarial loss: 0.442254\n",
      "epoch 92; iter: 0; batch classifier loss: 0.053653; batch adversarial loss: 0.526685\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077396; batch adversarial loss: 0.427661\n",
      "epoch 94; iter: 0; batch classifier loss: 0.064191; batch adversarial loss: 0.548028\n",
      "epoch 95; iter: 0; batch classifier loss: 0.028445; batch adversarial loss: 0.504088\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053646; batch adversarial loss: 0.417072\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049058; batch adversarial loss: 0.491328\n",
      "epoch 98; iter: 0; batch classifier loss: 0.056198; batch adversarial loss: 0.407840\n",
      "epoch 99; iter: 0; batch classifier loss: 0.028800; batch adversarial loss: 0.457458\n",
      "epoch 100; iter: 0; batch classifier loss: 0.037320; batch adversarial loss: 0.403473\n",
      "epoch 101; iter: 0; batch classifier loss: 0.026834; batch adversarial loss: 0.358792\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049717; batch adversarial loss: 0.396999\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023311; batch adversarial loss: 0.442641\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084475; batch adversarial loss: 0.410744\n",
      "epoch 105; iter: 0; batch classifier loss: 0.025549; batch adversarial loss: 0.430696\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037551; batch adversarial loss: 0.442539\n",
      "epoch 107; iter: 0; batch classifier loss: 0.037818; batch adversarial loss: 0.401274\n",
      "epoch 108; iter: 0; batch classifier loss: 0.027521; batch adversarial loss: 0.431978\n",
      "epoch 109; iter: 0; batch classifier loss: 0.027177; batch adversarial loss: 0.411106\n",
      "epoch 110; iter: 0; batch classifier loss: 0.034732; batch adversarial loss: 0.461220\n",
      "epoch 111; iter: 0; batch classifier loss: 0.087106; batch adversarial loss: 0.383598\n",
      "epoch 112; iter: 0; batch classifier loss: 0.024414; batch adversarial loss: 0.447215\n",
      "epoch 113; iter: 0; batch classifier loss: 0.028085; batch adversarial loss: 0.479488\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025675; batch adversarial loss: 0.418777\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020022; batch adversarial loss: 0.422630\n",
      "epoch 116; iter: 0; batch classifier loss: 0.023598; batch adversarial loss: 0.497259\n",
      "epoch 117; iter: 0; batch classifier loss: 0.022707; batch adversarial loss: 0.442032\n",
      "epoch 118; iter: 0; batch classifier loss: 0.090597; batch adversarial loss: 0.456813\n",
      "epoch 119; iter: 0; batch classifier loss: 0.035732; batch adversarial loss: 0.436059\n",
      "epoch 120; iter: 0; batch classifier loss: 0.024482; batch adversarial loss: 0.427088\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018406; batch adversarial loss: 0.424371\n",
      "epoch 122; iter: 0; batch classifier loss: 0.032550; batch adversarial loss: 0.476958\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044159; batch adversarial loss: 0.426589\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051601; batch adversarial loss: 0.409128\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027312; batch adversarial loss: 0.409117\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036320; batch adversarial loss: 0.439176\n",
      "epoch 127; iter: 0; batch classifier loss: 0.049682; batch adversarial loss: 0.429022\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026871; batch adversarial loss: 0.336517\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031871; batch adversarial loss: 0.552121\n",
      "epoch 130; iter: 0; batch classifier loss: 0.054219; batch adversarial loss: 0.318798\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019558; batch adversarial loss: 0.499441\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062185; batch adversarial loss: 0.449574\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034672; batch adversarial loss: 0.474400\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031483; batch adversarial loss: 0.394542\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029516; batch adversarial loss: 0.423430\n",
      "epoch 136; iter: 0; batch classifier loss: 0.025475; batch adversarial loss: 0.447983\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031240; batch adversarial loss: 0.559717\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085588; batch adversarial loss: 0.353814\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025287; batch adversarial loss: 0.357000\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038049; batch adversarial loss: 0.499805\n",
      "epoch 141; iter: 0; batch classifier loss: 0.033014; batch adversarial loss: 0.359499\n",
      "epoch 142; iter: 0; batch classifier loss: 0.039173; batch adversarial loss: 0.445180\n",
      "epoch 143; iter: 0; batch classifier loss: 0.016695; batch adversarial loss: 0.426248\n",
      "epoch 144; iter: 0; batch classifier loss: 0.062180; batch adversarial loss: 0.355436\n",
      "epoch 145; iter: 0; batch classifier loss: 0.035546; batch adversarial loss: 0.525806\n",
      "epoch 146; iter: 0; batch classifier loss: 0.028042; batch adversarial loss: 0.544165\n",
      "epoch 147; iter: 0; batch classifier loss: 0.012915; batch adversarial loss: 0.368597\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034872; batch adversarial loss: 0.452722\n",
      "epoch 149; iter: 0; batch classifier loss: 0.030594; batch adversarial loss: 0.388371\n",
      "epoch 150; iter: 0; batch classifier loss: 0.047305; batch adversarial loss: 0.266274\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037013; batch adversarial loss: 0.421474\n",
      "epoch 152; iter: 0; batch classifier loss: 0.062429; batch adversarial loss: 0.398314\n",
      "epoch 153; iter: 0; batch classifier loss: 0.034614; batch adversarial loss: 0.436662\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038622; batch adversarial loss: 0.414157\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057269; batch adversarial loss: 0.387190\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050586; batch adversarial loss: 0.414756\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034043; batch adversarial loss: 0.457455\n",
      "epoch 158; iter: 0; batch classifier loss: 0.054419; batch adversarial loss: 0.462581\n",
      "epoch 159; iter: 0; batch classifier loss: 0.041831; batch adversarial loss: 0.465965\n",
      "epoch 160; iter: 0; batch classifier loss: 0.043146; batch adversarial loss: 0.447590\n",
      "epoch 161; iter: 0; batch classifier loss: 0.050127; batch adversarial loss: 0.446297\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031733; batch adversarial loss: 0.367814\n",
      "epoch 163; iter: 0; batch classifier loss: 0.050427; batch adversarial loss: 0.453111\n",
      "epoch 164; iter: 0; batch classifier loss: 0.043733; batch adversarial loss: 0.300505\n",
      "epoch 165; iter: 0; batch classifier loss: 0.062992; batch adversarial loss: 0.415627\n",
      "epoch 166; iter: 0; batch classifier loss: 0.046423; batch adversarial loss: 0.414731\n",
      "epoch 167; iter: 0; batch classifier loss: 0.038407; batch adversarial loss: 0.406367\n",
      "epoch 168; iter: 0; batch classifier loss: 0.048243; batch adversarial loss: 0.404104\n",
      "epoch 169; iter: 0; batch classifier loss: 0.046296; batch adversarial loss: 0.366170\n",
      "epoch 170; iter: 0; batch classifier loss: 0.050513; batch adversarial loss: 0.453822\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025787; batch adversarial loss: 0.397578\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026587; batch adversarial loss: 0.444496\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034944; batch adversarial loss: 0.423129\n",
      "epoch 174; iter: 0; batch classifier loss: 0.072008; batch adversarial loss: 0.362610\n",
      "epoch 175; iter: 0; batch classifier loss: 0.041015; batch adversarial loss: 0.409023\n",
      "epoch 176; iter: 0; batch classifier loss: 0.074258; batch adversarial loss: 0.401701\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025880; batch adversarial loss: 0.400804\n",
      "epoch 178; iter: 0; batch classifier loss: 0.078446; batch adversarial loss: 0.351377\n",
      "epoch 179; iter: 0; batch classifier loss: 0.066007; batch adversarial loss: 0.457037\n",
      "epoch 180; iter: 0; batch classifier loss: 0.038677; batch adversarial loss: 0.441120\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042508; batch adversarial loss: 0.366854\n",
      "epoch 182; iter: 0; batch classifier loss: 0.047489; batch adversarial loss: 0.359877\n",
      "epoch 183; iter: 0; batch classifier loss: 0.058950; batch adversarial loss: 0.403184\n",
      "epoch 184; iter: 0; batch classifier loss: 0.044760; batch adversarial loss: 0.458116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 185; iter: 0; batch classifier loss: 0.041758; batch adversarial loss: 0.432965\n",
      "epoch 186; iter: 0; batch classifier loss: 0.065787; batch adversarial loss: 0.404203\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039862; batch adversarial loss: 0.378268\n",
      "epoch 188; iter: 0; batch classifier loss: 0.031410; batch adversarial loss: 0.399021\n",
      "epoch 189; iter: 0; batch classifier loss: 0.036533; batch adversarial loss: 0.371057\n",
      "epoch 190; iter: 0; batch classifier loss: 0.069161; batch adversarial loss: 0.458550\n",
      "epoch 191; iter: 0; batch classifier loss: 0.076619; batch adversarial loss: 0.434198\n",
      "epoch 192; iter: 0; batch classifier loss: 0.040452; batch adversarial loss: 0.380241\n",
      "epoch 193; iter: 0; batch classifier loss: 0.084144; batch adversarial loss: 0.501202\n",
      "epoch 194; iter: 0; batch classifier loss: 0.039251; batch adversarial loss: 0.470579\n",
      "epoch 195; iter: 0; batch classifier loss: 0.029033; batch adversarial loss: 0.357209\n",
      "epoch 196; iter: 0; batch classifier loss: 0.026759; batch adversarial loss: 0.372514\n",
      "epoch 197; iter: 0; batch classifier loss: 0.028350; batch adversarial loss: 0.441371\n",
      "epoch 198; iter: 0; batch classifier loss: 0.068381; batch adversarial loss: 0.532315\n",
      "epoch 199; iter: 0; batch classifier loss: 0.062277; batch adversarial loss: 0.448150\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693967; batch adversarial loss: 0.684514\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442845; batch adversarial loss: 0.655834\n",
      "epoch 2; iter: 0; batch classifier loss: 0.418377; batch adversarial loss: 0.641771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399863; batch adversarial loss: 0.575760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.336087; batch adversarial loss: 0.538626\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308499; batch adversarial loss: 0.558098\n",
      "epoch 6; iter: 0; batch classifier loss: 0.349134; batch adversarial loss: 0.526254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.279592; batch adversarial loss: 0.491256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271383; batch adversarial loss: 0.507626\n",
      "epoch 9; iter: 0; batch classifier loss: 0.280050; batch adversarial loss: 0.491643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.162331; batch adversarial loss: 0.502529\n",
      "epoch 11; iter: 0; batch classifier loss: 0.201408; batch adversarial loss: 0.448222\n",
      "epoch 12; iter: 0; batch classifier loss: 0.168538; batch adversarial loss: 0.486299\n",
      "epoch 13; iter: 0; batch classifier loss: 0.196866; batch adversarial loss: 0.414447\n",
      "epoch 14; iter: 0; batch classifier loss: 0.225434; batch adversarial loss: 0.424172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212675; batch adversarial loss: 0.522480\n",
      "epoch 16; iter: 0; batch classifier loss: 0.211913; batch adversarial loss: 0.453074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.199903; batch adversarial loss: 0.502149\n",
      "epoch 18; iter: 0; batch classifier loss: 0.160491; batch adversarial loss: 0.382483\n",
      "epoch 19; iter: 0; batch classifier loss: 0.185490; batch adversarial loss: 0.484221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.130974; batch adversarial loss: 0.482885\n",
      "epoch 21; iter: 0; batch classifier loss: 0.240325; batch adversarial loss: 0.446244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.135923; batch adversarial loss: 0.375324\n",
      "epoch 23; iter: 0; batch classifier loss: 0.138069; batch adversarial loss: 0.380576\n",
      "epoch 24; iter: 0; batch classifier loss: 0.160838; batch adversarial loss: 0.401461\n",
      "epoch 25; iter: 0; batch classifier loss: 0.201672; batch adversarial loss: 0.449277\n",
      "epoch 26; iter: 0; batch classifier loss: 0.175514; batch adversarial loss: 0.480535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.138288; batch adversarial loss: 0.459880\n",
      "epoch 28; iter: 0; batch classifier loss: 0.167012; batch adversarial loss: 0.364423\n",
      "epoch 29; iter: 0; batch classifier loss: 0.168471; batch adversarial loss: 0.403612\n",
      "epoch 30; iter: 0; batch classifier loss: 0.165381; batch adversarial loss: 0.377010\n",
      "epoch 31; iter: 0; batch classifier loss: 0.148143; batch adversarial loss: 0.356771\n",
      "epoch 32; iter: 0; batch classifier loss: 0.174468; batch adversarial loss: 0.431620\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164988; batch adversarial loss: 0.486093\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149811; batch adversarial loss: 0.470048\n",
      "epoch 35; iter: 0; batch classifier loss: 0.160876; batch adversarial loss: 0.384613\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165005; batch adversarial loss: 0.537340\n",
      "epoch 37; iter: 0; batch classifier loss: 0.121380; batch adversarial loss: 0.342629\n",
      "epoch 38; iter: 0; batch classifier loss: 0.181234; batch adversarial loss: 0.381715\n",
      "epoch 39; iter: 0; batch classifier loss: 0.136635; batch adversarial loss: 0.443049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115309; batch adversarial loss: 0.335138\n",
      "epoch 41; iter: 0; batch classifier loss: 0.174760; batch adversarial loss: 0.396773\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088676; batch adversarial loss: 0.486309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.117182; batch adversarial loss: 0.386997\n",
      "epoch 44; iter: 0; batch classifier loss: 0.130647; batch adversarial loss: 0.370009\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103964; batch adversarial loss: 0.393105\n",
      "epoch 46; iter: 0; batch classifier loss: 0.088859; batch adversarial loss: 0.465663\n",
      "epoch 47; iter: 0; batch classifier loss: 0.111997; batch adversarial loss: 0.436068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126479; batch adversarial loss: 0.365626\n",
      "epoch 49; iter: 0; batch classifier loss: 0.118394; batch adversarial loss: 0.413675\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081798; batch adversarial loss: 0.477209\n",
      "epoch 51; iter: 0; batch classifier loss: 0.093344; batch adversarial loss: 0.411059\n",
      "epoch 52; iter: 0; batch classifier loss: 0.108510; batch adversarial loss: 0.384437\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070307; batch adversarial loss: 0.397952\n",
      "epoch 54; iter: 0; batch classifier loss: 0.070158; batch adversarial loss: 0.384160\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070142; batch adversarial loss: 0.405499\n",
      "epoch 56; iter: 0; batch classifier loss: 0.095155; batch adversarial loss: 0.452769\n",
      "epoch 57; iter: 0; batch classifier loss: 0.121355; batch adversarial loss: 0.425521\n",
      "epoch 58; iter: 0; batch classifier loss: 0.096265; batch adversarial loss: 0.410141\n",
      "epoch 59; iter: 0; batch classifier loss: 0.086957; batch adversarial loss: 0.535100\n",
      "epoch 60; iter: 0; batch classifier loss: 0.082058; batch adversarial loss: 0.478241\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087508; batch adversarial loss: 0.473729\n",
      "epoch 62; iter: 0; batch classifier loss: 0.098764; batch adversarial loss: 0.413556\n",
      "epoch 63; iter: 0; batch classifier loss: 0.080998; batch adversarial loss: 0.487095\n",
      "epoch 64; iter: 0; batch classifier loss: 0.103187; batch adversarial loss: 0.417419\n",
      "epoch 65; iter: 0; batch classifier loss: 0.044489; batch adversarial loss: 0.377951\n",
      "epoch 66; iter: 0; batch classifier loss: 0.106389; batch adversarial loss: 0.459778\n",
      "epoch 67; iter: 0; batch classifier loss: 0.057776; batch adversarial loss: 0.409391\n",
      "epoch 68; iter: 0; batch classifier loss: 0.044743; batch adversarial loss: 0.327829\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072055; batch adversarial loss: 0.415593\n",
      "epoch 70; iter: 0; batch classifier loss: 0.081017; batch adversarial loss: 0.412655\n",
      "epoch 71; iter: 0; batch classifier loss: 0.084476; batch adversarial loss: 0.424451\n",
      "epoch 72; iter: 0; batch classifier loss: 0.094245; batch adversarial loss: 0.418570\n",
      "epoch 73; iter: 0; batch classifier loss: 0.080784; batch adversarial loss: 0.424709\n",
      "epoch 74; iter: 0; batch classifier loss: 0.075216; batch adversarial loss: 0.408579\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100895; batch adversarial loss: 0.415893\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065155; batch adversarial loss: 0.485579\n",
      "epoch 77; iter: 0; batch classifier loss: 0.072886; batch adversarial loss: 0.446740\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079336; batch adversarial loss: 0.448988\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060552; batch adversarial loss: 0.425522\n",
      "epoch 80; iter: 0; batch classifier loss: 0.097364; batch adversarial loss: 0.451564\n",
      "epoch 81; iter: 0; batch classifier loss: 0.080837; batch adversarial loss: 0.369071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82; iter: 0; batch classifier loss: 0.061978; batch adversarial loss: 0.381051\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105783; batch adversarial loss: 0.426946\n",
      "epoch 84; iter: 0; batch classifier loss: 0.067151; batch adversarial loss: 0.446038\n",
      "epoch 85; iter: 0; batch classifier loss: 0.069205; batch adversarial loss: 0.433113\n",
      "epoch 86; iter: 0; batch classifier loss: 0.078551; batch adversarial loss: 0.464219\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059696; batch adversarial loss: 0.406158\n",
      "epoch 88; iter: 0; batch classifier loss: 0.053754; batch adversarial loss: 0.296956\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076592; batch adversarial loss: 0.436705\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073557; batch adversarial loss: 0.417921\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056300; batch adversarial loss: 0.430986\n",
      "epoch 92; iter: 0; batch classifier loss: 0.090743; batch adversarial loss: 0.474320\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051773; batch adversarial loss: 0.442362\n",
      "epoch 94; iter: 0; batch classifier loss: 0.066204; batch adversarial loss: 0.377435\n",
      "epoch 95; iter: 0; batch classifier loss: 0.040758; batch adversarial loss: 0.470926\n",
      "epoch 96; iter: 0; batch classifier loss: 0.063274; batch adversarial loss: 0.482676\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078226; batch adversarial loss: 0.408470\n",
      "epoch 98; iter: 0; batch classifier loss: 0.109414; batch adversarial loss: 0.359030\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067995; batch adversarial loss: 0.442259\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050977; batch adversarial loss: 0.377175\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041862; batch adversarial loss: 0.366923\n",
      "epoch 102; iter: 0; batch classifier loss: 0.056007; batch adversarial loss: 0.415376\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082834; batch adversarial loss: 0.429248\n",
      "epoch 104; iter: 0; batch classifier loss: 0.046240; batch adversarial loss: 0.431281\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052263; batch adversarial loss: 0.375099\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041595; batch adversarial loss: 0.447273\n",
      "epoch 107; iter: 0; batch classifier loss: 0.073409; batch adversarial loss: 0.366283\n",
      "epoch 108; iter: 0; batch classifier loss: 0.063966; batch adversarial loss: 0.441668\n",
      "epoch 109; iter: 0; batch classifier loss: 0.085239; batch adversarial loss: 0.356320\n",
      "epoch 110; iter: 0; batch classifier loss: 0.056718; batch adversarial loss: 0.447578\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029245; batch adversarial loss: 0.389245\n",
      "epoch 112; iter: 0; batch classifier loss: 0.075729; batch adversarial loss: 0.326553\n",
      "epoch 113; iter: 0; batch classifier loss: 0.033720; batch adversarial loss: 0.500866\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051406; batch adversarial loss: 0.415701\n",
      "epoch 115; iter: 0; batch classifier loss: 0.060999; batch adversarial loss: 0.490973\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036758; batch adversarial loss: 0.363919\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033160; batch adversarial loss: 0.522225\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049888; batch adversarial loss: 0.407308\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040552; batch adversarial loss: 0.498541\n",
      "epoch 120; iter: 0; batch classifier loss: 0.045675; batch adversarial loss: 0.461733\n",
      "epoch 121; iter: 0; batch classifier loss: 0.017375; batch adversarial loss: 0.488216\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013909; batch adversarial loss: 0.509569\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043882; batch adversarial loss: 0.544216\n",
      "epoch 124; iter: 0; batch classifier loss: 0.034025; batch adversarial loss: 0.478548\n",
      "epoch 125; iter: 0; batch classifier loss: 0.045617; batch adversarial loss: 0.408264\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028966; batch adversarial loss: 0.423383\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030552; batch adversarial loss: 0.479885\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047483; batch adversarial loss: 0.457326\n",
      "epoch 129; iter: 0; batch classifier loss: 0.072070; batch adversarial loss: 0.433236\n",
      "epoch 130; iter: 0; batch classifier loss: 0.136327; batch adversarial loss: 0.758515\n",
      "epoch 131; iter: 0; batch classifier loss: 0.118065; batch adversarial loss: 0.490309\n",
      "epoch 132; iter: 0; batch classifier loss: 0.062768; batch adversarial loss: 0.525132\n",
      "epoch 133; iter: 0; batch classifier loss: 0.083453; batch adversarial loss: 0.648519\n",
      "epoch 134; iter: 0; batch classifier loss: 0.096406; batch adversarial loss: 0.610246\n",
      "epoch 135; iter: 0; batch classifier loss: 0.154144; batch adversarial loss: 0.600080\n",
      "epoch 136; iter: 0; batch classifier loss: 0.174589; batch adversarial loss: 0.719636\n",
      "epoch 137; iter: 0; batch classifier loss: 0.152453; batch adversarial loss: 0.621560\n",
      "epoch 138; iter: 0; batch classifier loss: 0.138773; batch adversarial loss: 0.591323\n",
      "epoch 139; iter: 0; batch classifier loss: 0.086596; batch adversarial loss: 0.508187\n",
      "epoch 140; iter: 0; batch classifier loss: 0.179532; batch adversarial loss: 0.675638\n",
      "epoch 141; iter: 0; batch classifier loss: 0.176670; batch adversarial loss: 0.665403\n",
      "epoch 142; iter: 0; batch classifier loss: 0.142348; batch adversarial loss: 0.710576\n",
      "epoch 143; iter: 0; batch classifier loss: 0.127869; batch adversarial loss: 0.651937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.205633; batch adversarial loss: 0.715114\n",
      "epoch 145; iter: 0; batch classifier loss: 0.125515; batch adversarial loss: 0.518219\n",
      "epoch 146; iter: 0; batch classifier loss: 0.202189; batch adversarial loss: 0.644939\n",
      "epoch 147; iter: 0; batch classifier loss: 0.121500; batch adversarial loss: 0.439987\n",
      "epoch 148; iter: 0; batch classifier loss: 0.156151; batch adversarial loss: 0.512846\n",
      "epoch 149; iter: 0; batch classifier loss: 0.187473; batch adversarial loss: 0.670847\n",
      "epoch 150; iter: 0; batch classifier loss: 0.110568; batch adversarial loss: 0.503249\n",
      "epoch 151; iter: 0; batch classifier loss: 0.125161; batch adversarial loss: 0.613633\n",
      "epoch 152; iter: 0; batch classifier loss: 0.128792; batch adversarial loss: 0.534720\n",
      "epoch 153; iter: 0; batch classifier loss: 0.110123; batch adversarial loss: 0.468671\n",
      "epoch 154; iter: 0; batch classifier loss: 0.133846; batch adversarial loss: 0.570659\n",
      "epoch 155; iter: 0; batch classifier loss: 0.122422; batch adversarial loss: 0.602311\n",
      "epoch 156; iter: 0; batch classifier loss: 0.129539; batch adversarial loss: 0.540899\n",
      "epoch 157; iter: 0; batch classifier loss: 0.088353; batch adversarial loss: 0.460093\n",
      "epoch 158; iter: 0; batch classifier loss: 0.144575; batch adversarial loss: 0.541225\n",
      "epoch 159; iter: 0; batch classifier loss: 0.125272; batch adversarial loss: 0.440936\n",
      "epoch 160; iter: 0; batch classifier loss: 0.128300; batch adversarial loss: 0.500416\n",
      "epoch 161; iter: 0; batch classifier loss: 0.107020; batch adversarial loss: 0.434809\n",
      "epoch 162; iter: 0; batch classifier loss: 0.084406; batch adversarial loss: 0.544366\n",
      "epoch 163; iter: 0; batch classifier loss: 0.096808; batch adversarial loss: 0.526272\n",
      "epoch 164; iter: 0; batch classifier loss: 0.091975; batch adversarial loss: 0.422037\n",
      "epoch 165; iter: 0; batch classifier loss: 0.115805; batch adversarial loss: 0.512393\n",
      "epoch 166; iter: 0; batch classifier loss: 0.127874; batch adversarial loss: 0.552789\n",
      "epoch 167; iter: 0; batch classifier loss: 0.144986; batch adversarial loss: 0.567038\n",
      "epoch 168; iter: 0; batch classifier loss: 0.123715; batch adversarial loss: 0.468065\n",
      "epoch 169; iter: 0; batch classifier loss: 0.156470; batch adversarial loss: 0.506068\n",
      "epoch 170; iter: 0; batch classifier loss: 0.103573; batch adversarial loss: 0.480304\n",
      "epoch 171; iter: 0; batch classifier loss: 0.136516; batch adversarial loss: 0.467163\n",
      "epoch 172; iter: 0; batch classifier loss: 0.165122; batch adversarial loss: 0.479301\n",
      "epoch 173; iter: 0; batch classifier loss: 0.136772; batch adversarial loss: 0.431143\n",
      "epoch 174; iter: 0; batch classifier loss: 0.128469; batch adversarial loss: 0.470093\n",
      "epoch 175; iter: 0; batch classifier loss: 0.151898; batch adversarial loss: 0.453121\n",
      "epoch 176; iter: 0; batch classifier loss: 0.103522; batch adversarial loss: 0.469173\n",
      "epoch 177; iter: 0; batch classifier loss: 0.049851; batch adversarial loss: 0.395062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 178; iter: 0; batch classifier loss: 0.045822; batch adversarial loss: 0.546357\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039914; batch adversarial loss: 0.534268\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035223; batch adversarial loss: 0.563855\n",
      "epoch 181; iter: 0; batch classifier loss: 0.047770; batch adversarial loss: 0.478421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.043659; batch adversarial loss: 0.424374\n",
      "epoch 183; iter: 0; batch classifier loss: 0.031319; batch adversarial loss: 0.360069\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038109; batch adversarial loss: 0.513609\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037200; batch adversarial loss: 0.451689\n",
      "epoch 186; iter: 0; batch classifier loss: 0.069348; batch adversarial loss: 0.523641\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045324; batch adversarial loss: 0.435374\n",
      "epoch 188; iter: 0; batch classifier loss: 0.052942; batch adversarial loss: 0.380853\n",
      "epoch 189; iter: 0; batch classifier loss: 0.049680; batch adversarial loss: 0.439523\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050861; batch adversarial loss: 0.561391\n",
      "epoch 191; iter: 0; batch classifier loss: 0.062387; batch adversarial loss: 0.573264\n",
      "epoch 192; iter: 0; batch classifier loss: 0.074781; batch adversarial loss: 0.485699\n",
      "epoch 193; iter: 0; batch classifier loss: 0.031232; batch adversarial loss: 0.444114\n",
      "epoch 194; iter: 0; batch classifier loss: 0.050343; batch adversarial loss: 0.530076\n",
      "epoch 195; iter: 0; batch classifier loss: 0.101341; batch adversarial loss: 0.464142\n",
      "epoch 196; iter: 0; batch classifier loss: 0.057544; batch adversarial loss: 0.496409\n",
      "epoch 197; iter: 0; batch classifier loss: 0.051956; batch adversarial loss: 0.399313\n",
      "epoch 198; iter: 0; batch classifier loss: 0.095440; batch adversarial loss: 0.448829\n",
      "epoch 199; iter: 0; batch classifier loss: 0.168748; batch adversarial loss: 0.362239\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702487; batch adversarial loss: 0.567540\n",
      "epoch 1; iter: 0; batch classifier loss: 0.437175; batch adversarial loss: 0.652174\n",
      "epoch 2; iter: 0; batch classifier loss: 0.413638; batch adversarial loss: 0.582002\n",
      "epoch 3; iter: 0; batch classifier loss: 0.300277; batch adversarial loss: 0.574691\n",
      "epoch 4; iter: 0; batch classifier loss: 0.393207; batch adversarial loss: 0.559469\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331396; batch adversarial loss: 0.543597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.490046\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301226; batch adversarial loss: 0.496812\n",
      "epoch 8; iter: 0; batch classifier loss: 0.270515; batch adversarial loss: 0.511910\n",
      "epoch 9; iter: 0; batch classifier loss: 0.233006; batch adversarial loss: 0.506212\n",
      "epoch 10; iter: 0; batch classifier loss: 0.240078; batch adversarial loss: 0.501650\n",
      "epoch 11; iter: 0; batch classifier loss: 0.235535; batch adversarial loss: 0.473217\n",
      "epoch 12; iter: 0; batch classifier loss: 0.230679; batch adversarial loss: 0.464520\n",
      "epoch 13; iter: 0; batch classifier loss: 0.177190; batch adversarial loss: 0.494313\n",
      "epoch 14; iter: 0; batch classifier loss: 0.156644; batch adversarial loss: 0.446852\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280831; batch adversarial loss: 0.444732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.173787; batch adversarial loss: 0.556247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.160059; batch adversarial loss: 0.479211\n",
      "epoch 18; iter: 0; batch classifier loss: 0.172068; batch adversarial loss: 0.522850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.191436; batch adversarial loss: 0.515747\n",
      "epoch 20; iter: 0; batch classifier loss: 0.109012; batch adversarial loss: 0.457371\n",
      "epoch 21; iter: 0; batch classifier loss: 0.186729; batch adversarial loss: 0.510491\n",
      "epoch 22; iter: 0; batch classifier loss: 0.189672; batch adversarial loss: 0.568349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.213323; batch adversarial loss: 0.578107\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195198; batch adversarial loss: 0.548025\n",
      "epoch 25; iter: 0; batch classifier loss: 0.204528; batch adversarial loss: 0.599859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261617; batch adversarial loss: 0.515038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.200731; batch adversarial loss: 0.435054\n",
      "epoch 28; iter: 0; batch classifier loss: 0.213321; batch adversarial loss: 0.515264\n",
      "epoch 29; iter: 0; batch classifier loss: 0.241078; batch adversarial loss: 0.526027\n",
      "epoch 30; iter: 0; batch classifier loss: 0.176697; batch adversarial loss: 0.426017\n",
      "epoch 31; iter: 0; batch classifier loss: 0.186313; batch adversarial loss: 0.452259\n",
      "epoch 32; iter: 0; batch classifier loss: 0.167096; batch adversarial loss: 0.425914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.366235; batch adversarial loss: 0.415108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.185184; batch adversarial loss: 0.419301\n",
      "epoch 35; iter: 0; batch classifier loss: 0.127226; batch adversarial loss: 0.454542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.108105; batch adversarial loss: 0.544238\n",
      "epoch 37; iter: 0; batch classifier loss: 0.093373; batch adversarial loss: 0.479515\n",
      "epoch 38; iter: 0; batch classifier loss: 0.092775; batch adversarial loss: 0.504634\n",
      "epoch 39; iter: 0; batch classifier loss: 0.072093; batch adversarial loss: 0.442917\n",
      "epoch 40; iter: 0; batch classifier loss: 0.096069; batch adversarial loss: 0.492237\n",
      "epoch 41; iter: 0; batch classifier loss: 0.077162; batch adversarial loss: 0.415469\n",
      "epoch 42; iter: 0; batch classifier loss: 0.110793; batch adversarial loss: 0.434130\n",
      "epoch 43; iter: 0; batch classifier loss: 0.134927; batch adversarial loss: 0.428619\n",
      "epoch 44; iter: 0; batch classifier loss: 0.058137; batch adversarial loss: 0.387158\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121428; batch adversarial loss: 0.442326\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075201; batch adversarial loss: 0.386439\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092051; batch adversarial loss: 0.456054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.084504; batch adversarial loss: 0.396934\n",
      "epoch 49; iter: 0; batch classifier loss: 0.076648; batch adversarial loss: 0.468888\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065275; batch adversarial loss: 0.461873\n",
      "epoch 51; iter: 0; batch classifier loss: 0.077493; batch adversarial loss: 0.420608\n",
      "epoch 52; iter: 0; batch classifier loss: 0.071700; batch adversarial loss: 0.529782\n",
      "epoch 53; iter: 0; batch classifier loss: 0.087184; batch adversarial loss: 0.389091\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062940; batch adversarial loss: 0.468043\n",
      "epoch 55; iter: 0; batch classifier loss: 0.134027; batch adversarial loss: 0.405043\n",
      "epoch 56; iter: 0; batch classifier loss: 0.085645; batch adversarial loss: 0.467395\n",
      "epoch 57; iter: 0; batch classifier loss: 0.056307; batch adversarial loss: 0.497108\n",
      "epoch 58; iter: 0; batch classifier loss: 0.095259; batch adversarial loss: 0.444516\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091770; batch adversarial loss: 0.451119\n",
      "epoch 60; iter: 0; batch classifier loss: 0.052417; batch adversarial loss: 0.471601\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114765; batch adversarial loss: 0.477825\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057290; batch adversarial loss: 0.466791\n",
      "epoch 63; iter: 0; batch classifier loss: 0.055374; batch adversarial loss: 0.446436\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057153; batch adversarial loss: 0.468091\n",
      "epoch 65; iter: 0; batch classifier loss: 0.070590; batch adversarial loss: 0.485147\n",
      "epoch 66; iter: 0; batch classifier loss: 0.091433; batch adversarial loss: 0.517953\n",
      "epoch 67; iter: 0; batch classifier loss: 0.121120; batch adversarial loss: 0.468742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.092589; batch adversarial loss: 0.429638\n",
      "epoch 69; iter: 0; batch classifier loss: 0.095859; batch adversarial loss: 0.458240\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088595; batch adversarial loss: 0.518372\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080799; batch adversarial loss: 0.429478\n",
      "epoch 72; iter: 0; batch classifier loss: 0.048677; batch adversarial loss: 0.477722\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081706; batch adversarial loss: 0.472536\n",
      "epoch 74; iter: 0; batch classifier loss: 0.099817; batch adversarial loss: 0.419054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75; iter: 0; batch classifier loss: 0.078628; batch adversarial loss: 0.403310\n",
      "epoch 76; iter: 0; batch classifier loss: 0.069145; batch adversarial loss: 0.463776\n",
      "epoch 77; iter: 0; batch classifier loss: 0.134649; batch adversarial loss: 0.529931\n",
      "epoch 78; iter: 0; batch classifier loss: 0.043117; batch adversarial loss: 0.461175\n",
      "epoch 79; iter: 0; batch classifier loss: 0.064210; batch adversarial loss: 0.465378\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085453; batch adversarial loss: 0.461273\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074033; batch adversarial loss: 0.400326\n",
      "epoch 82; iter: 0; batch classifier loss: 0.066494; batch adversarial loss: 0.479454\n",
      "epoch 83; iter: 0; batch classifier loss: 0.097203; batch adversarial loss: 0.364189\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048607; batch adversarial loss: 0.495504\n",
      "epoch 85; iter: 0; batch classifier loss: 0.100962; batch adversarial loss: 0.575035\n",
      "epoch 86; iter: 0; batch classifier loss: 0.067149; batch adversarial loss: 0.454307\n",
      "epoch 87; iter: 0; batch classifier loss: 0.122772; batch adversarial loss: 0.484307\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051113; batch adversarial loss: 0.629140\n",
      "epoch 89; iter: 0; batch classifier loss: 0.074187; batch adversarial loss: 0.442048\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058495; batch adversarial loss: 0.556526\n",
      "epoch 91; iter: 0; batch classifier loss: 0.162306; batch adversarial loss: 0.449068\n",
      "epoch 92; iter: 0; batch classifier loss: 0.078600; batch adversarial loss: 0.381606\n",
      "epoch 93; iter: 0; batch classifier loss: 0.069706; batch adversarial loss: 0.449552\n",
      "epoch 94; iter: 0; batch classifier loss: 0.112554; batch adversarial loss: 0.449281\n",
      "epoch 95; iter: 0; batch classifier loss: 0.081678; batch adversarial loss: 0.484832\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060671; batch adversarial loss: 0.545775\n",
      "epoch 97; iter: 0; batch classifier loss: 0.111064; batch adversarial loss: 0.430239\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081427; batch adversarial loss: 0.526275\n",
      "epoch 99; iter: 0; batch classifier loss: 0.132640; batch adversarial loss: 0.432645\n",
      "epoch 100; iter: 0; batch classifier loss: 0.111993; batch adversarial loss: 0.433037\n",
      "epoch 101; iter: 0; batch classifier loss: 0.087836; batch adversarial loss: 0.504969\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071103; batch adversarial loss: 0.411431\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064917; batch adversarial loss: 0.485738\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095191; batch adversarial loss: 0.496475\n",
      "epoch 105; iter: 0; batch classifier loss: 0.099222; batch adversarial loss: 0.456704\n",
      "epoch 106; iter: 0; batch classifier loss: 0.062431; batch adversarial loss: 0.385880\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061465; batch adversarial loss: 0.487157\n",
      "epoch 108; iter: 0; batch classifier loss: 0.073269; batch adversarial loss: 0.422235\n",
      "epoch 109; iter: 0; batch classifier loss: 0.059692; batch adversarial loss: 0.411536\n",
      "epoch 110; iter: 0; batch classifier loss: 0.083860; batch adversarial loss: 0.480134\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028678; batch adversarial loss: 0.408258\n",
      "epoch 112; iter: 0; batch classifier loss: 0.052597; batch adversarial loss: 0.456641\n",
      "epoch 113; iter: 0; batch classifier loss: 0.081247; batch adversarial loss: 0.435754\n",
      "epoch 114; iter: 0; batch classifier loss: 0.068830; batch adversarial loss: 0.436305\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036510; batch adversarial loss: 0.467272\n",
      "epoch 116; iter: 0; batch classifier loss: 0.060954; batch adversarial loss: 0.387905\n",
      "epoch 117; iter: 0; batch classifier loss: 0.082039; batch adversarial loss: 0.376197\n",
      "epoch 118; iter: 0; batch classifier loss: 0.071421; batch adversarial loss: 0.410674\n",
      "epoch 119; iter: 0; batch classifier loss: 0.071187; batch adversarial loss: 0.390046\n",
      "epoch 120; iter: 0; batch classifier loss: 0.051090; batch adversarial loss: 0.449241\n",
      "epoch 121; iter: 0; batch classifier loss: 0.068840; batch adversarial loss: 0.446136\n",
      "epoch 122; iter: 0; batch classifier loss: 0.062098; batch adversarial loss: 0.457881\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043194; batch adversarial loss: 0.496002\n",
      "epoch 124; iter: 0; batch classifier loss: 0.037952; batch adversarial loss: 0.469380\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054097; batch adversarial loss: 0.473134\n",
      "epoch 126; iter: 0; batch classifier loss: 0.048411; batch adversarial loss: 0.430704\n",
      "epoch 127; iter: 0; batch classifier loss: 0.056260; batch adversarial loss: 0.469660\n",
      "epoch 128; iter: 0; batch classifier loss: 0.065141; batch adversarial loss: 0.496253\n",
      "epoch 129; iter: 0; batch classifier loss: 0.097217; batch adversarial loss: 0.532161\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049746; batch adversarial loss: 0.400888\n",
      "epoch 131; iter: 0; batch classifier loss: 0.038158; batch adversarial loss: 0.402251\n",
      "epoch 132; iter: 0; batch classifier loss: 0.035182; batch adversarial loss: 0.438419\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060938; batch adversarial loss: 0.483747\n",
      "epoch 134; iter: 0; batch classifier loss: 0.021767; batch adversarial loss: 0.507400\n",
      "epoch 135; iter: 0; batch classifier loss: 0.079181; batch adversarial loss: 0.326416\n",
      "epoch 136; iter: 0; batch classifier loss: 0.056447; batch adversarial loss: 0.508007\n",
      "epoch 137; iter: 0; batch classifier loss: 0.028283; batch adversarial loss: 0.427852\n",
      "epoch 138; iter: 0; batch classifier loss: 0.032168; batch adversarial loss: 0.446393\n",
      "epoch 139; iter: 0; batch classifier loss: 0.042120; batch adversarial loss: 0.451078\n",
      "epoch 140; iter: 0; batch classifier loss: 0.074733; batch adversarial loss: 0.417153\n",
      "epoch 141; iter: 0; batch classifier loss: 0.051861; batch adversarial loss: 0.464596\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035314; batch adversarial loss: 0.332635\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043708; batch adversarial loss: 0.453107\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039584; batch adversarial loss: 0.495136\n",
      "epoch 145; iter: 0; batch classifier loss: 0.032374; batch adversarial loss: 0.465419\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037225; batch adversarial loss: 0.455141\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031927; batch adversarial loss: 0.496231\n",
      "epoch 148; iter: 0; batch classifier loss: 0.027518; batch adversarial loss: 0.388414\n",
      "epoch 149; iter: 0; batch classifier loss: 0.009009; batch adversarial loss: 0.439285\n",
      "epoch 150; iter: 0; batch classifier loss: 0.039944; batch adversarial loss: 0.444738\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042357; batch adversarial loss: 0.388019\n",
      "epoch 152; iter: 0; batch classifier loss: 0.047748; batch adversarial loss: 0.465335\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036029; batch adversarial loss: 0.472532\n",
      "epoch 154; iter: 0; batch classifier loss: 0.026096; batch adversarial loss: 0.490686\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043642; batch adversarial loss: 0.483329\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037542; batch adversarial loss: 0.333436\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019208; batch adversarial loss: 0.424850\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028803; batch adversarial loss: 0.399303\n",
      "epoch 159; iter: 0; batch classifier loss: 0.016397; batch adversarial loss: 0.368681\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021815; batch adversarial loss: 0.398790\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029205; batch adversarial loss: 0.460411\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019146; batch adversarial loss: 0.483679\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027481; batch adversarial loss: 0.447191\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025429; batch adversarial loss: 0.438233\n",
      "epoch 165; iter: 0; batch classifier loss: 0.068750; batch adversarial loss: 0.470745\n",
      "epoch 166; iter: 0; batch classifier loss: 0.021059; batch adversarial loss: 0.480080\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039358; batch adversarial loss: 0.481876\n",
      "epoch 168; iter: 0; batch classifier loss: 0.050682; batch adversarial loss: 0.505844\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043726; batch adversarial loss: 0.573389\n",
      "epoch 170; iter: 0; batch classifier loss: 0.022131; batch adversarial loss: 0.472777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 171; iter: 0; batch classifier loss: 0.028491; batch adversarial loss: 0.417437\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020627; batch adversarial loss: 0.472088\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032812; batch adversarial loss: 0.525085\n",
      "epoch 174; iter: 0; batch classifier loss: 0.056506; batch adversarial loss: 0.472930\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029590; batch adversarial loss: 0.518670\n",
      "epoch 176; iter: 0; batch classifier loss: 0.042176; batch adversarial loss: 0.434500\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030527; batch adversarial loss: 0.346399\n",
      "epoch 178; iter: 0; batch classifier loss: 0.025656; batch adversarial loss: 0.491432\n",
      "epoch 179; iter: 0; batch classifier loss: 0.079481; batch adversarial loss: 0.490273\n",
      "epoch 180; iter: 0; batch classifier loss: 0.043798; batch adversarial loss: 0.466810\n",
      "epoch 181; iter: 0; batch classifier loss: 0.019794; batch adversarial loss: 0.408814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026580; batch adversarial loss: 0.369618\n",
      "epoch 183; iter: 0; batch classifier loss: 0.009590; batch adversarial loss: 0.445377\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029845; batch adversarial loss: 0.452769\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027616; batch adversarial loss: 0.467862\n",
      "epoch 186; iter: 0; batch classifier loss: 0.043092; batch adversarial loss: 0.427998\n",
      "epoch 187; iter: 0; batch classifier loss: 0.043893; batch adversarial loss: 0.473192\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014968; batch adversarial loss: 0.456845\n",
      "epoch 189; iter: 0; batch classifier loss: 0.050417; batch adversarial loss: 0.421493\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023341; batch adversarial loss: 0.329545\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018201; batch adversarial loss: 0.483914\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019505; batch adversarial loss: 0.430807\n",
      "epoch 193; iter: 0; batch classifier loss: 0.047521; batch adversarial loss: 0.464320\n",
      "epoch 194; iter: 0; batch classifier loss: 0.030453; batch adversarial loss: 0.400776\n",
      "epoch 195; iter: 0; batch classifier loss: 0.021743; batch adversarial loss: 0.372291\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029563; batch adversarial loss: 0.424986\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058622; batch adversarial loss: 0.353088\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019735; batch adversarial loss: 0.472843\n",
      "epoch 199; iter: 0; batch classifier loss: 0.027888; batch adversarial loss: 0.540654\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700293; batch adversarial loss: 0.581061\n",
      "epoch 1; iter: 0; batch classifier loss: 0.403183; batch adversarial loss: 0.620865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.368318; batch adversarial loss: 0.597003\n",
      "epoch 3; iter: 0; batch classifier loss: 0.431807; batch adversarial loss: 0.573268\n",
      "epoch 4; iter: 0; batch classifier loss: 0.276045; batch adversarial loss: 0.545410\n",
      "epoch 5; iter: 0; batch classifier loss: 0.349032; batch adversarial loss: 0.533893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.253225; batch adversarial loss: 0.510195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.306309; batch adversarial loss: 0.488799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.256886; batch adversarial loss: 0.531593\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306358; batch adversarial loss: 0.509622\n",
      "epoch 10; iter: 0; batch classifier loss: 0.247681; batch adversarial loss: 0.456716\n",
      "epoch 11; iter: 0; batch classifier loss: 0.209302; batch adversarial loss: 0.572792\n",
      "epoch 12; iter: 0; batch classifier loss: 0.238986; batch adversarial loss: 0.559007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.203363; batch adversarial loss: 0.496143\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230500; batch adversarial loss: 0.512713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.172235; batch adversarial loss: 0.466240\n",
      "epoch 16; iter: 0; batch classifier loss: 0.241699; batch adversarial loss: 0.503911\n",
      "epoch 17; iter: 0; batch classifier loss: 0.209713; batch adversarial loss: 0.500379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.183119; batch adversarial loss: 0.470765\n",
      "epoch 19; iter: 0; batch classifier loss: 0.243323; batch adversarial loss: 0.498498\n",
      "epoch 20; iter: 0; batch classifier loss: 0.159821; batch adversarial loss: 0.478185\n",
      "epoch 21; iter: 0; batch classifier loss: 0.176425; batch adversarial loss: 0.423493\n",
      "epoch 22; iter: 0; batch classifier loss: 0.234792; batch adversarial loss: 0.530239\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240526; batch adversarial loss: 0.551041\n",
      "epoch 24; iter: 0; batch classifier loss: 0.129379; batch adversarial loss: 0.501233\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200308; batch adversarial loss: 0.488669\n",
      "epoch 26; iter: 0; batch classifier loss: 0.228242; batch adversarial loss: 0.503972\n",
      "epoch 27; iter: 0; batch classifier loss: 0.170641; batch adversarial loss: 0.476905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.242139; batch adversarial loss: 0.494030\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210480; batch adversarial loss: 0.471289\n",
      "epoch 30; iter: 0; batch classifier loss: 0.317634; batch adversarial loss: 0.540689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.249471; batch adversarial loss: 0.451188\n",
      "epoch 32; iter: 0; batch classifier loss: 0.342252; batch adversarial loss: 0.378563\n",
      "epoch 33; iter: 0; batch classifier loss: 0.121783; batch adversarial loss: 0.488723\n",
      "epoch 34; iter: 0; batch classifier loss: 0.149700; batch adversarial loss: 0.597601\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130675; batch adversarial loss: 0.521796\n",
      "epoch 36; iter: 0; batch classifier loss: 0.114447; batch adversarial loss: 0.396276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.111894; batch adversarial loss: 0.421039\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107600; batch adversarial loss: 0.424541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.105145; batch adversarial loss: 0.428925\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080194; batch adversarial loss: 0.563978\n",
      "epoch 41; iter: 0; batch classifier loss: 0.102785; batch adversarial loss: 0.471401\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088112; batch adversarial loss: 0.379229\n",
      "epoch 43; iter: 0; batch classifier loss: 0.066612; batch adversarial loss: 0.574815\n",
      "epoch 44; iter: 0; batch classifier loss: 0.070259; batch adversarial loss: 0.468176\n",
      "epoch 45; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.588588\n",
      "epoch 46; iter: 0; batch classifier loss: 0.090570; batch adversarial loss: 0.386740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.106058; batch adversarial loss: 0.434061\n",
      "epoch 48; iter: 0; batch classifier loss: 0.053613; batch adversarial loss: 0.475279\n",
      "epoch 49; iter: 0; batch classifier loss: 0.047844; batch adversarial loss: 0.513035\n",
      "epoch 50; iter: 0; batch classifier loss: 0.083160; batch adversarial loss: 0.511595\n",
      "epoch 51; iter: 0; batch classifier loss: 0.076813; batch adversarial loss: 0.535953\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099384; batch adversarial loss: 0.474464\n",
      "epoch 53; iter: 0; batch classifier loss: 0.121721; batch adversarial loss: 0.451315\n",
      "epoch 54; iter: 0; batch classifier loss: 0.081172; batch adversarial loss: 0.504915\n",
      "epoch 55; iter: 0; batch classifier loss: 0.125256; batch adversarial loss: 0.408646\n",
      "epoch 56; iter: 0; batch classifier loss: 0.035161; batch adversarial loss: 0.452991\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123581; batch adversarial loss: 0.448132\n",
      "epoch 58; iter: 0; batch classifier loss: 0.066124; batch adversarial loss: 0.376252\n",
      "epoch 59; iter: 0; batch classifier loss: 0.059268; batch adversarial loss: 0.430989\n",
      "epoch 60; iter: 0; batch classifier loss: 0.047289; batch adversarial loss: 0.430418\n",
      "epoch 61; iter: 0; batch classifier loss: 0.044448; batch adversarial loss: 0.431373\n",
      "epoch 62; iter: 0; batch classifier loss: 0.064538; batch adversarial loss: 0.502405\n",
      "epoch 63; iter: 0; batch classifier loss: 0.034994; batch adversarial loss: 0.447517\n",
      "epoch 64; iter: 0; batch classifier loss: 0.082694; batch adversarial loss: 0.521879\n",
      "epoch 65; iter: 0; batch classifier loss: 0.044613; batch adversarial loss: 0.499194\n",
      "epoch 66; iter: 0; batch classifier loss: 0.052383; batch adversarial loss: 0.387718\n",
      "epoch 67; iter: 0; batch classifier loss: 0.040785; batch adversarial loss: 0.491594\n",
      "epoch 68; iter: 0; batch classifier loss: 0.081074; batch adversarial loss: 0.438743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69; iter: 0; batch classifier loss: 0.095196; batch adversarial loss: 0.459567\n",
      "epoch 70; iter: 0; batch classifier loss: 0.074259; batch adversarial loss: 0.529041\n",
      "epoch 71; iter: 0; batch classifier loss: 0.080094; batch adversarial loss: 0.468338\n",
      "epoch 72; iter: 0; batch classifier loss: 0.109541; batch adversarial loss: 0.413557\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098889; batch adversarial loss: 0.457746\n",
      "epoch 74; iter: 0; batch classifier loss: 0.077155; batch adversarial loss: 0.437605\n",
      "epoch 75; iter: 0; batch classifier loss: 0.050644; batch adversarial loss: 0.424739\n",
      "epoch 76; iter: 0; batch classifier loss: 0.086181; batch adversarial loss: 0.503274\n",
      "epoch 77; iter: 0; batch classifier loss: 0.071601; batch adversarial loss: 0.401628\n",
      "epoch 78; iter: 0; batch classifier loss: 0.089446; batch adversarial loss: 0.467182\n",
      "epoch 79; iter: 0; batch classifier loss: 0.062962; batch adversarial loss: 0.461603\n",
      "epoch 80; iter: 0; batch classifier loss: 0.106669; batch adversarial loss: 0.513167\n",
      "epoch 81; iter: 0; batch classifier loss: 0.047026; batch adversarial loss: 0.467410\n",
      "epoch 82; iter: 0; batch classifier loss: 0.043018; batch adversarial loss: 0.573751\n",
      "epoch 83; iter: 0; batch classifier loss: 0.088768; batch adversarial loss: 0.395789\n",
      "epoch 84; iter: 0; batch classifier loss: 0.029866; batch adversarial loss: 0.560198\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071291; batch adversarial loss: 0.399580\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076571; batch adversarial loss: 0.449945\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062413; batch adversarial loss: 0.465290\n",
      "epoch 88; iter: 0; batch classifier loss: 0.086383; batch adversarial loss: 0.401268\n",
      "epoch 89; iter: 0; batch classifier loss: 0.020151; batch adversarial loss: 0.423595\n",
      "epoch 90; iter: 0; batch classifier loss: 0.055273; batch adversarial loss: 0.381201\n",
      "epoch 91; iter: 0; batch classifier loss: 0.067039; batch adversarial loss: 0.447537\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070818; batch adversarial loss: 0.415992\n",
      "epoch 93; iter: 0; batch classifier loss: 0.026002; batch adversarial loss: 0.441056\n",
      "epoch 94; iter: 0; batch classifier loss: 0.096779; batch adversarial loss: 0.504530\n",
      "epoch 95; iter: 0; batch classifier loss: 0.069789; batch adversarial loss: 0.405447\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062456; batch adversarial loss: 0.511072\n",
      "epoch 97; iter: 0; batch classifier loss: 0.085340; batch adversarial loss: 0.468912\n",
      "epoch 98; iter: 0; batch classifier loss: 0.076518; batch adversarial loss: 0.461729\n",
      "epoch 99; iter: 0; batch classifier loss: 0.033237; batch adversarial loss: 0.352965\n",
      "epoch 100; iter: 0; batch classifier loss: 0.064231; batch adversarial loss: 0.444274\n",
      "epoch 101; iter: 0; batch classifier loss: 0.082420; batch adversarial loss: 0.463933\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058127; batch adversarial loss: 0.400063\n",
      "epoch 103; iter: 0; batch classifier loss: 0.137959; batch adversarial loss: 0.404606\n",
      "epoch 104; iter: 0; batch classifier loss: 0.050651; batch adversarial loss: 0.459190\n",
      "epoch 105; iter: 0; batch classifier loss: 0.087524; batch adversarial loss: 0.417063\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067289; batch adversarial loss: 0.468920\n",
      "epoch 107; iter: 0; batch classifier loss: 0.028080; batch adversarial loss: 0.655672\n",
      "epoch 108; iter: 0; batch classifier loss: 0.049583; batch adversarial loss: 0.510487\n",
      "epoch 109; iter: 0; batch classifier loss: 0.061578; batch adversarial loss: 0.418848\n",
      "epoch 110; iter: 0; batch classifier loss: 0.062247; batch adversarial loss: 0.432257\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040950; batch adversarial loss: 0.492628\n",
      "epoch 112; iter: 0; batch classifier loss: 0.042001; batch adversarial loss: 0.481156\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054914; batch adversarial loss: 0.429799\n",
      "epoch 114; iter: 0; batch classifier loss: 0.015726; batch adversarial loss: 0.357083\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063430; batch adversarial loss: 0.414943\n",
      "epoch 116; iter: 0; batch classifier loss: 0.059545; batch adversarial loss: 0.449026\n",
      "epoch 117; iter: 0; batch classifier loss: 0.048542; batch adversarial loss: 0.354509\n",
      "epoch 118; iter: 0; batch classifier loss: 0.093344; batch adversarial loss: 0.443789\n",
      "epoch 119; iter: 0; batch classifier loss: 0.063385; batch adversarial loss: 0.442734\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028970; batch adversarial loss: 0.361084\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040149; batch adversarial loss: 0.408603\n",
      "epoch 122; iter: 0; batch classifier loss: 0.061145; batch adversarial loss: 0.434596\n",
      "epoch 123; iter: 0; batch classifier loss: 0.029885; batch adversarial loss: 0.410180\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031192; batch adversarial loss: 0.403324\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020548; batch adversarial loss: 0.503511\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050767; batch adversarial loss: 0.455665\n",
      "epoch 127; iter: 0; batch classifier loss: 0.014758; batch adversarial loss: 0.472229\n",
      "epoch 128; iter: 0; batch classifier loss: 0.039026; batch adversarial loss: 0.369140\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033460; batch adversarial loss: 0.473240\n",
      "epoch 130; iter: 0; batch classifier loss: 0.042100; batch adversarial loss: 0.458550\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043927; batch adversarial loss: 0.337247\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030530; batch adversarial loss: 0.483855\n",
      "epoch 133; iter: 0; batch classifier loss: 0.034548; batch adversarial loss: 0.509417\n",
      "epoch 134; iter: 0; batch classifier loss: 0.061049; batch adversarial loss: 0.478250\n",
      "epoch 135; iter: 0; batch classifier loss: 0.033837; batch adversarial loss: 0.445803\n",
      "epoch 136; iter: 0; batch classifier loss: 0.043816; batch adversarial loss: 0.507697\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036621; batch adversarial loss: 0.432526\n",
      "epoch 138; iter: 0; batch classifier loss: 0.070411; batch adversarial loss: 0.489575\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049064; batch adversarial loss: 0.392933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.039251; batch adversarial loss: 0.467647\n",
      "epoch 141; iter: 0; batch classifier loss: 0.058121; batch adversarial loss: 0.382032\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031665; batch adversarial loss: 0.448485\n",
      "epoch 143; iter: 0; batch classifier loss: 0.064973; batch adversarial loss: 0.460002\n",
      "epoch 144; iter: 0; batch classifier loss: 0.048278; batch adversarial loss: 0.488214\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028767; batch adversarial loss: 0.415612\n",
      "epoch 146; iter: 0; batch classifier loss: 0.018192; batch adversarial loss: 0.396715\n",
      "epoch 147; iter: 0; batch classifier loss: 0.011333; batch adversarial loss: 0.422668\n",
      "epoch 148; iter: 0; batch classifier loss: 0.026117; batch adversarial loss: 0.452552\n",
      "epoch 149; iter: 0; batch classifier loss: 0.023415; batch adversarial loss: 0.392603\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038639; batch adversarial loss: 0.456936\n",
      "epoch 151; iter: 0; batch classifier loss: 0.043179; batch adversarial loss: 0.430437\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019475; batch adversarial loss: 0.443917\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031045; batch adversarial loss: 0.447959\n",
      "epoch 154; iter: 0; batch classifier loss: 0.025123; batch adversarial loss: 0.522751\n",
      "epoch 155; iter: 0; batch classifier loss: 0.021341; batch adversarial loss: 0.446518\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015703; batch adversarial loss: 0.493867\n",
      "epoch 157; iter: 0; batch classifier loss: 0.056838; batch adversarial loss: 0.374041\n",
      "epoch 158; iter: 0; batch classifier loss: 0.034769; batch adversarial loss: 0.470293\n",
      "epoch 159; iter: 0; batch classifier loss: 0.021505; batch adversarial loss: 0.469985\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033309; batch adversarial loss: 0.417062\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042916; batch adversarial loss: 0.507500\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013558; batch adversarial loss: 0.456414\n",
      "epoch 163; iter: 0; batch classifier loss: 0.012958; batch adversarial loss: 0.557470\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047785; batch adversarial loss: 0.385954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 165; iter: 0; batch classifier loss: 0.018970; batch adversarial loss: 0.453838\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050503; batch adversarial loss: 0.419427\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016832; batch adversarial loss: 0.472298\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012849; batch adversarial loss: 0.459968\n",
      "epoch 169; iter: 0; batch classifier loss: 0.012845; batch adversarial loss: 0.464689\n",
      "epoch 170; iter: 0; batch classifier loss: 0.058523; batch adversarial loss: 0.424719\n",
      "epoch 171; iter: 0; batch classifier loss: 0.031094; batch adversarial loss: 0.399724\n",
      "epoch 172; iter: 0; batch classifier loss: 0.044404; batch adversarial loss: 0.452516\n",
      "epoch 173; iter: 0; batch classifier loss: 0.042056; batch adversarial loss: 0.507935\n",
      "epoch 174; iter: 0; batch classifier loss: 0.013465; batch adversarial loss: 0.490500\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023996; batch adversarial loss: 0.467090\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028636; batch adversarial loss: 0.557649\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015242; batch adversarial loss: 0.416964\n",
      "epoch 178; iter: 0; batch classifier loss: 0.011383; batch adversarial loss: 0.404326\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026491; batch adversarial loss: 0.414616\n",
      "epoch 180; iter: 0; batch classifier loss: 0.060753; batch adversarial loss: 0.374978\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018305; batch adversarial loss: 0.481196\n",
      "epoch 182; iter: 0; batch classifier loss: 0.004368; batch adversarial loss: 0.458251\n",
      "epoch 183; iter: 0; batch classifier loss: 0.032888; batch adversarial loss: 0.385366\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019487; batch adversarial loss: 0.364481\n",
      "epoch 185; iter: 0; batch classifier loss: 0.011409; batch adversarial loss: 0.511454\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023587; batch adversarial loss: 0.477606\n",
      "epoch 187; iter: 0; batch classifier loss: 0.025833; batch adversarial loss: 0.430157\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017080; batch adversarial loss: 0.445563\n",
      "epoch 189; iter: 0; batch classifier loss: 0.005394; batch adversarial loss: 0.535112\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049856; batch adversarial loss: 0.498412\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008330; batch adversarial loss: 0.440208\n",
      "epoch 192; iter: 0; batch classifier loss: 0.028040; batch adversarial loss: 0.380646\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010614; batch adversarial loss: 0.449619\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022713; batch adversarial loss: 0.372947\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011404; batch adversarial loss: 0.631734\n",
      "epoch 196; iter: 0; batch classifier loss: 0.021912; batch adversarial loss: 0.420515\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019716; batch adversarial loss: 0.461858\n",
      "epoch 198; iter: 0; batch classifier loss: 0.039167; batch adversarial loss: 0.483835\n",
      "epoch 199; iter: 0; batch classifier loss: 0.015991; batch adversarial loss: 0.413781\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684820; batch adversarial loss: 0.869641\n",
      "epoch 1; iter: 0; batch classifier loss: 0.684708; batch adversarial loss: 1.014452\n",
      "epoch 2; iter: 0; batch classifier loss: 0.926512; batch adversarial loss: 1.028842\n",
      "epoch 3; iter: 0; batch classifier loss: 0.983334; batch adversarial loss: 0.924408\n",
      "epoch 4; iter: 0; batch classifier loss: 0.954388; batch adversarial loss: 0.839590\n",
      "epoch 5; iter: 0; batch classifier loss: 0.961028; batch adversarial loss: 0.761920\n",
      "epoch 6; iter: 0; batch classifier loss: 0.753463; batch adversarial loss: 0.694399\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612845; batch adversarial loss: 0.622279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530361; batch adversarial loss: 0.548029\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498233; batch adversarial loss: 0.578960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.360064; batch adversarial loss: 0.501455\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363507; batch adversarial loss: 0.479668\n",
      "epoch 12; iter: 0; batch classifier loss: 0.277280; batch adversarial loss: 0.469982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331148; batch adversarial loss: 0.553764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249320; batch adversarial loss: 0.459817\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266900; batch adversarial loss: 0.491764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230013; batch adversarial loss: 0.560079\n",
      "epoch 17; iter: 0; batch classifier loss: 0.248206; batch adversarial loss: 0.483977\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236443; batch adversarial loss: 0.408458\n",
      "epoch 19; iter: 0; batch classifier loss: 0.296562; batch adversarial loss: 0.501346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.220512; batch adversarial loss: 0.509614\n",
      "epoch 21; iter: 0; batch classifier loss: 0.194343; batch adversarial loss: 0.503129\n",
      "epoch 22; iter: 0; batch classifier loss: 0.140171; batch adversarial loss: 0.431775\n",
      "epoch 23; iter: 0; batch classifier loss: 0.222351; batch adversarial loss: 0.429542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166733; batch adversarial loss: 0.482828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.234177; batch adversarial loss: 0.488219\n",
      "epoch 26; iter: 0; batch classifier loss: 0.191618; batch adversarial loss: 0.430658\n",
      "epoch 27; iter: 0; batch classifier loss: 0.178277; batch adversarial loss: 0.538291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.184105; batch adversarial loss: 0.478881\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156743; batch adversarial loss: 0.403221\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149358; batch adversarial loss: 0.497579\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205259; batch adversarial loss: 0.408052\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144450; batch adversarial loss: 0.428095\n",
      "epoch 33; iter: 0; batch classifier loss: 0.171540; batch adversarial loss: 0.410947\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137517; batch adversarial loss: 0.419220\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100377; batch adversarial loss: 0.340307\n",
      "epoch 36; iter: 0; batch classifier loss: 0.140744; batch adversarial loss: 0.416039\n",
      "epoch 37; iter: 0; batch classifier loss: 0.210686; batch adversarial loss: 0.438582\n",
      "epoch 38; iter: 0; batch classifier loss: 0.158540; batch adversarial loss: 0.509891\n",
      "epoch 39; iter: 0; batch classifier loss: 0.097348; batch adversarial loss: 0.537826\n",
      "epoch 40; iter: 0; batch classifier loss: 0.135338; batch adversarial loss: 0.477669\n",
      "epoch 41; iter: 0; batch classifier loss: 0.144799; batch adversarial loss: 0.443458\n",
      "epoch 42; iter: 0; batch classifier loss: 0.152551; batch adversarial loss: 0.385164\n",
      "epoch 43; iter: 0; batch classifier loss: 0.122393; batch adversarial loss: 0.427696\n",
      "epoch 44; iter: 0; batch classifier loss: 0.133086; batch adversarial loss: 0.492710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.125718; batch adversarial loss: 0.448307\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089230; batch adversarial loss: 0.416352\n",
      "epoch 47; iter: 0; batch classifier loss: 0.102942; batch adversarial loss: 0.501897\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131329; batch adversarial loss: 0.408887\n",
      "epoch 49; iter: 0; batch classifier loss: 0.113643; batch adversarial loss: 0.455906\n",
      "epoch 50; iter: 0; batch classifier loss: 0.131262; batch adversarial loss: 0.488029\n",
      "epoch 51; iter: 0; batch classifier loss: 0.087156; batch adversarial loss: 0.421190\n",
      "epoch 52; iter: 0; batch classifier loss: 0.125630; batch adversarial loss: 0.462314\n",
      "epoch 53; iter: 0; batch classifier loss: 0.113293; batch adversarial loss: 0.366338\n",
      "epoch 54; iter: 0; batch classifier loss: 0.097415; batch adversarial loss: 0.407453\n",
      "epoch 55; iter: 0; batch classifier loss: 0.074236; batch adversarial loss: 0.472022\n",
      "epoch 56; iter: 0; batch classifier loss: 0.073220; batch adversarial loss: 0.379037\n",
      "epoch 57; iter: 0; batch classifier loss: 0.054429; batch adversarial loss: 0.438636\n",
      "epoch 58; iter: 0; batch classifier loss: 0.090050; batch adversarial loss: 0.397910\n",
      "epoch 59; iter: 0; batch classifier loss: 0.065822; batch adversarial loss: 0.369710\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095409; batch adversarial loss: 0.364492\n",
      "epoch 61; iter: 0; batch classifier loss: 0.102269; batch adversarial loss: 0.517829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62; iter: 0; batch classifier loss: 0.104850; batch adversarial loss: 0.365110\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056582; batch adversarial loss: 0.517828\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092087; batch adversarial loss: 0.445097\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109591; batch adversarial loss: 0.451155\n",
      "epoch 66; iter: 0; batch classifier loss: 0.069882; batch adversarial loss: 0.383054\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056314; batch adversarial loss: 0.397961\n",
      "epoch 68; iter: 0; batch classifier loss: 0.064568; batch adversarial loss: 0.441954\n",
      "epoch 69; iter: 0; batch classifier loss: 0.067407; batch adversarial loss: 0.407997\n",
      "epoch 70; iter: 0; batch classifier loss: 0.052912; batch adversarial loss: 0.496201\n",
      "epoch 71; iter: 0; batch classifier loss: 0.046466; batch adversarial loss: 0.428471\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077191; batch adversarial loss: 0.495316\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076886; batch adversarial loss: 0.469535\n",
      "epoch 74; iter: 0; batch classifier loss: 0.052808; batch adversarial loss: 0.470950\n",
      "epoch 75; iter: 0; batch classifier loss: 0.082276; batch adversarial loss: 0.430438\n",
      "epoch 76; iter: 0; batch classifier loss: 0.029402; batch adversarial loss: 0.419563\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045184; batch adversarial loss: 0.439914\n",
      "epoch 78; iter: 0; batch classifier loss: 0.091070; batch adversarial loss: 0.472148\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052779; batch adversarial loss: 0.510971\n",
      "epoch 80; iter: 0; batch classifier loss: 0.072861; batch adversarial loss: 0.523764\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064120; batch adversarial loss: 0.414325\n",
      "epoch 82; iter: 0; batch classifier loss: 0.044125; batch adversarial loss: 0.443054\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075476; batch adversarial loss: 0.481713\n",
      "epoch 84; iter: 0; batch classifier loss: 0.032387; batch adversarial loss: 0.373904\n",
      "epoch 85; iter: 0; batch classifier loss: 0.055697; batch adversarial loss: 0.432576\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091270; batch adversarial loss: 0.559106\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047072; batch adversarial loss: 0.533948\n",
      "epoch 88; iter: 0; batch classifier loss: 0.054008; batch adversarial loss: 0.390377\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034733; batch adversarial loss: 0.408962\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065143; batch adversarial loss: 0.400005\n",
      "epoch 91; iter: 0; batch classifier loss: 0.054308; batch adversarial loss: 0.451004\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070952; batch adversarial loss: 0.382340\n",
      "epoch 93; iter: 0; batch classifier loss: 0.037061; batch adversarial loss: 0.468844\n",
      "epoch 94; iter: 0; batch classifier loss: 0.047555; batch adversarial loss: 0.457966\n",
      "epoch 95; iter: 0; batch classifier loss: 0.065368; batch adversarial loss: 0.387473\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045604; batch adversarial loss: 0.438967\n",
      "epoch 97; iter: 0; batch classifier loss: 0.048461; batch adversarial loss: 0.457367\n",
      "epoch 98; iter: 0; batch classifier loss: 0.043478; batch adversarial loss: 0.403718\n",
      "epoch 99; iter: 0; batch classifier loss: 0.043736; batch adversarial loss: 0.403976\n",
      "epoch 100; iter: 0; batch classifier loss: 0.050807; batch adversarial loss: 0.446567\n",
      "epoch 101; iter: 0; batch classifier loss: 0.057148; batch adversarial loss: 0.510492\n",
      "epoch 102; iter: 0; batch classifier loss: 0.044960; batch adversarial loss: 0.399013\n",
      "epoch 103; iter: 0; batch classifier loss: 0.077240; batch adversarial loss: 0.446601\n",
      "epoch 104; iter: 0; batch classifier loss: 0.021621; batch adversarial loss: 0.460467\n",
      "epoch 105; iter: 0; batch classifier loss: 0.052086; batch adversarial loss: 0.499103\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037889; batch adversarial loss: 0.542725\n",
      "epoch 107; iter: 0; batch classifier loss: 0.052984; batch adversarial loss: 0.495948\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042318; batch adversarial loss: 0.483752\n",
      "epoch 109; iter: 0; batch classifier loss: 0.053360; batch adversarial loss: 0.495940\n",
      "epoch 110; iter: 0; batch classifier loss: 0.048052; batch adversarial loss: 0.412883\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048670; batch adversarial loss: 0.431163\n",
      "epoch 112; iter: 0; batch classifier loss: 0.040301; batch adversarial loss: 0.512281\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027418; batch adversarial loss: 0.525160\n",
      "epoch 114; iter: 0; batch classifier loss: 0.052139; batch adversarial loss: 0.451838\n",
      "epoch 115; iter: 0; batch classifier loss: 0.024391; batch adversarial loss: 0.441734\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.478910\n",
      "epoch 117; iter: 0; batch classifier loss: 0.038454; batch adversarial loss: 0.343314\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040000; batch adversarial loss: 0.532059\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022083; batch adversarial loss: 0.488001\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027667; batch adversarial loss: 0.400537\n",
      "epoch 121; iter: 0; batch classifier loss: 0.015841; batch adversarial loss: 0.416415\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017701; batch adversarial loss: 0.472853\n",
      "epoch 123; iter: 0; batch classifier loss: 0.008703; batch adversarial loss: 0.527496\n",
      "epoch 124; iter: 0; batch classifier loss: 0.007950; batch adversarial loss: 0.484103\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017616; batch adversarial loss: 0.334345\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020216; batch adversarial loss: 0.377208\n",
      "epoch 127; iter: 0; batch classifier loss: 0.020408; batch adversarial loss: 0.453093\n",
      "epoch 128; iter: 0; batch classifier loss: 0.029059; batch adversarial loss: 0.377910\n",
      "epoch 129; iter: 0; batch classifier loss: 0.053953; batch adversarial loss: 0.504001\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030164; batch adversarial loss: 0.422289\n",
      "epoch 131; iter: 0; batch classifier loss: 0.015465; batch adversarial loss: 0.435267\n",
      "epoch 132; iter: 0; batch classifier loss: 0.071591; batch adversarial loss: 0.446409\n",
      "epoch 133; iter: 0; batch classifier loss: 0.013972; batch adversarial loss: 0.472194\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037327; batch adversarial loss: 0.450402\n",
      "epoch 135; iter: 0; batch classifier loss: 0.011733; batch adversarial loss: 0.402777\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017956; batch adversarial loss: 0.470013\n",
      "epoch 137; iter: 0; batch classifier loss: 0.021226; batch adversarial loss: 0.491008\n",
      "epoch 138; iter: 0; batch classifier loss: 0.023019; batch adversarial loss: 0.422015\n",
      "epoch 139; iter: 0; batch classifier loss: 0.013890; batch adversarial loss: 0.466328\n",
      "epoch 140; iter: 0; batch classifier loss: 0.023292; batch adversarial loss: 0.492483\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016420; batch adversarial loss: 0.415248\n",
      "epoch 142; iter: 0; batch classifier loss: 0.026899; batch adversarial loss: 0.364098\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020275; batch adversarial loss: 0.418437\n",
      "epoch 144; iter: 0; batch classifier loss: 0.050003; batch adversarial loss: 0.431235\n",
      "epoch 145; iter: 0; batch classifier loss: 0.036119; batch adversarial loss: 0.399078\n",
      "epoch 146; iter: 0; batch classifier loss: 0.043415; batch adversarial loss: 0.503948\n",
      "epoch 147; iter: 0; batch classifier loss: 0.022109; batch adversarial loss: 0.377701\n",
      "epoch 148; iter: 0; batch classifier loss: 0.030629; batch adversarial loss: 0.486392\n",
      "epoch 149; iter: 0; batch classifier loss: 0.039749; batch adversarial loss: 0.432523\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038664; batch adversarial loss: 0.485493\n",
      "epoch 151; iter: 0; batch classifier loss: 0.028096; batch adversarial loss: 0.426858\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013471; batch adversarial loss: 0.517358\n",
      "epoch 153; iter: 0; batch classifier loss: 0.025386; batch adversarial loss: 0.380298\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029775; batch adversarial loss: 0.381567\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019008; batch adversarial loss: 0.378760\n",
      "epoch 156; iter: 0; batch classifier loss: 0.043034; batch adversarial loss: 0.516415\n",
      "epoch 157; iter: 0; batch classifier loss: 0.043004; batch adversarial loss: 0.443499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 158; iter: 0; batch classifier loss: 0.014953; batch adversarial loss: 0.445754\n",
      "epoch 159; iter: 0; batch classifier loss: 0.031741; batch adversarial loss: 0.394228\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047953; batch adversarial loss: 0.373185\n",
      "epoch 161; iter: 0; batch classifier loss: 0.005966; batch adversarial loss: 0.458073\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021382; batch adversarial loss: 0.525772\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019876; batch adversarial loss: 0.394277\n",
      "epoch 164; iter: 0; batch classifier loss: 0.016917; batch adversarial loss: 0.536417\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026469; batch adversarial loss: 0.456506\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030913; batch adversarial loss: 0.376373\n",
      "epoch 167; iter: 0; batch classifier loss: 0.049410; batch adversarial loss: 0.364104\n",
      "epoch 168; iter: 0; batch classifier loss: 0.012539; batch adversarial loss: 0.405077\n",
      "epoch 169; iter: 0; batch classifier loss: 0.006822; batch adversarial loss: 0.444494\n",
      "epoch 170; iter: 0; batch classifier loss: 0.035174; batch adversarial loss: 0.468195\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019095; batch adversarial loss: 0.476511\n",
      "epoch 172; iter: 0; batch classifier loss: 0.045059; batch adversarial loss: 0.468053\n",
      "epoch 173; iter: 0; batch classifier loss: 0.019507; batch adversarial loss: 0.443530\n",
      "epoch 174; iter: 0; batch classifier loss: 0.004758; batch adversarial loss: 0.341504\n",
      "epoch 175; iter: 0; batch classifier loss: 0.013676; batch adversarial loss: 0.414350\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025550; batch adversarial loss: 0.472561\n",
      "epoch 177; iter: 0; batch classifier loss: 0.014270; batch adversarial loss: 0.577845\n",
      "epoch 178; iter: 0; batch classifier loss: 0.020962; batch adversarial loss: 0.483529\n",
      "epoch 179; iter: 0; batch classifier loss: 0.005026; batch adversarial loss: 0.390871\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019094; batch adversarial loss: 0.431921\n",
      "epoch 181; iter: 0; batch classifier loss: 0.042818; batch adversarial loss: 0.503177\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011875; batch adversarial loss: 0.336225\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019178; batch adversarial loss: 0.423411\n",
      "epoch 184; iter: 0; batch classifier loss: 0.041756; batch adversarial loss: 0.509184\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015409; batch adversarial loss: 0.457315\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032375; batch adversarial loss: 0.355520\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021510; batch adversarial loss: 0.430905\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017706; batch adversarial loss: 0.427632\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009412; batch adversarial loss: 0.527017\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010055; batch adversarial loss: 0.441951\n",
      "epoch 191; iter: 0; batch classifier loss: 0.007981; batch adversarial loss: 0.429227\n",
      "epoch 192; iter: 0; batch classifier loss: 0.041028; batch adversarial loss: 0.442081\n",
      "epoch 193; iter: 0; batch classifier loss: 0.009432; batch adversarial loss: 0.445360\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018897; batch adversarial loss: 0.335336\n",
      "epoch 195; iter: 0; batch classifier loss: 0.030777; batch adversarial loss: 0.380817\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006045; batch adversarial loss: 0.476818\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008357; batch adversarial loss: 0.498765\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020057; batch adversarial loss: 0.396206\n",
      "epoch 199; iter: 0; batch classifier loss: 0.020790; batch adversarial loss: 0.341774\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722144; batch adversarial loss: 0.634398\n",
      "epoch 1; iter: 0; batch classifier loss: 0.563136; batch adversarial loss: 0.634946\n",
      "epoch 2; iter: 0; batch classifier loss: 0.357958; batch adversarial loss: 0.642333\n",
      "epoch 3; iter: 0; batch classifier loss: 0.363252; batch adversarial loss: 0.631697\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472359; batch adversarial loss: 0.581559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.485652; batch adversarial loss: 0.615420\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439908; batch adversarial loss: 0.596876\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523486; batch adversarial loss: 0.578553\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504627; batch adversarial loss: 0.564577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476308; batch adversarial loss: 0.511178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.442713; batch adversarial loss: 0.511601\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430038; batch adversarial loss: 0.509410\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349495; batch adversarial loss: 0.465812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315884; batch adversarial loss: 0.524770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302933; batch adversarial loss: 0.505618\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308736; batch adversarial loss: 0.519171\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263054; batch adversarial loss: 0.485601\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269899; batch adversarial loss: 0.522030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245733; batch adversarial loss: 0.517566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324411; batch adversarial loss: 0.436002\n",
      "epoch 20; iter: 0; batch classifier loss: 0.253619; batch adversarial loss: 0.488002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.301772; batch adversarial loss: 0.478070\n",
      "epoch 22; iter: 0; batch classifier loss: 0.255489; batch adversarial loss: 0.453375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.271317; batch adversarial loss: 0.516368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.206208; batch adversarial loss: 0.586446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276274; batch adversarial loss: 0.443193\n",
      "epoch 26; iter: 0; batch classifier loss: 0.177267; batch adversarial loss: 0.552540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210745; batch adversarial loss: 0.444803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.173977; batch adversarial loss: 0.539551\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175850; batch adversarial loss: 0.397245\n",
      "epoch 30; iter: 0; batch classifier loss: 0.288763; batch adversarial loss: 0.461012\n",
      "epoch 31; iter: 0; batch classifier loss: 0.240693; batch adversarial loss: 0.548076\n",
      "epoch 32; iter: 0; batch classifier loss: 0.217756; batch adversarial loss: 0.424467\n",
      "epoch 33; iter: 0; batch classifier loss: 0.224671; batch adversarial loss: 0.585522\n",
      "epoch 34; iter: 0; batch classifier loss: 0.244295; batch adversarial loss: 0.485087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.286006; batch adversarial loss: 0.445360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.194839; batch adversarial loss: 0.459245\n",
      "epoch 37; iter: 0; batch classifier loss: 0.169613; batch adversarial loss: 0.552924\n",
      "epoch 38; iter: 0; batch classifier loss: 0.290518; batch adversarial loss: 0.451005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.221679; batch adversarial loss: 0.465909\n",
      "epoch 40; iter: 0; batch classifier loss: 0.193373; batch adversarial loss: 0.430889\n",
      "epoch 41; iter: 0; batch classifier loss: 0.201919; batch adversarial loss: 0.484130\n",
      "epoch 42; iter: 0; batch classifier loss: 0.231450; batch adversarial loss: 0.476820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.156740; batch adversarial loss: 0.513284\n",
      "epoch 44; iter: 0; batch classifier loss: 0.147333; batch adversarial loss: 0.492148\n",
      "epoch 45; iter: 0; batch classifier loss: 0.215526; batch adversarial loss: 0.439092\n",
      "epoch 46; iter: 0; batch classifier loss: 0.263039; batch adversarial loss: 0.560089\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246287; batch adversarial loss: 0.391964\n",
      "epoch 48; iter: 0; batch classifier loss: 0.217851; batch adversarial loss: 0.447995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.230669; batch adversarial loss: 0.497713\n",
      "epoch 50; iter: 0; batch classifier loss: 0.263460; batch adversarial loss: 0.449149\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189864; batch adversarial loss: 0.503623\n",
      "epoch 52; iter: 0; batch classifier loss: 0.195025; batch adversarial loss: 0.436621\n",
      "epoch 53; iter: 0; batch classifier loss: 0.220929; batch adversarial loss: 0.507007\n",
      "epoch 54; iter: 0; batch classifier loss: 0.222182; batch adversarial loss: 0.436302\n",
      "epoch 55; iter: 0; batch classifier loss: 0.146002; batch adversarial loss: 0.470975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56; iter: 0; batch classifier loss: 0.120200; batch adversarial loss: 0.469326\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102777; batch adversarial loss: 0.429563\n",
      "epoch 58; iter: 0; batch classifier loss: 0.077055; batch adversarial loss: 0.377908\n",
      "epoch 59; iter: 0; batch classifier loss: 0.067423; batch adversarial loss: 0.595592\n",
      "epoch 60; iter: 0; batch classifier loss: 0.034784; batch adversarial loss: 0.472460\n",
      "epoch 61; iter: 0; batch classifier loss: 0.087357; batch adversarial loss: 0.439793\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072631; batch adversarial loss: 0.398680\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074049; batch adversarial loss: 0.443113\n",
      "epoch 64; iter: 0; batch classifier loss: 0.061174; batch adversarial loss: 0.527829\n",
      "epoch 65; iter: 0; batch classifier loss: 0.042278; batch adversarial loss: 0.476149\n",
      "epoch 66; iter: 0; batch classifier loss: 0.058499; batch adversarial loss: 0.454234\n",
      "epoch 67; iter: 0; batch classifier loss: 0.085223; batch adversarial loss: 0.438783\n",
      "epoch 68; iter: 0; batch classifier loss: 0.071256; batch adversarial loss: 0.471508\n",
      "epoch 69; iter: 0; batch classifier loss: 0.033528; batch adversarial loss: 0.483323\n",
      "epoch 70; iter: 0; batch classifier loss: 0.043574; batch adversarial loss: 0.487262\n",
      "epoch 71; iter: 0; batch classifier loss: 0.052017; batch adversarial loss: 0.352174\n",
      "epoch 72; iter: 0; batch classifier loss: 0.050571; batch adversarial loss: 0.425956\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042351; batch adversarial loss: 0.430897\n",
      "epoch 74; iter: 0; batch classifier loss: 0.057331; batch adversarial loss: 0.499100\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061705; batch adversarial loss: 0.503659\n",
      "epoch 76; iter: 0; batch classifier loss: 0.052739; batch adversarial loss: 0.480342\n",
      "epoch 77; iter: 0; batch classifier loss: 0.045141; batch adversarial loss: 0.461294\n",
      "epoch 78; iter: 0; batch classifier loss: 0.041563; batch adversarial loss: 0.472247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.038434; batch adversarial loss: 0.447006\n",
      "epoch 80; iter: 0; batch classifier loss: 0.031713; batch adversarial loss: 0.574255\n",
      "epoch 81; iter: 0; batch classifier loss: 0.044116; batch adversarial loss: 0.400803\n",
      "epoch 82; iter: 0; batch classifier loss: 0.063263; batch adversarial loss: 0.481873\n",
      "epoch 83; iter: 0; batch classifier loss: 0.064957; batch adversarial loss: 0.384201\n",
      "epoch 84; iter: 0; batch classifier loss: 0.040019; batch adversarial loss: 0.535146\n",
      "epoch 85; iter: 0; batch classifier loss: 0.064513; batch adversarial loss: 0.466076\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061267; batch adversarial loss: 0.376784\n",
      "epoch 87; iter: 0; batch classifier loss: 0.042933; batch adversarial loss: 0.383179\n",
      "epoch 88; iter: 0; batch classifier loss: 0.034720; batch adversarial loss: 0.458864\n",
      "epoch 89; iter: 0; batch classifier loss: 0.020755; batch adversarial loss: 0.440656\n",
      "epoch 90; iter: 0; batch classifier loss: 0.034891; batch adversarial loss: 0.477746\n",
      "epoch 91; iter: 0; batch classifier loss: 0.041934; batch adversarial loss: 0.521171\n",
      "epoch 92; iter: 0; batch classifier loss: 0.030645; batch adversarial loss: 0.448352\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072576; batch adversarial loss: 0.461625\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041094; batch adversarial loss: 0.451977\n",
      "epoch 95; iter: 0; batch classifier loss: 0.088168; batch adversarial loss: 0.422968\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060972; batch adversarial loss: 0.395266\n",
      "epoch 97; iter: 0; batch classifier loss: 0.032998; batch adversarial loss: 0.662857\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059336; batch adversarial loss: 0.391777\n",
      "epoch 99; iter: 0; batch classifier loss: 0.048234; batch adversarial loss: 0.424242\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044030; batch adversarial loss: 0.431303\n",
      "epoch 101; iter: 0; batch classifier loss: 0.047731; batch adversarial loss: 0.475410\n",
      "epoch 102; iter: 0; batch classifier loss: 0.032492; batch adversarial loss: 0.437595\n",
      "epoch 103; iter: 0; batch classifier loss: 0.023638; batch adversarial loss: 0.475205\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031652; batch adversarial loss: 0.508718\n",
      "epoch 105; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.415233\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037979; batch adversarial loss: 0.342897\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032419; batch adversarial loss: 0.493613\n",
      "epoch 108; iter: 0; batch classifier loss: 0.028572; batch adversarial loss: 0.438833\n",
      "epoch 109; iter: 0; batch classifier loss: 0.051781; batch adversarial loss: 0.437252\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052904; batch adversarial loss: 0.388829\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048526; batch adversarial loss: 0.439859\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034074; batch adversarial loss: 0.518551\n",
      "epoch 113; iter: 0; batch classifier loss: 0.047594; batch adversarial loss: 0.482386\n",
      "epoch 114; iter: 0; batch classifier loss: 0.058610; batch adversarial loss: 0.460313\n",
      "epoch 115; iter: 0; batch classifier loss: 0.025627; batch adversarial loss: 0.451225\n",
      "epoch 116; iter: 0; batch classifier loss: 0.043388; batch adversarial loss: 0.468414\n",
      "epoch 117; iter: 0; batch classifier loss: 0.031941; batch adversarial loss: 0.464771\n",
      "epoch 118; iter: 0; batch classifier loss: 0.043300; batch adversarial loss: 0.463445\n",
      "epoch 119; iter: 0; batch classifier loss: 0.022929; batch adversarial loss: 0.411535\n",
      "epoch 120; iter: 0; batch classifier loss: 0.037121; batch adversarial loss: 0.451596\n",
      "epoch 121; iter: 0; batch classifier loss: 0.035852; batch adversarial loss: 0.453777\n",
      "epoch 122; iter: 0; batch classifier loss: 0.022354; batch adversarial loss: 0.410446\n",
      "epoch 123; iter: 0; batch classifier loss: 0.043353; batch adversarial loss: 0.520058\n",
      "epoch 124; iter: 0; batch classifier loss: 0.044182; batch adversarial loss: 0.385678\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020374; batch adversarial loss: 0.461751\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063945; batch adversarial loss: 0.461821\n",
      "epoch 127; iter: 0; batch classifier loss: 0.024550; batch adversarial loss: 0.452411\n",
      "epoch 128; iter: 0; batch classifier loss: 0.011055; batch adversarial loss: 0.493485\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014247; batch adversarial loss: 0.542112\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039429; batch adversarial loss: 0.444221\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023629; batch adversarial loss: 0.404919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023830; batch adversarial loss: 0.445538\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049790; batch adversarial loss: 0.398972\n",
      "epoch 134; iter: 0; batch classifier loss: 0.032929; batch adversarial loss: 0.439477\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037968; batch adversarial loss: 0.565840\n",
      "epoch 136; iter: 0; batch classifier loss: 0.014871; batch adversarial loss: 0.476838\n",
      "epoch 137; iter: 0; batch classifier loss: 0.004750; batch adversarial loss: 0.486103\n",
      "epoch 138; iter: 0; batch classifier loss: 0.044527; batch adversarial loss: 0.418178\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020790; batch adversarial loss: 0.592939\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025612; batch adversarial loss: 0.366642\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036641; batch adversarial loss: 0.446213\n",
      "epoch 142; iter: 0; batch classifier loss: 0.019265; batch adversarial loss: 0.438669\n",
      "epoch 143; iter: 0; batch classifier loss: 0.017505; batch adversarial loss: 0.359663\n",
      "epoch 144; iter: 0; batch classifier loss: 0.010179; batch adversarial loss: 0.433425\n",
      "epoch 145; iter: 0; batch classifier loss: 0.015210; batch adversarial loss: 0.473694\n",
      "epoch 146; iter: 0; batch classifier loss: 0.042678; batch adversarial loss: 0.455886\n",
      "epoch 147; iter: 0; batch classifier loss: 0.021816; batch adversarial loss: 0.426946\n",
      "epoch 148; iter: 0; batch classifier loss: 0.016729; batch adversarial loss: 0.363887\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034269; batch adversarial loss: 0.403983\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013321; batch adversarial loss: 0.465388\n",
      "epoch 151; iter: 0; batch classifier loss: 0.025855; batch adversarial loss: 0.445497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 152; iter: 0; batch classifier loss: 0.035380; batch adversarial loss: 0.496470\n",
      "epoch 153; iter: 0; batch classifier loss: 0.020813; batch adversarial loss: 0.472451\n",
      "epoch 154; iter: 0; batch classifier loss: 0.012127; batch adversarial loss: 0.524484\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033140; batch adversarial loss: 0.384133\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025231; batch adversarial loss: 0.435677\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024575; batch adversarial loss: 0.457750\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007357; batch adversarial loss: 0.500875\n",
      "epoch 159; iter: 0; batch classifier loss: 0.024214; batch adversarial loss: 0.458000\n",
      "epoch 160; iter: 0; batch classifier loss: 0.012846; batch adversarial loss: 0.455633\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024663; batch adversarial loss: 0.519065\n",
      "epoch 162; iter: 0; batch classifier loss: 0.013881; batch adversarial loss: 0.523955\n",
      "epoch 163; iter: 0; batch classifier loss: 0.008362; batch adversarial loss: 0.467979\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030210; batch adversarial loss: 0.465622\n",
      "epoch 165; iter: 0; batch classifier loss: 0.019629; batch adversarial loss: 0.419693\n",
      "epoch 166; iter: 0; batch classifier loss: 0.068281; batch adversarial loss: 0.451070\n",
      "epoch 167; iter: 0; batch classifier loss: 0.029987; batch adversarial loss: 0.465596\n",
      "epoch 168; iter: 0; batch classifier loss: 0.029802; batch adversarial loss: 0.482717\n",
      "epoch 169; iter: 0; batch classifier loss: 0.042995; batch adversarial loss: 0.409000\n",
      "epoch 170; iter: 0; batch classifier loss: 0.079800; batch adversarial loss: 0.439516\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032750; batch adversarial loss: 0.500771\n",
      "epoch 172; iter: 0; batch classifier loss: 0.017950; batch adversarial loss: 0.401170\n",
      "epoch 173; iter: 0; batch classifier loss: 0.021953; batch adversarial loss: 0.515549\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015468; batch adversarial loss: 0.427013\n",
      "epoch 175; iter: 0; batch classifier loss: 0.039906; batch adversarial loss: 0.450043\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010018; batch adversarial loss: 0.442966\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008261; batch adversarial loss: 0.441705\n",
      "epoch 178; iter: 0; batch classifier loss: 0.007145; batch adversarial loss: 0.406401\n",
      "epoch 179; iter: 0; batch classifier loss: 0.013396; batch adversarial loss: 0.440306\n",
      "epoch 180; iter: 0; batch classifier loss: 0.007449; batch adversarial loss: 0.490918\n",
      "epoch 181; iter: 0; batch classifier loss: 0.008554; batch adversarial loss: 0.510826\n",
      "epoch 182; iter: 0; batch classifier loss: 0.065373; batch adversarial loss: 0.499779\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015965; batch adversarial loss: 0.424477\n",
      "epoch 184; iter: 0; batch classifier loss: 0.029817; batch adversarial loss: 0.519075\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005936; batch adversarial loss: 0.501860\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014142; batch adversarial loss: 0.478900\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007928; batch adversarial loss: 0.519379\n",
      "epoch 188; iter: 0; batch classifier loss: 0.003296; batch adversarial loss: 0.437298\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009798; batch adversarial loss: 0.419563\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015577; batch adversarial loss: 0.488043\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020389; batch adversarial loss: 0.402294\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012075; batch adversarial loss: 0.541862\n",
      "epoch 193; iter: 0; batch classifier loss: 0.021986; batch adversarial loss: 0.426957\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012480; batch adversarial loss: 0.431596\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015249; batch adversarial loss: 0.526298\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006481; batch adversarial loss: 0.374140\n",
      "epoch 197; iter: 0; batch classifier loss: 0.023959; batch adversarial loss: 0.399484\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008051; batch adversarial loss: 0.523030\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009246; batch adversarial loss: 0.454343\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684486; batch adversarial loss: 0.983866\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692196; batch adversarial loss: 1.089470\n",
      "epoch 2; iter: 0; batch classifier loss: 0.882706; batch adversarial loss: 1.065795\n",
      "epoch 3; iter: 0; batch classifier loss: 1.050265; batch adversarial loss: 1.008332\n",
      "epoch 4; iter: 0; batch classifier loss: 1.025556; batch adversarial loss: 0.932425\n",
      "epoch 5; iter: 0; batch classifier loss: 0.799210; batch adversarial loss: 0.816677\n",
      "epoch 6; iter: 0; batch classifier loss: 0.898868; batch adversarial loss: 0.783765\n",
      "epoch 7; iter: 0; batch classifier loss: 0.718779; batch adversarial loss: 0.677189\n",
      "epoch 8; iter: 0; batch classifier loss: 0.697994; batch adversarial loss: 0.659739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580324; batch adversarial loss: 0.590559\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515639; batch adversarial loss: 0.525620\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406393; batch adversarial loss: 0.530328\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313289; batch adversarial loss: 0.526805\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306132; batch adversarial loss: 0.470390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248705; batch adversarial loss: 0.510073\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230282; batch adversarial loss: 0.491148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.242085; batch adversarial loss: 0.487308\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273711; batch adversarial loss: 0.477142\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243151; batch adversarial loss: 0.534808\n",
      "epoch 19; iter: 0; batch classifier loss: 0.249086; batch adversarial loss: 0.561473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.201655; batch adversarial loss: 0.541599\n",
      "epoch 21; iter: 0; batch classifier loss: 0.228231; batch adversarial loss: 0.527072\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163778; batch adversarial loss: 0.473122\n",
      "epoch 23; iter: 0; batch classifier loss: 0.172813; batch adversarial loss: 0.485449\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184606; batch adversarial loss: 0.505953\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205053; batch adversarial loss: 0.566659\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176523; batch adversarial loss: 0.492567\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184973; batch adversarial loss: 0.495556\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147500; batch adversarial loss: 0.424331\n",
      "epoch 29; iter: 0; batch classifier loss: 0.105010; batch adversarial loss: 0.528405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.122367; batch adversarial loss: 0.509471\n",
      "epoch 31; iter: 0; batch classifier loss: 0.139004; batch adversarial loss: 0.449255\n",
      "epoch 32; iter: 0; batch classifier loss: 0.108197; batch adversarial loss: 0.529788\n",
      "epoch 33; iter: 0; batch classifier loss: 0.143057; batch adversarial loss: 0.451313\n",
      "epoch 34; iter: 0; batch classifier loss: 0.130620; batch adversarial loss: 0.425569\n",
      "epoch 35; iter: 0; batch classifier loss: 0.095946; batch adversarial loss: 0.468599\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109825; batch adversarial loss: 0.543962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.113259; batch adversarial loss: 0.464308\n",
      "epoch 38; iter: 0; batch classifier loss: 0.105361; batch adversarial loss: 0.413776\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088926; batch adversarial loss: 0.477155\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114929; batch adversarial loss: 0.476774\n",
      "epoch 41; iter: 0; batch classifier loss: 0.076513; batch adversarial loss: 0.537848\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094808; batch adversarial loss: 0.470568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110501; batch adversarial loss: 0.493596\n",
      "epoch 44; iter: 0; batch classifier loss: 0.102257; batch adversarial loss: 0.430576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123258; batch adversarial loss: 0.493902\n",
      "epoch 46; iter: 0; batch classifier loss: 0.127065; batch adversarial loss: 0.390927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.063882; batch adversarial loss: 0.399044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.088005; batch adversarial loss: 0.422677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.100788; batch adversarial loss: 0.459787\n",
      "epoch 50; iter: 0; batch classifier loss: 0.065460; batch adversarial loss: 0.455577\n",
      "epoch 51; iter: 0; batch classifier loss: 0.039514; batch adversarial loss: 0.472596\n",
      "epoch 52; iter: 0; batch classifier loss: 0.077510; batch adversarial loss: 0.462144\n",
      "epoch 53; iter: 0; batch classifier loss: 0.079014; batch adversarial loss: 0.460463\n",
      "epoch 54; iter: 0; batch classifier loss: 0.056219; batch adversarial loss: 0.473988\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062737; batch adversarial loss: 0.510739\n",
      "epoch 56; iter: 0; batch classifier loss: 0.084101; batch adversarial loss: 0.443643\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088640; batch adversarial loss: 0.467333\n",
      "epoch 58; iter: 0; batch classifier loss: 0.085513; batch adversarial loss: 0.506845\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079584; batch adversarial loss: 0.378855\n",
      "epoch 60; iter: 0; batch classifier loss: 0.064509; batch adversarial loss: 0.498862\n",
      "epoch 61; iter: 0; batch classifier loss: 0.061543; batch adversarial loss: 0.441346\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090808; batch adversarial loss: 0.422998\n",
      "epoch 63; iter: 0; batch classifier loss: 0.058231; batch adversarial loss: 0.501612\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081821; batch adversarial loss: 0.432804\n",
      "epoch 65; iter: 0; batch classifier loss: 0.077577; batch adversarial loss: 0.624827\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056871; batch adversarial loss: 0.507819\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062506; batch adversarial loss: 0.453660\n",
      "epoch 68; iter: 0; batch classifier loss: 0.061406; batch adversarial loss: 0.464214\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087637; batch adversarial loss: 0.449186\n",
      "epoch 70; iter: 0; batch classifier loss: 0.031797; batch adversarial loss: 0.549304\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076556; batch adversarial loss: 0.482888\n",
      "epoch 72; iter: 0; batch classifier loss: 0.076331; batch adversarial loss: 0.481585\n",
      "epoch 73; iter: 0; batch classifier loss: 0.079464; batch adversarial loss: 0.430605\n",
      "epoch 74; iter: 0; batch classifier loss: 0.041431; batch adversarial loss: 0.462310\n",
      "epoch 75; iter: 0; batch classifier loss: 0.040270; batch adversarial loss: 0.490321\n",
      "epoch 76; iter: 0; batch classifier loss: 0.050224; batch adversarial loss: 0.454843\n",
      "epoch 77; iter: 0; batch classifier loss: 0.047726; batch adversarial loss: 0.429898\n",
      "epoch 78; iter: 0; batch classifier loss: 0.080278; batch adversarial loss: 0.344264\n",
      "epoch 79; iter: 0; batch classifier loss: 0.050143; batch adversarial loss: 0.466457\n",
      "epoch 80; iter: 0; batch classifier loss: 0.041858; batch adversarial loss: 0.462171\n",
      "epoch 81; iter: 0; batch classifier loss: 0.037592; batch adversarial loss: 0.467074\n",
      "epoch 82; iter: 0; batch classifier loss: 0.050479; batch adversarial loss: 0.379574\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070949; batch adversarial loss: 0.422640\n",
      "epoch 84; iter: 0; batch classifier loss: 0.031868; batch adversarial loss: 0.478905\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053213; batch adversarial loss: 0.382536\n",
      "epoch 86; iter: 0; batch classifier loss: 0.043722; batch adversarial loss: 0.464439\n",
      "epoch 87; iter: 0; batch classifier loss: 0.033493; batch adversarial loss: 0.479260\n",
      "epoch 88; iter: 0; batch classifier loss: 0.049834; batch adversarial loss: 0.501508\n",
      "epoch 89; iter: 0; batch classifier loss: 0.068704; batch adversarial loss: 0.437938\n",
      "epoch 90; iter: 0; batch classifier loss: 0.058015; batch adversarial loss: 0.487210\n",
      "epoch 91; iter: 0; batch classifier loss: 0.045231; batch adversarial loss: 0.417324\n",
      "epoch 92; iter: 0; batch classifier loss: 0.029001; batch adversarial loss: 0.475827\n",
      "epoch 93; iter: 0; batch classifier loss: 0.040537; batch adversarial loss: 0.419177\n",
      "epoch 94; iter: 0; batch classifier loss: 0.028607; batch adversarial loss: 0.446890\n",
      "epoch 95; iter: 0; batch classifier loss: 0.085468; batch adversarial loss: 0.550384\n",
      "epoch 96; iter: 0; batch classifier loss: 0.062796; batch adversarial loss: 0.457882\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050202; batch adversarial loss: 0.576683\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030668; batch adversarial loss: 0.533176\n",
      "epoch 99; iter: 0; batch classifier loss: 0.063255; batch adversarial loss: 0.360962\n",
      "epoch 100; iter: 0; batch classifier loss: 0.038346; batch adversarial loss: 0.498917\n",
      "epoch 101; iter: 0; batch classifier loss: 0.039137; batch adversarial loss: 0.469791\n",
      "epoch 102; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.447260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.054807; batch adversarial loss: 0.407997\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051938; batch adversarial loss: 0.509432\n",
      "epoch 105; iter: 0; batch classifier loss: 0.034107; batch adversarial loss: 0.382560\n",
      "epoch 106; iter: 0; batch classifier loss: 0.022240; batch adversarial loss: 0.538795\n",
      "epoch 107; iter: 0; batch classifier loss: 0.021719; batch adversarial loss: 0.441425\n",
      "epoch 108; iter: 0; batch classifier loss: 0.033628; batch adversarial loss: 0.479245\n",
      "epoch 109; iter: 0; batch classifier loss: 0.025134; batch adversarial loss: 0.455145\n",
      "epoch 110; iter: 0; batch classifier loss: 0.044040; batch adversarial loss: 0.404875\n",
      "epoch 111; iter: 0; batch classifier loss: 0.067062; batch adversarial loss: 0.393472\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035758; batch adversarial loss: 0.379725\n",
      "epoch 113; iter: 0; batch classifier loss: 0.057896; batch adversarial loss: 0.483131\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044287; batch adversarial loss: 0.514134\n",
      "epoch 115; iter: 0; batch classifier loss: 0.043053; batch adversarial loss: 0.532824\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056368; batch adversarial loss: 0.428862\n",
      "epoch 117; iter: 0; batch classifier loss: 0.027788; batch adversarial loss: 0.376640\n",
      "epoch 118; iter: 0; batch classifier loss: 0.045861; batch adversarial loss: 0.489449\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032183; batch adversarial loss: 0.478075\n",
      "epoch 120; iter: 0; batch classifier loss: 0.027975; batch adversarial loss: 0.456408\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040749; batch adversarial loss: 0.601154\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037811; batch adversarial loss: 0.364218\n",
      "epoch 123; iter: 0; batch classifier loss: 0.044196; batch adversarial loss: 0.495616\n",
      "epoch 124; iter: 0; batch classifier loss: 0.028089; batch adversarial loss: 0.420547\n",
      "epoch 125; iter: 0; batch classifier loss: 0.023077; batch adversarial loss: 0.542022\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045437; batch adversarial loss: 0.358357\n",
      "epoch 127; iter: 0; batch classifier loss: 0.039139; batch adversarial loss: 0.442911\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015898; batch adversarial loss: 0.481037\n",
      "epoch 129; iter: 0; batch classifier loss: 0.022746; batch adversarial loss: 0.492040\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045243; batch adversarial loss: 0.415390\n",
      "epoch 131; iter: 0; batch classifier loss: 0.029795; batch adversarial loss: 0.397267\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039869; batch adversarial loss: 0.424718\n",
      "epoch 133; iter: 0; batch classifier loss: 0.011892; batch adversarial loss: 0.544222\n",
      "epoch 134; iter: 0; batch classifier loss: 0.013577; batch adversarial loss: 0.413515\n",
      "epoch 135; iter: 0; batch classifier loss: 0.004298; batch adversarial loss: 0.422272\n",
      "epoch 136; iter: 0; batch classifier loss: 0.019461; batch adversarial loss: 0.543925\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018123; batch adversarial loss: 0.469806\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041477; batch adversarial loss: 0.438751\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031382; batch adversarial loss: 0.462578\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018158; batch adversarial loss: 0.460240\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035248; batch adversarial loss: 0.487382\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023353; batch adversarial loss: 0.483603\n",
      "epoch 143; iter: 0; batch classifier loss: 0.024972; batch adversarial loss: 0.488283\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016711; batch adversarial loss: 0.549720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 145; iter: 0; batch classifier loss: 0.019323; batch adversarial loss: 0.490983\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015697; batch adversarial loss: 0.505879\n",
      "epoch 147; iter: 0; batch classifier loss: 0.014391; batch adversarial loss: 0.417507\n",
      "epoch 148; iter: 0; batch classifier loss: 0.015206; batch adversarial loss: 0.408047\n",
      "epoch 149; iter: 0; batch classifier loss: 0.056837; batch adversarial loss: 0.465059\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016551; batch adversarial loss: 0.504187\n",
      "epoch 151; iter: 0; batch classifier loss: 0.034431; batch adversarial loss: 0.488206\n",
      "epoch 152; iter: 0; batch classifier loss: 0.011843; batch adversarial loss: 0.466876\n",
      "epoch 153; iter: 0; batch classifier loss: 0.026191; batch adversarial loss: 0.415873\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030807; batch adversarial loss: 0.462673\n",
      "epoch 155; iter: 0; batch classifier loss: 0.017375; batch adversarial loss: 0.443610\n",
      "epoch 156; iter: 0; batch classifier loss: 0.023977; batch adversarial loss: 0.400623\n",
      "epoch 157; iter: 0; batch classifier loss: 0.022754; batch adversarial loss: 0.458442\n",
      "epoch 158; iter: 0; batch classifier loss: 0.014191; batch adversarial loss: 0.490886\n",
      "epoch 159; iter: 0; batch classifier loss: 0.040944; batch adversarial loss: 0.394928\n",
      "epoch 160; iter: 0; batch classifier loss: 0.027865; batch adversarial loss: 0.424314\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015055; batch adversarial loss: 0.451598\n",
      "epoch 162; iter: 0; batch classifier loss: 0.026346; batch adversarial loss: 0.510152\n",
      "epoch 163; iter: 0; batch classifier loss: 0.024187; batch adversarial loss: 0.484864\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025412; batch adversarial loss: 0.473466\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011082; batch adversarial loss: 0.445439\n",
      "epoch 166; iter: 0; batch classifier loss: 0.029420; batch adversarial loss: 0.517778\n",
      "epoch 167; iter: 0; batch classifier loss: 0.015586; batch adversarial loss: 0.359497\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016335; batch adversarial loss: 0.491669\n",
      "epoch 169; iter: 0; batch classifier loss: 0.004953; batch adversarial loss: 0.419447\n",
      "epoch 170; iter: 0; batch classifier loss: 0.027481; batch adversarial loss: 0.516853\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023504; batch adversarial loss: 0.475549\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029077; batch adversarial loss: 0.410414\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020976; batch adversarial loss: 0.406390\n",
      "epoch 174; iter: 0; batch classifier loss: 0.048206; batch adversarial loss: 0.446985\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004734; batch adversarial loss: 0.412015\n",
      "epoch 176; iter: 0; batch classifier loss: 0.031063; batch adversarial loss: 0.477124\n",
      "epoch 177; iter: 0; batch classifier loss: 0.023459; batch adversarial loss: 0.490095\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021557; batch adversarial loss: 0.408890\n",
      "epoch 179; iter: 0; batch classifier loss: 0.008966; batch adversarial loss: 0.417103\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015402; batch adversarial loss: 0.424884\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017199; batch adversarial loss: 0.472753\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011232; batch adversarial loss: 0.375555\n",
      "epoch 183; iter: 0; batch classifier loss: 0.007869; batch adversarial loss: 0.469579\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009916; batch adversarial loss: 0.460097\n",
      "epoch 185; iter: 0; batch classifier loss: 0.009557; batch adversarial loss: 0.442880\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008836; batch adversarial loss: 0.458066\n",
      "epoch 187; iter: 0; batch classifier loss: 0.003237; batch adversarial loss: 0.545542\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005515; batch adversarial loss: 0.429068\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028415; batch adversarial loss: 0.372601\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006649; batch adversarial loss: 0.455672\n",
      "epoch 191; iter: 0; batch classifier loss: 0.001279; batch adversarial loss: 0.433232\n",
      "epoch 192; iter: 0; batch classifier loss: 0.019655; batch adversarial loss: 0.464806\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022045; batch adversarial loss: 0.470200\n",
      "epoch 194; iter: 0; batch classifier loss: 0.018949; batch adversarial loss: 0.556772\n",
      "epoch 195; iter: 0; batch classifier loss: 0.002547; batch adversarial loss: 0.428331\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005644; batch adversarial loss: 0.488670\n",
      "epoch 197; iter: 0; batch classifier loss: 0.015114; batch adversarial loss: 0.528968\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020825; batch adversarial loss: 0.438035\n",
      "epoch 199; iter: 0; batch classifier loss: 0.025535; batch adversarial loss: 0.423842\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718863; batch adversarial loss: 0.549503\n",
      "epoch 1; iter: 0; batch classifier loss: 0.443081; batch adversarial loss: 0.640009\n",
      "epoch 2; iter: 0; batch classifier loss: 0.453652; batch adversarial loss: 0.616771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.353692; batch adversarial loss: 0.569145\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364471; batch adversarial loss: 0.540295\n",
      "epoch 5; iter: 0; batch classifier loss: 0.311969; batch adversarial loss: 0.578337\n",
      "epoch 6; iter: 0; batch classifier loss: 0.344511; batch adversarial loss: 0.571815\n",
      "epoch 7; iter: 0; batch classifier loss: 0.403643; batch adversarial loss: 0.548937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325528; batch adversarial loss: 0.587762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386347; batch adversarial loss: 0.508084\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349822; batch adversarial loss: 0.574471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373140; batch adversarial loss: 0.546775\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366073; batch adversarial loss: 0.473318\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261666; batch adversarial loss: 0.518809\n",
      "epoch 14; iter: 0; batch classifier loss: 0.272233; batch adversarial loss: 0.493457\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290837; batch adversarial loss: 0.483616\n",
      "epoch 16; iter: 0; batch classifier loss: 0.218705; batch adversarial loss: 0.507339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247401; batch adversarial loss: 0.488656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181738; batch adversarial loss: 0.496770\n",
      "epoch 19; iter: 0; batch classifier loss: 0.160275; batch adversarial loss: 0.470135\n",
      "epoch 20; iter: 0; batch classifier loss: 0.173762; batch adversarial loss: 0.488560\n",
      "epoch 21; iter: 0; batch classifier loss: 0.234818; batch adversarial loss: 0.445951\n",
      "epoch 22; iter: 0; batch classifier loss: 0.145009; batch adversarial loss: 0.467256\n",
      "epoch 23; iter: 0; batch classifier loss: 0.142383; batch adversarial loss: 0.472623\n",
      "epoch 24; iter: 0; batch classifier loss: 0.166285; batch adversarial loss: 0.465579\n",
      "epoch 25; iter: 0; batch classifier loss: 0.159013; batch adversarial loss: 0.455001\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170536; batch adversarial loss: 0.447555\n",
      "epoch 27; iter: 0; batch classifier loss: 0.092766; batch adversarial loss: 0.572150\n",
      "epoch 28; iter: 0; batch classifier loss: 0.159257; batch adversarial loss: 0.507603\n",
      "epoch 29; iter: 0; batch classifier loss: 0.118957; batch adversarial loss: 0.478246\n",
      "epoch 30; iter: 0; batch classifier loss: 0.187400; batch adversarial loss: 0.482616\n",
      "epoch 31; iter: 0; batch classifier loss: 0.124068; batch adversarial loss: 0.498871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.119186; batch adversarial loss: 0.437777\n",
      "epoch 33; iter: 0; batch classifier loss: 0.149977; batch adversarial loss: 0.435294\n",
      "epoch 34; iter: 0; batch classifier loss: 0.135913; batch adversarial loss: 0.511794\n",
      "epoch 35; iter: 0; batch classifier loss: 0.150174; batch adversarial loss: 0.474704\n",
      "epoch 36; iter: 0; batch classifier loss: 0.112576; batch adversarial loss: 0.530346\n",
      "epoch 37; iter: 0; batch classifier loss: 0.073072; batch adversarial loss: 0.468515\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119724; batch adversarial loss: 0.446590\n",
      "epoch 39; iter: 0; batch classifier loss: 0.102297; batch adversarial loss: 0.431359\n",
      "epoch 40; iter: 0; batch classifier loss: 0.130115; batch adversarial loss: 0.494848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.103781; batch adversarial loss: 0.451564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.177160; batch adversarial loss: 0.545713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.123102; batch adversarial loss: 0.413418\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129801; batch adversarial loss: 0.422070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126231; batch adversarial loss: 0.479905\n",
      "epoch 46; iter: 0; batch classifier loss: 0.154468; batch adversarial loss: 0.446451\n",
      "epoch 47; iter: 0; batch classifier loss: 0.202049; batch adversarial loss: 0.562894\n",
      "epoch 48; iter: 0; batch classifier loss: 0.186510; batch adversarial loss: 0.557761\n",
      "epoch 49; iter: 0; batch classifier loss: 0.149660; batch adversarial loss: 0.491637\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102970; batch adversarial loss: 0.444108\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096576; batch adversarial loss: 0.386851\n",
      "epoch 52; iter: 0; batch classifier loss: 0.154275; batch adversarial loss: 0.553743\n",
      "epoch 53; iter: 0; batch classifier loss: 0.128003; batch adversarial loss: 0.551598\n",
      "epoch 54; iter: 0; batch classifier loss: 0.132179; batch adversarial loss: 0.443904\n",
      "epoch 55; iter: 0; batch classifier loss: 0.086103; batch adversarial loss: 0.469176\n",
      "epoch 56; iter: 0; batch classifier loss: 0.127957; batch adversarial loss: 0.387209\n",
      "epoch 57; iter: 0; batch classifier loss: 0.096130; batch adversarial loss: 0.347645\n",
      "epoch 58; iter: 0; batch classifier loss: 0.109416; batch adversarial loss: 0.390071\n",
      "epoch 59; iter: 0; batch classifier loss: 0.109221; batch adversarial loss: 0.434518\n",
      "epoch 60; iter: 0; batch classifier loss: 0.192750; batch adversarial loss: 0.526848\n",
      "epoch 61; iter: 0; batch classifier loss: 0.084975; batch adversarial loss: 0.540658\n",
      "epoch 62; iter: 0; batch classifier loss: 0.191002; batch adversarial loss: 0.427484\n",
      "epoch 63; iter: 0; batch classifier loss: 0.192208; batch adversarial loss: 0.514832\n",
      "epoch 64; iter: 0; batch classifier loss: 0.166567; batch adversarial loss: 0.394471\n",
      "epoch 65; iter: 0; batch classifier loss: 0.142990; batch adversarial loss: 0.463437\n",
      "epoch 66; iter: 0; batch classifier loss: 0.149411; batch adversarial loss: 0.513424\n",
      "epoch 67; iter: 0; batch classifier loss: 0.143078; batch adversarial loss: 0.431778\n",
      "epoch 68; iter: 0; batch classifier loss: 0.159646; batch adversarial loss: 0.382399\n",
      "epoch 69; iter: 0; batch classifier loss: 0.211081; batch adversarial loss: 0.362360\n",
      "epoch 70; iter: 0; batch classifier loss: 0.162269; batch adversarial loss: 0.430481\n",
      "epoch 71; iter: 0; batch classifier loss: 0.165070; batch adversarial loss: 0.410801\n",
      "epoch 72; iter: 0; batch classifier loss: 0.175102; batch adversarial loss: 0.478064\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168197; batch adversarial loss: 0.433915\n",
      "epoch 74; iter: 0; batch classifier loss: 0.144757; batch adversarial loss: 0.495632\n",
      "epoch 75; iter: 0; batch classifier loss: 0.139373; batch adversarial loss: 0.395505\n",
      "epoch 76; iter: 0; batch classifier loss: 0.158307; batch adversarial loss: 0.405780\n",
      "epoch 77; iter: 0; batch classifier loss: 0.139187; batch adversarial loss: 0.468271\n",
      "epoch 78; iter: 0; batch classifier loss: 0.167439; batch adversarial loss: 0.505675\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210601; batch adversarial loss: 0.484478\n",
      "epoch 80; iter: 0; batch classifier loss: 0.204605; batch adversarial loss: 0.482522\n",
      "epoch 81; iter: 0; batch classifier loss: 0.114846; batch adversarial loss: 0.473329\n",
      "epoch 82; iter: 0; batch classifier loss: 0.166801; batch adversarial loss: 0.385867\n",
      "epoch 83; iter: 0; batch classifier loss: 0.195799; batch adversarial loss: 0.411907\n",
      "epoch 84; iter: 0; batch classifier loss: 0.184591; batch adversarial loss: 0.543543\n",
      "epoch 85; iter: 0; batch classifier loss: 0.154502; batch adversarial loss: 0.438356\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150405; batch adversarial loss: 0.578475\n",
      "epoch 87; iter: 0; batch classifier loss: 0.216899; batch adversarial loss: 0.549930\n",
      "epoch 88; iter: 0; batch classifier loss: 0.187903; batch adversarial loss: 0.518008\n",
      "epoch 89; iter: 0; batch classifier loss: 0.171905; batch adversarial loss: 0.466692\n",
      "epoch 90; iter: 0; batch classifier loss: 0.231043; batch adversarial loss: 0.410378\n",
      "epoch 91; iter: 0; batch classifier loss: 0.187734; batch adversarial loss: 0.395117\n",
      "epoch 92; iter: 0; batch classifier loss: 0.127617; batch adversarial loss: 0.466593\n",
      "epoch 93; iter: 0; batch classifier loss: 0.112000; batch adversarial loss: 0.480934\n",
      "epoch 94; iter: 0; batch classifier loss: 0.191145; batch adversarial loss: 0.434165\n",
      "epoch 95; iter: 0; batch classifier loss: 0.164347; batch adversarial loss: 0.470478\n",
      "epoch 96; iter: 0; batch classifier loss: 0.225813; batch adversarial loss: 0.445327\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149515; batch adversarial loss: 0.445989\n",
      "epoch 98; iter: 0; batch classifier loss: 0.159488; batch adversarial loss: 0.385154\n",
      "epoch 99; iter: 0; batch classifier loss: 0.255512; batch adversarial loss: 0.445412\n",
      "epoch 100; iter: 0; batch classifier loss: 0.116321; batch adversarial loss: 0.397122\n",
      "epoch 101; iter: 0; batch classifier loss: 0.136931; batch adversarial loss: 0.481201\n",
      "epoch 102; iter: 0; batch classifier loss: 0.159724; batch adversarial loss: 0.448192\n",
      "epoch 103; iter: 0; batch classifier loss: 0.214711; batch adversarial loss: 0.447068\n",
      "epoch 104; iter: 0; batch classifier loss: 0.101597; batch adversarial loss: 0.470757\n",
      "epoch 105; iter: 0; batch classifier loss: 0.195435; batch adversarial loss: 0.496011\n",
      "epoch 106; iter: 0; batch classifier loss: 0.163478; batch adversarial loss: 0.457673\n",
      "epoch 107; iter: 0; batch classifier loss: 0.181598; batch adversarial loss: 0.412913\n",
      "epoch 108; iter: 0; batch classifier loss: 0.229169; batch adversarial loss: 0.482565\n",
      "epoch 109; iter: 0; batch classifier loss: 0.144475; batch adversarial loss: 0.507500\n",
      "epoch 110; iter: 0; batch classifier loss: 0.172427; batch adversarial loss: 0.520148\n",
      "epoch 111; iter: 0; batch classifier loss: 0.147763; batch adversarial loss: 0.461820\n",
      "epoch 112; iter: 0; batch classifier loss: 0.136892; batch adversarial loss: 0.385757\n",
      "epoch 113; iter: 0; batch classifier loss: 0.126314; batch adversarial loss: 0.397193\n",
      "epoch 114; iter: 0; batch classifier loss: 0.159518; batch adversarial loss: 0.507346\n",
      "epoch 115; iter: 0; batch classifier loss: 0.199002; batch adversarial loss: 0.459799\n",
      "epoch 116; iter: 0; batch classifier loss: 0.158938; batch adversarial loss: 0.469453\n",
      "epoch 117; iter: 0; batch classifier loss: 0.164762; batch adversarial loss: 0.435459\n",
      "epoch 118; iter: 0; batch classifier loss: 0.154085; batch adversarial loss: 0.449511\n",
      "epoch 119; iter: 0; batch classifier loss: 0.157631; batch adversarial loss: 0.482767\n",
      "epoch 120; iter: 0; batch classifier loss: 0.174037; batch adversarial loss: 0.387095\n",
      "epoch 121; iter: 0; batch classifier loss: 0.179179; batch adversarial loss: 0.542277\n",
      "epoch 122; iter: 0; batch classifier loss: 0.199152; batch adversarial loss: 0.446228\n",
      "epoch 123; iter: 0; batch classifier loss: 0.160285; batch adversarial loss: 0.543417\n",
      "epoch 124; iter: 0; batch classifier loss: 0.197571; batch adversarial loss: 0.518618\n",
      "epoch 125; iter: 0; batch classifier loss: 0.197598; batch adversarial loss: 0.469922\n",
      "epoch 126; iter: 0; batch classifier loss: 0.135389; batch adversarial loss: 0.484592\n",
      "epoch 127; iter: 0; batch classifier loss: 0.137649; batch adversarial loss: 0.506668\n",
      "epoch 128; iter: 0; batch classifier loss: 0.141243; batch adversarial loss: 0.506732\n",
      "epoch 129; iter: 0; batch classifier loss: 0.173150; batch adversarial loss: 0.398483\n",
      "epoch 130; iter: 0; batch classifier loss: 0.160400; batch adversarial loss: 0.409412\n",
      "epoch 131; iter: 0; batch classifier loss: 0.155549; batch adversarial loss: 0.579555\n",
      "epoch 132; iter: 0; batch classifier loss: 0.143301; batch adversarial loss: 0.483904\n",
      "epoch 133; iter: 0; batch classifier loss: 0.168975; batch adversarial loss: 0.506962\n",
      "epoch 134; iter: 0; batch classifier loss: 0.181842; batch adversarial loss: 0.494434\n",
      "epoch 135; iter: 0; batch classifier loss: 0.158602; batch adversarial loss: 0.482493\n",
      "epoch 136; iter: 0; batch classifier loss: 0.144409; batch adversarial loss: 0.569199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.136394; batch adversarial loss: 0.507529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 138; iter: 0; batch classifier loss: 0.192699; batch adversarial loss: 0.432898\n",
      "epoch 139; iter: 0; batch classifier loss: 0.173610; batch adversarial loss: 0.423063\n",
      "epoch 140; iter: 0; batch classifier loss: 0.178044; batch adversarial loss: 0.591639\n",
      "epoch 141; iter: 0; batch classifier loss: 0.202117; batch adversarial loss: 0.397993\n",
      "epoch 142; iter: 0; batch classifier loss: 0.152966; batch adversarial loss: 0.494381\n",
      "epoch 143; iter: 0; batch classifier loss: 0.168534; batch adversarial loss: 0.422332\n",
      "epoch 144; iter: 0; batch classifier loss: 0.193732; batch adversarial loss: 0.458964\n",
      "epoch 145; iter: 0; batch classifier loss: 0.243760; batch adversarial loss: 0.399416\n",
      "epoch 146; iter: 0; batch classifier loss: 0.249038; batch adversarial loss: 0.482233\n",
      "epoch 147; iter: 0; batch classifier loss: 0.194706; batch adversarial loss: 0.530970\n",
      "epoch 148; iter: 0; batch classifier loss: 0.192061; batch adversarial loss: 0.398311\n",
      "epoch 149; iter: 0; batch classifier loss: 0.171107; batch adversarial loss: 0.532318\n",
      "epoch 150; iter: 0; batch classifier loss: 0.151716; batch adversarial loss: 0.362069\n",
      "epoch 151; iter: 0; batch classifier loss: 0.254567; batch adversarial loss: 0.374288\n",
      "epoch 152; iter: 0; batch classifier loss: 0.188371; batch adversarial loss: 0.410837\n",
      "epoch 153; iter: 0; batch classifier loss: 0.160384; batch adversarial loss: 0.458453\n",
      "epoch 154; iter: 0; batch classifier loss: 0.188129; batch adversarial loss: 0.482400\n",
      "epoch 155; iter: 0; batch classifier loss: 0.189979; batch adversarial loss: 0.471152\n",
      "epoch 156; iter: 0; batch classifier loss: 0.196327; batch adversarial loss: 0.398402\n",
      "epoch 157; iter: 0; batch classifier loss: 0.173656; batch adversarial loss: 0.434911\n",
      "epoch 158; iter: 0; batch classifier loss: 0.215600; batch adversarial loss: 0.482414\n",
      "epoch 159; iter: 0; batch classifier loss: 0.141023; batch adversarial loss: 0.532014\n",
      "epoch 160; iter: 0; batch classifier loss: 0.179204; batch adversarial loss: 0.409918\n",
      "epoch 161; iter: 0; batch classifier loss: 0.212462; batch adversarial loss: 0.459979\n",
      "epoch 162; iter: 0; batch classifier loss: 0.205287; batch adversarial loss: 0.471383\n",
      "epoch 163; iter: 0; batch classifier loss: 0.167815; batch adversarial loss: 0.530726\n",
      "epoch 164; iter: 0; batch classifier loss: 0.220171; batch adversarial loss: 0.337268\n",
      "epoch 165; iter: 0; batch classifier loss: 0.194137; batch adversarial loss: 0.385606\n",
      "epoch 166; iter: 0; batch classifier loss: 0.175576; batch adversarial loss: 0.409558\n",
      "epoch 167; iter: 0; batch classifier loss: 0.155805; batch adversarial loss: 0.495739\n",
      "epoch 168; iter: 0; batch classifier loss: 0.263729; batch adversarial loss: 0.409827\n",
      "epoch 169; iter: 0; batch classifier loss: 0.159487; batch adversarial loss: 0.555103\n",
      "epoch 170; iter: 0; batch classifier loss: 0.149789; batch adversarial loss: 0.373899\n",
      "epoch 171; iter: 0; batch classifier loss: 0.196912; batch adversarial loss: 0.385564\n",
      "epoch 172; iter: 0; batch classifier loss: 0.130133; batch adversarial loss: 0.530602\n",
      "epoch 173; iter: 0; batch classifier loss: 0.132517; batch adversarial loss: 0.507318\n",
      "epoch 174; iter: 0; batch classifier loss: 0.134114; batch adversarial loss: 0.444315\n",
      "epoch 175; iter: 0; batch classifier loss: 0.206127; batch adversarial loss: 0.509670\n",
      "epoch 176; iter: 0; batch classifier loss: 0.104003; batch adversarial loss: 0.434969\n",
      "epoch 177; iter: 0; batch classifier loss: 0.107975; batch adversarial loss: 0.481153\n",
      "epoch 178; iter: 0; batch classifier loss: 0.135388; batch adversarial loss: 0.458639\n",
      "epoch 179; iter: 0; batch classifier loss: 0.081091; batch adversarial loss: 0.505634\n",
      "epoch 180; iter: 0; batch classifier loss: 0.054980; batch adversarial loss: 0.459826\n",
      "epoch 181; iter: 0; batch classifier loss: 0.061671; batch adversarial loss: 0.393883\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053626; batch adversarial loss: 0.448777\n",
      "epoch 183; iter: 0; batch classifier loss: 0.072847; batch adversarial loss: 0.480348\n",
      "epoch 184; iter: 0; batch classifier loss: 0.058137; batch adversarial loss: 0.537025\n",
      "epoch 185; iter: 0; batch classifier loss: 0.046611; batch adversarial loss: 0.580616\n",
      "epoch 186; iter: 0; batch classifier loss: 0.040411; batch adversarial loss: 0.498280\n",
      "epoch 187; iter: 0; batch classifier loss: 0.061885; batch adversarial loss: 0.463286\n",
      "epoch 188; iter: 0; batch classifier loss: 0.064495; batch adversarial loss: 0.474823\n",
      "epoch 189; iter: 0; batch classifier loss: 0.047543; batch adversarial loss: 0.434195\n",
      "epoch 190; iter: 0; batch classifier loss: 0.045714; batch adversarial loss: 0.556359\n",
      "epoch 191; iter: 0; batch classifier loss: 0.048858; batch adversarial loss: 0.477197\n",
      "epoch 192; iter: 0; batch classifier loss: 0.062176; batch adversarial loss: 0.431832\n",
      "epoch 193; iter: 0; batch classifier loss: 0.055603; batch adversarial loss: 0.433329\n",
      "epoch 194; iter: 0; batch classifier loss: 0.033756; batch adversarial loss: 0.459366\n",
      "epoch 195; iter: 0; batch classifier loss: 0.035890; batch adversarial loss: 0.434038\n",
      "epoch 196; iter: 0; batch classifier loss: 0.049373; batch adversarial loss: 0.466493\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036072; batch adversarial loss: 0.494136\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019199; batch adversarial loss: 0.410384\n",
      "epoch 199; iter: 0; batch classifier loss: 0.044426; batch adversarial loss: 0.424601\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686945; batch adversarial loss: 0.865392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.802115; batch adversarial loss: 1.035893\n",
      "epoch 2; iter: 0; batch classifier loss: 0.922593; batch adversarial loss: 0.992771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.855431; batch adversarial loss: 0.885909\n",
      "epoch 4; iter: 0; batch classifier loss: 0.843907; batch adversarial loss: 0.835521\n",
      "epoch 5; iter: 0; batch classifier loss: 0.788225; batch adversarial loss: 0.767960\n",
      "epoch 6; iter: 0; batch classifier loss: 0.736973; batch adversarial loss: 0.703698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.636805; batch adversarial loss: 0.630274\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566279; batch adversarial loss: 0.568597\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468783; batch adversarial loss: 0.513967\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440788; batch adversarial loss: 0.503723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319116; batch adversarial loss: 0.489028\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398064; batch adversarial loss: 0.587134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.300026; batch adversarial loss: 0.498576\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274609; batch adversarial loss: 0.544657\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268129; batch adversarial loss: 0.452981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.154025; batch adversarial loss: 0.492611\n",
      "epoch 17; iter: 0; batch classifier loss: 0.247089; batch adversarial loss: 0.470190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229216; batch adversarial loss: 0.495250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.238809; batch adversarial loss: 0.452632\n",
      "epoch 20; iter: 0; batch classifier loss: 0.178223; batch adversarial loss: 0.455164\n",
      "epoch 21; iter: 0; batch classifier loss: 0.214375; batch adversarial loss: 0.397680\n",
      "epoch 22; iter: 0; batch classifier loss: 0.183660; batch adversarial loss: 0.489496\n",
      "epoch 23; iter: 0; batch classifier loss: 0.245990; batch adversarial loss: 0.455244\n",
      "epoch 24; iter: 0; batch classifier loss: 0.227157; batch adversarial loss: 0.413197\n",
      "epoch 25; iter: 0; batch classifier loss: 0.158893; batch adversarial loss: 0.433230\n",
      "epoch 26; iter: 0; batch classifier loss: 0.199250; batch adversarial loss: 0.409373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.173197; batch adversarial loss: 0.458960\n",
      "epoch 28; iter: 0; batch classifier loss: 0.202170; batch adversarial loss: 0.488802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150166; batch adversarial loss: 0.503385\n",
      "epoch 30; iter: 0; batch classifier loss: 0.149470; batch adversarial loss: 0.384625\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176878; batch adversarial loss: 0.518215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145773; batch adversarial loss: 0.490826\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163962; batch adversarial loss: 0.496270\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122383; batch adversarial loss: 0.424742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.153680; batch adversarial loss: 0.401486\n",
      "epoch 36; iter: 0; batch classifier loss: 0.191154; batch adversarial loss: 0.414892\n",
      "epoch 37; iter: 0; batch classifier loss: 0.146796; batch adversarial loss: 0.408789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.087501; batch adversarial loss: 0.452467\n",
      "epoch 39; iter: 0; batch classifier loss: 0.124895; batch adversarial loss: 0.503962\n",
      "epoch 40; iter: 0; batch classifier loss: 0.137539; batch adversarial loss: 0.524008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136083; batch adversarial loss: 0.427952\n",
      "epoch 42; iter: 0; batch classifier loss: 0.138008; batch adversarial loss: 0.449196\n",
      "epoch 43; iter: 0; batch classifier loss: 0.103301; batch adversarial loss: 0.449584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124897; batch adversarial loss: 0.387107\n",
      "epoch 45; iter: 0; batch classifier loss: 0.104942; batch adversarial loss: 0.463837\n",
      "epoch 46; iter: 0; batch classifier loss: 0.100712; batch adversarial loss: 0.430952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.112884; batch adversarial loss: 0.443430\n",
      "epoch 48; iter: 0; batch classifier loss: 0.140210; batch adversarial loss: 0.508951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.100733; batch adversarial loss: 0.429716\n",
      "epoch 50; iter: 0; batch classifier loss: 0.094197; batch adversarial loss: 0.380677\n",
      "epoch 51; iter: 0; batch classifier loss: 0.127541; batch adversarial loss: 0.471821\n",
      "epoch 52; iter: 0; batch classifier loss: 0.144889; batch adversarial loss: 0.525683\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084273; batch adversarial loss: 0.485872\n",
      "epoch 54; iter: 0; batch classifier loss: 0.113307; batch adversarial loss: 0.409395\n",
      "epoch 55; iter: 0; batch classifier loss: 0.120699; batch adversarial loss: 0.479673\n",
      "epoch 56; iter: 0; batch classifier loss: 0.138299; batch adversarial loss: 0.423499\n",
      "epoch 57; iter: 0; batch classifier loss: 0.073171; batch adversarial loss: 0.494202\n",
      "epoch 58; iter: 0; batch classifier loss: 0.139654; batch adversarial loss: 0.443687\n",
      "epoch 59; iter: 0; batch classifier loss: 0.147654; batch adversarial loss: 0.477758\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122144; batch adversarial loss: 0.477047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.100445; batch adversarial loss: 0.401237\n",
      "epoch 62; iter: 0; batch classifier loss: 0.096949; batch adversarial loss: 0.395987\n",
      "epoch 63; iter: 0; batch classifier loss: 0.088997; batch adversarial loss: 0.467779\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081113; batch adversarial loss: 0.543708\n",
      "epoch 65; iter: 0; batch classifier loss: 0.104904; batch adversarial loss: 0.503972\n",
      "epoch 66; iter: 0; batch classifier loss: 0.135683; batch adversarial loss: 0.355743\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062964; batch adversarial loss: 0.434022\n",
      "epoch 68; iter: 0; batch classifier loss: 0.047744; batch adversarial loss: 0.434472\n",
      "epoch 69; iter: 0; batch classifier loss: 0.102457; batch adversarial loss: 0.408427\n",
      "epoch 70; iter: 0; batch classifier loss: 0.058289; batch adversarial loss: 0.408085\n",
      "epoch 71; iter: 0; batch classifier loss: 0.119190; batch adversarial loss: 0.427244\n",
      "epoch 72; iter: 0; batch classifier loss: 0.082244; batch adversarial loss: 0.450548\n",
      "epoch 73; iter: 0; batch classifier loss: 0.085929; batch adversarial loss: 0.502609\n",
      "epoch 74; iter: 0; batch classifier loss: 0.131520; batch adversarial loss: 0.578969\n",
      "epoch 75; iter: 0; batch classifier loss: 0.100950; batch adversarial loss: 0.512046\n",
      "epoch 76; iter: 0; batch classifier loss: 0.101635; batch adversarial loss: 0.412969\n",
      "epoch 77; iter: 0; batch classifier loss: 0.081990; batch adversarial loss: 0.497861\n",
      "epoch 78; iter: 0; batch classifier loss: 0.102859; batch adversarial loss: 0.466089\n",
      "epoch 79; iter: 0; batch classifier loss: 0.124170; batch adversarial loss: 0.434395\n",
      "epoch 80; iter: 0; batch classifier loss: 0.073078; batch adversarial loss: 0.456288\n",
      "epoch 81; iter: 0; batch classifier loss: 0.118634; batch adversarial loss: 0.410156\n",
      "epoch 82; iter: 0; batch classifier loss: 0.102955; batch adversarial loss: 0.497972\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062102; batch adversarial loss: 0.456090\n",
      "epoch 84; iter: 0; batch classifier loss: 0.076604; batch adversarial loss: 0.440006\n",
      "epoch 85; iter: 0; batch classifier loss: 0.100252; batch adversarial loss: 0.462683\n",
      "epoch 86; iter: 0; batch classifier loss: 0.104951; batch adversarial loss: 0.588147\n",
      "epoch 87; iter: 0; batch classifier loss: 0.050602; batch adversarial loss: 0.615703\n",
      "epoch 88; iter: 0; batch classifier loss: 0.127109; batch adversarial loss: 0.542531\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056794; batch adversarial loss: 0.495444\n",
      "epoch 90; iter: 0; batch classifier loss: 0.083354; batch adversarial loss: 0.495540\n",
      "epoch 91; iter: 0; batch classifier loss: 0.087158; batch adversarial loss: 0.419193\n",
      "epoch 92; iter: 0; batch classifier loss: 0.094244; batch adversarial loss: 0.408634\n",
      "epoch 93; iter: 0; batch classifier loss: 0.094654; batch adversarial loss: 0.496098\n",
      "epoch 94; iter: 0; batch classifier loss: 0.050980; batch adversarial loss: 0.398870\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075978; batch adversarial loss: 0.475360\n",
      "epoch 96; iter: 0; batch classifier loss: 0.109556; batch adversarial loss: 0.545777\n",
      "epoch 97; iter: 0; batch classifier loss: 0.096419; batch adversarial loss: 0.456733\n",
      "epoch 98; iter: 0; batch classifier loss: 0.107530; batch adversarial loss: 0.557758\n",
      "epoch 99; iter: 0; batch classifier loss: 0.100864; batch adversarial loss: 0.420558\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072128; batch adversarial loss: 0.465312\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062359; batch adversarial loss: 0.377941\n",
      "epoch 102; iter: 0; batch classifier loss: 0.043712; batch adversarial loss: 0.473146\n",
      "epoch 103; iter: 0; batch classifier loss: 0.068964; batch adversarial loss: 0.466960\n",
      "epoch 104; iter: 0; batch classifier loss: 0.092830; batch adversarial loss: 0.428063\n",
      "epoch 105; iter: 0; batch classifier loss: 0.063281; batch adversarial loss: 0.554909\n",
      "epoch 106; iter: 0; batch classifier loss: 0.108219; batch adversarial loss: 0.504201\n",
      "epoch 107; iter: 0; batch classifier loss: 0.061795; batch adversarial loss: 0.380009\n",
      "epoch 108; iter: 0; batch classifier loss: 0.101016; batch adversarial loss: 0.387140\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038918; batch adversarial loss: 0.424567\n",
      "epoch 110; iter: 0; batch classifier loss: 0.079499; batch adversarial loss: 0.503515\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081440; batch adversarial loss: 0.314525\n",
      "epoch 112; iter: 0; batch classifier loss: 0.073398; batch adversarial loss: 0.428329\n",
      "epoch 113; iter: 0; batch classifier loss: 0.109636; batch adversarial loss: 0.393293\n",
      "epoch 114; iter: 0; batch classifier loss: 0.081711; batch adversarial loss: 0.478918\n",
      "epoch 115; iter: 0; batch classifier loss: 0.097895; batch adversarial loss: 0.450365\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074579; batch adversarial loss: 0.436840\n",
      "epoch 117; iter: 0; batch classifier loss: 0.119381; batch adversarial loss: 0.475831\n",
      "epoch 118; iter: 0; batch classifier loss: 0.112054; batch adversarial loss: 0.430132\n",
      "epoch 119; iter: 0; batch classifier loss: 0.042391; batch adversarial loss: 0.499875\n",
      "epoch 120; iter: 0; batch classifier loss: 0.096116; batch adversarial loss: 0.518560\n",
      "epoch 121; iter: 0; batch classifier loss: 0.058710; batch adversarial loss: 0.541486\n",
      "epoch 122; iter: 0; batch classifier loss: 0.034164; batch adversarial loss: 0.447737\n",
      "epoch 123; iter: 0; batch classifier loss: 0.081836; batch adversarial loss: 0.503447\n",
      "epoch 124; iter: 0; batch classifier loss: 0.051061; batch adversarial loss: 0.412910\n",
      "epoch 125; iter: 0; batch classifier loss: 0.037403; batch adversarial loss: 0.516763\n",
      "epoch 126; iter: 0; batch classifier loss: 0.067257; batch adversarial loss: 0.546307\n",
      "epoch 127; iter: 0; batch classifier loss: 0.141905; batch adversarial loss: 0.331477\n",
      "epoch 128; iter: 0; batch classifier loss: 0.075139; batch adversarial loss: 0.523293\n",
      "epoch 129; iter: 0; batch classifier loss: 0.090329; batch adversarial loss: 0.410301\n",
      "epoch 130; iter: 0; batch classifier loss: 0.062549; batch adversarial loss: 0.430016\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055272; batch adversarial loss: 0.516529\n",
      "epoch 132; iter: 0; batch classifier loss: 0.084213; batch adversarial loss: 0.514413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.076371; batch adversarial loss: 0.428460\n",
      "epoch 134; iter: 0; batch classifier loss: 0.070331; batch adversarial loss: 0.438277\n",
      "epoch 135; iter: 0; batch classifier loss: 0.087263; batch adversarial loss: 0.385339\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039758; batch adversarial loss: 0.438609\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054225; batch adversarial loss: 0.426744\n",
      "epoch 138; iter: 0; batch classifier loss: 0.072983; batch adversarial loss: 0.498883\n",
      "epoch 139; iter: 0; batch classifier loss: 0.055571; batch adversarial loss: 0.445250\n",
      "epoch 140; iter: 0; batch classifier loss: 0.078579; batch adversarial loss: 0.364568\n",
      "epoch 141; iter: 0; batch classifier loss: 0.025901; batch adversarial loss: 0.462799\n",
      "epoch 142; iter: 0; batch classifier loss: 0.050653; batch adversarial loss: 0.467224\n",
      "epoch 143; iter: 0; batch classifier loss: 0.031973; batch adversarial loss: 0.381006\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036891; batch adversarial loss: 0.351517\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037580; batch adversarial loss: 0.327908\n",
      "epoch 146; iter: 0; batch classifier loss: 0.046275; batch adversarial loss: 0.460324\n",
      "epoch 147; iter: 0; batch classifier loss: 0.028626; batch adversarial loss: 0.414540\n",
      "epoch 148; iter: 0; batch classifier loss: 0.072493; batch adversarial loss: 0.446282\n",
      "epoch 149; iter: 0; batch classifier loss: 0.062831; batch adversarial loss: 0.444354\n",
      "epoch 150; iter: 0; batch classifier loss: 0.033963; batch adversarial loss: 0.396784\n",
      "epoch 151; iter: 0; batch classifier loss: 0.054142; batch adversarial loss: 0.447165\n",
      "epoch 152; iter: 0; batch classifier loss: 0.063538; batch adversarial loss: 0.405546\n",
      "epoch 153; iter: 0; batch classifier loss: 0.056515; batch adversarial loss: 0.438869\n",
      "epoch 154; iter: 0; batch classifier loss: 0.047287; batch adversarial loss: 0.436581\n",
      "epoch 155; iter: 0; batch classifier loss: 0.047712; batch adversarial loss: 0.459360\n",
      "epoch 156; iter: 0; batch classifier loss: 0.045071; batch adversarial loss: 0.447856\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034795; batch adversarial loss: 0.456633\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040010; batch adversarial loss: 0.444170\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013797; batch adversarial loss: 0.495768\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033986; batch adversarial loss: 0.355570\n",
      "epoch 161; iter: 0; batch classifier loss: 0.042803; batch adversarial loss: 0.355991\n",
      "epoch 162; iter: 0; batch classifier loss: 0.035617; batch adversarial loss: 0.444424\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023921; batch adversarial loss: 0.505687\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030390; batch adversarial loss: 0.419966\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027495; batch adversarial loss: 0.528059\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028831; batch adversarial loss: 0.499505\n",
      "epoch 167; iter: 0; batch classifier loss: 0.026016; batch adversarial loss: 0.352586\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026111; batch adversarial loss: 0.561572\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016800; batch adversarial loss: 0.440442\n",
      "epoch 170; iter: 0; batch classifier loss: 0.054166; batch adversarial loss: 0.370978\n",
      "epoch 171; iter: 0; batch classifier loss: 0.020491; batch adversarial loss: 0.423334\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039663; batch adversarial loss: 0.521250\n",
      "epoch 173; iter: 0; batch classifier loss: 0.046420; batch adversarial loss: 0.484900\n",
      "epoch 174; iter: 0; batch classifier loss: 0.019778; batch adversarial loss: 0.467160\n",
      "epoch 175; iter: 0; batch classifier loss: 0.040808; batch adversarial loss: 0.419088\n",
      "epoch 176; iter: 0; batch classifier loss: 0.037803; batch adversarial loss: 0.477659\n",
      "epoch 177; iter: 0; batch classifier loss: 0.054198; batch adversarial loss: 0.458390\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012120; batch adversarial loss: 0.468908\n",
      "epoch 179; iter: 0; batch classifier loss: 0.040537; batch adversarial loss: 0.508285\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035099; batch adversarial loss: 0.508703\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046321; batch adversarial loss: 0.533552\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021219; batch adversarial loss: 0.387635\n",
      "epoch 183; iter: 0; batch classifier loss: 0.025133; batch adversarial loss: 0.356933\n",
      "epoch 184; iter: 0; batch classifier loss: 0.011671; batch adversarial loss: 0.384594\n",
      "epoch 185; iter: 0; batch classifier loss: 0.042196; batch adversarial loss: 0.484031\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013423; batch adversarial loss: 0.437593\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042135; batch adversarial loss: 0.434153\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009351; batch adversarial loss: 0.397999\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007600; batch adversarial loss: 0.475897\n",
      "epoch 190; iter: 0; batch classifier loss: 0.030793; batch adversarial loss: 0.418665\n",
      "epoch 191; iter: 0; batch classifier loss: 0.020338; batch adversarial loss: 0.346176\n",
      "epoch 192; iter: 0; batch classifier loss: 0.007029; batch adversarial loss: 0.414865\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026787; batch adversarial loss: 0.364915\n",
      "epoch 194; iter: 0; batch classifier loss: 0.010672; batch adversarial loss: 0.370108\n",
      "epoch 195; iter: 0; batch classifier loss: 0.008735; batch adversarial loss: 0.415671\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019672; batch adversarial loss: 0.378946\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024422; batch adversarial loss: 0.465448\n",
      "epoch 198; iter: 0; batch classifier loss: 0.010071; batch adversarial loss: 0.404726\n",
      "epoch 199; iter: 0; batch classifier loss: 0.024072; batch adversarial loss: 0.440399\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691192; batch adversarial loss: 0.778031\n",
      "epoch 1; iter: 0; batch classifier loss: 0.483985; batch adversarial loss: 0.730943\n",
      "epoch 2; iter: 0; batch classifier loss: 0.506733; batch adversarial loss: 0.674138\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603826; batch adversarial loss: 0.628027\n",
      "epoch 4; iter: 0; batch classifier loss: 0.415608; batch adversarial loss: 0.605446\n",
      "epoch 5; iter: 0; batch classifier loss: 0.403273; batch adversarial loss: 0.569711\n",
      "epoch 6; iter: 0; batch classifier loss: 0.276720; batch adversarial loss: 0.568318\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354728; batch adversarial loss: 0.559132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390601; batch adversarial loss: 0.578624\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346515; batch adversarial loss: 0.583691\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333824; batch adversarial loss: 0.515287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426275; batch adversarial loss: 0.502091\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310888; batch adversarial loss: 0.512029\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282866; batch adversarial loss: 0.527949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.275727; batch adversarial loss: 0.508780\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306711; batch adversarial loss: 0.470818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359145; batch adversarial loss: 0.564709\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372951; batch adversarial loss: 0.482486\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388673; batch adversarial loss: 0.526061\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318643; batch adversarial loss: 0.428263\n",
      "epoch 20; iter: 0; batch classifier loss: 0.332140; batch adversarial loss: 0.508139\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285626; batch adversarial loss: 0.559907\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275814; batch adversarial loss: 0.539107\n",
      "epoch 23; iter: 0; batch classifier loss: 0.281189; batch adversarial loss: 0.445416\n",
      "epoch 24; iter: 0; batch classifier loss: 0.311658; batch adversarial loss: 0.478416\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349560; batch adversarial loss: 0.528589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308460; batch adversarial loss: 0.594122\n",
      "epoch 27; iter: 0; batch classifier loss: 0.250705; batch adversarial loss: 0.557467\n",
      "epoch 28; iter: 0; batch classifier loss: 0.231707; batch adversarial loss: 0.521363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.283590; batch adversarial loss: 0.510790\n",
      "epoch 30; iter: 0; batch classifier loss: 0.293005; batch adversarial loss: 0.493013\n",
      "epoch 31; iter: 0; batch classifier loss: 0.241361; batch adversarial loss: 0.434987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279488; batch adversarial loss: 0.517566\n",
      "epoch 33; iter: 0; batch classifier loss: 0.243964; batch adversarial loss: 0.476928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236516; batch adversarial loss: 0.473721\n",
      "epoch 35; iter: 0; batch classifier loss: 0.251273; batch adversarial loss: 0.464190\n",
      "epoch 36; iter: 0; batch classifier loss: 0.233182; batch adversarial loss: 0.524451\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283974; batch adversarial loss: 0.430785\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259628; batch adversarial loss: 0.584452\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246599; batch adversarial loss: 0.474232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.212119; batch adversarial loss: 0.422475\n",
      "epoch 41; iter: 0; batch classifier loss: 0.194348; batch adversarial loss: 0.419010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251452; batch adversarial loss: 0.438851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.241272; batch adversarial loss: 0.401292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.277344; batch adversarial loss: 0.452907\n",
      "epoch 45; iter: 0; batch classifier loss: 0.216244; batch adversarial loss: 0.477824\n",
      "epoch 46; iter: 0; batch classifier loss: 0.188737; batch adversarial loss: 0.468276\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192745; batch adversarial loss: 0.460532\n",
      "epoch 48; iter: 0; batch classifier loss: 0.206477; batch adversarial loss: 0.451802\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246847; batch adversarial loss: 0.367444\n",
      "epoch 50; iter: 0; batch classifier loss: 0.188118; batch adversarial loss: 0.495889\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231061; batch adversarial loss: 0.483599\n",
      "epoch 52; iter: 0; batch classifier loss: 0.250686; batch adversarial loss: 0.529234\n",
      "epoch 53; iter: 0; batch classifier loss: 0.151085; batch adversarial loss: 0.518672\n",
      "epoch 54; iter: 0; batch classifier loss: 0.189240; batch adversarial loss: 0.411988\n",
      "epoch 55; iter: 0; batch classifier loss: 0.205258; batch adversarial loss: 0.423413\n",
      "epoch 56; iter: 0; batch classifier loss: 0.221170; batch adversarial loss: 0.494594\n",
      "epoch 57; iter: 0; batch classifier loss: 0.181756; batch adversarial loss: 0.459042\n",
      "epoch 58; iter: 0; batch classifier loss: 0.162169; batch adversarial loss: 0.470740\n",
      "epoch 59; iter: 0; batch classifier loss: 0.203201; batch adversarial loss: 0.459221\n",
      "epoch 60; iter: 0; batch classifier loss: 0.146772; batch adversarial loss: 0.566947\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118621; batch adversarial loss: 0.447227\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071919; batch adversarial loss: 0.449966\n",
      "epoch 63; iter: 0; batch classifier loss: 0.199454; batch adversarial loss: 0.510188\n",
      "epoch 64; iter: 0; batch classifier loss: 0.248078; batch adversarial loss: 0.434854\n",
      "epoch 65; iter: 0; batch classifier loss: 0.105749; batch adversarial loss: 0.541711\n",
      "epoch 66; iter: 0; batch classifier loss: 0.191289; batch adversarial loss: 0.446631\n",
      "epoch 67; iter: 0; batch classifier loss: 0.197168; batch adversarial loss: 0.495013\n",
      "epoch 68; iter: 0; batch classifier loss: 0.305485; batch adversarial loss: 0.446765\n",
      "epoch 69; iter: 0; batch classifier loss: 0.200892; batch adversarial loss: 0.422670\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109565; batch adversarial loss: 0.409564\n",
      "epoch 71; iter: 0; batch classifier loss: 0.134388; batch adversarial loss: 0.491254\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187444; batch adversarial loss: 0.409831\n",
      "epoch 73; iter: 0; batch classifier loss: 0.274420; batch adversarial loss: 0.446738\n",
      "epoch 74; iter: 0; batch classifier loss: 0.241412; batch adversarial loss: 0.518931\n",
      "epoch 75; iter: 0; batch classifier loss: 0.262312; batch adversarial loss: 0.433248\n",
      "epoch 76; iter: 0; batch classifier loss: 0.146392; batch adversarial loss: 0.556041\n",
      "epoch 77; iter: 0; batch classifier loss: 0.177608; batch adversarial loss: 0.435784\n",
      "epoch 78; iter: 0; batch classifier loss: 0.158685; batch adversarial loss: 0.314507\n",
      "epoch 79; iter: 0; batch classifier loss: 0.167340; batch adversarial loss: 0.410453\n",
      "epoch 80; iter: 0; batch classifier loss: 0.122487; batch adversarial loss: 0.447161\n",
      "epoch 81; iter: 0; batch classifier loss: 0.171963; batch adversarial loss: 0.351199\n",
      "epoch 82; iter: 0; batch classifier loss: 0.224656; batch adversarial loss: 0.411476\n",
      "epoch 83; iter: 0; batch classifier loss: 0.162959; batch adversarial loss: 0.530866\n",
      "epoch 84; iter: 0; batch classifier loss: 0.132710; batch adversarial loss: 0.446056\n",
      "epoch 85; iter: 0; batch classifier loss: 0.061707; batch adversarial loss: 0.516642\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049563; batch adversarial loss: 0.467509\n",
      "epoch 87; iter: 0; batch classifier loss: 0.029739; batch adversarial loss: 0.515918\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087322; batch adversarial loss: 0.360881\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071753; batch adversarial loss: 0.440645\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037853; batch adversarial loss: 0.521568\n",
      "epoch 91; iter: 0; batch classifier loss: 0.059711; batch adversarial loss: 0.412221\n",
      "epoch 92; iter: 0; batch classifier loss: 0.052774; batch adversarial loss: 0.423039\n",
      "epoch 93; iter: 0; batch classifier loss: 0.048075; batch adversarial loss: 0.447526\n",
      "epoch 94; iter: 0; batch classifier loss: 0.048236; batch adversarial loss: 0.422211\n",
      "epoch 95; iter: 0; batch classifier loss: 0.122168; batch adversarial loss: 0.444664\n",
      "epoch 96; iter: 0; batch classifier loss: 0.026968; batch adversarial loss: 0.526219\n",
      "epoch 97; iter: 0; batch classifier loss: 0.042398; batch adversarial loss: 0.429545\n",
      "epoch 98; iter: 0; batch classifier loss: 0.033940; batch adversarial loss: 0.418815\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069295; batch adversarial loss: 0.407226\n",
      "epoch 100; iter: 0; batch classifier loss: 0.041642; batch adversarial loss: 0.501953\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044573; batch adversarial loss: 0.460738\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034780; batch adversarial loss: 0.470475\n",
      "epoch 103; iter: 0; batch classifier loss: 0.046937; batch adversarial loss: 0.450284\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053816; batch adversarial loss: 0.424816\n",
      "epoch 105; iter: 0; batch classifier loss: 0.069896; batch adversarial loss: 0.448188\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044305; batch adversarial loss: 0.382264\n",
      "epoch 107; iter: 0; batch classifier loss: 0.055000; batch adversarial loss: 0.509302\n",
      "epoch 108; iter: 0; batch classifier loss: 0.011064; batch adversarial loss: 0.509329\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033288; batch adversarial loss: 0.413791\n",
      "epoch 110; iter: 0; batch classifier loss: 0.016012; batch adversarial loss: 0.513132\n",
      "epoch 111; iter: 0; batch classifier loss: 0.056560; batch adversarial loss: 0.525831\n",
      "epoch 112; iter: 0; batch classifier loss: 0.027886; batch adversarial loss: 0.427922\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029035; batch adversarial loss: 0.466297\n",
      "epoch 114; iter: 0; batch classifier loss: 0.048322; batch adversarial loss: 0.386108\n",
      "epoch 115; iter: 0; batch classifier loss: 0.029281; batch adversarial loss: 0.404331\n",
      "epoch 116; iter: 0; batch classifier loss: 0.036739; batch adversarial loss: 0.416995\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017689; batch adversarial loss: 0.469819\n",
      "epoch 118; iter: 0; batch classifier loss: 0.026244; batch adversarial loss: 0.408894\n",
      "epoch 119; iter: 0; batch classifier loss: 0.027233; batch adversarial loss: 0.459227\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025057; batch adversarial loss: 0.407975\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030389; batch adversarial loss: 0.565589\n",
      "epoch 122; iter: 0; batch classifier loss: 0.018301; batch adversarial loss: 0.453961\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032553; batch adversarial loss: 0.491062\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030733; batch adversarial loss: 0.531398\n",
      "epoch 125; iter: 0; batch classifier loss: 0.082741; batch adversarial loss: 0.461772\n",
      "epoch 126; iter: 0; batch classifier loss: 0.013694; batch adversarial loss: 0.348922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127; iter: 0; batch classifier loss: 0.033962; batch adversarial loss: 0.441932\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026187; batch adversarial loss: 0.462526\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036227; batch adversarial loss: 0.424119\n",
      "epoch 130; iter: 0; batch classifier loss: 0.036494; batch adversarial loss: 0.431417\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021882; batch adversarial loss: 0.486042\n",
      "epoch 132; iter: 0; batch classifier loss: 0.016154; batch adversarial loss: 0.415594\n",
      "epoch 133; iter: 0; batch classifier loss: 0.025091; batch adversarial loss: 0.422504\n",
      "epoch 134; iter: 0; batch classifier loss: 0.009022; batch adversarial loss: 0.359842\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030323; batch adversarial loss: 0.340376\n",
      "epoch 136; iter: 0; batch classifier loss: 0.013499; batch adversarial loss: 0.418949\n",
      "epoch 137; iter: 0; batch classifier loss: 0.026267; batch adversarial loss: 0.461093\n",
      "epoch 138; iter: 0; batch classifier loss: 0.018454; batch adversarial loss: 0.473260\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025948; batch adversarial loss: 0.389933\n",
      "epoch 140; iter: 0; batch classifier loss: 0.043510; batch adversarial loss: 0.370294\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037756; batch adversarial loss: 0.491556\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029323; batch adversarial loss: 0.519224\n",
      "epoch 143; iter: 0; batch classifier loss: 0.010487; batch adversarial loss: 0.498155\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.356412\n",
      "epoch 145; iter: 0; batch classifier loss: 0.053151; batch adversarial loss: 0.457563\n",
      "epoch 146; iter: 0; batch classifier loss: 0.033406; batch adversarial loss: 0.388402\n",
      "epoch 147; iter: 0; batch classifier loss: 0.026957; batch adversarial loss: 0.496394\n",
      "epoch 148; iter: 0; batch classifier loss: 0.019614; batch adversarial loss: 0.456006\n",
      "epoch 149; iter: 0; batch classifier loss: 0.025465; batch adversarial loss: 0.508345\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025513; batch adversarial loss: 0.445814\n",
      "epoch 151; iter: 0; batch classifier loss: 0.022072; batch adversarial loss: 0.471894\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025156; batch adversarial loss: 0.530945\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027776; batch adversarial loss: 0.435212\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020542; batch adversarial loss: 0.542370\n",
      "epoch 155; iter: 0; batch classifier loss: 0.022644; batch adversarial loss: 0.398466\n",
      "epoch 156; iter: 0; batch classifier loss: 0.004592; batch adversarial loss: 0.534910\n",
      "epoch 157; iter: 0; batch classifier loss: 0.024655; batch adversarial loss: 0.433000\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008348; batch adversarial loss: 0.519266\n",
      "epoch 159; iter: 0; batch classifier loss: 0.042175; batch adversarial loss: 0.463170\n",
      "epoch 160; iter: 0; batch classifier loss: 0.009440; batch adversarial loss: 0.443674\n",
      "epoch 161; iter: 0; batch classifier loss: 0.007711; batch adversarial loss: 0.422664\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027069; batch adversarial loss: 0.514339\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035031; batch adversarial loss: 0.444305\n",
      "epoch 164; iter: 0; batch classifier loss: 0.003728; batch adversarial loss: 0.397768\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023942; batch adversarial loss: 0.448195\n",
      "epoch 166; iter: 0; batch classifier loss: 0.005000; batch adversarial loss: 0.489886\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016236; batch adversarial loss: 0.489328\n",
      "epoch 168; iter: 0; batch classifier loss: 0.013219; batch adversarial loss: 0.442656\n",
      "epoch 169; iter: 0; batch classifier loss: 0.039226; batch adversarial loss: 0.470209\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011596; batch adversarial loss: 0.428046\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026448; batch adversarial loss: 0.452454\n",
      "epoch 172; iter: 0; batch classifier loss: 0.014515; batch adversarial loss: 0.416736\n",
      "epoch 173; iter: 0; batch classifier loss: 0.026671; batch adversarial loss: 0.505031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.014228; batch adversarial loss: 0.467457\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021309; batch adversarial loss: 0.517175\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016085; batch adversarial loss: 0.380559\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019381; batch adversarial loss: 0.408169\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012244; batch adversarial loss: 0.436792\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007450; batch adversarial loss: 0.452397\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025680; batch adversarial loss: 0.423424\n",
      "epoch 181; iter: 0; batch classifier loss: 0.013864; batch adversarial loss: 0.466967\n",
      "epoch 182; iter: 0; batch classifier loss: 0.007923; batch adversarial loss: 0.501898\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010939; batch adversarial loss: 0.474273\n",
      "epoch 184; iter: 0; batch classifier loss: 0.024079; batch adversarial loss: 0.459324\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016790; batch adversarial loss: 0.440271\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006488; batch adversarial loss: 0.534270\n",
      "epoch 187; iter: 0; batch classifier loss: 0.021196; batch adversarial loss: 0.442992\n",
      "epoch 188; iter: 0; batch classifier loss: 0.033940; batch adversarial loss: 0.441749\n",
      "epoch 189; iter: 0; batch classifier loss: 0.012128; batch adversarial loss: 0.469834\n",
      "epoch 190; iter: 0; batch classifier loss: 0.015884; batch adversarial loss: 0.369890\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022349; batch adversarial loss: 0.410794\n",
      "epoch 192; iter: 0; batch classifier loss: 0.009660; batch adversarial loss: 0.367508\n",
      "epoch 193; iter: 0; batch classifier loss: 0.014551; batch adversarial loss: 0.421567\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028465; batch adversarial loss: 0.440709\n",
      "epoch 195; iter: 0; batch classifier loss: 0.016921; batch adversarial loss: 0.453315\n",
      "epoch 196; iter: 0; batch classifier loss: 0.005292; batch adversarial loss: 0.469677\n",
      "epoch 197; iter: 0; batch classifier loss: 0.012590; batch adversarial loss: 0.546422\n",
      "epoch 198; iter: 0; batch classifier loss: 0.016552; batch adversarial loss: 0.380057\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031798; batch adversarial loss: 0.531772\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746129; batch adversarial loss: 0.725464\n",
      "epoch 1; iter: 0; batch classifier loss: 0.449134; batch adversarial loss: 0.692307\n",
      "epoch 2; iter: 0; batch classifier loss: 0.389722; batch adversarial loss: 0.665782\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406831; batch adversarial loss: 0.647429\n",
      "epoch 4; iter: 0; batch classifier loss: 0.309501; batch adversarial loss: 0.585809\n",
      "epoch 5; iter: 0; batch classifier loss: 0.335695; batch adversarial loss: 0.555815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421159; batch adversarial loss: 0.488995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288756; batch adversarial loss: 0.522337\n",
      "epoch 8; iter: 0; batch classifier loss: 0.329535; batch adversarial loss: 0.509891\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324757; batch adversarial loss: 0.487502\n",
      "epoch 10; iter: 0; batch classifier loss: 0.271112; batch adversarial loss: 0.487239\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240759; batch adversarial loss: 0.493617\n",
      "epoch 12; iter: 0; batch classifier loss: 0.243134; batch adversarial loss: 0.426841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224235; batch adversarial loss: 0.509525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249871; batch adversarial loss: 0.412557\n",
      "epoch 15; iter: 0; batch classifier loss: 0.166417; batch adversarial loss: 0.490804\n",
      "epoch 16; iter: 0; batch classifier loss: 0.161062; batch adversarial loss: 0.519959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.158087; batch adversarial loss: 0.448086\n",
      "epoch 18; iter: 0; batch classifier loss: 0.147136; batch adversarial loss: 0.441778\n",
      "epoch 19; iter: 0; batch classifier loss: 0.198854; batch adversarial loss: 0.476409\n",
      "epoch 20; iter: 0; batch classifier loss: 0.204317; batch adversarial loss: 0.386912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161921; batch adversarial loss: 0.453078\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196623; batch adversarial loss: 0.460563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.111824; batch adversarial loss: 0.411024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.162462; batch adversarial loss: 0.401532\n",
      "epoch 25; iter: 0; batch classifier loss: 0.154987; batch adversarial loss: 0.450848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.104538; batch adversarial loss: 0.469816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167884; batch adversarial loss: 0.403718\n",
      "epoch 28; iter: 0; batch classifier loss: 0.164071; batch adversarial loss: 0.405839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.135931; batch adversarial loss: 0.458714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116265; batch adversarial loss: 0.416837\n",
      "epoch 31; iter: 0; batch classifier loss: 0.187008; batch adversarial loss: 0.436393\n",
      "epoch 32; iter: 0; batch classifier loss: 0.117291; batch adversarial loss: 0.387526\n",
      "epoch 33; iter: 0; batch classifier loss: 0.163405; batch adversarial loss: 0.455162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.092088; batch adversarial loss: 0.405327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.187570; batch adversarial loss: 0.413870\n",
      "epoch 36; iter: 0; batch classifier loss: 0.085671; batch adversarial loss: 0.346678\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136287; batch adversarial loss: 0.389470\n",
      "epoch 38; iter: 0; batch classifier loss: 0.117796; batch adversarial loss: 0.368952\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114487; batch adversarial loss: 0.417989\n",
      "epoch 40; iter: 0; batch classifier loss: 0.117485; batch adversarial loss: 0.490774\n",
      "epoch 41; iter: 0; batch classifier loss: 0.143057; batch adversarial loss: 0.385000\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095198; batch adversarial loss: 0.348569\n",
      "epoch 43; iter: 0; batch classifier loss: 0.097910; batch adversarial loss: 0.324628\n",
      "epoch 44; iter: 0; batch classifier loss: 0.110209; batch adversarial loss: 0.472049\n",
      "epoch 45; iter: 0; batch classifier loss: 0.142225; batch adversarial loss: 0.453885\n",
      "epoch 46; iter: 0; batch classifier loss: 0.069756; batch adversarial loss: 0.506370\n",
      "epoch 47; iter: 0; batch classifier loss: 0.051615; batch adversarial loss: 0.387407\n",
      "epoch 48; iter: 0; batch classifier loss: 0.083616; batch adversarial loss: 0.389508\n",
      "epoch 49; iter: 0; batch classifier loss: 0.064514; batch adversarial loss: 0.402165\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089483; batch adversarial loss: 0.376405\n",
      "epoch 51; iter: 0; batch classifier loss: 0.074330; batch adversarial loss: 0.507169\n",
      "epoch 52; iter: 0; batch classifier loss: 0.041157; batch adversarial loss: 0.406886\n",
      "epoch 53; iter: 0; batch classifier loss: 0.084398; batch adversarial loss: 0.448245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.074298; batch adversarial loss: 0.416090\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062313; batch adversarial loss: 0.363466\n",
      "epoch 56; iter: 0; batch classifier loss: 0.075503; batch adversarial loss: 0.453251\n",
      "epoch 57; iter: 0; batch classifier loss: 0.062784; batch adversarial loss: 0.397784\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082441; batch adversarial loss: 0.409456\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084840; batch adversarial loss: 0.422096\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066699; batch adversarial loss: 0.391387\n",
      "epoch 61; iter: 0; batch classifier loss: 0.053793; batch adversarial loss: 0.374222\n",
      "epoch 62; iter: 0; batch classifier loss: 0.072734; batch adversarial loss: 0.455987\n",
      "epoch 63; iter: 0; batch classifier loss: 0.114689; batch adversarial loss: 0.379342\n",
      "epoch 64; iter: 0; batch classifier loss: 0.076653; batch adversarial loss: 0.449369\n",
      "epoch 65; iter: 0; batch classifier loss: 0.082661; batch adversarial loss: 0.430910\n",
      "epoch 66; iter: 0; batch classifier loss: 0.047370; batch adversarial loss: 0.376366\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095094; batch adversarial loss: 0.415735\n",
      "epoch 68; iter: 0; batch classifier loss: 0.050159; batch adversarial loss: 0.417151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.068484; batch adversarial loss: 0.430131\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120306; batch adversarial loss: 0.506461\n",
      "epoch 71; iter: 0; batch classifier loss: 0.064216; batch adversarial loss: 0.359716\n",
      "epoch 72; iter: 0; batch classifier loss: 0.049441; batch adversarial loss: 0.394587\n",
      "epoch 73; iter: 0; batch classifier loss: 0.088811; batch adversarial loss: 0.386675\n",
      "epoch 74; iter: 0; batch classifier loss: 0.096961; batch adversarial loss: 0.407022\n",
      "epoch 75; iter: 0; batch classifier loss: 0.066244; batch adversarial loss: 0.361420\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090756; batch adversarial loss: 0.422840\n",
      "epoch 77; iter: 0; batch classifier loss: 0.112963; batch adversarial loss: 0.374041\n",
      "epoch 78; iter: 0; batch classifier loss: 0.066624; batch adversarial loss: 0.490245\n",
      "epoch 79; iter: 0; batch classifier loss: 0.058229; batch adversarial loss: 0.315464\n",
      "epoch 80; iter: 0; batch classifier loss: 0.074994; batch adversarial loss: 0.441737\n",
      "epoch 81; iter: 0; batch classifier loss: 0.088326; batch adversarial loss: 0.400103\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083689; batch adversarial loss: 0.430886\n",
      "epoch 83; iter: 0; batch classifier loss: 0.060092; batch adversarial loss: 0.353246\n",
      "epoch 84; iter: 0; batch classifier loss: 0.077594; batch adversarial loss: 0.380988\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075234; batch adversarial loss: 0.397546\n",
      "epoch 86; iter: 0; batch classifier loss: 0.036811; batch adversarial loss: 0.395662\n",
      "epoch 87; iter: 0; batch classifier loss: 0.090328; batch adversarial loss: 0.409889\n",
      "epoch 88; iter: 0; batch classifier loss: 0.072110; batch adversarial loss: 0.396587\n",
      "epoch 89; iter: 0; batch classifier loss: 0.079600; batch adversarial loss: 0.375297\n",
      "epoch 90; iter: 0; batch classifier loss: 0.067448; batch adversarial loss: 0.370276\n",
      "epoch 91; iter: 0; batch classifier loss: 0.057030; batch adversarial loss: 0.413406\n",
      "epoch 92; iter: 0; batch classifier loss: 0.069331; batch adversarial loss: 0.446247\n",
      "epoch 93; iter: 0; batch classifier loss: 0.039110; batch adversarial loss: 0.401074\n",
      "epoch 94; iter: 0; batch classifier loss: 0.071689; batch adversarial loss: 0.413442\n",
      "epoch 95; iter: 0; batch classifier loss: 0.033962; batch adversarial loss: 0.314283\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070070; batch adversarial loss: 0.444360\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047860; batch adversarial loss: 0.345798\n",
      "epoch 98; iter: 0; batch classifier loss: 0.024131; batch adversarial loss: 0.456904\n",
      "epoch 99; iter: 0; batch classifier loss: 0.041060; batch adversarial loss: 0.297895\n",
      "epoch 100; iter: 0; batch classifier loss: 0.061840; batch adversarial loss: 0.404428\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062906; batch adversarial loss: 0.482969\n",
      "epoch 102; iter: 0; batch classifier loss: 0.049268; batch adversarial loss: 0.317021\n",
      "epoch 103; iter: 0; batch classifier loss: 0.072409; batch adversarial loss: 0.443830\n",
      "epoch 104; iter: 0; batch classifier loss: 0.052870; batch adversarial loss: 0.373787\n",
      "epoch 105; iter: 0; batch classifier loss: 0.093470; batch adversarial loss: 0.452946\n",
      "epoch 106; iter: 0; batch classifier loss: 0.051198; batch adversarial loss: 0.395441\n",
      "epoch 107; iter: 0; batch classifier loss: 0.067358; batch adversarial loss: 0.410150\n",
      "epoch 108; iter: 0; batch classifier loss: 0.042076; batch adversarial loss: 0.480323\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030606; batch adversarial loss: 0.433613\n",
      "epoch 110; iter: 0; batch classifier loss: 0.053717; batch adversarial loss: 0.387907\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050907; batch adversarial loss: 0.393489\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032707; batch adversarial loss: 0.470622\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029545; batch adversarial loss: 0.387777\n",
      "epoch 114; iter: 0; batch classifier loss: 0.060862; batch adversarial loss: 0.420519\n",
      "epoch 115; iter: 0; batch classifier loss: 0.022184; batch adversarial loss: 0.515997\n",
      "epoch 116; iter: 0; batch classifier loss: 0.065506; batch adversarial loss: 0.400006\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032613; batch adversarial loss: 0.393404\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037028; batch adversarial loss: 0.389669\n",
      "epoch 119; iter: 0; batch classifier loss: 0.057464; batch adversarial loss: 0.424239\n",
      "epoch 120; iter: 0; batch classifier loss: 0.048767; batch adversarial loss: 0.431728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121; iter: 0; batch classifier loss: 0.032140; batch adversarial loss: 0.379842\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049357; batch adversarial loss: 0.544513\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037213; batch adversarial loss: 0.426144\n",
      "epoch 124; iter: 0; batch classifier loss: 0.030468; batch adversarial loss: 0.423366\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040714; batch adversarial loss: 0.482748\n",
      "epoch 126; iter: 0; batch classifier loss: 0.034606; batch adversarial loss: 0.428130\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030447; batch adversarial loss: 0.414157\n",
      "epoch 128; iter: 0; batch classifier loss: 0.041329; batch adversarial loss: 0.537127\n",
      "epoch 129; iter: 0; batch classifier loss: 0.025352; batch adversarial loss: 0.477637\n",
      "epoch 130; iter: 0; batch classifier loss: 0.049594; batch adversarial loss: 0.555174\n",
      "epoch 131; iter: 0; batch classifier loss: 0.055360; batch adversarial loss: 0.500282\n",
      "epoch 132; iter: 0; batch classifier loss: 0.111202; batch adversarial loss: 0.664449\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060757; batch adversarial loss: 0.412587\n",
      "epoch 134; iter: 0; batch classifier loss: 0.103457; batch adversarial loss: 0.686229\n",
      "epoch 135; iter: 0; batch classifier loss: 0.121780; batch adversarial loss: 0.729753\n",
      "epoch 136; iter: 0; batch classifier loss: 0.121951; batch adversarial loss: 0.638199\n",
      "epoch 137; iter: 0; batch classifier loss: 0.179966; batch adversarial loss: 0.691486\n",
      "epoch 138; iter: 0; batch classifier loss: 0.090227; batch adversarial loss: 0.421905\n",
      "epoch 139; iter: 0; batch classifier loss: 0.198066; batch adversarial loss: 0.742947\n",
      "epoch 140; iter: 0; batch classifier loss: 0.067778; batch adversarial loss: 0.448703\n",
      "epoch 141; iter: 0; batch classifier loss: 0.122601; batch adversarial loss: 0.659172\n",
      "epoch 142; iter: 0; batch classifier loss: 0.185821; batch adversarial loss: 0.662974\n",
      "epoch 143; iter: 0; batch classifier loss: 0.276457; batch adversarial loss: 0.829236\n",
      "epoch 144; iter: 0; batch classifier loss: 0.080581; batch adversarial loss: 0.455404\n",
      "epoch 145; iter: 0; batch classifier loss: 0.163110; batch adversarial loss: 0.644123\n",
      "epoch 146; iter: 0; batch classifier loss: 0.201225; batch adversarial loss: 0.648780\n",
      "epoch 147; iter: 0; batch classifier loss: 0.149289; batch adversarial loss: 0.565757\n",
      "epoch 148; iter: 0; batch classifier loss: 0.103849; batch adversarial loss: 0.450339\n",
      "epoch 149; iter: 0; batch classifier loss: 0.192639; batch adversarial loss: 0.625020\n",
      "epoch 150; iter: 0; batch classifier loss: 0.121451; batch adversarial loss: 0.578406\n",
      "epoch 151; iter: 0; batch classifier loss: 0.094929; batch adversarial loss: 0.476414\n",
      "epoch 152; iter: 0; batch classifier loss: 0.164049; batch adversarial loss: 0.531859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.191336; batch adversarial loss: 0.691815\n",
      "epoch 154; iter: 0; batch classifier loss: 0.146054; batch adversarial loss: 0.561220\n",
      "epoch 155; iter: 0; batch classifier loss: 0.134963; batch adversarial loss: 0.501165\n",
      "epoch 156; iter: 0; batch classifier loss: 0.128136; batch adversarial loss: 0.522147\n",
      "epoch 157; iter: 0; batch classifier loss: 0.190820; batch adversarial loss: 0.569296\n",
      "epoch 158; iter: 0; batch classifier loss: 0.166112; batch adversarial loss: 0.509363\n",
      "epoch 159; iter: 0; batch classifier loss: 0.105687; batch adversarial loss: 0.420566\n",
      "epoch 160; iter: 0; batch classifier loss: 0.158860; batch adversarial loss: 0.512047\n",
      "epoch 161; iter: 0; batch classifier loss: 0.190352; batch adversarial loss: 0.669386\n",
      "epoch 162; iter: 0; batch classifier loss: 0.173603; batch adversarial loss: 0.568719\n",
      "epoch 163; iter: 0; batch classifier loss: 0.183469; batch adversarial loss: 0.507615\n",
      "epoch 164; iter: 0; batch classifier loss: 0.113274; batch adversarial loss: 0.422608\n",
      "epoch 165; iter: 0; batch classifier loss: 0.180847; batch adversarial loss: 0.500936\n",
      "epoch 166; iter: 0; batch classifier loss: 0.131888; batch adversarial loss: 0.522819\n",
      "epoch 167; iter: 0; batch classifier loss: 0.186878; batch adversarial loss: 0.583458\n",
      "epoch 168; iter: 0; batch classifier loss: 0.130773; batch adversarial loss: 0.440504\n",
      "epoch 169; iter: 0; batch classifier loss: 0.087533; batch adversarial loss: 0.442915\n",
      "epoch 170; iter: 0; batch classifier loss: 0.156556; batch adversarial loss: 0.475865\n",
      "epoch 171; iter: 0; batch classifier loss: 0.109130; batch adversarial loss: 0.540223\n",
      "epoch 172; iter: 0; batch classifier loss: 0.084010; batch adversarial loss: 0.445298\n",
      "epoch 173; iter: 0; batch classifier loss: 0.116843; batch adversarial loss: 0.534469\n",
      "epoch 174; iter: 0; batch classifier loss: 0.104801; batch adversarial loss: 0.418065\n",
      "epoch 175; iter: 0; batch classifier loss: 0.069915; batch adversarial loss: 0.477607\n",
      "epoch 176; iter: 0; batch classifier loss: 0.099822; batch adversarial loss: 0.363058\n",
      "epoch 177; iter: 0; batch classifier loss: 0.104759; batch adversarial loss: 0.434020\n",
      "epoch 178; iter: 0; batch classifier loss: 0.072087; batch adversarial loss: 0.493041\n",
      "epoch 179; iter: 0; batch classifier loss: 0.033535; batch adversarial loss: 0.529869\n",
      "epoch 180; iter: 0; batch classifier loss: 0.026703; batch adversarial loss: 0.404518\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025996; batch adversarial loss: 0.382682\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053095; batch adversarial loss: 0.353813\n",
      "epoch 183; iter: 0; batch classifier loss: 0.024733; batch adversarial loss: 0.493841\n",
      "epoch 184; iter: 0; batch classifier loss: 0.032107; batch adversarial loss: 0.506235\n",
      "epoch 185; iter: 0; batch classifier loss: 0.044430; batch adversarial loss: 0.439968\n",
      "epoch 186; iter: 0; batch classifier loss: 0.013098; batch adversarial loss: 0.477555\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017088; batch adversarial loss: 0.539889\n",
      "epoch 188; iter: 0; batch classifier loss: 0.058064; batch adversarial loss: 0.448834\n",
      "epoch 189; iter: 0; batch classifier loss: 0.040829; batch adversarial loss: 0.397590\n",
      "epoch 190; iter: 0; batch classifier loss: 0.035720; batch adversarial loss: 0.456571\n",
      "epoch 191; iter: 0; batch classifier loss: 0.022389; batch adversarial loss: 0.405241\n",
      "epoch 192; iter: 0; batch classifier loss: 0.026577; batch adversarial loss: 0.442316\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015436; batch adversarial loss: 0.491651\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035116; batch adversarial loss: 0.426481\n",
      "epoch 195; iter: 0; batch classifier loss: 0.056006; batch adversarial loss: 0.417949\n",
      "epoch 196; iter: 0; batch classifier loss: 0.033357; batch adversarial loss: 0.495122\n",
      "epoch 197; iter: 0; batch classifier loss: 0.045476; batch adversarial loss: 0.357545\n",
      "epoch 198; iter: 0; batch classifier loss: 0.047249; batch adversarial loss: 0.445070\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026460; batch adversarial loss: 0.463642\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700470; batch adversarial loss: 0.808216\n",
      "epoch 1; iter: 0; batch classifier loss: 0.411861; batch adversarial loss: 0.840536\n",
      "epoch 2; iter: 0; batch classifier loss: 0.360518; batch adversarial loss: 0.818172\n",
      "epoch 3; iter: 0; batch classifier loss: 0.381276; batch adversarial loss: 0.751637\n",
      "epoch 4; iter: 0; batch classifier loss: 0.254747; batch adversarial loss: 0.686838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322838; batch adversarial loss: 0.661099\n",
      "epoch 6; iter: 0; batch classifier loss: 0.360506; batch adversarial loss: 0.654017\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319522; batch adversarial loss: 0.621003\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288370; batch adversarial loss: 0.574680\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332071; batch adversarial loss: 0.553998\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305586; batch adversarial loss: 0.578291\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286180; batch adversarial loss: 0.491708\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284096; batch adversarial loss: 0.495951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250755; batch adversarial loss: 0.461017\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279397; batch adversarial loss: 0.453164\n",
      "epoch 15; iter: 0; batch classifier loss: 0.272278; batch adversarial loss: 0.463053\n",
      "epoch 16; iter: 0; batch classifier loss: 0.235454; batch adversarial loss: 0.458217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.297944; batch adversarial loss: 0.430165\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234567; batch adversarial loss: 0.426549\n",
      "epoch 19; iter: 0; batch classifier loss: 0.192703; batch adversarial loss: 0.406739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250188; batch adversarial loss: 0.416102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.168279; batch adversarial loss: 0.454487\n",
      "epoch 22; iter: 0; batch classifier loss: 0.184965; batch adversarial loss: 0.444398\n",
      "epoch 23; iter: 0; batch classifier loss: 0.164917; batch adversarial loss: 0.489795\n",
      "epoch 24; iter: 0; batch classifier loss: 0.122635; batch adversarial loss: 0.379223\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130572; batch adversarial loss: 0.378430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146591; batch adversarial loss: 0.414472\n",
      "epoch 27; iter: 0; batch classifier loss: 0.132632; batch adversarial loss: 0.471341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.108231; batch adversarial loss: 0.438774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.143773; batch adversarial loss: 0.545647\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124752; batch adversarial loss: 0.491732\n",
      "epoch 31; iter: 0; batch classifier loss: 0.099391; batch adversarial loss: 0.469696\n",
      "epoch 32; iter: 0; batch classifier loss: 0.144293; batch adversarial loss: 0.491715\n",
      "epoch 33; iter: 0; batch classifier loss: 0.161503; batch adversarial loss: 0.418001\n",
      "epoch 34; iter: 0; batch classifier loss: 0.101878; batch adversarial loss: 0.430366\n",
      "epoch 35; iter: 0; batch classifier loss: 0.130744; batch adversarial loss: 0.419941\n",
      "epoch 36; iter: 0; batch classifier loss: 0.180704; batch adversarial loss: 0.401927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.136589; batch adversarial loss: 0.453139\n",
      "epoch 38; iter: 0; batch classifier loss: 0.130346; batch adversarial loss: 0.423613\n",
      "epoch 39; iter: 0; batch classifier loss: 0.151634; batch adversarial loss: 0.488765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.154115; batch adversarial loss: 0.439805\n",
      "epoch 41; iter: 0; batch classifier loss: 0.148794; batch adversarial loss: 0.416855\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115890; batch adversarial loss: 0.433571\n",
      "epoch 43; iter: 0; batch classifier loss: 0.129057; batch adversarial loss: 0.312280\n",
      "epoch 44; iter: 0; batch classifier loss: 0.153390; batch adversarial loss: 0.326434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.102972; batch adversarial loss: 0.336416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.097147; batch adversarial loss: 0.377012\n",
      "epoch 47; iter: 0; batch classifier loss: 0.136048; batch adversarial loss: 0.444935\n",
      "epoch 48; iter: 0; batch classifier loss: 0.090333; batch adversarial loss: 0.429768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.094107; batch adversarial loss: 0.452288\n",
      "epoch 50; iter: 0; batch classifier loss: 0.082765; batch adversarial loss: 0.374851\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090774; batch adversarial loss: 0.412940\n",
      "epoch 52; iter: 0; batch classifier loss: 0.112442; batch adversarial loss: 0.421371\n",
      "epoch 53; iter: 0; batch classifier loss: 0.135647; batch adversarial loss: 0.444576\n",
      "epoch 54; iter: 0; batch classifier loss: 0.077925; batch adversarial loss: 0.446374\n",
      "epoch 55; iter: 0; batch classifier loss: 0.092793; batch adversarial loss: 0.452083\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098720; batch adversarial loss: 0.414932\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097059; batch adversarial loss: 0.513927\n",
      "epoch 58; iter: 0; batch classifier loss: 0.055231; batch adversarial loss: 0.431153\n",
      "epoch 59; iter: 0; batch classifier loss: 0.108592; batch adversarial loss: 0.447434\n",
      "epoch 60; iter: 0; batch classifier loss: 0.065435; batch adversarial loss: 0.421041\n",
      "epoch 61; iter: 0; batch classifier loss: 0.068708; batch adversarial loss: 0.380933\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082595; batch adversarial loss: 0.407738\n",
      "epoch 63; iter: 0; batch classifier loss: 0.074077; batch adversarial loss: 0.438594\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085022; batch adversarial loss: 0.392378\n",
      "epoch 65; iter: 0; batch classifier loss: 0.066105; batch adversarial loss: 0.444119\n",
      "epoch 66; iter: 0; batch classifier loss: 0.077207; batch adversarial loss: 0.456821\n",
      "epoch 67; iter: 0; batch classifier loss: 0.081754; batch adversarial loss: 0.386970\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062394; batch adversarial loss: 0.428568\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106200; batch adversarial loss: 0.426863\n",
      "epoch 70; iter: 0; batch classifier loss: 0.069231; batch adversarial loss: 0.381413\n",
      "epoch 71; iter: 0; batch classifier loss: 0.083295; batch adversarial loss: 0.423150\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058098; batch adversarial loss: 0.407437\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074995; batch adversarial loss: 0.428601\n",
      "epoch 74; iter: 0; batch classifier loss: 0.086723; batch adversarial loss: 0.402533\n",
      "epoch 75; iter: 0; batch classifier loss: 0.081922; batch adversarial loss: 0.356649\n",
      "epoch 76; iter: 0; batch classifier loss: 0.089642; batch adversarial loss: 0.365345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.069677; batch adversarial loss: 0.448467\n",
      "epoch 78; iter: 0; batch classifier loss: 0.036116; batch adversarial loss: 0.421335\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072129; batch adversarial loss: 0.333693\n",
      "epoch 80; iter: 0; batch classifier loss: 0.045872; batch adversarial loss: 0.438717\n",
      "epoch 81; iter: 0; batch classifier loss: 0.059390; batch adversarial loss: 0.424477\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059260; batch adversarial loss: 0.489010\n",
      "epoch 83; iter: 0; batch classifier loss: 0.059559; batch adversarial loss: 0.433211\n",
      "epoch 84; iter: 0; batch classifier loss: 0.048005; batch adversarial loss: 0.405201\n",
      "epoch 85; iter: 0; batch classifier loss: 0.053203; batch adversarial loss: 0.369365\n",
      "epoch 86; iter: 0; batch classifier loss: 0.055510; batch adversarial loss: 0.343937\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036380; batch adversarial loss: 0.406345\n",
      "epoch 88; iter: 0; batch classifier loss: 0.058542; batch adversarial loss: 0.378947\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040008; batch adversarial loss: 0.428229\n",
      "epoch 90; iter: 0; batch classifier loss: 0.040460; batch adversarial loss: 0.461699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049825; batch adversarial loss: 0.372856\n",
      "epoch 92; iter: 0; batch classifier loss: 0.057754; batch adversarial loss: 0.530732\n",
      "epoch 93; iter: 0; batch classifier loss: 0.051910; batch adversarial loss: 0.452780\n",
      "epoch 94; iter: 0; batch classifier loss: 0.041072; batch adversarial loss: 0.420510\n",
      "epoch 95; iter: 0; batch classifier loss: 0.055814; batch adversarial loss: 0.441709\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037221; batch adversarial loss: 0.394589\n",
      "epoch 97; iter: 0; batch classifier loss: 0.023649; batch adversarial loss: 0.492366\n",
      "epoch 98; iter: 0; batch classifier loss: 0.053310; batch adversarial loss: 0.501832\n",
      "epoch 99; iter: 0; batch classifier loss: 0.046293; batch adversarial loss: 0.454919\n",
      "epoch 100; iter: 0; batch classifier loss: 0.045251; batch adversarial loss: 0.483935\n",
      "epoch 101; iter: 0; batch classifier loss: 0.026687; batch adversarial loss: 0.488774\n",
      "epoch 102; iter: 0; batch classifier loss: 0.024961; batch adversarial loss: 0.486858\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043287; batch adversarial loss: 0.423037\n",
      "epoch 104; iter: 0; batch classifier loss: 0.030546; batch adversarial loss: 0.459441\n",
      "epoch 105; iter: 0; batch classifier loss: 0.022365; batch adversarial loss: 0.428156\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039695; batch adversarial loss: 0.417174\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032527; batch adversarial loss: 0.466282\n",
      "epoch 108; iter: 0; batch classifier loss: 0.030857; batch adversarial loss: 0.432008\n",
      "epoch 109; iter: 0; batch classifier loss: 0.033304; batch adversarial loss: 0.511059\n",
      "epoch 110; iter: 0; batch classifier loss: 0.027586; batch adversarial loss: 0.393306\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046237; batch adversarial loss: 0.553463\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.618983\n",
      "epoch 113; iter: 0; batch classifier loss: 0.035940; batch adversarial loss: 0.397083\n",
      "epoch 114; iter: 0; batch classifier loss: 0.034335; batch adversarial loss: 0.470447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.025233; batch adversarial loss: 0.470305\n",
      "epoch 116; iter: 0; batch classifier loss: 0.038417; batch adversarial loss: 0.389818\n",
      "epoch 117; iter: 0; batch classifier loss: 0.079036; batch adversarial loss: 0.534814\n",
      "epoch 118; iter: 0; batch classifier loss: 0.085312; batch adversarial loss: 0.567813\n",
      "epoch 119; iter: 0; batch classifier loss: 0.132756; batch adversarial loss: 0.671579\n",
      "epoch 120; iter: 0; batch classifier loss: 0.083145; batch adversarial loss: 0.544420\n",
      "epoch 121; iter: 0; batch classifier loss: 0.134026; batch adversarial loss: 0.702585\n",
      "epoch 122; iter: 0; batch classifier loss: 0.072228; batch adversarial loss: 0.493178\n",
      "epoch 123; iter: 0; batch classifier loss: 0.089159; batch adversarial loss: 0.568363\n",
      "epoch 124; iter: 0; batch classifier loss: 0.119771; batch adversarial loss: 0.602954\n",
      "epoch 125; iter: 0; batch classifier loss: 0.068150; batch adversarial loss: 0.475251\n",
      "epoch 126; iter: 0; batch classifier loss: 0.096165; batch adversarial loss: 0.631793\n",
      "epoch 127; iter: 0; batch classifier loss: 0.116100; batch adversarial loss: 0.546197\n",
      "epoch 128; iter: 0; batch classifier loss: 0.164200; batch adversarial loss: 0.664632\n",
      "epoch 129; iter: 0; batch classifier loss: 0.145525; batch adversarial loss: 0.572775\n",
      "epoch 130; iter: 0; batch classifier loss: 0.140075; batch adversarial loss: 0.607840\n",
      "epoch 131; iter: 0; batch classifier loss: 0.196260; batch adversarial loss: 0.742104\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152960; batch adversarial loss: 0.592817\n",
      "epoch 133; iter: 0; batch classifier loss: 0.111488; batch adversarial loss: 0.540669\n",
      "epoch 134; iter: 0; batch classifier loss: 0.145444; batch adversarial loss: 0.629629\n",
      "epoch 135; iter: 0; batch classifier loss: 0.108794; batch adversarial loss: 0.588702\n",
      "epoch 136; iter: 0; batch classifier loss: 0.154220; batch adversarial loss: 0.585072\n",
      "epoch 137; iter: 0; batch classifier loss: 0.113979; batch adversarial loss: 0.557723\n",
      "epoch 138; iter: 0; batch classifier loss: 0.149459; batch adversarial loss: 0.598546\n",
      "epoch 139; iter: 0; batch classifier loss: 0.116565; batch adversarial loss: 0.493922\n",
      "epoch 140; iter: 0; batch classifier loss: 0.112616; batch adversarial loss: 0.482065\n",
      "epoch 141; iter: 0; batch classifier loss: 0.144544; batch adversarial loss: 0.599789\n",
      "epoch 142; iter: 0; batch classifier loss: 0.135068; batch adversarial loss: 0.460487\n",
      "epoch 143; iter: 0; batch classifier loss: 0.184666; batch adversarial loss: 0.502893\n",
      "epoch 144; iter: 0; batch classifier loss: 0.151443; batch adversarial loss: 0.578955\n",
      "epoch 145; iter: 0; batch classifier loss: 0.178362; batch adversarial loss: 0.573670\n",
      "epoch 146; iter: 0; batch classifier loss: 0.142552; batch adversarial loss: 0.492539\n",
      "epoch 147; iter: 0; batch classifier loss: 0.172240; batch adversarial loss: 0.583443\n",
      "epoch 148; iter: 0; batch classifier loss: 0.091601; batch adversarial loss: 0.552880\n",
      "epoch 149; iter: 0; batch classifier loss: 0.090731; batch adversarial loss: 0.445435\n",
      "epoch 150; iter: 0; batch classifier loss: 0.088549; batch adversarial loss: 0.457123\n",
      "epoch 151; iter: 0; batch classifier loss: 0.089963; batch adversarial loss: 0.471827\n",
      "epoch 152; iter: 0; batch classifier loss: 0.120805; batch adversarial loss: 0.471010\n",
      "epoch 153; iter: 0; batch classifier loss: 0.135238; batch adversarial loss: 0.516144\n",
      "epoch 154; iter: 0; batch classifier loss: 0.128239; batch adversarial loss: 0.499440\n",
      "epoch 155; iter: 0; batch classifier loss: 0.117946; batch adversarial loss: 0.464229\n",
      "epoch 156; iter: 0; batch classifier loss: 0.103745; batch adversarial loss: 0.513224\n",
      "epoch 157; iter: 0; batch classifier loss: 0.093662; batch adversarial loss: 0.484255\n",
      "epoch 158; iter: 0; batch classifier loss: 0.050392; batch adversarial loss: 0.419660\n",
      "epoch 159; iter: 0; batch classifier loss: 0.086762; batch adversarial loss: 0.442920\n",
      "epoch 160; iter: 0; batch classifier loss: 0.102143; batch adversarial loss: 0.477285\n",
      "epoch 161; iter: 0; batch classifier loss: 0.076917; batch adversarial loss: 0.484878\n",
      "epoch 162; iter: 0; batch classifier loss: 0.105030; batch adversarial loss: 0.483401\n",
      "epoch 163; iter: 0; batch classifier loss: 0.116246; batch adversarial loss: 0.398072\n",
      "epoch 164; iter: 0; batch classifier loss: 0.040705; batch adversarial loss: 0.530108\n",
      "epoch 165; iter: 0; batch classifier loss: 0.025224; batch adversarial loss: 0.491084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.050878; batch adversarial loss: 0.531816\n",
      "epoch 167; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.523077\n",
      "epoch 168; iter: 0; batch classifier loss: 0.026835; batch adversarial loss: 0.442961\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016148; batch adversarial loss: 0.451869\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.440515\n",
      "epoch 171; iter: 0; batch classifier loss: 0.056101; batch adversarial loss: 0.502175\n",
      "epoch 172; iter: 0; batch classifier loss: 0.054992; batch adversarial loss: 0.457822\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016497; batch adversarial loss: 0.404016\n",
      "epoch 174; iter: 0; batch classifier loss: 0.055017; batch adversarial loss: 0.367599\n",
      "epoch 175; iter: 0; batch classifier loss: 0.058169; batch adversarial loss: 0.444850\n",
      "epoch 176; iter: 0; batch classifier loss: 0.089542; batch adversarial loss: 0.444299\n",
      "epoch 177; iter: 0; batch classifier loss: 0.065308; batch adversarial loss: 0.491531\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055955; batch adversarial loss: 0.416886\n",
      "epoch 179; iter: 0; batch classifier loss: 0.058849; batch adversarial loss: 0.381134\n",
      "epoch 180; iter: 0; batch classifier loss: 0.047053; batch adversarial loss: 0.549082\n",
      "epoch 181; iter: 0; batch classifier loss: 0.039537; batch adversarial loss: 0.493124\n",
      "epoch 182; iter: 0; batch classifier loss: 0.053190; batch adversarial loss: 0.493639\n",
      "epoch 183; iter: 0; batch classifier loss: 0.109920; batch adversarial loss: 0.453966\n",
      "epoch 184; iter: 0; batch classifier loss: 0.106395; batch adversarial loss: 0.408673\n",
      "epoch 185; iter: 0; batch classifier loss: 0.067267; batch adversarial loss: 0.324745\n",
      "epoch 186; iter: 0; batch classifier loss: 0.068564; batch adversarial loss: 0.545181\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036149; batch adversarial loss: 0.456452\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043809; batch adversarial loss: 0.398894\n",
      "epoch 189; iter: 0; batch classifier loss: 0.072998; batch adversarial loss: 0.452683\n",
      "epoch 190; iter: 0; batch classifier loss: 0.061816; batch adversarial loss: 0.410597\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032455; batch adversarial loss: 0.490098\n",
      "epoch 192; iter: 0; batch classifier loss: 0.077116; batch adversarial loss: 0.387812\n",
      "epoch 193; iter: 0; batch classifier loss: 0.029151; batch adversarial loss: 0.498480\n",
      "epoch 194; iter: 0; batch classifier loss: 0.070890; batch adversarial loss: 0.366405\n",
      "epoch 195; iter: 0; batch classifier loss: 0.074606; batch adversarial loss: 0.474005\n",
      "epoch 196; iter: 0; batch classifier loss: 0.076330; batch adversarial loss: 0.497135\n",
      "epoch 197; iter: 0; batch classifier loss: 0.058664; batch adversarial loss: 0.455876\n",
      "epoch 198; iter: 0; batch classifier loss: 0.067382; batch adversarial loss: 0.391783\n",
      "epoch 199; iter: 0; batch classifier loss: 0.102947; batch adversarial loss: 0.455868\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697183; batch adversarial loss: 0.713818\n",
      "epoch 1; iter: 0; batch classifier loss: 0.472712; batch adversarial loss: 0.662858\n",
      "epoch 2; iter: 0; batch classifier loss: 0.448751; batch adversarial loss: 0.651788\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451501; batch adversarial loss: 0.619474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.463304; batch adversarial loss: 0.605630\n",
      "epoch 5; iter: 0; batch classifier loss: 0.464514; batch adversarial loss: 0.591268\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395839; batch adversarial loss: 0.546890\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420710; batch adversarial loss: 0.552626\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403394; batch adversarial loss: 0.541350\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453073; batch adversarial loss: 0.564456\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372076; batch adversarial loss: 0.515900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.454085; batch adversarial loss: 0.546982\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427261; batch adversarial loss: 0.494301\n",
      "epoch 13; iter: 0; batch classifier loss: 0.344935; batch adversarial loss: 0.539092\n",
      "epoch 14; iter: 0; batch classifier loss: 0.444598; batch adversarial loss: 0.523834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345382; batch adversarial loss: 0.524147\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339912; batch adversarial loss: 0.501269\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330027; batch adversarial loss: 0.463282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290488; batch adversarial loss: 0.515441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.314517; batch adversarial loss: 0.468015\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331354; batch adversarial loss: 0.488995\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306395; batch adversarial loss: 0.407025\n",
      "epoch 22; iter: 0; batch classifier loss: 0.325274; batch adversarial loss: 0.393862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.248852; batch adversarial loss: 0.441747\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323663; batch adversarial loss: 0.459436\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252180; batch adversarial loss: 0.502944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285471; batch adversarial loss: 0.499130\n",
      "epoch 27; iter: 0; batch classifier loss: 0.264459; batch adversarial loss: 0.451558\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268408; batch adversarial loss: 0.474077\n",
      "epoch 29; iter: 0; batch classifier loss: 0.215142; batch adversarial loss: 0.525027\n",
      "epoch 30; iter: 0; batch classifier loss: 0.290586; batch adversarial loss: 0.497133\n",
      "epoch 31; iter: 0; batch classifier loss: 0.294498; batch adversarial loss: 0.466396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.302440; batch adversarial loss: 0.475874\n",
      "epoch 33; iter: 0; batch classifier loss: 0.241137; batch adversarial loss: 0.400433\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240545; batch adversarial loss: 0.418514\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237682; batch adversarial loss: 0.489834\n",
      "epoch 36; iter: 0; batch classifier loss: 0.223063; batch adversarial loss: 0.352082\n",
      "epoch 37; iter: 0; batch classifier loss: 0.292488; batch adversarial loss: 0.437731\n",
      "epoch 38; iter: 0; batch classifier loss: 0.238620; batch adversarial loss: 0.460300\n",
      "epoch 39; iter: 0; batch classifier loss: 0.277136; batch adversarial loss: 0.505816\n",
      "epoch 40; iter: 0; batch classifier loss: 0.145936; batch adversarial loss: 0.517180\n",
      "epoch 41; iter: 0; batch classifier loss: 0.080799; batch adversarial loss: 0.446727\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095461; batch adversarial loss: 0.445522\n",
      "epoch 43; iter: 0; batch classifier loss: 0.183483; batch adversarial loss: 0.448040\n",
      "epoch 44; iter: 0; batch classifier loss: 0.201442; batch adversarial loss: 0.459218\n",
      "epoch 45; iter: 0; batch classifier loss: 0.177151; batch adversarial loss: 0.468650\n",
      "epoch 46; iter: 0; batch classifier loss: 0.106294; batch adversarial loss: 0.448130\n",
      "epoch 47; iter: 0; batch classifier loss: 0.192285; batch adversarial loss: 0.336750\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156177; batch adversarial loss: 0.497449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.162535; batch adversarial loss: 0.421781\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133793; batch adversarial loss: 0.398102\n",
      "epoch 51; iter: 0; batch classifier loss: 0.173293; batch adversarial loss: 0.435256\n",
      "epoch 52; iter: 0; batch classifier loss: 0.244422; batch adversarial loss: 0.495814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.149717; batch adversarial loss: 0.471063\n",
      "epoch 54; iter: 0; batch classifier loss: 0.062236; batch adversarial loss: 0.468209\n",
      "epoch 55; iter: 0; batch classifier loss: 0.091572; batch adversarial loss: 0.421335\n",
      "epoch 56; iter: 0; batch classifier loss: 0.179372; batch adversarial loss: 0.472246\n",
      "epoch 57; iter: 0; batch classifier loss: 0.141260; batch adversarial loss: 0.457728\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166803; batch adversarial loss: 0.444414\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161870; batch adversarial loss: 0.558737\n",
      "epoch 60; iter: 0; batch classifier loss: 0.203325; batch adversarial loss: 0.484471\n",
      "epoch 61; iter: 0; batch classifier loss: 0.171424; batch adversarial loss: 0.421505\n",
      "epoch 62; iter: 0; batch classifier loss: 0.148136; batch adversarial loss: 0.433645\n",
      "epoch 63; iter: 0; batch classifier loss: 0.172023; batch adversarial loss: 0.408883\n",
      "epoch 64; iter: 0; batch classifier loss: 0.177211; batch adversarial loss: 0.446506\n",
      "epoch 65; iter: 0; batch classifier loss: 0.240905; batch adversarial loss: 0.421498\n",
      "epoch 66; iter: 0; batch classifier loss: 0.088065; batch adversarial loss: 0.421024\n",
      "epoch 67; iter: 0; batch classifier loss: 0.078481; batch adversarial loss: 0.469841\n",
      "epoch 68; iter: 0; batch classifier loss: 0.087635; batch adversarial loss: 0.418517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.189775; batch adversarial loss: 0.457967\n",
      "epoch 70; iter: 0; batch classifier loss: 0.160421; batch adversarial loss: 0.523855\n",
      "epoch 71; iter: 0; batch classifier loss: 0.209300; batch adversarial loss: 0.359815\n",
      "epoch 72; iter: 0; batch classifier loss: 0.132944; batch adversarial loss: 0.522159\n",
      "epoch 73; iter: 0; batch classifier loss: 0.142340; batch adversarial loss: 0.519634\n",
      "epoch 74; iter: 0; batch classifier loss: 0.166892; batch adversarial loss: 0.332301\n",
      "epoch 75; iter: 0; batch classifier loss: 0.158543; batch adversarial loss: 0.421720\n",
      "epoch 76; iter: 0; batch classifier loss: 0.164125; batch adversarial loss: 0.446195\n",
      "epoch 77; iter: 0; batch classifier loss: 0.269440; batch adversarial loss: 0.383571\n",
      "epoch 78; iter: 0; batch classifier loss: 0.104872; batch adversarial loss: 0.446113\n",
      "epoch 79; iter: 0; batch classifier loss: 0.088827; batch adversarial loss: 0.510137\n",
      "epoch 80; iter: 0; batch classifier loss: 0.054647; batch adversarial loss: 0.429729\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083342; batch adversarial loss: 0.406621\n",
      "epoch 82; iter: 0; batch classifier loss: 0.087331; batch adversarial loss: 0.494523\n",
      "epoch 83; iter: 0; batch classifier loss: 0.075040; batch adversarial loss: 0.420842\n",
      "epoch 84; iter: 0; batch classifier loss: 0.102638; batch adversarial loss: 0.461009\n",
      "epoch 85; iter: 0; batch classifier loss: 0.059302; batch adversarial loss: 0.388861\n",
      "epoch 86; iter: 0; batch classifier loss: 0.049219; batch adversarial loss: 0.560791\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060992; batch adversarial loss: 0.488809\n",
      "epoch 88; iter: 0; batch classifier loss: 0.051085; batch adversarial loss: 0.476419\n",
      "epoch 89; iter: 0; batch classifier loss: 0.053018; batch adversarial loss: 0.408985\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059295; batch adversarial loss: 0.478699\n",
      "epoch 91; iter: 0; batch classifier loss: 0.039808; batch adversarial loss: 0.525043\n",
      "epoch 92; iter: 0; batch classifier loss: 0.113067; batch adversarial loss: 0.357294\n",
      "epoch 93; iter: 0; batch classifier loss: 0.059838; batch adversarial loss: 0.466923\n",
      "epoch 94; iter: 0; batch classifier loss: 0.040255; batch adversarial loss: 0.487272\n",
      "epoch 95; iter: 0; batch classifier loss: 0.072271; batch adversarial loss: 0.527362\n",
      "epoch 96; iter: 0; batch classifier loss: 0.040071; batch adversarial loss: 0.451705\n",
      "epoch 97; iter: 0; batch classifier loss: 0.058436; batch adversarial loss: 0.528010\n",
      "epoch 98; iter: 0; batch classifier loss: 0.042509; batch adversarial loss: 0.497919\n",
      "epoch 99; iter: 0; batch classifier loss: 0.065679; batch adversarial loss: 0.402975\n",
      "epoch 100; iter: 0; batch classifier loss: 0.044343; batch adversarial loss: 0.495533\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050084; batch adversarial loss: 0.381194\n",
      "epoch 102; iter: 0; batch classifier loss: 0.062365; batch adversarial loss: 0.458260\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082024; batch adversarial loss: 0.386570\n",
      "epoch 104; iter: 0; batch classifier loss: 0.056198; batch adversarial loss: 0.464080\n",
      "epoch 105; iter: 0; batch classifier loss: 0.060678; batch adversarial loss: 0.508285\n",
      "epoch 106; iter: 0; batch classifier loss: 0.024773; batch adversarial loss: 0.522832\n",
      "epoch 107; iter: 0; batch classifier loss: 0.025274; batch adversarial loss: 0.552361\n",
      "epoch 108; iter: 0; batch classifier loss: 0.016359; batch adversarial loss: 0.476801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.065465; batch adversarial loss: 0.369602\n",
      "epoch 110; iter: 0; batch classifier loss: 0.020652; batch adversarial loss: 0.450201\n",
      "epoch 111; iter: 0; batch classifier loss: 0.029917; batch adversarial loss: 0.442405\n",
      "epoch 112; iter: 0; batch classifier loss: 0.025571; batch adversarial loss: 0.447514\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037111; batch adversarial loss: 0.406494\n",
      "epoch 114; iter: 0; batch classifier loss: 0.055952; batch adversarial loss: 0.439633\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037906; batch adversarial loss: 0.516812\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026239; batch adversarial loss: 0.408351\n",
      "epoch 117; iter: 0; batch classifier loss: 0.028893; batch adversarial loss: 0.423342\n",
      "epoch 118; iter: 0; batch classifier loss: 0.041303; batch adversarial loss: 0.487583\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024801; batch adversarial loss: 0.453320\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036621; batch adversarial loss: 0.463327\n",
      "epoch 121; iter: 0; batch classifier loss: 0.049752; batch adversarial loss: 0.428612\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036500; batch adversarial loss: 0.423682\n",
      "epoch 123; iter: 0; batch classifier loss: 0.024726; batch adversarial loss: 0.490891\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021068; batch adversarial loss: 0.483102\n",
      "epoch 125; iter: 0; batch classifier loss: 0.017454; batch adversarial loss: 0.363445\n",
      "epoch 126; iter: 0; batch classifier loss: 0.022857; batch adversarial loss: 0.491331\n",
      "epoch 127; iter: 0; batch classifier loss: 0.043323; batch adversarial loss: 0.391352\n",
      "epoch 128; iter: 0; batch classifier loss: 0.047627; batch adversarial loss: 0.381336\n",
      "epoch 129; iter: 0; batch classifier loss: 0.055039; batch adversarial loss: 0.475376\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013482; batch adversarial loss: 0.376234\n",
      "epoch 131; iter: 0; batch classifier loss: 0.020265; batch adversarial loss: 0.427940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.040650; batch adversarial loss: 0.385369\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027575; batch adversarial loss: 0.461730\n",
      "epoch 134; iter: 0; batch classifier loss: 0.010853; batch adversarial loss: 0.476651\n",
      "epoch 135; iter: 0; batch classifier loss: 0.054357; batch adversarial loss: 0.454426\n",
      "epoch 136; iter: 0; batch classifier loss: 0.017191; batch adversarial loss: 0.415480\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039328; batch adversarial loss: 0.390603\n",
      "epoch 138; iter: 0; batch classifier loss: 0.019421; batch adversarial loss: 0.387896\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033715; batch adversarial loss: 0.442468\n",
      "epoch 140; iter: 0; batch classifier loss: 0.051004; batch adversarial loss: 0.427074\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017455; batch adversarial loss: 0.436421\n",
      "epoch 142; iter: 0; batch classifier loss: 0.027143; batch adversarial loss: 0.510068\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036698; batch adversarial loss: 0.472133\n",
      "epoch 144; iter: 0; batch classifier loss: 0.008942; batch adversarial loss: 0.494255\n",
      "epoch 145; iter: 0; batch classifier loss: 0.021594; batch adversarial loss: 0.447797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011951; batch adversarial loss: 0.414616\n",
      "epoch 147; iter: 0; batch classifier loss: 0.010420; batch adversarial loss: 0.445651\n",
      "epoch 148; iter: 0; batch classifier loss: 0.011321; batch adversarial loss: 0.487407\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026264; batch adversarial loss: 0.454617\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025266; batch adversarial loss: 0.460479\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018175; batch adversarial loss: 0.453575\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021711; batch adversarial loss: 0.399515\n",
      "epoch 153; iter: 0; batch classifier loss: 0.021082; batch adversarial loss: 0.393516\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028435; batch adversarial loss: 0.333701\n",
      "epoch 155; iter: 0; batch classifier loss: 0.011663; batch adversarial loss: 0.370294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.024016; batch adversarial loss: 0.358908\n",
      "epoch 157; iter: 0; batch classifier loss: 0.019728; batch adversarial loss: 0.402167\n",
      "epoch 158; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.440584\n",
      "epoch 159; iter: 0; batch classifier loss: 0.030818; batch adversarial loss: 0.436112\n",
      "epoch 160; iter: 0; batch classifier loss: 0.006132; batch adversarial loss: 0.513217\n",
      "epoch 161; iter: 0; batch classifier loss: 0.047735; batch adversarial loss: 0.403242\n",
      "epoch 162; iter: 0; batch classifier loss: 0.046109; batch adversarial loss: 0.426054\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015871; batch adversarial loss: 0.459269\n",
      "epoch 164; iter: 0; batch classifier loss: 0.029557; batch adversarial loss: 0.408469\n",
      "epoch 165; iter: 0; batch classifier loss: 0.016534; batch adversarial loss: 0.436292\n",
      "epoch 166; iter: 0; batch classifier loss: 0.012870; batch adversarial loss: 0.488269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012670; batch adversarial loss: 0.552545\n",
      "epoch 168; iter: 0; batch classifier loss: 0.007073; batch adversarial loss: 0.411086\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017296; batch adversarial loss: 0.486954\n",
      "epoch 170; iter: 0; batch classifier loss: 0.003227; batch adversarial loss: 0.454587\n",
      "epoch 171; iter: 0; batch classifier loss: 0.049277; batch adversarial loss: 0.406244\n",
      "epoch 172; iter: 0; batch classifier loss: 0.005366; batch adversarial loss: 0.526756\n",
      "epoch 173; iter: 0; batch classifier loss: 0.016902; batch adversarial loss: 0.454263\n",
      "epoch 174; iter: 0; batch classifier loss: 0.028700; batch adversarial loss: 0.508908\n",
      "epoch 175; iter: 0; batch classifier loss: 0.019795; batch adversarial loss: 0.492319\n",
      "epoch 176; iter: 0; batch classifier loss: 0.030109; batch adversarial loss: 0.415383\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011515; batch adversarial loss: 0.353197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034131; batch adversarial loss: 0.400141\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010952; batch adversarial loss: 0.432882\n",
      "epoch 180; iter: 0; batch classifier loss: 0.016696; batch adversarial loss: 0.472310\n",
      "epoch 181; iter: 0; batch classifier loss: 0.015196; batch adversarial loss: 0.487173\n",
      "epoch 182; iter: 0; batch classifier loss: 0.009768; batch adversarial loss: 0.410109\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046632; batch adversarial loss: 0.511327\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004240; batch adversarial loss: 0.418416\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024385; batch adversarial loss: 0.446665\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023507; batch adversarial loss: 0.470368\n",
      "epoch 187; iter: 0; batch classifier loss: 0.006572; batch adversarial loss: 0.384546\n",
      "epoch 188; iter: 0; batch classifier loss: 0.005130; batch adversarial loss: 0.489742\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011115; batch adversarial loss: 0.452601\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008582; batch adversarial loss: 0.424552\n",
      "epoch 191; iter: 0; batch classifier loss: 0.011053; batch adversarial loss: 0.525643\n",
      "epoch 192; iter: 0; batch classifier loss: 0.044065; batch adversarial loss: 0.551072\n",
      "epoch 193; iter: 0; batch classifier loss: 0.006819; batch adversarial loss: 0.388770\n",
      "epoch 194; iter: 0; batch classifier loss: 0.024930; batch adversarial loss: 0.428762\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009311; batch adversarial loss: 0.463399\n",
      "epoch 196; iter: 0; batch classifier loss: 0.016417; batch adversarial loss: 0.477774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.019520; batch adversarial loss: 0.510424\n",
      "epoch 198; iter: 0; batch classifier loss: 0.004048; batch adversarial loss: 0.444231\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018263; batch adversarial loss: 0.502237\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688088; batch adversarial loss: 0.506216\n",
      "epoch 1; iter: 0; batch classifier loss: 0.466298; batch adversarial loss: 0.586951\n",
      "epoch 2; iter: 0; batch classifier loss: 0.359312; batch adversarial loss: 0.585876\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415768; batch adversarial loss: 0.603911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.456610; batch adversarial loss: 0.531148\n",
      "epoch 5; iter: 0; batch classifier loss: 0.400845; batch adversarial loss: 0.568516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.427474; batch adversarial loss: 0.596184\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451411; batch adversarial loss: 0.540908\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505005; batch adversarial loss: 0.549670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561068; batch adversarial loss: 0.541586\n",
      "epoch 10; iter: 0; batch classifier loss: 0.716207; batch adversarial loss: 0.608691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.891627; batch adversarial loss: 0.488485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.576220; batch adversarial loss: 0.462840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398014; batch adversarial loss: 0.466132\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369769; batch adversarial loss: 0.492443\n",
      "epoch 15; iter: 0; batch classifier loss: 0.264500; batch adversarial loss: 0.490291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.225565; batch adversarial loss: 0.442464\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262150; batch adversarial loss: 0.516181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.226251; batch adversarial loss: 0.590545\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197247; batch adversarial loss: 0.446872\n",
      "epoch 20; iter: 0; batch classifier loss: 0.219530; batch adversarial loss: 0.415909\n",
      "epoch 21; iter: 0; batch classifier loss: 0.201048; batch adversarial loss: 0.411271\n",
      "epoch 22; iter: 0; batch classifier loss: 0.218649; batch adversarial loss: 0.424131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.171464; batch adversarial loss: 0.395653\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189488; batch adversarial loss: 0.455887\n",
      "epoch 25; iter: 0; batch classifier loss: 0.112523; batch adversarial loss: 0.396573\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176902; batch adversarial loss: 0.464008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.208421; batch adversarial loss: 0.397463\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175474; batch adversarial loss: 0.484800\n",
      "epoch 29; iter: 0; batch classifier loss: 0.150594; batch adversarial loss: 0.489197\n",
      "epoch 30; iter: 0; batch classifier loss: 0.116881; batch adversarial loss: 0.462200\n",
      "epoch 31; iter: 0; batch classifier loss: 0.162461; batch adversarial loss: 0.370478\n",
      "epoch 32; iter: 0; batch classifier loss: 0.140888; batch adversarial loss: 0.420344\n",
      "epoch 33; iter: 0; batch classifier loss: 0.128911; batch adversarial loss: 0.441382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.160707; batch adversarial loss: 0.469378\n",
      "epoch 35; iter: 0; batch classifier loss: 0.163260; batch adversarial loss: 0.510322\n",
      "epoch 36; iter: 0; batch classifier loss: 0.123414; batch adversarial loss: 0.448378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.133148; batch adversarial loss: 0.432090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.103519; batch adversarial loss: 0.400229\n",
      "epoch 39; iter: 0; batch classifier loss: 0.114633; batch adversarial loss: 0.498783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.106796; batch adversarial loss: 0.443411\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133557; batch adversarial loss: 0.425371\n",
      "epoch 42; iter: 0; batch classifier loss: 0.166797; batch adversarial loss: 0.395040\n",
      "epoch 43; iter: 0; batch classifier loss: 0.119638; batch adversarial loss: 0.459425\n",
      "epoch 44; iter: 0; batch classifier loss: 0.124587; batch adversarial loss: 0.457624\n",
      "epoch 45; iter: 0; batch classifier loss: 0.097646; batch adversarial loss: 0.591465\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094386; batch adversarial loss: 0.482511\n",
      "epoch 47; iter: 0; batch classifier loss: 0.115344; batch adversarial loss: 0.436081\n",
      "epoch 48; iter: 0; batch classifier loss: 0.121618; batch adversarial loss: 0.624208\n",
      "epoch 49; iter: 0; batch classifier loss: 0.109174; batch adversarial loss: 0.329630\n",
      "epoch 50; iter: 0; batch classifier loss: 0.130106; batch adversarial loss: 0.491623\n",
      "epoch 51; iter: 0; batch classifier loss: 0.094133; batch adversarial loss: 0.555729\n",
      "epoch 52; iter: 0; batch classifier loss: 0.142425; batch adversarial loss: 0.428862\n",
      "epoch 53; iter: 0; batch classifier loss: 0.129567; batch adversarial loss: 0.466050\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127519; batch adversarial loss: 0.374491\n",
      "epoch 55; iter: 0; batch classifier loss: 0.068674; batch adversarial loss: 0.409792\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128742; batch adversarial loss: 0.426262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.082868; batch adversarial loss: 0.463270\n",
      "epoch 58; iter: 0; batch classifier loss: 0.152703; batch adversarial loss: 0.362965\n",
      "epoch 59; iter: 0; batch classifier loss: 0.158199; batch adversarial loss: 0.435156\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095495; batch adversarial loss: 0.365500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.089666; batch adversarial loss: 0.476689\n",
      "epoch 62; iter: 0; batch classifier loss: 0.105603; batch adversarial loss: 0.471550\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076294; batch adversarial loss: 0.485675\n",
      "epoch 64; iter: 0; batch classifier loss: 0.130657; batch adversarial loss: 0.409746\n",
      "epoch 65; iter: 0; batch classifier loss: 0.106790; batch adversarial loss: 0.476435\n",
      "epoch 66; iter: 0; batch classifier loss: 0.154035; batch adversarial loss: 0.400908\n",
      "epoch 67; iter: 0; batch classifier loss: 0.073763; batch adversarial loss: 0.429909\n",
      "epoch 68; iter: 0; batch classifier loss: 0.155423; batch adversarial loss: 0.490449\n",
      "epoch 69; iter: 0; batch classifier loss: 0.106869; batch adversarial loss: 0.451089\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091727; batch adversarial loss: 0.440558\n",
      "epoch 71; iter: 0; batch classifier loss: 0.111060; batch adversarial loss: 0.407408\n",
      "epoch 72; iter: 0; batch classifier loss: 0.080977; batch adversarial loss: 0.441310\n",
      "epoch 73; iter: 0; batch classifier loss: 0.102148; batch adversarial loss: 0.334736\n",
      "epoch 74; iter: 0; batch classifier loss: 0.133131; batch adversarial loss: 0.421774\n",
      "epoch 75; iter: 0; batch classifier loss: 0.119083; batch adversarial loss: 0.449889\n",
      "epoch 76; iter: 0; batch classifier loss: 0.166014; batch adversarial loss: 0.404058\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136184; batch adversarial loss: 0.456634\n",
      "epoch 78; iter: 0; batch classifier loss: 0.103755; batch adversarial loss: 0.519914\n",
      "epoch 79; iter: 0; batch classifier loss: 0.112417; batch adversarial loss: 0.555023\n",
      "epoch 80; iter: 0; batch classifier loss: 0.108722; batch adversarial loss: 0.451921\n",
      "epoch 81; iter: 0; batch classifier loss: 0.128527; batch adversarial loss: 0.428232\n",
      "epoch 82; iter: 0; batch classifier loss: 0.122130; batch adversarial loss: 0.516277\n",
      "epoch 83; iter: 0; batch classifier loss: 0.061737; batch adversarial loss: 0.462187\n",
      "epoch 84; iter: 0; batch classifier loss: 0.105493; batch adversarial loss: 0.530905\n",
      "epoch 85; iter: 0; batch classifier loss: 0.103056; batch adversarial loss: 0.480841\n",
      "epoch 86; iter: 0; batch classifier loss: 0.046236; batch adversarial loss: 0.476773\n",
      "epoch 87; iter: 0; batch classifier loss: 0.105165; batch adversarial loss: 0.452503\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074312; batch adversarial loss: 0.392314\n",
      "epoch 89; iter: 0; batch classifier loss: 0.149131; batch adversarial loss: 0.472631\n",
      "epoch 90; iter: 0; batch classifier loss: 0.098424; batch adversarial loss: 0.500444\n",
      "epoch 91; iter: 0; batch classifier loss: 0.078258; batch adversarial loss: 0.473434\n",
      "epoch 92; iter: 0; batch classifier loss: 0.084538; batch adversarial loss: 0.436365\n",
      "epoch 93; iter: 0; batch classifier loss: 0.093785; batch adversarial loss: 0.467171\n",
      "epoch 94; iter: 0; batch classifier loss: 0.081714; batch adversarial loss: 0.526600\n",
      "epoch 95; iter: 0; batch classifier loss: 0.097252; batch adversarial loss: 0.343945\n",
      "epoch 96; iter: 0; batch classifier loss: 0.082911; batch adversarial loss: 0.437186\n",
      "epoch 97; iter: 0; batch classifier loss: 0.104156; batch adversarial loss: 0.487113\n",
      "epoch 98; iter: 0; batch classifier loss: 0.078782; batch adversarial loss: 0.451219\n",
      "epoch 99; iter: 0; batch classifier loss: 0.084018; batch adversarial loss: 0.524098\n",
      "epoch 100; iter: 0; batch classifier loss: 0.090310; batch adversarial loss: 0.429868\n",
      "epoch 101; iter: 0; batch classifier loss: 0.090280; batch adversarial loss: 0.423319\n",
      "epoch 102; iter: 0; batch classifier loss: 0.097426; batch adversarial loss: 0.431145\n",
      "epoch 103; iter: 0; batch classifier loss: 0.078744; batch adversarial loss: 0.357587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.082793; batch adversarial loss: 0.471953\n",
      "epoch 105; iter: 0; batch classifier loss: 0.141325; batch adversarial loss: 0.517973\n",
      "epoch 106; iter: 0; batch classifier loss: 0.092042; batch adversarial loss: 0.522407\n",
      "epoch 107; iter: 0; batch classifier loss: 0.091550; batch adversarial loss: 0.382263\n",
      "epoch 108; iter: 0; batch classifier loss: 0.065908; batch adversarial loss: 0.537567\n",
      "epoch 109; iter: 0; batch classifier loss: 0.082403; batch adversarial loss: 0.490843\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052918; batch adversarial loss: 0.499648\n",
      "epoch 111; iter: 0; batch classifier loss: 0.066815; batch adversarial loss: 0.476841\n",
      "epoch 112; iter: 0; batch classifier loss: 0.069464; batch adversarial loss: 0.442710\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029487; batch adversarial loss: 0.422542\n",
      "epoch 114; iter: 0; batch classifier loss: 0.047870; batch adversarial loss: 0.484605\n",
      "epoch 115; iter: 0; batch classifier loss: 0.056014; batch adversarial loss: 0.475479\n",
      "epoch 116; iter: 0; batch classifier loss: 0.019818; batch adversarial loss: 0.417062\n",
      "epoch 117; iter: 0; batch classifier loss: 0.066393; batch adversarial loss: 0.427496\n",
      "epoch 118; iter: 0; batch classifier loss: 0.055913; batch adversarial loss: 0.488601\n",
      "epoch 119; iter: 0; batch classifier loss: 0.048396; batch adversarial loss: 0.416272\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034902; batch adversarial loss: 0.428995\n",
      "epoch 121; iter: 0; batch classifier loss: 0.070426; batch adversarial loss: 0.422073\n",
      "epoch 122; iter: 0; batch classifier loss: 0.026144; batch adversarial loss: 0.431982\n",
      "epoch 123; iter: 0; batch classifier loss: 0.077988; batch adversarial loss: 0.333052\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027278; batch adversarial loss: 0.405099\n",
      "epoch 125; iter: 0; batch classifier loss: 0.123019; batch adversarial loss: 0.416846\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044375; batch adversarial loss: 0.408708\n",
      "epoch 127; iter: 0; batch classifier loss: 0.035544; batch adversarial loss: 0.445261\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044311; batch adversarial loss: 0.520192\n",
      "epoch 129; iter: 0; batch classifier loss: 0.019401; batch adversarial loss: 0.408200\n",
      "epoch 130; iter: 0; batch classifier loss: 0.058527; batch adversarial loss: 0.391822\n",
      "epoch 131; iter: 0; batch classifier loss: 0.056169; batch adversarial loss: 0.455644\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.385137\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041601; batch adversarial loss: 0.423888\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040385; batch adversarial loss: 0.528127\n",
      "epoch 135; iter: 0; batch classifier loss: 0.034971; batch adversarial loss: 0.434091\n",
      "epoch 136; iter: 0; batch classifier loss: 0.030374; batch adversarial loss: 0.439415\n",
      "epoch 137; iter: 0; batch classifier loss: 0.030756; batch adversarial loss: 0.474958\n",
      "epoch 138; iter: 0; batch classifier loss: 0.064892; batch adversarial loss: 0.441138\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034532; batch adversarial loss: 0.377451\n",
      "epoch 140; iter: 0; batch classifier loss: 0.041204; batch adversarial loss: 0.393279\n",
      "epoch 141; iter: 0; batch classifier loss: 0.034597; batch adversarial loss: 0.483248\n",
      "epoch 142; iter: 0; batch classifier loss: 0.012021; batch adversarial loss: 0.444449\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050145; batch adversarial loss: 0.465651\n",
      "epoch 144; iter: 0; batch classifier loss: 0.020341; batch adversarial loss: 0.443399\n",
      "epoch 145; iter: 0; batch classifier loss: 0.048098; batch adversarial loss: 0.391301\n",
      "epoch 146; iter: 0; batch classifier loss: 0.036561; batch adversarial loss: 0.385230\n",
      "epoch 147; iter: 0; batch classifier loss: 0.013544; batch adversarial loss: 0.387364\n",
      "epoch 148; iter: 0; batch classifier loss: 0.031474; batch adversarial loss: 0.465131\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029460; batch adversarial loss: 0.375746\n",
      "epoch 150; iter: 0; batch classifier loss: 0.030022; batch adversarial loss: 0.496926\n",
      "epoch 151; iter: 0; batch classifier loss: 0.031066; batch adversarial loss: 0.450434\n",
      "epoch 152; iter: 0; batch classifier loss: 0.043709; batch adversarial loss: 0.414924\n",
      "epoch 153; iter: 0; batch classifier loss: 0.017305; batch adversarial loss: 0.459654\n",
      "epoch 154; iter: 0; batch classifier loss: 0.017248; batch adversarial loss: 0.443383\n",
      "epoch 155; iter: 0; batch classifier loss: 0.032316; batch adversarial loss: 0.454215\n",
      "epoch 156; iter: 0; batch classifier loss: 0.040693; batch adversarial loss: 0.432398\n",
      "epoch 157; iter: 0; batch classifier loss: 0.036989; batch adversarial loss: 0.356808\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045545; batch adversarial loss: 0.395845\n",
      "epoch 159; iter: 0; batch classifier loss: 0.038818; batch adversarial loss: 0.422547\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015342; batch adversarial loss: 0.490535\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022599; batch adversarial loss: 0.458447\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036405; batch adversarial loss: 0.385581\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011440; batch adversarial loss: 0.348701\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047595; batch adversarial loss: 0.367844\n",
      "epoch 165; iter: 0; batch classifier loss: 0.010283; batch adversarial loss: 0.444240\n",
      "epoch 166; iter: 0; batch classifier loss: 0.038919; batch adversarial loss: 0.418539\n",
      "epoch 167; iter: 0; batch classifier loss: 0.014740; batch adversarial loss: 0.462988\n",
      "epoch 168; iter: 0; batch classifier loss: 0.059922; batch adversarial loss: 0.470636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.052016; batch adversarial loss: 0.434960\n",
      "epoch 170; iter: 0; batch classifier loss: 0.028398; batch adversarial loss: 0.393153\n",
      "epoch 171; iter: 0; batch classifier loss: 0.030601; batch adversarial loss: 0.408487\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010767; batch adversarial loss: 0.564981\n",
      "epoch 173; iter: 0; batch classifier loss: 0.003190; batch adversarial loss: 0.472031\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022598; batch adversarial loss: 0.445722\n",
      "epoch 175; iter: 0; batch classifier loss: 0.026871; batch adversarial loss: 0.589635\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040722; batch adversarial loss: 0.395508\n",
      "epoch 177; iter: 0; batch classifier loss: 0.015835; batch adversarial loss: 0.447027\n",
      "epoch 178; iter: 0; batch classifier loss: 0.012502; batch adversarial loss: 0.496538\n",
      "epoch 179; iter: 0; batch classifier loss: 0.026002; batch adversarial loss: 0.433671\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014367; batch adversarial loss: 0.461549\n",
      "epoch 181; iter: 0; batch classifier loss: 0.007433; batch adversarial loss: 0.504732\n",
      "epoch 182; iter: 0; batch classifier loss: 0.026729; batch adversarial loss: 0.374719\n",
      "epoch 183; iter: 0; batch classifier loss: 0.045644; batch adversarial loss: 0.466684\n",
      "epoch 184; iter: 0; batch classifier loss: 0.026898; batch adversarial loss: 0.429618\n",
      "epoch 185; iter: 0; batch classifier loss: 0.021884; batch adversarial loss: 0.511275\n",
      "epoch 186; iter: 0; batch classifier loss: 0.027753; batch adversarial loss: 0.444716\n",
      "epoch 187; iter: 0; batch classifier loss: 0.017669; batch adversarial loss: 0.374930\n",
      "epoch 188; iter: 0; batch classifier loss: 0.045824; batch adversarial loss: 0.368501\n",
      "epoch 189; iter: 0; batch classifier loss: 0.015949; batch adversarial loss: 0.457860\n",
      "epoch 190; iter: 0; batch classifier loss: 0.010514; batch adversarial loss: 0.431986\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021957; batch adversarial loss: 0.461238\n",
      "epoch 192; iter: 0; batch classifier loss: 0.014927; batch adversarial loss: 0.560107\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028837; batch adversarial loss: 0.409037\n",
      "epoch 194; iter: 0; batch classifier loss: 0.035957; batch adversarial loss: 0.400007\n",
      "epoch 195; iter: 0; batch classifier loss: 0.022473; batch adversarial loss: 0.479496\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010219; batch adversarial loss: 0.396751\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018059; batch adversarial loss: 0.461629\n",
      "epoch 198; iter: 0; batch classifier loss: 0.024675; batch adversarial loss: 0.430301\n",
      "epoch 199; iter: 0; batch classifier loss: 0.017806; batch adversarial loss: 0.429343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.674686; batch adversarial loss: 0.900536\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637965; batch adversarial loss: 0.946849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.839272; batch adversarial loss: 0.965509\n",
      "epoch 3; iter: 0; batch classifier loss: 1.039925; batch adversarial loss: 0.930824\n",
      "epoch 4; iter: 0; batch classifier loss: 0.975206; batch adversarial loss: 0.835226\n",
      "epoch 5; iter: 0; batch classifier loss: 0.750612; batch adversarial loss: 0.737211\n",
      "epoch 6; iter: 0; batch classifier loss: 0.693122; batch adversarial loss: 0.696864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.648218; batch adversarial loss: 0.583152\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520202; batch adversarial loss: 0.566402\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401158; batch adversarial loss: 0.524203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337967; batch adversarial loss: 0.503033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270806; batch adversarial loss: 0.492739\n",
      "epoch 12; iter: 0; batch classifier loss: 0.311010; batch adversarial loss: 0.451422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324474; batch adversarial loss: 0.499444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358169; batch adversarial loss: 0.446614\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266856; batch adversarial loss: 0.527033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281946; batch adversarial loss: 0.468576\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226424; batch adversarial loss: 0.421810\n",
      "epoch 18; iter: 0; batch classifier loss: 0.262641; batch adversarial loss: 0.522625\n",
      "epoch 19; iter: 0; batch classifier loss: 0.265159; batch adversarial loss: 0.485247\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257801; batch adversarial loss: 0.490315\n",
      "epoch 21; iter: 0; batch classifier loss: 0.215649; batch adversarial loss: 0.442624\n",
      "epoch 22; iter: 0; batch classifier loss: 0.208962; batch adversarial loss: 0.464257\n",
      "epoch 23; iter: 0; batch classifier loss: 0.174426; batch adversarial loss: 0.551988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251408; batch adversarial loss: 0.502415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.202209; batch adversarial loss: 0.476552\n",
      "epoch 26; iter: 0; batch classifier loss: 0.170184; batch adversarial loss: 0.467739\n",
      "epoch 27; iter: 0; batch classifier loss: 0.164945; batch adversarial loss: 0.550518\n",
      "epoch 28; iter: 0; batch classifier loss: 0.170502; batch adversarial loss: 0.502670\n",
      "epoch 29; iter: 0; batch classifier loss: 0.212660; batch adversarial loss: 0.455525\n",
      "epoch 30; iter: 0; batch classifier loss: 0.160316; batch adversarial loss: 0.460745\n",
      "epoch 31; iter: 0; batch classifier loss: 0.193510; batch adversarial loss: 0.471865\n",
      "epoch 32; iter: 0; batch classifier loss: 0.187038; batch adversarial loss: 0.392059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.164943; batch adversarial loss: 0.400399\n",
      "epoch 34; iter: 0; batch classifier loss: 0.137739; batch adversarial loss: 0.446363\n",
      "epoch 35; iter: 0; batch classifier loss: 0.142474; batch adversarial loss: 0.453370\n",
      "epoch 36; iter: 0; batch classifier loss: 0.169667; batch adversarial loss: 0.432599\n",
      "epoch 37; iter: 0; batch classifier loss: 0.187762; batch adversarial loss: 0.465045\n",
      "epoch 38; iter: 0; batch classifier loss: 0.113467; batch adversarial loss: 0.456089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.182447; batch adversarial loss: 0.486343\n",
      "epoch 40; iter: 0; batch classifier loss: 0.125481; batch adversarial loss: 0.482841\n",
      "epoch 41; iter: 0; batch classifier loss: 0.114391; batch adversarial loss: 0.422103\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179209; batch adversarial loss: 0.413987\n",
      "epoch 43; iter: 0; batch classifier loss: 0.162970; batch adversarial loss: 0.332765\n",
      "epoch 44; iter: 0; batch classifier loss: 0.131222; batch adversarial loss: 0.441145\n",
      "epoch 45; iter: 0; batch classifier loss: 0.081762; batch adversarial loss: 0.522397\n",
      "epoch 46; iter: 0; batch classifier loss: 0.116646; batch adversarial loss: 0.536975\n",
      "epoch 47; iter: 0; batch classifier loss: 0.120753; batch adversarial loss: 0.427110\n",
      "epoch 48; iter: 0; batch classifier loss: 0.112695; batch adversarial loss: 0.428723\n",
      "epoch 49; iter: 0; batch classifier loss: 0.101752; batch adversarial loss: 0.391687\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123709; batch adversarial loss: 0.455294\n",
      "epoch 51; iter: 0; batch classifier loss: 0.072541; batch adversarial loss: 0.394118\n",
      "epoch 52; iter: 0; batch classifier loss: 0.081259; batch adversarial loss: 0.391796\n",
      "epoch 53; iter: 0; batch classifier loss: 0.100243; batch adversarial loss: 0.548258\n",
      "epoch 54; iter: 0; batch classifier loss: 0.072999; batch adversarial loss: 0.401627\n",
      "epoch 55; iter: 0; batch classifier loss: 0.099219; batch adversarial loss: 0.405575\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087078; batch adversarial loss: 0.480132\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120621; batch adversarial loss: 0.400160\n",
      "epoch 58; iter: 0; batch classifier loss: 0.168943; batch adversarial loss: 0.497690\n",
      "epoch 59; iter: 0; batch classifier loss: 0.084263; batch adversarial loss: 0.465476\n",
      "epoch 60; iter: 0; batch classifier loss: 0.062706; batch adversarial loss: 0.456706\n",
      "epoch 61; iter: 0; batch classifier loss: 0.080146; batch adversarial loss: 0.415478\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057967; batch adversarial loss: 0.531221\n",
      "epoch 63; iter: 0; batch classifier loss: 0.054378; batch adversarial loss: 0.528946\n",
      "epoch 64; iter: 0; batch classifier loss: 0.122489; batch adversarial loss: 0.433531\n",
      "epoch 65; iter: 0; batch classifier loss: 0.079513; batch adversarial loss: 0.545304\n",
      "epoch 66; iter: 0; batch classifier loss: 0.076954; batch adversarial loss: 0.396661\n",
      "epoch 67; iter: 0; batch classifier loss: 0.122663; batch adversarial loss: 0.446869\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052597; batch adversarial loss: 0.423486\n",
      "epoch 69; iter: 0; batch classifier loss: 0.078711; batch adversarial loss: 0.428592\n",
      "epoch 70; iter: 0; batch classifier loss: 0.084489; batch adversarial loss: 0.444492\n",
      "epoch 71; iter: 0; batch classifier loss: 0.062590; batch adversarial loss: 0.451560\n",
      "epoch 72; iter: 0; batch classifier loss: 0.092605; batch adversarial loss: 0.364609\n",
      "epoch 73; iter: 0; batch classifier loss: 0.101898; batch adversarial loss: 0.400756\n",
      "epoch 74; iter: 0; batch classifier loss: 0.064990; batch adversarial loss: 0.526444\n",
      "epoch 75; iter: 0; batch classifier loss: 0.083753; batch adversarial loss: 0.517886\n",
      "epoch 76; iter: 0; batch classifier loss: 0.075689; batch adversarial loss: 0.487540\n",
      "epoch 77; iter: 0; batch classifier loss: 0.102795; batch adversarial loss: 0.470112\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072419; batch adversarial loss: 0.456738\n",
      "epoch 79; iter: 0; batch classifier loss: 0.077402; batch adversarial loss: 0.528735\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061877; batch adversarial loss: 0.517633\n",
      "epoch 81; iter: 0; batch classifier loss: 0.074041; batch adversarial loss: 0.543321\n",
      "epoch 82; iter: 0; batch classifier loss: 0.064650; batch adversarial loss: 0.433647\n",
      "epoch 83; iter: 0; batch classifier loss: 0.086271; batch adversarial loss: 0.327519\n",
      "epoch 84; iter: 0; batch classifier loss: 0.086724; batch adversarial loss: 0.372486\n",
      "epoch 85; iter: 0; batch classifier loss: 0.040900; batch adversarial loss: 0.406482\n",
      "epoch 86; iter: 0; batch classifier loss: 0.082914; batch adversarial loss: 0.412781\n",
      "epoch 87; iter: 0; batch classifier loss: 0.062333; batch adversarial loss: 0.474734\n",
      "epoch 88; iter: 0; batch classifier loss: 0.103752; batch adversarial loss: 0.472872\n",
      "epoch 89; iter: 0; batch classifier loss: 0.100076; batch adversarial loss: 0.489777\n",
      "epoch 90; iter: 0; batch classifier loss: 0.065066; batch adversarial loss: 0.447139\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055953; batch adversarial loss: 0.437871\n",
      "epoch 92; iter: 0; batch classifier loss: 0.044840; batch adversarial loss: 0.391860\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067897; batch adversarial loss: 0.414985\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079173; batch adversarial loss: 0.473821\n",
      "epoch 95; iter: 0; batch classifier loss: 0.047828; batch adversarial loss: 0.473785\n",
      "epoch 96; iter: 0; batch classifier loss: 0.072838; batch adversarial loss: 0.379679\n",
      "epoch 97; iter: 0; batch classifier loss: 0.050573; batch adversarial loss: 0.415308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.040560; batch adversarial loss: 0.446340\n",
      "epoch 99; iter: 0; batch classifier loss: 0.047794; batch adversarial loss: 0.410588\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109629; batch adversarial loss: 0.453468\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068289; batch adversarial loss: 0.408530\n",
      "epoch 102; iter: 0; batch classifier loss: 0.077886; batch adversarial loss: 0.521052\n",
      "epoch 103; iter: 0; batch classifier loss: 0.087606; batch adversarial loss: 0.473446\n",
      "epoch 104; iter: 0; batch classifier loss: 0.073224; batch adversarial loss: 0.524562\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040957; batch adversarial loss: 0.456909\n",
      "epoch 106; iter: 0; batch classifier loss: 0.056412; batch adversarial loss: 0.499159\n",
      "epoch 107; iter: 0; batch classifier loss: 0.032606; batch adversarial loss: 0.393172\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052153; batch adversarial loss: 0.492605\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029132; batch adversarial loss: 0.415988\n",
      "epoch 110; iter: 0; batch classifier loss: 0.049793; batch adversarial loss: 0.468221\n",
      "epoch 111; iter: 0; batch classifier loss: 0.073525; batch adversarial loss: 0.527992\n",
      "epoch 112; iter: 0; batch classifier loss: 0.046302; batch adversarial loss: 0.471980\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060716; batch adversarial loss: 0.507734\n",
      "epoch 114; iter: 0; batch classifier loss: 0.036158; batch adversarial loss: 0.470132\n",
      "epoch 115; iter: 0; batch classifier loss: 0.063204; batch adversarial loss: 0.425510\n",
      "epoch 116; iter: 0; batch classifier loss: 0.088430; batch adversarial loss: 0.410766\n",
      "epoch 117; iter: 0; batch classifier loss: 0.021748; batch adversarial loss: 0.581053\n",
      "epoch 118; iter: 0; batch classifier loss: 0.044620; batch adversarial loss: 0.438734\n",
      "epoch 119; iter: 0; batch classifier loss: 0.040601; batch adversarial loss: 0.446477\n",
      "epoch 120; iter: 0; batch classifier loss: 0.022311; batch adversarial loss: 0.427780\n",
      "epoch 121; iter: 0; batch classifier loss: 0.028344; batch adversarial loss: 0.414142\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035472; batch adversarial loss: 0.555573\n",
      "epoch 123; iter: 0; batch classifier loss: 0.060536; batch adversarial loss: 0.445971\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032489; batch adversarial loss: 0.478086\n",
      "epoch 125; iter: 0; batch classifier loss: 0.040495; batch adversarial loss: 0.498182\n",
      "epoch 126; iter: 0; batch classifier loss: 0.054192; batch adversarial loss: 0.432853\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044199; batch adversarial loss: 0.432067\n",
      "epoch 128; iter: 0; batch classifier loss: 0.019496; batch adversarial loss: 0.517017\n",
      "epoch 129; iter: 0; batch classifier loss: 0.064865; batch adversarial loss: 0.440803\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025975; batch adversarial loss: 0.447873\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031966; batch adversarial loss: 0.364458\n",
      "epoch 132; iter: 0; batch classifier loss: 0.023582; batch adversarial loss: 0.457182\n",
      "epoch 133; iter: 0; batch classifier loss: 0.018559; batch adversarial loss: 0.548387\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048667; batch adversarial loss: 0.492581\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039276; batch adversarial loss: 0.383716\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024522; batch adversarial loss: 0.429379\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036450; batch adversarial loss: 0.479958\n",
      "epoch 138; iter: 0; batch classifier loss: 0.041641; batch adversarial loss: 0.423871\n",
      "epoch 139; iter: 0; batch classifier loss: 0.028001; batch adversarial loss: 0.463771\n",
      "epoch 140; iter: 0; batch classifier loss: 0.047755; batch adversarial loss: 0.447056\n",
      "epoch 141; iter: 0; batch classifier loss: 0.032656; batch adversarial loss: 0.420537\n",
      "epoch 142; iter: 0; batch classifier loss: 0.023242; batch adversarial loss: 0.408981\n",
      "epoch 143; iter: 0; batch classifier loss: 0.033973; batch adversarial loss: 0.415675\n",
      "epoch 144; iter: 0; batch classifier loss: 0.025983; batch adversarial loss: 0.471565\n",
      "epoch 145; iter: 0; batch classifier loss: 0.044643; batch adversarial loss: 0.442293\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016733; batch adversarial loss: 0.401144\n",
      "epoch 147; iter: 0; batch classifier loss: 0.046153; batch adversarial loss: 0.413908\n",
      "epoch 148; iter: 0; batch classifier loss: 0.033779; batch adversarial loss: 0.431105\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013132; batch adversarial loss: 0.443170\n",
      "epoch 150; iter: 0; batch classifier loss: 0.028656; batch adversarial loss: 0.513417\n",
      "epoch 151; iter: 0; batch classifier loss: 0.008728; batch adversarial loss: 0.432842\n",
      "epoch 152; iter: 0; batch classifier loss: 0.032064; batch adversarial loss: 0.429757\n",
      "epoch 153; iter: 0; batch classifier loss: 0.012860; batch adversarial loss: 0.491095\n",
      "epoch 154; iter: 0; batch classifier loss: 0.023719; batch adversarial loss: 0.415093\n",
      "epoch 155; iter: 0; batch classifier loss: 0.044049; batch adversarial loss: 0.407294\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014855; batch adversarial loss: 0.450043\n",
      "epoch 157; iter: 0; batch classifier loss: 0.012983; batch adversarial loss: 0.488751\n",
      "epoch 158; iter: 0; batch classifier loss: 0.007956; batch adversarial loss: 0.443133\n",
      "epoch 159; iter: 0; batch classifier loss: 0.023441; batch adversarial loss: 0.524593\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030335; batch adversarial loss: 0.435533\n",
      "epoch 161; iter: 0; batch classifier loss: 0.015211; batch adversarial loss: 0.396331\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024788; batch adversarial loss: 0.443881\n",
      "epoch 163; iter: 0; batch classifier loss: 0.022646; batch adversarial loss: 0.483140\n",
      "epoch 164; iter: 0; batch classifier loss: 0.008530; batch adversarial loss: 0.494836\n",
      "epoch 165; iter: 0; batch classifier loss: 0.026620; batch adversarial loss: 0.431389\n",
      "epoch 166; iter: 0; batch classifier loss: 0.026772; batch adversarial loss: 0.518793\n",
      "epoch 167; iter: 0; batch classifier loss: 0.013025; batch adversarial loss: 0.522537\n",
      "epoch 168; iter: 0; batch classifier loss: 0.011553; batch adversarial loss: 0.381636\n",
      "epoch 169; iter: 0; batch classifier loss: 0.026817; batch adversarial loss: 0.362762\n",
      "epoch 170; iter: 0; batch classifier loss: 0.011023; batch adversarial loss: 0.418101\n",
      "epoch 171; iter: 0; batch classifier loss: 0.004979; batch adversarial loss: 0.424284\n",
      "epoch 172; iter: 0; batch classifier loss: 0.026130; batch adversarial loss: 0.485831\n",
      "epoch 173; iter: 0; batch classifier loss: 0.008242; batch adversarial loss: 0.540177\n",
      "epoch 174; iter: 0; batch classifier loss: 0.015262; batch adversarial loss: 0.414587\n",
      "epoch 175; iter: 0; batch classifier loss: 0.024132; batch adversarial loss: 0.499226\n",
      "epoch 176; iter: 0; batch classifier loss: 0.029460; batch adversarial loss: 0.339338\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006106; batch adversarial loss: 0.519606\n",
      "epoch 178; iter: 0; batch classifier loss: 0.005840; batch adversarial loss: 0.521654\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010024; batch adversarial loss: 0.502720\n",
      "epoch 180; iter: 0; batch classifier loss: 0.014527; batch adversarial loss: 0.413125\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017245; batch adversarial loss: 0.443748\n",
      "epoch 182; iter: 0; batch classifier loss: 0.036054; batch adversarial loss: 0.447172\n",
      "epoch 183; iter: 0; batch classifier loss: 0.013839; batch adversarial loss: 0.532572\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020126; batch adversarial loss: 0.437570\n",
      "epoch 185; iter: 0; batch classifier loss: 0.012589; batch adversarial loss: 0.440211\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009894; batch adversarial loss: 0.448710\n",
      "epoch 187; iter: 0; batch classifier loss: 0.019443; batch adversarial loss: 0.454922\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014073; batch adversarial loss: 0.497589\n",
      "epoch 189; iter: 0; batch classifier loss: 0.007208; batch adversarial loss: 0.395055\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013922; batch adversarial loss: 0.434915\n",
      "epoch 191; iter: 0; batch classifier loss: 0.018103; batch adversarial loss: 0.417299\n",
      "epoch 192; iter: 0; batch classifier loss: 0.032628; batch adversarial loss: 0.488690\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022020; batch adversarial loss: 0.350135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.013359; batch adversarial loss: 0.447446\n",
      "epoch 195; iter: 0; batch classifier loss: 0.015483; batch adversarial loss: 0.401320\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017504; batch adversarial loss: 0.382178\n",
      "epoch 197; iter: 0; batch classifier loss: 0.014623; batch adversarial loss: 0.428278\n",
      "epoch 198; iter: 0; batch classifier loss: 0.007334; batch adversarial loss: 0.400807\n",
      "epoch 199; iter: 0; batch classifier loss: 0.042205; batch adversarial loss: 0.365395\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677021; batch adversarial loss: 0.760887\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610123; batch adversarial loss: 0.725393\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630184; batch adversarial loss: 0.709564\n",
      "epoch 3; iter: 0; batch classifier loss: 0.549885; batch adversarial loss: 0.673806\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444560; batch adversarial loss: 0.600429\n",
      "epoch 5; iter: 0; batch classifier loss: 0.364954; batch adversarial loss: 0.602828\n",
      "epoch 6; iter: 0; batch classifier loss: 0.332548; batch adversarial loss: 0.541311\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301205; batch adversarial loss: 0.470894\n",
      "epoch 8; iter: 0; batch classifier loss: 0.279173; batch adversarial loss: 0.546235\n",
      "epoch 9; iter: 0; batch classifier loss: 0.302647; batch adversarial loss: 0.516037\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297446; batch adversarial loss: 0.514478\n",
      "epoch 11; iter: 0; batch classifier loss: 0.295841; batch adversarial loss: 0.521691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280050; batch adversarial loss: 0.562315\n",
      "epoch 13; iter: 0; batch classifier loss: 0.289783; batch adversarial loss: 0.581771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262197; batch adversarial loss: 0.467069\n",
      "epoch 15; iter: 0; batch classifier loss: 0.257874; batch adversarial loss: 0.479450\n",
      "epoch 16; iter: 0; batch classifier loss: 0.158988; batch adversarial loss: 0.489537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241754; batch adversarial loss: 0.562781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.202085; batch adversarial loss: 0.549250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.163271; batch adversarial loss: 0.441448\n",
      "epoch 20; iter: 0; batch classifier loss: 0.190965; batch adversarial loss: 0.418110\n",
      "epoch 21; iter: 0; batch classifier loss: 0.177201; batch adversarial loss: 0.474768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.216964; batch adversarial loss: 0.446135\n",
      "epoch 23; iter: 0; batch classifier loss: 0.177598; batch adversarial loss: 0.468304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.272760; batch adversarial loss: 0.469027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.191136; batch adversarial loss: 0.442311\n",
      "epoch 26; iter: 0; batch classifier loss: 0.181006; batch adversarial loss: 0.386206\n",
      "epoch 27; iter: 0; batch classifier loss: 0.162185; batch adversarial loss: 0.382201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.140000; batch adversarial loss: 0.393245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204448; batch adversarial loss: 0.489733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.131679; batch adversarial loss: 0.453036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140411; batch adversarial loss: 0.525764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.131832; batch adversarial loss: 0.395140\n",
      "epoch 33; iter: 0; batch classifier loss: 0.130420; batch adversarial loss: 0.431037\n",
      "epoch 34; iter: 0; batch classifier loss: 0.161403; batch adversarial loss: 0.514053\n",
      "epoch 35; iter: 0; batch classifier loss: 0.105911; batch adversarial loss: 0.448797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107617; batch adversarial loss: 0.444801\n",
      "epoch 37; iter: 0; batch classifier loss: 0.095480; batch adversarial loss: 0.451279\n",
      "epoch 38; iter: 0; batch classifier loss: 0.164056; batch adversarial loss: 0.469924\n",
      "epoch 39; iter: 0; batch classifier loss: 0.110560; batch adversarial loss: 0.401868\n",
      "epoch 40; iter: 0; batch classifier loss: 0.104718; batch adversarial loss: 0.466781\n",
      "epoch 41; iter: 0; batch classifier loss: 0.168791; batch adversarial loss: 0.467807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.113049; batch adversarial loss: 0.408032\n",
      "epoch 43; iter: 0; batch classifier loss: 0.135708; batch adversarial loss: 0.463703\n",
      "epoch 44; iter: 0; batch classifier loss: 0.129026; batch adversarial loss: 0.447994\n",
      "epoch 45; iter: 0; batch classifier loss: 0.099533; batch adversarial loss: 0.403325\n",
      "epoch 46; iter: 0; batch classifier loss: 0.133378; batch adversarial loss: 0.430626\n",
      "epoch 47; iter: 0; batch classifier loss: 0.164228; batch adversarial loss: 0.468240\n",
      "epoch 48; iter: 0; batch classifier loss: 0.156242; batch adversarial loss: 0.492372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.105817; batch adversarial loss: 0.418392\n",
      "epoch 50; iter: 0; batch classifier loss: 0.089576; batch adversarial loss: 0.432765\n",
      "epoch 51; iter: 0; batch classifier loss: 0.065705; batch adversarial loss: 0.497032\n",
      "epoch 52; iter: 0; batch classifier loss: 0.114439; batch adversarial loss: 0.496031\n",
      "epoch 53; iter: 0; batch classifier loss: 0.140005; batch adversarial loss: 0.397839\n",
      "epoch 54; iter: 0; batch classifier loss: 0.084718; batch adversarial loss: 0.486411\n",
      "epoch 55; iter: 0; batch classifier loss: 0.106503; batch adversarial loss: 0.441689\n",
      "epoch 56; iter: 0; batch classifier loss: 0.066501; batch adversarial loss: 0.365827\n",
      "epoch 57; iter: 0; batch classifier loss: 0.083202; batch adversarial loss: 0.449331\n",
      "epoch 58; iter: 0; batch classifier loss: 0.101562; batch adversarial loss: 0.531506\n",
      "epoch 59; iter: 0; batch classifier loss: 0.088126; batch adversarial loss: 0.375128\n",
      "epoch 60; iter: 0; batch classifier loss: 0.119163; batch adversarial loss: 0.481125\n",
      "epoch 61; iter: 0; batch classifier loss: 0.074152; batch adversarial loss: 0.430914\n",
      "epoch 62; iter: 0; batch classifier loss: 0.090719; batch adversarial loss: 0.486864\n",
      "epoch 63; iter: 0; batch classifier loss: 0.102754; batch adversarial loss: 0.463535\n",
      "epoch 64; iter: 0; batch classifier loss: 0.105844; batch adversarial loss: 0.361350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.145411; batch adversarial loss: 0.408224\n",
      "epoch 66; iter: 0; batch classifier loss: 0.087799; batch adversarial loss: 0.433477\n",
      "epoch 67; iter: 0; batch classifier loss: 0.064433; batch adversarial loss: 0.435236\n",
      "epoch 68; iter: 0; batch classifier loss: 0.106798; batch adversarial loss: 0.507392\n",
      "epoch 69; iter: 0; batch classifier loss: 0.069167; batch adversarial loss: 0.433656\n",
      "epoch 70; iter: 0; batch classifier loss: 0.091104; batch adversarial loss: 0.438001\n",
      "epoch 71; iter: 0; batch classifier loss: 0.096127; batch adversarial loss: 0.325246\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077923; batch adversarial loss: 0.399962\n",
      "epoch 73; iter: 0; batch classifier loss: 0.111622; batch adversarial loss: 0.461893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.050036; batch adversarial loss: 0.466660\n",
      "epoch 75; iter: 0; batch classifier loss: 0.060475; batch adversarial loss: 0.393810\n",
      "epoch 76; iter: 0; batch classifier loss: 0.091168; batch adversarial loss: 0.434173\n",
      "epoch 77; iter: 0; batch classifier loss: 0.084248; batch adversarial loss: 0.489659\n",
      "epoch 78; iter: 0; batch classifier loss: 0.075599; batch adversarial loss: 0.405306\n",
      "epoch 79; iter: 0; batch classifier loss: 0.091086; batch adversarial loss: 0.436995\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090404; batch adversarial loss: 0.426456\n",
      "epoch 81; iter: 0; batch classifier loss: 0.098740; batch adversarial loss: 0.421204\n",
      "epoch 82; iter: 0; batch classifier loss: 0.086526; batch adversarial loss: 0.538864\n",
      "epoch 83; iter: 0; batch classifier loss: 0.105801; batch adversarial loss: 0.433888\n",
      "epoch 84; iter: 0; batch classifier loss: 0.111710; batch adversarial loss: 0.338286\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085845; batch adversarial loss: 0.390760\n",
      "epoch 86; iter: 0; batch classifier loss: 0.060291; batch adversarial loss: 0.437453\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056405; batch adversarial loss: 0.357790\n",
      "epoch 88; iter: 0; batch classifier loss: 0.087300; batch adversarial loss: 0.354645\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034630; batch adversarial loss: 0.448881\n",
      "epoch 90; iter: 0; batch classifier loss: 0.066728; batch adversarial loss: 0.405700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91; iter: 0; batch classifier loss: 0.036058; batch adversarial loss: 0.441967\n",
      "epoch 92; iter: 0; batch classifier loss: 0.055998; batch adversarial loss: 0.401862\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080225; batch adversarial loss: 0.388010\n",
      "epoch 94; iter: 0; batch classifier loss: 0.021813; batch adversarial loss: 0.503519\n",
      "epoch 95; iter: 0; batch classifier loss: 0.075852; batch adversarial loss: 0.453205\n",
      "epoch 96; iter: 0; batch classifier loss: 0.071660; batch adversarial loss: 0.318212\n",
      "epoch 97; iter: 0; batch classifier loss: 0.056375; batch adversarial loss: 0.436807\n",
      "epoch 98; iter: 0; batch classifier loss: 0.030593; batch adversarial loss: 0.392003\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053075; batch adversarial loss: 0.354543\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070525; batch adversarial loss: 0.489959\n",
      "epoch 101; iter: 0; batch classifier loss: 0.068589; batch adversarial loss: 0.402527\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058337; batch adversarial loss: 0.381075\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038499; batch adversarial loss: 0.403907\n",
      "epoch 104; iter: 0; batch classifier loss: 0.032527; batch adversarial loss: 0.413596\n",
      "epoch 105; iter: 0; batch classifier loss: 0.086268; batch adversarial loss: 0.437753\n",
      "epoch 106; iter: 0; batch classifier loss: 0.049224; batch adversarial loss: 0.392487\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033826; batch adversarial loss: 0.430686\n",
      "epoch 108; iter: 0; batch classifier loss: 0.040247; batch adversarial loss: 0.497133\n",
      "epoch 109; iter: 0; batch classifier loss: 0.021836; batch adversarial loss: 0.434705\n",
      "epoch 110; iter: 0; batch classifier loss: 0.052545; batch adversarial loss: 0.390772\n",
      "epoch 111; iter: 0; batch classifier loss: 0.028834; batch adversarial loss: 0.415722\n",
      "epoch 112; iter: 0; batch classifier loss: 0.058852; batch adversarial loss: 0.461857\n",
      "epoch 113; iter: 0; batch classifier loss: 0.039327; batch adversarial loss: 0.589694\n",
      "epoch 114; iter: 0; batch classifier loss: 0.022995; batch adversarial loss: 0.395590\n",
      "epoch 115; iter: 0; batch classifier loss: 0.045461; batch adversarial loss: 0.375635\n",
      "epoch 116; iter: 0; batch classifier loss: 0.026191; batch adversarial loss: 0.510544\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032171; batch adversarial loss: 0.402292\n",
      "epoch 118; iter: 0; batch classifier loss: 0.024474; batch adversarial loss: 0.485299\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050876; batch adversarial loss: 0.427966\n",
      "epoch 120; iter: 0; batch classifier loss: 0.036458; batch adversarial loss: 0.367645\n",
      "epoch 121; iter: 0; batch classifier loss: 0.032254; batch adversarial loss: 0.435434\n",
      "epoch 122; iter: 0; batch classifier loss: 0.082175; batch adversarial loss: 0.449472\n",
      "epoch 123; iter: 0; batch classifier loss: 0.015979; batch adversarial loss: 0.470009\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046279; batch adversarial loss: 0.394162\n",
      "epoch 125; iter: 0; batch classifier loss: 0.020909; batch adversarial loss: 0.508359\n",
      "epoch 126; iter: 0; batch classifier loss: 0.035973; batch adversarial loss: 0.465861\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021068; batch adversarial loss: 0.426216\n",
      "epoch 128; iter: 0; batch classifier loss: 0.058803; batch adversarial loss: 0.418593\n",
      "epoch 129; iter: 0; batch classifier loss: 0.026455; batch adversarial loss: 0.401737\n",
      "epoch 130; iter: 0; batch classifier loss: 0.025577; batch adversarial loss: 0.365882\n",
      "epoch 131; iter: 0; batch classifier loss: 0.028023; batch adversarial loss: 0.378341\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015418; batch adversarial loss: 0.423361\n",
      "epoch 133; iter: 0; batch classifier loss: 0.049224; batch adversarial loss: 0.556455\n",
      "epoch 134; iter: 0; batch classifier loss: 0.025796; batch adversarial loss: 0.397159\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017501; batch adversarial loss: 0.396590\n",
      "epoch 136; iter: 0; batch classifier loss: 0.018890; batch adversarial loss: 0.464094\n",
      "epoch 137; iter: 0; batch classifier loss: 0.022082; batch adversarial loss: 0.443281\n",
      "epoch 138; iter: 0; batch classifier loss: 0.015153; batch adversarial loss: 0.485766\n",
      "epoch 139; iter: 0; batch classifier loss: 0.037539; batch adversarial loss: 0.472757\n",
      "epoch 140; iter: 0; batch classifier loss: 0.034623; batch adversarial loss: 0.458756\n",
      "epoch 141; iter: 0; batch classifier loss: 0.028186; batch adversarial loss: 0.452034\n",
      "epoch 142; iter: 0; batch classifier loss: 0.034325; batch adversarial loss: 0.479600\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050575; batch adversarial loss: 0.431520\n",
      "epoch 144; iter: 0; batch classifier loss: 0.009342; batch adversarial loss: 0.600270\n",
      "epoch 145; iter: 0; batch classifier loss: 0.020081; batch adversarial loss: 0.418663\n",
      "epoch 146; iter: 0; batch classifier loss: 0.045047; batch adversarial loss: 0.360624\n",
      "epoch 147; iter: 0; batch classifier loss: 0.027295; batch adversarial loss: 0.453851\n",
      "epoch 148; iter: 0; batch classifier loss: 0.020519; batch adversarial loss: 0.478093\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026721; batch adversarial loss: 0.534314\n",
      "epoch 150; iter: 0; batch classifier loss: 0.013100; batch adversarial loss: 0.422315\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015501; batch adversarial loss: 0.347080\n",
      "epoch 152; iter: 0; batch classifier loss: 0.018349; batch adversarial loss: 0.428185\n",
      "epoch 153; iter: 0; batch classifier loss: 0.022579; batch adversarial loss: 0.395357\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028686; batch adversarial loss: 0.433602\n",
      "epoch 155; iter: 0; batch classifier loss: 0.056861; batch adversarial loss: 0.552043\n",
      "epoch 156; iter: 0; batch classifier loss: 0.015698; batch adversarial loss: 0.439831\n",
      "epoch 157; iter: 0; batch classifier loss: 0.048277; batch adversarial loss: 0.381685\n",
      "epoch 158; iter: 0; batch classifier loss: 0.017850; batch adversarial loss: 0.493889\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022352; batch adversarial loss: 0.438436\n",
      "epoch 160; iter: 0; batch classifier loss: 0.021950; batch adversarial loss: 0.521585\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035212; batch adversarial loss: 0.416821\n",
      "epoch 162; iter: 0; batch classifier loss: 0.016647; batch adversarial loss: 0.472308\n",
      "epoch 163; iter: 0; batch classifier loss: 0.006666; batch adversarial loss: 0.482186\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010076; batch adversarial loss: 0.465410\n",
      "epoch 165; iter: 0; batch classifier loss: 0.023207; batch adversarial loss: 0.470262\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014858; batch adversarial loss: 0.395176\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006309; batch adversarial loss: 0.461829\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016088; batch adversarial loss: 0.381248\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020327; batch adversarial loss: 0.388665\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020101; batch adversarial loss: 0.402943\n",
      "epoch 171; iter: 0; batch classifier loss: 0.058465; batch adversarial loss: 0.422367\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012984; batch adversarial loss: 0.323572\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027407; batch adversarial loss: 0.474251\n",
      "epoch 174; iter: 0; batch classifier loss: 0.017230; batch adversarial loss: 0.364020\n",
      "epoch 175; iter: 0; batch classifier loss: 0.029347; batch adversarial loss: 0.450372\n",
      "epoch 176; iter: 0; batch classifier loss: 0.033450; batch adversarial loss: 0.537220\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021956; batch adversarial loss: 0.489141\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013886; batch adversarial loss: 0.446721\n",
      "epoch 179; iter: 0; batch classifier loss: 0.028554; batch adversarial loss: 0.451334\n",
      "epoch 180; iter: 0; batch classifier loss: 0.010200; batch adversarial loss: 0.448206\n",
      "epoch 181; iter: 0; batch classifier loss: 0.011352; batch adversarial loss: 0.402125\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021445; batch adversarial loss: 0.423862\n",
      "epoch 183; iter: 0; batch classifier loss: 0.017784; batch adversarial loss: 0.404363\n",
      "epoch 184; iter: 0; batch classifier loss: 0.018184; batch adversarial loss: 0.484772\n",
      "epoch 185; iter: 0; batch classifier loss: 0.053224; batch adversarial loss: 0.429783\n",
      "epoch 186; iter: 0; batch classifier loss: 0.005261; batch adversarial loss: 0.410627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 187; iter: 0; batch classifier loss: 0.046041; batch adversarial loss: 0.360483\n",
      "epoch 188; iter: 0; batch classifier loss: 0.007025; batch adversarial loss: 0.468981\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013569; batch adversarial loss: 0.490226\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023375; batch adversarial loss: 0.513568\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019647; batch adversarial loss: 0.353037\n",
      "epoch 192; iter: 0; batch classifier loss: 0.021054; batch adversarial loss: 0.487648\n",
      "epoch 193; iter: 0; batch classifier loss: 0.085937; batch adversarial loss: 0.341580\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014086; batch adversarial loss: 0.541184\n",
      "epoch 195; iter: 0; batch classifier loss: 0.011537; batch adversarial loss: 0.438728\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015424; batch adversarial loss: 0.492886\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013054; batch adversarial loss: 0.382288\n",
      "epoch 198; iter: 0; batch classifier loss: 0.002757; batch adversarial loss: 0.450431\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031842; batch adversarial loss: 0.413032\n",
      "epoch 0; iter: 0; batch classifier loss: 0.665892; batch adversarial loss: 0.608095\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433282; batch adversarial loss: 0.628324\n",
      "epoch 2; iter: 0; batch classifier loss: 0.340843; batch adversarial loss: 0.607738\n",
      "epoch 3; iter: 0; batch classifier loss: 0.438004; batch adversarial loss: 0.568007\n",
      "epoch 4; iter: 0; batch classifier loss: 0.269943; batch adversarial loss: 0.577652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.384866; batch adversarial loss: 0.497196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321836; batch adversarial loss: 0.499915\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273427; batch adversarial loss: 0.512203\n",
      "epoch 8; iter: 0; batch classifier loss: 0.238811; batch adversarial loss: 0.506921\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297464; batch adversarial loss: 0.524217\n",
      "epoch 10; iter: 0; batch classifier loss: 0.226516; batch adversarial loss: 0.513752\n",
      "epoch 11; iter: 0; batch classifier loss: 0.214955; batch adversarial loss: 0.476329\n",
      "epoch 12; iter: 0; batch classifier loss: 0.227175; batch adversarial loss: 0.506740\n",
      "epoch 13; iter: 0; batch classifier loss: 0.241665; batch adversarial loss: 0.400596\n",
      "epoch 14; iter: 0; batch classifier loss: 0.181791; batch adversarial loss: 0.468925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.174293; batch adversarial loss: 0.449576\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254595; batch adversarial loss: 0.458070\n",
      "epoch 17; iter: 0; batch classifier loss: 0.226501; batch adversarial loss: 0.434600\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219436; batch adversarial loss: 0.512295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.165283; batch adversarial loss: 0.450792\n",
      "epoch 20; iter: 0; batch classifier loss: 0.215629; batch adversarial loss: 0.487536\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199274; batch adversarial loss: 0.519551\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194080; batch adversarial loss: 0.584410\n",
      "epoch 23; iter: 0; batch classifier loss: 0.146298; batch adversarial loss: 0.399125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270006; batch adversarial loss: 0.521103\n",
      "epoch 25; iter: 0; batch classifier loss: 0.183606; batch adversarial loss: 0.485233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154282; batch adversarial loss: 0.414524\n",
      "epoch 27; iter: 0; batch classifier loss: 0.184510; batch adversarial loss: 0.476108\n",
      "epoch 28; iter: 0; batch classifier loss: 0.187225; batch adversarial loss: 0.493913\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177972; batch adversarial loss: 0.496149\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172987; batch adversarial loss: 0.503766\n",
      "epoch 31; iter: 0; batch classifier loss: 0.195975; batch adversarial loss: 0.463483\n",
      "epoch 32; iter: 0; batch classifier loss: 0.220239; batch adversarial loss: 0.479779\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271488; batch adversarial loss: 0.514427\n",
      "epoch 34; iter: 0; batch classifier loss: 0.233296; batch adversarial loss: 0.479046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141467; batch adversarial loss: 0.497526\n",
      "epoch 36; iter: 0; batch classifier loss: 0.095376; batch adversarial loss: 0.441816\n",
      "epoch 37; iter: 0; batch classifier loss: 0.162816; batch adversarial loss: 0.496855\n",
      "epoch 38; iter: 0; batch classifier loss: 0.101746; batch adversarial loss: 0.401587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.092253; batch adversarial loss: 0.486103\n",
      "epoch 40; iter: 0; batch classifier loss: 0.098972; batch adversarial loss: 0.497135\n",
      "epoch 41; iter: 0; batch classifier loss: 0.119126; batch adversarial loss: 0.515488\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137699; batch adversarial loss: 0.484219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.089940; batch adversarial loss: 0.482716\n",
      "epoch 44; iter: 0; batch classifier loss: 0.058076; batch adversarial loss: 0.478863\n",
      "epoch 45; iter: 0; batch classifier loss: 0.055763; batch adversarial loss: 0.503081\n",
      "epoch 46; iter: 0; batch classifier loss: 0.094558; batch adversarial loss: 0.414500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.065957; batch adversarial loss: 0.487466\n",
      "epoch 48; iter: 0; batch classifier loss: 0.071771; batch adversarial loss: 0.461681\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099687; batch adversarial loss: 0.433312\n",
      "epoch 50; iter: 0; batch classifier loss: 0.122695; batch adversarial loss: 0.405820\n",
      "epoch 51; iter: 0; batch classifier loss: 0.117366; batch adversarial loss: 0.376767\n",
      "epoch 52; iter: 0; batch classifier loss: 0.058198; batch adversarial loss: 0.442313\n",
      "epoch 53; iter: 0; batch classifier loss: 0.085913; batch adversarial loss: 0.443051\n",
      "epoch 54; iter: 0; batch classifier loss: 0.112674; batch adversarial loss: 0.418952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.110292; batch adversarial loss: 0.479264\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064380; batch adversarial loss: 0.383032\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102184; batch adversarial loss: 0.494758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.087736; batch adversarial loss: 0.469484\n",
      "epoch 59; iter: 0; batch classifier loss: 0.091118; batch adversarial loss: 0.381398\n",
      "epoch 60; iter: 0; batch classifier loss: 0.043539; batch adversarial loss: 0.417414\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078993; batch adversarial loss: 0.436207\n",
      "epoch 62; iter: 0; batch classifier loss: 0.108814; batch adversarial loss: 0.383901\n",
      "epoch 63; iter: 0; batch classifier loss: 0.089957; batch adversarial loss: 0.393814\n",
      "epoch 64; iter: 0; batch classifier loss: 0.064415; batch adversarial loss: 0.451450\n",
      "epoch 65; iter: 0; batch classifier loss: 0.083954; batch adversarial loss: 0.404717\n",
      "epoch 66; iter: 0; batch classifier loss: 0.125595; batch adversarial loss: 0.523454\n",
      "epoch 67; iter: 0; batch classifier loss: 0.099682; batch adversarial loss: 0.446769\n",
      "epoch 68; iter: 0; batch classifier loss: 0.103189; batch adversarial loss: 0.494087\n",
      "epoch 69; iter: 0; batch classifier loss: 0.090086; batch adversarial loss: 0.430482\n",
      "epoch 70; iter: 0; batch classifier loss: 0.087052; batch adversarial loss: 0.543571\n",
      "epoch 71; iter: 0; batch classifier loss: 0.090357; batch adversarial loss: 0.448097\n",
      "epoch 72; iter: 0; batch classifier loss: 0.122741; batch adversarial loss: 0.416968\n",
      "epoch 73; iter: 0; batch classifier loss: 0.110218; batch adversarial loss: 0.368032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.116917; batch adversarial loss: 0.470882\n",
      "epoch 75; iter: 0; batch classifier loss: 0.146262; batch adversarial loss: 0.452150\n",
      "epoch 76; iter: 0; batch classifier loss: 0.120979; batch adversarial loss: 0.469787\n",
      "epoch 77; iter: 0; batch classifier loss: 0.121778; batch adversarial loss: 0.370875\n",
      "epoch 78; iter: 0; batch classifier loss: 0.109522; batch adversarial loss: 0.410295\n",
      "epoch 79; iter: 0; batch classifier loss: 0.101626; batch adversarial loss: 0.458799\n",
      "epoch 80; iter: 0; batch classifier loss: 0.085488; batch adversarial loss: 0.381638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.111460; batch adversarial loss: 0.526697\n",
      "epoch 82; iter: 0; batch classifier loss: 0.103576; batch adversarial loss: 0.544641\n",
      "epoch 83; iter: 0; batch classifier loss: 0.144949; batch adversarial loss: 0.434469\n",
      "epoch 84; iter: 0; batch classifier loss: 0.101844; batch adversarial loss: 0.611437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.104152; batch adversarial loss: 0.439462\n",
      "epoch 86; iter: 0; batch classifier loss: 0.150028; batch adversarial loss: 0.399726\n",
      "epoch 87; iter: 0; batch classifier loss: 0.138622; batch adversarial loss: 0.396519\n",
      "epoch 88; iter: 0; batch classifier loss: 0.202709; batch adversarial loss: 0.427841\n",
      "epoch 89; iter: 0; batch classifier loss: 0.119723; batch adversarial loss: 0.409452\n",
      "epoch 90; iter: 0; batch classifier loss: 0.171847; batch adversarial loss: 0.458108\n",
      "epoch 91; iter: 0; batch classifier loss: 0.085279; batch adversarial loss: 0.350856\n",
      "epoch 92; iter: 0; batch classifier loss: 0.126533; batch adversarial loss: 0.433946\n",
      "epoch 93; iter: 0; batch classifier loss: 0.128317; batch adversarial loss: 0.407132\n",
      "epoch 94; iter: 0; batch classifier loss: 0.135592; batch adversarial loss: 0.485972\n",
      "epoch 95; iter: 0; batch classifier loss: 0.118808; batch adversarial loss: 0.433855\n",
      "epoch 96; iter: 0; batch classifier loss: 0.135771; batch adversarial loss: 0.432474\n",
      "epoch 97; iter: 0; batch classifier loss: 0.122061; batch adversarial loss: 0.482868\n",
      "epoch 98; iter: 0; batch classifier loss: 0.102676; batch adversarial loss: 0.548235\n",
      "epoch 99; iter: 0; batch classifier loss: 0.086884; batch adversarial loss: 0.408819\n",
      "epoch 100; iter: 0; batch classifier loss: 0.132694; batch adversarial loss: 0.418101\n",
      "epoch 101; iter: 0; batch classifier loss: 0.122417; batch adversarial loss: 0.547670\n",
      "epoch 102; iter: 0; batch classifier loss: 0.105128; batch adversarial loss: 0.474774\n",
      "epoch 103; iter: 0; batch classifier loss: 0.116184; batch adversarial loss: 0.445629\n",
      "epoch 104; iter: 0; batch classifier loss: 0.161878; batch adversarial loss: 0.369883\n",
      "epoch 105; iter: 0; batch classifier loss: 0.168858; batch adversarial loss: 0.360081\n",
      "epoch 106; iter: 0; batch classifier loss: 0.117955; batch adversarial loss: 0.362016\n",
      "epoch 107; iter: 0; batch classifier loss: 0.158528; batch adversarial loss: 0.520370\n",
      "epoch 108; iter: 0; batch classifier loss: 0.098500; batch adversarial loss: 0.436412\n",
      "epoch 109; iter: 0; batch classifier loss: 0.180569; batch adversarial loss: 0.397624\n",
      "epoch 110; iter: 0; batch classifier loss: 0.158123; batch adversarial loss: 0.421480\n",
      "epoch 111; iter: 0; batch classifier loss: 0.101978; batch adversarial loss: 0.497839\n",
      "epoch 112; iter: 0; batch classifier loss: 0.141727; batch adversarial loss: 0.409251\n",
      "epoch 113; iter: 0; batch classifier loss: 0.156727; batch adversarial loss: 0.398389\n",
      "epoch 114; iter: 0; batch classifier loss: 0.138804; batch adversarial loss: 0.457412\n",
      "epoch 115; iter: 0; batch classifier loss: 0.157669; batch adversarial loss: 0.471743\n",
      "epoch 116; iter: 0; batch classifier loss: 0.135787; batch adversarial loss: 0.472865\n",
      "epoch 117; iter: 0; batch classifier loss: 0.092725; batch adversarial loss: 0.472633\n",
      "epoch 118; iter: 0; batch classifier loss: 0.144571; batch adversarial loss: 0.497772\n",
      "epoch 119; iter: 0; batch classifier loss: 0.159700; batch adversarial loss: 0.409027\n",
      "epoch 120; iter: 0; batch classifier loss: 0.117996; batch adversarial loss: 0.456987\n",
      "epoch 121; iter: 0; batch classifier loss: 0.164189; batch adversarial loss: 0.519817\n",
      "epoch 122; iter: 0; batch classifier loss: 0.095011; batch adversarial loss: 0.459040\n",
      "epoch 123; iter: 0; batch classifier loss: 0.125940; batch adversarial loss: 0.445645\n",
      "epoch 124; iter: 0; batch classifier loss: 0.112511; batch adversarial loss: 0.505663\n",
      "epoch 125; iter: 0; batch classifier loss: 0.094529; batch adversarial loss: 0.496445\n",
      "epoch 126; iter: 0; batch classifier loss: 0.095064; batch adversarial loss: 0.421314\n",
      "epoch 127; iter: 0; batch classifier loss: 0.124758; batch adversarial loss: 0.456617\n",
      "epoch 128; iter: 0; batch classifier loss: 0.075446; batch adversarial loss: 0.567479\n",
      "epoch 129; iter: 0; batch classifier loss: 0.092413; batch adversarial loss: 0.519848\n",
      "epoch 130; iter: 0; batch classifier loss: 0.091695; batch adversarial loss: 0.470308\n",
      "epoch 131; iter: 0; batch classifier loss: 0.120752; batch adversarial loss: 0.468639\n",
      "epoch 132; iter: 0; batch classifier loss: 0.109526; batch adversarial loss: 0.394238\n",
      "epoch 133; iter: 0; batch classifier loss: 0.069138; batch adversarial loss: 0.432490\n",
      "epoch 134; iter: 0; batch classifier loss: 0.065964; batch adversarial loss: 0.446800\n",
      "epoch 135; iter: 0; batch classifier loss: 0.120406; batch adversarial loss: 0.404093\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039462; batch adversarial loss: 0.436772\n",
      "epoch 137; iter: 0; batch classifier loss: 0.101931; batch adversarial loss: 0.498907\n",
      "epoch 138; iter: 0; batch classifier loss: 0.062977; batch adversarial loss: 0.482398\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036499; batch adversarial loss: 0.410435\n",
      "epoch 140; iter: 0; batch classifier loss: 0.059224; batch adversarial loss: 0.481881\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060129; batch adversarial loss: 0.494639\n",
      "epoch 142; iter: 0; batch classifier loss: 0.058091; batch adversarial loss: 0.355648\n",
      "epoch 143; iter: 0; batch classifier loss: 0.064984; batch adversarial loss: 0.438307\n",
      "epoch 144; iter: 0; batch classifier loss: 0.104713; batch adversarial loss: 0.455150\n",
      "epoch 145; iter: 0; batch classifier loss: 0.054227; batch adversarial loss: 0.403405\n",
      "epoch 146; iter: 0; batch classifier loss: 0.079313; batch adversarial loss: 0.410658\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033432; batch adversarial loss: 0.433250\n",
      "epoch 148; iter: 0; batch classifier loss: 0.042325; batch adversarial loss: 0.480938\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069396; batch adversarial loss: 0.519043\n",
      "epoch 150; iter: 0; batch classifier loss: 0.068789; batch adversarial loss: 0.458755\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041027; batch adversarial loss: 0.522730\n",
      "epoch 152; iter: 0; batch classifier loss: 0.091159; batch adversarial loss: 0.465903\n",
      "epoch 153; iter: 0; batch classifier loss: 0.048353; batch adversarial loss: 0.432809\n",
      "epoch 154; iter: 0; batch classifier loss: 0.077331; batch adversarial loss: 0.450902\n",
      "epoch 155; iter: 0; batch classifier loss: 0.046506; batch adversarial loss: 0.446936\n",
      "epoch 156; iter: 0; batch classifier loss: 0.053517; batch adversarial loss: 0.355061\n",
      "epoch 157; iter: 0; batch classifier loss: 0.041025; batch adversarial loss: 0.488632\n",
      "epoch 158; iter: 0; batch classifier loss: 0.048509; batch adversarial loss: 0.414653\n",
      "epoch 159; iter: 0; batch classifier loss: 0.048750; batch adversarial loss: 0.371929\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038826; batch adversarial loss: 0.446722\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049621; batch adversarial loss: 0.515676\n",
      "epoch 162; iter: 0; batch classifier loss: 0.027486; batch adversarial loss: 0.353098\n",
      "epoch 163; iter: 0; batch classifier loss: 0.052464; batch adversarial loss: 0.456281\n",
      "epoch 164; iter: 0; batch classifier loss: 0.031005; batch adversarial loss: 0.413523\n",
      "epoch 165; iter: 0; batch classifier loss: 0.030416; batch adversarial loss: 0.427087\n",
      "epoch 166; iter: 0; batch classifier loss: 0.052614; batch adversarial loss: 0.497386\n",
      "epoch 167; iter: 0; batch classifier loss: 0.023924; batch adversarial loss: 0.535382\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022913; batch adversarial loss: 0.470443\n",
      "epoch 169; iter: 0; batch classifier loss: 0.033286; batch adversarial loss: 0.461871\n",
      "epoch 170; iter: 0; batch classifier loss: 0.075283; batch adversarial loss: 0.492981\n",
      "epoch 171; iter: 0; batch classifier loss: 0.034825; batch adversarial loss: 0.461385\n",
      "epoch 172; iter: 0; batch classifier loss: 0.033648; batch adversarial loss: 0.467270\n",
      "epoch 173; iter: 0; batch classifier loss: 0.027720; batch adversarial loss: 0.399352\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018604; batch adversarial loss: 0.505741\n",
      "epoch 175; iter: 0; batch classifier loss: 0.042154; batch adversarial loss: 0.382066\n",
      "epoch 176; iter: 0; batch classifier loss: 0.026018; batch adversarial loss: 0.527902\n",
      "epoch 177; iter: 0; batch classifier loss: 0.030893; batch adversarial loss: 0.444613\n",
      "epoch 178; iter: 0; batch classifier loss: 0.063779; batch adversarial loss: 0.502356\n",
      "epoch 179; iter: 0; batch classifier loss: 0.059824; batch adversarial loss: 0.500090\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025087; batch adversarial loss: 0.501790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.025327; batch adversarial loss: 0.403628\n",
      "epoch 182; iter: 0; batch classifier loss: 0.029382; batch adversarial loss: 0.507587\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018665; batch adversarial loss: 0.398238\n",
      "epoch 184; iter: 0; batch classifier loss: 0.013515; batch adversarial loss: 0.429050\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032894; batch adversarial loss: 0.447548\n",
      "epoch 186; iter: 0; batch classifier loss: 0.019201; batch adversarial loss: 0.372656\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028564; batch adversarial loss: 0.466846\n",
      "epoch 188; iter: 0; batch classifier loss: 0.014313; batch adversarial loss: 0.424433\n",
      "epoch 189; iter: 0; batch classifier loss: 0.017976; batch adversarial loss: 0.619020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021187; batch adversarial loss: 0.485471\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019533; batch adversarial loss: 0.506081\n",
      "epoch 192; iter: 0; batch classifier loss: 0.053059; batch adversarial loss: 0.502883\n",
      "epoch 193; iter: 0; batch classifier loss: 0.024332; batch adversarial loss: 0.514067\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017188; batch adversarial loss: 0.476854\n",
      "epoch 195; iter: 0; batch classifier loss: 0.049127; batch adversarial loss: 0.534191\n",
      "epoch 196; iter: 0; batch classifier loss: 0.009877; batch adversarial loss: 0.435010\n",
      "epoch 197; iter: 0; batch classifier loss: 0.027596; batch adversarial loss: 0.469861\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022522; batch adversarial loss: 0.536790\n",
      "epoch 199; iter: 0; batch classifier loss: 0.018363; batch adversarial loss: 0.495587\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704506; batch adversarial loss: 0.582878\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387957; batch adversarial loss: 0.618821\n",
      "epoch 2; iter: 0; batch classifier loss: 0.449315; batch adversarial loss: 0.657487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.398787; batch adversarial loss: 0.582707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.383438; batch adversarial loss: 0.593391\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363340; batch adversarial loss: 0.617669\n",
      "epoch 6; iter: 0; batch classifier loss: 0.457489; batch adversarial loss: 0.585283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.425856; batch adversarial loss: 0.607750\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549081; batch adversarial loss: 0.635484\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563529; batch adversarial loss: 0.610564\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598659; batch adversarial loss: 0.460292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473313; batch adversarial loss: 0.491457\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339405; batch adversarial loss: 0.491127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.289785; batch adversarial loss: 0.459650\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294730; batch adversarial loss: 0.543864\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296884; batch adversarial loss: 0.471321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.230611; batch adversarial loss: 0.478171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246985; batch adversarial loss: 0.499098\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285915; batch adversarial loss: 0.507715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.213420; batch adversarial loss: 0.539425\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250406; batch adversarial loss: 0.473617\n",
      "epoch 21; iter: 0; batch classifier loss: 0.199790; batch adversarial loss: 0.499702\n",
      "epoch 22; iter: 0; batch classifier loss: 0.196001; batch adversarial loss: 0.457554\n",
      "epoch 23; iter: 0; batch classifier loss: 0.206457; batch adversarial loss: 0.431123\n",
      "epoch 24; iter: 0; batch classifier loss: 0.255792; batch adversarial loss: 0.405030\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254301; batch adversarial loss: 0.436309\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261729; batch adversarial loss: 0.465256\n",
      "epoch 27; iter: 0; batch classifier loss: 0.205025; batch adversarial loss: 0.482019\n",
      "epoch 28; iter: 0; batch classifier loss: 0.254693; batch adversarial loss: 0.514064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.165907; batch adversarial loss: 0.485807\n",
      "epoch 30; iter: 0; batch classifier loss: 0.110313; batch adversarial loss: 0.436285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134604; batch adversarial loss: 0.468279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.134810; batch adversarial loss: 0.551261\n",
      "epoch 33; iter: 0; batch classifier loss: 0.155111; batch adversarial loss: 0.461307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.157712; batch adversarial loss: 0.433126\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159372; batch adversarial loss: 0.548094\n",
      "epoch 36; iter: 0; batch classifier loss: 0.162105; batch adversarial loss: 0.439986\n",
      "epoch 37; iter: 0; batch classifier loss: 0.175095; batch adversarial loss: 0.471331\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119631; batch adversarial loss: 0.484144\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197111; batch adversarial loss: 0.473652\n",
      "epoch 40; iter: 0; batch classifier loss: 0.148997; batch adversarial loss: 0.402835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.166846; batch adversarial loss: 0.466457\n",
      "epoch 42; iter: 0; batch classifier loss: 0.141848; batch adversarial loss: 0.448776\n",
      "epoch 43; iter: 0; batch classifier loss: 0.143273; batch adversarial loss: 0.512259\n",
      "epoch 44; iter: 0; batch classifier loss: 0.152026; batch adversarial loss: 0.359180\n",
      "epoch 45; iter: 0; batch classifier loss: 0.173440; batch adversarial loss: 0.476731\n",
      "epoch 46; iter: 0; batch classifier loss: 0.142410; batch adversarial loss: 0.461331\n",
      "epoch 47; iter: 0; batch classifier loss: 0.194306; batch adversarial loss: 0.411241\n",
      "epoch 48; iter: 0; batch classifier loss: 0.144422; batch adversarial loss: 0.465111\n",
      "epoch 49; iter: 0; batch classifier loss: 0.200210; batch adversarial loss: 0.437074\n",
      "epoch 50; iter: 0; batch classifier loss: 0.132667; batch adversarial loss: 0.436478\n",
      "epoch 51; iter: 0; batch classifier loss: 0.133209; batch adversarial loss: 0.496552\n",
      "epoch 52; iter: 0; batch classifier loss: 0.167897; batch adversarial loss: 0.425332\n",
      "epoch 53; iter: 0; batch classifier loss: 0.153437; batch adversarial loss: 0.458915\n",
      "epoch 54; iter: 0; batch classifier loss: 0.127464; batch adversarial loss: 0.450808\n",
      "epoch 55; iter: 0; batch classifier loss: 0.201492; batch adversarial loss: 0.437110\n",
      "epoch 56; iter: 0; batch classifier loss: 0.194471; batch adversarial loss: 0.405371\n",
      "epoch 57; iter: 0; batch classifier loss: 0.186263; batch adversarial loss: 0.376709\n",
      "epoch 58; iter: 0; batch classifier loss: 0.161979; batch adversarial loss: 0.520580\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176986; batch adversarial loss: 0.526611\n",
      "epoch 60; iter: 0; batch classifier loss: 0.149819; batch adversarial loss: 0.530561\n",
      "epoch 61; iter: 0; batch classifier loss: 0.109860; batch adversarial loss: 0.493208\n",
      "epoch 62; iter: 0; batch classifier loss: 0.136876; batch adversarial loss: 0.510543\n",
      "epoch 63; iter: 0; batch classifier loss: 0.126929; batch adversarial loss: 0.480340\n",
      "epoch 64; iter: 0; batch classifier loss: 0.173427; batch adversarial loss: 0.486021\n",
      "epoch 65; iter: 0; batch classifier loss: 0.134345; batch adversarial loss: 0.509093\n",
      "epoch 66; iter: 0; batch classifier loss: 0.139277; batch adversarial loss: 0.477883\n",
      "epoch 67; iter: 0; batch classifier loss: 0.159543; batch adversarial loss: 0.483493\n",
      "epoch 68; iter: 0; batch classifier loss: 0.160047; batch adversarial loss: 0.442052\n",
      "epoch 69; iter: 0; batch classifier loss: 0.196009; batch adversarial loss: 0.403970\n",
      "epoch 70; iter: 0; batch classifier loss: 0.144175; batch adversarial loss: 0.436693\n",
      "epoch 71; iter: 0; batch classifier loss: 0.098851; batch adversarial loss: 0.588975\n",
      "epoch 72; iter: 0; batch classifier loss: 0.167171; batch adversarial loss: 0.485828\n",
      "epoch 73; iter: 0; batch classifier loss: 0.263643; batch adversarial loss: 0.399032\n",
      "epoch 74; iter: 0; batch classifier loss: 0.143377; batch adversarial loss: 0.424133\n",
      "epoch 75; iter: 0; batch classifier loss: 0.153448; batch adversarial loss: 0.606655\n",
      "epoch 76; iter: 0; batch classifier loss: 0.185946; batch adversarial loss: 0.532858\n",
      "epoch 77; iter: 0; batch classifier loss: 0.145808; batch adversarial loss: 0.509829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78; iter: 0; batch classifier loss: 0.120763; batch adversarial loss: 0.480482\n",
      "epoch 79; iter: 0; batch classifier loss: 0.169117; batch adversarial loss: 0.456982\n",
      "epoch 80; iter: 0; batch classifier loss: 0.118465; batch adversarial loss: 0.500470\n",
      "epoch 81; iter: 0; batch classifier loss: 0.223768; batch adversarial loss: 0.507384\n",
      "epoch 82; iter: 0; batch classifier loss: 0.125674; batch adversarial loss: 0.506376\n",
      "epoch 83; iter: 0; batch classifier loss: 0.183743; batch adversarial loss: 0.384194\n",
      "epoch 84; iter: 0; batch classifier loss: 0.219966; batch adversarial loss: 0.388939\n",
      "epoch 85; iter: 0; batch classifier loss: 0.117574; batch adversarial loss: 0.499776\n",
      "epoch 86; iter: 0; batch classifier loss: 0.181035; batch adversarial loss: 0.526150\n",
      "epoch 87; iter: 0; batch classifier loss: 0.136827; batch adversarial loss: 0.538761\n",
      "epoch 88; iter: 0; batch classifier loss: 0.131885; batch adversarial loss: 0.459422\n",
      "epoch 89; iter: 0; batch classifier loss: 0.260837; batch adversarial loss: 0.500482\n",
      "epoch 90; iter: 0; batch classifier loss: 0.159408; batch adversarial loss: 0.504096\n",
      "epoch 91; iter: 0; batch classifier loss: 0.131348; batch adversarial loss: 0.434832\n",
      "epoch 92; iter: 0; batch classifier loss: 0.251834; batch adversarial loss: 0.496912\n",
      "epoch 93; iter: 0; batch classifier loss: 0.169531; batch adversarial loss: 0.627441\n",
      "epoch 94; iter: 0; batch classifier loss: 0.147279; batch adversarial loss: 0.392681\n",
      "epoch 95; iter: 0; batch classifier loss: 0.175543; batch adversarial loss: 0.449796\n",
      "epoch 96; iter: 0; batch classifier loss: 0.156034; batch adversarial loss: 0.516750\n",
      "epoch 97; iter: 0; batch classifier loss: 0.199551; batch adversarial loss: 0.367930\n",
      "epoch 98; iter: 0; batch classifier loss: 0.144105; batch adversarial loss: 0.436503\n",
      "epoch 99; iter: 0; batch classifier loss: 0.122059; batch adversarial loss: 0.505652\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109873; batch adversarial loss: 0.493844\n",
      "epoch 101; iter: 0; batch classifier loss: 0.166163; batch adversarial loss: 0.508368\n",
      "epoch 102; iter: 0; batch classifier loss: 0.101151; batch adversarial loss: 0.448249\n",
      "epoch 103; iter: 0; batch classifier loss: 0.251630; batch adversarial loss: 0.415197\n",
      "epoch 104; iter: 0; batch classifier loss: 0.136455; batch adversarial loss: 0.487532\n",
      "epoch 105; iter: 0; batch classifier loss: 0.181320; batch adversarial loss: 0.498628\n",
      "epoch 106; iter: 0; batch classifier loss: 0.269547; batch adversarial loss: 0.397938\n",
      "epoch 107; iter: 0; batch classifier loss: 0.176116; batch adversarial loss: 0.482002\n",
      "epoch 108; iter: 0; batch classifier loss: 0.254115; batch adversarial loss: 0.436078\n",
      "epoch 109; iter: 0; batch classifier loss: 0.226012; batch adversarial loss: 0.490113\n",
      "epoch 110; iter: 0; batch classifier loss: 0.196955; batch adversarial loss: 0.459529\n",
      "epoch 111; iter: 0; batch classifier loss: 0.218630; batch adversarial loss: 0.434113\n",
      "epoch 112; iter: 0; batch classifier loss: 0.165553; batch adversarial loss: 0.459463\n",
      "epoch 113; iter: 0; batch classifier loss: 0.098432; batch adversarial loss: 0.472543\n",
      "epoch 114; iter: 0; batch classifier loss: 0.128418; batch adversarial loss: 0.509217\n",
      "epoch 115; iter: 0; batch classifier loss: 0.155297; batch adversarial loss: 0.502540\n",
      "epoch 116; iter: 0; batch classifier loss: 0.158895; batch adversarial loss: 0.519585\n",
      "epoch 117; iter: 0; batch classifier loss: 0.222517; batch adversarial loss: 0.493632\n",
      "epoch 118; iter: 0; batch classifier loss: 0.211836; batch adversarial loss: 0.543692\n",
      "epoch 119; iter: 0; batch classifier loss: 0.160701; batch adversarial loss: 0.403127\n",
      "epoch 120; iter: 0; batch classifier loss: 0.165161; batch adversarial loss: 0.431207\n",
      "epoch 121; iter: 0; batch classifier loss: 0.185568; batch adversarial loss: 0.469204\n",
      "epoch 122; iter: 0; batch classifier loss: 0.172920; batch adversarial loss: 0.487897\n",
      "epoch 123; iter: 0; batch classifier loss: 0.179697; batch adversarial loss: 0.456547\n",
      "epoch 124; iter: 0; batch classifier loss: 0.217643; batch adversarial loss: 0.475567\n",
      "epoch 125; iter: 0; batch classifier loss: 0.287974; batch adversarial loss: 0.479118\n",
      "epoch 126; iter: 0; batch classifier loss: 0.181503; batch adversarial loss: 0.414346\n",
      "epoch 127; iter: 0; batch classifier loss: 0.208275; batch adversarial loss: 0.481663\n",
      "epoch 128; iter: 0; batch classifier loss: 0.192925; batch adversarial loss: 0.444494\n",
      "epoch 129; iter: 0; batch classifier loss: 0.197149; batch adversarial loss: 0.412789\n",
      "epoch 130; iter: 0; batch classifier loss: 0.165266; batch adversarial loss: 0.495902\n",
      "epoch 131; iter: 0; batch classifier loss: 0.199611; batch adversarial loss: 0.389865\n",
      "epoch 132; iter: 0; batch classifier loss: 0.198641; batch adversarial loss: 0.503353\n",
      "epoch 133; iter: 0; batch classifier loss: 0.210461; batch adversarial loss: 0.517500\n",
      "epoch 134; iter: 0; batch classifier loss: 0.191194; batch adversarial loss: 0.479708\n",
      "epoch 135; iter: 0; batch classifier loss: 0.245068; batch adversarial loss: 0.397820\n",
      "epoch 136; iter: 0; batch classifier loss: 0.252437; batch adversarial loss: 0.519624\n",
      "epoch 137; iter: 0; batch classifier loss: 0.191831; batch adversarial loss: 0.457538\n",
      "epoch 138; iter: 0; batch classifier loss: 0.200094; batch adversarial loss: 0.408949\n",
      "epoch 139; iter: 0; batch classifier loss: 0.218999; batch adversarial loss: 0.421065\n",
      "epoch 140; iter: 0; batch classifier loss: 0.216944; batch adversarial loss: 0.460180\n",
      "epoch 141; iter: 0; batch classifier loss: 0.259081; batch adversarial loss: 0.449298\n",
      "epoch 142; iter: 0; batch classifier loss: 0.166302; batch adversarial loss: 0.459415\n",
      "epoch 143; iter: 0; batch classifier loss: 0.144005; batch adversarial loss: 0.411285\n",
      "epoch 144; iter: 0; batch classifier loss: 0.200735; batch adversarial loss: 0.460759\n",
      "epoch 145; iter: 0; batch classifier loss: 0.190211; batch adversarial loss: 0.436090\n",
      "epoch 146; iter: 0; batch classifier loss: 0.149732; batch adversarial loss: 0.474075\n",
      "epoch 147; iter: 0; batch classifier loss: 0.218176; batch adversarial loss: 0.558241\n",
      "epoch 148; iter: 0; batch classifier loss: 0.205853; batch adversarial loss: 0.472233\n",
      "epoch 149; iter: 0; batch classifier loss: 0.214190; batch adversarial loss: 0.384391\n",
      "epoch 150; iter: 0; batch classifier loss: 0.231094; batch adversarial loss: 0.483071\n",
      "epoch 151; iter: 0; batch classifier loss: 0.167576; batch adversarial loss: 0.435046\n",
      "epoch 152; iter: 0; batch classifier loss: 0.188693; batch adversarial loss: 0.496598\n",
      "epoch 153; iter: 0; batch classifier loss: 0.198826; batch adversarial loss: 0.530760\n",
      "epoch 154; iter: 0; batch classifier loss: 0.209358; batch adversarial loss: 0.422681\n",
      "epoch 155; iter: 0; batch classifier loss: 0.206959; batch adversarial loss: 0.349904\n",
      "epoch 156; iter: 0; batch classifier loss: 0.103850; batch adversarial loss: 0.507001\n",
      "epoch 157; iter: 0; batch classifier loss: 0.067555; batch adversarial loss: 0.506230\n",
      "epoch 158; iter: 0; batch classifier loss: 0.125431; batch adversarial loss: 0.418512\n",
      "epoch 159; iter: 0; batch classifier loss: 0.090854; batch adversarial loss: 0.407453\n",
      "epoch 160; iter: 0; batch classifier loss: 0.158700; batch adversarial loss: 0.493849\n",
      "epoch 161; iter: 0; batch classifier loss: 0.134697; batch adversarial loss: 0.452615\n",
      "epoch 162; iter: 0; batch classifier loss: 0.138565; batch adversarial loss: 0.459520\n",
      "epoch 163; iter: 0; batch classifier loss: 0.142399; batch adversarial loss: 0.473319\n",
      "epoch 164; iter: 0; batch classifier loss: 0.155308; batch adversarial loss: 0.472418\n",
      "epoch 165; iter: 0; batch classifier loss: 0.137864; batch adversarial loss: 0.475160\n",
      "epoch 166; iter: 0; batch classifier loss: 0.204960; batch adversarial loss: 0.517402\n",
      "epoch 167; iter: 0; batch classifier loss: 0.147583; batch adversarial loss: 0.473955\n",
      "epoch 168; iter: 0; batch classifier loss: 0.115433; batch adversarial loss: 0.430436\n",
      "epoch 169; iter: 0; batch classifier loss: 0.096682; batch adversarial loss: 0.490410\n",
      "epoch 170; iter: 0; batch classifier loss: 0.082033; batch adversarial loss: 0.346030\n",
      "epoch 171; iter: 0; batch classifier loss: 0.066281; batch adversarial loss: 0.414947\n",
      "epoch 172; iter: 0; batch classifier loss: 0.089605; batch adversarial loss: 0.549979\n",
      "epoch 173; iter: 0; batch classifier loss: 0.092002; batch adversarial loss: 0.453141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174; iter: 0; batch classifier loss: 0.072361; batch adversarial loss: 0.475423\n",
      "epoch 175; iter: 0; batch classifier loss: 0.100183; batch adversarial loss: 0.463751\n",
      "epoch 176; iter: 0; batch classifier loss: 0.062237; batch adversarial loss: 0.505668\n",
      "epoch 177; iter: 0; batch classifier loss: 0.080933; batch adversarial loss: 0.438568\n",
      "epoch 178; iter: 0; batch classifier loss: 0.047075; batch adversarial loss: 0.413893\n",
      "epoch 179; iter: 0; batch classifier loss: 0.063278; batch adversarial loss: 0.452315\n",
      "epoch 180; iter: 0; batch classifier loss: 0.051156; batch adversarial loss: 0.562068\n",
      "epoch 181; iter: 0; batch classifier loss: 0.032009; batch adversarial loss: 0.446395\n",
      "epoch 182; iter: 0; batch classifier loss: 0.033841; batch adversarial loss: 0.491046\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030171; batch adversarial loss: 0.362947\n",
      "epoch 184; iter: 0; batch classifier loss: 0.055522; batch adversarial loss: 0.463231\n",
      "epoch 185; iter: 0; batch classifier loss: 0.036535; batch adversarial loss: 0.412880\n",
      "epoch 186; iter: 0; batch classifier loss: 0.032724; batch adversarial loss: 0.504923\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038956; batch adversarial loss: 0.451046\n",
      "epoch 188; iter: 0; batch classifier loss: 0.043963; batch adversarial loss: 0.417962\n",
      "epoch 189; iter: 0; batch classifier loss: 0.029985; batch adversarial loss: 0.537054\n",
      "epoch 190; iter: 0; batch classifier loss: 0.039665; batch adversarial loss: 0.484767\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046068; batch adversarial loss: 0.534802\n",
      "epoch 192; iter: 0; batch classifier loss: 0.030208; batch adversarial loss: 0.407473\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037008; batch adversarial loss: 0.415905\n",
      "epoch 194; iter: 0; batch classifier loss: 0.025012; batch adversarial loss: 0.479925\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014655; batch adversarial loss: 0.504506\n",
      "epoch 196; iter: 0; batch classifier loss: 0.037235; batch adversarial loss: 0.469712\n",
      "epoch 197; iter: 0; batch classifier loss: 0.018659; batch adversarial loss: 0.445758\n",
      "epoch 198; iter: 0; batch classifier loss: 0.025793; batch adversarial loss: 0.373689\n",
      "epoch 199; iter: 0; batch classifier loss: 0.040458; batch adversarial loss: 0.387403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700344; batch adversarial loss: 0.890609\n",
      "epoch 1; iter: 0; batch classifier loss: 0.544754; batch adversarial loss: 0.954953\n",
      "epoch 2; iter: 0; batch classifier loss: 0.475204; batch adversarial loss: 0.913069\n",
      "epoch 3; iter: 0; batch classifier loss: 0.393540; batch adversarial loss: 0.885502\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446966; batch adversarial loss: 0.804470\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357388; batch adversarial loss: 0.722575\n",
      "epoch 6; iter: 0; batch classifier loss: 0.262136; batch adversarial loss: 0.653455\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316812; batch adversarial loss: 0.617052\n",
      "epoch 8; iter: 0; batch classifier loss: 0.245593; batch adversarial loss: 0.602215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317407; batch adversarial loss: 0.604184\n",
      "epoch 10; iter: 0; batch classifier loss: 0.295001; batch adversarial loss: 0.547267\n",
      "epoch 11; iter: 0; batch classifier loss: 0.284463; batch adversarial loss: 0.538100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.266756; batch adversarial loss: 0.543917\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242494; batch adversarial loss: 0.513951\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236382; batch adversarial loss: 0.562344\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287678; batch adversarial loss: 0.509370\n",
      "epoch 16; iter: 0; batch classifier loss: 0.243956; batch adversarial loss: 0.509381\n",
      "epoch 17; iter: 0; batch classifier loss: 0.221681; batch adversarial loss: 0.479885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.215701; batch adversarial loss: 0.452183\n",
      "epoch 19; iter: 0; batch classifier loss: 0.168636; batch adversarial loss: 0.525137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.207866; batch adversarial loss: 0.508395\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279491; batch adversarial loss: 0.443128\n",
      "epoch 22; iter: 0; batch classifier loss: 0.243648; batch adversarial loss: 0.491133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220687; batch adversarial loss: 0.479321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.235257; batch adversarial loss: 0.459434\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197524; batch adversarial loss: 0.412923\n",
      "epoch 26; iter: 0; batch classifier loss: 0.171038; batch adversarial loss: 0.423887\n",
      "epoch 27; iter: 0; batch classifier loss: 0.151093; batch adversarial loss: 0.405501\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168033; batch adversarial loss: 0.511514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.129059; batch adversarial loss: 0.376250\n",
      "epoch 30; iter: 0; batch classifier loss: 0.142416; batch adversarial loss: 0.396840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.174139; batch adversarial loss: 0.444088\n",
      "epoch 32; iter: 0; batch classifier loss: 0.129768; batch adversarial loss: 0.405633\n",
      "epoch 33; iter: 0; batch classifier loss: 0.099409; batch adversarial loss: 0.404049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.116768; batch adversarial loss: 0.364217\n",
      "epoch 35; iter: 0; batch classifier loss: 0.096607; batch adversarial loss: 0.451445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.109752; batch adversarial loss: 0.381887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.132920; batch adversarial loss: 0.301407\n",
      "epoch 38; iter: 0; batch classifier loss: 0.098262; batch adversarial loss: 0.351277\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184696; batch adversarial loss: 0.366895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.081696; batch adversarial loss: 0.380377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.105400; batch adversarial loss: 0.426613\n",
      "epoch 42; iter: 0; batch classifier loss: 0.095408; batch adversarial loss: 0.511959\n",
      "epoch 43; iter: 0; batch classifier loss: 0.078277; batch adversarial loss: 0.439916\n",
      "epoch 44; iter: 0; batch classifier loss: 0.047570; batch adversarial loss: 0.415102\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103608; batch adversarial loss: 0.476853\n",
      "epoch 46; iter: 0; batch classifier loss: 0.109087; batch adversarial loss: 0.400002\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091842; batch adversarial loss: 0.381925\n",
      "epoch 48; iter: 0; batch classifier loss: 0.106210; batch adversarial loss: 0.502633\n",
      "epoch 49; iter: 0; batch classifier loss: 0.059494; batch adversarial loss: 0.409042\n",
      "epoch 50; iter: 0; batch classifier loss: 0.152334; batch adversarial loss: 0.504210\n",
      "epoch 51; iter: 0; batch classifier loss: 0.099064; batch adversarial loss: 0.472970\n",
      "epoch 52; iter: 0; batch classifier loss: 0.082752; batch adversarial loss: 0.447855\n",
      "epoch 53; iter: 0; batch classifier loss: 0.076565; batch adversarial loss: 0.455641\n",
      "epoch 54; iter: 0; batch classifier loss: 0.073019; batch adversarial loss: 0.360894\n",
      "epoch 55; iter: 0; batch classifier loss: 0.061643; batch adversarial loss: 0.413418\n",
      "epoch 56; iter: 0; batch classifier loss: 0.120072; batch adversarial loss: 0.429590\n",
      "epoch 57; iter: 0; batch classifier loss: 0.105791; batch adversarial loss: 0.406075\n",
      "epoch 58; iter: 0; batch classifier loss: 0.144782; batch adversarial loss: 0.422011\n",
      "epoch 59; iter: 0; batch classifier loss: 0.085260; batch adversarial loss: 0.446625\n",
      "epoch 60; iter: 0; batch classifier loss: 0.091600; batch adversarial loss: 0.545847\n",
      "epoch 61; iter: 0; batch classifier loss: 0.093383; batch adversarial loss: 0.390477\n",
      "epoch 62; iter: 0; batch classifier loss: 0.101231; batch adversarial loss: 0.486072\n",
      "epoch 63; iter: 0; batch classifier loss: 0.056377; batch adversarial loss: 0.356058\n",
      "epoch 64; iter: 0; batch classifier loss: 0.066429; batch adversarial loss: 0.438510\n",
      "epoch 65; iter: 0; batch classifier loss: 0.045672; batch adversarial loss: 0.421212\n",
      "epoch 66; iter: 0; batch classifier loss: 0.133627; batch adversarial loss: 0.478612\n",
      "epoch 67; iter: 0; batch classifier loss: 0.066712; batch adversarial loss: 0.316717\n",
      "epoch 68; iter: 0; batch classifier loss: 0.097176; batch adversarial loss: 0.406773\n",
      "epoch 69; iter: 0; batch classifier loss: 0.052133; batch adversarial loss: 0.423682\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095633; batch adversarial loss: 0.411694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71; iter: 0; batch classifier loss: 0.050424; batch adversarial loss: 0.410856\n",
      "epoch 72; iter: 0; batch classifier loss: 0.058534; batch adversarial loss: 0.358179\n",
      "epoch 73; iter: 0; batch classifier loss: 0.061177; batch adversarial loss: 0.461308\n",
      "epoch 74; iter: 0; batch classifier loss: 0.055478; batch adversarial loss: 0.381983\n",
      "epoch 75; iter: 0; batch classifier loss: 0.021207; batch adversarial loss: 0.391940\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081514; batch adversarial loss: 0.398959\n",
      "epoch 77; iter: 0; batch classifier loss: 0.122901; batch adversarial loss: 0.414104\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099707; batch adversarial loss: 0.454144\n",
      "epoch 79; iter: 0; batch classifier loss: 0.071459; batch adversarial loss: 0.498546\n",
      "epoch 80; iter: 0; batch classifier loss: 0.046647; batch adversarial loss: 0.400279\n",
      "epoch 81; iter: 0; batch classifier loss: 0.050358; batch adversarial loss: 0.462254\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068274; batch adversarial loss: 0.486923\n",
      "epoch 83; iter: 0; batch classifier loss: 0.052526; batch adversarial loss: 0.427190\n",
      "epoch 84; iter: 0; batch classifier loss: 0.071499; batch adversarial loss: 0.369210\n",
      "epoch 85; iter: 0; batch classifier loss: 0.066403; batch adversarial loss: 0.479530\n",
      "epoch 86; iter: 0; batch classifier loss: 0.054349; batch adversarial loss: 0.346028\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044902; batch adversarial loss: 0.414715\n",
      "epoch 88; iter: 0; batch classifier loss: 0.093813; batch adversarial loss: 0.390200\n",
      "epoch 89; iter: 0; batch classifier loss: 0.031813; batch adversarial loss: 0.302382\n",
      "epoch 90; iter: 0; batch classifier loss: 0.059931; batch adversarial loss: 0.413371\n",
      "epoch 91; iter: 0; batch classifier loss: 0.025206; batch adversarial loss: 0.393053\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059957; batch adversarial loss: 0.431638\n",
      "epoch 93; iter: 0; batch classifier loss: 0.064923; batch adversarial loss: 0.350463\n",
      "epoch 94; iter: 0; batch classifier loss: 0.065855; batch adversarial loss: 0.437394\n",
      "epoch 95; iter: 0; batch classifier loss: 0.096070; batch adversarial loss: 0.450639\n",
      "epoch 96; iter: 0; batch classifier loss: 0.056916; batch adversarial loss: 0.367340\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062456; batch adversarial loss: 0.380135\n",
      "epoch 98; iter: 0; batch classifier loss: 0.025968; batch adversarial loss: 0.377594\n",
      "epoch 99; iter: 0; batch classifier loss: 0.069214; batch adversarial loss: 0.416335\n",
      "epoch 100; iter: 0; batch classifier loss: 0.075127; batch adversarial loss: 0.464157\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044051; batch adversarial loss: 0.459860\n",
      "epoch 102; iter: 0; batch classifier loss: 0.071805; batch adversarial loss: 0.378118\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043742; batch adversarial loss: 0.509015\n",
      "epoch 104; iter: 0; batch classifier loss: 0.077553; batch adversarial loss: 0.337746\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047338; batch adversarial loss: 0.386188\n",
      "epoch 106; iter: 0; batch classifier loss: 0.099831; batch adversarial loss: 0.450363\n",
      "epoch 107; iter: 0; batch classifier loss: 0.082646; batch adversarial loss: 0.377915\n",
      "epoch 108; iter: 0; batch classifier loss: 0.076455; batch adversarial loss: 0.416662\n",
      "epoch 109; iter: 0; batch classifier loss: 0.068121; batch adversarial loss: 0.414330\n",
      "epoch 110; iter: 0; batch classifier loss: 0.057400; batch adversarial loss: 0.403714\n",
      "epoch 111; iter: 0; batch classifier loss: 0.033011; batch adversarial loss: 0.480706\n",
      "epoch 112; iter: 0; batch classifier loss: 0.039374; batch adversarial loss: 0.406677\n",
      "epoch 113; iter: 0; batch classifier loss: 0.055248; batch adversarial loss: 0.405260\n",
      "epoch 114; iter: 0; batch classifier loss: 0.044176; batch adversarial loss: 0.430559\n",
      "epoch 115; iter: 0; batch classifier loss: 0.074661; batch adversarial loss: 0.483393\n",
      "epoch 116; iter: 0; batch classifier loss: 0.067772; batch adversarial loss: 0.451078\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047786; batch adversarial loss: 0.396109\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057418; batch adversarial loss: 0.361044\n",
      "epoch 119; iter: 0; batch classifier loss: 0.045235; batch adversarial loss: 0.522045\n",
      "epoch 120; iter: 0; batch classifier loss: 0.073698; batch adversarial loss: 0.461792\n",
      "epoch 121; iter: 0; batch classifier loss: 0.054672; batch adversarial loss: 0.452203\n",
      "epoch 122; iter: 0; batch classifier loss: 0.049123; batch adversarial loss: 0.384186\n",
      "epoch 123; iter: 0; batch classifier loss: 0.074124; batch adversarial loss: 0.490021\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036991; batch adversarial loss: 0.401117\n",
      "epoch 125; iter: 0; batch classifier loss: 0.056405; batch adversarial loss: 0.413802\n",
      "epoch 126; iter: 0; batch classifier loss: 0.070953; batch adversarial loss: 0.490961\n",
      "epoch 127; iter: 0; batch classifier loss: 0.051202; batch adversarial loss: 0.343939\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064763; batch adversarial loss: 0.435402\n",
      "epoch 129; iter: 0; batch classifier loss: 0.063137; batch adversarial loss: 0.421565\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073680; batch adversarial loss: 0.350931\n",
      "epoch 131; iter: 0; batch classifier loss: 0.021546; batch adversarial loss: 0.468513\n",
      "epoch 132; iter: 0; batch classifier loss: 0.073334; batch adversarial loss: 0.454241\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059799; batch adversarial loss: 0.444893\n",
      "epoch 134; iter: 0; batch classifier loss: 0.066002; batch adversarial loss: 0.370211\n",
      "epoch 135; iter: 0; batch classifier loss: 0.067672; batch adversarial loss: 0.496810\n",
      "epoch 136; iter: 0; batch classifier loss: 0.057129; batch adversarial loss: 0.378723\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037303; batch adversarial loss: 0.383310\n",
      "epoch 138; iter: 0; batch classifier loss: 0.079300; batch adversarial loss: 0.443585\n",
      "epoch 139; iter: 0; batch classifier loss: 0.050562; batch adversarial loss: 0.385398\n",
      "epoch 140; iter: 0; batch classifier loss: 0.053339; batch adversarial loss: 0.419710\n",
      "epoch 141; iter: 0; batch classifier loss: 0.056270; batch adversarial loss: 0.395524\n",
      "epoch 142; iter: 0; batch classifier loss: 0.052429; batch adversarial loss: 0.431297\n",
      "epoch 143; iter: 0; batch classifier loss: 0.073239; batch adversarial loss: 0.356928\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051644; batch adversarial loss: 0.442108\n",
      "epoch 145; iter: 0; batch classifier loss: 0.046754; batch adversarial loss: 0.403825\n",
      "epoch 146; iter: 0; batch classifier loss: 0.051156; batch adversarial loss: 0.351270\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071825; batch adversarial loss: 0.432897\n",
      "epoch 148; iter: 0; batch classifier loss: 0.104402; batch adversarial loss: 0.376390\n",
      "epoch 149; iter: 0; batch classifier loss: 0.059364; batch adversarial loss: 0.379031\n",
      "epoch 150; iter: 0; batch classifier loss: 0.085985; batch adversarial loss: 0.417315\n",
      "epoch 151; iter: 0; batch classifier loss: 0.063574; batch adversarial loss: 0.433553\n",
      "epoch 152; iter: 0; batch classifier loss: 0.053606; batch adversarial loss: 0.386240\n",
      "epoch 153; iter: 0; batch classifier loss: 0.066926; batch adversarial loss: 0.391821\n",
      "epoch 154; iter: 0; batch classifier loss: 0.041362; batch adversarial loss: 0.290386\n",
      "epoch 155; iter: 0; batch classifier loss: 0.057798; batch adversarial loss: 0.448001\n",
      "epoch 156; iter: 0; batch classifier loss: 0.077970; batch adversarial loss: 0.454358\n",
      "epoch 157; iter: 0; batch classifier loss: 0.044844; batch adversarial loss: 0.405135\n",
      "epoch 158; iter: 0; batch classifier loss: 0.057183; batch adversarial loss: 0.416945\n",
      "epoch 159; iter: 0; batch classifier loss: 0.049204; batch adversarial loss: 0.361665\n",
      "epoch 160; iter: 0; batch classifier loss: 0.033665; batch adversarial loss: 0.416965\n",
      "epoch 161; iter: 0; batch classifier loss: 0.030396; batch adversarial loss: 0.364514\n",
      "epoch 162; iter: 0; batch classifier loss: 0.089693; batch adversarial loss: 0.425436\n",
      "epoch 163; iter: 0; batch classifier loss: 0.056917; batch adversarial loss: 0.461707\n",
      "epoch 164; iter: 0; batch classifier loss: 0.057502; batch adversarial loss: 0.536296\n",
      "epoch 165; iter: 0; batch classifier loss: 0.032435; batch adversarial loss: 0.438740\n",
      "epoch 166; iter: 0; batch classifier loss: 0.054037; batch adversarial loss: 0.455445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167; iter: 0; batch classifier loss: 0.078877; batch adversarial loss: 0.417981\n",
      "epoch 168; iter: 0; batch classifier loss: 0.080689; batch adversarial loss: 0.480973\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036792; batch adversarial loss: 0.552713\n",
      "epoch 170; iter: 0; batch classifier loss: 0.084975; batch adversarial loss: 0.514357\n",
      "epoch 171; iter: 0; batch classifier loss: 0.075896; batch adversarial loss: 0.405916\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039556; batch adversarial loss: 0.386396\n",
      "epoch 173; iter: 0; batch classifier loss: 0.040009; batch adversarial loss: 0.399302\n",
      "epoch 174; iter: 0; batch classifier loss: 0.069128; batch adversarial loss: 0.433829\n",
      "epoch 175; iter: 0; batch classifier loss: 0.046733; batch adversarial loss: 0.482592\n",
      "epoch 176; iter: 0; batch classifier loss: 0.070144; batch adversarial loss: 0.566197\n",
      "epoch 177; iter: 0; batch classifier loss: 0.058000; batch adversarial loss: 0.372139\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052007; batch adversarial loss: 0.504671\n",
      "epoch 179; iter: 0; batch classifier loss: 0.044287; batch adversarial loss: 0.493774\n",
      "epoch 180; iter: 0; batch classifier loss: 0.022275; batch adversarial loss: 0.426560\n",
      "epoch 181; iter: 0; batch classifier loss: 0.030687; batch adversarial loss: 0.444638\n",
      "epoch 182; iter: 0; batch classifier loss: 0.039597; batch adversarial loss: 0.414716\n",
      "epoch 183; iter: 0; batch classifier loss: 0.023731; batch adversarial loss: 0.437420\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025917; batch adversarial loss: 0.448722\n",
      "epoch 185; iter: 0; batch classifier loss: 0.038151; batch adversarial loss: 0.412049\n",
      "epoch 186; iter: 0; batch classifier loss: 0.055727; batch adversarial loss: 0.489177\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038201; batch adversarial loss: 0.464108\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018918; batch adversarial loss: 0.491792\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043337; batch adversarial loss: 0.486859\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049425; batch adversarial loss: 0.548695\n",
      "epoch 191; iter: 0; batch classifier loss: 0.029507; batch adversarial loss: 0.499151\n",
      "epoch 192; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.480517\n",
      "epoch 193; iter: 0; batch classifier loss: 0.042704; batch adversarial loss: 0.404070\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041467; batch adversarial loss: 0.411603\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036960; batch adversarial loss: 0.396037\n",
      "epoch 196; iter: 0; batch classifier loss: 0.035158; batch adversarial loss: 0.448431\n",
      "epoch 197; iter: 0; batch classifier loss: 0.034215; batch adversarial loss: 0.413731\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031353; batch adversarial loss: 0.456841\n",
      "epoch 199; iter: 0; batch classifier loss: 0.029279; batch adversarial loss: 0.601875\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679757; batch adversarial loss: 0.601533\n",
      "epoch 1; iter: 0; batch classifier loss: 0.458108; batch adversarial loss: 0.630611\n",
      "epoch 2; iter: 0; batch classifier loss: 0.456045; batch adversarial loss: 0.563879\n",
      "epoch 3; iter: 0; batch classifier loss: 0.332504; batch adversarial loss: 0.600618\n",
      "epoch 4; iter: 0; batch classifier loss: 0.338612; batch adversarial loss: 0.513131\n",
      "epoch 5; iter: 0; batch classifier loss: 0.343909; batch adversarial loss: 0.557169\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288839; batch adversarial loss: 0.607230\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312129; batch adversarial loss: 0.596372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.344281; batch adversarial loss: 0.510898\n",
      "epoch 9; iter: 0; batch classifier loss: 0.257114; batch adversarial loss: 0.525966\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348176; batch adversarial loss: 0.424405\n",
      "epoch 11; iter: 0; batch classifier loss: 0.315974; batch adversarial loss: 0.531488\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236192; batch adversarial loss: 0.528686\n",
      "epoch 13; iter: 0; batch classifier loss: 0.250370; batch adversarial loss: 0.444428\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358715; batch adversarial loss: 0.547357\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298116; batch adversarial loss: 0.488202\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385809; batch adversarial loss: 0.583526\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397957; batch adversarial loss: 0.520412\n",
      "epoch 18; iter: 0; batch classifier loss: 0.379253; batch adversarial loss: 0.469356\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458615; batch adversarial loss: 0.495217\n",
      "epoch 20; iter: 0; batch classifier loss: 0.301188; batch adversarial loss: 0.481391\n",
      "epoch 21; iter: 0; batch classifier loss: 0.226388; batch adversarial loss: 0.460606\n",
      "epoch 22; iter: 0; batch classifier loss: 0.228016; batch adversarial loss: 0.453572\n",
      "epoch 23; iter: 0; batch classifier loss: 0.187186; batch adversarial loss: 0.415464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.159764; batch adversarial loss: 0.410822\n",
      "epoch 25; iter: 0; batch classifier loss: 0.205610; batch adversarial loss: 0.501986\n",
      "epoch 26; iter: 0; batch classifier loss: 0.176129; batch adversarial loss: 0.428976\n",
      "epoch 27; iter: 0; batch classifier loss: 0.159062; batch adversarial loss: 0.513450\n",
      "epoch 28; iter: 0; batch classifier loss: 0.176683; batch adversarial loss: 0.480588\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151910; batch adversarial loss: 0.438417\n",
      "epoch 30; iter: 0; batch classifier loss: 0.124159; batch adversarial loss: 0.493025\n",
      "epoch 31; iter: 0; batch classifier loss: 0.166269; batch adversarial loss: 0.398126\n",
      "epoch 32; iter: 0; batch classifier loss: 0.092346; batch adversarial loss: 0.515544\n",
      "epoch 33; iter: 0; batch classifier loss: 0.110028; batch adversarial loss: 0.378481\n",
      "epoch 34; iter: 0; batch classifier loss: 0.103454; batch adversarial loss: 0.477100\n",
      "epoch 35; iter: 0; batch classifier loss: 0.122991; batch adversarial loss: 0.466094\n",
      "epoch 36; iter: 0; batch classifier loss: 0.118834; batch adversarial loss: 0.495716\n",
      "epoch 37; iter: 0; batch classifier loss: 0.129602; batch adversarial loss: 0.496372\n",
      "epoch 38; iter: 0; batch classifier loss: 0.120830; batch adversarial loss: 0.453101\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095444; batch adversarial loss: 0.452070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.103517; batch adversarial loss: 0.404708\n",
      "epoch 41; iter: 0; batch classifier loss: 0.089613; batch adversarial loss: 0.468333\n",
      "epoch 42; iter: 0; batch classifier loss: 0.108122; batch adversarial loss: 0.438363\n",
      "epoch 43; iter: 0; batch classifier loss: 0.137495; batch adversarial loss: 0.420312\n",
      "epoch 44; iter: 0; batch classifier loss: 0.119107; batch adversarial loss: 0.347439\n",
      "epoch 45; iter: 0; batch classifier loss: 0.123831; batch adversarial loss: 0.412904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103795; batch adversarial loss: 0.449297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070663; batch adversarial loss: 0.480396\n",
      "epoch 48; iter: 0; batch classifier loss: 0.114779; batch adversarial loss: 0.531340\n",
      "epoch 49; iter: 0; batch classifier loss: 0.110748; batch adversarial loss: 0.525728\n",
      "epoch 50; iter: 0; batch classifier loss: 0.123578; batch adversarial loss: 0.488645\n",
      "epoch 51; iter: 0; batch classifier loss: 0.121037; batch adversarial loss: 0.468530\n",
      "epoch 52; iter: 0; batch classifier loss: 0.113195; batch adversarial loss: 0.510024\n",
      "epoch 53; iter: 0; batch classifier loss: 0.146757; batch adversarial loss: 0.427307\n",
      "epoch 54; iter: 0; batch classifier loss: 0.105124; batch adversarial loss: 0.523148\n",
      "epoch 55; iter: 0; batch classifier loss: 0.124454; batch adversarial loss: 0.447918\n",
      "epoch 56; iter: 0; batch classifier loss: 0.116385; batch adversarial loss: 0.467348\n",
      "epoch 57; iter: 0; batch classifier loss: 0.126074; batch adversarial loss: 0.436882\n",
      "epoch 58; iter: 0; batch classifier loss: 0.088404; batch adversarial loss: 0.458698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092657; batch adversarial loss: 0.501305\n",
      "epoch 60; iter: 0; batch classifier loss: 0.122423; batch adversarial loss: 0.578911\n",
      "epoch 61; iter: 0; batch classifier loss: 0.133554; batch adversarial loss: 0.406191\n",
      "epoch 62; iter: 0; batch classifier loss: 0.141291; batch adversarial loss: 0.413701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.105869; batch adversarial loss: 0.377352\n",
      "epoch 64; iter: 0; batch classifier loss: 0.072977; batch adversarial loss: 0.393163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65; iter: 0; batch classifier loss: 0.070085; batch adversarial loss: 0.423601\n",
      "epoch 66; iter: 0; batch classifier loss: 0.095521; batch adversarial loss: 0.355459\n",
      "epoch 67; iter: 0; batch classifier loss: 0.092839; batch adversarial loss: 0.355062\n",
      "epoch 68; iter: 0; batch classifier loss: 0.094462; batch adversarial loss: 0.423262\n",
      "epoch 69; iter: 0; batch classifier loss: 0.100401; batch adversarial loss: 0.503845\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120394; batch adversarial loss: 0.552485\n",
      "epoch 71; iter: 0; batch classifier loss: 0.103805; batch adversarial loss: 0.397937\n",
      "epoch 72; iter: 0; batch classifier loss: 0.100194; batch adversarial loss: 0.398293\n",
      "epoch 73; iter: 0; batch classifier loss: 0.130575; batch adversarial loss: 0.425473\n",
      "epoch 74; iter: 0; batch classifier loss: 0.098726; batch adversarial loss: 0.434561\n",
      "epoch 75; iter: 0; batch classifier loss: 0.134581; batch adversarial loss: 0.533556\n",
      "epoch 76; iter: 0; batch classifier loss: 0.055483; batch adversarial loss: 0.506571\n",
      "epoch 77; iter: 0; batch classifier loss: 0.116188; batch adversarial loss: 0.482528\n",
      "epoch 78; iter: 0; batch classifier loss: 0.079541; batch adversarial loss: 0.537521\n",
      "epoch 79; iter: 0; batch classifier loss: 0.072615; batch adversarial loss: 0.439976\n",
      "epoch 80; iter: 0; batch classifier loss: 0.122214; batch adversarial loss: 0.421105\n",
      "epoch 81; iter: 0; batch classifier loss: 0.108472; batch adversarial loss: 0.475953\n",
      "epoch 82; iter: 0; batch classifier loss: 0.084570; batch adversarial loss: 0.454239\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080450; batch adversarial loss: 0.318397\n",
      "epoch 84; iter: 0; batch classifier loss: 0.089582; batch adversarial loss: 0.376869\n",
      "epoch 85; iter: 0; batch classifier loss: 0.092685; batch adversarial loss: 0.505412\n",
      "epoch 86; iter: 0; batch classifier loss: 0.098662; batch adversarial loss: 0.411965\n",
      "epoch 87; iter: 0; batch classifier loss: 0.080557; batch adversarial loss: 0.422902\n",
      "epoch 88; iter: 0; batch classifier loss: 0.091637; batch adversarial loss: 0.528689\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085438; batch adversarial loss: 0.563219\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072537; batch adversarial loss: 0.490764\n",
      "epoch 91; iter: 0; batch classifier loss: 0.089128; batch adversarial loss: 0.344305\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059704; batch adversarial loss: 0.558630\n",
      "epoch 93; iter: 0; batch classifier loss: 0.056715; batch adversarial loss: 0.457832\n",
      "epoch 94; iter: 0; batch classifier loss: 0.076648; batch adversarial loss: 0.480526\n",
      "epoch 95; iter: 0; batch classifier loss: 0.101960; batch adversarial loss: 0.406019\n",
      "epoch 96; iter: 0; batch classifier loss: 0.067461; batch adversarial loss: 0.490297\n",
      "epoch 97; iter: 0; batch classifier loss: 0.072968; batch adversarial loss: 0.473139\n",
      "epoch 98; iter: 0; batch classifier loss: 0.060798; batch adversarial loss: 0.483495\n",
      "epoch 99; iter: 0; batch classifier loss: 0.087631; batch adversarial loss: 0.402068\n",
      "epoch 100; iter: 0; batch classifier loss: 0.109966; batch adversarial loss: 0.384747\n",
      "epoch 101; iter: 0; batch classifier loss: 0.041579; batch adversarial loss: 0.517068\n",
      "epoch 102; iter: 0; batch classifier loss: 0.102463; batch adversarial loss: 0.489304\n",
      "epoch 103; iter: 0; batch classifier loss: 0.082832; batch adversarial loss: 0.491317\n",
      "epoch 104; iter: 0; batch classifier loss: 0.080846; batch adversarial loss: 0.344739\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075219; batch adversarial loss: 0.407562\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040618; batch adversarial loss: 0.437988\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060998; batch adversarial loss: 0.432198\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045009; batch adversarial loss: 0.468358\n",
      "epoch 109; iter: 0; batch classifier loss: 0.080721; batch adversarial loss: 0.402555\n",
      "epoch 110; iter: 0; batch classifier loss: 0.024622; batch adversarial loss: 0.454934\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053640; batch adversarial loss: 0.378234\n",
      "epoch 112; iter: 0; batch classifier loss: 0.030524; batch adversarial loss: 0.442128\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040808; batch adversarial loss: 0.494960\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045246; batch adversarial loss: 0.401494\n",
      "epoch 115; iter: 0; batch classifier loss: 0.039196; batch adversarial loss: 0.472355\n",
      "epoch 116; iter: 0; batch classifier loss: 0.049929; batch adversarial loss: 0.469837\n",
      "epoch 117; iter: 0; batch classifier loss: 0.033074; batch adversarial loss: 0.384234\n",
      "epoch 118; iter: 0; batch classifier loss: 0.053828; batch adversarial loss: 0.482191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.103730; batch adversarial loss: 0.402975\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035583; batch adversarial loss: 0.459627\n",
      "epoch 121; iter: 0; batch classifier loss: 0.047458; batch adversarial loss: 0.469457\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047597; batch adversarial loss: 0.433763\n",
      "epoch 123; iter: 0; batch classifier loss: 0.036223; batch adversarial loss: 0.447991\n",
      "epoch 124; iter: 0; batch classifier loss: 0.048323; batch adversarial loss: 0.484090\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046189; batch adversarial loss: 0.457352\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038921; batch adversarial loss: 0.390880\n",
      "epoch 127; iter: 0; batch classifier loss: 0.062959; batch adversarial loss: 0.457282\n",
      "epoch 128; iter: 0; batch classifier loss: 0.079475; batch adversarial loss: 0.431582\n",
      "epoch 129; iter: 0; batch classifier loss: 0.041443; batch adversarial loss: 0.438083\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031553; batch adversarial loss: 0.496450\n",
      "epoch 131; iter: 0; batch classifier loss: 0.017595; batch adversarial loss: 0.470919\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024071; batch adversarial loss: 0.453973\n",
      "epoch 133; iter: 0; batch classifier loss: 0.015828; batch adversarial loss: 0.483703\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035051; batch adversarial loss: 0.407540\n",
      "epoch 135; iter: 0; batch classifier loss: 0.044058; batch adversarial loss: 0.464945\n",
      "epoch 136; iter: 0; batch classifier loss: 0.011486; batch adversarial loss: 0.484765\n",
      "epoch 137; iter: 0; batch classifier loss: 0.033792; batch adversarial loss: 0.373384\n",
      "epoch 138; iter: 0; batch classifier loss: 0.010582; batch adversarial loss: 0.479334\n",
      "epoch 139; iter: 0; batch classifier loss: 0.017971; batch adversarial loss: 0.438994\n",
      "epoch 140; iter: 0; batch classifier loss: 0.025608; batch adversarial loss: 0.493977\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022709; batch adversarial loss: 0.490918\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025854; batch adversarial loss: 0.396682\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027898; batch adversarial loss: 0.397660\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014721; batch adversarial loss: 0.511064\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037259; batch adversarial loss: 0.432265\n",
      "epoch 146; iter: 0; batch classifier loss: 0.011979; batch adversarial loss: 0.482811\n",
      "epoch 147; iter: 0; batch classifier loss: 0.039483; batch adversarial loss: 0.414190\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024587; batch adversarial loss: 0.492914\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015912; batch adversarial loss: 0.413382\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029868; batch adversarial loss: 0.582735\n",
      "epoch 151; iter: 0; batch classifier loss: 0.012347; batch adversarial loss: 0.406258\n",
      "epoch 152; iter: 0; batch classifier loss: 0.022919; batch adversarial loss: 0.354687\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036492; batch adversarial loss: 0.475392\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030140; batch adversarial loss: 0.393984\n",
      "epoch 155; iter: 0; batch classifier loss: 0.027439; batch adversarial loss: 0.498816\n",
      "epoch 156; iter: 0; batch classifier loss: 0.039426; batch adversarial loss: 0.531083\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015183; batch adversarial loss: 0.481659\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032957; batch adversarial loss: 0.464279\n",
      "epoch 159; iter: 0; batch classifier loss: 0.029837; batch adversarial loss: 0.496024\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010825; batch adversarial loss: 0.420644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161; iter: 0; batch classifier loss: 0.009878; batch adversarial loss: 0.464046\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019051; batch adversarial loss: 0.417061\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027989; batch adversarial loss: 0.482440\n",
      "epoch 164; iter: 0; batch classifier loss: 0.011677; batch adversarial loss: 0.410337\n",
      "epoch 165; iter: 0; batch classifier loss: 0.011472; batch adversarial loss: 0.543735\n",
      "epoch 166; iter: 0; batch classifier loss: 0.023904; batch adversarial loss: 0.457797\n",
      "epoch 167; iter: 0; batch classifier loss: 0.040179; batch adversarial loss: 0.399084\n",
      "epoch 168; iter: 0; batch classifier loss: 0.053566; batch adversarial loss: 0.476781\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043097; batch adversarial loss: 0.429980\n",
      "epoch 170; iter: 0; batch classifier loss: 0.023913; batch adversarial loss: 0.476116\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021312; batch adversarial loss: 0.395858\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036886; batch adversarial loss: 0.413863\n",
      "epoch 173; iter: 0; batch classifier loss: 0.032245; batch adversarial loss: 0.493132\n",
      "epoch 174; iter: 0; batch classifier loss: 0.012157; batch adversarial loss: 0.449060\n",
      "epoch 175; iter: 0; batch classifier loss: 0.023848; batch adversarial loss: 0.401985\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010785; batch adversarial loss: 0.499304\n",
      "epoch 177; iter: 0; batch classifier loss: 0.009724; batch adversarial loss: 0.511583\n",
      "epoch 178; iter: 0; batch classifier loss: 0.031610; batch adversarial loss: 0.468973\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012105; batch adversarial loss: 0.556445\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021265; batch adversarial loss: 0.403108\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009438; batch adversarial loss: 0.520224\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018697; batch adversarial loss: 0.549929\n",
      "epoch 183; iter: 0; batch classifier loss: 0.018404; batch adversarial loss: 0.473857\n",
      "epoch 184; iter: 0; batch classifier loss: 0.010349; batch adversarial loss: 0.367206\n",
      "epoch 185; iter: 0; batch classifier loss: 0.005679; batch adversarial loss: 0.454301\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023271; batch adversarial loss: 0.448008\n",
      "epoch 187; iter: 0; batch classifier loss: 0.036123; batch adversarial loss: 0.456822\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028350; batch adversarial loss: 0.499708\n",
      "epoch 189; iter: 0; batch classifier loss: 0.020160; batch adversarial loss: 0.489669\n",
      "epoch 190; iter: 0; batch classifier loss: 0.013287; batch adversarial loss: 0.301489\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021861; batch adversarial loss: 0.418860\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035601; batch adversarial loss: 0.397434\n",
      "epoch 193; iter: 0; batch classifier loss: 0.015616; batch adversarial loss: 0.519454\n",
      "epoch 194; iter: 0; batch classifier loss: 0.009559; batch adversarial loss: 0.481478\n",
      "epoch 195; iter: 0; batch classifier loss: 0.033644; batch adversarial loss: 0.444558\n",
      "epoch 196; iter: 0; batch classifier loss: 0.007894; batch adversarial loss: 0.438786\n",
      "epoch 197; iter: 0; batch classifier loss: 0.013690; batch adversarial loss: 0.320203\n",
      "epoch 198; iter: 0; batch classifier loss: 0.008317; batch adversarial loss: 0.463202\n",
      "epoch 199; iter: 0; batch classifier loss: 0.022276; batch adversarial loss: 0.354549\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695966; batch adversarial loss: 0.848299\n",
      "epoch 1; iter: 0; batch classifier loss: 0.384409; batch adversarial loss: 0.850374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.333817; batch adversarial loss: 0.769541\n",
      "epoch 3; iter: 0; batch classifier loss: 0.364549; batch adversarial loss: 0.740161\n",
      "epoch 4; iter: 0; batch classifier loss: 0.299360; batch adversarial loss: 0.726668\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.691909\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319942; batch adversarial loss: 0.655587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.262487; batch adversarial loss: 0.617697\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317422; batch adversarial loss: 0.583707\n",
      "epoch 9; iter: 0; batch classifier loss: 0.256286; batch adversarial loss: 0.578511\n",
      "epoch 10; iter: 0; batch classifier loss: 0.255470; batch adversarial loss: 0.555235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.253029; batch adversarial loss: 0.550636\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205100; batch adversarial loss: 0.516800\n",
      "epoch 13; iter: 0; batch classifier loss: 0.239438; batch adversarial loss: 0.530969\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333450; batch adversarial loss: 0.436731\n",
      "epoch 15; iter: 0; batch classifier loss: 0.293555; batch adversarial loss: 0.461237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.229989; batch adversarial loss: 0.435617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295699; batch adversarial loss: 0.439175\n",
      "epoch 18; iter: 0; batch classifier loss: 0.252790; batch adversarial loss: 0.438312\n",
      "epoch 19; iter: 0; batch classifier loss: 0.232529; batch adversarial loss: 0.436179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302135; batch adversarial loss: 0.429667\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279829; batch adversarial loss: 0.384870\n",
      "epoch 22; iter: 0; batch classifier loss: 0.169756; batch adversarial loss: 0.401499\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242728; batch adversarial loss: 0.426844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.214821; batch adversarial loss: 0.385343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.245032; batch adversarial loss: 0.491014\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180377; batch adversarial loss: 0.356393\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229681; batch adversarial loss: 0.422893\n",
      "epoch 28; iter: 0; batch classifier loss: 0.225104; batch adversarial loss: 0.402277\n",
      "epoch 29; iter: 0; batch classifier loss: 0.116318; batch adversarial loss: 0.254762\n",
      "epoch 30; iter: 0; batch classifier loss: 0.180852; batch adversarial loss: 0.348203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.172111; batch adversarial loss: 0.364604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.138854; batch adversarial loss: 0.392092\n",
      "epoch 33; iter: 0; batch classifier loss: 0.178028; batch adversarial loss: 0.437867\n",
      "epoch 34; iter: 0; batch classifier loss: 0.179239; batch adversarial loss: 0.305401\n",
      "epoch 35; iter: 0; batch classifier loss: 0.121620; batch adversarial loss: 0.356834\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131521; batch adversarial loss: 0.372413\n",
      "epoch 37; iter: 0; batch classifier loss: 0.161361; batch adversarial loss: 0.478485\n",
      "epoch 38; iter: 0; batch classifier loss: 0.140967; batch adversarial loss: 0.484511\n",
      "epoch 39; iter: 0; batch classifier loss: 0.156611; batch adversarial loss: 0.545487\n",
      "epoch 40; iter: 0; batch classifier loss: 0.114213; batch adversarial loss: 0.418587\n",
      "epoch 41; iter: 0; batch classifier loss: 0.134061; batch adversarial loss: 0.439525\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088556; batch adversarial loss: 0.368338\n",
      "epoch 43; iter: 0; batch classifier loss: 0.104982; batch adversarial loss: 0.357954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106028; batch adversarial loss: 0.367874\n",
      "epoch 45; iter: 0; batch classifier loss: 0.105619; batch adversarial loss: 0.391860\n",
      "epoch 46; iter: 0; batch classifier loss: 0.104384; batch adversarial loss: 0.314009\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085332; batch adversarial loss: 0.336099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.099894; batch adversarial loss: 0.392187\n",
      "epoch 49; iter: 0; batch classifier loss: 0.086895; batch adversarial loss: 0.403548\n",
      "epoch 50; iter: 0; batch classifier loss: 0.098535; batch adversarial loss: 0.415956\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096767; batch adversarial loss: 0.480743\n",
      "epoch 52; iter: 0; batch classifier loss: 0.072653; batch adversarial loss: 0.337772\n",
      "epoch 53; iter: 0; batch classifier loss: 0.139821; batch adversarial loss: 0.469530\n",
      "epoch 54; iter: 0; batch classifier loss: 0.089125; batch adversarial loss: 0.341192\n",
      "epoch 55; iter: 0; batch classifier loss: 0.070927; batch adversarial loss: 0.398163\n",
      "epoch 56; iter: 0; batch classifier loss: 0.133807; batch adversarial loss: 0.450009\n",
      "epoch 57; iter: 0; batch classifier loss: 0.069357; batch adversarial loss: 0.378613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58; iter: 0; batch classifier loss: 0.114907; batch adversarial loss: 0.449597\n",
      "epoch 59; iter: 0; batch classifier loss: 0.126978; batch adversarial loss: 0.489391\n",
      "epoch 60; iter: 0; batch classifier loss: 0.078932; batch adversarial loss: 0.429713\n",
      "epoch 61; iter: 0; batch classifier loss: 0.059849; batch adversarial loss: 0.330181\n",
      "epoch 62; iter: 0; batch classifier loss: 0.080558; batch adversarial loss: 0.426993\n",
      "epoch 63; iter: 0; batch classifier loss: 0.066585; batch adversarial loss: 0.386445\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099543; batch adversarial loss: 0.484053\n",
      "epoch 65; iter: 0; batch classifier loss: 0.128249; batch adversarial loss: 0.435402\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072035; batch adversarial loss: 0.409265\n",
      "epoch 67; iter: 0; batch classifier loss: 0.103812; batch adversarial loss: 0.435681\n",
      "epoch 68; iter: 0; batch classifier loss: 0.102002; batch adversarial loss: 0.395243\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081923; batch adversarial loss: 0.465310\n",
      "epoch 70; iter: 0; batch classifier loss: 0.046220; batch adversarial loss: 0.374561\n",
      "epoch 71; iter: 0; batch classifier loss: 0.075421; batch adversarial loss: 0.500093\n",
      "epoch 72; iter: 0; batch classifier loss: 0.077704; batch adversarial loss: 0.431627\n",
      "epoch 73; iter: 0; batch classifier loss: 0.049619; batch adversarial loss: 0.442235\n",
      "epoch 74; iter: 0; batch classifier loss: 0.058101; batch adversarial loss: 0.499193\n",
      "epoch 75; iter: 0; batch classifier loss: 0.129869; batch adversarial loss: 0.367518\n",
      "epoch 76; iter: 0; batch classifier loss: 0.065102; batch adversarial loss: 0.437309\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080893; batch adversarial loss: 0.371307\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077900; batch adversarial loss: 0.411842\n",
      "epoch 79; iter: 0; batch classifier loss: 0.063615; batch adversarial loss: 0.307064\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061255; batch adversarial loss: 0.370396\n",
      "epoch 81; iter: 0; batch classifier loss: 0.053542; batch adversarial loss: 0.403152\n",
      "epoch 82; iter: 0; batch classifier loss: 0.067970; batch adversarial loss: 0.404722\n",
      "epoch 83; iter: 0; batch classifier loss: 0.080848; batch adversarial loss: 0.461049\n",
      "epoch 84; iter: 0; batch classifier loss: 0.039620; batch adversarial loss: 0.383374\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085453; batch adversarial loss: 0.500848\n",
      "epoch 86; iter: 0; batch classifier loss: 0.056926; batch adversarial loss: 0.493918\n",
      "epoch 87; iter: 0; batch classifier loss: 0.037301; batch adversarial loss: 0.353665\n",
      "epoch 88; iter: 0; batch classifier loss: 0.050297; batch adversarial loss: 0.422461\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056562; batch adversarial loss: 0.385648\n",
      "epoch 90; iter: 0; batch classifier loss: 0.048178; batch adversarial loss: 0.374319\n",
      "epoch 91; iter: 0; batch classifier loss: 0.081565; batch adversarial loss: 0.386936\n",
      "epoch 92; iter: 0; batch classifier loss: 0.059301; batch adversarial loss: 0.447185\n",
      "epoch 93; iter: 0; batch classifier loss: 0.077806; batch adversarial loss: 0.373574\n",
      "epoch 94; iter: 0; batch classifier loss: 0.053798; batch adversarial loss: 0.452759\n",
      "epoch 95; iter: 0; batch classifier loss: 0.093191; batch adversarial loss: 0.403064\n",
      "epoch 96; iter: 0; batch classifier loss: 0.037152; batch adversarial loss: 0.370725\n",
      "epoch 97; iter: 0; batch classifier loss: 0.047124; batch adversarial loss: 0.388535\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081727; batch adversarial loss: 0.356331\n",
      "epoch 99; iter: 0; batch classifier loss: 0.070004; batch adversarial loss: 0.357268\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049457; batch adversarial loss: 0.454392\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049825; batch adversarial loss: 0.440576\n",
      "epoch 102; iter: 0; batch classifier loss: 0.061552; batch adversarial loss: 0.419764\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033492; batch adversarial loss: 0.393237\n",
      "epoch 104; iter: 0; batch classifier loss: 0.057249; batch adversarial loss: 0.407590\n",
      "epoch 105; iter: 0; batch classifier loss: 0.042958; batch adversarial loss: 0.432202\n",
      "epoch 106; iter: 0; batch classifier loss: 0.029385; batch adversarial loss: 0.362907\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036401; batch adversarial loss: 0.399794\n",
      "epoch 108; iter: 0; batch classifier loss: 0.025037; batch adversarial loss: 0.296201\n",
      "epoch 109; iter: 0; batch classifier loss: 0.070679; batch adversarial loss: 0.429249\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035181; batch adversarial loss: 0.411439\n",
      "epoch 111; iter: 0; batch classifier loss: 0.022723; batch adversarial loss: 0.461679\n",
      "epoch 112; iter: 0; batch classifier loss: 0.032438; batch adversarial loss: 0.438484\n",
      "epoch 113; iter: 0; batch classifier loss: 0.046852; batch adversarial loss: 0.503644\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039584; batch adversarial loss: 0.327992\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028968; batch adversarial loss: 0.332620\n",
      "epoch 116; iter: 0; batch classifier loss: 0.015922; batch adversarial loss: 0.428297\n",
      "epoch 117; iter: 0; batch classifier loss: 0.032214; batch adversarial loss: 0.419807\n",
      "epoch 118; iter: 0; batch classifier loss: 0.062123; batch adversarial loss: 0.401936\n",
      "epoch 119; iter: 0; batch classifier loss: 0.024490; batch adversarial loss: 0.324124\n",
      "epoch 120; iter: 0; batch classifier loss: 0.031254; batch adversarial loss: 0.527820\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025593; batch adversarial loss: 0.481192\n",
      "epoch 122; iter: 0; batch classifier loss: 0.013412; batch adversarial loss: 0.449415\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027622; batch adversarial loss: 0.413167\n",
      "epoch 124; iter: 0; batch classifier loss: 0.046399; batch adversarial loss: 0.424692\n",
      "epoch 125; iter: 0; batch classifier loss: 0.021396; batch adversarial loss: 0.389108\n",
      "epoch 126; iter: 0; batch classifier loss: 0.020692; batch adversarial loss: 0.433456\n",
      "epoch 127; iter: 0; batch classifier loss: 0.021901; batch adversarial loss: 0.431820\n",
      "epoch 128; iter: 0; batch classifier loss: 0.009974; batch adversarial loss: 0.450577\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049527; batch adversarial loss: 0.481632\n",
      "epoch 130; iter: 0; batch classifier loss: 0.051668; batch adversarial loss: 0.499807\n",
      "epoch 131; iter: 0; batch classifier loss: 0.025442; batch adversarial loss: 0.493910\n",
      "epoch 132; iter: 0; batch classifier loss: 0.030607; batch adversarial loss: 0.421157\n",
      "epoch 133; iter: 0; batch classifier loss: 0.027469; batch adversarial loss: 0.364540\n",
      "epoch 134; iter: 0; batch classifier loss: 0.020869; batch adversarial loss: 0.428555\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051072; batch adversarial loss: 0.406770\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054586; batch adversarial loss: 0.589943\n",
      "epoch 137; iter: 0; batch classifier loss: 0.124899; batch adversarial loss: 0.559249\n",
      "epoch 138; iter: 0; batch classifier loss: 0.085112; batch adversarial loss: 0.551157\n",
      "epoch 139; iter: 0; batch classifier loss: 0.078370; batch adversarial loss: 0.498052\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050570; batch adversarial loss: 0.447923\n",
      "epoch 141; iter: 0; batch classifier loss: 0.117436; batch adversarial loss: 0.577004\n",
      "epoch 142; iter: 0; batch classifier loss: 0.114809; batch adversarial loss: 0.756550\n",
      "epoch 143; iter: 0; batch classifier loss: 0.192841; batch adversarial loss: 0.733447\n",
      "epoch 144; iter: 0; batch classifier loss: 0.201086; batch adversarial loss: 0.644946\n",
      "epoch 145; iter: 0; batch classifier loss: 0.281054; batch adversarial loss: 0.860730\n",
      "epoch 146; iter: 0; batch classifier loss: 0.176751; batch adversarial loss: 0.705549\n",
      "epoch 147; iter: 0; batch classifier loss: 0.233163; batch adversarial loss: 0.804857\n",
      "epoch 148; iter: 0; batch classifier loss: 0.273126; batch adversarial loss: 0.901053\n",
      "epoch 149; iter: 0; batch classifier loss: 0.207668; batch adversarial loss: 0.691813\n",
      "epoch 150; iter: 0; batch classifier loss: 0.225288; batch adversarial loss: 0.766408\n",
      "epoch 151; iter: 0; batch classifier loss: 0.168718; batch adversarial loss: 0.689197\n",
      "epoch 152; iter: 0; batch classifier loss: 0.214678; batch adversarial loss: 0.676669\n",
      "epoch 153; iter: 0; batch classifier loss: 0.145937; batch adversarial loss: 0.516775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154; iter: 0; batch classifier loss: 0.269902; batch adversarial loss: 0.717533\n",
      "epoch 155; iter: 0; batch classifier loss: 0.153977; batch adversarial loss: 0.552536\n",
      "epoch 156; iter: 0; batch classifier loss: 0.248724; batch adversarial loss: 0.638704\n",
      "epoch 157; iter: 0; batch classifier loss: 0.074066; batch adversarial loss: 0.516081\n",
      "epoch 158; iter: 0; batch classifier loss: 0.158415; batch adversarial loss: 0.563642\n",
      "epoch 159; iter: 0; batch classifier loss: 0.201964; batch adversarial loss: 0.718664\n",
      "epoch 160; iter: 0; batch classifier loss: 0.169186; batch adversarial loss: 0.647797\n",
      "epoch 161; iter: 0; batch classifier loss: 0.135725; batch adversarial loss: 0.505279\n",
      "epoch 162; iter: 0; batch classifier loss: 0.157622; batch adversarial loss: 0.616712\n",
      "epoch 163; iter: 0; batch classifier loss: 0.188513; batch adversarial loss: 0.519879\n",
      "epoch 164; iter: 0; batch classifier loss: 0.217625; batch adversarial loss: 0.630901\n",
      "epoch 165; iter: 0; batch classifier loss: 0.175131; batch adversarial loss: 0.559010\n",
      "epoch 166; iter: 0; batch classifier loss: 0.169047; batch adversarial loss: 0.594792\n",
      "epoch 167; iter: 0; batch classifier loss: 0.161898; batch adversarial loss: 0.490520\n",
      "epoch 168; iter: 0; batch classifier loss: 0.162428; batch adversarial loss: 0.532473\n",
      "epoch 169; iter: 0; batch classifier loss: 0.220702; batch adversarial loss: 0.653722\n",
      "epoch 170; iter: 0; batch classifier loss: 0.169110; batch adversarial loss: 0.513073\n",
      "epoch 171; iter: 0; batch classifier loss: 0.168927; batch adversarial loss: 0.528085\n",
      "epoch 172; iter: 0; batch classifier loss: 0.130638; batch adversarial loss: 0.425961\n",
      "epoch 173; iter: 0; batch classifier loss: 0.122995; batch adversarial loss: 0.395355\n",
      "epoch 174; iter: 0; batch classifier loss: 0.132251; batch adversarial loss: 0.522822\n",
      "epoch 175; iter: 0; batch classifier loss: 0.147465; batch adversarial loss: 0.458209\n",
      "epoch 176; iter: 0; batch classifier loss: 0.147941; batch adversarial loss: 0.511309\n",
      "epoch 177; iter: 0; batch classifier loss: 0.146012; batch adversarial loss: 0.499807\n",
      "epoch 178; iter: 0; batch classifier loss: 0.121978; batch adversarial loss: 0.430219\n",
      "epoch 179; iter: 0; batch classifier loss: 0.118923; batch adversarial loss: 0.463947\n",
      "epoch 180; iter: 0; batch classifier loss: 0.116998; batch adversarial loss: 0.448048\n",
      "epoch 181; iter: 0; batch classifier loss: 0.112801; batch adversarial loss: 0.480942\n",
      "epoch 182; iter: 0; batch classifier loss: 0.100622; batch adversarial loss: 0.462485\n",
      "epoch 183; iter: 0; batch classifier loss: 0.098660; batch adversarial loss: 0.438469\n",
      "epoch 184; iter: 0; batch classifier loss: 0.121858; batch adversarial loss: 0.446617\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037298; batch adversarial loss: 0.383652\n",
      "epoch 186; iter: 0; batch classifier loss: 0.023159; batch adversarial loss: 0.457143\n",
      "epoch 187; iter: 0; batch classifier loss: 0.042020; batch adversarial loss: 0.465297\n",
      "epoch 188; iter: 0; batch classifier loss: 0.028054; batch adversarial loss: 0.428146\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026202; batch adversarial loss: 0.429860\n",
      "epoch 190; iter: 0; batch classifier loss: 0.025671; batch adversarial loss: 0.435221\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021437; batch adversarial loss: 0.456248\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013810; batch adversarial loss: 0.394245\n",
      "epoch 193; iter: 0; batch classifier loss: 0.040216; batch adversarial loss: 0.375972\n",
      "epoch 194; iter: 0; batch classifier loss: 0.032687; batch adversarial loss: 0.463672\n",
      "epoch 195; iter: 0; batch classifier loss: 0.038389; batch adversarial loss: 0.473841\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031030; batch adversarial loss: 0.481571\n",
      "epoch 197; iter: 0; batch classifier loss: 0.041791; batch adversarial loss: 0.476945\n",
      "epoch 198; iter: 0; batch classifier loss: 0.054488; batch adversarial loss: 0.448704\n",
      "epoch 199; iter: 0; batch classifier loss: 0.056463; batch adversarial loss: 0.333380\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718860; batch adversarial loss: 0.876640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.429061; batch adversarial loss: 0.801686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.430299; batch adversarial loss: 0.761540\n",
      "epoch 3; iter: 0; batch classifier loss: 0.341026; batch adversarial loss: 0.711117\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340847; batch adversarial loss: 0.655401\n",
      "epoch 5; iter: 0; batch classifier loss: 0.346799; batch adversarial loss: 0.651737\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363076; batch adversarial loss: 0.605919\n",
      "epoch 7; iter: 0; batch classifier loss: 0.300147; batch adversarial loss: 0.607192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.284108; batch adversarial loss: 0.574604\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363472; batch adversarial loss: 0.551473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.320919; batch adversarial loss: 0.526586\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308385; batch adversarial loss: 0.505292\n",
      "epoch 12; iter: 0; batch classifier loss: 0.255060; batch adversarial loss: 0.483944\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.450934\n",
      "epoch 14; iter: 0; batch classifier loss: 0.270862; batch adversarial loss: 0.530422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224610; batch adversarial loss: 0.431946\n",
      "epoch 16; iter: 0; batch classifier loss: 0.261932; batch adversarial loss: 0.489299\n",
      "epoch 17; iter: 0; batch classifier loss: 0.157418; batch adversarial loss: 0.425196\n",
      "epoch 18; iter: 0; batch classifier loss: 0.216182; batch adversarial loss: 0.369348\n",
      "epoch 19; iter: 0; batch classifier loss: 0.236288; batch adversarial loss: 0.450723\n",
      "epoch 20; iter: 0; batch classifier loss: 0.196632; batch adversarial loss: 0.401670\n",
      "epoch 21; iter: 0; batch classifier loss: 0.172894; batch adversarial loss: 0.430593\n",
      "epoch 22; iter: 0; batch classifier loss: 0.168737; batch adversarial loss: 0.489399\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214774; batch adversarial loss: 0.377287\n",
      "epoch 24; iter: 0; batch classifier loss: 0.202956; batch adversarial loss: 0.408011\n",
      "epoch 25; iter: 0; batch classifier loss: 0.197651; batch adversarial loss: 0.405755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.220805; batch adversarial loss: 0.432157\n",
      "epoch 27; iter: 0; batch classifier loss: 0.160119; batch adversarial loss: 0.373260\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207342; batch adversarial loss: 0.493774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.210302; batch adversarial loss: 0.417458\n",
      "epoch 30; iter: 0; batch classifier loss: 0.172555; batch adversarial loss: 0.399992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.152383; batch adversarial loss: 0.462753\n",
      "epoch 32; iter: 0; batch classifier loss: 0.158015; batch adversarial loss: 0.344986\n",
      "epoch 33; iter: 0; batch classifier loss: 0.179875; batch adversarial loss: 0.391225\n",
      "epoch 34; iter: 0; batch classifier loss: 0.132646; batch adversarial loss: 0.441595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.156597; batch adversarial loss: 0.420795\n",
      "epoch 36; iter: 0; batch classifier loss: 0.115123; batch adversarial loss: 0.375473\n",
      "epoch 37; iter: 0; batch classifier loss: 0.122793; batch adversarial loss: 0.324055\n",
      "epoch 38; iter: 0; batch classifier loss: 0.119872; batch adversarial loss: 0.435125\n",
      "epoch 39; iter: 0; batch classifier loss: 0.107611; batch adversarial loss: 0.415938\n",
      "epoch 40; iter: 0; batch classifier loss: 0.150824; batch adversarial loss: 0.333622\n",
      "epoch 41; iter: 0; batch classifier loss: 0.115795; batch adversarial loss: 0.488814\n",
      "epoch 42; iter: 0; batch classifier loss: 0.137055; batch adversarial loss: 0.432740\n",
      "epoch 43; iter: 0; batch classifier loss: 0.084501; batch adversarial loss: 0.392428\n",
      "epoch 44; iter: 0; batch classifier loss: 0.075797; batch adversarial loss: 0.387598\n",
      "epoch 45; iter: 0; batch classifier loss: 0.103388; batch adversarial loss: 0.358688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.120369; batch adversarial loss: 0.425116\n",
      "epoch 47; iter: 0; batch classifier loss: 0.166599; batch adversarial loss: 0.537703\n",
      "epoch 48; iter: 0; batch classifier loss: 0.145525; batch adversarial loss: 0.482024\n",
      "epoch 49; iter: 0; batch classifier loss: 0.093319; batch adversarial loss: 0.498519\n",
      "epoch 50; iter: 0; batch classifier loss: 0.069497; batch adversarial loss: 0.380746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51; iter: 0; batch classifier loss: 0.127184; batch adversarial loss: 0.344806\n",
      "epoch 52; iter: 0; batch classifier loss: 0.103234; batch adversarial loss: 0.390839\n",
      "epoch 53; iter: 0; batch classifier loss: 0.095779; batch adversarial loss: 0.343045\n",
      "epoch 54; iter: 0; batch classifier loss: 0.065643; batch adversarial loss: 0.364732\n",
      "epoch 55; iter: 0; batch classifier loss: 0.077288; batch adversarial loss: 0.299386\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081620; batch adversarial loss: 0.443370\n",
      "epoch 57; iter: 0; batch classifier loss: 0.080640; batch adversarial loss: 0.382672\n",
      "epoch 58; iter: 0; batch classifier loss: 0.071790; batch adversarial loss: 0.423292\n",
      "epoch 59; iter: 0; batch classifier loss: 0.092773; batch adversarial loss: 0.451323\n",
      "epoch 60; iter: 0; batch classifier loss: 0.102911; batch adversarial loss: 0.380815\n",
      "epoch 61; iter: 0; batch classifier loss: 0.078216; batch adversarial loss: 0.458565\n",
      "epoch 62; iter: 0; batch classifier loss: 0.097277; batch adversarial loss: 0.424320\n",
      "epoch 63; iter: 0; batch classifier loss: 0.071665; batch adversarial loss: 0.368371\n",
      "epoch 64; iter: 0; batch classifier loss: 0.084728; batch adversarial loss: 0.482851\n",
      "epoch 65; iter: 0; batch classifier loss: 0.092399; batch adversarial loss: 0.381788\n",
      "epoch 66; iter: 0; batch classifier loss: 0.072227; batch adversarial loss: 0.413524\n",
      "epoch 67; iter: 0; batch classifier loss: 0.101161; batch adversarial loss: 0.384085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.084043; batch adversarial loss: 0.489154\n",
      "epoch 69; iter: 0; batch classifier loss: 0.087414; batch adversarial loss: 0.353103\n",
      "epoch 70; iter: 0; batch classifier loss: 0.108651; batch adversarial loss: 0.468332\n",
      "epoch 71; iter: 0; batch classifier loss: 0.081398; batch adversarial loss: 0.439657\n",
      "epoch 72; iter: 0; batch classifier loss: 0.061543; batch adversarial loss: 0.435456\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062612; batch adversarial loss: 0.427448\n",
      "epoch 74; iter: 0; batch classifier loss: 0.079665; batch adversarial loss: 0.453567\n",
      "epoch 75; iter: 0; batch classifier loss: 0.104039; batch adversarial loss: 0.454653\n",
      "epoch 76; iter: 0; batch classifier loss: 0.048720; batch adversarial loss: 0.370642\n",
      "epoch 77; iter: 0; batch classifier loss: 0.054588; batch adversarial loss: 0.495088\n",
      "epoch 78; iter: 0; batch classifier loss: 0.068092; batch adversarial loss: 0.431772\n",
      "epoch 79; iter: 0; batch classifier loss: 0.060351; batch adversarial loss: 0.460564\n",
      "epoch 80; iter: 0; batch classifier loss: 0.080972; batch adversarial loss: 0.352109\n",
      "epoch 81; iter: 0; batch classifier loss: 0.082006; batch adversarial loss: 0.480381\n",
      "epoch 82; iter: 0; batch classifier loss: 0.052598; batch adversarial loss: 0.487770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.108898; batch adversarial loss: 0.450341\n",
      "epoch 84; iter: 0; batch classifier loss: 0.084318; batch adversarial loss: 0.425355\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075908; batch adversarial loss: 0.452889\n",
      "epoch 86; iter: 0; batch classifier loss: 0.050955; batch adversarial loss: 0.476867\n",
      "epoch 87; iter: 0; batch classifier loss: 0.077635; batch adversarial loss: 0.440758\n",
      "epoch 88; iter: 0; batch classifier loss: 0.057483; batch adversarial loss: 0.410849\n",
      "epoch 89; iter: 0; batch classifier loss: 0.072159; batch adversarial loss: 0.401166\n",
      "epoch 90; iter: 0; batch classifier loss: 0.103377; batch adversarial loss: 0.426749\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062308; batch adversarial loss: 0.417808\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066933; batch adversarial loss: 0.387221\n",
      "epoch 93; iter: 0; batch classifier loss: 0.119407; batch adversarial loss: 0.395091\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070734; batch adversarial loss: 0.493889\n",
      "epoch 95; iter: 0; batch classifier loss: 0.101260; batch adversarial loss: 0.499519\n",
      "epoch 96; iter: 0; batch classifier loss: 0.045481; batch adversarial loss: 0.426631\n",
      "epoch 97; iter: 0; batch classifier loss: 0.060240; batch adversarial loss: 0.506572\n",
      "epoch 98; iter: 0; batch classifier loss: 0.096895; batch adversarial loss: 0.426684\n",
      "epoch 99; iter: 0; batch classifier loss: 0.072716; batch adversarial loss: 0.346257\n",
      "epoch 100; iter: 0; batch classifier loss: 0.060309; batch adversarial loss: 0.443746\n",
      "epoch 101; iter: 0; batch classifier loss: 0.046389; batch adversarial loss: 0.341901\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034083; batch adversarial loss: 0.353621\n",
      "epoch 103; iter: 0; batch classifier loss: 0.055209; batch adversarial loss: 0.466457\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051278; batch adversarial loss: 0.454483\n",
      "epoch 105; iter: 0; batch classifier loss: 0.061433; batch adversarial loss: 0.400200\n",
      "epoch 106; iter: 0; batch classifier loss: 0.097106; batch adversarial loss: 0.453801\n",
      "epoch 107; iter: 0; batch classifier loss: 0.057628; batch adversarial loss: 0.482968\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067377; batch adversarial loss: 0.428951\n",
      "epoch 109; iter: 0; batch classifier loss: 0.039151; batch adversarial loss: 0.476355\n",
      "epoch 110; iter: 0; batch classifier loss: 0.067254; batch adversarial loss: 0.445240\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050899; batch adversarial loss: 0.402953\n",
      "epoch 112; iter: 0; batch classifier loss: 0.082972; batch adversarial loss: 0.413431\n",
      "epoch 113; iter: 0; batch classifier loss: 0.025541; batch adversarial loss: 0.359968\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080837; batch adversarial loss: 0.551120\n",
      "epoch 115; iter: 0; batch classifier loss: 0.049850; batch adversarial loss: 0.379699\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037977; batch adversarial loss: 0.354205\n",
      "epoch 117; iter: 0; batch classifier loss: 0.034568; batch adversarial loss: 0.483031\n",
      "epoch 118; iter: 0; batch classifier loss: 0.047613; batch adversarial loss: 0.539420\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029975; batch adversarial loss: 0.433643\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035349; batch adversarial loss: 0.426806\n",
      "epoch 121; iter: 0; batch classifier loss: 0.040684; batch adversarial loss: 0.403319\n",
      "epoch 122; iter: 0; batch classifier loss: 0.031215; batch adversarial loss: 0.392674\n",
      "epoch 123; iter: 0; batch classifier loss: 0.034739; batch adversarial loss: 0.414148\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032216; batch adversarial loss: 0.439390\n",
      "epoch 125; iter: 0; batch classifier loss: 0.053037; batch adversarial loss: 0.417350\n",
      "epoch 126; iter: 0; batch classifier loss: 0.031323; batch adversarial loss: 0.445146\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034391; batch adversarial loss: 0.405863\n",
      "epoch 128; iter: 0; batch classifier loss: 0.055413; batch adversarial loss: 0.426323\n",
      "epoch 129; iter: 0; batch classifier loss: 0.031626; batch adversarial loss: 0.451164\n",
      "epoch 130; iter: 0; batch classifier loss: 0.021395; batch adversarial loss: 0.493439\n",
      "epoch 131; iter: 0; batch classifier loss: 0.026781; batch adversarial loss: 0.405056\n",
      "epoch 132; iter: 0; batch classifier loss: 0.022692; batch adversarial loss: 0.450015\n",
      "epoch 133; iter: 0; batch classifier loss: 0.026929; batch adversarial loss: 0.447216\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037642; batch adversarial loss: 0.454356\n",
      "epoch 135; iter: 0; batch classifier loss: 0.012943; batch adversarial loss: 0.480043\n",
      "epoch 136; iter: 0; batch classifier loss: 0.031902; batch adversarial loss: 0.522085\n",
      "epoch 137; iter: 0; batch classifier loss: 0.053225; batch adversarial loss: 0.446532\n",
      "epoch 138; iter: 0; batch classifier loss: 0.020836; batch adversarial loss: 0.391140\n",
      "epoch 139; iter: 0; batch classifier loss: 0.070818; batch adversarial loss: 0.587550\n",
      "epoch 140; iter: 0; batch classifier loss: 0.073256; batch adversarial loss: 0.485542\n",
      "epoch 141; iter: 0; batch classifier loss: 0.073773; batch adversarial loss: 0.562744\n",
      "epoch 142; iter: 0; batch classifier loss: 0.105132; batch adversarial loss: 0.570930\n",
      "epoch 143; iter: 0; batch classifier loss: 0.142257; batch adversarial loss: 0.735366\n",
      "epoch 144; iter: 0; batch classifier loss: 0.092722; batch adversarial loss: 0.574666\n",
      "epoch 145; iter: 0; batch classifier loss: 0.111839; batch adversarial loss: 0.559151\n",
      "epoch 146; iter: 0; batch classifier loss: 0.122765; batch adversarial loss: 0.639382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 147; iter: 0; batch classifier loss: 0.155105; batch adversarial loss: 0.772343\n",
      "epoch 148; iter: 0; batch classifier loss: 0.132747; batch adversarial loss: 0.557508\n",
      "epoch 149; iter: 0; batch classifier loss: 0.251329; batch adversarial loss: 0.749795\n",
      "epoch 150; iter: 0; batch classifier loss: 0.141223; batch adversarial loss: 0.636740\n",
      "epoch 151; iter: 0; batch classifier loss: 0.154404; batch adversarial loss: 0.604710\n",
      "epoch 152; iter: 0; batch classifier loss: 0.167061; batch adversarial loss: 0.737417\n",
      "epoch 153; iter: 0; batch classifier loss: 0.230654; batch adversarial loss: 0.677156\n",
      "epoch 154; iter: 0; batch classifier loss: 0.196264; batch adversarial loss: 0.722496\n",
      "epoch 155; iter: 0; batch classifier loss: 0.115094; batch adversarial loss: 0.471307\n",
      "epoch 156; iter: 0; batch classifier loss: 0.160979; batch adversarial loss: 0.547788\n",
      "epoch 157; iter: 0; batch classifier loss: 0.073694; batch adversarial loss: 0.508684\n",
      "epoch 158; iter: 0; batch classifier loss: 0.183881; batch adversarial loss: 0.638197\n",
      "epoch 159; iter: 0; batch classifier loss: 0.176882; batch adversarial loss: 0.557230\n",
      "epoch 160; iter: 0; batch classifier loss: 0.167800; batch adversarial loss: 0.550987\n",
      "epoch 161; iter: 0; batch classifier loss: 0.197340; batch adversarial loss: 0.639048\n",
      "epoch 162; iter: 0; batch classifier loss: 0.197671; batch adversarial loss: 0.652449\n",
      "epoch 163; iter: 0; batch classifier loss: 0.213189; batch adversarial loss: 0.705775\n",
      "epoch 164; iter: 0; batch classifier loss: 0.161047; batch adversarial loss: 0.592907\n",
      "epoch 165; iter: 0; batch classifier loss: 0.109185; batch adversarial loss: 0.485462\n",
      "epoch 166; iter: 0; batch classifier loss: 0.149608; batch adversarial loss: 0.513962\n",
      "epoch 167; iter: 0; batch classifier loss: 0.188020; batch adversarial loss: 0.648383\n",
      "epoch 168; iter: 0; batch classifier loss: 0.163943; batch adversarial loss: 0.557882\n",
      "epoch 169; iter: 0; batch classifier loss: 0.192611; batch adversarial loss: 0.482577\n",
      "epoch 170; iter: 0; batch classifier loss: 0.074026; batch adversarial loss: 0.401490\n",
      "epoch 171; iter: 0; batch classifier loss: 0.135736; batch adversarial loss: 0.499694\n",
      "epoch 172; iter: 0; batch classifier loss: 0.179111; batch adversarial loss: 0.551610\n",
      "epoch 173; iter: 0; batch classifier loss: 0.146899; batch adversarial loss: 0.535752\n",
      "epoch 174; iter: 0; batch classifier loss: 0.222383; batch adversarial loss: 0.628272\n",
      "epoch 175; iter: 0; batch classifier loss: 0.127811; batch adversarial loss: 0.507815\n",
      "epoch 176; iter: 0; batch classifier loss: 0.140642; batch adversarial loss: 0.519911\n",
      "epoch 177; iter: 0; batch classifier loss: 0.099784; batch adversarial loss: 0.406241\n",
      "epoch 178; iter: 0; batch classifier loss: 0.103122; batch adversarial loss: 0.478574\n",
      "epoch 179; iter: 0; batch classifier loss: 0.120599; batch adversarial loss: 0.426238\n",
      "epoch 180; iter: 0; batch classifier loss: 0.097807; batch adversarial loss: 0.411594\n",
      "epoch 181; iter: 0; batch classifier loss: 0.085254; batch adversarial loss: 0.394766\n",
      "epoch 182; iter: 0; batch classifier loss: 0.129562; batch adversarial loss: 0.457056\n",
      "epoch 183; iter: 0; batch classifier loss: 0.185251; batch adversarial loss: 0.540681\n",
      "epoch 184; iter: 0; batch classifier loss: 0.073109; batch adversarial loss: 0.350166\n",
      "epoch 185; iter: 0; batch classifier loss: 0.183547; batch adversarial loss: 0.517032\n",
      "epoch 186; iter: 0; batch classifier loss: 0.137995; batch adversarial loss: 0.408528\n",
      "epoch 187; iter: 0; batch classifier loss: 0.045771; batch adversarial loss: 0.552817\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041922; batch adversarial loss: 0.430403\n",
      "epoch 189; iter: 0; batch classifier loss: 0.044308; batch adversarial loss: 0.416407\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034437; batch adversarial loss: 0.414976\n",
      "epoch 191; iter: 0; batch classifier loss: 0.052238; batch adversarial loss: 0.426052\n",
      "epoch 192; iter: 0; batch classifier loss: 0.033589; batch adversarial loss: 0.436232\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011267; batch adversarial loss: 0.384361\n",
      "epoch 194; iter: 0; batch classifier loss: 0.063509; batch adversarial loss: 0.392856\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027408; batch adversarial loss: 0.467145\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030142; batch adversarial loss: 0.407948\n",
      "epoch 197; iter: 0; batch classifier loss: 0.033166; batch adversarial loss: 0.366237\n",
      "epoch 198; iter: 0; batch classifier loss: 0.053496; batch adversarial loss: 0.456680\n",
      "epoch 199; iter: 0; batch classifier loss: 0.049010; batch adversarial loss: 0.481528\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723518; batch adversarial loss: 0.535993\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375693; batch adversarial loss: 0.595106\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423621; batch adversarial loss: 0.593464\n",
      "epoch 3; iter: 0; batch classifier loss: 0.391160; batch adversarial loss: 0.585399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372684; batch adversarial loss: 0.610160\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365033; batch adversarial loss: 0.532939\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476224; batch adversarial loss: 0.606693\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384661; batch adversarial loss: 0.601391\n",
      "epoch 8; iter: 0; batch classifier loss: 0.460320; batch adversarial loss: 0.568849\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565556; batch adversarial loss: 0.549629\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439745; batch adversarial loss: 0.552352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381841; batch adversarial loss: 0.595999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408793; batch adversarial loss: 0.481309\n",
      "epoch 13; iter: 0; batch classifier loss: 0.232999; batch adversarial loss: 0.524531\n",
      "epoch 14; iter: 0; batch classifier loss: 0.258926; batch adversarial loss: 0.485268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282602; batch adversarial loss: 0.495876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.183572; batch adversarial loss: 0.460084\n",
      "epoch 17; iter: 0; batch classifier loss: 0.107543; batch adversarial loss: 0.447846\n",
      "epoch 18; iter: 0; batch classifier loss: 0.245352; batch adversarial loss: 0.446295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212200; batch adversarial loss: 0.453937\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328438; batch adversarial loss: 0.455904\n",
      "epoch 21; iter: 0; batch classifier loss: 0.184970; batch adversarial loss: 0.415048\n",
      "epoch 22; iter: 0; batch classifier loss: 0.152062; batch adversarial loss: 0.426332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.217197; batch adversarial loss: 0.444703\n",
      "epoch 24; iter: 0; batch classifier loss: 0.180265; batch adversarial loss: 0.446631\n",
      "epoch 25; iter: 0; batch classifier loss: 0.161723; batch adversarial loss: 0.483134\n",
      "epoch 26; iter: 0; batch classifier loss: 0.198006; batch adversarial loss: 0.426696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.221455; batch adversarial loss: 0.453627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.119648; batch adversarial loss: 0.522562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145918; batch adversarial loss: 0.451990\n",
      "epoch 30; iter: 0; batch classifier loss: 0.144929; batch adversarial loss: 0.480058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.160124; batch adversarial loss: 0.452271\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176904; batch adversarial loss: 0.436476\n",
      "epoch 33; iter: 0; batch classifier loss: 0.150994; batch adversarial loss: 0.435531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122523; batch adversarial loss: 0.495739\n",
      "epoch 35; iter: 0; batch classifier loss: 0.141474; batch adversarial loss: 0.473949\n",
      "epoch 36; iter: 0; batch classifier loss: 0.187580; batch adversarial loss: 0.540707\n",
      "epoch 37; iter: 0; batch classifier loss: 0.110153; batch adversarial loss: 0.408695\n",
      "epoch 38; iter: 0; batch classifier loss: 0.169849; batch adversarial loss: 0.432209\n",
      "epoch 39; iter: 0; batch classifier loss: 0.145088; batch adversarial loss: 0.471120\n",
      "epoch 40; iter: 0; batch classifier loss: 0.110099; batch adversarial loss: 0.426854\n",
      "epoch 41; iter: 0; batch classifier loss: 0.165761; batch adversarial loss: 0.506284\n",
      "epoch 42; iter: 0; batch classifier loss: 0.111514; batch adversarial loss: 0.392720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.152903; batch adversarial loss: 0.504046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.195030; batch adversarial loss: 0.441917\n",
      "epoch 45; iter: 0; batch classifier loss: 0.145247; batch adversarial loss: 0.476946\n",
      "epoch 46; iter: 0; batch classifier loss: 0.202212; batch adversarial loss: 0.360857\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185889; batch adversarial loss: 0.394811\n",
      "epoch 48; iter: 0; batch classifier loss: 0.185582; batch adversarial loss: 0.413731\n",
      "epoch 49; iter: 0; batch classifier loss: 0.157700; batch adversarial loss: 0.482064\n",
      "epoch 50; iter: 0; batch classifier loss: 0.155377; batch adversarial loss: 0.450823\n",
      "epoch 51; iter: 0; batch classifier loss: 0.104976; batch adversarial loss: 0.318998\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161878; batch adversarial loss: 0.311052\n",
      "epoch 53; iter: 0; batch classifier loss: 0.165484; batch adversarial loss: 0.521285\n",
      "epoch 54; iter: 0; batch classifier loss: 0.101053; batch adversarial loss: 0.447983\n",
      "epoch 55; iter: 0; batch classifier loss: 0.173687; batch adversarial loss: 0.448288\n",
      "epoch 56; iter: 0; batch classifier loss: 0.159365; batch adversarial loss: 0.520941\n",
      "epoch 57; iter: 0; batch classifier loss: 0.185244; batch adversarial loss: 0.435736\n",
      "epoch 58; iter: 0; batch classifier loss: 0.102461; batch adversarial loss: 0.407680\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170929; batch adversarial loss: 0.436960\n",
      "epoch 60; iter: 0; batch classifier loss: 0.134899; batch adversarial loss: 0.485280\n",
      "epoch 61; iter: 0; batch classifier loss: 0.118672; batch adversarial loss: 0.383718\n",
      "epoch 62; iter: 0; batch classifier loss: 0.111491; batch adversarial loss: 0.554741\n",
      "epoch 63; iter: 0; batch classifier loss: 0.187291; batch adversarial loss: 0.421857\n",
      "epoch 64; iter: 0; batch classifier loss: 0.089597; batch adversarial loss: 0.410881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.186161; batch adversarial loss: 0.480261\n",
      "epoch 66; iter: 0; batch classifier loss: 0.212089; batch adversarial loss: 0.409098\n",
      "epoch 67; iter: 0; batch classifier loss: 0.142248; batch adversarial loss: 0.456612\n",
      "epoch 68; iter: 0; batch classifier loss: 0.202644; batch adversarial loss: 0.457380\n",
      "epoch 69; iter: 0; batch classifier loss: 0.197464; batch adversarial loss: 0.470019\n",
      "epoch 70; iter: 0; batch classifier loss: 0.160262; batch adversarial loss: 0.499936\n",
      "epoch 71; iter: 0; batch classifier loss: 0.146191; batch adversarial loss: 0.460876\n",
      "epoch 72; iter: 0; batch classifier loss: 0.178311; batch adversarial loss: 0.421873\n",
      "epoch 73; iter: 0; batch classifier loss: 0.164896; batch adversarial loss: 0.571276\n",
      "epoch 74; iter: 0; batch classifier loss: 0.256685; batch adversarial loss: 0.384083\n",
      "epoch 75; iter: 0; batch classifier loss: 0.195134; batch adversarial loss: 0.486955\n",
      "epoch 76; iter: 0; batch classifier loss: 0.156936; batch adversarial loss: 0.434912\n",
      "epoch 77; iter: 0; batch classifier loss: 0.138098; batch adversarial loss: 0.472758\n",
      "epoch 78; iter: 0; batch classifier loss: 0.160660; batch adversarial loss: 0.495503\n",
      "epoch 79; iter: 0; batch classifier loss: 0.206130; batch adversarial loss: 0.420770\n",
      "epoch 80; iter: 0; batch classifier loss: 0.137463; batch adversarial loss: 0.469698\n",
      "epoch 81; iter: 0; batch classifier loss: 0.193427; batch adversarial loss: 0.459325\n",
      "epoch 82; iter: 0; batch classifier loss: 0.189786; batch adversarial loss: 0.434691\n",
      "epoch 83; iter: 0; batch classifier loss: 0.169630; batch adversarial loss: 0.472683\n",
      "epoch 84; iter: 0; batch classifier loss: 0.213879; batch adversarial loss: 0.448289\n",
      "epoch 85; iter: 0; batch classifier loss: 0.191944; batch adversarial loss: 0.485141\n",
      "epoch 86; iter: 0; batch classifier loss: 0.206804; batch adversarial loss: 0.396234\n",
      "epoch 87; iter: 0; batch classifier loss: 0.208668; batch adversarial loss: 0.395336\n",
      "epoch 88; iter: 0; batch classifier loss: 0.228599; batch adversarial loss: 0.420228\n",
      "epoch 89; iter: 0; batch classifier loss: 0.128242; batch adversarial loss: 0.433256\n",
      "epoch 90; iter: 0; batch classifier loss: 0.146295; batch adversarial loss: 0.457369\n",
      "epoch 91; iter: 0; batch classifier loss: 0.183167; batch adversarial loss: 0.459230\n",
      "epoch 92; iter: 0; batch classifier loss: 0.152856; batch adversarial loss: 0.559109\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136439; batch adversarial loss: 0.395587\n",
      "epoch 94; iter: 0; batch classifier loss: 0.149392; batch adversarial loss: 0.507980\n",
      "epoch 95; iter: 0; batch classifier loss: 0.182846; batch adversarial loss: 0.510042\n",
      "epoch 96; iter: 0; batch classifier loss: 0.124955; batch adversarial loss: 0.446768\n",
      "epoch 97; iter: 0; batch classifier loss: 0.167305; batch adversarial loss: 0.383644\n",
      "epoch 98; iter: 0; batch classifier loss: 0.146141; batch adversarial loss: 0.434671\n",
      "epoch 99; iter: 0; batch classifier loss: 0.153842; batch adversarial loss: 0.268912\n",
      "epoch 100; iter: 0; batch classifier loss: 0.208666; batch adversarial loss: 0.421840\n",
      "epoch 101; iter: 0; batch classifier loss: 0.151539; batch adversarial loss: 0.422064\n",
      "epoch 102; iter: 0; batch classifier loss: 0.215920; batch adversarial loss: 0.472894\n",
      "epoch 103; iter: 0; batch classifier loss: 0.159837; batch adversarial loss: 0.520086\n",
      "epoch 104; iter: 0; batch classifier loss: 0.182801; batch adversarial loss: 0.445778\n",
      "epoch 105; iter: 0; batch classifier loss: 0.173929; batch adversarial loss: 0.484990\n",
      "epoch 106; iter: 0; batch classifier loss: 0.220500; batch adversarial loss: 0.381661\n",
      "epoch 107; iter: 0; batch classifier loss: 0.166330; batch adversarial loss: 0.407333\n",
      "epoch 108; iter: 0; batch classifier loss: 0.122880; batch adversarial loss: 0.344598\n",
      "epoch 109; iter: 0; batch classifier loss: 0.141540; batch adversarial loss: 0.408628\n",
      "epoch 110; iter: 0; batch classifier loss: 0.121453; batch adversarial loss: 0.509091\n",
      "epoch 111; iter: 0; batch classifier loss: 0.132137; batch adversarial loss: 0.370574\n",
      "epoch 112; iter: 0; batch classifier loss: 0.178191; batch adversarial loss: 0.370107\n",
      "epoch 113; iter: 0; batch classifier loss: 0.165618; batch adversarial loss: 0.546628\n",
      "epoch 114; iter: 0; batch classifier loss: 0.094246; batch adversarial loss: 0.459790\n",
      "epoch 115; iter: 0; batch classifier loss: 0.153554; batch adversarial loss: 0.407057\n",
      "epoch 116; iter: 0; batch classifier loss: 0.120940; batch adversarial loss: 0.396054\n",
      "epoch 117; iter: 0; batch classifier loss: 0.125881; batch adversarial loss: 0.445742\n",
      "epoch 118; iter: 0; batch classifier loss: 0.169004; batch adversarial loss: 0.535725\n",
      "epoch 119; iter: 0; batch classifier loss: 0.131573; batch adversarial loss: 0.421909\n",
      "epoch 120; iter: 0; batch classifier loss: 0.150273; batch adversarial loss: 0.433876\n",
      "epoch 121; iter: 0; batch classifier loss: 0.125800; batch adversarial loss: 0.395797\n",
      "epoch 122; iter: 0; batch classifier loss: 0.111724; batch adversarial loss: 0.395326\n",
      "epoch 123; iter: 0; batch classifier loss: 0.139415; batch adversarial loss: 0.403888\n",
      "epoch 124; iter: 0; batch classifier loss: 0.072335; batch adversarial loss: 0.456138\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089712; batch adversarial loss: 0.471481\n",
      "epoch 126; iter: 0; batch classifier loss: 0.121477; batch adversarial loss: 0.461311\n",
      "epoch 127; iter: 0; batch classifier loss: 0.083576; batch adversarial loss: 0.483539\n",
      "epoch 128; iter: 0; batch classifier loss: 0.074392; batch adversarial loss: 0.382382\n",
      "epoch 129; iter: 0; batch classifier loss: 0.116074; batch adversarial loss: 0.386044\n",
      "epoch 130; iter: 0; batch classifier loss: 0.075637; batch adversarial loss: 0.468672\n",
      "epoch 131; iter: 0; batch classifier loss: 0.060059; batch adversarial loss: 0.428874\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068478; batch adversarial loss: 0.326169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.068860; batch adversarial loss: 0.394747\n",
      "epoch 134; iter: 0; batch classifier loss: 0.064178; batch adversarial loss: 0.432845\n",
      "epoch 135; iter: 0; batch classifier loss: 0.083100; batch adversarial loss: 0.475979\n",
      "epoch 136; iter: 0; batch classifier loss: 0.045090; batch adversarial loss: 0.413396\n",
      "epoch 137; iter: 0; batch classifier loss: 0.039083; batch adversarial loss: 0.417727\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036026; batch adversarial loss: 0.438893\n",
      "epoch 139; iter: 0; batch classifier loss: 0.026956; batch adversarial loss: 0.518215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 140; iter: 0; batch classifier loss: 0.043255; batch adversarial loss: 0.515274\n",
      "epoch 141; iter: 0; batch classifier loss: 0.045472; batch adversarial loss: 0.509990\n",
      "epoch 142; iter: 0; batch classifier loss: 0.032613; batch adversarial loss: 0.387103\n",
      "epoch 143; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.480100\n",
      "epoch 144; iter: 0; batch classifier loss: 0.026261; batch adversarial loss: 0.401403\n",
      "epoch 145; iter: 0; batch classifier loss: 0.034479; batch adversarial loss: 0.423943\n",
      "epoch 146; iter: 0; batch classifier loss: 0.023907; batch adversarial loss: 0.590737\n",
      "epoch 147; iter: 0; batch classifier loss: 0.019137; batch adversarial loss: 0.465741\n",
      "epoch 148; iter: 0; batch classifier loss: 0.051285; batch adversarial loss: 0.516976\n",
      "epoch 149; iter: 0; batch classifier loss: 0.028313; batch adversarial loss: 0.402213\n",
      "epoch 150; iter: 0; batch classifier loss: 0.044575; batch adversarial loss: 0.549938\n",
      "epoch 151; iter: 0; batch classifier loss: 0.023421; batch adversarial loss: 0.405828\n",
      "epoch 152; iter: 0; batch classifier loss: 0.037198; batch adversarial loss: 0.374917\n",
      "epoch 153; iter: 0; batch classifier loss: 0.031893; batch adversarial loss: 0.384106\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043578; batch adversarial loss: 0.381582\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023827; batch adversarial loss: 0.433488\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025169; batch adversarial loss: 0.450973\n",
      "epoch 157; iter: 0; batch classifier loss: 0.050323; batch adversarial loss: 0.467520\n",
      "epoch 158; iter: 0; batch classifier loss: 0.039702; batch adversarial loss: 0.431594\n",
      "epoch 159; iter: 0; batch classifier loss: 0.044759; batch adversarial loss: 0.428814\n",
      "epoch 160; iter: 0; batch classifier loss: 0.015808; batch adversarial loss: 0.394047\n",
      "epoch 161; iter: 0; batch classifier loss: 0.013645; batch adversarial loss: 0.398881\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014993; batch adversarial loss: 0.474401\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038884; batch adversarial loss: 0.372318\n",
      "epoch 164; iter: 0; batch classifier loss: 0.041015; batch adversarial loss: 0.414652\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027596; batch adversarial loss: 0.418605\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013821; batch adversarial loss: 0.314593\n",
      "epoch 167; iter: 0; batch classifier loss: 0.020844; batch adversarial loss: 0.436560\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022562; batch adversarial loss: 0.420789\n",
      "epoch 169; iter: 0; batch classifier loss: 0.036501; batch adversarial loss: 0.406432\n",
      "epoch 170; iter: 0; batch classifier loss: 0.012363; batch adversarial loss: 0.524247\n",
      "epoch 171; iter: 0; batch classifier loss: 0.032637; batch adversarial loss: 0.439115\n",
      "epoch 172; iter: 0; batch classifier loss: 0.010945; batch adversarial loss: 0.443231\n",
      "epoch 173; iter: 0; batch classifier loss: 0.013284; batch adversarial loss: 0.372875\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029365; batch adversarial loss: 0.477944\n",
      "epoch 175; iter: 0; batch classifier loss: 0.043666; batch adversarial loss: 0.292950\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011850; batch adversarial loss: 0.477357\n",
      "epoch 177; iter: 0; batch classifier loss: 0.025929; batch adversarial loss: 0.410856\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013836; batch adversarial loss: 0.381501\n",
      "epoch 179; iter: 0; batch classifier loss: 0.023954; batch adversarial loss: 0.426465\n",
      "epoch 180; iter: 0; batch classifier loss: 0.028321; batch adversarial loss: 0.375034\n",
      "epoch 181; iter: 0; batch classifier loss: 0.025907; batch adversarial loss: 0.356051\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017118; batch adversarial loss: 0.446809\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027015; batch adversarial loss: 0.406342\n",
      "epoch 184; iter: 0; batch classifier loss: 0.030665; batch adversarial loss: 0.376603\n",
      "epoch 185; iter: 0; batch classifier loss: 0.032090; batch adversarial loss: 0.406686\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021603; batch adversarial loss: 0.480154\n",
      "epoch 187; iter: 0; batch classifier loss: 0.010412; batch adversarial loss: 0.496955\n",
      "epoch 188; iter: 0; batch classifier loss: 0.011481; batch adversarial loss: 0.459732\n",
      "epoch 189; iter: 0; batch classifier loss: 0.014969; batch adversarial loss: 0.402488\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023453; batch adversarial loss: 0.454123\n",
      "epoch 191; iter: 0; batch classifier loss: 0.028646; batch adversarial loss: 0.417499\n",
      "epoch 192; iter: 0; batch classifier loss: 0.022694; batch adversarial loss: 0.465087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.026826; batch adversarial loss: 0.437894\n",
      "epoch 194; iter: 0; batch classifier loss: 0.012072; batch adversarial loss: 0.384003\n",
      "epoch 195; iter: 0; batch classifier loss: 0.019868; batch adversarial loss: 0.456196\n",
      "epoch 196; iter: 0; batch classifier loss: 0.020059; batch adversarial loss: 0.440478\n",
      "epoch 197; iter: 0; batch classifier loss: 0.004014; batch adversarial loss: 0.358908\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022251; batch adversarial loss: 0.437349\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011094; batch adversarial loss: 0.421277\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693937; batch adversarial loss: 1.052687\n",
      "epoch 1; iter: 0; batch classifier loss: 0.557426; batch adversarial loss: 1.190190\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458024; batch adversarial loss: 1.033431\n",
      "epoch 3; iter: 0; batch classifier loss: 0.392899; batch adversarial loss: 1.052110\n",
      "epoch 4; iter: 0; batch classifier loss: 0.441631; batch adversarial loss: 0.892382\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440245; batch adversarial loss: 0.867803\n",
      "epoch 6; iter: 0; batch classifier loss: 0.258607; batch adversarial loss: 0.774295\n",
      "epoch 7; iter: 0; batch classifier loss: 0.298748; batch adversarial loss: 0.729866\n",
      "epoch 8; iter: 0; batch classifier loss: 0.315182; batch adversarial loss: 0.699963\n",
      "epoch 9; iter: 0; batch classifier loss: 0.292339; batch adversarial loss: 0.684582\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250698; batch adversarial loss: 0.628236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.256959; batch adversarial loss: 0.613166\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251125; batch adversarial loss: 0.625757\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227564; batch adversarial loss: 0.584833\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262071; batch adversarial loss: 0.543263\n",
      "epoch 15; iter: 0; batch classifier loss: 0.212554; batch adversarial loss: 0.578898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.212176; batch adversarial loss: 0.515320\n",
      "epoch 17; iter: 0; batch classifier loss: 0.196898; batch adversarial loss: 0.492359\n",
      "epoch 18; iter: 0; batch classifier loss: 0.224797; batch adversarial loss: 0.539672\n",
      "epoch 19; iter: 0; batch classifier loss: 0.233934; batch adversarial loss: 0.497266\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210552; batch adversarial loss: 0.520635\n",
      "epoch 21; iter: 0; batch classifier loss: 0.163614; batch adversarial loss: 0.510411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163497; batch adversarial loss: 0.480072\n",
      "epoch 23; iter: 0; batch classifier loss: 0.218717; batch adversarial loss: 0.468872\n",
      "epoch 24; iter: 0; batch classifier loss: 0.157836; batch adversarial loss: 0.513269\n",
      "epoch 25; iter: 0; batch classifier loss: 0.155874; batch adversarial loss: 0.426427\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209471; batch adversarial loss: 0.493954\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188311; batch adversarial loss: 0.488965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.172525; batch adversarial loss: 0.427416\n",
      "epoch 29; iter: 0; batch classifier loss: 0.163214; batch adversarial loss: 0.472123\n",
      "epoch 30; iter: 0; batch classifier loss: 0.245223; batch adversarial loss: 0.421276\n",
      "epoch 31; iter: 0; batch classifier loss: 0.243729; batch adversarial loss: 0.427948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.265360; batch adversarial loss: 0.402791\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291556; batch adversarial loss: 0.372586\n",
      "epoch 34; iter: 0; batch classifier loss: 0.291861; batch adversarial loss: 0.407851\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235673; batch adversarial loss: 0.437131\n",
      "epoch 36; iter: 0; batch classifier loss: 0.262641; batch adversarial loss: 0.345096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 0; batch classifier loss: 0.208708; batch adversarial loss: 0.416353\n",
      "epoch 38; iter: 0; batch classifier loss: 0.283809; batch adversarial loss: 0.394909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176996; batch adversarial loss: 0.388860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.243358; batch adversarial loss: 0.426920\n",
      "epoch 41; iter: 0; batch classifier loss: 0.234470; batch adversarial loss: 0.410800\n",
      "epoch 42; iter: 0; batch classifier loss: 0.240816; batch adversarial loss: 0.409687\n",
      "epoch 43; iter: 0; batch classifier loss: 0.224612; batch adversarial loss: 0.445178\n",
      "epoch 44; iter: 0; batch classifier loss: 0.144793; batch adversarial loss: 0.402801\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197738; batch adversarial loss: 0.379626\n",
      "epoch 46; iter: 0; batch classifier loss: 0.203033; batch adversarial loss: 0.344588\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175982; batch adversarial loss: 0.361794\n",
      "epoch 48; iter: 0; batch classifier loss: 0.135607; batch adversarial loss: 0.366210\n",
      "epoch 49; iter: 0; batch classifier loss: 0.099159; batch adversarial loss: 0.320461\n",
      "epoch 50; iter: 0; batch classifier loss: 0.191994; batch adversarial loss: 0.398897\n",
      "epoch 51; iter: 0; batch classifier loss: 0.105707; batch adversarial loss: 0.485805\n",
      "epoch 52; iter: 0; batch classifier loss: 0.164789; batch adversarial loss: 0.394595\n",
      "epoch 53; iter: 0; batch classifier loss: 0.196385; batch adversarial loss: 0.408581\n",
      "epoch 54; iter: 0; batch classifier loss: 0.124094; batch adversarial loss: 0.490897\n",
      "epoch 55; iter: 0; batch classifier loss: 0.126605; batch adversarial loss: 0.383996\n",
      "epoch 56; iter: 0; batch classifier loss: 0.153391; batch adversarial loss: 0.430695\n",
      "epoch 57; iter: 0; batch classifier loss: 0.102357; batch adversarial loss: 0.438964\n",
      "epoch 58; iter: 0; batch classifier loss: 0.125444; batch adversarial loss: 0.405077\n",
      "epoch 59; iter: 0; batch classifier loss: 0.105969; batch adversarial loss: 0.399186\n",
      "epoch 60; iter: 0; batch classifier loss: 0.112049; batch adversarial loss: 0.423626\n",
      "epoch 61; iter: 0; batch classifier loss: 0.104284; batch adversarial loss: 0.418303\n",
      "epoch 62; iter: 0; batch classifier loss: 0.089905; batch adversarial loss: 0.399789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.158311; batch adversarial loss: 0.426829\n",
      "epoch 64; iter: 0; batch classifier loss: 0.110895; batch adversarial loss: 0.418233\n",
      "epoch 65; iter: 0; batch classifier loss: 0.068639; batch adversarial loss: 0.406988\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109096; batch adversarial loss: 0.274391\n",
      "epoch 67; iter: 0; batch classifier loss: 0.134977; batch adversarial loss: 0.385179\n",
      "epoch 68; iter: 0; batch classifier loss: 0.122793; batch adversarial loss: 0.432091\n",
      "epoch 69; iter: 0; batch classifier loss: 0.071023; batch adversarial loss: 0.342146\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073992; batch adversarial loss: 0.378864\n",
      "epoch 71; iter: 0; batch classifier loss: 0.082762; batch adversarial loss: 0.451684\n",
      "epoch 72; iter: 0; batch classifier loss: 0.074779; batch adversarial loss: 0.349339\n",
      "epoch 73; iter: 0; batch classifier loss: 0.074620; batch adversarial loss: 0.306681\n",
      "epoch 74; iter: 0; batch classifier loss: 0.097208; batch adversarial loss: 0.427352\n",
      "epoch 75; iter: 0; batch classifier loss: 0.070962; batch adversarial loss: 0.428448\n",
      "epoch 76; iter: 0; batch classifier loss: 0.073991; batch adversarial loss: 0.261479\n",
      "epoch 77; iter: 0; batch classifier loss: 0.067886; batch adversarial loss: 0.364375\n",
      "epoch 78; iter: 0; batch classifier loss: 0.106860; batch adversarial loss: 0.387294\n",
      "epoch 79; iter: 0; batch classifier loss: 0.102350; batch adversarial loss: 0.489632\n",
      "epoch 80; iter: 0; batch classifier loss: 0.090765; batch adversarial loss: 0.401454\n",
      "epoch 81; iter: 0; batch classifier loss: 0.049765; batch adversarial loss: 0.417431\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074967; batch adversarial loss: 0.407683\n",
      "epoch 83; iter: 0; batch classifier loss: 0.072440; batch adversarial loss: 0.407817\n",
      "epoch 84; iter: 0; batch classifier loss: 0.082339; batch adversarial loss: 0.367868\n",
      "epoch 85; iter: 0; batch classifier loss: 0.058642; batch adversarial loss: 0.318928\n",
      "epoch 86; iter: 0; batch classifier loss: 0.069243; batch adversarial loss: 0.476780\n",
      "epoch 87; iter: 0; batch classifier loss: 0.100046; batch adversarial loss: 0.402654\n",
      "epoch 88; iter: 0; batch classifier loss: 0.045718; batch adversarial loss: 0.448726\n",
      "epoch 89; iter: 0; batch classifier loss: 0.050115; batch adversarial loss: 0.393827\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106704; batch adversarial loss: 0.415412\n",
      "epoch 91; iter: 0; batch classifier loss: 0.049266; batch adversarial loss: 0.370702\n",
      "epoch 92; iter: 0; batch classifier loss: 0.101958; batch adversarial loss: 0.403148\n",
      "epoch 93; iter: 0; batch classifier loss: 0.080022; batch adversarial loss: 0.483498\n",
      "epoch 94; iter: 0; batch classifier loss: 0.088037; batch adversarial loss: 0.354321\n",
      "epoch 95; iter: 0; batch classifier loss: 0.079239; batch adversarial loss: 0.390978\n",
      "epoch 96; iter: 0; batch classifier loss: 0.042180; batch adversarial loss: 0.357156\n",
      "epoch 97; iter: 0; batch classifier loss: 0.052758; batch adversarial loss: 0.473474\n",
      "epoch 98; iter: 0; batch classifier loss: 0.062322; batch adversarial loss: 0.448055\n",
      "epoch 99; iter: 0; batch classifier loss: 0.061847; batch adversarial loss: 0.415323\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057782; batch adversarial loss: 0.380373\n",
      "epoch 101; iter: 0; batch classifier loss: 0.070371; batch adversarial loss: 0.402586\n",
      "epoch 102; iter: 0; batch classifier loss: 0.059826; batch adversarial loss: 0.296270\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051407; batch adversarial loss: 0.419782\n",
      "epoch 104; iter: 0; batch classifier loss: 0.063831; batch adversarial loss: 0.394293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075788; batch adversarial loss: 0.427540\n",
      "epoch 106; iter: 0; batch classifier loss: 0.067281; batch adversarial loss: 0.430341\n",
      "epoch 107; iter: 0; batch classifier loss: 0.063944; batch adversarial loss: 0.469639\n",
      "epoch 108; iter: 0; batch classifier loss: 0.059286; batch adversarial loss: 0.411760\n",
      "epoch 109; iter: 0; batch classifier loss: 0.081017; batch adversarial loss: 0.380188\n",
      "epoch 110; iter: 0; batch classifier loss: 0.107363; batch adversarial loss: 0.452901\n",
      "epoch 111; iter: 0; batch classifier loss: 0.057265; batch adversarial loss: 0.466148\n",
      "epoch 112; iter: 0; batch classifier loss: 0.059430; batch adversarial loss: 0.381280\n",
      "epoch 113; iter: 0; batch classifier loss: 0.049094; batch adversarial loss: 0.409514\n",
      "epoch 114; iter: 0; batch classifier loss: 0.064876; batch adversarial loss: 0.384004\n",
      "epoch 115; iter: 0; batch classifier loss: 0.062182; batch adversarial loss: 0.467173\n",
      "epoch 116; iter: 0; batch classifier loss: 0.053125; batch adversarial loss: 0.444692\n",
      "epoch 117; iter: 0; batch classifier loss: 0.069336; batch adversarial loss: 0.424307\n",
      "epoch 118; iter: 0; batch classifier loss: 0.061733; batch adversarial loss: 0.438226\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056211; batch adversarial loss: 0.453987\n",
      "epoch 120; iter: 0; batch classifier loss: 0.106535; batch adversarial loss: 0.401834\n",
      "epoch 121; iter: 0; batch classifier loss: 0.045489; batch adversarial loss: 0.361168\n",
      "epoch 122; iter: 0; batch classifier loss: 0.085271; batch adversarial loss: 0.402495\n",
      "epoch 123; iter: 0; batch classifier loss: 0.086209; batch adversarial loss: 0.462493\n",
      "epoch 124; iter: 0; batch classifier loss: 0.078700; batch adversarial loss: 0.451658\n",
      "epoch 125; iter: 0; batch classifier loss: 0.073990; batch adversarial loss: 0.452284\n",
      "epoch 126; iter: 0; batch classifier loss: 0.050013; batch adversarial loss: 0.365148\n",
      "epoch 127; iter: 0; batch classifier loss: 0.063766; batch adversarial loss: 0.412000\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044219; batch adversarial loss: 0.407155\n",
      "epoch 129; iter: 0; batch classifier loss: 0.038996; batch adversarial loss: 0.484431\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073188; batch adversarial loss: 0.464224\n",
      "epoch 131; iter: 0; batch classifier loss: 0.073312; batch adversarial loss: 0.403764\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046914; batch adversarial loss: 0.361231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 133; iter: 0; batch classifier loss: 0.055444; batch adversarial loss: 0.332544\n",
      "epoch 134; iter: 0; batch classifier loss: 0.048039; batch adversarial loss: 0.444093\n",
      "epoch 135; iter: 0; batch classifier loss: 0.063265; batch adversarial loss: 0.371193\n",
      "epoch 136; iter: 0; batch classifier loss: 0.066591; batch adversarial loss: 0.328861\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066039; batch adversarial loss: 0.313485\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057470; batch adversarial loss: 0.456320\n",
      "epoch 139; iter: 0; batch classifier loss: 0.049679; batch adversarial loss: 0.496671\n",
      "epoch 140; iter: 0; batch classifier loss: 0.045014; batch adversarial loss: 0.382547\n",
      "epoch 141; iter: 0; batch classifier loss: 0.043853; batch adversarial loss: 0.421593\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037368; batch adversarial loss: 0.364409\n",
      "epoch 143; iter: 0; batch classifier loss: 0.049928; batch adversarial loss: 0.403854\n",
      "epoch 144; iter: 0; batch classifier loss: 0.039267; batch adversarial loss: 0.411022\n",
      "epoch 145; iter: 0; batch classifier loss: 0.041763; batch adversarial loss: 0.385345\n",
      "epoch 146; iter: 0; batch classifier loss: 0.054589; batch adversarial loss: 0.421866\n",
      "epoch 147; iter: 0; batch classifier loss: 0.083351; batch adversarial loss: 0.392781\n",
      "epoch 148; iter: 0; batch classifier loss: 0.043436; batch adversarial loss: 0.369640\n",
      "epoch 149; iter: 0; batch classifier loss: 0.040922; batch adversarial loss: 0.487011\n",
      "epoch 150; iter: 0; batch classifier loss: 0.054620; batch adversarial loss: 0.458503\n",
      "epoch 151; iter: 0; batch classifier loss: 0.086841; batch adversarial loss: 0.491960\n",
      "epoch 152; iter: 0; batch classifier loss: 0.034288; batch adversarial loss: 0.388508\n",
      "epoch 153; iter: 0; batch classifier loss: 0.042173; batch adversarial loss: 0.349985\n",
      "epoch 154; iter: 0; batch classifier loss: 0.056672; batch adversarial loss: 0.392596\n",
      "epoch 155; iter: 0; batch classifier loss: 0.033983; batch adversarial loss: 0.420210\n",
      "epoch 156; iter: 0; batch classifier loss: 0.050974; batch adversarial loss: 0.387601\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032259; batch adversarial loss: 0.525120\n",
      "epoch 158; iter: 0; batch classifier loss: 0.042800; batch adversarial loss: 0.493435\n",
      "epoch 159; iter: 0; batch classifier loss: 0.050367; batch adversarial loss: 0.360687\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031320; batch adversarial loss: 0.384325\n",
      "epoch 161; iter: 0; batch classifier loss: 0.029982; batch adversarial loss: 0.520962\n",
      "epoch 162; iter: 0; batch classifier loss: 0.051333; batch adversarial loss: 0.446550\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017717; batch adversarial loss: 0.477157\n",
      "epoch 164; iter: 0; batch classifier loss: 0.030110; batch adversarial loss: 0.391431\n",
      "epoch 165; iter: 0; batch classifier loss: 0.039917; batch adversarial loss: 0.443249\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013746; batch adversarial loss: 0.348327\n",
      "epoch 167; iter: 0; batch classifier loss: 0.042396; batch adversarial loss: 0.511056\n",
      "epoch 168; iter: 0; batch classifier loss: 0.030414; batch adversarial loss: 0.423275\n",
      "epoch 169; iter: 0; batch classifier loss: 0.040911; batch adversarial loss: 0.421525\n",
      "epoch 170; iter: 0; batch classifier loss: 0.015222; batch adversarial loss: 0.529483\n",
      "epoch 171; iter: 0; batch classifier loss: 0.036759; batch adversarial loss: 0.426862\n",
      "epoch 172; iter: 0; batch classifier loss: 0.020436; batch adversarial loss: 0.449167\n",
      "epoch 173; iter: 0; batch classifier loss: 0.039001; batch adversarial loss: 0.418297\n",
      "epoch 174; iter: 0; batch classifier loss: 0.027260; batch adversarial loss: 0.464981\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025310; batch adversarial loss: 0.367688\n",
      "epoch 176; iter: 0; batch classifier loss: 0.022459; batch adversarial loss: 0.387523\n",
      "epoch 177; iter: 0; batch classifier loss: 0.020040; batch adversarial loss: 0.552680\n",
      "epoch 178; iter: 0; batch classifier loss: 0.026709; batch adversarial loss: 0.517622\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019721; batch adversarial loss: 0.415149\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025586; batch adversarial loss: 0.479934\n",
      "epoch 181; iter: 0; batch classifier loss: 0.100605; batch adversarial loss: 0.438349\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027096; batch adversarial loss: 0.410322\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015140; batch adversarial loss: 0.456937\n",
      "epoch 184; iter: 0; batch classifier loss: 0.035589; batch adversarial loss: 0.446003\n",
      "epoch 185; iter: 0; batch classifier loss: 0.034806; batch adversarial loss: 0.502782\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041921; batch adversarial loss: 0.462442\n",
      "epoch 187; iter: 0; batch classifier loss: 0.091474; batch adversarial loss: 0.519598\n",
      "epoch 188; iter: 0; batch classifier loss: 0.062453; batch adversarial loss: 0.479087\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060978; batch adversarial loss: 0.532431\n",
      "epoch 190; iter: 0; batch classifier loss: 0.075029; batch adversarial loss: 0.577695\n",
      "epoch 191; iter: 0; batch classifier loss: 0.027785; batch adversarial loss: 0.350859\n",
      "epoch 192; iter: 0; batch classifier loss: 0.106797; batch adversarial loss: 0.642351\n",
      "epoch 193; iter: 0; batch classifier loss: 0.065907; batch adversarial loss: 0.575076\n",
      "epoch 194; iter: 0; batch classifier loss: 0.112010; batch adversarial loss: 0.542832\n",
      "epoch 195; iter: 0; batch classifier loss: 0.070263; batch adversarial loss: 0.614149\n",
      "epoch 196; iter: 0; batch classifier loss: 0.152693; batch adversarial loss: 0.689419\n",
      "epoch 197; iter: 0; batch classifier loss: 0.153751; batch adversarial loss: 0.742810\n",
      "epoch 198; iter: 0; batch classifier loss: 0.156347; batch adversarial loss: 0.680825\n",
      "epoch 199; iter: 0; batch classifier loss: 0.126841; batch adversarial loss: 0.502789\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705276; batch adversarial loss: 0.823090\n",
      "epoch 1; iter: 0; batch classifier loss: 0.478874; batch adversarial loss: 0.863485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.683578; batch adversarial loss: 0.828304\n",
      "epoch 3; iter: 0; batch classifier loss: 0.824545; batch adversarial loss: 0.770866\n",
      "epoch 4; iter: 0; batch classifier loss: 0.819286; batch adversarial loss: 0.679219\n",
      "epoch 5; iter: 0; batch classifier loss: 0.759724; batch adversarial loss: 0.632854\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565655; batch adversarial loss: 0.568435\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463265; batch adversarial loss: 0.532286\n",
      "epoch 8; iter: 0; batch classifier loss: 0.271524; batch adversarial loss: 0.574023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.410594; batch adversarial loss: 0.526488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298153; batch adversarial loss: 0.573475\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346774; batch adversarial loss: 0.523637\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373232; batch adversarial loss: 0.499087\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277104; batch adversarial loss: 0.575725\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318702; batch adversarial loss: 0.487760\n",
      "epoch 15; iter: 0; batch classifier loss: 0.332840; batch adversarial loss: 0.493143\n",
      "epoch 16; iter: 0; batch classifier loss: 0.412125; batch adversarial loss: 0.456228\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346449; batch adversarial loss: 0.519389\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299766; batch adversarial loss: 0.520496\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458280; batch adversarial loss: 0.441759\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313238; batch adversarial loss: 0.456071\n",
      "epoch 21; iter: 0; batch classifier loss: 0.351233; batch adversarial loss: 0.489859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.409040; batch adversarial loss: 0.452590\n",
      "epoch 23; iter: 0; batch classifier loss: 0.298436; batch adversarial loss: 0.515994\n",
      "epoch 24; iter: 0; batch classifier loss: 0.241118; batch adversarial loss: 0.440706\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310969; batch adversarial loss: 0.482037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.341046; batch adversarial loss: 0.406982\n",
      "epoch 27; iter: 0; batch classifier loss: 0.249598; batch adversarial loss: 0.439302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.270923; batch adversarial loss: 0.483484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.369811; batch adversarial loss: 0.455017\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264343; batch adversarial loss: 0.533617\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283282; batch adversarial loss: 0.487064\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238221; batch adversarial loss: 0.481170\n",
      "epoch 33; iter: 0; batch classifier loss: 0.225546; batch adversarial loss: 0.507702\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312418; batch adversarial loss: 0.410138\n",
      "epoch 35; iter: 0; batch classifier loss: 0.234527; batch adversarial loss: 0.408285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282759; batch adversarial loss: 0.450223\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277554; batch adversarial loss: 0.388628\n",
      "epoch 38; iter: 0; batch classifier loss: 0.290316; batch adversarial loss: 0.406589\n",
      "epoch 39; iter: 0; batch classifier loss: 0.206129; batch adversarial loss: 0.466045\n",
      "epoch 40; iter: 0; batch classifier loss: 0.278792; batch adversarial loss: 0.437142\n",
      "epoch 41; iter: 0; batch classifier loss: 0.245565; batch adversarial loss: 0.421313\n",
      "epoch 42; iter: 0; batch classifier loss: 0.241426; batch adversarial loss: 0.423824\n",
      "epoch 43; iter: 0; batch classifier loss: 0.244941; batch adversarial loss: 0.454729\n",
      "epoch 44; iter: 0; batch classifier loss: 0.254747; batch adversarial loss: 0.471702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.229506; batch adversarial loss: 0.506985\n",
      "epoch 46; iter: 0; batch classifier loss: 0.259845; batch adversarial loss: 0.405156\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215507; batch adversarial loss: 0.426332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.221643; batch adversarial loss: 0.426621\n",
      "epoch 49; iter: 0; batch classifier loss: 0.173005; batch adversarial loss: 0.446920\n",
      "epoch 50; iter: 0; batch classifier loss: 0.180853; batch adversarial loss: 0.418758\n",
      "epoch 51; iter: 0; batch classifier loss: 0.191382; batch adversarial loss: 0.396685\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198610; batch adversarial loss: 0.412555\n",
      "epoch 53; iter: 0; batch classifier loss: 0.132149; batch adversarial loss: 0.445460\n",
      "epoch 54; iter: 0; batch classifier loss: 0.208368; batch adversarial loss: 0.463635\n",
      "epoch 55; iter: 0; batch classifier loss: 0.213480; batch adversarial loss: 0.423831\n",
      "epoch 56; iter: 0; batch classifier loss: 0.213289; batch adversarial loss: 0.509415\n",
      "epoch 57; iter: 0; batch classifier loss: 0.234521; batch adversarial loss: 0.419863\n",
      "epoch 58; iter: 0; batch classifier loss: 0.194101; batch adversarial loss: 0.436151\n",
      "epoch 59; iter: 0; batch classifier loss: 0.267976; batch adversarial loss: 0.447330\n",
      "epoch 60; iter: 0; batch classifier loss: 0.162158; batch adversarial loss: 0.395071\n",
      "epoch 61; iter: 0; batch classifier loss: 0.267445; batch adversarial loss: 0.356153\n",
      "epoch 62; iter: 0; batch classifier loss: 0.189820; batch adversarial loss: 0.408315\n",
      "epoch 63; iter: 0; batch classifier loss: 0.186075; batch adversarial loss: 0.433347\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189741; batch adversarial loss: 0.434346\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205718; batch adversarial loss: 0.433603\n",
      "epoch 66; iter: 0; batch classifier loss: 0.208985; batch adversarial loss: 0.368934\n",
      "epoch 67; iter: 0; batch classifier loss: 0.280458; batch adversarial loss: 0.434000\n",
      "epoch 68; iter: 0; batch classifier loss: 0.158799; batch adversarial loss: 0.472517\n",
      "epoch 69; iter: 0; batch classifier loss: 0.279533; batch adversarial loss: 0.485371\n",
      "epoch 70; iter: 0; batch classifier loss: 0.122434; batch adversarial loss: 0.510709\n",
      "epoch 71; iter: 0; batch classifier loss: 0.178289; batch adversarial loss: 0.472342\n",
      "epoch 72; iter: 0; batch classifier loss: 0.090381; batch adversarial loss: 0.381900\n",
      "epoch 73; iter: 0; batch classifier loss: 0.198756; batch adversarial loss: 0.523980\n",
      "epoch 74; iter: 0; batch classifier loss: 0.260446; batch adversarial loss: 0.459279\n",
      "epoch 75; iter: 0; batch classifier loss: 0.141654; batch adversarial loss: 0.589816\n",
      "epoch 76; iter: 0; batch classifier loss: 0.148853; batch adversarial loss: 0.445441\n",
      "epoch 77; iter: 0; batch classifier loss: 0.129612; batch adversarial loss: 0.485578\n",
      "epoch 78; iter: 0; batch classifier loss: 0.236201; batch adversarial loss: 0.408187\n",
      "epoch 79; iter: 0; batch classifier loss: 0.244348; batch adversarial loss: 0.473056\n",
      "epoch 80; iter: 0; batch classifier loss: 0.180367; batch adversarial loss: 0.523380\n",
      "epoch 81; iter: 0; batch classifier loss: 0.162834; batch adversarial loss: 0.434034\n",
      "epoch 82; iter: 0; batch classifier loss: 0.237082; batch adversarial loss: 0.368680\n",
      "epoch 83; iter: 0; batch classifier loss: 0.199520; batch adversarial loss: 0.381303\n",
      "epoch 84; iter: 0; batch classifier loss: 0.185759; batch adversarial loss: 0.433503\n",
      "epoch 85; iter: 0; batch classifier loss: 0.219285; batch adversarial loss: 0.472595\n",
      "epoch 86; iter: 0; batch classifier loss: 0.107378; batch adversarial loss: 0.446408\n",
      "epoch 87; iter: 0; batch classifier loss: 0.074123; batch adversarial loss: 0.430009\n",
      "epoch 88; iter: 0; batch classifier loss: 0.096015; batch adversarial loss: 0.421073\n",
      "epoch 89; iter: 0; batch classifier loss: 0.121999; batch adversarial loss: 0.495707\n",
      "epoch 90; iter: 0; batch classifier loss: 0.154152; batch adversarial loss: 0.480193\n",
      "epoch 91; iter: 0; batch classifier loss: 0.160921; batch adversarial loss: 0.549521\n",
      "epoch 92; iter: 0; batch classifier loss: 0.142620; batch adversarial loss: 0.573094\n",
      "epoch 93; iter: 0; batch classifier loss: 0.103160; batch adversarial loss: 0.409305\n",
      "epoch 94; iter: 0; batch classifier loss: 0.100829; batch adversarial loss: 0.441975\n",
      "epoch 95; iter: 0; batch classifier loss: 0.116929; batch adversarial loss: 0.497018\n",
      "epoch 96; iter: 0; batch classifier loss: 0.093069; batch adversarial loss: 0.447606\n",
      "epoch 97; iter: 0; batch classifier loss: 0.079099; batch adversarial loss: 0.443424\n",
      "epoch 98; iter: 0; batch classifier loss: 0.087879; batch adversarial loss: 0.474693\n",
      "epoch 99; iter: 0; batch classifier loss: 0.077415; batch adversarial loss: 0.447989\n",
      "epoch 100; iter: 0; batch classifier loss: 0.095575; batch adversarial loss: 0.398447\n",
      "epoch 101; iter: 0; batch classifier loss: 0.066816; batch adversarial loss: 0.390207\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069468; batch adversarial loss: 0.431253\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084641; batch adversarial loss: 0.562878\n",
      "epoch 104; iter: 0; batch classifier loss: 0.095739; batch adversarial loss: 0.383785\n",
      "epoch 105; iter: 0; batch classifier loss: 0.041821; batch adversarial loss: 0.452836\n",
      "epoch 106; iter: 0; batch classifier loss: 0.042416; batch adversarial loss: 0.452939\n",
      "epoch 107; iter: 0; batch classifier loss: 0.103258; batch adversarial loss: 0.375992\n",
      "epoch 108; iter: 0; batch classifier loss: 0.071648; batch adversarial loss: 0.380607\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041494; batch adversarial loss: 0.438568\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059693; batch adversarial loss: 0.412253\n",
      "epoch 111; iter: 0; batch classifier loss: 0.040490; batch adversarial loss: 0.499879\n",
      "epoch 112; iter: 0; batch classifier loss: 0.045816; batch adversarial loss: 0.451043\n",
      "epoch 113; iter: 0; batch classifier loss: 0.041696; batch adversarial loss: 0.442495\n",
      "epoch 114; iter: 0; batch classifier loss: 0.062292; batch adversarial loss: 0.439204\n",
      "epoch 115; iter: 0; batch classifier loss: 0.034459; batch adversarial loss: 0.464016\n",
      "epoch 116; iter: 0; batch classifier loss: 0.054323; batch adversarial loss: 0.465153\n",
      "epoch 117; iter: 0; batch classifier loss: 0.024504; batch adversarial loss: 0.451967\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054321; batch adversarial loss: 0.564191\n",
      "epoch 119; iter: 0; batch classifier loss: 0.029196; batch adversarial loss: 0.404510\n",
      "epoch 120; iter: 0; batch classifier loss: 0.046986; batch adversarial loss: 0.471417\n",
      "epoch 121; iter: 0; batch classifier loss: 0.012928; batch adversarial loss: 0.488141\n",
      "epoch 122; iter: 0; batch classifier loss: 0.017656; batch adversarial loss: 0.405362\n",
      "epoch 123; iter: 0; batch classifier loss: 0.047423; batch adversarial loss: 0.397378\n",
      "epoch 124; iter: 0; batch classifier loss: 0.052173; batch adversarial loss: 0.350865\n",
      "epoch 125; iter: 0; batch classifier loss: 0.060124; batch adversarial loss: 0.396180\n",
      "epoch 126; iter: 0; batch classifier loss: 0.062458; batch adversarial loss: 0.442114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127; iter: 0; batch classifier loss: 0.047951; batch adversarial loss: 0.373904\n",
      "epoch 128; iter: 0; batch classifier loss: 0.025850; batch adversarial loss: 0.442597\n",
      "epoch 129; iter: 0; batch classifier loss: 0.028687; batch adversarial loss: 0.402696\n",
      "epoch 130; iter: 0; batch classifier loss: 0.060022; batch adversarial loss: 0.384413\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032600; batch adversarial loss: 0.468909\n",
      "epoch 132; iter: 0; batch classifier loss: 0.048711; batch adversarial loss: 0.557362\n",
      "epoch 133; iter: 0; batch classifier loss: 0.058700; batch adversarial loss: 0.383162\n",
      "epoch 134; iter: 0; batch classifier loss: 0.031742; batch adversarial loss: 0.385288\n",
      "epoch 135; iter: 0; batch classifier loss: 0.029798; batch adversarial loss: 0.440138\n",
      "epoch 136; iter: 0; batch classifier loss: 0.040473; batch adversarial loss: 0.376490\n",
      "epoch 137; iter: 0; batch classifier loss: 0.023296; batch adversarial loss: 0.539807\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026291; batch adversarial loss: 0.370999\n",
      "epoch 139; iter: 0; batch classifier loss: 0.018108; batch adversarial loss: 0.343126\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027562; batch adversarial loss: 0.385822\n",
      "epoch 141; iter: 0; batch classifier loss: 0.016158; batch adversarial loss: 0.366892\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036941; batch adversarial loss: 0.371655\n",
      "epoch 143; iter: 0; batch classifier loss: 0.028213; batch adversarial loss: 0.442176\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016107; batch adversarial loss: 0.440707\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043500; batch adversarial loss: 0.429629\n",
      "epoch 146; iter: 0; batch classifier loss: 0.027136; batch adversarial loss: 0.450669\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018243; batch adversarial loss: 0.502522\n",
      "epoch 148; iter: 0; batch classifier loss: 0.028313; batch adversarial loss: 0.460840\n",
      "epoch 149; iter: 0; batch classifier loss: 0.026183; batch adversarial loss: 0.492710\n",
      "epoch 150; iter: 0; batch classifier loss: 0.015564; batch adversarial loss: 0.421448\n",
      "epoch 151; iter: 0; batch classifier loss: 0.018302; batch adversarial loss: 0.395042\n",
      "epoch 152; iter: 0; batch classifier loss: 0.024198; batch adversarial loss: 0.452858\n",
      "epoch 153; iter: 0; batch classifier loss: 0.006899; batch adversarial loss: 0.426628\n",
      "epoch 154; iter: 0; batch classifier loss: 0.006667; batch adversarial loss: 0.476340\n",
      "epoch 155; iter: 0; batch classifier loss: 0.034727; batch adversarial loss: 0.403835\n",
      "epoch 156; iter: 0; batch classifier loss: 0.034559; batch adversarial loss: 0.460032\n",
      "epoch 157; iter: 0; batch classifier loss: 0.015656; batch adversarial loss: 0.449339\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045417; batch adversarial loss: 0.430380\n",
      "epoch 159; iter: 0; batch classifier loss: 0.047844; batch adversarial loss: 0.348970\n",
      "epoch 160; iter: 0; batch classifier loss: 0.019052; batch adversarial loss: 0.376244\n",
      "epoch 161; iter: 0; batch classifier loss: 0.031529; batch adversarial loss: 0.360889\n",
      "epoch 162; iter: 0; batch classifier loss: 0.036888; batch adversarial loss: 0.379658\n",
      "epoch 163; iter: 0; batch classifier loss: 0.011752; batch adversarial loss: 0.364707\n",
      "epoch 164; iter: 0; batch classifier loss: 0.012816; batch adversarial loss: 0.608227\n",
      "epoch 165; iter: 0; batch classifier loss: 0.013622; batch adversarial loss: 0.480397\n",
      "epoch 166; iter: 0; batch classifier loss: 0.014565; batch adversarial loss: 0.437269\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025047; batch adversarial loss: 0.494182\n",
      "epoch 168; iter: 0; batch classifier loss: 0.028492; batch adversarial loss: 0.426682\n",
      "epoch 169; iter: 0; batch classifier loss: 0.018507; batch adversarial loss: 0.444599\n",
      "epoch 170; iter: 0; batch classifier loss: 0.019596; batch adversarial loss: 0.393942\n",
      "epoch 171; iter: 0; batch classifier loss: 0.005690; batch adversarial loss: 0.354773\n",
      "epoch 172; iter: 0; batch classifier loss: 0.024185; batch adversarial loss: 0.392497\n",
      "epoch 173; iter: 0; batch classifier loss: 0.018129; batch adversarial loss: 0.442754\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007987; batch adversarial loss: 0.396007\n",
      "epoch 175; iter: 0; batch classifier loss: 0.045003; batch adversarial loss: 0.476135\n",
      "epoch 176; iter: 0; batch classifier loss: 0.010192; batch adversarial loss: 0.402330\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010151; batch adversarial loss: 0.515769\n",
      "epoch 178; iter: 0; batch classifier loss: 0.034729; batch adversarial loss: 0.372597\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011963; batch adversarial loss: 0.494294\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032773; batch adversarial loss: 0.411476\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017108; batch adversarial loss: 0.455198\n",
      "epoch 182; iter: 0; batch classifier loss: 0.013139; batch adversarial loss: 0.492102\n",
      "epoch 183; iter: 0; batch classifier loss: 0.010265; batch adversarial loss: 0.373748\n",
      "epoch 184; iter: 0; batch classifier loss: 0.019955; batch adversarial loss: 0.393109\n",
      "epoch 185; iter: 0; batch classifier loss: 0.002281; batch adversarial loss: 0.448403\n",
      "epoch 186; iter: 0; batch classifier loss: 0.007819; batch adversarial loss: 0.513985\n",
      "epoch 187; iter: 0; batch classifier loss: 0.008295; batch adversarial loss: 0.523279\n",
      "epoch 188; iter: 0; batch classifier loss: 0.012461; batch adversarial loss: 0.537399\n",
      "epoch 189; iter: 0; batch classifier loss: 0.013855; batch adversarial loss: 0.381175\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020346; batch adversarial loss: 0.497277\n",
      "epoch 191; iter: 0; batch classifier loss: 0.021498; batch adversarial loss: 0.424137\n",
      "epoch 192; iter: 0; batch classifier loss: 0.003468; batch adversarial loss: 0.462055\n",
      "epoch 193; iter: 0; batch classifier loss: 0.019757; batch adversarial loss: 0.452122\n",
      "epoch 194; iter: 0; batch classifier loss: 0.004752; batch adversarial loss: 0.431723\n",
      "epoch 195; iter: 0; batch classifier loss: 0.009491; batch adversarial loss: 0.460821\n",
      "epoch 196; iter: 0; batch classifier loss: 0.015328; batch adversarial loss: 0.453338\n",
      "epoch 197; iter: 0; batch classifier loss: 0.022519; batch adversarial loss: 0.417459\n",
      "epoch 198; iter: 0; batch classifier loss: 0.020293; batch adversarial loss: 0.392287\n",
      "epoch 199; iter: 0; batch classifier loss: 0.019223; batch adversarial loss: 0.480188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689202; batch adversarial loss: 0.609805\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423635; batch adversarial loss: 0.627659\n",
      "epoch 2; iter: 0; batch classifier loss: 0.469532; batch adversarial loss: 0.649785\n",
      "epoch 3; iter: 0; batch classifier loss: 0.404852; batch adversarial loss: 0.554114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.428571; batch adversarial loss: 0.632414\n",
      "epoch 5; iter: 0; batch classifier loss: 0.486556; batch adversarial loss: 0.534559\n",
      "epoch 6; iter: 0; batch classifier loss: 0.455855; batch adversarial loss: 0.668587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503813; batch adversarial loss: 0.593059\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516792; batch adversarial loss: 0.567200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458097; batch adversarial loss: 0.553662\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408831; batch adversarial loss: 0.581792\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331341; batch adversarial loss: 0.497177\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372722; batch adversarial loss: 0.514829\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299178; batch adversarial loss: 0.513690\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283233; batch adversarial loss: 0.523288\n",
      "epoch 15; iter: 0; batch classifier loss: 0.226499; batch adversarial loss: 0.464350\n",
      "epoch 16; iter: 0; batch classifier loss: 0.195635; batch adversarial loss: 0.514838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269575; batch adversarial loss: 0.511873\n",
      "epoch 18; iter: 0; batch classifier loss: 0.243832; batch adversarial loss: 0.460621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.186858; batch adversarial loss: 0.524090\n",
      "epoch 20; iter: 0; batch classifier loss: 0.189435; batch adversarial loss: 0.426093\n",
      "epoch 21; iter: 0; batch classifier loss: 0.242742; batch adversarial loss: 0.433943\n",
      "epoch 22; iter: 0; batch classifier loss: 0.175044; batch adversarial loss: 0.426802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 0; batch classifier loss: 0.173574; batch adversarial loss: 0.503198\n",
      "epoch 24; iter: 0; batch classifier loss: 0.147537; batch adversarial loss: 0.450617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.200947; batch adversarial loss: 0.515885\n",
      "epoch 26; iter: 0; batch classifier loss: 0.213165; batch adversarial loss: 0.457740\n",
      "epoch 27; iter: 0; batch classifier loss: 0.094529; batch adversarial loss: 0.480198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.168689; batch adversarial loss: 0.432395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.189425; batch adversarial loss: 0.440614\n",
      "epoch 30; iter: 0; batch classifier loss: 0.128424; batch adversarial loss: 0.409668\n",
      "epoch 31; iter: 0; batch classifier loss: 0.083253; batch adversarial loss: 0.419639\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102620; batch adversarial loss: 0.453887\n",
      "epoch 33; iter: 0; batch classifier loss: 0.148363; batch adversarial loss: 0.352701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.102210; batch adversarial loss: 0.471541\n",
      "epoch 35; iter: 0; batch classifier loss: 0.100246; batch adversarial loss: 0.594152\n",
      "epoch 36; iter: 0; batch classifier loss: 0.117774; batch adversarial loss: 0.437392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.119103; batch adversarial loss: 0.501933\n",
      "epoch 38; iter: 0; batch classifier loss: 0.148504; batch adversarial loss: 0.433965\n",
      "epoch 39; iter: 0; batch classifier loss: 0.088210; batch adversarial loss: 0.455073\n",
      "epoch 40; iter: 0; batch classifier loss: 0.122758; batch adversarial loss: 0.471378\n",
      "epoch 41; iter: 0; batch classifier loss: 0.087790; batch adversarial loss: 0.417643\n",
      "epoch 42; iter: 0; batch classifier loss: 0.100025; batch adversarial loss: 0.418989\n",
      "epoch 43; iter: 0; batch classifier loss: 0.142726; batch adversarial loss: 0.541950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.106576; batch adversarial loss: 0.459553\n",
      "epoch 45; iter: 0; batch classifier loss: 0.094675; batch adversarial loss: 0.514361\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103668; batch adversarial loss: 0.340354\n",
      "epoch 47; iter: 0; batch classifier loss: 0.093461; batch adversarial loss: 0.501673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.080233; batch adversarial loss: 0.416786\n",
      "epoch 49; iter: 0; batch classifier loss: 0.055118; batch adversarial loss: 0.539180\n",
      "epoch 50; iter: 0; batch classifier loss: 0.178752; batch adversarial loss: 0.418018\n",
      "epoch 51; iter: 0; batch classifier loss: 0.118240; batch adversarial loss: 0.391054\n",
      "epoch 52; iter: 0; batch classifier loss: 0.099449; batch adversarial loss: 0.439542\n",
      "epoch 53; iter: 0; batch classifier loss: 0.098156; batch adversarial loss: 0.527788\n",
      "epoch 54; iter: 0; batch classifier loss: 0.116034; batch adversarial loss: 0.502678\n",
      "epoch 55; iter: 0; batch classifier loss: 0.107225; batch adversarial loss: 0.490358\n",
      "epoch 56; iter: 0; batch classifier loss: 0.102781; batch adversarial loss: 0.482178\n",
      "epoch 57; iter: 0; batch classifier loss: 0.120481; batch adversarial loss: 0.457370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.111584; batch adversarial loss: 0.424656\n",
      "epoch 59; iter: 0; batch classifier loss: 0.055839; batch adversarial loss: 0.417838\n",
      "epoch 60; iter: 0; batch classifier loss: 0.080423; batch adversarial loss: 0.510991\n",
      "epoch 61; iter: 0; batch classifier loss: 0.090644; batch adversarial loss: 0.441245\n",
      "epoch 62; iter: 0; batch classifier loss: 0.082260; batch adversarial loss: 0.482003\n",
      "epoch 63; iter: 0; batch classifier loss: 0.100602; batch adversarial loss: 0.405419\n",
      "epoch 64; iter: 0; batch classifier loss: 0.092568; batch adversarial loss: 0.350386\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072700; batch adversarial loss: 0.520373\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082789; batch adversarial loss: 0.335400\n",
      "epoch 67; iter: 0; batch classifier loss: 0.145439; batch adversarial loss: 0.522500\n",
      "epoch 68; iter: 0; batch classifier loss: 0.065235; batch adversarial loss: 0.354789\n",
      "epoch 69; iter: 0; batch classifier loss: 0.060750; batch adversarial loss: 0.473216\n",
      "epoch 70; iter: 0; batch classifier loss: 0.086169; batch adversarial loss: 0.422994\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063149; batch adversarial loss: 0.380275\n",
      "epoch 72; iter: 0; batch classifier loss: 0.111646; batch adversarial loss: 0.468103\n",
      "epoch 73; iter: 0; batch classifier loss: 0.084016; batch adversarial loss: 0.430765\n",
      "epoch 74; iter: 0; batch classifier loss: 0.066481; batch adversarial loss: 0.554800\n",
      "epoch 75; iter: 0; batch classifier loss: 0.107604; batch adversarial loss: 0.529191\n",
      "epoch 76; iter: 0; batch classifier loss: 0.088992; batch adversarial loss: 0.365896\n",
      "epoch 77; iter: 0; batch classifier loss: 0.076657; batch adversarial loss: 0.508768\n",
      "epoch 78; iter: 0; batch classifier loss: 0.073890; batch adversarial loss: 0.461787\n",
      "epoch 79; iter: 0; batch classifier loss: 0.099749; batch adversarial loss: 0.476128\n",
      "epoch 80; iter: 0; batch classifier loss: 0.133748; batch adversarial loss: 0.529320\n",
      "epoch 81; iter: 0; batch classifier loss: 0.104617; batch adversarial loss: 0.437187\n",
      "epoch 82; iter: 0; batch classifier loss: 0.054091; batch adversarial loss: 0.515700\n",
      "epoch 83; iter: 0; batch classifier loss: 0.024760; batch adversarial loss: 0.573920\n",
      "epoch 84; iter: 0; batch classifier loss: 0.097445; batch adversarial loss: 0.592258\n",
      "epoch 85; iter: 0; batch classifier loss: 0.077874; batch adversarial loss: 0.465436\n",
      "epoch 86; iter: 0; batch classifier loss: 0.111822; batch adversarial loss: 0.464961\n",
      "epoch 87; iter: 0; batch classifier loss: 0.057310; batch adversarial loss: 0.458179\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035413; batch adversarial loss: 0.485906\n",
      "epoch 89; iter: 0; batch classifier loss: 0.071946; batch adversarial loss: 0.471193\n",
      "epoch 90; iter: 0; batch classifier loss: 0.089730; batch adversarial loss: 0.424740\n",
      "epoch 91; iter: 0; batch classifier loss: 0.062836; batch adversarial loss: 0.521443\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065888; batch adversarial loss: 0.446184\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089243; batch adversarial loss: 0.508749\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077097; batch adversarial loss: 0.536763\n",
      "epoch 95; iter: 0; batch classifier loss: 0.090596; batch adversarial loss: 0.522483\n",
      "epoch 96; iter: 0; batch classifier loss: 0.047157; batch adversarial loss: 0.481815\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055067; batch adversarial loss: 0.402050\n",
      "epoch 98; iter: 0; batch classifier loss: 0.067428; batch adversarial loss: 0.509720\n",
      "epoch 99; iter: 0; batch classifier loss: 0.054813; batch adversarial loss: 0.435627\n",
      "epoch 100; iter: 0; batch classifier loss: 0.066890; batch adversarial loss: 0.435156\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031413; batch adversarial loss: 0.524664\n",
      "epoch 102; iter: 0; batch classifier loss: 0.034050; batch adversarial loss: 0.452012\n",
      "epoch 103; iter: 0; batch classifier loss: 0.022964; batch adversarial loss: 0.563053\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051029; batch adversarial loss: 0.553622\n",
      "epoch 105; iter: 0; batch classifier loss: 0.047534; batch adversarial loss: 0.442272\n",
      "epoch 106; iter: 0; batch classifier loss: 0.061024; batch adversarial loss: 0.463169\n",
      "epoch 107; iter: 0; batch classifier loss: 0.054448; batch adversarial loss: 0.489688\n",
      "epoch 108; iter: 0; batch classifier loss: 0.077416; batch adversarial loss: 0.458771\n",
      "epoch 109; iter: 0; batch classifier loss: 0.044423; batch adversarial loss: 0.463846\n",
      "epoch 110; iter: 0; batch classifier loss: 0.051259; batch adversarial loss: 0.522715\n",
      "epoch 111; iter: 0; batch classifier loss: 0.048909; batch adversarial loss: 0.451020\n",
      "epoch 112; iter: 0; batch classifier loss: 0.048578; batch adversarial loss: 0.414110\n",
      "epoch 113; iter: 0; batch classifier loss: 0.043350; batch adversarial loss: 0.458050\n",
      "epoch 114; iter: 0; batch classifier loss: 0.050315; batch adversarial loss: 0.475858\n",
      "epoch 115; iter: 0; batch classifier loss: 0.041463; batch adversarial loss: 0.415774\n",
      "epoch 116; iter: 0; batch classifier loss: 0.056126; batch adversarial loss: 0.357559\n",
      "epoch 117; iter: 0; batch classifier loss: 0.023493; batch adversarial loss: 0.405666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.054861; batch adversarial loss: 0.419694\n",
      "epoch 119; iter: 0; batch classifier loss: 0.068493; batch adversarial loss: 0.442481\n",
      "epoch 120; iter: 0; batch classifier loss: 0.013003; batch adversarial loss: 0.418164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121; iter: 0; batch classifier loss: 0.071598; batch adversarial loss: 0.463093\n",
      "epoch 122; iter: 0; batch classifier loss: 0.025135; batch adversarial loss: 0.571388\n",
      "epoch 123; iter: 0; batch classifier loss: 0.032324; batch adversarial loss: 0.384858\n",
      "epoch 124; iter: 0; batch classifier loss: 0.031685; batch adversarial loss: 0.533389\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054011; batch adversarial loss: 0.491109\n",
      "epoch 126; iter: 0; batch classifier loss: 0.024891; batch adversarial loss: 0.422997\n",
      "epoch 127; iter: 0; batch classifier loss: 0.058133; batch adversarial loss: 0.407436\n",
      "epoch 128; iter: 0; batch classifier loss: 0.052100; batch adversarial loss: 0.452160\n",
      "epoch 129; iter: 0; batch classifier loss: 0.056205; batch adversarial loss: 0.409437\n",
      "epoch 130; iter: 0; batch classifier loss: 0.022138; batch adversarial loss: 0.485764\n",
      "epoch 131; iter: 0; batch classifier loss: 0.032934; batch adversarial loss: 0.511466\n",
      "epoch 132; iter: 0; batch classifier loss: 0.036251; batch adversarial loss: 0.425579\n",
      "epoch 133; iter: 0; batch classifier loss: 0.060512; batch adversarial loss: 0.427496\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037109; batch adversarial loss: 0.453734\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020235; batch adversarial loss: 0.549154\n",
      "epoch 136; iter: 0; batch classifier loss: 0.049945; batch adversarial loss: 0.484955\n",
      "epoch 137; iter: 0; batch classifier loss: 0.031116; batch adversarial loss: 0.473313\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036436; batch adversarial loss: 0.457469\n",
      "epoch 139; iter: 0; batch classifier loss: 0.057163; batch adversarial loss: 0.458727\n",
      "epoch 140; iter: 0; batch classifier loss: 0.054805; batch adversarial loss: 0.440497\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036568; batch adversarial loss: 0.468292\n",
      "epoch 142; iter: 0; batch classifier loss: 0.055446; batch adversarial loss: 0.487001\n",
      "epoch 143; iter: 0; batch classifier loss: 0.030992; batch adversarial loss: 0.400552\n",
      "epoch 144; iter: 0; batch classifier loss: 0.037504; batch adversarial loss: 0.439586\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025902; batch adversarial loss: 0.414083\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024962; batch adversarial loss: 0.419392\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024167; batch adversarial loss: 0.458259\n",
      "epoch 148; iter: 0; batch classifier loss: 0.014230; batch adversarial loss: 0.438498\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069259; batch adversarial loss: 0.444023\n",
      "epoch 150; iter: 0; batch classifier loss: 0.038680; batch adversarial loss: 0.550298\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041755; batch adversarial loss: 0.485424\n",
      "epoch 152; iter: 0; batch classifier loss: 0.019445; batch adversarial loss: 0.453335\n",
      "epoch 153; iter: 0; batch classifier loss: 0.073609; batch adversarial loss: 0.428218\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014561; batch adversarial loss: 0.423584\n",
      "epoch 155; iter: 0; batch classifier loss: 0.039600; batch adversarial loss: 0.437461\n",
      "epoch 156; iter: 0; batch classifier loss: 0.033745; batch adversarial loss: 0.552267\n",
      "epoch 157; iter: 0; batch classifier loss: 0.087632; batch adversarial loss: 0.385151\n",
      "epoch 158; iter: 0; batch classifier loss: 0.047962; batch adversarial loss: 0.336276\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025443; batch adversarial loss: 0.463954\n",
      "epoch 160; iter: 0; batch classifier loss: 0.017974; batch adversarial loss: 0.392863\n",
      "epoch 161; iter: 0; batch classifier loss: 0.049637; batch adversarial loss: 0.447419\n",
      "epoch 162; iter: 0; batch classifier loss: 0.024520; batch adversarial loss: 0.501803\n",
      "epoch 163; iter: 0; batch classifier loss: 0.026819; batch adversarial loss: 0.370162\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025767; batch adversarial loss: 0.444627\n",
      "epoch 165; iter: 0; batch classifier loss: 0.018438; batch adversarial loss: 0.385597\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033936; batch adversarial loss: 0.496567\n",
      "epoch 167; iter: 0; batch classifier loss: 0.058610; batch adversarial loss: 0.449768\n",
      "epoch 168; iter: 0; batch classifier loss: 0.021548; batch adversarial loss: 0.493252\n",
      "epoch 169; iter: 0; batch classifier loss: 0.053765; batch adversarial loss: 0.369340\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020545; batch adversarial loss: 0.468954\n",
      "epoch 171; iter: 0; batch classifier loss: 0.012478; batch adversarial loss: 0.494545\n",
      "epoch 172; iter: 0; batch classifier loss: 0.007661; batch adversarial loss: 0.436871\n",
      "epoch 173; iter: 0; batch classifier loss: 0.041918; batch adversarial loss: 0.518555\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036988; batch adversarial loss: 0.476464\n",
      "epoch 175; iter: 0; batch classifier loss: 0.021215; batch adversarial loss: 0.589820\n",
      "epoch 176; iter: 0; batch classifier loss: 0.012501; batch adversarial loss: 0.429955\n",
      "epoch 177; iter: 0; batch classifier loss: 0.041982; batch adversarial loss: 0.529806\n",
      "epoch 178; iter: 0; batch classifier loss: 0.038589; batch adversarial loss: 0.463838\n",
      "epoch 179; iter: 0; batch classifier loss: 0.037398; batch adversarial loss: 0.508195\n",
      "epoch 180; iter: 0; batch classifier loss: 0.035132; batch adversarial loss: 0.449496\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017561; batch adversarial loss: 0.540027\n",
      "epoch 182; iter: 0; batch classifier loss: 0.027185; batch adversarial loss: 0.462114\n",
      "epoch 183; iter: 0; batch classifier loss: 0.046460; batch adversarial loss: 0.422536\n",
      "epoch 184; iter: 0; batch classifier loss: 0.034045; batch adversarial loss: 0.539592\n",
      "epoch 185; iter: 0; batch classifier loss: 0.016802; batch adversarial loss: 0.437210\n",
      "epoch 186; iter: 0; batch classifier loss: 0.006318; batch adversarial loss: 0.508580\n",
      "epoch 187; iter: 0; batch classifier loss: 0.016272; batch adversarial loss: 0.388041\n",
      "epoch 188; iter: 0; batch classifier loss: 0.013336; batch adversarial loss: 0.501239\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018514; batch adversarial loss: 0.455064\n",
      "epoch 190; iter: 0; batch classifier loss: 0.008868; batch adversarial loss: 0.565156\n",
      "epoch 191; iter: 0; batch classifier loss: 0.014278; batch adversarial loss: 0.422143\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012456; batch adversarial loss: 0.379933\n",
      "epoch 193; iter: 0; batch classifier loss: 0.028330; batch adversarial loss: 0.482256\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014310; batch adversarial loss: 0.483541\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012705; batch adversarial loss: 0.334980\n",
      "epoch 196; iter: 0; batch classifier loss: 0.019565; batch adversarial loss: 0.412156\n",
      "epoch 197; iter: 0; batch classifier loss: 0.003284; batch adversarial loss: 0.434662\n",
      "epoch 198; iter: 0; batch classifier loss: 0.028850; batch adversarial loss: 0.516502\n",
      "epoch 199; iter: 0; batch classifier loss: 0.005415; batch adversarial loss: 0.473799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699578; batch adversarial loss: 0.652288\n",
      "epoch 1; iter: 0; batch classifier loss: 0.433288; batch adversarial loss: 0.643356\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391077; batch adversarial loss: 0.597259\n",
      "epoch 3; iter: 0; batch classifier loss: 0.349684; batch adversarial loss: 0.579804\n",
      "epoch 4; iter: 0; batch classifier loss: 0.348026; batch adversarial loss: 0.547968\n",
      "epoch 5; iter: 0; batch classifier loss: 0.303777; batch adversarial loss: 0.527956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.308974; batch adversarial loss: 0.516740\n",
      "epoch 7; iter: 0; batch classifier loss: 0.261112; batch adversarial loss: 0.512529\n",
      "epoch 8; iter: 0; batch classifier loss: 0.276417; batch adversarial loss: 0.469427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.192437; batch adversarial loss: 0.511430\n",
      "epoch 10; iter: 0; batch classifier loss: 0.278898; batch adversarial loss: 0.491869\n",
      "epoch 11; iter: 0; batch classifier loss: 0.231907; batch adversarial loss: 0.466882\n",
      "epoch 12; iter: 0; batch classifier loss: 0.161168; batch adversarial loss: 0.521526\n",
      "epoch 13; iter: 0; batch classifier loss: 0.219235; batch adversarial loss: 0.525670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.180047; batch adversarial loss: 0.547343\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267576; batch adversarial loss: 0.458342\n",
      "epoch 16; iter: 0; batch classifier loss: 0.146820; batch adversarial loss: 0.430172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 0; batch classifier loss: 0.176215; batch adversarial loss: 0.503138\n",
      "epoch 18; iter: 0; batch classifier loss: 0.214893; batch adversarial loss: 0.501615\n",
      "epoch 19; iter: 0; batch classifier loss: 0.147393; batch adversarial loss: 0.490407\n",
      "epoch 20; iter: 0; batch classifier loss: 0.143278; batch adversarial loss: 0.467355\n",
      "epoch 21; iter: 0; batch classifier loss: 0.211547; batch adversarial loss: 0.484169\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167850; batch adversarial loss: 0.407368\n",
      "epoch 23; iter: 0; batch classifier loss: 0.202472; batch adversarial loss: 0.463702\n",
      "epoch 24; iter: 0; batch classifier loss: 0.189536; batch adversarial loss: 0.472661\n",
      "epoch 25; iter: 0; batch classifier loss: 0.325245; batch adversarial loss: 0.499759\n",
      "epoch 26; iter: 0; batch classifier loss: 0.330876; batch adversarial loss: 0.559280\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442313; batch adversarial loss: 0.508078\n",
      "epoch 28; iter: 0; batch classifier loss: 0.254204; batch adversarial loss: 0.465684\n",
      "epoch 29; iter: 0; batch classifier loss: 0.175700; batch adversarial loss: 0.477175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.139681; batch adversarial loss: 0.488212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.144236; batch adversarial loss: 0.375114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.092552; batch adversarial loss: 0.495346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195808; batch adversarial loss: 0.467957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.128277; batch adversarial loss: 0.464219\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198576; batch adversarial loss: 0.414092\n",
      "epoch 36; iter: 0; batch classifier loss: 0.084254; batch adversarial loss: 0.440539\n",
      "epoch 37; iter: 0; batch classifier loss: 0.125311; batch adversarial loss: 0.419027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.076044; batch adversarial loss: 0.463489\n",
      "epoch 39; iter: 0; batch classifier loss: 0.085577; batch adversarial loss: 0.514992\n",
      "epoch 40; iter: 0; batch classifier loss: 0.115384; batch adversarial loss: 0.474987\n",
      "epoch 41; iter: 0; batch classifier loss: 0.106616; batch adversarial loss: 0.335752\n",
      "epoch 42; iter: 0; batch classifier loss: 0.094674; batch adversarial loss: 0.405942\n",
      "epoch 43; iter: 0; batch classifier loss: 0.067446; batch adversarial loss: 0.440778\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093347; batch adversarial loss: 0.432147\n",
      "epoch 45; iter: 0; batch classifier loss: 0.093263; batch adversarial loss: 0.444631\n",
      "epoch 46; iter: 0; batch classifier loss: 0.089169; batch adversarial loss: 0.468028\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070267; batch adversarial loss: 0.483272\n",
      "epoch 48; iter: 0; batch classifier loss: 0.087088; batch adversarial loss: 0.540355\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079863; batch adversarial loss: 0.541253\n",
      "epoch 50; iter: 0; batch classifier loss: 0.110753; batch adversarial loss: 0.431041\n",
      "epoch 51; iter: 0; batch classifier loss: 0.108239; batch adversarial loss: 0.444892\n",
      "epoch 52; iter: 0; batch classifier loss: 0.100189; batch adversarial loss: 0.464951\n",
      "epoch 53; iter: 0; batch classifier loss: 0.062463; batch adversarial loss: 0.380552\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079913; batch adversarial loss: 0.408049\n",
      "epoch 55; iter: 0; batch classifier loss: 0.098664; batch adversarial loss: 0.467009\n",
      "epoch 56; iter: 0; batch classifier loss: 0.087622; batch adversarial loss: 0.370317\n",
      "epoch 57; iter: 0; batch classifier loss: 0.045546; batch adversarial loss: 0.447770\n",
      "epoch 58; iter: 0; batch classifier loss: 0.060847; batch adversarial loss: 0.573159\n",
      "epoch 59; iter: 0; batch classifier loss: 0.050722; batch adversarial loss: 0.478308\n",
      "epoch 60; iter: 0; batch classifier loss: 0.096925; batch adversarial loss: 0.498181\n",
      "epoch 61; iter: 0; batch classifier loss: 0.058795; batch adversarial loss: 0.474484\n",
      "epoch 62; iter: 0; batch classifier loss: 0.102914; batch adversarial loss: 0.544764\n",
      "epoch 63; iter: 0; batch classifier loss: 0.096706; batch adversarial loss: 0.436915\n",
      "epoch 64; iter: 0; batch classifier loss: 0.120222; batch adversarial loss: 0.456818\n",
      "epoch 65; iter: 0; batch classifier loss: 0.094396; batch adversarial loss: 0.482771\n",
      "epoch 66; iter: 0; batch classifier loss: 0.055824; batch adversarial loss: 0.486480\n",
      "epoch 67; iter: 0; batch classifier loss: 0.107864; batch adversarial loss: 0.508915\n",
      "epoch 68; iter: 0; batch classifier loss: 0.066094; batch adversarial loss: 0.503956\n",
      "epoch 69; iter: 0; batch classifier loss: 0.064862; batch adversarial loss: 0.317003\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065241; batch adversarial loss: 0.398258\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095618; batch adversarial loss: 0.356913\n",
      "epoch 72; iter: 0; batch classifier loss: 0.136979; batch adversarial loss: 0.402126\n",
      "epoch 73; iter: 0; batch classifier loss: 0.038138; batch adversarial loss: 0.388191\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067184; batch adversarial loss: 0.447661\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075913; batch adversarial loss: 0.421087\n",
      "epoch 76; iter: 0; batch classifier loss: 0.090085; batch adversarial loss: 0.631436\n",
      "epoch 77; iter: 0; batch classifier loss: 0.048948; batch adversarial loss: 0.374054\n",
      "epoch 78; iter: 0; batch classifier loss: 0.081221; batch adversarial loss: 0.478724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.052397; batch adversarial loss: 0.486911\n",
      "epoch 80; iter: 0; batch classifier loss: 0.109102; batch adversarial loss: 0.375109\n",
      "epoch 81; iter: 0; batch classifier loss: 0.064295; batch adversarial loss: 0.559618\n",
      "epoch 82; iter: 0; batch classifier loss: 0.059340; batch adversarial loss: 0.491982\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062026; batch adversarial loss: 0.548161\n",
      "epoch 84; iter: 0; batch classifier loss: 0.060266; batch adversarial loss: 0.472379\n",
      "epoch 85; iter: 0; batch classifier loss: 0.086274; batch adversarial loss: 0.459204\n",
      "epoch 86; iter: 0; batch classifier loss: 0.086382; batch adversarial loss: 0.508506\n",
      "epoch 87; iter: 0; batch classifier loss: 0.056264; batch adversarial loss: 0.387330\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064556; batch adversarial loss: 0.424912\n",
      "epoch 89; iter: 0; batch classifier loss: 0.040823; batch adversarial loss: 0.529428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.054222; batch adversarial loss: 0.432462\n",
      "epoch 91; iter: 0; batch classifier loss: 0.074171; batch adversarial loss: 0.495886\n",
      "epoch 92; iter: 0; batch classifier loss: 0.065502; batch adversarial loss: 0.478700\n",
      "epoch 93; iter: 0; batch classifier loss: 0.031389; batch adversarial loss: 0.524493\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077852; batch adversarial loss: 0.478279\n",
      "epoch 95; iter: 0; batch classifier loss: 0.076958; batch adversarial loss: 0.464984\n",
      "epoch 96; iter: 0; batch classifier loss: 0.073517; batch adversarial loss: 0.358224\n",
      "epoch 97; iter: 0; batch classifier loss: 0.033058; batch adversarial loss: 0.446271\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044018; batch adversarial loss: 0.403348\n",
      "epoch 99; iter: 0; batch classifier loss: 0.125781; batch adversarial loss: 0.479268\n",
      "epoch 100; iter: 0; batch classifier loss: 0.049314; batch adversarial loss: 0.500488\n",
      "epoch 101; iter: 0; batch classifier loss: 0.059973; batch adversarial loss: 0.467783\n",
      "epoch 102; iter: 0; batch classifier loss: 0.058107; batch adversarial loss: 0.493358\n",
      "epoch 103; iter: 0; batch classifier loss: 0.071571; batch adversarial loss: 0.553973\n",
      "epoch 104; iter: 0; batch classifier loss: 0.018890; batch adversarial loss: 0.524779\n",
      "epoch 105; iter: 0; batch classifier loss: 0.059264; batch adversarial loss: 0.499024\n",
      "epoch 106; iter: 0; batch classifier loss: 0.034633; batch adversarial loss: 0.401728\n",
      "epoch 107; iter: 0; batch classifier loss: 0.045707; batch adversarial loss: 0.507443\n",
      "epoch 108; iter: 0; batch classifier loss: 0.045819; batch adversarial loss: 0.385925\n",
      "epoch 109; iter: 0; batch classifier loss: 0.031643; batch adversarial loss: 0.439018\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064446; batch adversarial loss: 0.510740\n",
      "epoch 111; iter: 0; batch classifier loss: 0.081332; batch adversarial loss: 0.501085\n",
      "epoch 112; iter: 0; batch classifier loss: 0.034706; batch adversarial loss: 0.513751\n",
      "epoch 113; iter: 0; batch classifier loss: 0.020327; batch adversarial loss: 0.411299\n",
      "epoch 114; iter: 0; batch classifier loss: 0.045764; batch adversarial loss: 0.412171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 115; iter: 0; batch classifier loss: 0.038007; batch adversarial loss: 0.403709\n",
      "epoch 116; iter: 0; batch classifier loss: 0.093060; batch adversarial loss: 0.395559\n",
      "epoch 117; iter: 0; batch classifier loss: 0.035179; batch adversarial loss: 0.514473\n",
      "epoch 118; iter: 0; batch classifier loss: 0.066066; batch adversarial loss: 0.499999\n",
      "epoch 119; iter: 0; batch classifier loss: 0.017990; batch adversarial loss: 0.404848\n",
      "epoch 120; iter: 0; batch classifier loss: 0.066165; batch adversarial loss: 0.436139\n",
      "epoch 121; iter: 0; batch classifier loss: 0.084666; batch adversarial loss: 0.463514\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030163; batch adversarial loss: 0.520542\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033945; batch adversarial loss: 0.389938\n",
      "epoch 124; iter: 0; batch classifier loss: 0.055924; batch adversarial loss: 0.509209\n",
      "epoch 125; iter: 0; batch classifier loss: 0.054414; batch adversarial loss: 0.525453\n",
      "epoch 126; iter: 0; batch classifier loss: 0.027449; batch adversarial loss: 0.482768\n",
      "epoch 127; iter: 0; batch classifier loss: 0.048647; batch adversarial loss: 0.433156\n",
      "epoch 128; iter: 0; batch classifier loss: 0.064960; batch adversarial loss: 0.443677\n",
      "epoch 129; iter: 0; batch classifier loss: 0.047932; batch adversarial loss: 0.402875\n",
      "epoch 130; iter: 0; batch classifier loss: 0.053226; batch adversarial loss: 0.458488\n",
      "epoch 131; iter: 0; batch classifier loss: 0.043341; batch adversarial loss: 0.454926\n",
      "epoch 132; iter: 0; batch classifier loss: 0.046528; batch adversarial loss: 0.464589\n",
      "epoch 133; iter: 0; batch classifier loss: 0.040386; batch adversarial loss: 0.421697\n",
      "epoch 134; iter: 0; batch classifier loss: 0.067051; batch adversarial loss: 0.479056\n",
      "epoch 135; iter: 0; batch classifier loss: 0.047072; batch adversarial loss: 0.457863\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036778; batch adversarial loss: 0.482222\n",
      "epoch 137; iter: 0; batch classifier loss: 0.049665; batch adversarial loss: 0.451994\n",
      "epoch 138; iter: 0; batch classifier loss: 0.029825; batch adversarial loss: 0.428649\n",
      "epoch 139; iter: 0; batch classifier loss: 0.031684; batch adversarial loss: 0.502681\n",
      "epoch 140; iter: 0; batch classifier loss: 0.062618; batch adversarial loss: 0.526266\n",
      "epoch 141; iter: 0; batch classifier loss: 0.026777; batch adversarial loss: 0.446551\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036987; batch adversarial loss: 0.466249\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050708; batch adversarial loss: 0.522126\n",
      "epoch 144; iter: 0; batch classifier loss: 0.014244; batch adversarial loss: 0.448210\n",
      "epoch 145; iter: 0; batch classifier loss: 0.028092; batch adversarial loss: 0.487143\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025582; batch adversarial loss: 0.478080\n",
      "epoch 147; iter: 0; batch classifier loss: 0.042933; batch adversarial loss: 0.391664\n",
      "epoch 148; iter: 0; batch classifier loss: 0.034118; batch adversarial loss: 0.416693\n",
      "epoch 149; iter: 0; batch classifier loss: 0.029831; batch adversarial loss: 0.475424\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025576; batch adversarial loss: 0.567108\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037704; batch adversarial loss: 0.375002\n",
      "epoch 152; iter: 0; batch classifier loss: 0.051398; batch adversarial loss: 0.494801\n",
      "epoch 153; iter: 0; batch classifier loss: 0.018868; batch adversarial loss: 0.387433\n",
      "epoch 154; iter: 0; batch classifier loss: 0.059449; batch adversarial loss: 0.462442\n",
      "epoch 155; iter: 0; batch classifier loss: 0.031696; batch adversarial loss: 0.548743\n",
      "epoch 156; iter: 0; batch classifier loss: 0.042524; batch adversarial loss: 0.468412\n",
      "epoch 157; iter: 0; batch classifier loss: 0.062006; batch adversarial loss: 0.358381\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027202; batch adversarial loss: 0.440356\n",
      "epoch 159; iter: 0; batch classifier loss: 0.039221; batch adversarial loss: 0.434501\n",
      "epoch 160; iter: 0; batch classifier loss: 0.022891; batch adversarial loss: 0.563924\n",
      "epoch 161; iter: 0; batch classifier loss: 0.008897; batch adversarial loss: 0.495418\n",
      "epoch 162; iter: 0; batch classifier loss: 0.015989; batch adversarial loss: 0.506720\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010467; batch adversarial loss: 0.524736\n",
      "epoch 164; iter: 0; batch classifier loss: 0.010307; batch adversarial loss: 0.553730\n",
      "epoch 165; iter: 0; batch classifier loss: 0.029969; batch adversarial loss: 0.436934\n",
      "epoch 166; iter: 0; batch classifier loss: 0.013349; batch adversarial loss: 0.500806\n",
      "epoch 167; iter: 0; batch classifier loss: 0.016382; batch adversarial loss: 0.503020\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015030; batch adversarial loss: 0.385059\n",
      "epoch 169; iter: 0; batch classifier loss: 0.041185; batch adversarial loss: 0.468799\n",
      "epoch 170; iter: 0; batch classifier loss: 0.031032; batch adversarial loss: 0.414504\n",
      "epoch 171; iter: 0; batch classifier loss: 0.028275; batch adversarial loss: 0.499136\n",
      "epoch 172; iter: 0; batch classifier loss: 0.030139; batch adversarial loss: 0.492104\n",
      "epoch 173; iter: 0; batch classifier loss: 0.047889; batch adversarial loss: 0.463693\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029235; batch adversarial loss: 0.439721\n",
      "epoch 175; iter: 0; batch classifier loss: 0.038198; batch adversarial loss: 0.379861\n",
      "epoch 176; iter: 0; batch classifier loss: 0.018421; batch adversarial loss: 0.478577\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037563; batch adversarial loss: 0.442603\n",
      "epoch 178; iter: 0; batch classifier loss: 0.013080; batch adversarial loss: 0.413481\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007171; batch adversarial loss: 0.509954\n",
      "epoch 180; iter: 0; batch classifier loss: 0.030439; batch adversarial loss: 0.409179\n",
      "epoch 181; iter: 0; batch classifier loss: 0.046024; batch adversarial loss: 0.544434\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021168; batch adversarial loss: 0.465811\n",
      "epoch 183; iter: 0; batch classifier loss: 0.015167; batch adversarial loss: 0.442188\n",
      "epoch 184; iter: 0; batch classifier loss: 0.025574; batch adversarial loss: 0.521857\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024430; batch adversarial loss: 0.455845\n",
      "epoch 186; iter: 0; batch classifier loss: 0.041111; batch adversarial loss: 0.385533\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024533; batch adversarial loss: 0.518781\n",
      "epoch 188; iter: 0; batch classifier loss: 0.016985; batch adversarial loss: 0.524758\n",
      "epoch 189; iter: 0; batch classifier loss: 0.043223; batch adversarial loss: 0.363058\n",
      "epoch 190; iter: 0; batch classifier loss: 0.041987; batch adversarial loss: 0.469964\n",
      "epoch 191; iter: 0; batch classifier loss: 0.032591; batch adversarial loss: 0.384313\n",
      "epoch 192; iter: 0; batch classifier loss: 0.051492; batch adversarial loss: 0.456243\n",
      "epoch 193; iter: 0; batch classifier loss: 0.030682; batch adversarial loss: 0.498407\n",
      "epoch 194; iter: 0; batch classifier loss: 0.013789; batch adversarial loss: 0.481665\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027366; batch adversarial loss: 0.420250\n",
      "epoch 196; iter: 0; batch classifier loss: 0.029371; batch adversarial loss: 0.418042\n",
      "epoch 197; iter: 0; batch classifier loss: 0.039960; batch adversarial loss: 0.447803\n",
      "epoch 198; iter: 0; batch classifier loss: 0.018052; batch adversarial loss: 0.440837\n",
      "epoch 199; iter: 0; batch classifier loss: 0.028426; batch adversarial loss: 0.451479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704120; batch adversarial loss: 0.828685\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417490; batch adversarial loss: 0.758900\n",
      "epoch 2; iter: 0; batch classifier loss: 0.502484; batch adversarial loss: 0.729887\n",
      "epoch 3; iter: 0; batch classifier loss: 0.724304; batch adversarial loss: 0.680154\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616141; batch adversarial loss: 0.629862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438732; batch adversarial loss: 0.602094\n",
      "epoch 6; iter: 0; batch classifier loss: 0.458135; batch adversarial loss: 0.554451\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382793; batch adversarial loss: 0.536494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355142; batch adversarial loss: 0.550708\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331870; batch adversarial loss: 0.554470\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455902; batch adversarial loss: 0.578440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 0; batch classifier loss: 0.485259; batch adversarial loss: 0.513725\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367969; batch adversarial loss: 0.524249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.386804; batch adversarial loss: 0.519529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387192; batch adversarial loss: 0.471973\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414573; batch adversarial loss: 0.535652\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480067; batch adversarial loss: 0.445537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366952; batch adversarial loss: 0.480934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.456753; batch adversarial loss: 0.503149\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426799; batch adversarial loss: 0.486388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377254; batch adversarial loss: 0.448626\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389424; batch adversarial loss: 0.544554\n",
      "epoch 22; iter: 0; batch classifier loss: 0.387316; batch adversarial loss: 0.453388\n",
      "epoch 23; iter: 0; batch classifier loss: 0.385647; batch adversarial loss: 0.462546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.309645; batch adversarial loss: 0.451008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.382019; batch adversarial loss: 0.399250\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334155; batch adversarial loss: 0.495359\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272035; batch adversarial loss: 0.449069\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302828; batch adversarial loss: 0.464916\n",
      "epoch 29; iter: 0; batch classifier loss: 0.296204; batch adversarial loss: 0.505191\n",
      "epoch 30; iter: 0; batch classifier loss: 0.281661; batch adversarial loss: 0.446860\n",
      "epoch 31; iter: 0; batch classifier loss: 0.247051; batch adversarial loss: 0.452119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.277901; batch adversarial loss: 0.462503\n",
      "epoch 33; iter: 0; batch classifier loss: 0.253928; batch adversarial loss: 0.428643\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240751; batch adversarial loss: 0.500651\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293985; batch adversarial loss: 0.404867\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268324; batch adversarial loss: 0.465423\n",
      "epoch 37; iter: 0; batch classifier loss: 0.198195; batch adversarial loss: 0.461271\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213137; batch adversarial loss: 0.441469\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197814; batch adversarial loss: 0.437673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.243780; batch adversarial loss: 0.446973\n",
      "epoch 41; iter: 0; batch classifier loss: 0.135879; batch adversarial loss: 0.413747\n",
      "epoch 42; iter: 0; batch classifier loss: 0.210724; batch adversarial loss: 0.377157\n",
      "epoch 43; iter: 0; batch classifier loss: 0.264069; batch adversarial loss: 0.413838\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287221; batch adversarial loss: 0.422354\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289384; batch adversarial loss: 0.411773\n",
      "epoch 46; iter: 0; batch classifier loss: 0.218796; batch adversarial loss: 0.446454\n",
      "epoch 47; iter: 0; batch classifier loss: 0.175818; batch adversarial loss: 0.501635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.204645; batch adversarial loss: 0.437747\n",
      "epoch 49; iter: 0; batch classifier loss: 0.206871; batch adversarial loss: 0.551557\n",
      "epoch 50; iter: 0; batch classifier loss: 0.222103; batch adversarial loss: 0.506700\n",
      "epoch 51; iter: 0; batch classifier loss: 0.200662; batch adversarial loss: 0.494112\n",
      "epoch 52; iter: 0; batch classifier loss: 0.242555; batch adversarial loss: 0.504406\n",
      "epoch 53; iter: 0; batch classifier loss: 0.179221; batch adversarial loss: 0.491553\n",
      "epoch 54; iter: 0; batch classifier loss: 0.200238; batch adversarial loss: 0.508245\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212495; batch adversarial loss: 0.493876\n",
      "epoch 56; iter: 0; batch classifier loss: 0.208970; batch adversarial loss: 0.351273\n",
      "epoch 57; iter: 0; batch classifier loss: 0.258981; batch adversarial loss: 0.473390\n",
      "epoch 58; iter: 0; batch classifier loss: 0.276499; batch adversarial loss: 0.458442\n",
      "epoch 59; iter: 0; batch classifier loss: 0.186338; batch adversarial loss: 0.483693\n",
      "epoch 60; iter: 0; batch classifier loss: 0.172107; batch adversarial loss: 0.433334\n",
      "epoch 61; iter: 0; batch classifier loss: 0.289999; batch adversarial loss: 0.435120\n",
      "epoch 62; iter: 0; batch classifier loss: 0.248394; batch adversarial loss: 0.421660\n",
      "epoch 63; iter: 0; batch classifier loss: 0.242244; batch adversarial loss: 0.422049\n",
      "epoch 64; iter: 0; batch classifier loss: 0.192136; batch adversarial loss: 0.470845\n",
      "epoch 65; iter: 0; batch classifier loss: 0.205408; batch adversarial loss: 0.422629\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109094; batch adversarial loss: 0.397316\n",
      "epoch 67; iter: 0; batch classifier loss: 0.095164; batch adversarial loss: 0.532002\n",
      "epoch 68; iter: 0; batch classifier loss: 0.152588; batch adversarial loss: 0.520151\n",
      "epoch 69; iter: 0; batch classifier loss: 0.196459; batch adversarial loss: 0.482968\n",
      "epoch 70; iter: 0; batch classifier loss: 0.195379; batch adversarial loss: 0.498085\n",
      "epoch 71; iter: 0; batch classifier loss: 0.166168; batch adversarial loss: 0.421637\n",
      "epoch 72; iter: 0; batch classifier loss: 0.162962; batch adversarial loss: 0.458332\n",
      "epoch 73; iter: 0; batch classifier loss: 0.214455; batch adversarial loss: 0.446158\n",
      "epoch 74; iter: 0; batch classifier loss: 0.252569; batch adversarial loss: 0.372428\n",
      "epoch 75; iter: 0; batch classifier loss: 0.156818; batch adversarial loss: 0.384809\n",
      "epoch 76; iter: 0; batch classifier loss: 0.218207; batch adversarial loss: 0.533884\n",
      "epoch 77; iter: 0; batch classifier loss: 0.166106; batch adversarial loss: 0.470535\n",
      "epoch 78; iter: 0; batch classifier loss: 0.202233; batch adversarial loss: 0.421514\n",
      "epoch 79; iter: 0; batch classifier loss: 0.210361; batch adversarial loss: 0.446490\n",
      "epoch 80; iter: 0; batch classifier loss: 0.164598; batch adversarial loss: 0.483542\n",
      "epoch 81; iter: 0; batch classifier loss: 0.171453; batch adversarial loss: 0.521624\n",
      "epoch 82; iter: 0; batch classifier loss: 0.192268; batch adversarial loss: 0.395929\n",
      "epoch 83; iter: 0; batch classifier loss: 0.210268; batch adversarial loss: 0.359299\n",
      "epoch 84; iter: 0; batch classifier loss: 0.227367; batch adversarial loss: 0.483828\n",
      "epoch 85; iter: 0; batch classifier loss: 0.187377; batch adversarial loss: 0.458741\n",
      "epoch 86; iter: 0; batch classifier loss: 0.192223; batch adversarial loss: 0.420800\n",
      "epoch 87; iter: 0; batch classifier loss: 0.231333; batch adversarial loss: 0.458792\n",
      "epoch 88; iter: 0; batch classifier loss: 0.248460; batch adversarial loss: 0.433712\n",
      "epoch 89; iter: 0; batch classifier loss: 0.230478; batch adversarial loss: 0.384472\n",
      "epoch 90; iter: 0; batch classifier loss: 0.189074; batch adversarial loss: 0.508261\n",
      "epoch 91; iter: 0; batch classifier loss: 0.110022; batch adversarial loss: 0.496015\n",
      "epoch 92; iter: 0; batch classifier loss: 0.087099; batch adversarial loss: 0.394558\n",
      "epoch 93; iter: 0; batch classifier loss: 0.106934; batch adversarial loss: 0.485366\n",
      "epoch 94; iter: 0; batch classifier loss: 0.057686; batch adversarial loss: 0.423475\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058302; batch adversarial loss: 0.369123\n",
      "epoch 96; iter: 0; batch classifier loss: 0.060388; batch adversarial loss: 0.436229\n",
      "epoch 97; iter: 0; batch classifier loss: 0.090157; batch adversarial loss: 0.399888\n",
      "epoch 98; iter: 0; batch classifier loss: 0.040748; batch adversarial loss: 0.329869\n",
      "epoch 99; iter: 0; batch classifier loss: 0.064878; batch adversarial loss: 0.414121\n",
      "epoch 100; iter: 0; batch classifier loss: 0.039467; batch adversarial loss: 0.400056\n",
      "epoch 101; iter: 0; batch classifier loss: 0.049625; batch adversarial loss: 0.466498\n",
      "epoch 102; iter: 0; batch classifier loss: 0.029159; batch adversarial loss: 0.457241\n",
      "epoch 103; iter: 0; batch classifier loss: 0.043561; batch adversarial loss: 0.501366\n",
      "epoch 104; iter: 0; batch classifier loss: 0.040613; batch adversarial loss: 0.417518\n",
      "epoch 105; iter: 0; batch classifier loss: 0.071748; batch adversarial loss: 0.453920\n",
      "epoch 106; iter: 0; batch classifier loss: 0.033647; batch adversarial loss: 0.453920\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030639; batch adversarial loss: 0.449682\n",
      "epoch 108; iter: 0; batch classifier loss: 0.032608; batch adversarial loss: 0.441941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 109; iter: 0; batch classifier loss: 0.047517; batch adversarial loss: 0.463863\n",
      "epoch 110; iter: 0; batch classifier loss: 0.059481; batch adversarial loss: 0.478371\n",
      "epoch 111; iter: 0; batch classifier loss: 0.069385; batch adversarial loss: 0.445193\n",
      "epoch 112; iter: 0; batch classifier loss: 0.043506; batch adversarial loss: 0.396531\n",
      "epoch 113; iter: 0; batch classifier loss: 0.013538; batch adversarial loss: 0.455521\n",
      "epoch 114; iter: 0; batch classifier loss: 0.038690; batch adversarial loss: 0.521226\n",
      "epoch 115; iter: 0; batch classifier loss: 0.057094; batch adversarial loss: 0.438417\n",
      "epoch 116; iter: 0; batch classifier loss: 0.027124; batch adversarial loss: 0.439464\n",
      "epoch 117; iter: 0; batch classifier loss: 0.089306; batch adversarial loss: 0.421201\n",
      "epoch 118; iter: 0; batch classifier loss: 0.015597; batch adversarial loss: 0.508397\n",
      "epoch 119; iter: 0; batch classifier loss: 0.013693; batch adversarial loss: 0.457349\n",
      "epoch 120; iter: 0; batch classifier loss: 0.033546; batch adversarial loss: 0.431558\n",
      "epoch 121; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.527485\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035925; batch adversarial loss: 0.392383\n",
      "epoch 123; iter: 0; batch classifier loss: 0.033644; batch adversarial loss: 0.540212\n",
      "epoch 124; iter: 0; batch classifier loss: 0.021921; batch adversarial loss: 0.484908\n",
      "epoch 125; iter: 0; batch classifier loss: 0.041273; batch adversarial loss: 0.464083\n",
      "epoch 126; iter: 0; batch classifier loss: 0.025960; batch adversarial loss: 0.431244\n",
      "epoch 127; iter: 0; batch classifier loss: 0.015515; batch adversarial loss: 0.352681\n",
      "epoch 128; iter: 0; batch classifier loss: 0.014275; batch adversarial loss: 0.423520\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033800; batch adversarial loss: 0.464542\n",
      "epoch 130; iter: 0; batch classifier loss: 0.031356; batch adversarial loss: 0.429508\n",
      "epoch 131; iter: 0; batch classifier loss: 0.022092; batch adversarial loss: 0.487033\n",
      "epoch 132; iter: 0; batch classifier loss: 0.043771; batch adversarial loss: 0.377116\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041503; batch adversarial loss: 0.396352\n",
      "epoch 134; iter: 0; batch classifier loss: 0.027793; batch adversarial loss: 0.549619\n",
      "epoch 135; iter: 0; batch classifier loss: 0.024442; batch adversarial loss: 0.485034\n",
      "epoch 136; iter: 0; batch classifier loss: 0.054510; batch adversarial loss: 0.392693\n",
      "epoch 137; iter: 0; batch classifier loss: 0.079847; batch adversarial loss: 0.446155\n",
      "epoch 138; iter: 0; batch classifier loss: 0.016084; batch adversarial loss: 0.546962\n",
      "epoch 139; iter: 0; batch classifier loss: 0.025320; batch adversarial loss: 0.509149\n",
      "epoch 140; iter: 0; batch classifier loss: 0.017032; batch adversarial loss: 0.350584\n",
      "epoch 141; iter: 0; batch classifier loss: 0.021818; batch adversarial loss: 0.515107\n",
      "epoch 142; iter: 0; batch classifier loss: 0.018992; batch adversarial loss: 0.525705\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037105; batch adversarial loss: 0.411937\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019210; batch adversarial loss: 0.482067\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022548; batch adversarial loss: 0.381777\n",
      "epoch 146; iter: 0; batch classifier loss: 0.024209; batch adversarial loss: 0.512473\n",
      "epoch 147; iter: 0; batch classifier loss: 0.025110; batch adversarial loss: 0.407893\n",
      "epoch 148; iter: 0; batch classifier loss: 0.018776; batch adversarial loss: 0.435936\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034438; batch adversarial loss: 0.496053\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018295; batch adversarial loss: 0.537288\n",
      "epoch 151; iter: 0; batch classifier loss: 0.021524; batch adversarial loss: 0.456149\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013798; batch adversarial loss: 0.508447\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030121; batch adversarial loss: 0.429514\n",
      "epoch 154; iter: 0; batch classifier loss: 0.030605; batch adversarial loss: 0.515260\n",
      "epoch 155; iter: 0; batch classifier loss: 0.010665; batch adversarial loss: 0.434394\n",
      "epoch 156; iter: 0; batch classifier loss: 0.030865; batch adversarial loss: 0.550252\n",
      "epoch 157; iter: 0; batch classifier loss: 0.017849; batch adversarial loss: 0.444561\n",
      "epoch 158; iter: 0; batch classifier loss: 0.004965; batch adversarial loss: 0.466916\n",
      "epoch 159; iter: 0; batch classifier loss: 0.022607; batch adversarial loss: 0.420641\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010882; batch adversarial loss: 0.493041\n",
      "epoch 161; iter: 0; batch classifier loss: 0.024142; batch adversarial loss: 0.469524\n",
      "epoch 162; iter: 0; batch classifier loss: 0.041121; batch adversarial loss: 0.386972\n",
      "epoch 163; iter: 0; batch classifier loss: 0.017987; batch adversarial loss: 0.362857\n",
      "epoch 164; iter: 0; batch classifier loss: 0.064922; batch adversarial loss: 0.485312\n",
      "epoch 165; iter: 0; batch classifier loss: 0.012570; batch adversarial loss: 0.449971\n",
      "epoch 166; iter: 0; batch classifier loss: 0.008916; batch adversarial loss: 0.475652\n",
      "epoch 167; iter: 0; batch classifier loss: 0.009989; batch adversarial loss: 0.418825\n",
      "epoch 168; iter: 0; batch classifier loss: 0.016943; batch adversarial loss: 0.406332\n",
      "epoch 169; iter: 0; batch classifier loss: 0.020627; batch adversarial loss: 0.425803\n",
      "epoch 170; iter: 0; batch classifier loss: 0.007022; batch adversarial loss: 0.502968\n",
      "epoch 171; iter: 0; batch classifier loss: 0.019912; batch adversarial loss: 0.450471\n",
      "epoch 172; iter: 0; batch classifier loss: 0.035776; batch adversarial loss: 0.547200\n",
      "epoch 173; iter: 0; batch classifier loss: 0.020273; batch adversarial loss: 0.428731\n",
      "epoch 174; iter: 0; batch classifier loss: 0.032831; batch adversarial loss: 0.444262\n",
      "epoch 175; iter: 0; batch classifier loss: 0.025472; batch adversarial loss: 0.452043\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011701; batch adversarial loss: 0.386549\n",
      "epoch 177; iter: 0; batch classifier loss: 0.011233; batch adversarial loss: 0.519978\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015876; batch adversarial loss: 0.486809\n",
      "epoch 179; iter: 0; batch classifier loss: 0.021508; batch adversarial loss: 0.405458\n",
      "epoch 180; iter: 0; batch classifier loss: 0.021773; batch adversarial loss: 0.497649\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018304; batch adversarial loss: 0.451116\n",
      "epoch 182; iter: 0; batch classifier loss: 0.011933; batch adversarial loss: 0.433559\n",
      "epoch 183; iter: 0; batch classifier loss: 0.027100; batch adversarial loss: 0.413552\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050222; batch adversarial loss: 0.454792\n",
      "epoch 185; iter: 0; batch classifier loss: 0.010679; batch adversarial loss: 0.454757\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022159; batch adversarial loss: 0.449991\n",
      "epoch 187; iter: 0; batch classifier loss: 0.029174; batch adversarial loss: 0.387351\n",
      "epoch 188; iter: 0; batch classifier loss: 0.009792; batch adversarial loss: 0.484827\n",
      "epoch 189; iter: 0; batch classifier loss: 0.011066; batch adversarial loss: 0.368025\n",
      "epoch 190; iter: 0; batch classifier loss: 0.019516; batch adversarial loss: 0.477471\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017452; batch adversarial loss: 0.397196\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012231; batch adversarial loss: 0.487374\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008069; batch adversarial loss: 0.459574\n",
      "epoch 194; iter: 0; batch classifier loss: 0.028547; batch adversarial loss: 0.401054\n",
      "epoch 195; iter: 0; batch classifier loss: 0.012844; batch adversarial loss: 0.525850\n",
      "epoch 196; iter: 0; batch classifier loss: 0.031098; batch adversarial loss: 0.431824\n",
      "epoch 197; iter: 0; batch classifier loss: 0.010830; batch adversarial loss: 0.358544\n",
      "epoch 198; iter: 0; batch classifier loss: 0.015053; batch adversarial loss: 0.401415\n",
      "epoch 199; iter: 0; batch classifier loss: 0.052502; batch adversarial loss: 0.451721\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685105; batch adversarial loss: 0.516454\n",
      "epoch 1; iter: 0; batch classifier loss: 0.446687; batch adversarial loss: 0.625757\n",
      "epoch 2; iter: 0; batch classifier loss: 0.395273; batch adversarial loss: 0.580816\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396715; batch adversarial loss: 0.601286\n",
      "epoch 4; iter: 0; batch classifier loss: 0.301705; batch adversarial loss: 0.544805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369570; batch adversarial loss: 0.482956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 0; batch classifier loss: 0.316901; batch adversarial loss: 0.541300\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312986; batch adversarial loss: 0.615143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.346926; batch adversarial loss: 0.543877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.294591; batch adversarial loss: 0.578153\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337270; batch adversarial loss: 0.645368\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287818; batch adversarial loss: 0.563152\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280881; batch adversarial loss: 0.618782\n",
      "epoch 13; iter: 0; batch classifier loss: 0.255385; batch adversarial loss: 0.585536\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430066; batch adversarial loss: 0.505242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367541; batch adversarial loss: 0.532492\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350715; batch adversarial loss: 0.533230\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.527606\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368163; batch adversarial loss: 0.527141\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284849; batch adversarial loss: 0.488981\n",
      "epoch 20; iter: 0; batch classifier loss: 0.172816; batch adversarial loss: 0.552095\n",
      "epoch 21; iter: 0; batch classifier loss: 0.140750; batch adversarial loss: 0.480960\n",
      "epoch 22; iter: 0; batch classifier loss: 0.197253; batch adversarial loss: 0.497196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.154360; batch adversarial loss: 0.407771\n",
      "epoch 24; iter: 0; batch classifier loss: 0.153222; batch adversarial loss: 0.508564\n",
      "epoch 25; iter: 0; batch classifier loss: 0.192511; batch adversarial loss: 0.476257\n",
      "epoch 26; iter: 0; batch classifier loss: 0.097715; batch adversarial loss: 0.507056\n",
      "epoch 27; iter: 0; batch classifier loss: 0.172190; batch adversarial loss: 0.476106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.141241; batch adversarial loss: 0.509774\n",
      "epoch 29; iter: 0; batch classifier loss: 0.153610; batch adversarial loss: 0.587267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.121968; batch adversarial loss: 0.488675\n",
      "epoch 31; iter: 0; batch classifier loss: 0.112475; batch adversarial loss: 0.424070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157847; batch adversarial loss: 0.521919\n",
      "epoch 33; iter: 0; batch classifier loss: 0.116213; batch adversarial loss: 0.391011\n",
      "epoch 34; iter: 0; batch classifier loss: 0.119083; batch adversarial loss: 0.438252\n",
      "epoch 35; iter: 0; batch classifier loss: 0.102469; batch adversarial loss: 0.432320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154460; batch adversarial loss: 0.467362\n",
      "epoch 37; iter: 0; batch classifier loss: 0.082357; batch adversarial loss: 0.465611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.138776; batch adversarial loss: 0.437455\n",
      "epoch 39; iter: 0; batch classifier loss: 0.095762; batch adversarial loss: 0.485682\n",
      "epoch 40; iter: 0; batch classifier loss: 0.116004; batch adversarial loss: 0.397942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.177475; batch adversarial loss: 0.384122\n",
      "epoch 42; iter: 0; batch classifier loss: 0.089589; batch adversarial loss: 0.514613\n",
      "epoch 43; iter: 0; batch classifier loss: 0.081880; batch adversarial loss: 0.338735\n",
      "epoch 44; iter: 0; batch classifier loss: 0.086202; batch adversarial loss: 0.429663\n",
      "epoch 45; iter: 0; batch classifier loss: 0.098353; batch adversarial loss: 0.467593\n",
      "epoch 46; iter: 0; batch classifier loss: 0.103908; batch adversarial loss: 0.455453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.087445; batch adversarial loss: 0.559964\n",
      "epoch 48; iter: 0; batch classifier loss: 0.132792; batch adversarial loss: 0.496544\n",
      "epoch 49; iter: 0; batch classifier loss: 0.080199; batch adversarial loss: 0.435868\n",
      "epoch 50; iter: 0; batch classifier loss: 0.109782; batch adversarial loss: 0.363847\n",
      "epoch 51; iter: 0; batch classifier loss: 0.114088; batch adversarial loss: 0.449423\n",
      "epoch 52; iter: 0; batch classifier loss: 0.093779; batch adversarial loss: 0.413565\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106586; batch adversarial loss: 0.402901\n",
      "epoch 54; iter: 0; batch classifier loss: 0.052326; batch adversarial loss: 0.455400\n",
      "epoch 55; iter: 0; batch classifier loss: 0.111115; batch adversarial loss: 0.374058\n",
      "epoch 56; iter: 0; batch classifier loss: 0.098984; batch adversarial loss: 0.391179\n",
      "epoch 57; iter: 0; batch classifier loss: 0.136414; batch adversarial loss: 0.406278\n",
      "epoch 58; iter: 0; batch classifier loss: 0.115292; batch adversarial loss: 0.382696\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095256; batch adversarial loss: 0.403016\n",
      "epoch 60; iter: 0; batch classifier loss: 0.076980; batch adversarial loss: 0.507884\n",
      "epoch 61; iter: 0; batch classifier loss: 0.130951; batch adversarial loss: 0.492776\n",
      "epoch 62; iter: 0; batch classifier loss: 0.085967; batch adversarial loss: 0.489390\n",
      "epoch 63; iter: 0; batch classifier loss: 0.104089; batch adversarial loss: 0.460734\n",
      "epoch 64; iter: 0; batch classifier loss: 0.099157; batch adversarial loss: 0.488254\n",
      "epoch 65; iter: 0; batch classifier loss: 0.085281; batch adversarial loss: 0.464951\n",
      "epoch 66; iter: 0; batch classifier loss: 0.118924; batch adversarial loss: 0.502350\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117565; batch adversarial loss: 0.554694\n",
      "epoch 68; iter: 0; batch classifier loss: 0.062041; batch adversarial loss: 0.463315\n",
      "epoch 69; iter: 0; batch classifier loss: 0.070311; batch adversarial loss: 0.428584\n",
      "epoch 70; iter: 0; batch classifier loss: 0.085562; batch adversarial loss: 0.447057\n",
      "epoch 71; iter: 0; batch classifier loss: 0.190440; batch adversarial loss: 0.453945\n",
      "epoch 72; iter: 0; batch classifier loss: 0.098981; batch adversarial loss: 0.536211\n",
      "epoch 73; iter: 0; batch classifier loss: 0.116479; batch adversarial loss: 0.419888\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071959; batch adversarial loss: 0.557951\n",
      "epoch 75; iter: 0; batch classifier loss: 0.131341; batch adversarial loss: 0.536621\n",
      "epoch 76; iter: 0; batch classifier loss: 0.080563; batch adversarial loss: 0.488099\n",
      "epoch 77; iter: 0; batch classifier loss: 0.110894; batch adversarial loss: 0.535853\n",
      "epoch 78; iter: 0; batch classifier loss: 0.099663; batch adversarial loss: 0.505684\n",
      "epoch 79; iter: 0; batch classifier loss: 0.108835; batch adversarial loss: 0.460524\n",
      "epoch 80; iter: 0; batch classifier loss: 0.145272; batch adversarial loss: 0.422991\n",
      "epoch 81; iter: 0; batch classifier loss: 0.070297; batch adversarial loss: 0.464684\n",
      "epoch 82; iter: 0; batch classifier loss: 0.130586; batch adversarial loss: 0.449770\n",
      "epoch 83; iter: 0; batch classifier loss: 0.098675; batch adversarial loss: 0.478661\n",
      "epoch 84; iter: 0; batch classifier loss: 0.134242; batch adversarial loss: 0.422348\n",
      "epoch 85; iter: 0; batch classifier loss: 0.122872; batch adversarial loss: 0.438252\n",
      "epoch 86; iter: 0; batch classifier loss: 0.121639; batch adversarial loss: 0.488770\n",
      "epoch 87; iter: 0; batch classifier loss: 0.068309; batch adversarial loss: 0.399166\n",
      "epoch 88; iter: 0; batch classifier loss: 0.073176; batch adversarial loss: 0.537400\n",
      "epoch 89; iter: 0; batch classifier loss: 0.109679; batch adversarial loss: 0.481879\n",
      "epoch 90; iter: 0; batch classifier loss: 0.076040; batch adversarial loss: 0.482400\n",
      "epoch 91; iter: 0; batch classifier loss: 0.093864; batch adversarial loss: 0.436275\n",
      "epoch 92; iter: 0; batch classifier loss: 0.066619; batch adversarial loss: 0.512548\n",
      "epoch 93; iter: 0; batch classifier loss: 0.084280; batch adversarial loss: 0.451906\n",
      "epoch 94; iter: 0; batch classifier loss: 0.090299; batch adversarial loss: 0.387939\n",
      "epoch 95; iter: 0; batch classifier loss: 0.068860; batch adversarial loss: 0.389470\n",
      "epoch 96; iter: 0; batch classifier loss: 0.099721; batch adversarial loss: 0.508255\n",
      "epoch 97; iter: 0; batch classifier loss: 0.099595; batch adversarial loss: 0.467533\n",
      "epoch 98; iter: 0; batch classifier loss: 0.074695; batch adversarial loss: 0.451791\n",
      "epoch 99; iter: 0; batch classifier loss: 0.074730; batch adversarial loss: 0.544401\n",
      "epoch 100; iter: 0; batch classifier loss: 0.094175; batch adversarial loss: 0.489337\n",
      "epoch 101; iter: 0; batch classifier loss: 0.050941; batch adversarial loss: 0.419889\n",
      "epoch 102; iter: 0; batch classifier loss: 0.104410; batch adversarial loss: 0.453383\n",
      "epoch 103; iter: 0; batch classifier loss: 0.084963; batch adversarial loss: 0.455518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104; iter: 0; batch classifier loss: 0.072444; batch adversarial loss: 0.407293\n",
      "epoch 105; iter: 0; batch classifier loss: 0.076242; batch adversarial loss: 0.428354\n",
      "epoch 106; iter: 0; batch classifier loss: 0.106262; batch adversarial loss: 0.397476\n",
      "epoch 107; iter: 0; batch classifier loss: 0.060306; batch adversarial loss: 0.542290\n",
      "epoch 108; iter: 0; batch classifier loss: 0.052698; batch adversarial loss: 0.417348\n",
      "epoch 109; iter: 0; batch classifier loss: 0.064287; batch adversarial loss: 0.459180\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046931; batch adversarial loss: 0.483020\n",
      "epoch 111; iter: 0; batch classifier loss: 0.062432; batch adversarial loss: 0.479008\n",
      "epoch 112; iter: 0; batch classifier loss: 0.080435; batch adversarial loss: 0.433900\n",
      "epoch 113; iter: 0; batch classifier loss: 0.034009; batch adversarial loss: 0.491227\n",
      "epoch 114; iter: 0; batch classifier loss: 0.039522; batch adversarial loss: 0.558734\n",
      "epoch 115; iter: 0; batch classifier loss: 0.054966; batch adversarial loss: 0.419996\n",
      "epoch 116; iter: 0; batch classifier loss: 0.102468; batch adversarial loss: 0.440247\n",
      "epoch 117; iter: 0; batch classifier loss: 0.100398; batch adversarial loss: 0.517666\n",
      "epoch 118; iter: 0; batch classifier loss: 0.031830; batch adversarial loss: 0.464758\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056085; batch adversarial loss: 0.514704\n",
      "epoch 120; iter: 0; batch classifier loss: 0.039712; batch adversarial loss: 0.434702\n",
      "epoch 121; iter: 0; batch classifier loss: 0.021499; batch adversarial loss: 0.450656\n",
      "epoch 122; iter: 0; batch classifier loss: 0.030646; batch adversarial loss: 0.429210\n",
      "epoch 123; iter: 0; batch classifier loss: 0.050287; batch adversarial loss: 0.387454\n",
      "epoch 124; iter: 0; batch classifier loss: 0.075207; batch adversarial loss: 0.399745\n",
      "epoch 125; iter: 0; batch classifier loss: 0.046111; batch adversarial loss: 0.492120\n",
      "epoch 126; iter: 0; batch classifier loss: 0.039173; batch adversarial loss: 0.427395\n",
      "epoch 127; iter: 0; batch classifier loss: 0.044050; batch adversarial loss: 0.519587\n",
      "epoch 128; iter: 0; batch classifier loss: 0.035590; batch adversarial loss: 0.399666\n",
      "epoch 129; iter: 0; batch classifier loss: 0.046511; batch adversarial loss: 0.457433\n",
      "epoch 130; iter: 0; batch classifier loss: 0.039496; batch adversarial loss: 0.469156\n",
      "epoch 131; iter: 0; batch classifier loss: 0.031710; batch adversarial loss: 0.411809\n",
      "epoch 132; iter: 0; batch classifier loss: 0.034545; batch adversarial loss: 0.550847\n",
      "epoch 133; iter: 0; batch classifier loss: 0.041050; batch adversarial loss: 0.578710\n",
      "epoch 134; iter: 0; batch classifier loss: 0.098314; batch adversarial loss: 0.443275\n",
      "epoch 135; iter: 0; batch classifier loss: 0.051107; batch adversarial loss: 0.452271\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033365; batch adversarial loss: 0.440568\n",
      "epoch 137; iter: 0; batch classifier loss: 0.073533; batch adversarial loss: 0.518881\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048892; batch adversarial loss: 0.488605\n",
      "epoch 139; iter: 0; batch classifier loss: 0.021266; batch adversarial loss: 0.464910\n",
      "epoch 140; iter: 0; batch classifier loss: 0.015834; batch adversarial loss: 0.501702\n",
      "epoch 141; iter: 0; batch classifier loss: 0.036188; batch adversarial loss: 0.475411\n",
      "epoch 142; iter: 0; batch classifier loss: 0.044068; batch adversarial loss: 0.382662\n",
      "epoch 143; iter: 0; batch classifier loss: 0.029088; batch adversarial loss: 0.464433\n",
      "epoch 144; iter: 0; batch classifier loss: 0.016538; batch adversarial loss: 0.417048\n",
      "epoch 145; iter: 0; batch classifier loss: 0.013440; batch adversarial loss: 0.480116\n",
      "epoch 146; iter: 0; batch classifier loss: 0.010968; batch adversarial loss: 0.446468\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029603; batch adversarial loss: 0.512465\n",
      "epoch 148; iter: 0; batch classifier loss: 0.035833; batch adversarial loss: 0.545438\n",
      "epoch 149; iter: 0; batch classifier loss: 0.032532; batch adversarial loss: 0.406617\n",
      "epoch 150; iter: 0; batch classifier loss: 0.018199; batch adversarial loss: 0.443686\n",
      "epoch 151; iter: 0; batch classifier loss: 0.024293; batch adversarial loss: 0.445948\n",
      "epoch 152; iter: 0; batch classifier loss: 0.005955; batch adversarial loss: 0.550545\n",
      "epoch 153; iter: 0; batch classifier loss: 0.035499; batch adversarial loss: 0.477350\n",
      "epoch 154; iter: 0; batch classifier loss: 0.028575; batch adversarial loss: 0.461627\n",
      "epoch 155; iter: 0; batch classifier loss: 0.018269; batch adversarial loss: 0.414992\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022257; batch adversarial loss: 0.448553\n",
      "epoch 157; iter: 0; batch classifier loss: 0.031050; batch adversarial loss: 0.468608\n",
      "epoch 158; iter: 0; batch classifier loss: 0.027949; batch adversarial loss: 0.467710\n",
      "epoch 159; iter: 0; batch classifier loss: 0.026215; batch adversarial loss: 0.456218\n",
      "epoch 160; iter: 0; batch classifier loss: 0.035524; batch adversarial loss: 0.471110\n",
      "epoch 161; iter: 0; batch classifier loss: 0.011238; batch adversarial loss: 0.373212\n",
      "epoch 162; iter: 0; batch classifier loss: 0.021129; batch adversarial loss: 0.419829\n",
      "epoch 163; iter: 0; batch classifier loss: 0.023370; batch adversarial loss: 0.510136\n",
      "epoch 164; iter: 0; batch classifier loss: 0.047811; batch adversarial loss: 0.480178\n",
      "epoch 165; iter: 0; batch classifier loss: 0.008103; batch adversarial loss: 0.415142\n",
      "epoch 166; iter: 0; batch classifier loss: 0.024872; batch adversarial loss: 0.483577\n",
      "epoch 167; iter: 0; batch classifier loss: 0.052439; batch adversarial loss: 0.455374\n",
      "epoch 168; iter: 0; batch classifier loss: 0.036689; batch adversarial loss: 0.413637\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021630; batch adversarial loss: 0.444966\n",
      "epoch 170; iter: 0; batch classifier loss: 0.026443; batch adversarial loss: 0.530459\n",
      "epoch 171; iter: 0; batch classifier loss: 0.040415; batch adversarial loss: 0.371150\n",
      "epoch 172; iter: 0; batch classifier loss: 0.013908; batch adversarial loss: 0.477718\n",
      "epoch 173; iter: 0; batch classifier loss: 0.010498; batch adversarial loss: 0.508508\n",
      "epoch 174; iter: 0; batch classifier loss: 0.018006; batch adversarial loss: 0.486469\n",
      "epoch 175; iter: 0; batch classifier loss: 0.063862; batch adversarial loss: 0.477795\n",
      "epoch 176; iter: 0; batch classifier loss: 0.025022; batch adversarial loss: 0.420597\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021904; batch adversarial loss: 0.507880\n",
      "epoch 178; iter: 0; batch classifier loss: 0.015375; batch adversarial loss: 0.509480\n",
      "epoch 179; iter: 0; batch classifier loss: 0.019985; batch adversarial loss: 0.394461\n",
      "epoch 180; iter: 0; batch classifier loss: 0.015135; batch adversarial loss: 0.443897\n",
      "epoch 181; iter: 0; batch classifier loss: 0.009380; batch adversarial loss: 0.469074\n",
      "epoch 182; iter: 0; batch classifier loss: 0.032794; batch adversarial loss: 0.424699\n",
      "epoch 183; iter: 0; batch classifier loss: 0.022319; batch adversarial loss: 0.421440\n",
      "epoch 184; iter: 0; batch classifier loss: 0.020177; batch adversarial loss: 0.417951\n",
      "epoch 185; iter: 0; batch classifier loss: 0.018349; batch adversarial loss: 0.455173\n",
      "epoch 186; iter: 0; batch classifier loss: 0.025364; batch adversarial loss: 0.535371\n",
      "epoch 187; iter: 0; batch classifier loss: 0.032936; batch adversarial loss: 0.566936\n",
      "epoch 188; iter: 0; batch classifier loss: 0.010001; batch adversarial loss: 0.476394\n",
      "epoch 189; iter: 0; batch classifier loss: 0.006443; batch adversarial loss: 0.493694\n",
      "epoch 190; iter: 0; batch classifier loss: 0.006264; batch adversarial loss: 0.454103\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017817; batch adversarial loss: 0.498242\n",
      "epoch 192; iter: 0; batch classifier loss: 0.012764; batch adversarial loss: 0.467240\n",
      "epoch 193; iter: 0; batch classifier loss: 0.008157; batch adversarial loss: 0.488275\n",
      "epoch 194; iter: 0; batch classifier loss: 0.017515; batch adversarial loss: 0.461474\n",
      "epoch 195; iter: 0; batch classifier loss: 0.060006; batch adversarial loss: 0.367279\n",
      "epoch 196; iter: 0; batch classifier loss: 0.004580; batch adversarial loss: 0.511686\n",
      "epoch 197; iter: 0; batch classifier loss: 0.035678; batch adversarial loss: 0.444792\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037106; batch adversarial loss: 0.422962\n",
      "epoch 199; iter: 0; batch classifier loss: 0.011553; batch adversarial loss: 0.477999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.676631; batch adversarial loss: 0.579236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386569; batch adversarial loss: 0.597875\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366105; batch adversarial loss: 0.644444\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361212; batch adversarial loss: 0.602791\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422691; batch adversarial loss: 0.597428\n",
      "epoch 5; iter: 0; batch classifier loss: 0.388075; batch adversarial loss: 0.575164\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500265; batch adversarial loss: 0.581089\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629925; batch adversarial loss: 0.652151\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645530; batch adversarial loss: 0.581786\n",
      "epoch 9; iter: 0; batch classifier loss: 0.633719; batch adversarial loss: 0.606921\n",
      "epoch 10; iter: 0; batch classifier loss: 0.674483; batch adversarial loss: 0.538953\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528598; batch adversarial loss: 0.562177\n",
      "epoch 12; iter: 0; batch classifier loss: 0.358199; batch adversarial loss: 0.539608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.290865; batch adversarial loss: 0.517105\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303071; batch adversarial loss: 0.489055\n",
      "epoch 15; iter: 0; batch classifier loss: 0.224438; batch adversarial loss: 0.479774\n",
      "epoch 16; iter: 0; batch classifier loss: 0.252972; batch adversarial loss: 0.454124\n",
      "epoch 17; iter: 0; batch classifier loss: 0.192421; batch adversarial loss: 0.475769\n",
      "epoch 18; iter: 0; batch classifier loss: 0.200944; batch adversarial loss: 0.482420\n",
      "epoch 19; iter: 0; batch classifier loss: 0.234983; batch adversarial loss: 0.456895\n",
      "epoch 20; iter: 0; batch classifier loss: 0.197610; batch adversarial loss: 0.440147\n",
      "epoch 21; iter: 0; batch classifier loss: 0.169962; batch adversarial loss: 0.552319\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236118; batch adversarial loss: 0.470116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242158; batch adversarial loss: 0.442437\n",
      "epoch 24; iter: 0; batch classifier loss: 0.178662; batch adversarial loss: 0.633521\n",
      "epoch 25; iter: 0; batch classifier loss: 0.148995; batch adversarial loss: 0.439348\n",
      "epoch 26; iter: 0; batch classifier loss: 0.194151; batch adversarial loss: 0.436502\n",
      "epoch 27; iter: 0; batch classifier loss: 0.199348; batch adversarial loss: 0.481970\n",
      "epoch 28; iter: 0; batch classifier loss: 0.155913; batch adversarial loss: 0.503475\n",
      "epoch 29; iter: 0; batch classifier loss: 0.164033; batch adversarial loss: 0.548960\n",
      "epoch 30; iter: 0; batch classifier loss: 0.154380; batch adversarial loss: 0.431303\n",
      "epoch 31; iter: 0; batch classifier loss: 0.117277; batch adversarial loss: 0.495628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.168493; batch adversarial loss: 0.450599\n",
      "epoch 33; iter: 0; batch classifier loss: 0.138528; batch adversarial loss: 0.462352\n",
      "epoch 34; iter: 0; batch classifier loss: 0.197139; batch adversarial loss: 0.505106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.177306; batch adversarial loss: 0.531568\n",
      "epoch 36; iter: 0; batch classifier loss: 0.154133; batch adversarial loss: 0.480927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.206199; batch adversarial loss: 0.353349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.170760; batch adversarial loss: 0.427742\n",
      "epoch 39; iter: 0; batch classifier loss: 0.206921; batch adversarial loss: 0.436972\n",
      "epoch 40; iter: 0; batch classifier loss: 0.155168; batch adversarial loss: 0.375442\n",
      "epoch 41; iter: 0; batch classifier loss: 0.133304; batch adversarial loss: 0.462260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.153603; batch adversarial loss: 0.406011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.149103; batch adversarial loss: 0.490575\n",
      "epoch 44; iter: 0; batch classifier loss: 0.202847; batch adversarial loss: 0.517317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.126240; batch adversarial loss: 0.593887\n",
      "epoch 46; iter: 0; batch classifier loss: 0.150583; batch adversarial loss: 0.414297\n",
      "epoch 47; iter: 0; batch classifier loss: 0.172718; batch adversarial loss: 0.353664\n",
      "epoch 48; iter: 0; batch classifier loss: 0.134258; batch adversarial loss: 0.455484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.176656; batch adversarial loss: 0.406144\n",
      "epoch 50; iter: 0; batch classifier loss: 0.232380; batch adversarial loss: 0.449509\n",
      "epoch 51; iter: 0; batch classifier loss: 0.184634; batch adversarial loss: 0.455241\n",
      "epoch 52; iter: 0; batch classifier loss: 0.198145; batch adversarial loss: 0.460758\n",
      "epoch 53; iter: 0; batch classifier loss: 0.217204; batch adversarial loss: 0.399796\n",
      "epoch 54; iter: 0; batch classifier loss: 0.150893; batch adversarial loss: 0.455251\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237311; batch adversarial loss: 0.432294\n",
      "epoch 56; iter: 0; batch classifier loss: 0.210038; batch adversarial loss: 0.518435\n",
      "epoch 57; iter: 0; batch classifier loss: 0.181848; batch adversarial loss: 0.448890\n",
      "epoch 58; iter: 0; batch classifier loss: 0.177609; batch adversarial loss: 0.508935\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161605; batch adversarial loss: 0.435602\n",
      "epoch 60; iter: 0; batch classifier loss: 0.240577; batch adversarial loss: 0.432807\n",
      "epoch 61; iter: 0; batch classifier loss: 0.234305; batch adversarial loss: 0.422464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.185043; batch adversarial loss: 0.496686\n",
      "epoch 63; iter: 0; batch classifier loss: 0.166206; batch adversarial loss: 0.434377\n",
      "epoch 64; iter: 0; batch classifier loss: 0.153926; batch adversarial loss: 0.483911\n",
      "epoch 65; iter: 0; batch classifier loss: 0.125582; batch adversarial loss: 0.471091\n",
      "epoch 66; iter: 0; batch classifier loss: 0.121165; batch adversarial loss: 0.370278\n",
      "epoch 67; iter: 0; batch classifier loss: 0.118296; batch adversarial loss: 0.419303\n",
      "epoch 68; iter: 0; batch classifier loss: 0.156836; batch adversarial loss: 0.470621\n",
      "epoch 69; iter: 0; batch classifier loss: 0.149934; batch adversarial loss: 0.420983\n",
      "epoch 70; iter: 0; batch classifier loss: 0.138121; batch adversarial loss: 0.383285\n",
      "epoch 71; iter: 0; batch classifier loss: 0.169532; batch adversarial loss: 0.521286\n",
      "epoch 72; iter: 0; batch classifier loss: 0.149818; batch adversarial loss: 0.509095\n",
      "epoch 73; iter: 0; batch classifier loss: 0.193741; batch adversarial loss: 0.433680\n",
      "epoch 74; iter: 0; batch classifier loss: 0.148536; batch adversarial loss: 0.406729\n",
      "epoch 75; iter: 0; batch classifier loss: 0.250843; batch adversarial loss: 0.384774\n",
      "epoch 76; iter: 0; batch classifier loss: 0.152142; batch adversarial loss: 0.497074\n",
      "epoch 77; iter: 0; batch classifier loss: 0.193982; batch adversarial loss: 0.396351\n",
      "epoch 78; iter: 0; batch classifier loss: 0.148913; batch adversarial loss: 0.497235\n",
      "epoch 79; iter: 0; batch classifier loss: 0.184587; batch adversarial loss: 0.508878\n",
      "epoch 80; iter: 0; batch classifier loss: 0.245585; batch adversarial loss: 0.483764\n",
      "epoch 81; iter: 0; batch classifier loss: 0.147919; batch adversarial loss: 0.508588\n",
      "epoch 82; iter: 0; batch classifier loss: 0.149145; batch adversarial loss: 0.496015\n",
      "epoch 83; iter: 0; batch classifier loss: 0.206030; batch adversarial loss: 0.407809\n",
      "epoch 84; iter: 0; batch classifier loss: 0.149539; batch adversarial loss: 0.445616\n",
      "epoch 85; iter: 0; batch classifier loss: 0.127966; batch adversarial loss: 0.485089\n",
      "epoch 86; iter: 0; batch classifier loss: 0.115515; batch adversarial loss: 0.482146\n",
      "epoch 87; iter: 0; batch classifier loss: 0.137736; batch adversarial loss: 0.496302\n",
      "epoch 88; iter: 0; batch classifier loss: 0.149839; batch adversarial loss: 0.409265\n",
      "epoch 89; iter: 0; batch classifier loss: 0.140890; batch adversarial loss: 0.459428\n",
      "epoch 90; iter: 0; batch classifier loss: 0.156345; batch adversarial loss: 0.433429\n",
      "epoch 91; iter: 0; batch classifier loss: 0.216255; batch adversarial loss: 0.409069\n",
      "epoch 92; iter: 0; batch classifier loss: 0.155637; batch adversarial loss: 0.445922\n",
      "epoch 93; iter: 0; batch classifier loss: 0.136191; batch adversarial loss: 0.409392\n",
      "epoch 94; iter: 0; batch classifier loss: 0.194113; batch adversarial loss: 0.495311\n",
      "epoch 95; iter: 0; batch classifier loss: 0.156815; batch adversarial loss: 0.558340\n",
      "epoch 96; iter: 0; batch classifier loss: 0.197438; batch adversarial loss: 0.433999\n",
      "epoch 97; iter: 0; batch classifier loss: 0.149075; batch adversarial loss: 0.408778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98; iter: 0; batch classifier loss: 0.153069; batch adversarial loss: 0.458624\n",
      "epoch 99; iter: 0; batch classifier loss: 0.187659; batch adversarial loss: 0.433560\n",
      "epoch 100; iter: 0; batch classifier loss: 0.219619; batch adversarial loss: 0.471427\n",
      "epoch 101; iter: 0; batch classifier loss: 0.073628; batch adversarial loss: 0.482684\n",
      "epoch 102; iter: 0; batch classifier loss: 0.069932; batch adversarial loss: 0.544012\n",
      "epoch 103; iter: 0; batch classifier loss: 0.053423; batch adversarial loss: 0.494428\n",
      "epoch 104; iter: 0; batch classifier loss: 0.071237; batch adversarial loss: 0.409838\n",
      "epoch 105; iter: 0; batch classifier loss: 0.054682; batch adversarial loss: 0.506538\n",
      "epoch 106; iter: 0; batch classifier loss: 0.077278; batch adversarial loss: 0.565158\n",
      "epoch 107; iter: 0; batch classifier loss: 0.098704; batch adversarial loss: 0.430147\n",
      "epoch 108; iter: 0; batch classifier loss: 0.060146; batch adversarial loss: 0.391205\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076588; batch adversarial loss: 0.298840\n",
      "epoch 110; iter: 0; batch classifier loss: 0.064152; batch adversarial loss: 0.456530\n",
      "epoch 111; iter: 0; batch classifier loss: 0.046609; batch adversarial loss: 0.435540\n",
      "epoch 112; iter: 0; batch classifier loss: 0.061097; batch adversarial loss: 0.436053\n",
      "epoch 113; iter: 0; batch classifier loss: 0.030492; batch adversarial loss: 0.494471\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051288; batch adversarial loss: 0.462135\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072826; batch adversarial loss: 0.467478\n",
      "epoch 116; iter: 0; batch classifier loss: 0.058324; batch adversarial loss: 0.388202\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056817; batch adversarial loss: 0.484220\n",
      "epoch 118; iter: 0; batch classifier loss: 0.039559; batch adversarial loss: 0.488287\n",
      "epoch 119; iter: 0; batch classifier loss: 0.050055; batch adversarial loss: 0.442192\n",
      "epoch 120; iter: 0; batch classifier loss: 0.055487; batch adversarial loss: 0.344772\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036566; batch adversarial loss: 0.453565\n",
      "epoch 122; iter: 0; batch classifier loss: 0.064746; batch adversarial loss: 0.499468\n",
      "epoch 123; iter: 0; batch classifier loss: 0.027686; batch adversarial loss: 0.449816\n",
      "epoch 124; iter: 0; batch classifier loss: 0.019925; batch adversarial loss: 0.464458\n",
      "epoch 125; iter: 0; batch classifier loss: 0.049436; batch adversarial loss: 0.473995\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045861; batch adversarial loss: 0.393314\n",
      "epoch 127; iter: 0; batch classifier loss: 0.026160; batch adversarial loss: 0.500170\n",
      "epoch 128; iter: 0; batch classifier loss: 0.044480; batch adversarial loss: 0.401688\n",
      "epoch 129; iter: 0; batch classifier loss: 0.042893; batch adversarial loss: 0.445986\n",
      "epoch 130; iter: 0; batch classifier loss: 0.046554; batch adversarial loss: 0.417238\n",
      "epoch 131; iter: 0; batch classifier loss: 0.037842; batch adversarial loss: 0.495294\n",
      "epoch 132; iter: 0; batch classifier loss: 0.057935; batch adversarial loss: 0.401825\n",
      "epoch 133; iter: 0; batch classifier loss: 0.053713; batch adversarial loss: 0.487396\n",
      "epoch 134; iter: 0; batch classifier loss: 0.040215; batch adversarial loss: 0.399822\n",
      "epoch 135; iter: 0; batch classifier loss: 0.017004; batch adversarial loss: 0.414441\n",
      "epoch 136; iter: 0; batch classifier loss: 0.039380; batch adversarial loss: 0.520264\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036608; batch adversarial loss: 0.464702\n",
      "epoch 138; iter: 0; batch classifier loss: 0.026581; batch adversarial loss: 0.491846\n",
      "epoch 139; iter: 0; batch classifier loss: 0.048705; batch adversarial loss: 0.447491\n",
      "epoch 140; iter: 0; batch classifier loss: 0.048501; batch adversarial loss: 0.473892\n",
      "epoch 141; iter: 0; batch classifier loss: 0.044259; batch adversarial loss: 0.351517\n",
      "epoch 142; iter: 0; batch classifier loss: 0.038769; batch adversarial loss: 0.501194\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050627; batch adversarial loss: 0.396131\n",
      "epoch 144; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.434447\n",
      "epoch 145; iter: 0; batch classifier loss: 0.039756; batch adversarial loss: 0.430943\n",
      "epoch 146; iter: 0; batch classifier loss: 0.015798; batch adversarial loss: 0.446320\n",
      "epoch 147; iter: 0; batch classifier loss: 0.033027; batch adversarial loss: 0.459604\n",
      "epoch 148; iter: 0; batch classifier loss: 0.045322; batch adversarial loss: 0.426857\n",
      "epoch 149; iter: 0; batch classifier loss: 0.015907; batch adversarial loss: 0.499302\n",
      "epoch 150; iter: 0; batch classifier loss: 0.027302; batch adversarial loss: 0.402322\n",
      "epoch 151; iter: 0; batch classifier loss: 0.017396; batch adversarial loss: 0.462362\n",
      "epoch 152; iter: 0; batch classifier loss: 0.059176; batch adversarial loss: 0.437739\n",
      "epoch 153; iter: 0; batch classifier loss: 0.030867; batch adversarial loss: 0.536959\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032293; batch adversarial loss: 0.447290\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029573; batch adversarial loss: 0.447172\n",
      "epoch 156; iter: 0; batch classifier loss: 0.028798; batch adversarial loss: 0.490595\n",
      "epoch 157; iter: 0; batch classifier loss: 0.020857; batch adversarial loss: 0.351077\n",
      "epoch 158; iter: 0; batch classifier loss: 0.045056; batch adversarial loss: 0.495142\n",
      "epoch 159; iter: 0; batch classifier loss: 0.027381; batch adversarial loss: 0.484818\n",
      "epoch 160; iter: 0; batch classifier loss: 0.007827; batch adversarial loss: 0.420167\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027632; batch adversarial loss: 0.546544\n",
      "epoch 162; iter: 0; batch classifier loss: 0.014572; batch adversarial loss: 0.418923\n",
      "epoch 163; iter: 0; batch classifier loss: 0.029380; batch adversarial loss: 0.493819\n",
      "epoch 164; iter: 0; batch classifier loss: 0.020926; batch adversarial loss: 0.504994\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043390; batch adversarial loss: 0.444703\n",
      "epoch 166; iter: 0; batch classifier loss: 0.033125; batch adversarial loss: 0.388731\n",
      "epoch 167; iter: 0; batch classifier loss: 0.006883; batch adversarial loss: 0.396189\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015998; batch adversarial loss: 0.468247\n",
      "epoch 169; iter: 0; batch classifier loss: 0.031234; batch adversarial loss: 0.418861\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032351; batch adversarial loss: 0.475502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.023668; batch adversarial loss: 0.496122\n",
      "epoch 172; iter: 0; batch classifier loss: 0.022778; batch adversarial loss: 0.514314\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006668; batch adversarial loss: 0.556929\n",
      "epoch 174; iter: 0; batch classifier loss: 0.029538; batch adversarial loss: 0.502937\n",
      "epoch 175; iter: 0; batch classifier loss: 0.014102; batch adversarial loss: 0.503909\n",
      "epoch 176; iter: 0; batch classifier loss: 0.017038; batch adversarial loss: 0.434298\n",
      "epoch 177; iter: 0; batch classifier loss: 0.022411; batch adversarial loss: 0.491459\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041415; batch adversarial loss: 0.407362\n",
      "epoch 179; iter: 0; batch classifier loss: 0.014367; batch adversarial loss: 0.430459\n",
      "epoch 180; iter: 0; batch classifier loss: 0.032133; batch adversarial loss: 0.515994\n",
      "epoch 181; iter: 0; batch classifier loss: 0.027351; batch adversarial loss: 0.416842\n",
      "epoch 182; iter: 0; batch classifier loss: 0.028101; batch adversarial loss: 0.455214\n",
      "epoch 183; iter: 0; batch classifier loss: 0.011802; batch adversarial loss: 0.539386\n",
      "epoch 184; iter: 0; batch classifier loss: 0.012272; batch adversarial loss: 0.489702\n",
      "epoch 185; iter: 0; batch classifier loss: 0.027430; batch adversarial loss: 0.509570\n",
      "epoch 186; iter: 0; batch classifier loss: 0.008776; batch adversarial loss: 0.451839\n",
      "epoch 187; iter: 0; batch classifier loss: 0.024070; batch adversarial loss: 0.552994\n",
      "epoch 188; iter: 0; batch classifier loss: 0.017748; batch adversarial loss: 0.378535\n",
      "epoch 189; iter: 0; batch classifier loss: 0.028899; batch adversarial loss: 0.439772\n",
      "epoch 190; iter: 0; batch classifier loss: 0.021520; batch adversarial loss: 0.447942\n",
      "epoch 191; iter: 0; batch classifier loss: 0.012728; batch adversarial loss: 0.409777\n",
      "epoch 192; iter: 0; batch classifier loss: 0.006335; batch adversarial loss: 0.514255\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043556; batch adversarial loss: 0.418664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194; iter: 0; batch classifier loss: 0.020861; batch adversarial loss: 0.387427\n",
      "epoch 195; iter: 0; batch classifier loss: 0.023128; batch adversarial loss: 0.419229\n",
      "epoch 196; iter: 0; batch classifier loss: 0.013898; batch adversarial loss: 0.435610\n",
      "epoch 197; iter: 0; batch classifier loss: 0.040207; batch adversarial loss: 0.515310\n",
      "epoch 198; iter: 0; batch classifier loss: 0.031064; batch adversarial loss: 0.502345\n",
      "epoch 199; iter: 0; batch classifier loss: 0.021759; batch adversarial loss: 0.374000\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679882; batch adversarial loss: 0.573523\n",
      "epoch 1; iter: 0; batch classifier loss: 0.513307; batch adversarial loss: 0.616172\n",
      "epoch 2; iter: 0; batch classifier loss: 0.500052; batch adversarial loss: 0.594312\n",
      "epoch 3; iter: 0; batch classifier loss: 0.294060; batch adversarial loss: 0.584732\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369055; batch adversarial loss: 0.554947\n",
      "epoch 5; iter: 0; batch classifier loss: 0.479543; batch adversarial loss: 0.609471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368529; batch adversarial loss: 0.568601\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504103; batch adversarial loss: 0.558842\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573954; batch adversarial loss: 0.590880\n",
      "epoch 9; iter: 0; batch classifier loss: 0.660892; batch adversarial loss: 0.555665\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511144; batch adversarial loss: 0.578137\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458320; batch adversarial loss: 0.585764\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397840; batch adversarial loss: 0.461776\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379920; batch adversarial loss: 0.476769\n",
      "epoch 14; iter: 0; batch classifier loss: 0.347689; batch adversarial loss: 0.433975\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256928; batch adversarial loss: 0.555903\n",
      "epoch 16; iter: 0; batch classifier loss: 0.276530; batch adversarial loss: 0.462762\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301999; batch adversarial loss: 0.570417\n",
      "epoch 18; iter: 0; batch classifier loss: 0.213900; batch adversarial loss: 0.442862\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281488; batch adversarial loss: 0.513562\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271615; batch adversarial loss: 0.569251\n",
      "epoch 21; iter: 0; batch classifier loss: 0.246676; batch adversarial loss: 0.505820\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263989; batch adversarial loss: 0.453019\n",
      "epoch 23; iter: 0; batch classifier loss: 0.243209; batch adversarial loss: 0.480695\n",
      "epoch 24; iter: 0; batch classifier loss: 0.262267; batch adversarial loss: 0.408783\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213730; batch adversarial loss: 0.480479\n",
      "epoch 26; iter: 0; batch classifier loss: 0.328101; batch adversarial loss: 0.413265\n",
      "epoch 27; iter: 0; batch classifier loss: 0.237742; batch adversarial loss: 0.411063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.210150; batch adversarial loss: 0.535987\n",
      "epoch 29; iter: 0; batch classifier loss: 0.136384; batch adversarial loss: 0.508728\n",
      "epoch 30; iter: 0; batch classifier loss: 0.205145; batch adversarial loss: 0.413899\n",
      "epoch 31; iter: 0; batch classifier loss: 0.178041; batch adversarial loss: 0.484985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.210613; batch adversarial loss: 0.404231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.188031; batch adversarial loss: 0.493705\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212885; batch adversarial loss: 0.465451\n",
      "epoch 35; iter: 0; batch classifier loss: 0.171498; batch adversarial loss: 0.386565\n",
      "epoch 36; iter: 0; batch classifier loss: 0.161804; batch adversarial loss: 0.510864\n",
      "epoch 37; iter: 0; batch classifier loss: 0.182437; batch adversarial loss: 0.450781\n",
      "epoch 38; iter: 0; batch classifier loss: 0.207355; batch adversarial loss: 0.385215\n",
      "epoch 39; iter: 0; batch classifier loss: 0.148790; batch adversarial loss: 0.464646\n",
      "epoch 40; iter: 0; batch classifier loss: 0.197598; batch adversarial loss: 0.520852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.150999; batch adversarial loss: 0.495592\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205982; batch adversarial loss: 0.407507\n",
      "epoch 43; iter: 0; batch classifier loss: 0.179781; batch adversarial loss: 0.458498\n",
      "epoch 44; iter: 0; batch classifier loss: 0.217642; batch adversarial loss: 0.327897\n",
      "epoch 45; iter: 0; batch classifier loss: 0.216852; batch adversarial loss: 0.416935\n",
      "epoch 46; iter: 0; batch classifier loss: 0.166629; batch adversarial loss: 0.367224\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259582; batch adversarial loss: 0.420858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.149768; batch adversarial loss: 0.465534\n",
      "epoch 49; iter: 0; batch classifier loss: 0.231120; batch adversarial loss: 0.374966\n",
      "epoch 50; iter: 0; batch classifier loss: 0.133529; batch adversarial loss: 0.467492\n",
      "epoch 51; iter: 0; batch classifier loss: 0.205766; batch adversarial loss: 0.390398\n",
      "epoch 52; iter: 0; batch classifier loss: 0.151908; batch adversarial loss: 0.541600\n",
      "epoch 53; iter: 0; batch classifier loss: 0.175873; batch adversarial loss: 0.432735\n",
      "epoch 54; iter: 0; batch classifier loss: 0.213509; batch adversarial loss: 0.384423\n",
      "epoch 55; iter: 0; batch classifier loss: 0.221969; batch adversarial loss: 0.436570\n",
      "epoch 56; iter: 0; batch classifier loss: 0.264960; batch adversarial loss: 0.473675\n",
      "epoch 57; iter: 0; batch classifier loss: 0.190751; batch adversarial loss: 0.592326\n",
      "epoch 58; iter: 0; batch classifier loss: 0.196988; batch adversarial loss: 0.423061\n",
      "epoch 59; iter: 0; batch classifier loss: 0.230268; batch adversarial loss: 0.408570\n",
      "epoch 60; iter: 0; batch classifier loss: 0.173443; batch adversarial loss: 0.481219\n",
      "epoch 61; iter: 0; batch classifier loss: 0.240294; batch adversarial loss: 0.396634\n",
      "epoch 62; iter: 0; batch classifier loss: 0.190554; batch adversarial loss: 0.449094\n",
      "epoch 63; iter: 0; batch classifier loss: 0.211957; batch adversarial loss: 0.424714\n",
      "epoch 64; iter: 0; batch classifier loss: 0.189394; batch adversarial loss: 0.446278\n",
      "epoch 65; iter: 0; batch classifier loss: 0.206164; batch adversarial loss: 0.386061\n",
      "epoch 66; iter: 0; batch classifier loss: 0.234784; batch adversarial loss: 0.385821\n",
      "epoch 67; iter: 0; batch classifier loss: 0.253531; batch adversarial loss: 0.483168\n",
      "epoch 68; iter: 0; batch classifier loss: 0.160452; batch adversarial loss: 0.446591\n",
      "epoch 69; iter: 0; batch classifier loss: 0.136071; batch adversarial loss: 0.557532\n",
      "epoch 70; iter: 0; batch classifier loss: 0.243026; batch adversarial loss: 0.458113\n",
      "epoch 71; iter: 0; batch classifier loss: 0.294020; batch adversarial loss: 0.372476\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187974; batch adversarial loss: 0.470860\n",
      "epoch 73; iter: 0; batch classifier loss: 0.249784; batch adversarial loss: 0.409292\n",
      "epoch 74; iter: 0; batch classifier loss: 0.245318; batch adversarial loss: 0.471336\n",
      "epoch 75; iter: 0; batch classifier loss: 0.197215; batch adversarial loss: 0.458353\n",
      "epoch 76; iter: 0; batch classifier loss: 0.230360; batch adversarial loss: 0.459137\n",
      "epoch 77; iter: 0; batch classifier loss: 0.136964; batch adversarial loss: 0.569070\n",
      "epoch 78; iter: 0; batch classifier loss: 0.123374; batch adversarial loss: 0.457780\n",
      "epoch 79; iter: 0; batch classifier loss: 0.070177; batch adversarial loss: 0.469277\n",
      "epoch 80; iter: 0; batch classifier loss: 0.126264; batch adversarial loss: 0.403734\n",
      "epoch 81; iter: 0; batch classifier loss: 0.076133; batch adversarial loss: 0.499650\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065147; batch adversarial loss: 0.369144\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087999; batch adversarial loss: 0.395904\n",
      "epoch 84; iter: 0; batch classifier loss: 0.106181; batch adversarial loss: 0.392770\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057923; batch adversarial loss: 0.430528\n",
      "epoch 86; iter: 0; batch classifier loss: 0.091403; batch adversarial loss: 0.443572\n",
      "epoch 87; iter: 0; batch classifier loss: 0.044112; batch adversarial loss: 0.478095\n",
      "epoch 88; iter: 0; batch classifier loss: 0.095540; batch adversarial loss: 0.389382\n",
      "epoch 89; iter: 0; batch classifier loss: 0.078520; batch adversarial loss: 0.488527\n",
      "epoch 90; iter: 0; batch classifier loss: 0.063178; batch adversarial loss: 0.498088\n",
      "epoch 91; iter: 0; batch classifier loss: 0.083628; batch adversarial loss: 0.455921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 0; batch classifier loss: 0.068697; batch adversarial loss: 0.460364\n",
      "epoch 93; iter: 0; batch classifier loss: 0.067205; batch adversarial loss: 0.531028\n",
      "epoch 94; iter: 0; batch classifier loss: 0.079609; batch adversarial loss: 0.394318\n",
      "epoch 95; iter: 0; batch classifier loss: 0.058452; batch adversarial loss: 0.414969\n",
      "epoch 96; iter: 0; batch classifier loss: 0.084734; batch adversarial loss: 0.427638\n",
      "epoch 97; iter: 0; batch classifier loss: 0.053860; batch adversarial loss: 0.517324\n",
      "epoch 98; iter: 0; batch classifier loss: 0.059882; batch adversarial loss: 0.484453\n",
      "epoch 99; iter: 0; batch classifier loss: 0.088888; batch adversarial loss: 0.465856\n",
      "epoch 100; iter: 0; batch classifier loss: 0.093658; batch adversarial loss: 0.363164\n",
      "epoch 101; iter: 0; batch classifier loss: 0.053209; batch adversarial loss: 0.429616\n",
      "epoch 102; iter: 0; batch classifier loss: 0.055465; batch adversarial loss: 0.398570\n",
      "epoch 103; iter: 0; batch classifier loss: 0.060325; batch adversarial loss: 0.531576\n",
      "epoch 104; iter: 0; batch classifier loss: 0.060931; batch adversarial loss: 0.494698\n",
      "epoch 105; iter: 0; batch classifier loss: 0.055006; batch adversarial loss: 0.411294\n",
      "epoch 106; iter: 0; batch classifier loss: 0.041533; batch adversarial loss: 0.467143\n",
      "epoch 107; iter: 0; batch classifier loss: 0.033893; batch adversarial loss: 0.516725\n",
      "epoch 108; iter: 0; batch classifier loss: 0.079541; batch adversarial loss: 0.408309\n",
      "epoch 109; iter: 0; batch classifier loss: 0.026856; batch adversarial loss: 0.486251\n",
      "epoch 110; iter: 0; batch classifier loss: 0.047715; batch adversarial loss: 0.381682\n",
      "epoch 111; iter: 0; batch classifier loss: 0.047124; batch adversarial loss: 0.357831\n",
      "epoch 112; iter: 0; batch classifier loss: 0.050858; batch adversarial loss: 0.416663\n",
      "epoch 113; iter: 0; batch classifier loss: 0.029483; batch adversarial loss: 0.502934\n",
      "epoch 114; iter: 0; batch classifier loss: 0.040474; batch adversarial loss: 0.527496\n",
      "epoch 115; iter: 0; batch classifier loss: 0.061029; batch adversarial loss: 0.444991\n",
      "epoch 116; iter: 0; batch classifier loss: 0.040742; batch adversarial loss: 0.392664\n",
      "epoch 117; iter: 0; batch classifier loss: 0.076294; batch adversarial loss: 0.438578\n",
      "epoch 118; iter: 0; batch classifier loss: 0.077578; batch adversarial loss: 0.449271\n",
      "epoch 119; iter: 0; batch classifier loss: 0.031343; batch adversarial loss: 0.449114\n",
      "epoch 120; iter: 0; batch classifier loss: 0.041243; batch adversarial loss: 0.455533\n",
      "epoch 121; iter: 0; batch classifier loss: 0.057417; batch adversarial loss: 0.495528\n",
      "epoch 122; iter: 0; batch classifier loss: 0.035924; batch adversarial loss: 0.532903\n",
      "epoch 123; iter: 0; batch classifier loss: 0.053530; batch adversarial loss: 0.384480\n",
      "epoch 124; iter: 0; batch classifier loss: 0.065583; batch adversarial loss: 0.514205\n",
      "epoch 125; iter: 0; batch classifier loss: 0.055585; batch adversarial loss: 0.401476\n",
      "epoch 126; iter: 0; batch classifier loss: 0.055038; batch adversarial loss: 0.565152\n",
      "epoch 127; iter: 0; batch classifier loss: 0.052998; batch adversarial loss: 0.446372\n",
      "epoch 128; iter: 0; batch classifier loss: 0.042916; batch adversarial loss: 0.516720\n",
      "epoch 129; iter: 0; batch classifier loss: 0.057649; batch adversarial loss: 0.377491\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057709; batch adversarial loss: 0.470556\n",
      "epoch 131; iter: 0; batch classifier loss: 0.071240; batch adversarial loss: 0.431394\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024836; batch adversarial loss: 0.342753\n",
      "epoch 133; iter: 0; batch classifier loss: 0.028676; batch adversarial loss: 0.389960\n",
      "epoch 134; iter: 0; batch classifier loss: 0.060114; batch adversarial loss: 0.396520\n",
      "epoch 135; iter: 0; batch classifier loss: 0.048727; batch adversarial loss: 0.399438\n",
      "epoch 136; iter: 0; batch classifier loss: 0.033368; batch adversarial loss: 0.438068\n",
      "epoch 137; iter: 0; batch classifier loss: 0.018186; batch adversarial loss: 0.365516\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048673; batch adversarial loss: 0.405897\n",
      "epoch 139; iter: 0; batch classifier loss: 0.019766; batch adversarial loss: 0.467478\n",
      "epoch 140; iter: 0; batch classifier loss: 0.060487; batch adversarial loss: 0.443445\n",
      "epoch 141; iter: 0; batch classifier loss: 0.018936; batch adversarial loss: 0.466043\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036990; batch adversarial loss: 0.417091\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037555; batch adversarial loss: 0.400416\n",
      "epoch 144; iter: 0; batch classifier loss: 0.031300; batch adversarial loss: 0.408366\n",
      "epoch 145; iter: 0; batch classifier loss: 0.018576; batch adversarial loss: 0.498066\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040283; batch adversarial loss: 0.493315\n",
      "epoch 147; iter: 0; batch classifier loss: 0.024114; batch adversarial loss: 0.542751\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013498; batch adversarial loss: 0.377882\n",
      "epoch 149; iter: 0; batch classifier loss: 0.044569; batch adversarial loss: 0.322234\n",
      "epoch 150; iter: 0; batch classifier loss: 0.048390; batch adversarial loss: 0.491529\n",
      "epoch 151; iter: 0; batch classifier loss: 0.015363; batch adversarial loss: 0.477292\n",
      "epoch 152; iter: 0; batch classifier loss: 0.025089; batch adversarial loss: 0.509215\n",
      "epoch 153; iter: 0; batch classifier loss: 0.011259; batch adversarial loss: 0.469766\n",
      "epoch 154; iter: 0; batch classifier loss: 0.011760; batch adversarial loss: 0.366700\n",
      "epoch 155; iter: 0; batch classifier loss: 0.029429; batch adversarial loss: 0.522024\n",
      "epoch 156; iter: 0; batch classifier loss: 0.025924; batch adversarial loss: 0.535527\n",
      "epoch 157; iter: 0; batch classifier loss: 0.013547; batch adversarial loss: 0.386030\n",
      "epoch 158; iter: 0; batch classifier loss: 0.032593; batch adversarial loss: 0.432189\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017946; batch adversarial loss: 0.462012\n",
      "epoch 160; iter: 0; batch classifier loss: 0.047299; batch adversarial loss: 0.528688\n",
      "epoch 161; iter: 0; batch classifier loss: 0.035672; batch adversarial loss: 0.446873\n",
      "epoch 162; iter: 0; batch classifier loss: 0.031050; batch adversarial loss: 0.425123\n",
      "epoch 163; iter: 0; batch classifier loss: 0.035041; batch adversarial loss: 0.432651\n",
      "epoch 164; iter: 0; batch classifier loss: 0.013915; batch adversarial loss: 0.394625\n",
      "epoch 165; iter: 0; batch classifier loss: 0.046189; batch adversarial loss: 0.434002\n",
      "epoch 166; iter: 0; batch classifier loss: 0.010204; batch adversarial loss: 0.450838\n",
      "epoch 167; iter: 0; batch classifier loss: 0.027186; batch adversarial loss: 0.416408\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022367; batch adversarial loss: 0.475967\n",
      "epoch 169; iter: 0; batch classifier loss: 0.017719; batch adversarial loss: 0.550460\n",
      "epoch 170; iter: 0; batch classifier loss: 0.024081; batch adversarial loss: 0.427632\n",
      "epoch 171; iter: 0; batch classifier loss: 0.026689; batch adversarial loss: 0.491210\n",
      "epoch 172; iter: 0; batch classifier loss: 0.036490; batch adversarial loss: 0.524326\n",
      "epoch 173; iter: 0; batch classifier loss: 0.034867; batch adversarial loss: 0.410487\n",
      "epoch 174; iter: 0; batch classifier loss: 0.026119; batch adversarial loss: 0.551380\n",
      "epoch 175; iter: 0; batch classifier loss: 0.007453; batch adversarial loss: 0.359326\n",
      "epoch 176; iter: 0; batch classifier loss: 0.009190; batch adversarial loss: 0.431569\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021680; batch adversarial loss: 0.383072\n",
      "epoch 178; iter: 0; batch classifier loss: 0.021525; batch adversarial loss: 0.442822\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012192; batch adversarial loss: 0.418354\n",
      "epoch 180; iter: 0; batch classifier loss: 0.019890; batch adversarial loss: 0.482777\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029313; batch adversarial loss: 0.492722\n",
      "epoch 182; iter: 0; batch classifier loss: 0.018024; batch adversarial loss: 0.425471\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021612; batch adversarial loss: 0.514159\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016096; batch adversarial loss: 0.420422\n",
      "epoch 185; iter: 0; batch classifier loss: 0.028881; batch adversarial loss: 0.447351\n",
      "epoch 186; iter: 0; batch classifier loss: 0.028111; batch adversarial loss: 0.514358\n",
      "epoch 187; iter: 0; batch classifier loss: 0.031778; batch adversarial loss: 0.334776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188; iter: 0; batch classifier loss: 0.020065; batch adversarial loss: 0.366375\n",
      "epoch 189; iter: 0; batch classifier loss: 0.018254; batch adversarial loss: 0.416336\n",
      "epoch 190; iter: 0; batch classifier loss: 0.040023; batch adversarial loss: 0.435773\n",
      "epoch 191; iter: 0; batch classifier loss: 0.017506; batch adversarial loss: 0.412667\n",
      "epoch 192; iter: 0; batch classifier loss: 0.055985; batch adversarial loss: 0.315531\n",
      "epoch 193; iter: 0; batch classifier loss: 0.020699; batch adversarial loss: 0.359427\n",
      "epoch 194; iter: 0; batch classifier loss: 0.029988; batch adversarial loss: 0.504595\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013942; batch adversarial loss: 0.516618\n",
      "epoch 196; iter: 0; batch classifier loss: 0.023573; batch adversarial loss: 0.375673\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006975; batch adversarial loss: 0.487449\n",
      "epoch 198; iter: 0; batch classifier loss: 0.033359; batch adversarial loss: 0.474752\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010230; batch adversarial loss: 0.465811\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695700; batch adversarial loss: 0.840718\n",
      "epoch 1; iter: 0; batch classifier loss: 0.462330; batch adversarial loss: 0.819920\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.766303\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362301; batch adversarial loss: 0.751525\n",
      "epoch 4; iter: 0; batch classifier loss: 0.389844; batch adversarial loss: 0.676516\n",
      "epoch 5; iter: 0; batch classifier loss: 0.278685; batch adversarial loss: 0.712596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.321395; batch adversarial loss: 0.645706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332525; batch adversarial loss: 0.604216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273605; batch adversarial loss: 0.597055\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299593; batch adversarial loss: 0.564188\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294700; batch adversarial loss: 0.527939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.239567; batch adversarial loss: 0.567496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.243662; batch adversarial loss: 0.502143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264201; batch adversarial loss: 0.481750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236328; batch adversarial loss: 0.477136\n",
      "epoch 15; iter: 0; batch classifier loss: 0.198568; batch adversarial loss: 0.489909\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316549; batch adversarial loss: 0.430262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249227; batch adversarial loss: 0.469948\n",
      "epoch 18; iter: 0; batch classifier loss: 0.149936; batch adversarial loss: 0.444823\n",
      "epoch 19; iter: 0; batch classifier loss: 0.172056; batch adversarial loss: 0.391168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.230207; batch adversarial loss: 0.428917\n",
      "epoch 21; iter: 0; batch classifier loss: 0.260416; batch adversarial loss: 0.367746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.233152; batch adversarial loss: 0.414712\n",
      "epoch 23; iter: 0; batch classifier loss: 0.272304; batch adversarial loss: 0.429356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.209048; batch adversarial loss: 0.417721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.252708; batch adversarial loss: 0.403358\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209568; batch adversarial loss: 0.452814\n",
      "epoch 27; iter: 0; batch classifier loss: 0.209164; batch adversarial loss: 0.444563\n",
      "epoch 28; iter: 0; batch classifier loss: 0.233358; batch adversarial loss: 0.323246\n",
      "epoch 29; iter: 0; batch classifier loss: 0.220552; batch adversarial loss: 0.451674\n",
      "epoch 30; iter: 0; batch classifier loss: 0.200563; batch adversarial loss: 0.395744\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223963; batch adversarial loss: 0.454355\n",
      "epoch 32; iter: 0; batch classifier loss: 0.209099; batch adversarial loss: 0.396075\n",
      "epoch 33; iter: 0; batch classifier loss: 0.115915; batch adversarial loss: 0.413237\n",
      "epoch 34; iter: 0; batch classifier loss: 0.152978; batch adversarial loss: 0.412266\n",
      "epoch 35; iter: 0; batch classifier loss: 0.220482; batch adversarial loss: 0.391254\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126082; batch adversarial loss: 0.469494\n",
      "epoch 37; iter: 0; batch classifier loss: 0.170077; batch adversarial loss: 0.360849\n",
      "epoch 38; iter: 0; batch classifier loss: 0.136494; batch adversarial loss: 0.416486\n",
      "epoch 39; iter: 0; batch classifier loss: 0.147632; batch adversarial loss: 0.470385\n",
      "epoch 40; iter: 0; batch classifier loss: 0.129405; batch adversarial loss: 0.408879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.125514; batch adversarial loss: 0.453820\n",
      "epoch 42; iter: 0; batch classifier loss: 0.087415; batch adversarial loss: 0.410366\n",
      "epoch 43; iter: 0; batch classifier loss: 0.151461; batch adversarial loss: 0.403186\n",
      "epoch 44; iter: 0; batch classifier loss: 0.096771; batch adversarial loss: 0.419600\n",
      "epoch 45; iter: 0; batch classifier loss: 0.121506; batch adversarial loss: 0.482084\n",
      "epoch 46; iter: 0; batch classifier loss: 0.082796; batch adversarial loss: 0.418881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.130626; batch adversarial loss: 0.416780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.131012; batch adversarial loss: 0.386177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098181; batch adversarial loss: 0.364205\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102288; batch adversarial loss: 0.454890\n",
      "epoch 51; iter: 0; batch classifier loss: 0.141578; batch adversarial loss: 0.500733\n",
      "epoch 52; iter: 0; batch classifier loss: 0.098997; batch adversarial loss: 0.428335\n",
      "epoch 53; iter: 0; batch classifier loss: 0.058020; batch adversarial loss: 0.485628\n",
      "epoch 54; iter: 0; batch classifier loss: 0.103110; batch adversarial loss: 0.393203\n",
      "epoch 55; iter: 0; batch classifier loss: 0.073046; batch adversarial loss: 0.513490\n",
      "epoch 56; iter: 0; batch classifier loss: 0.100743; batch adversarial loss: 0.441782\n",
      "epoch 57; iter: 0; batch classifier loss: 0.123282; batch adversarial loss: 0.413993\n",
      "epoch 58; iter: 0; batch classifier loss: 0.117844; batch adversarial loss: 0.410473\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098361; batch adversarial loss: 0.420811\n",
      "epoch 60; iter: 0; batch classifier loss: 0.066134; batch adversarial loss: 0.473656\n",
      "epoch 61; iter: 0; batch classifier loss: 0.114724; batch adversarial loss: 0.426325\n",
      "epoch 62; iter: 0; batch classifier loss: 0.083860; batch adversarial loss: 0.449718\n",
      "epoch 63; iter: 0; batch classifier loss: 0.099283; batch adversarial loss: 0.509825\n",
      "epoch 64; iter: 0; batch classifier loss: 0.057243; batch adversarial loss: 0.438244\n",
      "epoch 65; iter: 0; batch classifier loss: 0.058540; batch adversarial loss: 0.484991\n",
      "epoch 66; iter: 0; batch classifier loss: 0.056071; batch adversarial loss: 0.471364\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063443; batch adversarial loss: 0.436012\n",
      "epoch 68; iter: 0; batch classifier loss: 0.052088; batch adversarial loss: 0.479457\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082026; batch adversarial loss: 0.457170\n",
      "epoch 70; iter: 0; batch classifier loss: 0.076293; batch adversarial loss: 0.509690\n",
      "epoch 71; iter: 0; batch classifier loss: 0.071762; batch adversarial loss: 0.481893\n",
      "epoch 72; iter: 0; batch classifier loss: 0.064001; batch adversarial loss: 0.378360\n",
      "epoch 73; iter: 0; batch classifier loss: 0.076613; batch adversarial loss: 0.402979\n",
      "epoch 74; iter: 0; batch classifier loss: 0.084987; batch adversarial loss: 0.377618\n",
      "epoch 75; iter: 0; batch classifier loss: 0.039435; batch adversarial loss: 0.363324\n",
      "epoch 76; iter: 0; batch classifier loss: 0.063173; batch adversarial loss: 0.405216\n",
      "epoch 77; iter: 0; batch classifier loss: 0.080702; batch adversarial loss: 0.444229\n",
      "epoch 78; iter: 0; batch classifier loss: 0.053853; batch adversarial loss: 0.463696\n",
      "epoch 79; iter: 0; batch classifier loss: 0.059421; batch adversarial loss: 0.429597\n",
      "epoch 80; iter: 0; batch classifier loss: 0.098813; batch adversarial loss: 0.477778\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062560; batch adversarial loss: 0.544657\n",
      "epoch 82; iter: 0; batch classifier loss: 0.074675; batch adversarial loss: 0.411714\n",
      "epoch 83; iter: 0; batch classifier loss: 0.074298; batch adversarial loss: 0.462271\n",
      "epoch 84; iter: 0; batch classifier loss: 0.059991; batch adversarial loss: 0.453305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85; iter: 0; batch classifier loss: 0.050068; batch adversarial loss: 0.494736\n",
      "epoch 86; iter: 0; batch classifier loss: 0.074065; batch adversarial loss: 0.395100\n",
      "epoch 87; iter: 0; batch classifier loss: 0.069960; batch adversarial loss: 0.513936\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061262; batch adversarial loss: 0.437637\n",
      "epoch 89; iter: 0; batch classifier loss: 0.034044; batch adversarial loss: 0.481893\n",
      "epoch 90; iter: 0; batch classifier loss: 0.042534; batch adversarial loss: 0.455054\n",
      "epoch 91; iter: 0; batch classifier loss: 0.055605; batch adversarial loss: 0.489093\n",
      "epoch 92; iter: 0; batch classifier loss: 0.085772; batch adversarial loss: 0.366966\n",
      "epoch 93; iter: 0; batch classifier loss: 0.035902; batch adversarial loss: 0.580953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.045121; batch adversarial loss: 0.450355\n",
      "epoch 95; iter: 0; batch classifier loss: 0.051215; batch adversarial loss: 0.354202\n",
      "epoch 96; iter: 0; batch classifier loss: 0.051154; batch adversarial loss: 0.396396\n",
      "epoch 97; iter: 0; batch classifier loss: 0.030991; batch adversarial loss: 0.405197\n",
      "epoch 98; iter: 0; batch classifier loss: 0.023124; batch adversarial loss: 0.445187\n",
      "epoch 99; iter: 0; batch classifier loss: 0.032148; batch adversarial loss: 0.502752\n",
      "epoch 100; iter: 0; batch classifier loss: 0.042458; batch adversarial loss: 0.482204\n",
      "epoch 101; iter: 0; batch classifier loss: 0.032140; batch adversarial loss: 0.488871\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036538; batch adversarial loss: 0.435624\n",
      "epoch 103; iter: 0; batch classifier loss: 0.051930; batch adversarial loss: 0.456487\n",
      "epoch 104; iter: 0; batch classifier loss: 0.058598; batch adversarial loss: 0.449772\n",
      "epoch 105; iter: 0; batch classifier loss: 0.020023; batch adversarial loss: 0.416499\n",
      "epoch 106; iter: 0; batch classifier loss: 0.066440; batch adversarial loss: 0.445175\n",
      "epoch 107; iter: 0; batch classifier loss: 0.030659; batch adversarial loss: 0.449806\n",
      "epoch 108; iter: 0; batch classifier loss: 0.051758; batch adversarial loss: 0.571520\n",
      "epoch 109; iter: 0; batch classifier loss: 0.101218; batch adversarial loss: 0.599654\n",
      "epoch 110; iter: 0; batch classifier loss: 0.144271; batch adversarial loss: 0.552033\n",
      "epoch 111; iter: 0; batch classifier loss: 0.151638; batch adversarial loss: 0.535108\n",
      "epoch 112; iter: 0; batch classifier loss: 0.193520; batch adversarial loss: 0.694346\n",
      "epoch 113; iter: 0; batch classifier loss: 0.128559; batch adversarial loss: 0.598421\n",
      "epoch 114; iter: 0; batch classifier loss: 0.092887; batch adversarial loss: 0.472683\n",
      "epoch 115; iter: 0; batch classifier loss: 0.198072; batch adversarial loss: 0.708698\n",
      "epoch 116; iter: 0; batch classifier loss: 0.163660; batch adversarial loss: 0.571804\n",
      "epoch 117; iter: 0; batch classifier loss: 0.133001; batch adversarial loss: 0.661937\n",
      "epoch 118; iter: 0; batch classifier loss: 0.152171; batch adversarial loss: 0.515746\n",
      "epoch 119; iter: 0; batch classifier loss: 0.158639; batch adversarial loss: 0.556822\n",
      "epoch 120; iter: 0; batch classifier loss: 0.178915; batch adversarial loss: 0.637285\n",
      "epoch 121; iter: 0; batch classifier loss: 0.149402; batch adversarial loss: 0.551389\n",
      "epoch 122; iter: 0; batch classifier loss: 0.246691; batch adversarial loss: 0.732207\n",
      "epoch 123; iter: 0; batch classifier loss: 0.174749; batch adversarial loss: 0.579174\n",
      "epoch 124; iter: 0; batch classifier loss: 0.121174; batch adversarial loss: 0.521441\n",
      "epoch 125; iter: 0; batch classifier loss: 0.150958; batch adversarial loss: 0.603413\n",
      "epoch 126; iter: 0; batch classifier loss: 0.170208; batch adversarial loss: 0.499727\n",
      "epoch 127; iter: 0; batch classifier loss: 0.186167; batch adversarial loss: 0.550161\n",
      "epoch 128; iter: 0; batch classifier loss: 0.168049; batch adversarial loss: 0.562740\n",
      "epoch 129; iter: 0; batch classifier loss: 0.183989; batch adversarial loss: 0.595420\n",
      "epoch 130; iter: 0; batch classifier loss: 0.103061; batch adversarial loss: 0.515667\n",
      "epoch 131; iter: 0; batch classifier loss: 0.118960; batch adversarial loss: 0.490915\n",
      "epoch 132; iter: 0; batch classifier loss: 0.152145; batch adversarial loss: 0.622609\n",
      "epoch 133; iter: 0; batch classifier loss: 0.098064; batch adversarial loss: 0.502004\n",
      "epoch 134; iter: 0; batch classifier loss: 0.201933; batch adversarial loss: 0.582879\n",
      "epoch 135; iter: 0; batch classifier loss: 0.154652; batch adversarial loss: 0.640514\n",
      "epoch 136; iter: 0; batch classifier loss: 0.127092; batch adversarial loss: 0.507110\n",
      "epoch 137; iter: 0; batch classifier loss: 0.122286; batch adversarial loss: 0.405412\n",
      "epoch 138; iter: 0; batch classifier loss: 0.142060; batch adversarial loss: 0.463719\n",
      "epoch 139; iter: 0; batch classifier loss: 0.106850; batch adversarial loss: 0.521846\n",
      "epoch 140; iter: 0; batch classifier loss: 0.105915; batch adversarial loss: 0.432252\n",
      "epoch 141; iter: 0; batch classifier loss: 0.078360; batch adversarial loss: 0.451877\n",
      "epoch 142; iter: 0; batch classifier loss: 0.160309; batch adversarial loss: 0.561883\n",
      "epoch 143; iter: 0; batch classifier loss: 0.152279; batch adversarial loss: 0.435478\n",
      "epoch 144; iter: 0; batch classifier loss: 0.051966; batch adversarial loss: 0.493700\n",
      "epoch 145; iter: 0; batch classifier loss: 0.064045; batch adversarial loss: 0.405544\n",
      "epoch 146; iter: 0; batch classifier loss: 0.035330; batch adversarial loss: 0.516741\n",
      "epoch 147; iter: 0; batch classifier loss: 0.043530; batch adversarial loss: 0.392034\n",
      "epoch 148; iter: 0; batch classifier loss: 0.041380; batch adversarial loss: 0.534780\n",
      "epoch 149; iter: 0; batch classifier loss: 0.031277; batch adversarial loss: 0.371896\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016409; batch adversarial loss: 0.451074\n",
      "epoch 151; iter: 0; batch classifier loss: 0.042153; batch adversarial loss: 0.445127\n",
      "epoch 152; iter: 0; batch classifier loss: 0.028661; batch adversarial loss: 0.466706\n",
      "epoch 153; iter: 0; batch classifier loss: 0.070067; batch adversarial loss: 0.419292\n",
      "epoch 154; iter: 0; batch classifier loss: 0.015500; batch adversarial loss: 0.377933\n",
      "epoch 155; iter: 0; batch classifier loss: 0.043209; batch adversarial loss: 0.499216\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036973; batch adversarial loss: 0.577105\n",
      "epoch 157; iter: 0; batch classifier loss: 0.059400; batch adversarial loss: 0.433643\n",
      "epoch 158; iter: 0; batch classifier loss: 0.040687; batch adversarial loss: 0.433490\n",
      "epoch 159; iter: 0; batch classifier loss: 0.035351; batch adversarial loss: 0.412199\n",
      "epoch 160; iter: 0; batch classifier loss: 0.070932; batch adversarial loss: 0.409366\n",
      "epoch 161; iter: 0; batch classifier loss: 0.084669; batch adversarial loss: 0.440024\n",
      "epoch 162; iter: 0; batch classifier loss: 0.044031; batch adversarial loss: 0.489952\n",
      "epoch 163; iter: 0; batch classifier loss: 0.071732; batch adversarial loss: 0.442248\n",
      "epoch 164; iter: 0; batch classifier loss: 0.063278; batch adversarial loss: 0.399017\n",
      "epoch 165; iter: 0; batch classifier loss: 0.072827; batch adversarial loss: 0.457084\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036923; batch adversarial loss: 0.550636\n",
      "epoch 167; iter: 0; batch classifier loss: 0.064614; batch adversarial loss: 0.432179\n",
      "epoch 168; iter: 0; batch classifier loss: 0.081183; batch adversarial loss: 0.416940\n",
      "epoch 169; iter: 0; batch classifier loss: 0.066971; batch adversarial loss: 0.429469\n",
      "epoch 170; iter: 0; batch classifier loss: 0.073254; batch adversarial loss: 0.517087\n",
      "epoch 171; iter: 0; batch classifier loss: 0.050501; batch adversarial loss: 0.459474\n",
      "epoch 172; iter: 0; batch classifier loss: 0.079164; batch adversarial loss: 0.364737\n",
      "epoch 173; iter: 0; batch classifier loss: 0.052197; batch adversarial loss: 0.376772\n",
      "epoch 174; iter: 0; batch classifier loss: 0.063260; batch adversarial loss: 0.473892\n",
      "epoch 175; iter: 0; batch classifier loss: 0.052081; batch adversarial loss: 0.468110\n",
      "epoch 176; iter: 0; batch classifier loss: 0.058340; batch adversarial loss: 0.533821\n",
      "epoch 177; iter: 0; batch classifier loss: 0.101115; batch adversarial loss: 0.445033\n",
      "epoch 178; iter: 0; batch classifier loss: 0.074660; batch adversarial loss: 0.285060\n",
      "epoch 179; iter: 0; batch classifier loss: 0.036719; batch adversarial loss: 0.495224\n",
      "epoch 180; iter: 0; batch classifier loss: 0.085276; batch adversarial loss: 0.490315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181; iter: 0; batch classifier loss: 0.046526; batch adversarial loss: 0.463853\n",
      "epoch 182; iter: 0; batch classifier loss: 0.081428; batch adversarial loss: 0.460220\n",
      "epoch 183; iter: 0; batch classifier loss: 0.098220; batch adversarial loss: 0.499806\n",
      "epoch 184; iter: 0; batch classifier loss: 0.050799; batch adversarial loss: 0.610996\n",
      "epoch 185; iter: 0; batch classifier loss: 0.090544; batch adversarial loss: 0.478183\n",
      "epoch 186; iter: 0; batch classifier loss: 0.049018; batch adversarial loss: 0.554615\n",
      "epoch 187; iter: 0; batch classifier loss: 0.053489; batch adversarial loss: 0.374182\n",
      "epoch 188; iter: 0; batch classifier loss: 0.055688; batch adversarial loss: 0.431980\n",
      "epoch 189; iter: 0; batch classifier loss: 0.063694; batch adversarial loss: 0.557414\n",
      "epoch 190; iter: 0; batch classifier loss: 0.050950; batch adversarial loss: 0.481499\n",
      "epoch 191; iter: 0; batch classifier loss: 0.055439; batch adversarial loss: 0.458523\n",
      "epoch 192; iter: 0; batch classifier loss: 0.068734; batch adversarial loss: 0.372101\n",
      "epoch 193; iter: 0; batch classifier loss: 0.087085; batch adversarial loss: 0.462209\n",
      "epoch 194; iter: 0; batch classifier loss: 0.068459; batch adversarial loss: 0.375915\n",
      "epoch 195; iter: 0; batch classifier loss: 0.052562; batch adversarial loss: 0.463767\n",
      "epoch 196; iter: 0; batch classifier loss: 0.063262; batch adversarial loss: 0.496236\n",
      "epoch 197; iter: 0; batch classifier loss: 0.112141; batch adversarial loss: 0.381893\n",
      "epoch 198; iter: 0; batch classifier loss: 0.044611; batch adversarial loss: 0.520379\n",
      "epoch 199; iter: 0; batch classifier loss: 0.057313; batch adversarial loss: 0.488564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697954; batch adversarial loss: 1.051782\n",
      "epoch 1; iter: 0; batch classifier loss: 0.519314; batch adversarial loss: 1.148906\n",
      "epoch 2; iter: 0; batch classifier loss: 0.673512; batch adversarial loss: 1.092496\n",
      "epoch 3; iter: 0; batch classifier loss: 0.817270; batch adversarial loss: 1.056502\n",
      "epoch 4; iter: 0; batch classifier loss: 0.905970; batch adversarial loss: 0.939216\n",
      "epoch 5; iter: 0; batch classifier loss: 0.733179; batch adversarial loss: 0.881309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.705416; batch adversarial loss: 0.793168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.635039; batch adversarial loss: 0.714051\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466898; batch adversarial loss: 0.649864\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250663; batch adversarial loss: 0.614024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304202; batch adversarial loss: 0.607047\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264016; batch adversarial loss: 0.538650\n",
      "epoch 12; iter: 0; batch classifier loss: 0.263373; batch adversarial loss: 0.571772\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264120; batch adversarial loss: 0.542574\n",
      "epoch 14; iter: 0; batch classifier loss: 0.251110; batch adversarial loss: 0.535764\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277427; batch adversarial loss: 0.507694\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244990; batch adversarial loss: 0.432399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282724; batch adversarial loss: 0.512088\n",
      "epoch 18; iter: 0; batch classifier loss: 0.205383; batch adversarial loss: 0.509502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.195622; batch adversarial loss: 0.527288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.135009; batch adversarial loss: 0.464431\n",
      "epoch 21; iter: 0; batch classifier loss: 0.195239; batch adversarial loss: 0.500675\n",
      "epoch 22; iter: 0; batch classifier loss: 0.163153; batch adversarial loss: 0.462541\n",
      "epoch 23; iter: 0; batch classifier loss: 0.178296; batch adversarial loss: 0.462642\n",
      "epoch 24; iter: 0; batch classifier loss: 0.213929; batch adversarial loss: 0.428993\n",
      "epoch 25; iter: 0; batch classifier loss: 0.223032; batch adversarial loss: 0.443309\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160888; batch adversarial loss: 0.403224\n",
      "epoch 27; iter: 0; batch classifier loss: 0.238913; batch adversarial loss: 0.455895\n",
      "epoch 28; iter: 0; batch classifier loss: 0.147869; batch adversarial loss: 0.480724\n",
      "epoch 29; iter: 0; batch classifier loss: 0.151417; batch adversarial loss: 0.457055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.134345; batch adversarial loss: 0.465805\n",
      "epoch 31; iter: 0; batch classifier loss: 0.109431; batch adversarial loss: 0.417317\n",
      "epoch 32; iter: 0; batch classifier loss: 0.102907; batch adversarial loss: 0.310736\n",
      "epoch 33; iter: 0; batch classifier loss: 0.080450; batch adversarial loss: 0.571474\n",
      "epoch 34; iter: 0; batch classifier loss: 0.070205; batch adversarial loss: 0.421521\n",
      "epoch 35; iter: 0; batch classifier loss: 0.108086; batch adversarial loss: 0.461736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.107570; batch adversarial loss: 0.503898\n",
      "epoch 37; iter: 0; batch classifier loss: 0.105407; batch adversarial loss: 0.436163\n",
      "epoch 38; iter: 0; batch classifier loss: 0.092178; batch adversarial loss: 0.397111\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113275; batch adversarial loss: 0.425860\n",
      "epoch 40; iter: 0; batch classifier loss: 0.077843; batch adversarial loss: 0.429941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.136390; batch adversarial loss: 0.402642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.063984; batch adversarial loss: 0.379736\n",
      "epoch 43; iter: 0; batch classifier loss: 0.073306; batch adversarial loss: 0.524694\n",
      "epoch 44; iter: 0; batch classifier loss: 0.069086; batch adversarial loss: 0.454902\n",
      "epoch 45; iter: 0; batch classifier loss: 0.077570; batch adversarial loss: 0.422463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.048651; batch adversarial loss: 0.453648\n",
      "epoch 47; iter: 0; batch classifier loss: 0.105707; batch adversarial loss: 0.491978\n",
      "epoch 48; iter: 0; batch classifier loss: 0.031481; batch adversarial loss: 0.445751\n",
      "epoch 49; iter: 0; batch classifier loss: 0.079360; batch adversarial loss: 0.351508\n",
      "epoch 50; iter: 0; batch classifier loss: 0.045455; batch adversarial loss: 0.448943\n",
      "epoch 51; iter: 0; batch classifier loss: 0.057141; batch adversarial loss: 0.387061\n",
      "epoch 52; iter: 0; batch classifier loss: 0.052466; batch adversarial loss: 0.306825\n",
      "epoch 53; iter: 0; batch classifier loss: 0.067009; batch adversarial loss: 0.403844\n",
      "epoch 54; iter: 0; batch classifier loss: 0.092001; batch adversarial loss: 0.376341\n",
      "epoch 55; iter: 0; batch classifier loss: 0.039031; batch adversarial loss: 0.478137\n",
      "epoch 56; iter: 0; batch classifier loss: 0.064463; batch adversarial loss: 0.446864\n",
      "epoch 57; iter: 0; batch classifier loss: 0.065802; batch adversarial loss: 0.470447\n",
      "epoch 58; iter: 0; batch classifier loss: 0.080786; batch adversarial loss: 0.470086\n",
      "epoch 59; iter: 0; batch classifier loss: 0.075789; batch adversarial loss: 0.386459\n",
      "epoch 60; iter: 0; batch classifier loss: 0.025896; batch adversarial loss: 0.416013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.064200; batch adversarial loss: 0.460494\n",
      "epoch 62; iter: 0; batch classifier loss: 0.047557; batch adversarial loss: 0.413453\n",
      "epoch 63; iter: 0; batch classifier loss: 0.072305; batch adversarial loss: 0.394514\n",
      "epoch 64; iter: 0; batch classifier loss: 0.085055; batch adversarial loss: 0.434241\n",
      "epoch 65; iter: 0; batch classifier loss: 0.056110; batch adversarial loss: 0.439664\n",
      "epoch 66; iter: 0; batch classifier loss: 0.067909; batch adversarial loss: 0.443784\n",
      "epoch 67; iter: 0; batch classifier loss: 0.082137; batch adversarial loss: 0.540383\n",
      "epoch 68; iter: 0; batch classifier loss: 0.045975; batch adversarial loss: 0.436809\n",
      "epoch 69; iter: 0; batch classifier loss: 0.058571; batch adversarial loss: 0.501528\n",
      "epoch 70; iter: 0; batch classifier loss: 0.051396; batch adversarial loss: 0.396905\n",
      "epoch 71; iter: 0; batch classifier loss: 0.063795; batch adversarial loss: 0.380405\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085564; batch adversarial loss: 0.436768\n",
      "epoch 73; iter: 0; batch classifier loss: 0.062897; batch adversarial loss: 0.415026\n",
      "epoch 74; iter: 0; batch classifier loss: 0.071436; batch adversarial loss: 0.446366\n",
      "epoch 75; iter: 0; batch classifier loss: 0.042898; batch adversarial loss: 0.410919\n",
      "epoch 76; iter: 0; batch classifier loss: 0.078275; batch adversarial loss: 0.510466\n",
      "epoch 77; iter: 0; batch classifier loss: 0.034946; batch adversarial loss: 0.407469\n",
      "epoch 78; iter: 0; batch classifier loss: 0.072205; batch adversarial loss: 0.401890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79; iter: 0; batch classifier loss: 0.053530; batch adversarial loss: 0.427107\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067750; batch adversarial loss: 0.464638\n",
      "epoch 81; iter: 0; batch classifier loss: 0.083774; batch adversarial loss: 0.529040\n",
      "epoch 82; iter: 0; batch classifier loss: 0.083781; batch adversarial loss: 0.423032\n",
      "epoch 83; iter: 0; batch classifier loss: 0.115596; batch adversarial loss: 0.456003\n",
      "epoch 84; iter: 0; batch classifier loss: 0.081630; batch adversarial loss: 0.490749\n",
      "epoch 85; iter: 0; batch classifier loss: 0.057176; batch adversarial loss: 0.483560\n",
      "epoch 86; iter: 0; batch classifier loss: 0.037172; batch adversarial loss: 0.542184\n",
      "epoch 87; iter: 0; batch classifier loss: 0.073125; batch adversarial loss: 0.361681\n",
      "epoch 88; iter: 0; batch classifier loss: 0.035008; batch adversarial loss: 0.524843\n",
      "epoch 89; iter: 0; batch classifier loss: 0.093733; batch adversarial loss: 0.457846\n",
      "epoch 90; iter: 0; batch classifier loss: 0.072516; batch adversarial loss: 0.477236\n",
      "epoch 91; iter: 0; batch classifier loss: 0.076664; batch adversarial loss: 0.394735\n",
      "epoch 92; iter: 0; batch classifier loss: 0.020256; batch adversarial loss: 0.373262\n",
      "epoch 93; iter: 0; batch classifier loss: 0.034428; batch adversarial loss: 0.445479\n",
      "epoch 94; iter: 0; batch classifier loss: 0.070691; batch adversarial loss: 0.473448\n",
      "epoch 95; iter: 0; batch classifier loss: 0.057266; batch adversarial loss: 0.462879\n",
      "epoch 96; iter: 0; batch classifier loss: 0.046663; batch adversarial loss: 0.467724\n",
      "epoch 97; iter: 0; batch classifier loss: 0.062094; batch adversarial loss: 0.441175\n",
      "epoch 98; iter: 0; batch classifier loss: 0.055487; batch adversarial loss: 0.480490\n",
      "epoch 99; iter: 0; batch classifier loss: 0.067675; batch adversarial loss: 0.456587\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046352; batch adversarial loss: 0.453911\n",
      "epoch 101; iter: 0; batch classifier loss: 0.072149; batch adversarial loss: 0.448376\n",
      "epoch 102; iter: 0; batch classifier loss: 0.060332; batch adversarial loss: 0.419928\n",
      "epoch 103; iter: 0; batch classifier loss: 0.033085; batch adversarial loss: 0.396710\n",
      "epoch 104; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.435872\n",
      "epoch 105; iter: 0; batch classifier loss: 0.049563; batch adversarial loss: 0.508787\n",
      "epoch 106; iter: 0; batch classifier loss: 0.044637; batch adversarial loss: 0.421716\n",
      "epoch 107; iter: 0; batch classifier loss: 0.062136; batch adversarial loss: 0.438981\n",
      "epoch 108; iter: 0; batch classifier loss: 0.024281; batch adversarial loss: 0.394045\n",
      "epoch 109; iter: 0; batch classifier loss: 0.030119; batch adversarial loss: 0.435496\n",
      "epoch 110; iter: 0; batch classifier loss: 0.028888; batch adversarial loss: 0.407427\n",
      "epoch 111; iter: 0; batch classifier loss: 0.053308; batch adversarial loss: 0.436330\n",
      "epoch 112; iter: 0; batch classifier loss: 0.055762; batch adversarial loss: 0.461192\n",
      "epoch 113; iter: 0; batch classifier loss: 0.053645; batch adversarial loss: 0.341707\n",
      "epoch 114; iter: 0; batch classifier loss: 0.054819; batch adversarial loss: 0.500172\n",
      "epoch 115; iter: 0; batch classifier loss: 0.072024; batch adversarial loss: 0.490318\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068243; batch adversarial loss: 0.493338\n",
      "epoch 117; iter: 0; batch classifier loss: 0.047819; batch adversarial loss: 0.452351\n",
      "epoch 118; iter: 0; batch classifier loss: 0.040443; batch adversarial loss: 0.392363\n",
      "epoch 119; iter: 0; batch classifier loss: 0.053447; batch adversarial loss: 0.431977\n",
      "epoch 120; iter: 0; batch classifier loss: 0.025646; batch adversarial loss: 0.374157\n",
      "epoch 121; iter: 0; batch classifier loss: 0.059630; batch adversarial loss: 0.422981\n",
      "epoch 122; iter: 0; batch classifier loss: 0.052327; batch adversarial loss: 0.455218\n",
      "epoch 123; iter: 0; batch classifier loss: 0.061854; batch adversarial loss: 0.456050\n",
      "epoch 124; iter: 0; batch classifier loss: 0.036457; batch adversarial loss: 0.426707\n",
      "epoch 125; iter: 0; batch classifier loss: 0.018166; batch adversarial loss: 0.345884\n",
      "epoch 126; iter: 0; batch classifier loss: 0.079053; batch adversarial loss: 0.371774\n",
      "epoch 127; iter: 0; batch classifier loss: 0.054667; batch adversarial loss: 0.458243\n",
      "epoch 128; iter: 0; batch classifier loss: 0.062486; batch adversarial loss: 0.409855\n",
      "epoch 129; iter: 0; batch classifier loss: 0.066532; batch adversarial loss: 0.464328\n",
      "epoch 130; iter: 0; batch classifier loss: 0.086927; batch adversarial loss: 0.454905\n",
      "epoch 131; iter: 0; batch classifier loss: 0.052706; batch adversarial loss: 0.441002\n",
      "epoch 132; iter: 0; batch classifier loss: 0.063132; batch adversarial loss: 0.450050\n",
      "epoch 133; iter: 0; batch classifier loss: 0.035629; batch adversarial loss: 0.371059\n",
      "epoch 134; iter: 0; batch classifier loss: 0.038130; batch adversarial loss: 0.469096\n",
      "epoch 135; iter: 0; batch classifier loss: 0.039156; batch adversarial loss: 0.453399\n",
      "epoch 136; iter: 0; batch classifier loss: 0.085923; batch adversarial loss: 0.482820\n",
      "epoch 137; iter: 0; batch classifier loss: 0.038011; batch adversarial loss: 0.458103\n",
      "epoch 138; iter: 0; batch classifier loss: 0.057115; batch adversarial loss: 0.445580\n",
      "epoch 139; iter: 0; batch classifier loss: 0.061856; batch adversarial loss: 0.353690\n",
      "epoch 140; iter: 0; batch classifier loss: 0.056190; batch adversarial loss: 0.449856\n",
      "epoch 141; iter: 0; batch classifier loss: 0.035681; batch adversarial loss: 0.350103\n",
      "epoch 142; iter: 0; batch classifier loss: 0.022981; batch adversarial loss: 0.361810\n",
      "epoch 143; iter: 0; batch classifier loss: 0.036651; batch adversarial loss: 0.446349\n",
      "epoch 144; iter: 0; batch classifier loss: 0.052259; batch adversarial loss: 0.503280\n",
      "epoch 145; iter: 0; batch classifier loss: 0.075117; batch adversarial loss: 0.486857\n",
      "epoch 146; iter: 0; batch classifier loss: 0.063452; batch adversarial loss: 0.457199\n",
      "epoch 147; iter: 0; batch classifier loss: 0.051637; batch adversarial loss: 0.339556\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024033; batch adversarial loss: 0.433841\n",
      "epoch 149; iter: 0; batch classifier loss: 0.069741; batch adversarial loss: 0.550611\n",
      "epoch 150; iter: 0; batch classifier loss: 0.062996; batch adversarial loss: 0.496203\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048039; batch adversarial loss: 0.313091\n",
      "epoch 152; iter: 0; batch classifier loss: 0.035791; batch adversarial loss: 0.378691\n",
      "epoch 153; iter: 0; batch classifier loss: 0.041307; batch adversarial loss: 0.374154\n",
      "epoch 154; iter: 0; batch classifier loss: 0.034900; batch adversarial loss: 0.433947\n",
      "epoch 155; iter: 0; batch classifier loss: 0.051615; batch adversarial loss: 0.480202\n",
      "epoch 156; iter: 0; batch classifier loss: 0.057814; batch adversarial loss: 0.410932\n",
      "epoch 157; iter: 0; batch classifier loss: 0.046902; batch adversarial loss: 0.491806\n",
      "epoch 158; iter: 0; batch classifier loss: 0.044556; batch adversarial loss: 0.423953\n",
      "epoch 159; iter: 0; batch classifier loss: 0.045786; batch adversarial loss: 0.410918\n",
      "epoch 160; iter: 0; batch classifier loss: 0.041377; batch adversarial loss: 0.465162\n",
      "epoch 161; iter: 0; batch classifier loss: 0.074862; batch adversarial loss: 0.410655\n",
      "epoch 162; iter: 0; batch classifier loss: 0.052817; batch adversarial loss: 0.385127\n",
      "epoch 163; iter: 0; batch classifier loss: 0.038632; batch adversarial loss: 0.435533\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024161; batch adversarial loss: 0.436839\n",
      "epoch 165; iter: 0; batch classifier loss: 0.041810; batch adversarial loss: 0.408860\n",
      "epoch 166; iter: 0; batch classifier loss: 0.049002; batch adversarial loss: 0.440869\n",
      "epoch 167; iter: 0; batch classifier loss: 0.079358; batch adversarial loss: 0.468974\n",
      "epoch 168; iter: 0; batch classifier loss: 0.069600; batch adversarial loss: 0.414860\n",
      "epoch 169; iter: 0; batch classifier loss: 0.034301; batch adversarial loss: 0.432966\n",
      "epoch 170; iter: 0; batch classifier loss: 0.032317; batch adversarial loss: 0.411686\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054328; batch adversarial loss: 0.413108\n",
      "epoch 172; iter: 0; batch classifier loss: 0.029723; batch adversarial loss: 0.410572\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025503; batch adversarial loss: 0.358748\n",
      "epoch 174; iter: 0; batch classifier loss: 0.061293; batch adversarial loss: 0.412683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175; iter: 0; batch classifier loss: 0.060596; batch adversarial loss: 0.474943\n",
      "epoch 176; iter: 0; batch classifier loss: 0.039284; batch adversarial loss: 0.357180\n",
      "epoch 177; iter: 0; batch classifier loss: 0.021421; batch adversarial loss: 0.378197\n",
      "epoch 178; iter: 0; batch classifier loss: 0.055369; batch adversarial loss: 0.473314\n",
      "epoch 179; iter: 0; batch classifier loss: 0.050132; batch adversarial loss: 0.413970\n",
      "epoch 180; iter: 0; batch classifier loss: 0.080992; batch adversarial loss: 0.432687\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044458; batch adversarial loss: 0.457951\n",
      "epoch 182; iter: 0; batch classifier loss: 0.054802; batch adversarial loss: 0.407982\n",
      "epoch 183; iter: 0; batch classifier loss: 0.061734; batch adversarial loss: 0.465627\n",
      "epoch 184; iter: 0; batch classifier loss: 0.046568; batch adversarial loss: 0.477507\n",
      "epoch 185; iter: 0; batch classifier loss: 0.060815; batch adversarial loss: 0.555202\n",
      "epoch 186; iter: 0; batch classifier loss: 0.060777; batch adversarial loss: 0.522890\n",
      "epoch 187; iter: 0; batch classifier loss: 0.038873; batch adversarial loss: 0.424778\n",
      "epoch 188; iter: 0; batch classifier loss: 0.048363; batch adversarial loss: 0.473392\n",
      "epoch 189; iter: 0; batch classifier loss: 0.048554; batch adversarial loss: 0.380868\n",
      "epoch 190; iter: 0; batch classifier loss: 0.061154; batch adversarial loss: 0.512459\n",
      "epoch 191; iter: 0; batch classifier loss: 0.051323; batch adversarial loss: 0.383392\n",
      "epoch 192; iter: 0; batch classifier loss: 0.047871; batch adversarial loss: 0.461905\n",
      "epoch 193; iter: 0; batch classifier loss: 0.043257; batch adversarial loss: 0.375178\n",
      "epoch 194; iter: 0; batch classifier loss: 0.041691; batch adversarial loss: 0.426401\n",
      "epoch 195; iter: 0; batch classifier loss: 0.061358; batch adversarial loss: 0.459596\n",
      "epoch 196; iter: 0; batch classifier loss: 0.041574; batch adversarial loss: 0.473613\n",
      "epoch 197; iter: 0; batch classifier loss: 0.037261; batch adversarial loss: 0.429550\n",
      "epoch 198; iter: 0; batch classifier loss: 0.047009; batch adversarial loss: 0.517581\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026126; batch adversarial loss: 0.354199\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685082; batch adversarial loss: 0.794701\n",
      "epoch 1; iter: 0; batch classifier loss: 0.336399; batch adversarial loss: 0.735570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.402106; batch adversarial loss: 0.718630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380187; batch adversarial loss: 0.698744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.279024; batch adversarial loss: 0.626727\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323330; batch adversarial loss: 0.608709\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315486; batch adversarial loss: 0.586554\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310932; batch adversarial loss: 0.582423\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368148; batch adversarial loss: 0.545298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.366423; batch adversarial loss: 0.486842\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292616; batch adversarial loss: 0.499338\n",
      "epoch 11; iter: 0; batch classifier loss: 0.217113; batch adversarial loss: 0.482605\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270333; batch adversarial loss: 0.467504\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278202; batch adversarial loss: 0.472316\n",
      "epoch 14; iter: 0; batch classifier loss: 0.215494; batch adversarial loss: 0.473177\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286508; batch adversarial loss: 0.456172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.253895; batch adversarial loss: 0.390139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.193050; batch adversarial loss: 0.405923\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293989; batch adversarial loss: 0.445593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.197113; batch adversarial loss: 0.420477\n",
      "epoch 20; iter: 0; batch classifier loss: 0.232795; batch adversarial loss: 0.401765\n",
      "epoch 21; iter: 0; batch classifier loss: 0.248883; batch adversarial loss: 0.445483\n",
      "epoch 22; iter: 0; batch classifier loss: 0.220025; batch adversarial loss: 0.374786\n",
      "epoch 23; iter: 0; batch classifier loss: 0.236372; batch adversarial loss: 0.354081\n",
      "epoch 24; iter: 0; batch classifier loss: 0.184142; batch adversarial loss: 0.398988\n",
      "epoch 25; iter: 0; batch classifier loss: 0.164156; batch adversarial loss: 0.362740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.209355; batch adversarial loss: 0.383790\n",
      "epoch 27; iter: 0; batch classifier loss: 0.144433; batch adversarial loss: 0.438896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.124011; batch adversarial loss: 0.363105\n",
      "epoch 29; iter: 0; batch classifier loss: 0.171439; batch adversarial loss: 0.382887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.177265; batch adversarial loss: 0.420577\n",
      "epoch 31; iter: 0; batch classifier loss: 0.113573; batch adversarial loss: 0.428976\n",
      "epoch 32; iter: 0; batch classifier loss: 0.157667; batch adversarial loss: 0.389239\n",
      "epoch 33; iter: 0; batch classifier loss: 0.142620; batch adversarial loss: 0.430069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.140949; batch adversarial loss: 0.416414\n",
      "epoch 35; iter: 0; batch classifier loss: 0.153468; batch adversarial loss: 0.383675\n",
      "epoch 36; iter: 0; batch classifier loss: 0.126259; batch adversarial loss: 0.387431\n",
      "epoch 37; iter: 0; batch classifier loss: 0.144891; batch adversarial loss: 0.406858\n",
      "epoch 38; iter: 0; batch classifier loss: 0.123242; batch adversarial loss: 0.452991\n",
      "epoch 39; iter: 0; batch classifier loss: 0.116398; batch adversarial loss: 0.515120\n",
      "epoch 40; iter: 0; batch classifier loss: 0.169021; batch adversarial loss: 0.426553\n",
      "epoch 41; iter: 0; batch classifier loss: 0.096959; batch adversarial loss: 0.438799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.088769; batch adversarial loss: 0.416817\n",
      "epoch 43; iter: 0; batch classifier loss: 0.110160; batch adversarial loss: 0.359263\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093588; batch adversarial loss: 0.436535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.106384; batch adversarial loss: 0.441225\n",
      "epoch 46; iter: 0; batch classifier loss: 0.149463; batch adversarial loss: 0.444512\n",
      "epoch 47; iter: 0; batch classifier loss: 0.113692; batch adversarial loss: 0.339635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.120073; batch adversarial loss: 0.419512\n",
      "epoch 49; iter: 0; batch classifier loss: 0.136674; batch adversarial loss: 0.408700\n",
      "epoch 50; iter: 0; batch classifier loss: 0.102057; batch adversarial loss: 0.488414\n",
      "epoch 51; iter: 0; batch classifier loss: 0.083409; batch adversarial loss: 0.435876\n",
      "epoch 52; iter: 0; batch classifier loss: 0.076109; batch adversarial loss: 0.398934\n",
      "epoch 53; iter: 0; batch classifier loss: 0.122615; batch adversarial loss: 0.419697\n",
      "epoch 54; iter: 0; batch classifier loss: 0.052491; batch adversarial loss: 0.416614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.112634; batch adversarial loss: 0.436052\n",
      "epoch 56; iter: 0; batch classifier loss: 0.074359; batch adversarial loss: 0.433598\n",
      "epoch 57; iter: 0; batch classifier loss: 0.090402; batch adversarial loss: 0.481497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145107; batch adversarial loss: 0.347170\n",
      "epoch 59; iter: 0; batch classifier loss: 0.098929; batch adversarial loss: 0.486024\n",
      "epoch 60; iter: 0; batch classifier loss: 0.095435; batch adversarial loss: 0.402521\n",
      "epoch 61; iter: 0; batch classifier loss: 0.106334; batch adversarial loss: 0.385456\n",
      "epoch 62; iter: 0; batch classifier loss: 0.062505; batch adversarial loss: 0.332339\n",
      "epoch 63; iter: 0; batch classifier loss: 0.076299; batch adversarial loss: 0.407620\n",
      "epoch 64; iter: 0; batch classifier loss: 0.069432; batch adversarial loss: 0.435246\n",
      "epoch 65; iter: 0; batch classifier loss: 0.090239; batch adversarial loss: 0.381596\n",
      "epoch 66; iter: 0; batch classifier loss: 0.082001; batch adversarial loss: 0.418563\n",
      "epoch 67; iter: 0; batch classifier loss: 0.056718; batch adversarial loss: 0.404776\n",
      "epoch 68; iter: 0; batch classifier loss: 0.118217; batch adversarial loss: 0.497941\n",
      "epoch 69; iter: 0; batch classifier loss: 0.081011; batch adversarial loss: 0.379667\n",
      "epoch 70; iter: 0; batch classifier loss: 0.095547; batch adversarial loss: 0.427645\n",
      "epoch 71; iter: 0; batch classifier loss: 0.101234; batch adversarial loss: 0.421929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72; iter: 0; batch classifier loss: 0.083656; batch adversarial loss: 0.566783\n",
      "epoch 73; iter: 0; batch classifier loss: 0.069737; batch adversarial loss: 0.404462\n",
      "epoch 74; iter: 0; batch classifier loss: 0.063513; batch adversarial loss: 0.420112\n",
      "epoch 75; iter: 0; batch classifier loss: 0.064469; batch adversarial loss: 0.389154\n",
      "epoch 76; iter: 0; batch classifier loss: 0.122310; batch adversarial loss: 0.405917\n",
      "epoch 77; iter: 0; batch classifier loss: 0.088635; batch adversarial loss: 0.535488\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052529; batch adversarial loss: 0.377690\n",
      "epoch 79; iter: 0; batch classifier loss: 0.066730; batch adversarial loss: 0.431277\n",
      "epoch 80; iter: 0; batch classifier loss: 0.083378; batch adversarial loss: 0.399101\n",
      "epoch 81; iter: 0; batch classifier loss: 0.062134; batch adversarial loss: 0.466034\n",
      "epoch 82; iter: 0; batch classifier loss: 0.093609; batch adversarial loss: 0.358547\n",
      "epoch 83; iter: 0; batch classifier loss: 0.055837; batch adversarial loss: 0.383145\n",
      "epoch 84; iter: 0; batch classifier loss: 0.051845; batch adversarial loss: 0.490388\n",
      "epoch 85; iter: 0; batch classifier loss: 0.085410; batch adversarial loss: 0.484243\n",
      "epoch 86; iter: 0; batch classifier loss: 0.071760; batch adversarial loss: 0.385386\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047875; batch adversarial loss: 0.455211\n",
      "epoch 88; iter: 0; batch classifier loss: 0.077869; batch adversarial loss: 0.407413\n",
      "epoch 89; iter: 0; batch classifier loss: 0.066075; batch adversarial loss: 0.426205\n",
      "epoch 90; iter: 0; batch classifier loss: 0.038433; batch adversarial loss: 0.443700\n",
      "epoch 91; iter: 0; batch classifier loss: 0.064814; batch adversarial loss: 0.424491\n",
      "epoch 92; iter: 0; batch classifier loss: 0.054117; batch adversarial loss: 0.376962\n",
      "epoch 93; iter: 0; batch classifier loss: 0.101234; batch adversarial loss: 0.440471\n",
      "epoch 94; iter: 0; batch classifier loss: 0.102603; batch adversarial loss: 0.393342\n",
      "epoch 95; iter: 0; batch classifier loss: 0.039623; batch adversarial loss: 0.422844\n",
      "epoch 96; iter: 0; batch classifier loss: 0.041978; batch adversarial loss: 0.433847\n",
      "epoch 97; iter: 0; batch classifier loss: 0.055848; batch adversarial loss: 0.421327\n",
      "epoch 98; iter: 0; batch classifier loss: 0.057251; batch adversarial loss: 0.420435\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039400; batch adversarial loss: 0.412643\n",
      "epoch 100; iter: 0; batch classifier loss: 0.046604; batch adversarial loss: 0.498980\n",
      "epoch 101; iter: 0; batch classifier loss: 0.065081; batch adversarial loss: 0.309618\n",
      "epoch 102; iter: 0; batch classifier loss: 0.040932; batch adversarial loss: 0.424922\n",
      "epoch 103; iter: 0; batch classifier loss: 0.039126; batch adversarial loss: 0.425413\n",
      "epoch 104; iter: 0; batch classifier loss: 0.031880; batch adversarial loss: 0.454094\n",
      "epoch 105; iter: 0; batch classifier loss: 0.030479; batch adversarial loss: 0.318128\n",
      "epoch 106; iter: 0; batch classifier loss: 0.043465; batch adversarial loss: 0.492887\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039380; batch adversarial loss: 0.433378\n",
      "epoch 108; iter: 0; batch classifier loss: 0.043937; batch adversarial loss: 0.473878\n",
      "epoch 109; iter: 0; batch classifier loss: 0.041807; batch adversarial loss: 0.436270\n",
      "epoch 110; iter: 0; batch classifier loss: 0.055577; batch adversarial loss: 0.407261\n",
      "epoch 111; iter: 0; batch classifier loss: 0.041484; batch adversarial loss: 0.466671\n",
      "epoch 112; iter: 0; batch classifier loss: 0.035111; batch adversarial loss: 0.381847\n",
      "epoch 113; iter: 0; batch classifier loss: 0.027831; batch adversarial loss: 0.418168\n",
      "epoch 114; iter: 0; batch classifier loss: 0.033302; batch adversarial loss: 0.448314\n",
      "epoch 115; iter: 0; batch classifier loss: 0.020719; batch adversarial loss: 0.505636\n",
      "epoch 116; iter: 0; batch classifier loss: 0.025703; batch adversarial loss: 0.473955\n",
      "epoch 117; iter: 0; batch classifier loss: 0.017355; batch adversarial loss: 0.420524\n",
      "epoch 118; iter: 0; batch classifier loss: 0.052487; batch adversarial loss: 0.526370\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033824; batch adversarial loss: 0.415136\n",
      "epoch 120; iter: 0; batch classifier loss: 0.050737; batch adversarial loss: 0.518748\n",
      "epoch 121; iter: 0; batch classifier loss: 0.025914; batch adversarial loss: 0.513012\n",
      "epoch 122; iter: 0; batch classifier loss: 0.036525; batch adversarial loss: 0.451870\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038117; batch adversarial loss: 0.555840\n",
      "epoch 124; iter: 0; batch classifier loss: 0.032016; batch adversarial loss: 0.481657\n",
      "epoch 125; iter: 0; batch classifier loss: 0.066755; batch adversarial loss: 0.641663\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038207; batch adversarial loss: 0.450507\n",
      "epoch 127; iter: 0; batch classifier loss: 0.050659; batch adversarial loss: 0.594354\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037673; batch adversarial loss: 0.406070\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035548; batch adversarial loss: 0.456078\n",
      "epoch 130; iter: 0; batch classifier loss: 0.057592; batch adversarial loss: 0.571000\n",
      "epoch 131; iter: 0; batch classifier loss: 0.070491; batch adversarial loss: 0.496940\n",
      "epoch 132; iter: 0; batch classifier loss: 0.068686; batch adversarial loss: 0.554600\n",
      "epoch 133; iter: 0; batch classifier loss: 0.055326; batch adversarial loss: 0.523497\n",
      "epoch 134; iter: 0; batch classifier loss: 0.163610; batch adversarial loss: 0.653486\n",
      "epoch 135; iter: 0; batch classifier loss: 0.084172; batch adversarial loss: 0.497174\n",
      "epoch 136; iter: 0; batch classifier loss: 0.106215; batch adversarial loss: 0.628858\n",
      "epoch 137; iter: 0; batch classifier loss: 0.064492; batch adversarial loss: 0.507408\n",
      "epoch 138; iter: 0; batch classifier loss: 0.133332; batch adversarial loss: 0.608339\n",
      "epoch 139; iter: 0; batch classifier loss: 0.101831; batch adversarial loss: 0.462022\n",
      "epoch 140; iter: 0; batch classifier loss: 0.173129; batch adversarial loss: 0.627239\n",
      "epoch 141; iter: 0; batch classifier loss: 0.103046; batch adversarial loss: 0.548715\n",
      "epoch 142; iter: 0; batch classifier loss: 0.166053; batch adversarial loss: 0.642963\n",
      "epoch 143; iter: 0; batch classifier loss: 0.119525; batch adversarial loss: 0.611348\n",
      "epoch 144; iter: 0; batch classifier loss: 0.163967; batch adversarial loss: 0.534259\n",
      "epoch 145; iter: 0; batch classifier loss: 0.123891; batch adversarial loss: 0.554283\n",
      "epoch 146; iter: 0; batch classifier loss: 0.141166; batch adversarial loss: 0.611105\n",
      "epoch 147; iter: 0; batch classifier loss: 0.163043; batch adversarial loss: 0.656353\n",
      "epoch 148; iter: 0; batch classifier loss: 0.109827; batch adversarial loss: 0.581786\n",
      "epoch 149; iter: 0; batch classifier loss: 0.140275; batch adversarial loss: 0.589867\n",
      "epoch 150; iter: 0; batch classifier loss: 0.146673; batch adversarial loss: 0.562756\n",
      "epoch 151; iter: 0; batch classifier loss: 0.100111; batch adversarial loss: 0.511480\n",
      "epoch 152; iter: 0; batch classifier loss: 0.233213; batch adversarial loss: 0.626102\n",
      "epoch 153; iter: 0; batch classifier loss: 0.114204; batch adversarial loss: 0.486332\n",
      "epoch 154; iter: 0; batch classifier loss: 0.126985; batch adversarial loss: 0.508312\n",
      "epoch 155; iter: 0; batch classifier loss: 0.157993; batch adversarial loss: 0.587850\n",
      "epoch 156; iter: 0; batch classifier loss: 0.099858; batch adversarial loss: 0.446514\n",
      "epoch 157; iter: 0; batch classifier loss: 0.135745; batch adversarial loss: 0.485307\n",
      "epoch 158; iter: 0; batch classifier loss: 0.135353; batch adversarial loss: 0.472968\n",
      "epoch 159; iter: 0; batch classifier loss: 0.085727; batch adversarial loss: 0.529788\n",
      "epoch 160; iter: 0; batch classifier loss: 0.031886; batch adversarial loss: 0.306783\n",
      "epoch 161; iter: 0; batch classifier loss: 0.164944; batch adversarial loss: 0.607222\n",
      "epoch 162; iter: 0; batch classifier loss: 0.112102; batch adversarial loss: 0.534220\n",
      "epoch 163; iter: 0; batch classifier loss: 0.098662; batch adversarial loss: 0.449853\n",
      "epoch 164; iter: 0; batch classifier loss: 0.158379; batch adversarial loss: 0.541896\n",
      "epoch 165; iter: 0; batch classifier loss: 0.075018; batch adversarial loss: 0.481995\n",
      "epoch 166; iter: 0; batch classifier loss: 0.115414; batch adversarial loss: 0.520003\n",
      "epoch 167; iter: 0; batch classifier loss: 0.121610; batch adversarial loss: 0.626824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 0; batch classifier loss: 0.076137; batch adversarial loss: 0.391411\n",
      "epoch 169; iter: 0; batch classifier loss: 0.115839; batch adversarial loss: 0.539000\n",
      "epoch 170; iter: 0; batch classifier loss: 0.082478; batch adversarial loss: 0.529051\n",
      "epoch 171; iter: 0; batch classifier loss: 0.078293; batch adversarial loss: 0.419608\n",
      "epoch 172; iter: 0; batch classifier loss: 0.103562; batch adversarial loss: 0.575650\n",
      "epoch 173; iter: 0; batch classifier loss: 0.097606; batch adversarial loss: 0.354531\n",
      "epoch 174; iter: 0; batch classifier loss: 0.117440; batch adversarial loss: 0.448525\n",
      "epoch 175; iter: 0; batch classifier loss: 0.083624; batch adversarial loss: 0.410324\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040277; batch adversarial loss: 0.412575\n",
      "epoch 177; iter: 0; batch classifier loss: 0.055920; batch adversarial loss: 0.348587\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037417; batch adversarial loss: 0.383807\n",
      "epoch 179; iter: 0; batch classifier loss: 0.039059; batch adversarial loss: 0.494575\n",
      "epoch 180; iter: 0; batch classifier loss: 0.031852; batch adversarial loss: 0.500363\n",
      "epoch 181; iter: 0; batch classifier loss: 0.044326; batch adversarial loss: 0.470421\n",
      "epoch 182; iter: 0; batch classifier loss: 0.056643; batch adversarial loss: 0.483989\n",
      "epoch 183; iter: 0; batch classifier loss: 0.021825; batch adversarial loss: 0.478435\n",
      "epoch 184; iter: 0; batch classifier loss: 0.072267; batch adversarial loss: 0.383266\n",
      "epoch 185; iter: 0; batch classifier loss: 0.033564; batch adversarial loss: 0.441278\n",
      "epoch 186; iter: 0; batch classifier loss: 0.063041; batch adversarial loss: 0.482200\n",
      "epoch 187; iter: 0; batch classifier loss: 0.028090; batch adversarial loss: 0.503814\n",
      "epoch 188; iter: 0; batch classifier loss: 0.023887; batch adversarial loss: 0.534380\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021724; batch adversarial loss: 0.564386\n",
      "epoch 190; iter: 0; batch classifier loss: 0.034142; batch adversarial loss: 0.515158\n",
      "epoch 191; iter: 0; batch classifier loss: 0.054036; batch adversarial loss: 0.399129\n",
      "epoch 192; iter: 0; batch classifier loss: 0.077091; batch adversarial loss: 0.409842\n",
      "epoch 193; iter: 0; batch classifier loss: 0.055837; batch adversarial loss: 0.479023\n",
      "epoch 194; iter: 0; batch classifier loss: 0.089952; batch adversarial loss: 0.366869\n",
      "epoch 195; iter: 0; batch classifier loss: 0.078760; batch adversarial loss: 0.373501\n",
      "epoch 196; iter: 0; batch classifier loss: 0.027313; batch adversarial loss: 0.550774\n",
      "epoch 197; iter: 0; batch classifier loss: 0.029985; batch adversarial loss: 0.447491\n",
      "epoch 198; iter: 0; batch classifier loss: 0.089215; batch adversarial loss: 0.410411\n",
      "epoch 199; iter: 0; batch classifier loss: 0.079790; batch adversarial loss: 0.490445\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710614; batch adversarial loss: 0.751079\n",
      "epoch 1; iter: 0; batch classifier loss: 0.420561; batch adversarial loss: 0.697201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.421269; batch adversarial loss: 0.662709\n",
      "epoch 3; iter: 0; batch classifier loss: 0.362427; batch adversarial loss: 0.638539\n",
      "epoch 4; iter: 0; batch classifier loss: 0.306953; batch adversarial loss: 0.595757\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391288; batch adversarial loss: 0.550597\n",
      "epoch 6; iter: 0; batch classifier loss: 0.374249; batch adversarial loss: 0.519669\n",
      "epoch 7; iter: 0; batch classifier loss: 0.321752; batch adversarial loss: 0.512378\n",
      "epoch 8; iter: 0; batch classifier loss: 0.260299; batch adversarial loss: 0.491076\n",
      "epoch 9; iter: 0; batch classifier loss: 0.261502; batch adversarial loss: 0.483284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.257395; batch adversarial loss: 0.468313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.221325; batch adversarial loss: 0.488915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.234404; batch adversarial loss: 0.451297\n",
      "epoch 13; iter: 0; batch classifier loss: 0.157642; batch adversarial loss: 0.464938\n",
      "epoch 14; iter: 0; batch classifier loss: 0.162422; batch adversarial loss: 0.485087\n",
      "epoch 15; iter: 0; batch classifier loss: 0.183528; batch adversarial loss: 0.484788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202216; batch adversarial loss: 0.454154\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210636; batch adversarial loss: 0.436236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.181777; batch adversarial loss: 0.498447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.167380; batch adversarial loss: 0.442208\n",
      "epoch 20; iter: 0; batch classifier loss: 0.157773; batch adversarial loss: 0.458210\n",
      "epoch 21; iter: 0; batch classifier loss: 0.161008; batch adversarial loss: 0.567135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.098135; batch adversarial loss: 0.522937\n",
      "epoch 23; iter: 0; batch classifier loss: 0.163881; batch adversarial loss: 0.419113\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167829; batch adversarial loss: 0.497101\n",
      "epoch 25; iter: 0; batch classifier loss: 0.166729; batch adversarial loss: 0.427719\n",
      "epoch 26; iter: 0; batch classifier loss: 0.154178; batch adversarial loss: 0.431474\n",
      "epoch 27; iter: 0; batch classifier loss: 0.167668; batch adversarial loss: 0.420042\n",
      "epoch 28; iter: 0; batch classifier loss: 0.197330; batch adversarial loss: 0.423841\n",
      "epoch 29; iter: 0; batch classifier loss: 0.172633; batch adversarial loss: 0.428684\n",
      "epoch 30; iter: 0; batch classifier loss: 0.137908; batch adversarial loss: 0.416968\n",
      "epoch 31; iter: 0; batch classifier loss: 0.140081; batch adversarial loss: 0.463392\n",
      "epoch 32; iter: 0; batch classifier loss: 0.151420; batch adversarial loss: 0.433761\n",
      "epoch 33; iter: 0; batch classifier loss: 0.141094; batch adversarial loss: 0.388561\n",
      "epoch 34; iter: 0; batch classifier loss: 0.122121; batch adversarial loss: 0.388985\n",
      "epoch 35; iter: 0; batch classifier loss: 0.125443; batch adversarial loss: 0.357121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.105316; batch adversarial loss: 0.452962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.185709; batch adversarial loss: 0.340376\n",
      "epoch 38; iter: 0; batch classifier loss: 0.090806; batch adversarial loss: 0.358266\n",
      "epoch 39; iter: 0; batch classifier loss: 0.121046; batch adversarial loss: 0.421355\n",
      "epoch 40; iter: 0; batch classifier loss: 0.080111; batch adversarial loss: 0.376878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.112952; batch adversarial loss: 0.466035\n",
      "epoch 42; iter: 0; batch classifier loss: 0.147852; batch adversarial loss: 0.420182\n",
      "epoch 43; iter: 0; batch classifier loss: 0.130229; batch adversarial loss: 0.449621\n",
      "epoch 44; iter: 0; batch classifier loss: 0.078088; batch adversarial loss: 0.347292\n",
      "epoch 45; iter: 0; batch classifier loss: 0.095169; batch adversarial loss: 0.375018\n",
      "epoch 46; iter: 0; batch classifier loss: 0.110609; batch adversarial loss: 0.397215\n",
      "epoch 47; iter: 0; batch classifier loss: 0.092343; batch adversarial loss: 0.496269\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082655; batch adversarial loss: 0.542128\n",
      "epoch 49; iter: 0; batch classifier loss: 0.089508; batch adversarial loss: 0.456396\n",
      "epoch 50; iter: 0; batch classifier loss: 0.081837; batch adversarial loss: 0.439871\n",
      "epoch 51; iter: 0; batch classifier loss: 0.096185; batch adversarial loss: 0.432639\n",
      "epoch 52; iter: 0; batch classifier loss: 0.105409; batch adversarial loss: 0.418386\n",
      "epoch 53; iter: 0; batch classifier loss: 0.106484; batch adversarial loss: 0.441181\n",
      "epoch 54; iter: 0; batch classifier loss: 0.117405; batch adversarial loss: 0.517986\n",
      "epoch 55; iter: 0; batch classifier loss: 0.081809; batch adversarial loss: 0.431760\n",
      "epoch 56; iter: 0; batch classifier loss: 0.077704; batch adversarial loss: 0.398033\n",
      "epoch 57; iter: 0; batch classifier loss: 0.088211; batch adversarial loss: 0.479897\n",
      "epoch 58; iter: 0; batch classifier loss: 0.081184; batch adversarial loss: 0.400557\n",
      "epoch 59; iter: 0; batch classifier loss: 0.072378; batch adversarial loss: 0.351440\n",
      "epoch 60; iter: 0; batch classifier loss: 0.115433; batch adversarial loss: 0.399627\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082115; batch adversarial loss: 0.355092\n",
      "epoch 62; iter: 0; batch classifier loss: 0.087557; batch adversarial loss: 0.412889\n",
      "epoch 63; iter: 0; batch classifier loss: 0.087948; batch adversarial loss: 0.450699\n",
      "epoch 64; iter: 0; batch classifier loss: 0.063926; batch adversarial loss: 0.411758\n",
      "epoch 65; iter: 0; batch classifier loss: 0.061279; batch adversarial loss: 0.415286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66; iter: 0; batch classifier loss: 0.077839; batch adversarial loss: 0.334942\n",
      "epoch 67; iter: 0; batch classifier loss: 0.117827; batch adversarial loss: 0.546085\n",
      "epoch 68; iter: 0; batch classifier loss: 0.076829; batch adversarial loss: 0.354828\n",
      "epoch 69; iter: 0; batch classifier loss: 0.082171; batch adversarial loss: 0.487849\n",
      "epoch 70; iter: 0; batch classifier loss: 0.120490; batch adversarial loss: 0.396874\n",
      "epoch 71; iter: 0; batch classifier loss: 0.061868; batch adversarial loss: 0.451198\n",
      "epoch 72; iter: 0; batch classifier loss: 0.085204; batch adversarial loss: 0.368574\n",
      "epoch 73; iter: 0; batch classifier loss: 0.072742; batch adversarial loss: 0.378171\n",
      "epoch 74; iter: 0; batch classifier loss: 0.067619; batch adversarial loss: 0.446338\n",
      "epoch 75; iter: 0; batch classifier loss: 0.057255; batch adversarial loss: 0.367957\n",
      "epoch 76; iter: 0; batch classifier loss: 0.113891; batch adversarial loss: 0.475349\n",
      "epoch 77; iter: 0; batch classifier loss: 0.070447; batch adversarial loss: 0.449989\n",
      "epoch 78; iter: 0; batch classifier loss: 0.052967; batch adversarial loss: 0.429485\n",
      "epoch 79; iter: 0; batch classifier loss: 0.093661; batch adversarial loss: 0.410259\n",
      "epoch 80; iter: 0; batch classifier loss: 0.078975; batch adversarial loss: 0.404756\n",
      "epoch 81; iter: 0; batch classifier loss: 0.052780; batch adversarial loss: 0.411292\n",
      "epoch 82; iter: 0; batch classifier loss: 0.091909; batch adversarial loss: 0.511062\n",
      "epoch 83; iter: 0; batch classifier loss: 0.062430; batch adversarial loss: 0.455073\n",
      "epoch 84; iter: 0; batch classifier loss: 0.103666; batch adversarial loss: 0.427634\n",
      "epoch 85; iter: 0; batch classifier loss: 0.107041; batch adversarial loss: 0.409778\n",
      "epoch 86; iter: 0; batch classifier loss: 0.076114; batch adversarial loss: 0.427192\n",
      "epoch 87; iter: 0; batch classifier loss: 0.060898; batch adversarial loss: 0.394414\n",
      "epoch 88; iter: 0; batch classifier loss: 0.074868; batch adversarial loss: 0.403658\n",
      "epoch 89; iter: 0; batch classifier loss: 0.056589; batch adversarial loss: 0.421813\n",
      "epoch 90; iter: 0; batch classifier loss: 0.079780; batch adversarial loss: 0.337235\n",
      "epoch 91; iter: 0; batch classifier loss: 0.100689; batch adversarial loss: 0.462279\n",
      "epoch 92; iter: 0; batch classifier loss: 0.102016; batch adversarial loss: 0.455019\n",
      "epoch 93; iter: 0; batch classifier loss: 0.061992; batch adversarial loss: 0.405747\n",
      "epoch 94; iter: 0; batch classifier loss: 0.078882; batch adversarial loss: 0.482843\n",
      "epoch 95; iter: 0; batch classifier loss: 0.071863; batch adversarial loss: 0.421392\n",
      "epoch 96; iter: 0; batch classifier loss: 0.088509; batch adversarial loss: 0.444545\n",
      "epoch 97; iter: 0; batch classifier loss: 0.049689; batch adversarial loss: 0.436363\n",
      "epoch 98; iter: 0; batch classifier loss: 0.081802; batch adversarial loss: 0.410559\n",
      "epoch 99; iter: 0; batch classifier loss: 0.076464; batch adversarial loss: 0.372768\n",
      "epoch 100; iter: 0; batch classifier loss: 0.062051; batch adversarial loss: 0.485860\n",
      "epoch 101; iter: 0; batch classifier loss: 0.076903; batch adversarial loss: 0.369128\n",
      "epoch 102; iter: 0; batch classifier loss: 0.068872; batch adversarial loss: 0.412909\n",
      "epoch 103; iter: 0; batch classifier loss: 0.094120; batch adversarial loss: 0.398843\n",
      "epoch 104; iter: 0; batch classifier loss: 0.079563; batch adversarial loss: 0.431515\n",
      "epoch 105; iter: 0; batch classifier loss: 0.064977; batch adversarial loss: 0.421767\n",
      "epoch 106; iter: 0; batch classifier loss: 0.053191; batch adversarial loss: 0.395771\n",
      "epoch 107; iter: 0; batch classifier loss: 0.039906; batch adversarial loss: 0.315476\n",
      "epoch 108; iter: 0; batch classifier loss: 0.035031; batch adversarial loss: 0.449275\n",
      "epoch 109; iter: 0; batch classifier loss: 0.071619; batch adversarial loss: 0.356929\n",
      "epoch 110; iter: 0; batch classifier loss: 0.088076; batch adversarial loss: 0.420016\n",
      "epoch 111; iter: 0; batch classifier loss: 0.086376; batch adversarial loss: 0.411568\n",
      "epoch 112; iter: 0; batch classifier loss: 0.071219; batch adversarial loss: 0.392453\n",
      "epoch 113; iter: 0; batch classifier loss: 0.060306; batch adversarial loss: 0.419202\n",
      "epoch 114; iter: 0; batch classifier loss: 0.051804; batch adversarial loss: 0.432860\n",
      "epoch 115; iter: 0; batch classifier loss: 0.064406; batch adversarial loss: 0.370556\n",
      "epoch 116; iter: 0; batch classifier loss: 0.074527; batch adversarial loss: 0.412794\n",
      "epoch 117; iter: 0; batch classifier loss: 0.049987; batch adversarial loss: 0.397821\n",
      "epoch 118; iter: 0; batch classifier loss: 0.049481; batch adversarial loss: 0.445841\n",
      "epoch 119; iter: 0; batch classifier loss: 0.082014; batch adversarial loss: 0.490131\n",
      "epoch 120; iter: 0; batch classifier loss: 0.058834; batch adversarial loss: 0.512956\n",
      "epoch 121; iter: 0; batch classifier loss: 0.060089; batch adversarial loss: 0.430935\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055231; batch adversarial loss: 0.469743\n",
      "epoch 123; iter: 0; batch classifier loss: 0.064405; batch adversarial loss: 0.412194\n",
      "epoch 124; iter: 0; batch classifier loss: 0.087675; batch adversarial loss: 0.490749\n",
      "epoch 125; iter: 0; batch classifier loss: 0.039948; batch adversarial loss: 0.464165\n",
      "epoch 126; iter: 0; batch classifier loss: 0.045405; batch adversarial loss: 0.441658\n",
      "epoch 127; iter: 0; batch classifier loss: 0.047613; batch adversarial loss: 0.393808\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036217; batch adversarial loss: 0.409220\n",
      "epoch 129; iter: 0; batch classifier loss: 0.036205; batch adversarial loss: 0.455601\n",
      "epoch 130; iter: 0; batch classifier loss: 0.030319; batch adversarial loss: 0.448005\n",
      "epoch 131; iter: 0; batch classifier loss: 0.064544; batch adversarial loss: 0.438365\n",
      "epoch 132; iter: 0; batch classifier loss: 0.059384; batch adversarial loss: 0.445249\n",
      "epoch 133; iter: 0; batch classifier loss: 0.045691; batch adversarial loss: 0.550089\n",
      "epoch 134; iter: 0; batch classifier loss: 0.057441; batch adversarial loss: 0.405927\n",
      "epoch 135; iter: 0; batch classifier loss: 0.013514; batch adversarial loss: 0.472908\n",
      "epoch 136; iter: 0; batch classifier loss: 0.063110; batch adversarial loss: 0.388291\n",
      "epoch 137; iter: 0; batch classifier loss: 0.025132; batch adversarial loss: 0.456715\n",
      "epoch 138; iter: 0; batch classifier loss: 0.035500; batch adversarial loss: 0.390983\n",
      "epoch 139; iter: 0; batch classifier loss: 0.033761; batch adversarial loss: 0.597788\n",
      "epoch 140; iter: 0; batch classifier loss: 0.026209; batch adversarial loss: 0.457631\n",
      "epoch 141; iter: 0; batch classifier loss: 0.022001; batch adversarial loss: 0.426944\n",
      "epoch 142; iter: 0; batch classifier loss: 0.031056; batch adversarial loss: 0.483533\n",
      "epoch 143; iter: 0; batch classifier loss: 0.025195; batch adversarial loss: 0.468877\n",
      "epoch 144; iter: 0; batch classifier loss: 0.038195; batch adversarial loss: 0.414074\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031225; batch adversarial loss: 0.471824\n",
      "epoch 146; iter: 0; batch classifier loss: 0.030901; batch adversarial loss: 0.434128\n",
      "epoch 147; iter: 0; batch classifier loss: 0.018033; batch adversarial loss: 0.452603\n",
      "epoch 148; iter: 0; batch classifier loss: 0.039104; batch adversarial loss: 0.417074\n",
      "epoch 149; iter: 0; batch classifier loss: 0.020166; batch adversarial loss: 0.574977\n",
      "epoch 150; iter: 0; batch classifier loss: 0.022043; batch adversarial loss: 0.393870\n",
      "epoch 151; iter: 0; batch classifier loss: 0.041090; batch adversarial loss: 0.427273\n",
      "epoch 152; iter: 0; batch classifier loss: 0.056661; batch adversarial loss: 0.412859\n",
      "epoch 153; iter: 0; batch classifier loss: 0.055215; batch adversarial loss: 0.592750\n",
      "epoch 154; iter: 0; batch classifier loss: 0.110177; batch adversarial loss: 0.675418\n",
      "epoch 155; iter: 0; batch classifier loss: 0.095540; batch adversarial loss: 0.648255\n",
      "epoch 156; iter: 0; batch classifier loss: 0.172726; batch adversarial loss: 0.723805\n",
      "epoch 157; iter: 0; batch classifier loss: 0.097115; batch adversarial loss: 0.576623\n",
      "epoch 158; iter: 0; batch classifier loss: 0.092190; batch adversarial loss: 0.609052\n",
      "epoch 159; iter: 0; batch classifier loss: 0.178736; batch adversarial loss: 0.705069\n",
      "epoch 160; iter: 0; batch classifier loss: 0.173771; batch adversarial loss: 0.713732\n",
      "epoch 161; iter: 0; batch classifier loss: 0.138951; batch adversarial loss: 0.660910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 162; iter: 0; batch classifier loss: 0.141821; batch adversarial loss: 0.691146\n",
      "epoch 163; iter: 0; batch classifier loss: 0.154855; batch adversarial loss: 0.717601\n",
      "epoch 164; iter: 0; batch classifier loss: 0.274503; batch adversarial loss: 0.970450\n",
      "epoch 165; iter: 0; batch classifier loss: 0.240239; batch adversarial loss: 0.943554\n",
      "epoch 166; iter: 0; batch classifier loss: 0.218315; batch adversarial loss: 0.738399\n",
      "epoch 167; iter: 0; batch classifier loss: 0.189888; batch adversarial loss: 0.668938\n",
      "epoch 168; iter: 0; batch classifier loss: 0.161767; batch adversarial loss: 0.612286\n",
      "epoch 169; iter: 0; batch classifier loss: 0.180635; batch adversarial loss: 0.647751\n",
      "epoch 170; iter: 0; batch classifier loss: 0.184592; batch adversarial loss: 0.700025\n",
      "epoch 171; iter: 0; batch classifier loss: 0.150117; batch adversarial loss: 0.679620\n",
      "epoch 172; iter: 0; batch classifier loss: 0.289265; batch adversarial loss: 0.845497\n",
      "epoch 173; iter: 0; batch classifier loss: 0.086633; batch adversarial loss: 0.546132\n",
      "epoch 174; iter: 0; batch classifier loss: 0.127718; batch adversarial loss: 0.547943\n",
      "epoch 175; iter: 0; batch classifier loss: 0.160058; batch adversarial loss: 0.679306\n",
      "epoch 176; iter: 0; batch classifier loss: 0.209581; batch adversarial loss: 0.677532\n",
      "epoch 177; iter: 0; batch classifier loss: 0.235433; batch adversarial loss: 0.723352\n",
      "epoch 178; iter: 0; batch classifier loss: 0.199151; batch adversarial loss: 0.702062\n",
      "epoch 179; iter: 0; batch classifier loss: 0.123405; batch adversarial loss: 0.603555\n",
      "epoch 180; iter: 0; batch classifier loss: 0.280601; batch adversarial loss: 0.805964\n",
      "epoch 181; iter: 0; batch classifier loss: 0.157929; batch adversarial loss: 0.541134\n",
      "epoch 182; iter: 0; batch classifier loss: 0.163841; batch adversarial loss: 0.656694\n",
      "epoch 183; iter: 0; batch classifier loss: 0.165199; batch adversarial loss: 0.587819\n",
      "epoch 184; iter: 0; batch classifier loss: 0.113650; batch adversarial loss: 0.549514\n",
      "epoch 185; iter: 0; batch classifier loss: 0.196558; batch adversarial loss: 0.652978\n",
      "epoch 186; iter: 0; batch classifier loss: 0.182998; batch adversarial loss: 0.536346\n",
      "epoch 187; iter: 0; batch classifier loss: 0.219825; batch adversarial loss: 0.675274\n",
      "epoch 188; iter: 0; batch classifier loss: 0.229183; batch adversarial loss: 0.677285\n",
      "epoch 189; iter: 0; batch classifier loss: 0.258780; batch adversarial loss: 0.703811\n",
      "epoch 190; iter: 0; batch classifier loss: 0.137323; batch adversarial loss: 0.461515\n",
      "epoch 191; iter: 0; batch classifier loss: 0.198746; batch adversarial loss: 0.620939\n",
      "epoch 192; iter: 0; batch classifier loss: 0.146756; batch adversarial loss: 0.473573\n",
      "epoch 193; iter: 0; batch classifier loss: 0.146096; batch adversarial loss: 0.605266\n",
      "epoch 194; iter: 0; batch classifier loss: 0.133979; batch adversarial loss: 0.508544\n",
      "epoch 195; iter: 0; batch classifier loss: 0.094490; batch adversarial loss: 0.437585\n",
      "epoch 196; iter: 0; batch classifier loss: 0.139252; batch adversarial loss: 0.573187\n",
      "epoch 197; iter: 0; batch classifier loss: 0.187315; batch adversarial loss: 0.629256\n",
      "epoch 198; iter: 0; batch classifier loss: 0.126940; batch adversarial loss: 0.477438\n",
      "epoch 199; iter: 0; batch classifier loss: 0.132614; batch adversarial loss: 0.533898\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693850; batch adversarial loss: 0.757066\n",
      "epoch 1; iter: 0; batch classifier loss: 0.461069; batch adversarial loss: 0.696901\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376647; batch adversarial loss: 0.728679\n",
      "epoch 3; iter: 0; batch classifier loss: 0.348878; batch adversarial loss: 0.709557\n",
      "epoch 4; iter: 0; batch classifier loss: 0.341926; batch adversarial loss: 0.623459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.327030; batch adversarial loss: 0.603857\n",
      "epoch 6; iter: 0; batch classifier loss: 0.275971; batch adversarial loss: 0.571662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293854; batch adversarial loss: 0.546843\n",
      "epoch 8; iter: 0; batch classifier loss: 0.239394; batch adversarial loss: 0.529000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282087; batch adversarial loss: 0.475382\n",
      "epoch 10; iter: 0; batch classifier loss: 0.231225; batch adversarial loss: 0.499399\n",
      "epoch 11; iter: 0; batch classifier loss: 0.189784; batch adversarial loss: 0.508079\n",
      "epoch 12; iter: 0; batch classifier loss: 0.211151; batch adversarial loss: 0.478047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229072; batch adversarial loss: 0.491348\n",
      "epoch 14; iter: 0; batch classifier loss: 0.212704; batch adversarial loss: 0.507779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.176052; batch adversarial loss: 0.446014\n",
      "epoch 16; iter: 0; batch classifier loss: 0.182033; batch adversarial loss: 0.482819\n",
      "epoch 17; iter: 0; batch classifier loss: 0.160076; batch adversarial loss: 0.501509\n",
      "epoch 18; iter: 0; batch classifier loss: 0.143807; batch adversarial loss: 0.480073\n",
      "epoch 19; iter: 0; batch classifier loss: 0.153451; batch adversarial loss: 0.385015\n",
      "epoch 20; iter: 0; batch classifier loss: 0.153334; batch adversarial loss: 0.423450\n",
      "epoch 21; iter: 0; batch classifier loss: 0.146386; batch adversarial loss: 0.358735\n",
      "epoch 22; iter: 0; batch classifier loss: 0.112211; batch adversarial loss: 0.353898\n",
      "epoch 23; iter: 0; batch classifier loss: 0.165290; batch adversarial loss: 0.381477\n",
      "epoch 24; iter: 0; batch classifier loss: 0.140158; batch adversarial loss: 0.400866\n",
      "epoch 25; iter: 0; batch classifier loss: 0.130058; batch adversarial loss: 0.486872\n",
      "epoch 26; iter: 0; batch classifier loss: 0.160111; batch adversarial loss: 0.356749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.112251; batch adversarial loss: 0.411426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.130109; batch adversarial loss: 0.376723\n",
      "epoch 29; iter: 0; batch classifier loss: 0.145128; batch adversarial loss: 0.397319\n",
      "epoch 30; iter: 0; batch classifier loss: 0.148774; batch adversarial loss: 0.397013\n",
      "epoch 31; iter: 0; batch classifier loss: 0.134490; batch adversarial loss: 0.395065\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115814; batch adversarial loss: 0.351049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.126292; batch adversarial loss: 0.447071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.139152; batch adversarial loss: 0.389619\n",
      "epoch 35; iter: 0; batch classifier loss: 0.117155; batch adversarial loss: 0.363430\n",
      "epoch 36; iter: 0; batch classifier loss: 0.099996; batch adversarial loss: 0.408643\n",
      "epoch 37; iter: 0; batch classifier loss: 0.096547; batch adversarial loss: 0.370407\n",
      "epoch 38; iter: 0; batch classifier loss: 0.150643; batch adversarial loss: 0.351014\n",
      "epoch 39; iter: 0; batch classifier loss: 0.100549; batch adversarial loss: 0.383872\n",
      "epoch 40; iter: 0; batch classifier loss: 0.101129; batch adversarial loss: 0.414848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.094976; batch adversarial loss: 0.480491\n",
      "epoch 42; iter: 0; batch classifier loss: 0.162151; batch adversarial loss: 0.390501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.161891; batch adversarial loss: 0.425493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.100656; batch adversarial loss: 0.400846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.089957; batch adversarial loss: 0.376233\n",
      "epoch 46; iter: 0; batch classifier loss: 0.075291; batch adversarial loss: 0.383652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.085880; batch adversarial loss: 0.431036\n",
      "epoch 48; iter: 0; batch classifier loss: 0.077167; batch adversarial loss: 0.402560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.072978; batch adversarial loss: 0.342536\n",
      "epoch 50; iter: 0; batch classifier loss: 0.115299; batch adversarial loss: 0.406821\n",
      "epoch 51; iter: 0; batch classifier loss: 0.084414; batch adversarial loss: 0.392225\n",
      "epoch 52; iter: 0; batch classifier loss: 0.098102; batch adversarial loss: 0.382473\n",
      "epoch 53; iter: 0; batch classifier loss: 0.050599; batch adversarial loss: 0.410622\n",
      "epoch 54; iter: 0; batch classifier loss: 0.086207; batch adversarial loss: 0.444804\n",
      "epoch 55; iter: 0; batch classifier loss: 0.102699; batch adversarial loss: 0.366637\n",
      "epoch 56; iter: 0; batch classifier loss: 0.094421; batch adversarial loss: 0.464039\n",
      "epoch 57; iter: 0; batch classifier loss: 0.072630; batch adversarial loss: 0.471146\n",
      "epoch 58; iter: 0; batch classifier loss: 0.082177; batch adversarial loss: 0.381130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59; iter: 0; batch classifier loss: 0.072005; batch adversarial loss: 0.433750\n",
      "epoch 60; iter: 0; batch classifier loss: 0.060221; batch adversarial loss: 0.335406\n",
      "epoch 61; iter: 0; batch classifier loss: 0.082509; batch adversarial loss: 0.338413\n",
      "epoch 62; iter: 0; batch classifier loss: 0.071919; batch adversarial loss: 0.452784\n",
      "epoch 63; iter: 0; batch classifier loss: 0.082166; batch adversarial loss: 0.521385\n",
      "epoch 64; iter: 0; batch classifier loss: 0.081804; batch adversarial loss: 0.439304\n",
      "epoch 65; iter: 0; batch classifier loss: 0.072982; batch adversarial loss: 0.472813\n",
      "epoch 66; iter: 0; batch classifier loss: 0.089863; batch adversarial loss: 0.364329\n",
      "epoch 67; iter: 0; batch classifier loss: 0.063514; batch adversarial loss: 0.337296\n",
      "epoch 68; iter: 0; batch classifier loss: 0.036129; batch adversarial loss: 0.332351\n",
      "epoch 69; iter: 0; batch classifier loss: 0.072702; batch adversarial loss: 0.466650\n",
      "epoch 70; iter: 0; batch classifier loss: 0.073022; batch adversarial loss: 0.379819\n",
      "epoch 71; iter: 0; batch classifier loss: 0.076280; batch adversarial loss: 0.369174\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054434; batch adversarial loss: 0.379746\n",
      "epoch 73; iter: 0; batch classifier loss: 0.098206; batch adversarial loss: 0.392494\n",
      "epoch 74; iter: 0; batch classifier loss: 0.054383; batch adversarial loss: 0.397488\n",
      "epoch 75; iter: 0; batch classifier loss: 0.075680; batch adversarial loss: 0.477953\n",
      "epoch 76; iter: 0; batch classifier loss: 0.074049; batch adversarial loss: 0.438229\n",
      "epoch 77; iter: 0; batch classifier loss: 0.091489; batch adversarial loss: 0.432836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.077277; batch adversarial loss: 0.527259\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049306; batch adversarial loss: 0.502411\n",
      "epoch 80; iter: 0; batch classifier loss: 0.067932; batch adversarial loss: 0.383919\n",
      "epoch 81; iter: 0; batch classifier loss: 0.039148; batch adversarial loss: 0.360694\n",
      "epoch 82; iter: 0; batch classifier loss: 0.068935; batch adversarial loss: 0.381742\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039411; batch adversarial loss: 0.407619\n",
      "epoch 84; iter: 0; batch classifier loss: 0.033408; batch adversarial loss: 0.446275\n",
      "epoch 85; iter: 0; batch classifier loss: 0.068853; batch adversarial loss: 0.392123\n",
      "epoch 86; iter: 0; batch classifier loss: 0.042927; batch adversarial loss: 0.444216\n",
      "epoch 87; iter: 0; batch classifier loss: 0.064307; batch adversarial loss: 0.320932\n",
      "epoch 88; iter: 0; batch classifier loss: 0.115546; batch adversarial loss: 0.397493\n",
      "epoch 89; iter: 0; batch classifier loss: 0.035100; batch adversarial loss: 0.350572\n",
      "epoch 90; iter: 0; batch classifier loss: 0.027946; batch adversarial loss: 0.403513\n",
      "epoch 91; iter: 0; batch classifier loss: 0.027529; batch adversarial loss: 0.459737\n",
      "epoch 92; iter: 0; batch classifier loss: 0.030000; batch adversarial loss: 0.445977\n",
      "epoch 93; iter: 0; batch classifier loss: 0.032787; batch adversarial loss: 0.485078\n",
      "epoch 94; iter: 0; batch classifier loss: 0.052483; batch adversarial loss: 0.411725\n",
      "epoch 95; iter: 0; batch classifier loss: 0.025847; batch adversarial loss: 0.413355\n",
      "epoch 96; iter: 0; batch classifier loss: 0.053690; batch adversarial loss: 0.449526\n",
      "epoch 97; iter: 0; batch classifier loss: 0.046338; batch adversarial loss: 0.371640\n",
      "epoch 98; iter: 0; batch classifier loss: 0.044463; batch adversarial loss: 0.448928\n",
      "epoch 99; iter: 0; batch classifier loss: 0.037711; batch adversarial loss: 0.432113\n",
      "epoch 100; iter: 0; batch classifier loss: 0.018651; batch adversarial loss: 0.482150\n",
      "epoch 101; iter: 0; batch classifier loss: 0.031021; batch adversarial loss: 0.417885\n",
      "epoch 102; iter: 0; batch classifier loss: 0.035740; batch adversarial loss: 0.375591\n",
      "epoch 103; iter: 0; batch classifier loss: 0.061576; batch adversarial loss: 0.404736\n",
      "epoch 104; iter: 0; batch classifier loss: 0.053676; batch adversarial loss: 0.380741\n",
      "epoch 105; iter: 0; batch classifier loss: 0.037579; batch adversarial loss: 0.421390\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040211; batch adversarial loss: 0.463566\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036440; batch adversarial loss: 0.485523\n",
      "epoch 108; iter: 0; batch classifier loss: 0.020442; batch adversarial loss: 0.445935\n",
      "epoch 109; iter: 0; batch classifier loss: 0.029606; batch adversarial loss: 0.482203\n",
      "epoch 110; iter: 0; batch classifier loss: 0.030358; batch adversarial loss: 0.434144\n",
      "epoch 111; iter: 0; batch classifier loss: 0.027038; batch adversarial loss: 0.384094\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026889; batch adversarial loss: 0.419105\n",
      "epoch 113; iter: 0; batch classifier loss: 0.015578; batch adversarial loss: 0.364946\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057763; batch adversarial loss: 0.489372\n",
      "epoch 115; iter: 0; batch classifier loss: 0.010938; batch adversarial loss: 0.491139\n",
      "epoch 116; iter: 0; batch classifier loss: 0.033042; batch adversarial loss: 0.488690\n",
      "epoch 117; iter: 0; batch classifier loss: 0.026669; batch adversarial loss: 0.430946\n",
      "epoch 118; iter: 0; batch classifier loss: 0.023762; batch adversarial loss: 0.421012\n",
      "epoch 119; iter: 0; batch classifier loss: 0.097397; batch adversarial loss: 0.470518\n",
      "epoch 120; iter: 0; batch classifier loss: 0.028807; batch adversarial loss: 0.534076\n",
      "epoch 121; iter: 0; batch classifier loss: 0.030846; batch adversarial loss: 0.324871\n",
      "epoch 122; iter: 0; batch classifier loss: 0.038616; batch adversarial loss: 0.445312\n",
      "epoch 123; iter: 0; batch classifier loss: 0.030726; batch adversarial loss: 0.465818\n",
      "epoch 124; iter: 0; batch classifier loss: 0.027422; batch adversarial loss: 0.462613\n",
      "epoch 125; iter: 0; batch classifier loss: 0.022455; batch adversarial loss: 0.441654\n",
      "epoch 126; iter: 0; batch classifier loss: 0.012607; batch adversarial loss: 0.449840\n",
      "epoch 127; iter: 0; batch classifier loss: 0.072627; batch adversarial loss: 0.588422\n",
      "epoch 128; iter: 0; batch classifier loss: 0.016658; batch adversarial loss: 0.445048\n",
      "epoch 129; iter: 0; batch classifier loss: 0.049414; batch adversarial loss: 0.465732\n",
      "epoch 130; iter: 0; batch classifier loss: 0.068412; batch adversarial loss: 0.588015\n",
      "epoch 131; iter: 0; batch classifier loss: 0.078170; batch adversarial loss: 0.546628\n",
      "epoch 132; iter: 0; batch classifier loss: 0.029295; batch adversarial loss: 0.524885\n",
      "epoch 133; iter: 0; batch classifier loss: 0.047739; batch adversarial loss: 0.463415\n",
      "epoch 134; iter: 0; batch classifier loss: 0.084401; batch adversarial loss: 0.508979\n",
      "epoch 135; iter: 0; batch classifier loss: 0.138605; batch adversarial loss: 0.643601\n",
      "epoch 136; iter: 0; batch classifier loss: 0.110393; batch adversarial loss: 0.519916\n",
      "epoch 137; iter: 0; batch classifier loss: 0.087855; batch adversarial loss: 0.453552\n",
      "epoch 138; iter: 0; batch classifier loss: 0.074498; batch adversarial loss: 0.490066\n",
      "epoch 139; iter: 0; batch classifier loss: 0.062949; batch adversarial loss: 0.572611\n",
      "epoch 140; iter: 0; batch classifier loss: 0.122721; batch adversarial loss: 0.574690\n",
      "epoch 141; iter: 0; batch classifier loss: 0.060789; batch adversarial loss: 0.514510\n",
      "epoch 142; iter: 0; batch classifier loss: 0.160929; batch adversarial loss: 0.662968\n",
      "epoch 143; iter: 0; batch classifier loss: 0.077529; batch adversarial loss: 0.635992\n",
      "epoch 144; iter: 0; batch classifier loss: 0.114577; batch adversarial loss: 0.639405\n",
      "epoch 145; iter: 0; batch classifier loss: 0.092128; batch adversarial loss: 0.524992\n",
      "epoch 146; iter: 0; batch classifier loss: 0.121984; batch adversarial loss: 0.623345\n",
      "epoch 147; iter: 0; batch classifier loss: 0.071316; batch adversarial loss: 0.572522\n",
      "epoch 148; iter: 0; batch classifier loss: 0.090214; batch adversarial loss: 0.525602\n",
      "epoch 149; iter: 0; batch classifier loss: 0.121911; batch adversarial loss: 0.662027\n",
      "epoch 150; iter: 0; batch classifier loss: 0.143079; batch adversarial loss: 0.547247\n",
      "epoch 151; iter: 0; batch classifier loss: 0.195317; batch adversarial loss: 0.694885\n",
      "epoch 152; iter: 0; batch classifier loss: 0.158634; batch adversarial loss: 0.592201\n",
      "epoch 153; iter: 0; batch classifier loss: 0.160115; batch adversarial loss: 0.643123\n",
      "epoch 154; iter: 0; batch classifier loss: 0.110223; batch adversarial loss: 0.549886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 155; iter: 0; batch classifier loss: 0.231193; batch adversarial loss: 0.704870\n",
      "epoch 156; iter: 0; batch classifier loss: 0.094499; batch adversarial loss: 0.518930\n",
      "epoch 157; iter: 0; batch classifier loss: 0.132318; batch adversarial loss: 0.557748\n",
      "epoch 158; iter: 0; batch classifier loss: 0.092221; batch adversarial loss: 0.499573\n",
      "epoch 159; iter: 0; batch classifier loss: 0.119612; batch adversarial loss: 0.493309\n",
      "epoch 160; iter: 0; batch classifier loss: 0.124663; batch adversarial loss: 0.579040\n",
      "epoch 161; iter: 0; batch classifier loss: 0.083550; batch adversarial loss: 0.532964\n",
      "epoch 162; iter: 0; batch classifier loss: 0.068538; batch adversarial loss: 0.494548\n",
      "epoch 163; iter: 0; batch classifier loss: 0.132678; batch adversarial loss: 0.507833\n",
      "epoch 164; iter: 0; batch classifier loss: 0.146413; batch adversarial loss: 0.594102\n",
      "epoch 165; iter: 0; batch classifier loss: 0.105702; batch adversarial loss: 0.450932\n",
      "epoch 166; iter: 0; batch classifier loss: 0.137714; batch adversarial loss: 0.540678\n",
      "epoch 167; iter: 0; batch classifier loss: 0.182039; batch adversarial loss: 0.556021\n",
      "epoch 168; iter: 0; batch classifier loss: 0.138445; batch adversarial loss: 0.552704\n",
      "epoch 169; iter: 0; batch classifier loss: 0.157282; batch adversarial loss: 0.512173\n",
      "epoch 170; iter: 0; batch classifier loss: 0.100472; batch adversarial loss: 0.507770\n",
      "epoch 171; iter: 0; batch classifier loss: 0.145341; batch adversarial loss: 0.547424\n",
      "epoch 172; iter: 0; batch classifier loss: 0.116136; batch adversarial loss: 0.465724\n",
      "epoch 173; iter: 0; batch classifier loss: 0.130159; batch adversarial loss: 0.519052\n",
      "epoch 174; iter: 0; batch classifier loss: 0.136063; batch adversarial loss: 0.520037\n",
      "epoch 175; iter: 0; batch classifier loss: 0.146892; batch adversarial loss: 0.588125\n",
      "epoch 176; iter: 0; batch classifier loss: 0.088052; batch adversarial loss: 0.400428\n",
      "epoch 177; iter: 0; batch classifier loss: 0.161683; batch adversarial loss: 0.481907\n",
      "epoch 178; iter: 0; batch classifier loss: 0.089490; batch adversarial loss: 0.442330\n",
      "epoch 179; iter: 0; batch classifier loss: 0.147194; batch adversarial loss: 0.522838\n",
      "epoch 180; iter: 0; batch classifier loss: 0.137283; batch adversarial loss: 0.480773\n",
      "epoch 181; iter: 0; batch classifier loss: 0.093371; batch adversarial loss: 0.410814\n",
      "epoch 182; iter: 0; batch classifier loss: 0.128466; batch adversarial loss: 0.572076\n",
      "epoch 183; iter: 0; batch classifier loss: 0.111428; batch adversarial loss: 0.555007\n",
      "epoch 184; iter: 0; batch classifier loss: 0.147616; batch adversarial loss: 0.591564\n",
      "epoch 185; iter: 0; batch classifier loss: 0.116976; batch adversarial loss: 0.399309\n",
      "epoch 186; iter: 0; batch classifier loss: 0.110696; batch adversarial loss: 0.458600\n",
      "epoch 187; iter: 0; batch classifier loss: 0.047834; batch adversarial loss: 0.457416\n",
      "epoch 188; iter: 0; batch classifier loss: 0.041381; batch adversarial loss: 0.393983\n",
      "epoch 189; iter: 0; batch classifier loss: 0.034924; batch adversarial loss: 0.526923\n",
      "epoch 190; iter: 0; batch classifier loss: 0.049774; batch adversarial loss: 0.404606\n",
      "epoch 191; iter: 0; batch classifier loss: 0.046580; batch adversarial loss: 0.553449\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013356; batch adversarial loss: 0.391498\n",
      "epoch 193; iter: 0; batch classifier loss: 0.035136; batch adversarial loss: 0.408664\n",
      "epoch 194; iter: 0; batch classifier loss: 0.026976; batch adversarial loss: 0.437965\n",
      "epoch 195; iter: 0; batch classifier loss: 0.027860; batch adversarial loss: 0.495513\n",
      "epoch 196; iter: 0; batch classifier loss: 0.010088; batch adversarial loss: 0.465443\n",
      "epoch 197; iter: 0; batch classifier loss: 0.060471; batch adversarial loss: 0.388896\n",
      "epoch 198; iter: 0; batch classifier loss: 0.035593; batch adversarial loss: 0.465335\n",
      "epoch 199; iter: 0; batch classifier loss: 0.043598; batch adversarial loss: 0.466768\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680246; batch adversarial loss: 0.810024\n",
      "epoch 1; iter: 0; batch classifier loss: 0.451362; batch adversarial loss: 0.767051\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396623; batch adversarial loss: 0.696835\n",
      "epoch 3; iter: 0; batch classifier loss: 0.357894; batch adversarial loss: 0.657939\n",
      "epoch 4; iter: 0; batch classifier loss: 0.282866; batch adversarial loss: 0.631828\n",
      "epoch 5; iter: 0; batch classifier loss: 0.359983; batch adversarial loss: 0.614349\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340352; batch adversarial loss: 0.566218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.293507; batch adversarial loss: 0.560358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.253195; batch adversarial loss: 0.528033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279180; batch adversarial loss: 0.518231\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264363; batch adversarial loss: 0.524841\n",
      "epoch 11; iter: 0; batch classifier loss: 0.212207; batch adversarial loss: 0.516823\n",
      "epoch 12; iter: 0; batch classifier loss: 0.217285; batch adversarial loss: 0.475998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225085; batch adversarial loss: 0.490410\n",
      "epoch 14; iter: 0; batch classifier loss: 0.200967; batch adversarial loss: 0.412896\n",
      "epoch 15; iter: 0; batch classifier loss: 0.175124; batch adversarial loss: 0.416507\n",
      "epoch 16; iter: 0; batch classifier loss: 0.180157; batch adversarial loss: 0.436534\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180319; batch adversarial loss: 0.450502\n",
      "epoch 18; iter: 0; batch classifier loss: 0.128997; batch adversarial loss: 0.490971\n",
      "epoch 19; iter: 0; batch classifier loss: 0.157482; batch adversarial loss: 0.409686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.206601; batch adversarial loss: 0.425286\n",
      "epoch 21; iter: 0; batch classifier loss: 0.148190; batch adversarial loss: 0.442754\n",
      "epoch 22; iter: 0; batch classifier loss: 0.174904; batch adversarial loss: 0.425326\n",
      "epoch 23; iter: 0; batch classifier loss: 0.184027; batch adversarial loss: 0.441240\n",
      "epoch 24; iter: 0; batch classifier loss: 0.122847; batch adversarial loss: 0.502580\n",
      "epoch 25; iter: 0; batch classifier loss: 0.153292; batch adversarial loss: 0.461803\n",
      "epoch 26; iter: 0; batch classifier loss: 0.140401; batch adversarial loss: 0.434970\n",
      "epoch 27; iter: 0; batch classifier loss: 0.134465; batch adversarial loss: 0.349610\n",
      "epoch 28; iter: 0; batch classifier loss: 0.116398; batch adversarial loss: 0.386064\n",
      "epoch 29; iter: 0; batch classifier loss: 0.147992; batch adversarial loss: 0.384682\n",
      "epoch 30; iter: 0; batch classifier loss: 0.185652; batch adversarial loss: 0.370000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.157063; batch adversarial loss: 0.399511\n",
      "epoch 32; iter: 0; batch classifier loss: 0.086406; batch adversarial loss: 0.337716\n",
      "epoch 33; iter: 0; batch classifier loss: 0.109652; batch adversarial loss: 0.382544\n",
      "epoch 34; iter: 0; batch classifier loss: 0.155361; batch adversarial loss: 0.440136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.159473; batch adversarial loss: 0.492241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.131805; batch adversarial loss: 0.370042\n",
      "epoch 37; iter: 0; batch classifier loss: 0.117400; batch adversarial loss: 0.436241\n",
      "epoch 38; iter: 0; batch classifier loss: 0.121056; batch adversarial loss: 0.467714\n",
      "epoch 39; iter: 0; batch classifier loss: 0.113234; batch adversarial loss: 0.398287\n",
      "epoch 40; iter: 0; batch classifier loss: 0.088190; batch adversarial loss: 0.373893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.147243; batch adversarial loss: 0.450062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.115763; batch adversarial loss: 0.411150\n",
      "epoch 43; iter: 0; batch classifier loss: 0.094286; batch adversarial loss: 0.475003\n",
      "epoch 44; iter: 0; batch classifier loss: 0.093093; batch adversarial loss: 0.397029\n",
      "epoch 45; iter: 0; batch classifier loss: 0.091354; batch adversarial loss: 0.399148\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084032; batch adversarial loss: 0.442064\n",
      "epoch 47; iter: 0; batch classifier loss: 0.070785; batch adversarial loss: 0.420990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.082436; batch adversarial loss: 0.481553\n",
      "epoch 49; iter: 0; batch classifier loss: 0.157507; batch adversarial loss: 0.470778\n",
      "epoch 50; iter: 0; batch classifier loss: 0.058240; batch adversarial loss: 0.330891\n",
      "epoch 51; iter: 0; batch classifier loss: 0.090727; batch adversarial loss: 0.440442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52; iter: 0; batch classifier loss: 0.084740; batch adversarial loss: 0.419793\n",
      "epoch 53; iter: 0; batch classifier loss: 0.070385; batch adversarial loss: 0.460603\n",
      "epoch 54; iter: 0; batch classifier loss: 0.079855; batch adversarial loss: 0.426939\n",
      "epoch 55; iter: 0; batch classifier loss: 0.105906; batch adversarial loss: 0.466212\n",
      "epoch 56; iter: 0; batch classifier loss: 0.081573; batch adversarial loss: 0.395374\n",
      "epoch 57; iter: 0; batch classifier loss: 0.097551; batch adversarial loss: 0.428597\n",
      "epoch 58; iter: 0; batch classifier loss: 0.078323; batch adversarial loss: 0.349382\n",
      "epoch 59; iter: 0; batch classifier loss: 0.079000; batch adversarial loss: 0.351624\n",
      "epoch 60; iter: 0; batch classifier loss: 0.069518; batch adversarial loss: 0.474845\n",
      "epoch 61; iter: 0; batch classifier loss: 0.051768; batch adversarial loss: 0.401141\n",
      "epoch 62; iter: 0; batch classifier loss: 0.057501; batch adversarial loss: 0.381303\n",
      "epoch 63; iter: 0; batch classifier loss: 0.097334; batch adversarial loss: 0.416759\n",
      "epoch 64; iter: 0; batch classifier loss: 0.071696; batch adversarial loss: 0.434989\n",
      "epoch 65; iter: 0; batch classifier loss: 0.069237; batch adversarial loss: 0.408543\n",
      "epoch 66; iter: 0; batch classifier loss: 0.092645; batch adversarial loss: 0.415954\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062363; batch adversarial loss: 0.358176\n",
      "epoch 68; iter: 0; batch classifier loss: 0.078024; batch adversarial loss: 0.420950\n",
      "epoch 69; iter: 0; batch classifier loss: 0.099522; batch adversarial loss: 0.430774\n",
      "epoch 70; iter: 0; batch classifier loss: 0.048283; batch adversarial loss: 0.459545\n",
      "epoch 71; iter: 0; batch classifier loss: 0.050152; batch adversarial loss: 0.478964\n",
      "epoch 72; iter: 0; batch classifier loss: 0.126334; batch adversarial loss: 0.460600\n",
      "epoch 73; iter: 0; batch classifier loss: 0.081574; batch adversarial loss: 0.378716\n",
      "epoch 74; iter: 0; batch classifier loss: 0.059598; batch adversarial loss: 0.416375\n",
      "epoch 75; iter: 0; batch classifier loss: 0.061496; batch adversarial loss: 0.425710\n",
      "epoch 76; iter: 0; batch classifier loss: 0.123520; batch adversarial loss: 0.596970\n",
      "epoch 77; iter: 0; batch classifier loss: 0.066887; batch adversarial loss: 0.398697\n",
      "epoch 78; iter: 0; batch classifier loss: 0.050505; batch adversarial loss: 0.259168\n",
      "epoch 79; iter: 0; batch classifier loss: 0.049194; batch adversarial loss: 0.414830\n",
      "epoch 80; iter: 0; batch classifier loss: 0.061995; batch adversarial loss: 0.579532\n",
      "epoch 81; iter: 0; batch classifier loss: 0.042050; batch adversarial loss: 0.409492\n",
      "epoch 82; iter: 0; batch classifier loss: 0.065200; batch adversarial loss: 0.470623\n",
      "epoch 83; iter: 0; batch classifier loss: 0.087788; batch adversarial loss: 0.504947\n",
      "epoch 84; iter: 0; batch classifier loss: 0.046046; batch adversarial loss: 0.408114\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070376; batch adversarial loss: 0.433473\n",
      "epoch 86; iter: 0; batch classifier loss: 0.112443; batch adversarial loss: 0.428856\n",
      "epoch 87; iter: 0; batch classifier loss: 0.061519; batch adversarial loss: 0.417747\n",
      "epoch 88; iter: 0; batch classifier loss: 0.063082; batch adversarial loss: 0.421238\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076482; batch adversarial loss: 0.465270\n",
      "epoch 90; iter: 0; batch classifier loss: 0.052314; batch adversarial loss: 0.403419\n",
      "epoch 91; iter: 0; batch classifier loss: 0.090064; batch adversarial loss: 0.391610\n",
      "epoch 92; iter: 0; batch classifier loss: 0.079510; batch adversarial loss: 0.455735\n",
      "epoch 93; iter: 0; batch classifier loss: 0.079772; batch adversarial loss: 0.383312\n",
      "epoch 94; iter: 0; batch classifier loss: 0.082038; batch adversarial loss: 0.452308\n",
      "epoch 95; iter: 0; batch classifier loss: 0.070079; batch adversarial loss: 0.430858\n",
      "epoch 96; iter: 0; batch classifier loss: 0.070542; batch adversarial loss: 0.401781\n",
      "epoch 97; iter: 0; batch classifier loss: 0.078586; batch adversarial loss: 0.390479\n",
      "epoch 98; iter: 0; batch classifier loss: 0.051892; batch adversarial loss: 0.351760\n",
      "epoch 99; iter: 0; batch classifier loss: 0.100085; batch adversarial loss: 0.369088\n",
      "epoch 100; iter: 0; batch classifier loss: 0.070429; batch adversarial loss: 0.526962\n",
      "epoch 101; iter: 0; batch classifier loss: 0.062177; batch adversarial loss: 0.372672\n",
      "epoch 102; iter: 0; batch classifier loss: 0.052578; batch adversarial loss: 0.361974\n",
      "epoch 103; iter: 0; batch classifier loss: 0.064209; batch adversarial loss: 0.440526\n",
      "epoch 104; iter: 0; batch classifier loss: 0.084991; batch adversarial loss: 0.427764\n",
      "epoch 105; iter: 0; batch classifier loss: 0.075899; batch adversarial loss: 0.398857\n",
      "epoch 106; iter: 0; batch classifier loss: 0.086655; batch adversarial loss: 0.371182\n",
      "epoch 107; iter: 0; batch classifier loss: 0.072560; batch adversarial loss: 0.415791\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037579; batch adversarial loss: 0.450042\n",
      "epoch 109; iter: 0; batch classifier loss: 0.076421; batch adversarial loss: 0.361580\n",
      "epoch 110; iter: 0; batch classifier loss: 0.085078; batch adversarial loss: 0.451300\n",
      "epoch 111; iter: 0; batch classifier loss: 0.050001; batch adversarial loss: 0.437623\n",
      "epoch 112; iter: 0; batch classifier loss: 0.070341; batch adversarial loss: 0.467763\n",
      "epoch 113; iter: 0; batch classifier loss: 0.054719; batch adversarial loss: 0.454870\n",
      "epoch 114; iter: 0; batch classifier loss: 0.025872; batch adversarial loss: 0.436652\n",
      "epoch 115; iter: 0; batch classifier loss: 0.088157; batch adversarial loss: 0.364016\n",
      "epoch 116; iter: 0; batch classifier loss: 0.068860; batch adversarial loss: 0.503922\n",
      "epoch 117; iter: 0; batch classifier loss: 0.054794; batch adversarial loss: 0.365507\n",
      "epoch 118; iter: 0; batch classifier loss: 0.057859; batch adversarial loss: 0.429109\n",
      "epoch 119; iter: 0; batch classifier loss: 0.056717; batch adversarial loss: 0.471496\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030335; batch adversarial loss: 0.407111\n",
      "epoch 121; iter: 0; batch classifier loss: 0.065963; batch adversarial loss: 0.376735\n",
      "epoch 122; iter: 0; batch classifier loss: 0.080630; batch adversarial loss: 0.387025\n",
      "epoch 123; iter: 0; batch classifier loss: 0.046558; batch adversarial loss: 0.482181\n",
      "epoch 124; iter: 0; batch classifier loss: 0.054431; batch adversarial loss: 0.455886\n",
      "epoch 125; iter: 0; batch classifier loss: 0.048923; batch adversarial loss: 0.424171\n",
      "epoch 126; iter: 0; batch classifier loss: 0.063491; batch adversarial loss: 0.471608\n",
      "epoch 127; iter: 0; batch classifier loss: 0.074584; batch adversarial loss: 0.450946\n",
      "epoch 128; iter: 0; batch classifier loss: 0.034057; batch adversarial loss: 0.391885\n",
      "epoch 129; iter: 0; batch classifier loss: 0.045730; batch adversarial loss: 0.396627\n",
      "epoch 130; iter: 0; batch classifier loss: 0.045819; batch adversarial loss: 0.472035\n",
      "epoch 131; iter: 0; batch classifier loss: 0.033456; batch adversarial loss: 0.404604\n",
      "epoch 132; iter: 0; batch classifier loss: 0.038060; batch adversarial loss: 0.481108\n",
      "epoch 133; iter: 0; batch classifier loss: 0.059510; batch adversarial loss: 0.458737\n",
      "epoch 134; iter: 0; batch classifier loss: 0.092608; batch adversarial loss: 0.294569\n",
      "epoch 135; iter: 0; batch classifier loss: 0.035613; batch adversarial loss: 0.387551\n",
      "epoch 136; iter: 0; batch classifier loss: 0.032607; batch adversarial loss: 0.377211\n",
      "epoch 137; iter: 0; batch classifier loss: 0.054927; batch adversarial loss: 0.416166\n",
      "epoch 138; iter: 0; batch classifier loss: 0.037195; batch adversarial loss: 0.535292\n",
      "epoch 139; iter: 0; batch classifier loss: 0.024973; batch adversarial loss: 0.346557\n",
      "epoch 140; iter: 0; batch classifier loss: 0.040989; batch adversarial loss: 0.365437\n",
      "epoch 141; iter: 0; batch classifier loss: 0.061527; batch adversarial loss: 0.383124\n",
      "epoch 142; iter: 0; batch classifier loss: 0.036629; batch adversarial loss: 0.461586\n",
      "epoch 143; iter: 0; batch classifier loss: 0.050296; batch adversarial loss: 0.447158\n",
      "epoch 144; iter: 0; batch classifier loss: 0.022128; batch adversarial loss: 0.438879\n",
      "epoch 145; iter: 0; batch classifier loss: 0.043014; batch adversarial loss: 0.409481\n",
      "epoch 146; iter: 0; batch classifier loss: 0.040362; batch adversarial loss: 0.430532\n",
      "epoch 147; iter: 0; batch classifier loss: 0.061685; batch adversarial loss: 0.455469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148; iter: 0; batch classifier loss: 0.037847; batch adversarial loss: 0.377027\n",
      "epoch 149; iter: 0; batch classifier loss: 0.035228; batch adversarial loss: 0.415800\n",
      "epoch 150; iter: 0; batch classifier loss: 0.036711; batch adversarial loss: 0.413352\n",
      "epoch 151; iter: 0; batch classifier loss: 0.057024; batch adversarial loss: 0.354891\n",
      "epoch 152; iter: 0; batch classifier loss: 0.021167; batch adversarial loss: 0.403204\n",
      "epoch 153; iter: 0; batch classifier loss: 0.036562; batch adversarial loss: 0.481959\n",
      "epoch 154; iter: 0; batch classifier loss: 0.020174; batch adversarial loss: 0.457301\n",
      "epoch 155; iter: 0; batch classifier loss: 0.016768; batch adversarial loss: 0.389349\n",
      "epoch 156; iter: 0; batch classifier loss: 0.056939; batch adversarial loss: 0.429712\n",
      "epoch 157; iter: 0; batch classifier loss: 0.057703; batch adversarial loss: 0.474522\n",
      "epoch 158; iter: 0; batch classifier loss: 0.028923; batch adversarial loss: 0.464557\n",
      "epoch 159; iter: 0; batch classifier loss: 0.053022; batch adversarial loss: 0.360971\n",
      "epoch 160; iter: 0; batch classifier loss: 0.037965; batch adversarial loss: 0.508851\n",
      "epoch 161; iter: 0; batch classifier loss: 0.017292; batch adversarial loss: 0.483919\n",
      "epoch 162; iter: 0; batch classifier loss: 0.023030; batch adversarial loss: 0.431961\n",
      "epoch 163; iter: 0; batch classifier loss: 0.027547; batch adversarial loss: 0.451107\n",
      "epoch 164; iter: 0; batch classifier loss: 0.025519; batch adversarial loss: 0.453974\n",
      "epoch 165; iter: 0; batch classifier loss: 0.043868; batch adversarial loss: 0.482589\n",
      "epoch 166; iter: 0; batch classifier loss: 0.030977; batch adversarial loss: 0.452906\n",
      "epoch 167; iter: 0; batch classifier loss: 0.025049; batch adversarial loss: 0.435779\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022976; batch adversarial loss: 0.415849\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037039; batch adversarial loss: 0.437933\n",
      "epoch 170; iter: 0; batch classifier loss: 0.066824; batch adversarial loss: 0.500502\n",
      "epoch 171; iter: 0; batch classifier loss: 0.054750; batch adversarial loss: 0.548538\n",
      "epoch 172; iter: 0; batch classifier loss: 0.069844; batch adversarial loss: 0.598237\n",
      "epoch 173; iter: 0; batch classifier loss: 0.088701; batch adversarial loss: 0.597451\n",
      "epoch 174; iter: 0; batch classifier loss: 0.062667; batch adversarial loss: 0.538452\n",
      "epoch 175; iter: 0; batch classifier loss: 0.105406; batch adversarial loss: 0.546457\n",
      "epoch 176; iter: 0; batch classifier loss: 0.085068; batch adversarial loss: 0.640727\n",
      "epoch 177; iter: 0; batch classifier loss: 0.149263; batch adversarial loss: 0.641293\n",
      "epoch 178; iter: 0; batch classifier loss: 0.139230; batch adversarial loss: 0.583276\n",
      "epoch 179; iter: 0; batch classifier loss: 0.097342; batch adversarial loss: 0.610108\n",
      "epoch 180; iter: 0; batch classifier loss: 0.186549; batch adversarial loss: 0.715575\n",
      "epoch 181; iter: 0; batch classifier loss: 0.184800; batch adversarial loss: 0.818158\n",
      "epoch 182; iter: 0; batch classifier loss: 0.176090; batch adversarial loss: 0.766948\n",
      "epoch 183; iter: 0; batch classifier loss: 0.140865; batch adversarial loss: 0.590785\n",
      "epoch 184; iter: 0; batch classifier loss: 0.217001; batch adversarial loss: 0.824571\n",
      "epoch 185; iter: 0; batch classifier loss: 0.183061; batch adversarial loss: 0.694886\n",
      "epoch 186; iter: 0; batch classifier loss: 0.106078; batch adversarial loss: 0.550794\n",
      "epoch 187; iter: 0; batch classifier loss: 0.166436; batch adversarial loss: 0.693852\n",
      "epoch 188; iter: 0; batch classifier loss: 0.300494; batch adversarial loss: 0.869091\n",
      "epoch 189; iter: 0; batch classifier loss: 0.170566; batch adversarial loss: 0.537992\n",
      "epoch 190; iter: 0; batch classifier loss: 0.273520; batch adversarial loss: 0.833910\n",
      "epoch 191; iter: 0; batch classifier loss: 0.212256; batch adversarial loss: 0.720380\n",
      "epoch 192; iter: 0; batch classifier loss: 0.183971; batch adversarial loss: 0.604828\n",
      "epoch 193; iter: 0; batch classifier loss: 0.174028; batch adversarial loss: 0.658259\n",
      "epoch 194; iter: 0; batch classifier loss: 0.206571; batch adversarial loss: 0.774236\n",
      "epoch 195; iter: 0; batch classifier loss: 0.133588; batch adversarial loss: 0.533002\n",
      "epoch 196; iter: 0; batch classifier loss: 0.197487; batch adversarial loss: 0.640587\n",
      "epoch 197; iter: 0; batch classifier loss: 0.227869; batch adversarial loss: 0.744096\n",
      "epoch 198; iter: 0; batch classifier loss: 0.252542; batch adversarial loss: 0.686332\n",
      "epoch 199; iter: 0; batch classifier loss: 0.185571; batch adversarial loss: 0.621490\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689543; batch adversarial loss: 0.913997\n",
      "epoch 1; iter: 0; batch classifier loss: 0.548097; batch adversarial loss: 0.934639\n",
      "epoch 2; iter: 0; batch classifier loss: 0.685040; batch adversarial loss: 0.929732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.882969; batch adversarial loss: 0.874907\n",
      "epoch 4; iter: 0; batch classifier loss: 1.018461; batch adversarial loss: 0.787123\n",
      "epoch 5; iter: 0; batch classifier loss: 1.022321; batch adversarial loss: 0.703612\n",
      "epoch 6; iter: 0; batch classifier loss: 1.067711; batch adversarial loss: 0.642531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.930727; batch adversarial loss: 0.614146\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536772; batch adversarial loss: 0.561116\n",
      "epoch 9; iter: 0; batch classifier loss: 0.380105; batch adversarial loss: 0.536259\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333625; batch adversarial loss: 0.526341\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352368; batch adversarial loss: 0.564017\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362154; batch adversarial loss: 0.520703\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396334; batch adversarial loss: 0.531049\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368220; batch adversarial loss: 0.503669\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386575; batch adversarial loss: 0.494818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343754; batch adversarial loss: 0.481318\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331220; batch adversarial loss: 0.499810\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358810; batch adversarial loss: 0.500428\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382423; batch adversarial loss: 0.476922\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294130; batch adversarial loss: 0.485365\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324134; batch adversarial loss: 0.542502\n",
      "epoch 22; iter: 0; batch classifier loss: 0.381856; batch adversarial loss: 0.458579\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306925; batch adversarial loss: 0.499822\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347429; batch adversarial loss: 0.455826\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291016; batch adversarial loss: 0.470233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276729; batch adversarial loss: 0.504794\n",
      "epoch 27; iter: 0; batch classifier loss: 0.236524; batch adversarial loss: 0.484674\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275229; batch adversarial loss: 0.439986\n",
      "epoch 29; iter: 0; batch classifier loss: 0.232334; batch adversarial loss: 0.529381\n",
      "epoch 30; iter: 0; batch classifier loss: 0.288596; batch adversarial loss: 0.434942\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283472; batch adversarial loss: 0.510199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.237902; batch adversarial loss: 0.504069\n",
      "epoch 33; iter: 0; batch classifier loss: 0.282631; batch adversarial loss: 0.467459\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279849; batch adversarial loss: 0.468268\n",
      "epoch 35; iter: 0; batch classifier loss: 0.279354; batch adversarial loss: 0.419732\n",
      "epoch 36; iter: 0; batch classifier loss: 0.183278; batch adversarial loss: 0.513530\n",
      "epoch 37; iter: 0; batch classifier loss: 0.297948; batch adversarial loss: 0.472062\n",
      "epoch 38; iter: 0; batch classifier loss: 0.228694; batch adversarial loss: 0.472941\n",
      "epoch 39; iter: 0; batch classifier loss: 0.231685; batch adversarial loss: 0.450419\n",
      "epoch 40; iter: 0; batch classifier loss: 0.202614; batch adversarial loss: 0.420474\n",
      "epoch 41; iter: 0; batch classifier loss: 0.229373; batch adversarial loss: 0.483887\n",
      "epoch 42; iter: 0; batch classifier loss: 0.213485; batch adversarial loss: 0.470483\n",
      "epoch 43; iter: 0; batch classifier loss: 0.198156; batch adversarial loss: 0.481515\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211132; batch adversarial loss: 0.386168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 0; batch classifier loss: 0.168020; batch adversarial loss: 0.573793\n",
      "epoch 46; iter: 0; batch classifier loss: 0.219640; batch adversarial loss: 0.453918\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252066; batch adversarial loss: 0.460092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.211017; batch adversarial loss: 0.436385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.234560; batch adversarial loss: 0.474145\n",
      "epoch 50; iter: 0; batch classifier loss: 0.204141; batch adversarial loss: 0.497282\n",
      "epoch 51; iter: 0; batch classifier loss: 0.181585; batch adversarial loss: 0.446684\n",
      "epoch 52; iter: 0; batch classifier loss: 0.141034; batch adversarial loss: 0.425215\n",
      "epoch 53; iter: 0; batch classifier loss: 0.160098; batch adversarial loss: 0.505424\n",
      "epoch 54; iter: 0; batch classifier loss: 0.180379; batch adversarial loss: 0.387911\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215606; batch adversarial loss: 0.432515\n",
      "epoch 56; iter: 0; batch classifier loss: 0.165415; batch adversarial loss: 0.400885\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170971; batch adversarial loss: 0.398558\n",
      "epoch 58; iter: 0; batch classifier loss: 0.175160; batch adversarial loss: 0.497488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.176790; batch adversarial loss: 0.445394\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209819; batch adversarial loss: 0.338047\n",
      "epoch 61; iter: 0; batch classifier loss: 0.156677; batch adversarial loss: 0.459216\n",
      "epoch 62; iter: 0; batch classifier loss: 0.144550; batch adversarial loss: 0.481671\n",
      "epoch 63; iter: 0; batch classifier loss: 0.208947; batch adversarial loss: 0.434346\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199902; batch adversarial loss: 0.532647\n",
      "epoch 65; iter: 0; batch classifier loss: 0.204802; batch adversarial loss: 0.457621\n",
      "epoch 66; iter: 0; batch classifier loss: 0.151210; batch adversarial loss: 0.446355\n",
      "epoch 67; iter: 0; batch classifier loss: 0.146519; batch adversarial loss: 0.569631\n",
      "epoch 68; iter: 0; batch classifier loss: 0.111854; batch adversarial loss: 0.422708\n",
      "epoch 69; iter: 0; batch classifier loss: 0.170244; batch adversarial loss: 0.375363\n",
      "epoch 70; iter: 0; batch classifier loss: 0.249436; batch adversarial loss: 0.470155\n",
      "epoch 71; iter: 0; batch classifier loss: 0.148235; batch adversarial loss: 0.448991\n",
      "epoch 72; iter: 0; batch classifier loss: 0.201852; batch adversarial loss: 0.506427\n",
      "epoch 73; iter: 0; batch classifier loss: 0.187272; batch adversarial loss: 0.505950\n",
      "epoch 74; iter: 0; batch classifier loss: 0.225230; batch adversarial loss: 0.480131\n",
      "epoch 75; iter: 0; batch classifier loss: 0.213568; batch adversarial loss: 0.459768\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153725; batch adversarial loss: 0.520891\n",
      "epoch 77; iter: 0; batch classifier loss: 0.228069; batch adversarial loss: 0.470056\n",
      "epoch 78; iter: 0; batch classifier loss: 0.115939; batch adversarial loss: 0.471940\n",
      "epoch 79; iter: 0; batch classifier loss: 0.190945; batch adversarial loss: 0.435656\n",
      "epoch 80; iter: 0; batch classifier loss: 0.156460; batch adversarial loss: 0.517819\n",
      "epoch 81; iter: 0; batch classifier loss: 0.184672; batch adversarial loss: 0.385333\n",
      "epoch 82; iter: 0; batch classifier loss: 0.171713; batch adversarial loss: 0.458014\n",
      "epoch 83; iter: 0; batch classifier loss: 0.190556; batch adversarial loss: 0.398211\n",
      "epoch 84; iter: 0; batch classifier loss: 0.165371; batch adversarial loss: 0.567927\n",
      "epoch 85; iter: 0; batch classifier loss: 0.194083; batch adversarial loss: 0.483153\n",
      "epoch 86; iter: 0; batch classifier loss: 0.143965; batch adversarial loss: 0.422092\n",
      "epoch 87; iter: 0; batch classifier loss: 0.178740; batch adversarial loss: 0.482179\n",
      "epoch 88; iter: 0; batch classifier loss: 0.139935; batch adversarial loss: 0.385912\n",
      "epoch 89; iter: 0; batch classifier loss: 0.173436; batch adversarial loss: 0.471630\n",
      "epoch 90; iter: 0; batch classifier loss: 0.178701; batch adversarial loss: 0.446935\n",
      "epoch 91; iter: 0; batch classifier loss: 0.187237; batch adversarial loss: 0.409557\n",
      "epoch 92; iter: 0; batch classifier loss: 0.104245; batch adversarial loss: 0.497035\n",
      "epoch 93; iter: 0; batch classifier loss: 0.113410; batch adversarial loss: 0.410037\n",
      "epoch 94; iter: 0; batch classifier loss: 0.153439; batch adversarial loss: 0.445962\n",
      "epoch 95; iter: 0; batch classifier loss: 0.190909; batch adversarial loss: 0.435004\n",
      "epoch 96; iter: 0; batch classifier loss: 0.182795; batch adversarial loss: 0.433466\n",
      "epoch 97; iter: 0; batch classifier loss: 0.157161; batch adversarial loss: 0.493173\n",
      "epoch 98; iter: 0; batch classifier loss: 0.195266; batch adversarial loss: 0.432736\n",
      "epoch 99; iter: 0; batch classifier loss: 0.136846; batch adversarial loss: 0.521645\n",
      "epoch 100; iter: 0; batch classifier loss: 0.174493; batch adversarial loss: 0.457785\n",
      "epoch 101; iter: 0; batch classifier loss: 0.138661; batch adversarial loss: 0.336682\n",
      "epoch 102; iter: 0; batch classifier loss: 0.147514; batch adversarial loss: 0.372538\n",
      "epoch 103; iter: 0; batch classifier loss: 0.176559; batch adversarial loss: 0.507709\n",
      "epoch 104; iter: 0; batch classifier loss: 0.126677; batch adversarial loss: 0.458051\n",
      "epoch 105; iter: 0; batch classifier loss: 0.099911; batch adversarial loss: 0.446913\n",
      "epoch 106; iter: 0; batch classifier loss: 0.167724; batch adversarial loss: 0.386305\n",
      "epoch 107; iter: 0; batch classifier loss: 0.129928; batch adversarial loss: 0.459027\n",
      "epoch 108; iter: 0; batch classifier loss: 0.123247; batch adversarial loss: 0.519669\n",
      "epoch 109; iter: 0; batch classifier loss: 0.115295; batch adversarial loss: 0.517309\n",
      "epoch 110; iter: 0; batch classifier loss: 0.105979; batch adversarial loss: 0.532277\n",
      "epoch 111; iter: 0; batch classifier loss: 0.160448; batch adversarial loss: 0.470432\n",
      "epoch 112; iter: 0; batch classifier loss: 0.147090; batch adversarial loss: 0.445767\n",
      "epoch 113; iter: 0; batch classifier loss: 0.133265; batch adversarial loss: 0.459747\n",
      "epoch 114; iter: 0; batch classifier loss: 0.080510; batch adversarial loss: 0.398040\n",
      "epoch 115; iter: 0; batch classifier loss: 0.142641; batch adversarial loss: 0.590623\n",
      "epoch 116; iter: 0; batch classifier loss: 0.142945; batch adversarial loss: 0.408791\n",
      "epoch 117; iter: 0; batch classifier loss: 0.105487; batch adversarial loss: 0.425267\n",
      "epoch 118; iter: 0; batch classifier loss: 0.120179; batch adversarial loss: 0.384323\n",
      "epoch 119; iter: 0; batch classifier loss: 0.124700; batch adversarial loss: 0.444623\n",
      "epoch 120; iter: 0; batch classifier loss: 0.085837; batch adversarial loss: 0.534905\n",
      "epoch 121; iter: 0; batch classifier loss: 0.085177; batch adversarial loss: 0.474008\n",
      "epoch 122; iter: 0; batch classifier loss: 0.135230; batch adversarial loss: 0.333110\n",
      "epoch 123; iter: 0; batch classifier loss: 0.048771; batch adversarial loss: 0.408736\n",
      "epoch 124; iter: 0; batch classifier loss: 0.139719; batch adversarial loss: 0.483153\n",
      "epoch 125; iter: 0; batch classifier loss: 0.089413; batch adversarial loss: 0.396350\n",
      "epoch 126; iter: 0; batch classifier loss: 0.084985; batch adversarial loss: 0.392968\n",
      "epoch 127; iter: 0; batch classifier loss: 0.094483; batch adversarial loss: 0.517912\n",
      "epoch 128; iter: 0; batch classifier loss: 0.026963; batch adversarial loss: 0.453451\n",
      "epoch 129; iter: 0; batch classifier loss: 0.054425; batch adversarial loss: 0.518731\n",
      "epoch 130; iter: 0; batch classifier loss: 0.073255; batch adversarial loss: 0.486788\n",
      "epoch 131; iter: 0; batch classifier loss: 0.034749; batch adversarial loss: 0.454708\n",
      "epoch 132; iter: 0; batch classifier loss: 0.049397; batch adversarial loss: 0.402750\n",
      "epoch 133; iter: 0; batch classifier loss: 0.031021; batch adversarial loss: 0.381624\n",
      "epoch 134; iter: 0; batch classifier loss: 0.034255; batch adversarial loss: 0.410104\n",
      "epoch 135; iter: 0; batch classifier loss: 0.019434; batch adversarial loss: 0.392521\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024610; batch adversarial loss: 0.393502\n",
      "epoch 137; iter: 0; batch classifier loss: 0.036196; batch adversarial loss: 0.463904\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031768; batch adversarial loss: 0.410277\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036492; batch adversarial loss: 0.523693\n",
      "epoch 140; iter: 0; batch classifier loss: 0.038428; batch adversarial loss: 0.452925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141; iter: 0; batch classifier loss: 0.052128; batch adversarial loss: 0.436720\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037624; batch adversarial loss: 0.493566\n",
      "epoch 143; iter: 0; batch classifier loss: 0.032230; batch adversarial loss: 0.480721\n",
      "epoch 144; iter: 0; batch classifier loss: 0.029862; batch adversarial loss: 0.517500\n",
      "epoch 145; iter: 0; batch classifier loss: 0.031431; batch adversarial loss: 0.410801\n",
      "epoch 146; iter: 0; batch classifier loss: 0.037825; batch adversarial loss: 0.453427\n",
      "epoch 147; iter: 0; batch classifier loss: 0.020353; batch adversarial loss: 0.438285\n",
      "epoch 148; iter: 0; batch classifier loss: 0.013913; batch adversarial loss: 0.526850\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011347; batch adversarial loss: 0.446605\n",
      "epoch 150; iter: 0; batch classifier loss: 0.011286; batch adversarial loss: 0.485572\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029325; batch adversarial loss: 0.491459\n",
      "epoch 152; iter: 0; batch classifier loss: 0.023272; batch adversarial loss: 0.485905\n",
      "epoch 153; iter: 0; batch classifier loss: 0.016158; batch adversarial loss: 0.450941\n",
      "epoch 154; iter: 0; batch classifier loss: 0.027193; batch adversarial loss: 0.408432\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023542; batch adversarial loss: 0.537961\n",
      "epoch 156; iter: 0; batch classifier loss: 0.037359; batch adversarial loss: 0.444172\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032573; batch adversarial loss: 0.446568\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010797; batch adversarial loss: 0.387792\n",
      "epoch 159; iter: 0; batch classifier loss: 0.017492; batch adversarial loss: 0.395206\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010200; batch adversarial loss: 0.479564\n",
      "epoch 161; iter: 0; batch classifier loss: 0.022960; batch adversarial loss: 0.493904\n",
      "epoch 162; iter: 0; batch classifier loss: 0.020865; batch adversarial loss: 0.385087\n",
      "epoch 163; iter: 0; batch classifier loss: 0.010057; batch adversarial loss: 0.414489\n",
      "epoch 164; iter: 0; batch classifier loss: 0.027711; batch adversarial loss: 0.395728\n",
      "epoch 165; iter: 0; batch classifier loss: 0.027906; batch adversarial loss: 0.500618\n",
      "epoch 166; iter: 0; batch classifier loss: 0.032444; batch adversarial loss: 0.488431\n",
      "epoch 167; iter: 0; batch classifier loss: 0.012479; batch adversarial loss: 0.513794\n",
      "epoch 168; iter: 0; batch classifier loss: 0.031151; batch adversarial loss: 0.452519\n",
      "epoch 169; iter: 0; batch classifier loss: 0.021752; batch adversarial loss: 0.509440\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021376; batch adversarial loss: 0.405471\n",
      "epoch 171; iter: 0; batch classifier loss: 0.021865; batch adversarial loss: 0.390699\n",
      "epoch 172; iter: 0; batch classifier loss: 0.012816; batch adversarial loss: 0.460955\n",
      "epoch 173; iter: 0; batch classifier loss: 0.033980; batch adversarial loss: 0.523408\n",
      "epoch 174; iter: 0; batch classifier loss: 0.022769; batch adversarial loss: 0.623594\n",
      "epoch 175; iter: 0; batch classifier loss: 0.018490; batch adversarial loss: 0.439043\n",
      "epoch 176; iter: 0; batch classifier loss: 0.019541; batch adversarial loss: 0.462760\n",
      "epoch 177; iter: 0; batch classifier loss: 0.008308; batch adversarial loss: 0.438756\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039474; batch adversarial loss: 0.422911\n",
      "epoch 179; iter: 0; batch classifier loss: 0.010933; batch adversarial loss: 0.526545\n",
      "epoch 180; iter: 0; batch classifier loss: 0.025866; batch adversarial loss: 0.486439\n",
      "epoch 181; iter: 0; batch classifier loss: 0.029571; batch adversarial loss: 0.503800\n",
      "epoch 182; iter: 0; batch classifier loss: 0.014229; batch adversarial loss: 0.387972\n",
      "epoch 183; iter: 0; batch classifier loss: 0.029961; batch adversarial loss: 0.420192\n",
      "epoch 184; iter: 0; batch classifier loss: 0.016659; batch adversarial loss: 0.433171\n",
      "epoch 185; iter: 0; batch classifier loss: 0.015789; batch adversarial loss: 0.463997\n",
      "epoch 186; iter: 0; batch classifier loss: 0.009110; batch adversarial loss: 0.389142\n",
      "epoch 187; iter: 0; batch classifier loss: 0.018754; batch adversarial loss: 0.458825\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006102; batch adversarial loss: 0.447519\n",
      "epoch 189; iter: 0; batch classifier loss: 0.021028; batch adversarial loss: 0.421183\n",
      "epoch 190; iter: 0; batch classifier loss: 0.023161; batch adversarial loss: 0.565063\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008598; batch adversarial loss: 0.487903\n",
      "epoch 192; iter: 0; batch classifier loss: 0.035410; batch adversarial loss: 0.440808\n",
      "epoch 193; iter: 0; batch classifier loss: 0.022546; batch adversarial loss: 0.428986\n",
      "epoch 194; iter: 0; batch classifier loss: 0.014402; batch adversarial loss: 0.421163\n",
      "epoch 195; iter: 0; batch classifier loss: 0.005932; batch adversarial loss: 0.462267\n",
      "epoch 196; iter: 0; batch classifier loss: 0.030918; batch adversarial loss: 0.452308\n",
      "epoch 197; iter: 0; batch classifier loss: 0.009518; batch adversarial loss: 0.396693\n",
      "epoch 198; iter: 0; batch classifier loss: 0.009699; batch adversarial loss: 0.486388\n",
      "epoch 199; iter: 0; batch classifier loss: 0.026764; batch adversarial loss: 0.440656\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708161; batch adversarial loss: 0.632518\n",
      "epoch 1; iter: 0; batch classifier loss: 0.518360; batch adversarial loss: 0.610236\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535843; batch adversarial loss: 0.606388\n",
      "epoch 3; iter: 0; batch classifier loss: 0.390141; batch adversarial loss: 0.599022\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382892; batch adversarial loss: 0.626497\n",
      "epoch 5; iter: 0; batch classifier loss: 0.511481; batch adversarial loss: 0.580913\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563531; batch adversarial loss: 0.588618\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500330; batch adversarial loss: 0.563970\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426269; batch adversarial loss: 0.555941\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414084; batch adversarial loss: 0.581960\n",
      "epoch 10; iter: 0; batch classifier loss: 0.362265; batch adversarial loss: 0.537268\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360466; batch adversarial loss: 0.540677\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422144; batch adversarial loss: 0.531421\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430459; batch adversarial loss: 0.524158\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356439; batch adversarial loss: 0.504602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347349; batch adversarial loss: 0.534679\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.459150\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.543026\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257937; batch adversarial loss: 0.403908\n",
      "epoch 19; iter: 0; batch classifier loss: 0.314833; batch adversarial loss: 0.418959\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278634; batch adversarial loss: 0.449687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249246; batch adversarial loss: 0.451116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.308415; batch adversarial loss: 0.477212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242862; batch adversarial loss: 0.507581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261467; batch adversarial loss: 0.484585\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216494; batch adversarial loss: 0.429585\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244711; batch adversarial loss: 0.458749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281848; batch adversarial loss: 0.448435\n",
      "epoch 28; iter: 0; batch classifier loss: 0.178076; batch adversarial loss: 0.497157\n",
      "epoch 29; iter: 0; batch classifier loss: 0.213757; batch adversarial loss: 0.553909\n",
      "epoch 30; iter: 0; batch classifier loss: 0.150461; batch adversarial loss: 0.512257\n",
      "epoch 31; iter: 0; batch classifier loss: 0.261511; batch adversarial loss: 0.428973\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304960; batch adversarial loss: 0.435669\n",
      "epoch 33; iter: 0; batch classifier loss: 0.201877; batch adversarial loss: 0.403675\n",
      "epoch 34; iter: 0; batch classifier loss: 0.208724; batch adversarial loss: 0.537148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.181095; batch adversarial loss: 0.388224\n",
      "epoch 36; iter: 0; batch classifier loss: 0.165401; batch adversarial loss: 0.354131\n",
      "epoch 37; iter: 0; batch classifier loss: 0.179579; batch adversarial loss: 0.517824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.176061; batch adversarial loss: 0.488745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.270597; batch adversarial loss: 0.423221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.181568; batch adversarial loss: 0.340318\n",
      "epoch 41; iter: 0; batch classifier loss: 0.215699; batch adversarial loss: 0.555345\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174083; batch adversarial loss: 0.449441\n",
      "epoch 43; iter: 0; batch classifier loss: 0.171599; batch adversarial loss: 0.417490\n",
      "epoch 44; iter: 0; batch classifier loss: 0.212252; batch adversarial loss: 0.405845\n",
      "epoch 45; iter: 0; batch classifier loss: 0.208932; batch adversarial loss: 0.422596\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242066; batch adversarial loss: 0.475960\n",
      "epoch 47; iter: 0; batch classifier loss: 0.205313; batch adversarial loss: 0.425661\n",
      "epoch 48; iter: 0; batch classifier loss: 0.226104; batch adversarial loss: 0.338401\n",
      "epoch 49; iter: 0; batch classifier loss: 0.151252; batch adversarial loss: 0.547247\n",
      "epoch 50; iter: 0; batch classifier loss: 0.181594; batch adversarial loss: 0.534147\n",
      "epoch 51; iter: 0; batch classifier loss: 0.203390; batch adversarial loss: 0.422662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.180724; batch adversarial loss: 0.480844\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222910; batch adversarial loss: 0.399266\n",
      "epoch 54; iter: 0; batch classifier loss: 0.179362; batch adversarial loss: 0.408203\n",
      "epoch 55; iter: 0; batch classifier loss: 0.178611; batch adversarial loss: 0.470402\n",
      "epoch 56; iter: 0; batch classifier loss: 0.132050; batch adversarial loss: 0.398670\n",
      "epoch 57; iter: 0; batch classifier loss: 0.179249; batch adversarial loss: 0.473252\n",
      "epoch 58; iter: 0; batch classifier loss: 0.191924; batch adversarial loss: 0.423130\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192082; batch adversarial loss: 0.421357\n",
      "epoch 60; iter: 0; batch classifier loss: 0.143640; batch adversarial loss: 0.462170\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175377; batch adversarial loss: 0.445698\n",
      "epoch 62; iter: 0; batch classifier loss: 0.231073; batch adversarial loss: 0.399867\n",
      "epoch 63; iter: 0; batch classifier loss: 0.162443; batch adversarial loss: 0.520615\n",
      "epoch 64; iter: 0; batch classifier loss: 0.171537; batch adversarial loss: 0.494335\n",
      "epoch 65; iter: 0; batch classifier loss: 0.197286; batch adversarial loss: 0.424075\n",
      "epoch 66; iter: 0; batch classifier loss: 0.256621; batch adversarial loss: 0.422484\n",
      "epoch 67; iter: 0; batch classifier loss: 0.153528; batch adversarial loss: 0.445622\n",
      "epoch 68; iter: 0; batch classifier loss: 0.215346; batch adversarial loss: 0.372363\n",
      "epoch 69; iter: 0; batch classifier loss: 0.161453; batch adversarial loss: 0.482706\n",
      "epoch 70; iter: 0; batch classifier loss: 0.182925; batch adversarial loss: 0.445804\n",
      "epoch 71; iter: 0; batch classifier loss: 0.186903; batch adversarial loss: 0.422238\n",
      "epoch 72; iter: 0; batch classifier loss: 0.216217; batch adversarial loss: 0.371757\n",
      "epoch 73; iter: 0; batch classifier loss: 0.139755; batch adversarial loss: 0.484145\n",
      "epoch 74; iter: 0; batch classifier loss: 0.208239; batch adversarial loss: 0.507008\n",
      "epoch 75; iter: 0; batch classifier loss: 0.189552; batch adversarial loss: 0.447020\n",
      "epoch 76; iter: 0; batch classifier loss: 0.240851; batch adversarial loss: 0.422116\n",
      "epoch 77; iter: 0; batch classifier loss: 0.101101; batch adversarial loss: 0.520922\n",
      "epoch 78; iter: 0; batch classifier loss: 0.086505; batch adversarial loss: 0.381415\n",
      "epoch 79; iter: 0; batch classifier loss: 0.115380; batch adversarial loss: 0.475154\n",
      "epoch 80; iter: 0; batch classifier loss: 0.199080; batch adversarial loss: 0.492674\n",
      "epoch 81; iter: 0; batch classifier loss: 0.090493; batch adversarial loss: 0.520698\n",
      "epoch 82; iter: 0; batch classifier loss: 0.113510; batch adversarial loss: 0.412165\n",
      "epoch 83; iter: 0; batch classifier loss: 0.083756; batch adversarial loss: 0.438255\n",
      "epoch 84; iter: 0; batch classifier loss: 0.113630; batch adversarial loss: 0.358088\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070255; batch adversarial loss: 0.396138\n",
      "epoch 86; iter: 0; batch classifier loss: 0.100156; batch adversarial loss: 0.503270\n",
      "epoch 87; iter: 0; batch classifier loss: 0.092127; batch adversarial loss: 0.493604\n",
      "epoch 88; iter: 0; batch classifier loss: 0.124174; batch adversarial loss: 0.518519\n",
      "epoch 89; iter: 0; batch classifier loss: 0.094202; batch adversarial loss: 0.383024\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073465; batch adversarial loss: 0.378751\n",
      "epoch 91; iter: 0; batch classifier loss: 0.096573; batch adversarial loss: 0.462737\n",
      "epoch 92; iter: 0; batch classifier loss: 0.074636; batch adversarial loss: 0.481273\n",
      "epoch 93; iter: 0; batch classifier loss: 0.089677; batch adversarial loss: 0.371953\n",
      "epoch 94; iter: 0; batch classifier loss: 0.084582; batch adversarial loss: 0.411533\n",
      "epoch 95; iter: 0; batch classifier loss: 0.064437; batch adversarial loss: 0.453814\n",
      "epoch 96; iter: 0; batch classifier loss: 0.091420; batch adversarial loss: 0.451506\n",
      "epoch 97; iter: 0; batch classifier loss: 0.066032; batch adversarial loss: 0.454480\n",
      "epoch 98; iter: 0; batch classifier loss: 0.103302; batch adversarial loss: 0.300933\n",
      "epoch 99; iter: 0; batch classifier loss: 0.052976; batch adversarial loss: 0.412298\n",
      "epoch 100; iter: 0; batch classifier loss: 0.076417; batch adversarial loss: 0.417882\n",
      "epoch 101; iter: 0; batch classifier loss: 0.055812; batch adversarial loss: 0.454356\n",
      "epoch 102; iter: 0; batch classifier loss: 0.037327; batch adversarial loss: 0.421289\n",
      "epoch 103; iter: 0; batch classifier loss: 0.066954; batch adversarial loss: 0.437378\n",
      "epoch 104; iter: 0; batch classifier loss: 0.043617; batch adversarial loss: 0.541228\n",
      "epoch 105; iter: 0; batch classifier loss: 0.040232; batch adversarial loss: 0.517600\n",
      "epoch 106; iter: 0; batch classifier loss: 0.075711; batch adversarial loss: 0.488629\n",
      "epoch 107; iter: 0; batch classifier loss: 0.107433; batch adversarial loss: 0.424644\n",
      "epoch 108; iter: 0; batch classifier loss: 0.036173; batch adversarial loss: 0.415976\n",
      "epoch 109; iter: 0; batch classifier loss: 0.037374; batch adversarial loss: 0.430608\n",
      "epoch 110; iter: 0; batch classifier loss: 0.041157; batch adversarial loss: 0.551063\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042478; batch adversarial loss: 0.529089\n",
      "epoch 112; iter: 0; batch classifier loss: 0.033712; batch adversarial loss: 0.451173\n",
      "epoch 113; iter: 0; batch classifier loss: 0.071488; batch adversarial loss: 0.481772\n",
      "epoch 114; iter: 0; batch classifier loss: 0.049337; batch adversarial loss: 0.427229\n",
      "epoch 115; iter: 0; batch classifier loss: 0.028704; batch adversarial loss: 0.443292\n",
      "epoch 116; iter: 0; batch classifier loss: 0.085982; batch adversarial loss: 0.499928\n",
      "epoch 117; iter: 0; batch classifier loss: 0.056194; batch adversarial loss: 0.490472\n",
      "epoch 118; iter: 0; batch classifier loss: 0.029320; batch adversarial loss: 0.438678\n",
      "epoch 119; iter: 0; batch classifier loss: 0.032207; batch adversarial loss: 0.462134\n",
      "epoch 120; iter: 0; batch classifier loss: 0.049952; batch adversarial loss: 0.455501\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036728; batch adversarial loss: 0.439625\n",
      "epoch 122; iter: 0; batch classifier loss: 0.015281; batch adversarial loss: 0.449097\n",
      "epoch 123; iter: 0; batch classifier loss: 0.042261; batch adversarial loss: 0.423335\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041518; batch adversarial loss: 0.511026\n",
      "epoch 125; iter: 0; batch classifier loss: 0.028836; batch adversarial loss: 0.475033\n",
      "epoch 126; iter: 0; batch classifier loss: 0.038973; batch adversarial loss: 0.419221\n",
      "epoch 127; iter: 0; batch classifier loss: 0.030881; batch adversarial loss: 0.412270\n",
      "epoch 128; iter: 0; batch classifier loss: 0.024236; batch adversarial loss: 0.443120\n",
      "epoch 129; iter: 0; batch classifier loss: 0.017852; batch adversarial loss: 0.545859\n",
      "epoch 130; iter: 0; batch classifier loss: 0.013145; batch adversarial loss: 0.409091\n",
      "epoch 131; iter: 0; batch classifier loss: 0.023440; batch adversarial loss: 0.457194\n",
      "epoch 132; iter: 0; batch classifier loss: 0.015999; batch adversarial loss: 0.376748\n",
      "epoch 133; iter: 0; batch classifier loss: 0.033688; batch adversarial loss: 0.382072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134; iter: 0; batch classifier loss: 0.050246; batch adversarial loss: 0.415126\n",
      "epoch 135; iter: 0; batch classifier loss: 0.020256; batch adversarial loss: 0.439541\n",
      "epoch 136; iter: 0; batch classifier loss: 0.024339; batch adversarial loss: 0.399975\n",
      "epoch 137; iter: 0; batch classifier loss: 0.014830; batch adversarial loss: 0.491868\n",
      "epoch 138; iter: 0; batch classifier loss: 0.048983; batch adversarial loss: 0.411184\n",
      "epoch 139; iter: 0; batch classifier loss: 0.022757; batch adversarial loss: 0.503213\n",
      "epoch 140; iter: 0; batch classifier loss: 0.022405; batch adversarial loss: 0.475248\n",
      "epoch 141; iter: 0; batch classifier loss: 0.027825; batch adversarial loss: 0.391512\n",
      "epoch 142; iter: 0; batch classifier loss: 0.025831; batch adversarial loss: 0.392719\n",
      "epoch 143; iter: 0; batch classifier loss: 0.027783; batch adversarial loss: 0.465400\n",
      "epoch 144; iter: 0; batch classifier loss: 0.033853; batch adversarial loss: 0.457330\n",
      "epoch 145; iter: 0; batch classifier loss: 0.025808; batch adversarial loss: 0.511991\n",
      "epoch 146; iter: 0; batch classifier loss: 0.031108; batch adversarial loss: 0.415830\n",
      "epoch 147; iter: 0; batch classifier loss: 0.031203; batch adversarial loss: 0.393508\n",
      "epoch 148; iter: 0; batch classifier loss: 0.025564; batch adversarial loss: 0.424843\n",
      "epoch 149; iter: 0; batch classifier loss: 0.011537; batch adversarial loss: 0.492477\n",
      "epoch 150; iter: 0; batch classifier loss: 0.029517; batch adversarial loss: 0.462999\n",
      "epoch 151; iter: 0; batch classifier loss: 0.016534; batch adversarial loss: 0.528121\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013328; batch adversarial loss: 0.552596\n",
      "epoch 153; iter: 0; batch classifier loss: 0.032096; batch adversarial loss: 0.453599\n",
      "epoch 154; iter: 0; batch classifier loss: 0.032040; batch adversarial loss: 0.411841\n",
      "epoch 155; iter: 0; batch classifier loss: 0.012068; batch adversarial loss: 0.406578\n",
      "epoch 156; iter: 0; batch classifier loss: 0.013702; batch adversarial loss: 0.376287\n",
      "epoch 157; iter: 0; batch classifier loss: 0.016005; batch adversarial loss: 0.471344\n",
      "epoch 158; iter: 0; batch classifier loss: 0.080290; batch adversarial loss: 0.447340\n",
      "epoch 159; iter: 0; batch classifier loss: 0.018850; batch adversarial loss: 0.413365\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024004; batch adversarial loss: 0.427462\n",
      "epoch 161; iter: 0; batch classifier loss: 0.041942; batch adversarial loss: 0.496959\n",
      "epoch 162; iter: 0; batch classifier loss: 0.019149; batch adversarial loss: 0.440325\n",
      "epoch 163; iter: 0; batch classifier loss: 0.015198; batch adversarial loss: 0.496082\n",
      "epoch 164; iter: 0; batch classifier loss: 0.015538; batch adversarial loss: 0.459259\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036814; batch adversarial loss: 0.504914\n",
      "epoch 166; iter: 0; batch classifier loss: 0.007327; batch adversarial loss: 0.530238\n",
      "epoch 167; iter: 0; batch classifier loss: 0.052905; batch adversarial loss: 0.513017\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015124; batch adversarial loss: 0.404137\n",
      "epoch 169; iter: 0; batch classifier loss: 0.008923; batch adversarial loss: 0.450867\n",
      "epoch 170; iter: 0; batch classifier loss: 0.021035; batch adversarial loss: 0.395148\n",
      "epoch 171; iter: 0; batch classifier loss: 0.041513; batch adversarial loss: 0.420982\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011314; batch adversarial loss: 0.434855\n",
      "epoch 173; iter: 0; batch classifier loss: 0.025724; batch adversarial loss: 0.503647\n",
      "epoch 174; iter: 0; batch classifier loss: 0.007067; batch adversarial loss: 0.506957\n",
      "epoch 175; iter: 0; batch classifier loss: 0.004246; batch adversarial loss: 0.376929\n",
      "epoch 176; iter: 0; batch classifier loss: 0.011809; batch adversarial loss: 0.424664\n",
      "epoch 177; iter: 0; batch classifier loss: 0.048724; batch adversarial loss: 0.398612\n",
      "epoch 178; iter: 0; batch classifier loss: 0.052765; batch adversarial loss: 0.464049\n",
      "epoch 179; iter: 0; batch classifier loss: 0.007489; batch adversarial loss: 0.318337\n",
      "epoch 180; iter: 0; batch classifier loss: 0.017220; batch adversarial loss: 0.423241\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018876; batch adversarial loss: 0.426460\n",
      "epoch 182; iter: 0; batch classifier loss: 0.021970; batch adversarial loss: 0.414242\n",
      "epoch 183; iter: 0; batch classifier loss: 0.019689; batch adversarial loss: 0.405751\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009765; batch adversarial loss: 0.405809\n",
      "epoch 185; iter: 0; batch classifier loss: 0.024446; batch adversarial loss: 0.426143\n",
      "epoch 186; iter: 0; batch classifier loss: 0.022395; batch adversarial loss: 0.462956\n",
      "epoch 187; iter: 0; batch classifier loss: 0.013508; batch adversarial loss: 0.328070\n",
      "epoch 188; iter: 0; batch classifier loss: 0.054668; batch adversarial loss: 0.525736\n",
      "epoch 189; iter: 0; batch classifier loss: 0.060881; batch adversarial loss: 0.378545\n",
      "epoch 190; iter: 0; batch classifier loss: 0.020676; batch adversarial loss: 0.369079\n",
      "epoch 191; iter: 0; batch classifier loss: 0.019238; batch adversarial loss: 0.454872\n",
      "epoch 192; iter: 0; batch classifier loss: 0.002474; batch adversarial loss: 0.540087\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012615; batch adversarial loss: 0.437057\n",
      "epoch 194; iter: 0; batch classifier loss: 0.022647; batch adversarial loss: 0.367322\n",
      "epoch 195; iter: 0; batch classifier loss: 0.014201; batch adversarial loss: 0.471078\n",
      "epoch 196; iter: 0; batch classifier loss: 0.017740; batch adversarial loss: 0.487950\n",
      "epoch 197; iter: 0; batch classifier loss: 0.024127; batch adversarial loss: 0.390895\n",
      "epoch 198; iter: 0; batch classifier loss: 0.019540; batch adversarial loss: 0.445138\n",
      "epoch 199; iter: 0; batch classifier loss: 0.010469; batch adversarial loss: 0.456064\n",
      "epoch 0; iter: 0; batch classifier loss: 0.728305; batch adversarial loss: 0.644223\n",
      "epoch 1; iter: 0; batch classifier loss: 0.476860; batch adversarial loss: 0.668785\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384955; batch adversarial loss: 0.624591\n",
      "epoch 3; iter: 0; batch classifier loss: 0.421527; batch adversarial loss: 0.608066\n",
      "epoch 4; iter: 0; batch classifier loss: 0.355715; batch adversarial loss: 0.588125\n",
      "epoch 5; iter: 0; batch classifier loss: 0.294269; batch adversarial loss: 0.519576\n",
      "epoch 6; iter: 0; batch classifier loss: 0.280220; batch adversarial loss: 0.538988\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307582; batch adversarial loss: 0.538581\n",
      "epoch 8; iter: 0; batch classifier loss: 0.232982; batch adversarial loss: 0.493396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326248; batch adversarial loss: 0.462250\n",
      "epoch 10; iter: 0; batch classifier loss: 0.264620; batch adversarial loss: 0.502186\n",
      "epoch 11; iter: 0; batch classifier loss: 0.215402; batch adversarial loss: 0.427197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.197457; batch adversarial loss: 0.543157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242284; batch adversarial loss: 0.470659\n",
      "epoch 14; iter: 0; batch classifier loss: 0.159096; batch adversarial loss: 0.480046\n",
      "epoch 15; iter: 0; batch classifier loss: 0.145058; batch adversarial loss: 0.508804\n",
      "epoch 16; iter: 0; batch classifier loss: 0.224812; batch adversarial loss: 0.488146\n",
      "epoch 17; iter: 0; batch classifier loss: 0.169272; batch adversarial loss: 0.550311\n",
      "epoch 18; iter: 0; batch classifier loss: 0.212948; batch adversarial loss: 0.406687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.230778; batch adversarial loss: 0.473808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.217559; batch adversarial loss: 0.520276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.136450; batch adversarial loss: 0.490252\n",
      "epoch 22; iter: 0; batch classifier loss: 0.167314; batch adversarial loss: 0.485749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.167489; batch adversarial loss: 0.477664\n",
      "epoch 24; iter: 0; batch classifier loss: 0.167482; batch adversarial loss: 0.492768\n",
      "epoch 25; iter: 0; batch classifier loss: 0.118363; batch adversarial loss: 0.475578\n",
      "epoch 26; iter: 0; batch classifier loss: 0.146879; batch adversarial loss: 0.446241\n",
      "epoch 27; iter: 0; batch classifier loss: 0.147748; batch adversarial loss: 0.451436\n",
      "epoch 28; iter: 0; batch classifier loss: 0.175589; batch adversarial loss: 0.422907\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235404; batch adversarial loss: 0.513364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 0; batch classifier loss: 0.150623; batch adversarial loss: 0.468003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.176586; batch adversarial loss: 0.549308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.145343; batch adversarial loss: 0.411808\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264790; batch adversarial loss: 0.483940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.228942; batch adversarial loss: 0.439520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.186718; batch adversarial loss: 0.451722\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277754; batch adversarial loss: 0.521578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.318466; batch adversarial loss: 0.434997\n",
      "epoch 38; iter: 0; batch classifier loss: 0.107706; batch adversarial loss: 0.468102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.109706; batch adversarial loss: 0.469761\n",
      "epoch 40; iter: 0; batch classifier loss: 0.091348; batch adversarial loss: 0.390581\n",
      "epoch 41; iter: 0; batch classifier loss: 0.044027; batch adversarial loss: 0.453552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.073097; batch adversarial loss: 0.435466\n",
      "epoch 43; iter: 0; batch classifier loss: 0.071095; batch adversarial loss: 0.399743\n",
      "epoch 44; iter: 0; batch classifier loss: 0.073384; batch adversarial loss: 0.365412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.101746; batch adversarial loss: 0.448484\n",
      "epoch 46; iter: 0; batch classifier loss: 0.084351; batch adversarial loss: 0.441766\n",
      "epoch 47; iter: 0; batch classifier loss: 0.091256; batch adversarial loss: 0.534255\n",
      "epoch 48; iter: 0; batch classifier loss: 0.065617; batch adversarial loss: 0.374956\n",
      "epoch 49; iter: 0; batch classifier loss: 0.098881; batch adversarial loss: 0.427240\n",
      "epoch 50; iter: 0; batch classifier loss: 0.075048; batch adversarial loss: 0.408747\n",
      "epoch 51; iter: 0; batch classifier loss: 0.059189; batch adversarial loss: 0.412743\n",
      "epoch 52; iter: 0; batch classifier loss: 0.060592; batch adversarial loss: 0.501871\n",
      "epoch 53; iter: 0; batch classifier loss: 0.123436; batch adversarial loss: 0.526628\n",
      "epoch 54; iter: 0; batch classifier loss: 0.090827; batch adversarial loss: 0.486082\n",
      "epoch 55; iter: 0; batch classifier loss: 0.062157; batch adversarial loss: 0.388477\n",
      "epoch 56; iter: 0; batch classifier loss: 0.122279; batch adversarial loss: 0.455752\n",
      "epoch 57; iter: 0; batch classifier loss: 0.051546; batch adversarial loss: 0.524706\n",
      "epoch 58; iter: 0; batch classifier loss: 0.045626; batch adversarial loss: 0.485631\n",
      "epoch 59; iter: 0; batch classifier loss: 0.095222; batch adversarial loss: 0.410622\n",
      "epoch 60; iter: 0; batch classifier loss: 0.098271; batch adversarial loss: 0.408581\n",
      "epoch 61; iter: 0; batch classifier loss: 0.063843; batch adversarial loss: 0.429102\n",
      "epoch 62; iter: 0; batch classifier loss: 0.066612; batch adversarial loss: 0.454724\n",
      "epoch 63; iter: 0; batch classifier loss: 0.118616; batch adversarial loss: 0.440244\n",
      "epoch 64; iter: 0; batch classifier loss: 0.040078; batch adversarial loss: 0.490400\n",
      "epoch 65; iter: 0; batch classifier loss: 0.109018; batch adversarial loss: 0.431556\n",
      "epoch 66; iter: 0; batch classifier loss: 0.074504; batch adversarial loss: 0.434882\n",
      "epoch 67; iter: 0; batch classifier loss: 0.062386; batch adversarial loss: 0.414883\n",
      "epoch 68; iter: 0; batch classifier loss: 0.069483; batch adversarial loss: 0.423975\n",
      "epoch 69; iter: 0; batch classifier loss: 0.063800; batch adversarial loss: 0.372696\n",
      "epoch 70; iter: 0; batch classifier loss: 0.065858; batch adversarial loss: 0.453540\n",
      "epoch 71; iter: 0; batch classifier loss: 0.055022; batch adversarial loss: 0.477885\n",
      "epoch 72; iter: 0; batch classifier loss: 0.054912; batch adversarial loss: 0.574089\n",
      "epoch 73; iter: 0; batch classifier loss: 0.042349; batch adversarial loss: 0.376090\n",
      "epoch 74; iter: 0; batch classifier loss: 0.087460; batch adversarial loss: 0.524305\n",
      "epoch 75; iter: 0; batch classifier loss: 0.063294; batch adversarial loss: 0.463408\n",
      "epoch 76; iter: 0; batch classifier loss: 0.081058; batch adversarial loss: 0.525017\n",
      "epoch 77; iter: 0; batch classifier loss: 0.051239; batch adversarial loss: 0.461073\n",
      "epoch 78; iter: 0; batch classifier loss: 0.031196; batch adversarial loss: 0.435686\n",
      "epoch 79; iter: 0; batch classifier loss: 0.080228; batch adversarial loss: 0.526547\n",
      "epoch 80; iter: 0; batch classifier loss: 0.063141; batch adversarial loss: 0.572326\n",
      "epoch 81; iter: 0; batch classifier loss: 0.057651; batch adversarial loss: 0.454159\n",
      "epoch 82; iter: 0; batch classifier loss: 0.062915; batch adversarial loss: 0.480187\n",
      "epoch 83; iter: 0; batch classifier loss: 0.041067; batch adversarial loss: 0.469974\n",
      "epoch 84; iter: 0; batch classifier loss: 0.049568; batch adversarial loss: 0.457377\n",
      "epoch 85; iter: 0; batch classifier loss: 0.075084; batch adversarial loss: 0.386633\n",
      "epoch 86; iter: 0; batch classifier loss: 0.031746; batch adversarial loss: 0.448653\n",
      "epoch 87; iter: 0; batch classifier loss: 0.059331; batch adversarial loss: 0.469723\n",
      "epoch 88; iter: 0; batch classifier loss: 0.064315; batch adversarial loss: 0.490824\n",
      "epoch 89; iter: 0; batch classifier loss: 0.058651; batch adversarial loss: 0.471865\n",
      "epoch 90; iter: 0; batch classifier loss: 0.106759; batch adversarial loss: 0.432250\n",
      "epoch 91; iter: 0; batch classifier loss: 0.071349; batch adversarial loss: 0.422602\n",
      "epoch 92; iter: 0; batch classifier loss: 0.030607; batch adversarial loss: 0.393084\n",
      "epoch 93; iter: 0; batch classifier loss: 0.060769; batch adversarial loss: 0.411479\n",
      "epoch 94; iter: 0; batch classifier loss: 0.042839; batch adversarial loss: 0.500073\n",
      "epoch 95; iter: 0; batch classifier loss: 0.078778; batch adversarial loss: 0.461869\n",
      "epoch 96; iter: 0; batch classifier loss: 0.064331; batch adversarial loss: 0.457864\n",
      "epoch 97; iter: 0; batch classifier loss: 0.059221; batch adversarial loss: 0.500504\n",
      "epoch 98; iter: 0; batch classifier loss: 0.090938; batch adversarial loss: 0.421614\n",
      "epoch 99; iter: 0; batch classifier loss: 0.020453; batch adversarial loss: 0.404292\n",
      "epoch 100; iter: 0; batch classifier loss: 0.072199; batch adversarial loss: 0.484474\n",
      "epoch 101; iter: 0; batch classifier loss: 0.085303; batch adversarial loss: 0.483249\n",
      "epoch 102; iter: 0; batch classifier loss: 0.036146; batch adversarial loss: 0.487618\n",
      "epoch 103; iter: 0; batch classifier loss: 0.057434; batch adversarial loss: 0.395496\n",
      "epoch 104; iter: 0; batch classifier loss: 0.051054; batch adversarial loss: 0.509973\n",
      "epoch 105; iter: 0; batch classifier loss: 0.032761; batch adversarial loss: 0.400138\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040137; batch adversarial loss: 0.516340\n",
      "epoch 107; iter: 0; batch classifier loss: 0.064000; batch adversarial loss: 0.397384\n",
      "epoch 108; iter: 0; batch classifier loss: 0.075865; batch adversarial loss: 0.437443\n",
      "epoch 109; iter: 0; batch classifier loss: 0.045691; batch adversarial loss: 0.509577\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050374; batch adversarial loss: 0.407290\n",
      "epoch 111; iter: 0; batch classifier loss: 0.054820; batch adversarial loss: 0.466647\n",
      "epoch 112; iter: 0; batch classifier loss: 0.031775; batch adversarial loss: 0.371910\n",
      "epoch 113; iter: 0; batch classifier loss: 0.059263; batch adversarial loss: 0.499255\n",
      "epoch 114; iter: 0; batch classifier loss: 0.026675; batch adversarial loss: 0.450632\n",
      "epoch 115; iter: 0; batch classifier loss: 0.037023; batch adversarial loss: 0.430880\n",
      "epoch 116; iter: 0; batch classifier loss: 0.052392; batch adversarial loss: 0.371233\n",
      "epoch 117; iter: 0; batch classifier loss: 0.080224; batch adversarial loss: 0.448711\n",
      "epoch 118; iter: 0; batch classifier loss: 0.021637; batch adversarial loss: 0.504130\n",
      "epoch 119; iter: 0; batch classifier loss: 0.041204; batch adversarial loss: 0.468446\n",
      "epoch 120; iter: 0; batch classifier loss: 0.030074; batch adversarial loss: 0.455325\n",
      "epoch 121; iter: 0; batch classifier loss: 0.018301; batch adversarial loss: 0.529531\n",
      "epoch 122; iter: 0; batch classifier loss: 0.047493; batch adversarial loss: 0.508816\n",
      "epoch 123; iter: 0; batch classifier loss: 0.016302; batch adversarial loss: 0.398902\n",
      "epoch 124; iter: 0; batch classifier loss: 0.026349; batch adversarial loss: 0.397375\n",
      "epoch 125; iter: 0; batch classifier loss: 0.026845; batch adversarial loss: 0.537773\n",
      "epoch 126; iter: 0; batch classifier loss: 0.044943; batch adversarial loss: 0.499692\n",
      "epoch 127; iter: 0; batch classifier loss: 0.036597; batch adversarial loss: 0.499797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 128; iter: 0; batch classifier loss: 0.034379; batch adversarial loss: 0.397366\n",
      "epoch 129; iter: 0; batch classifier loss: 0.033023; batch adversarial loss: 0.466555\n",
      "epoch 130; iter: 0; batch classifier loss: 0.035914; batch adversarial loss: 0.442392\n",
      "epoch 131; iter: 0; batch classifier loss: 0.019620; batch adversarial loss: 0.485200\n",
      "epoch 132; iter: 0; batch classifier loss: 0.021923; batch adversarial loss: 0.442479\n",
      "epoch 133; iter: 0; batch classifier loss: 0.022234; batch adversarial loss: 0.423163\n",
      "epoch 134; iter: 0; batch classifier loss: 0.017777; batch adversarial loss: 0.496111\n",
      "epoch 135; iter: 0; batch classifier loss: 0.030509; batch adversarial loss: 0.443635\n",
      "epoch 136; iter: 0; batch classifier loss: 0.072006; batch adversarial loss: 0.602200\n",
      "epoch 137; iter: 0; batch classifier loss: 0.066753; batch adversarial loss: 0.376494\n",
      "epoch 138; iter: 0; batch classifier loss: 0.013763; batch adversarial loss: 0.586696\n",
      "epoch 139; iter: 0; batch classifier loss: 0.032637; batch adversarial loss: 0.341504\n",
      "epoch 140; iter: 0; batch classifier loss: 0.050154; batch adversarial loss: 0.418410\n",
      "epoch 141; iter: 0; batch classifier loss: 0.031970; batch adversarial loss: 0.511767\n",
      "epoch 142; iter: 0; batch classifier loss: 0.042938; batch adversarial loss: 0.486120\n",
      "epoch 143; iter: 0; batch classifier loss: 0.035470; batch adversarial loss: 0.367653\n",
      "epoch 144; iter: 0; batch classifier loss: 0.019156; batch adversarial loss: 0.469178\n",
      "epoch 145; iter: 0; batch classifier loss: 0.022941; batch adversarial loss: 0.534638\n",
      "epoch 146; iter: 0; batch classifier loss: 0.016557; batch adversarial loss: 0.432750\n",
      "epoch 147; iter: 0; batch classifier loss: 0.029888; batch adversarial loss: 0.374697\n",
      "epoch 148; iter: 0; batch classifier loss: 0.024324; batch adversarial loss: 0.470072\n",
      "epoch 149; iter: 0; batch classifier loss: 0.068952; batch adversarial loss: 0.445785\n",
      "epoch 150; iter: 0; batch classifier loss: 0.025295; batch adversarial loss: 0.377894\n",
      "epoch 151; iter: 0; batch classifier loss: 0.029169; batch adversarial loss: 0.454825\n",
      "epoch 152; iter: 0; batch classifier loss: 0.027776; batch adversarial loss: 0.446366\n",
      "epoch 153; iter: 0; batch classifier loss: 0.015515; batch adversarial loss: 0.496500\n",
      "epoch 154; iter: 0; batch classifier loss: 0.043179; batch adversarial loss: 0.401363\n",
      "epoch 155; iter: 0; batch classifier loss: 0.025242; batch adversarial loss: 0.452602\n",
      "epoch 156; iter: 0; batch classifier loss: 0.029311; batch adversarial loss: 0.424094\n",
      "epoch 157; iter: 0; batch classifier loss: 0.028506; batch adversarial loss: 0.436363\n",
      "epoch 158; iter: 0; batch classifier loss: 0.010462; batch adversarial loss: 0.460546\n",
      "epoch 159; iter: 0; batch classifier loss: 0.025117; batch adversarial loss: 0.426946\n",
      "epoch 160; iter: 0; batch classifier loss: 0.024443; batch adversarial loss: 0.412992\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027343; batch adversarial loss: 0.393593\n",
      "epoch 162; iter: 0; batch classifier loss: 0.025161; batch adversarial loss: 0.483101\n",
      "epoch 163; iter: 0; batch classifier loss: 0.019174; batch adversarial loss: 0.484907\n",
      "epoch 164; iter: 0; batch classifier loss: 0.024499; batch adversarial loss: 0.379000\n",
      "epoch 165; iter: 0; batch classifier loss: 0.021158; batch adversarial loss: 0.482115\n",
      "epoch 166; iter: 0; batch classifier loss: 0.045094; batch adversarial loss: 0.441744\n",
      "epoch 167; iter: 0; batch classifier loss: 0.011620; batch adversarial loss: 0.467527\n",
      "epoch 168; iter: 0; batch classifier loss: 0.032532; batch adversarial loss: 0.476762\n",
      "epoch 169; iter: 0; batch classifier loss: 0.043981; batch adversarial loss: 0.325948\n",
      "epoch 170; iter: 0; batch classifier loss: 0.066281; batch adversarial loss: 0.445338\n",
      "epoch 171; iter: 0; batch classifier loss: 0.025833; batch adversarial loss: 0.436862\n",
      "epoch 172; iter: 0; batch classifier loss: 0.015992; batch adversarial loss: 0.436545\n",
      "epoch 173; iter: 0; batch classifier loss: 0.048028; batch adversarial loss: 0.451446\n",
      "epoch 174; iter: 0; batch classifier loss: 0.036559; batch adversarial loss: 0.420529\n",
      "epoch 175; iter: 0; batch classifier loss: 0.044101; batch adversarial loss: 0.388368\n",
      "epoch 176; iter: 0; batch classifier loss: 0.016129; batch adversarial loss: 0.430949\n",
      "epoch 177; iter: 0; batch classifier loss: 0.006771; batch adversarial loss: 0.493191\n",
      "epoch 178; iter: 0; batch classifier loss: 0.039684; batch adversarial loss: 0.454982\n",
      "epoch 179; iter: 0; batch classifier loss: 0.059434; batch adversarial loss: 0.453941\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006296; batch adversarial loss: 0.463506\n",
      "epoch 181; iter: 0; batch classifier loss: 0.017573; batch adversarial loss: 0.433999\n",
      "epoch 182; iter: 0; batch classifier loss: 0.017867; batch adversarial loss: 0.388303\n",
      "epoch 183; iter: 0; batch classifier loss: 0.030085; batch adversarial loss: 0.556097\n",
      "epoch 184; iter: 0; batch classifier loss: 0.006519; batch adversarial loss: 0.572005\n",
      "epoch 185; iter: 0; batch classifier loss: 0.022336; batch adversarial loss: 0.448473\n",
      "epoch 186; iter: 0; batch classifier loss: 0.014784; batch adversarial loss: 0.411856\n",
      "epoch 187; iter: 0; batch classifier loss: 0.026887; batch adversarial loss: 0.483246\n",
      "epoch 188; iter: 0; batch classifier loss: 0.018789; batch adversarial loss: 0.465864\n",
      "epoch 189; iter: 0; batch classifier loss: 0.026065; batch adversarial loss: 0.468005\n",
      "epoch 190; iter: 0; batch classifier loss: 0.018424; batch adversarial loss: 0.558475\n",
      "epoch 191; iter: 0; batch classifier loss: 0.025874; batch adversarial loss: 0.436657\n",
      "epoch 192; iter: 0; batch classifier loss: 0.050579; batch adversarial loss: 0.351101\n",
      "epoch 193; iter: 0; batch classifier loss: 0.010364; batch adversarial loss: 0.555067\n",
      "epoch 194; iter: 0; batch classifier loss: 0.011623; batch adversarial loss: 0.514943\n",
      "epoch 195; iter: 0; batch classifier loss: 0.013574; batch adversarial loss: 0.410789\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011980; batch adversarial loss: 0.427003\n",
      "epoch 197; iter: 0; batch classifier loss: 0.021765; batch adversarial loss: 0.468974\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037492; batch adversarial loss: 0.375397\n",
      "epoch 199; iter: 0; batch classifier loss: 0.009645; batch adversarial loss: 0.398916\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715288; batch adversarial loss: 0.646947\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528493; batch adversarial loss: 0.625085\n",
      "epoch 2; iter: 0; batch classifier loss: 0.390393; batch adversarial loss: 0.614586\n",
      "epoch 3; iter: 0; batch classifier loss: 0.474281; batch adversarial loss: 0.599122\n",
      "epoch 4; iter: 0; batch classifier loss: 0.455533; batch adversarial loss: 0.605857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.468800; batch adversarial loss: 0.546651\n",
      "epoch 6; iter: 0; batch classifier loss: 0.424383; batch adversarial loss: 0.552395\n",
      "epoch 7; iter: 0; batch classifier loss: 0.457023; batch adversarial loss: 0.512979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340188; batch adversarial loss: 0.544186\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346450; batch adversarial loss: 0.615540\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470479; batch adversarial loss: 0.531578\n",
      "epoch 11; iter: 0; batch classifier loss: 0.336388; batch adversarial loss: 0.556973\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344106; batch adversarial loss: 0.500490\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284068; batch adversarial loss: 0.484732\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309830; batch adversarial loss: 0.487246\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270066; batch adversarial loss: 0.474285\n",
      "epoch 16; iter: 0; batch classifier loss: 0.285699; batch adversarial loss: 0.463381\n",
      "epoch 17; iter: 0; batch classifier loss: 0.219485; batch adversarial loss: 0.537035\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241630; batch adversarial loss: 0.483391\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279290; batch adversarial loss: 0.452115\n",
      "epoch 20; iter: 0; batch classifier loss: 0.224000; batch adversarial loss: 0.494967\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217822; batch adversarial loss: 0.426464\n",
      "epoch 22; iter: 0; batch classifier loss: 0.226722; batch adversarial loss: 0.487656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.214876; batch adversarial loss: 0.487278\n",
      "epoch 24; iter: 0; batch classifier loss: 0.285351; batch adversarial loss: 0.474239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.178382; batch adversarial loss: 0.447170\n",
      "epoch 26; iter: 0; batch classifier loss: 0.229176; batch adversarial loss: 0.423389\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188553; batch adversarial loss: 0.463771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.206938; batch adversarial loss: 0.471114\n",
      "epoch 29; iter: 0; batch classifier loss: 0.199462; batch adversarial loss: 0.411260\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195174; batch adversarial loss: 0.394592\n",
      "epoch 31; iter: 0; batch classifier loss: 0.169017; batch adversarial loss: 0.546335\n",
      "epoch 32; iter: 0; batch classifier loss: 0.176060; batch adversarial loss: 0.568646\n",
      "epoch 33; iter: 0; batch classifier loss: 0.183495; batch adversarial loss: 0.510789\n",
      "epoch 34; iter: 0; batch classifier loss: 0.212455; batch adversarial loss: 0.426336\n",
      "epoch 35; iter: 0; batch classifier loss: 0.215849; batch adversarial loss: 0.414891\n",
      "epoch 36; iter: 0; batch classifier loss: 0.182639; batch adversarial loss: 0.460505\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226859; batch adversarial loss: 0.508614\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269080; batch adversarial loss: 0.399843\n",
      "epoch 39; iter: 0; batch classifier loss: 0.213816; batch adversarial loss: 0.378659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.233906; batch adversarial loss: 0.473796\n",
      "epoch 41; iter: 0; batch classifier loss: 0.224775; batch adversarial loss: 0.453897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.179097; batch adversarial loss: 0.435963\n",
      "epoch 43; iter: 0; batch classifier loss: 0.159820; batch adversarial loss: 0.519120\n",
      "epoch 44; iter: 0; batch classifier loss: 0.190562; batch adversarial loss: 0.421536\n",
      "epoch 45; iter: 0; batch classifier loss: 0.140540; batch adversarial loss: 0.544517\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245285; batch adversarial loss: 0.420958\n",
      "epoch 47; iter: 0; batch classifier loss: 0.161657; batch adversarial loss: 0.475349\n",
      "epoch 48; iter: 0; batch classifier loss: 0.170981; batch adversarial loss: 0.411012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.167403; batch adversarial loss: 0.459276\n",
      "epoch 50; iter: 0; batch classifier loss: 0.154663; batch adversarial loss: 0.504123\n",
      "epoch 51; iter: 0; batch classifier loss: 0.149359; batch adversarial loss: 0.508938\n",
      "epoch 52; iter: 0; batch classifier loss: 0.167137; batch adversarial loss: 0.435442\n",
      "epoch 53; iter: 0; batch classifier loss: 0.207918; batch adversarial loss: 0.419944\n",
      "epoch 54; iter: 0; batch classifier loss: 0.222165; batch adversarial loss: 0.364852\n",
      "epoch 55; iter: 0; batch classifier loss: 0.123108; batch adversarial loss: 0.481768\n",
      "epoch 56; iter: 0; batch classifier loss: 0.131737; batch adversarial loss: 0.495888\n",
      "epoch 57; iter: 0; batch classifier loss: 0.124270; batch adversarial loss: 0.506208\n",
      "epoch 58; iter: 0; batch classifier loss: 0.170434; batch adversarial loss: 0.386101\n",
      "epoch 59; iter: 0; batch classifier loss: 0.172164; batch adversarial loss: 0.497460\n",
      "epoch 60; iter: 0; batch classifier loss: 0.164696; batch adversarial loss: 0.558031\n",
      "epoch 61; iter: 0; batch classifier loss: 0.128687; batch adversarial loss: 0.459951\n",
      "epoch 62; iter: 0; batch classifier loss: 0.155100; batch adversarial loss: 0.520082\n",
      "epoch 63; iter: 0; batch classifier loss: 0.138406; batch adversarial loss: 0.447066\n",
      "epoch 64; iter: 0; batch classifier loss: 0.107332; batch adversarial loss: 0.505494\n",
      "epoch 65; iter: 0; batch classifier loss: 0.130349; batch adversarial loss: 0.494463\n",
      "epoch 66; iter: 0; batch classifier loss: 0.109779; batch adversarial loss: 0.400198\n",
      "epoch 67; iter: 0; batch classifier loss: 0.094305; batch adversarial loss: 0.606110\n",
      "epoch 68; iter: 0; batch classifier loss: 0.168160; batch adversarial loss: 0.445728\n",
      "epoch 69; iter: 0; batch classifier loss: 0.126231; batch adversarial loss: 0.445625\n",
      "epoch 70; iter: 0; batch classifier loss: 0.113375; batch adversarial loss: 0.433582\n",
      "epoch 71; iter: 0; batch classifier loss: 0.095128; batch adversarial loss: 0.435427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.102196; batch adversarial loss: 0.473321\n",
      "epoch 73; iter: 0; batch classifier loss: 0.125260; batch adversarial loss: 0.392947\n",
      "epoch 74; iter: 0; batch classifier loss: 0.089197; batch adversarial loss: 0.474243\n",
      "epoch 75; iter: 0; batch classifier loss: 0.130923; batch adversarial loss: 0.422368\n",
      "epoch 76; iter: 0; batch classifier loss: 0.121377; batch adversarial loss: 0.432800\n",
      "epoch 77; iter: 0; batch classifier loss: 0.083875; batch adversarial loss: 0.516261\n",
      "epoch 78; iter: 0; batch classifier loss: 0.108908; batch adversarial loss: 0.446462\n",
      "epoch 79; iter: 0; batch classifier loss: 0.127913; batch adversarial loss: 0.385750\n",
      "epoch 80; iter: 0; batch classifier loss: 0.096921; batch adversarial loss: 0.491887\n",
      "epoch 81; iter: 0; batch classifier loss: 0.078622; batch adversarial loss: 0.414373\n",
      "epoch 82; iter: 0; batch classifier loss: 0.071382; batch adversarial loss: 0.463087\n",
      "epoch 83; iter: 0; batch classifier loss: 0.070120; batch adversarial loss: 0.546156\n",
      "epoch 84; iter: 0; batch classifier loss: 0.064632; batch adversarial loss: 0.493903\n",
      "epoch 85; iter: 0; batch classifier loss: 0.071238; batch adversarial loss: 0.560083\n",
      "epoch 86; iter: 0; batch classifier loss: 0.092095; batch adversarial loss: 0.475437\n",
      "epoch 87; iter: 0; batch classifier loss: 0.047846; batch adversarial loss: 0.497251\n",
      "epoch 88; iter: 0; batch classifier loss: 0.069894; batch adversarial loss: 0.435463\n",
      "epoch 89; iter: 0; batch classifier loss: 0.076562; batch adversarial loss: 0.443936\n",
      "epoch 90; iter: 0; batch classifier loss: 0.082605; batch adversarial loss: 0.367044\n",
      "epoch 91; iter: 0; batch classifier loss: 0.056445; batch adversarial loss: 0.444058\n",
      "epoch 92; iter: 0; batch classifier loss: 0.060326; batch adversarial loss: 0.467716\n",
      "epoch 93; iter: 0; batch classifier loss: 0.072786; batch adversarial loss: 0.379199\n",
      "epoch 94; iter: 0; batch classifier loss: 0.075333; batch adversarial loss: 0.457016\n",
      "epoch 95; iter: 0; batch classifier loss: 0.042460; batch adversarial loss: 0.446534\n",
      "epoch 96; iter: 0; batch classifier loss: 0.029576; batch adversarial loss: 0.468407\n",
      "epoch 97; iter: 0; batch classifier loss: 0.118662; batch adversarial loss: 0.469336\n",
      "epoch 98; iter: 0; batch classifier loss: 0.022216; batch adversarial loss: 0.403122\n",
      "epoch 99; iter: 0; batch classifier loss: 0.039178; batch adversarial loss: 0.397190\n",
      "epoch 100; iter: 0; batch classifier loss: 0.057153; batch adversarial loss: 0.426505\n",
      "epoch 101; iter: 0; batch classifier loss: 0.048851; batch adversarial loss: 0.431088\n",
      "epoch 102; iter: 0; batch classifier loss: 0.026594; batch adversarial loss: 0.398661\n",
      "epoch 103; iter: 0; batch classifier loss: 0.058427; batch adversarial loss: 0.497692\n",
      "epoch 104; iter: 0; batch classifier loss: 0.054784; batch adversarial loss: 0.439585\n",
      "epoch 105; iter: 0; batch classifier loss: 0.045081; batch adversarial loss: 0.344731\n",
      "epoch 106; iter: 0; batch classifier loss: 0.040246; batch adversarial loss: 0.447276\n",
      "epoch 107; iter: 0; batch classifier loss: 0.022314; batch adversarial loss: 0.368544\n",
      "epoch 108; iter: 0; batch classifier loss: 0.067543; batch adversarial loss: 0.507592\n",
      "epoch 109; iter: 0; batch classifier loss: 0.063554; batch adversarial loss: 0.489753\n",
      "epoch 110; iter: 0; batch classifier loss: 0.046488; batch adversarial loss: 0.377652\n",
      "epoch 111; iter: 0; batch classifier loss: 0.042201; batch adversarial loss: 0.393495\n",
      "epoch 112; iter: 0; batch classifier loss: 0.026418; batch adversarial loss: 0.455730\n",
      "epoch 113; iter: 0; batch classifier loss: 0.038591; batch adversarial loss: 0.418906\n",
      "epoch 114; iter: 0; batch classifier loss: 0.041404; batch adversarial loss: 0.480627\n",
      "epoch 115; iter: 0; batch classifier loss: 0.048459; batch adversarial loss: 0.484669\n",
      "epoch 116; iter: 0; batch classifier loss: 0.034486; batch adversarial loss: 0.379046\n",
      "epoch 117; iter: 0; batch classifier loss: 0.025181; batch adversarial loss: 0.418650\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037374; batch adversarial loss: 0.428997\n",
      "epoch 119; iter: 0; batch classifier loss: 0.026838; batch adversarial loss: 0.411715\n",
      "epoch 120; iter: 0; batch classifier loss: 0.034094; batch adversarial loss: 0.479494\n",
      "epoch 121; iter: 0; batch classifier loss: 0.053115; batch adversarial loss: 0.424895\n",
      "epoch 122; iter: 0; batch classifier loss: 0.009484; batch adversarial loss: 0.429792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 123; iter: 0; batch classifier loss: 0.020560; batch adversarial loss: 0.503937\n",
      "epoch 124; iter: 0; batch classifier loss: 0.041318; batch adversarial loss: 0.458578\n",
      "epoch 125; iter: 0; batch classifier loss: 0.027994; batch adversarial loss: 0.465437\n",
      "epoch 126; iter: 0; batch classifier loss: 0.021484; batch adversarial loss: 0.532361\n",
      "epoch 127; iter: 0; batch classifier loss: 0.034035; batch adversarial loss: 0.423721\n",
      "epoch 128; iter: 0; batch classifier loss: 0.015583; batch adversarial loss: 0.438318\n",
      "epoch 129; iter: 0; batch classifier loss: 0.014658; batch adversarial loss: 0.390117\n",
      "epoch 130; iter: 0; batch classifier loss: 0.017742; batch adversarial loss: 0.479958\n",
      "epoch 131; iter: 0; batch classifier loss: 0.041367; batch adversarial loss: 0.462855\n",
      "epoch 132; iter: 0; batch classifier loss: 0.039012; batch adversarial loss: 0.393185\n",
      "epoch 133; iter: 0; batch classifier loss: 0.021425; batch adversarial loss: 0.393377\n",
      "epoch 134; iter: 0; batch classifier loss: 0.037721; batch adversarial loss: 0.491993\n",
      "epoch 135; iter: 0; batch classifier loss: 0.040732; batch adversarial loss: 0.376962\n",
      "epoch 136; iter: 0; batch classifier loss: 0.027095; batch adversarial loss: 0.448407\n",
      "epoch 137; iter: 0; batch classifier loss: 0.020605; batch adversarial loss: 0.463230\n",
      "epoch 138; iter: 0; batch classifier loss: 0.040459; batch adversarial loss: 0.340318\n",
      "epoch 139; iter: 0; batch classifier loss: 0.034222; batch adversarial loss: 0.491770\n",
      "epoch 140; iter: 0; batch classifier loss: 0.018096; batch adversarial loss: 0.542430\n",
      "epoch 141; iter: 0; batch classifier loss: 0.017157; batch adversarial loss: 0.522472\n",
      "epoch 142; iter: 0; batch classifier loss: 0.035251; batch adversarial loss: 0.391288\n",
      "epoch 143; iter: 0; batch classifier loss: 0.020647; batch adversarial loss: 0.461409\n",
      "epoch 144; iter: 0; batch classifier loss: 0.040229; batch adversarial loss: 0.363858\n",
      "epoch 145; iter: 0; batch classifier loss: 0.062804; batch adversarial loss: 0.449280\n",
      "epoch 146; iter: 0; batch classifier loss: 0.008702; batch adversarial loss: 0.373810\n",
      "epoch 147; iter: 0; batch classifier loss: 0.052973; batch adversarial loss: 0.358417\n",
      "epoch 148; iter: 0; batch classifier loss: 0.017793; batch adversarial loss: 0.603876\n",
      "epoch 149; iter: 0; batch classifier loss: 0.034850; batch adversarial loss: 0.421762\n",
      "epoch 150; iter: 0; batch classifier loss: 0.016591; batch adversarial loss: 0.448556\n",
      "epoch 151; iter: 0; batch classifier loss: 0.048923; batch adversarial loss: 0.473618\n",
      "epoch 152; iter: 0; batch classifier loss: 0.013293; batch adversarial loss: 0.433262\n",
      "epoch 153; iter: 0; batch classifier loss: 0.019084; batch adversarial loss: 0.440489\n",
      "epoch 154; iter: 0; batch classifier loss: 0.014180; batch adversarial loss: 0.452075\n",
      "epoch 155; iter: 0; batch classifier loss: 0.023870; batch adversarial loss: 0.405151\n",
      "epoch 156; iter: 0; batch classifier loss: 0.014970; batch adversarial loss: 0.503637\n",
      "epoch 157; iter: 0; batch classifier loss: 0.032781; batch adversarial loss: 0.482650\n",
      "epoch 158; iter: 0; batch classifier loss: 0.008848; batch adversarial loss: 0.497653\n",
      "epoch 159; iter: 0; batch classifier loss: 0.011544; batch adversarial loss: 0.562729\n",
      "epoch 160; iter: 0; batch classifier loss: 0.030285; batch adversarial loss: 0.444447\n",
      "epoch 161; iter: 0; batch classifier loss: 0.027804; batch adversarial loss: 0.454221\n",
      "epoch 162; iter: 0; batch classifier loss: 0.009411; batch adversarial loss: 0.438807\n",
      "epoch 163; iter: 0; batch classifier loss: 0.007459; batch adversarial loss: 0.395861\n",
      "epoch 164; iter: 0; batch classifier loss: 0.009948; batch adversarial loss: 0.478805\n",
      "epoch 165; iter: 0; batch classifier loss: 0.024180; batch adversarial loss: 0.479321\n",
      "epoch 166; iter: 0; batch classifier loss: 0.028685; batch adversarial loss: 0.374719\n",
      "epoch 167; iter: 0; batch classifier loss: 0.032133; batch adversarial loss: 0.532127\n",
      "epoch 168; iter: 0; batch classifier loss: 0.015098; batch adversarial loss: 0.478664\n",
      "epoch 169; iter: 0; batch classifier loss: 0.016426; batch adversarial loss: 0.418624\n",
      "epoch 170; iter: 0; batch classifier loss: 0.020797; batch adversarial loss: 0.448527\n",
      "epoch 171; iter: 0; batch classifier loss: 0.016852; batch adversarial loss: 0.406480\n",
      "epoch 172; iter: 0; batch classifier loss: 0.021103; batch adversarial loss: 0.406311\n",
      "epoch 173; iter: 0; batch classifier loss: 0.006333; batch adversarial loss: 0.468731\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003211; batch adversarial loss: 0.485238\n",
      "epoch 175; iter: 0; batch classifier loss: 0.012381; batch adversarial loss: 0.438805\n",
      "epoch 176; iter: 0; batch classifier loss: 0.027807; batch adversarial loss: 0.572647\n",
      "epoch 177; iter: 0; batch classifier loss: 0.019117; batch adversarial loss: 0.523036\n",
      "epoch 178; iter: 0; batch classifier loss: 0.029672; batch adversarial loss: 0.455016\n",
      "epoch 179; iter: 0; batch classifier loss: 0.011913; batch adversarial loss: 0.535689\n",
      "epoch 180; iter: 0; batch classifier loss: 0.006422; batch adversarial loss: 0.542317\n",
      "epoch 181; iter: 0; batch classifier loss: 0.001812; batch adversarial loss: 0.532486\n",
      "epoch 182; iter: 0; batch classifier loss: 0.012461; batch adversarial loss: 0.422392\n",
      "epoch 183; iter: 0; batch classifier loss: 0.008268; batch adversarial loss: 0.434017\n",
      "epoch 184; iter: 0; batch classifier loss: 0.009966; batch adversarial loss: 0.401001\n",
      "epoch 185; iter: 0; batch classifier loss: 0.013989; batch adversarial loss: 0.473420\n",
      "epoch 186; iter: 0; batch classifier loss: 0.021100; batch adversarial loss: 0.557391\n",
      "epoch 187; iter: 0; batch classifier loss: 0.005823; batch adversarial loss: 0.406037\n",
      "epoch 188; iter: 0; batch classifier loss: 0.027469; batch adversarial loss: 0.406173\n",
      "epoch 189; iter: 0; batch classifier loss: 0.009542; batch adversarial loss: 0.443180\n",
      "epoch 190; iter: 0; batch classifier loss: 0.026465; batch adversarial loss: 0.420675\n",
      "epoch 191; iter: 0; batch classifier loss: 0.008566; batch adversarial loss: 0.362405\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013751; batch adversarial loss: 0.591544\n",
      "epoch 193; iter: 0; batch classifier loss: 0.012789; batch adversarial loss: 0.393325\n",
      "epoch 194; iter: 0; batch classifier loss: 0.002836; batch adversarial loss: 0.369438\n",
      "epoch 195; iter: 0; batch classifier loss: 0.018587; batch adversarial loss: 0.381648\n",
      "epoch 196; iter: 0; batch classifier loss: 0.006655; batch adversarial loss: 0.410663\n",
      "epoch 197; iter: 0; batch classifier loss: 0.008102; batch adversarial loss: 0.533130\n",
      "epoch 198; iter: 0; batch classifier loss: 0.022023; batch adversarial loss: 0.415351\n",
      "epoch 199; iter: 0; batch classifier loss: 0.031902; batch adversarial loss: 0.478484\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691616; batch adversarial loss: 0.668784\n",
      "epoch 1; iter: 0; batch classifier loss: 0.534174; batch adversarial loss: 0.650709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.453417; batch adversarial loss: 0.623726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464656; batch adversarial loss: 0.605194\n",
      "epoch 4; iter: 0; batch classifier loss: 0.464173; batch adversarial loss: 0.594038\n",
      "epoch 5; iter: 0; batch classifier loss: 0.436435; batch adversarial loss: 0.604691\n",
      "epoch 6; iter: 0; batch classifier loss: 0.551534; batch adversarial loss: 0.565632\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513394; batch adversarial loss: 0.588510\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399920; batch adversarial loss: 0.527147\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389878; batch adversarial loss: 0.588465\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475609; batch adversarial loss: 0.520814\n",
      "epoch 11; iter: 0; batch classifier loss: 0.481999; batch adversarial loss: 0.540099\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413286; batch adversarial loss: 0.521628\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380056; batch adversarial loss: 0.557628\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436026; batch adversarial loss: 0.428687\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372963; batch adversarial loss: 0.490941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289366; batch adversarial loss: 0.468468\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295719; batch adversarial loss: 0.519876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322264; batch adversarial loss: 0.512850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308845; batch adversarial loss: 0.502574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 0; batch classifier loss: 0.314571; batch adversarial loss: 0.435619\n",
      "epoch 21; iter: 0; batch classifier loss: 0.296489; batch adversarial loss: 0.445527\n",
      "epoch 22; iter: 0; batch classifier loss: 0.242938; batch adversarial loss: 0.508788\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292379; batch adversarial loss: 0.507649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.239979; batch adversarial loss: 0.525895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222547; batch adversarial loss: 0.455893\n",
      "epoch 26; iter: 0; batch classifier loss: 0.222570; batch adversarial loss: 0.444728\n",
      "epoch 27; iter: 0; batch classifier loss: 0.275263; batch adversarial loss: 0.514216\n",
      "epoch 28; iter: 0; batch classifier loss: 0.163344; batch adversarial loss: 0.470816\n",
      "epoch 29; iter: 0; batch classifier loss: 0.156921; batch adversarial loss: 0.568322\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323774; batch adversarial loss: 0.523148\n",
      "epoch 31; iter: 0; batch classifier loss: 0.311884; batch adversarial loss: 0.432421\n",
      "epoch 32; iter: 0; batch classifier loss: 0.206774; batch adversarial loss: 0.495534\n",
      "epoch 33; iter: 0; batch classifier loss: 0.279795; batch adversarial loss: 0.425795\n",
      "epoch 34; iter: 0; batch classifier loss: 0.186441; batch adversarial loss: 0.490053\n",
      "epoch 35; iter: 0; batch classifier loss: 0.206147; batch adversarial loss: 0.485204\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250765; batch adversarial loss: 0.432873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.211747; batch adversarial loss: 0.535891\n",
      "epoch 38; iter: 0; batch classifier loss: 0.213093; batch adversarial loss: 0.458429\n",
      "epoch 39; iter: 0; batch classifier loss: 0.233186; batch adversarial loss: 0.450838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.245418; batch adversarial loss: 0.457533\n",
      "epoch 41; iter: 0; batch classifier loss: 0.155887; batch adversarial loss: 0.482495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.193791; batch adversarial loss: 0.472538\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258353; batch adversarial loss: 0.588834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.192997; batch adversarial loss: 0.526937\n",
      "epoch 45; iter: 0; batch classifier loss: 0.124074; batch adversarial loss: 0.527824\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266999; batch adversarial loss: 0.425631\n",
      "epoch 47; iter: 0; batch classifier loss: 0.185501; batch adversarial loss: 0.472589\n",
      "epoch 48; iter: 0; batch classifier loss: 0.194621; batch adversarial loss: 0.529463\n",
      "epoch 49; iter: 0; batch classifier loss: 0.196218; batch adversarial loss: 0.471527\n",
      "epoch 50; iter: 0; batch classifier loss: 0.125349; batch adversarial loss: 0.435360\n",
      "epoch 51; iter: 0; batch classifier loss: 0.080358; batch adversarial loss: 0.420887\n",
      "epoch 52; iter: 0; batch classifier loss: 0.155321; batch adversarial loss: 0.434063\n",
      "epoch 53; iter: 0; batch classifier loss: 0.223129; batch adversarial loss: 0.447110\n",
      "epoch 54; iter: 0; batch classifier loss: 0.166656; batch adversarial loss: 0.482406\n",
      "epoch 55; iter: 0; batch classifier loss: 0.118694; batch adversarial loss: 0.492194\n",
      "epoch 56; iter: 0; batch classifier loss: 0.274644; batch adversarial loss: 0.324963\n",
      "epoch 57; iter: 0; batch classifier loss: 0.169435; batch adversarial loss: 0.456583\n",
      "epoch 58; iter: 0; batch classifier loss: 0.139160; batch adversarial loss: 0.459695\n",
      "epoch 59; iter: 0; batch classifier loss: 0.193646; batch adversarial loss: 0.447002\n",
      "epoch 60; iter: 0; batch classifier loss: 0.180831; batch adversarial loss: 0.434427\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163551; batch adversarial loss: 0.530392\n",
      "epoch 62; iter: 0; batch classifier loss: 0.154507; batch adversarial loss: 0.480809\n",
      "epoch 63; iter: 0; batch classifier loss: 0.194913; batch adversarial loss: 0.590493\n",
      "epoch 64; iter: 0; batch classifier loss: 0.195666; batch adversarial loss: 0.507350\n",
      "epoch 65; iter: 0; batch classifier loss: 0.158987; batch adversarial loss: 0.434259\n",
      "epoch 66; iter: 0; batch classifier loss: 0.126341; batch adversarial loss: 0.458048\n",
      "epoch 67; iter: 0; batch classifier loss: 0.216284; batch adversarial loss: 0.495742\n",
      "epoch 68; iter: 0; batch classifier loss: 0.079901; batch adversarial loss: 0.506555\n",
      "epoch 69; iter: 0; batch classifier loss: 0.101627; batch adversarial loss: 0.445857\n",
      "epoch 70; iter: 0; batch classifier loss: 0.088412; batch adversarial loss: 0.470496\n",
      "epoch 71; iter: 0; batch classifier loss: 0.215567; batch adversarial loss: 0.483827\n",
      "epoch 72; iter: 0; batch classifier loss: 0.221476; batch adversarial loss: 0.434096\n",
      "epoch 73; iter: 0; batch classifier loss: 0.131702; batch adversarial loss: 0.457019\n",
      "epoch 74; iter: 0; batch classifier loss: 0.092616; batch adversarial loss: 0.519255\n",
      "epoch 75; iter: 0; batch classifier loss: 0.149280; batch adversarial loss: 0.465553\n",
      "epoch 76; iter: 0; batch classifier loss: 0.083428; batch adversarial loss: 0.529815\n",
      "epoch 77; iter: 0; batch classifier loss: 0.114532; batch adversarial loss: 0.414663\n",
      "epoch 78; iter: 0; batch classifier loss: 0.128018; batch adversarial loss: 0.383365\n",
      "epoch 79; iter: 0; batch classifier loss: 0.132193; batch adversarial loss: 0.415273\n",
      "epoch 80; iter: 0; batch classifier loss: 0.143873; batch adversarial loss: 0.392221\n",
      "epoch 81; iter: 0; batch classifier loss: 0.113621; batch adversarial loss: 0.496089\n",
      "epoch 82; iter: 0; batch classifier loss: 0.072541; batch adversarial loss: 0.436679\n",
      "epoch 83; iter: 0; batch classifier loss: 0.081420; batch adversarial loss: 0.523102\n",
      "epoch 84; iter: 0; batch classifier loss: 0.115337; batch adversarial loss: 0.564682\n",
      "epoch 85; iter: 0; batch classifier loss: 0.070064; batch adversarial loss: 0.443870\n",
      "epoch 86; iter: 0; batch classifier loss: 0.061210; batch adversarial loss: 0.496847\n",
      "epoch 87; iter: 0; batch classifier loss: 0.072564; batch adversarial loss: 0.525454\n",
      "epoch 88; iter: 0; batch classifier loss: 0.061010; batch adversarial loss: 0.401594\n",
      "epoch 89; iter: 0; batch classifier loss: 0.085007; batch adversarial loss: 0.418155\n",
      "epoch 90; iter: 0; batch classifier loss: 0.073329; batch adversarial loss: 0.433106\n",
      "epoch 91; iter: 0; batch classifier loss: 0.109423; batch adversarial loss: 0.424998\n",
      "epoch 92; iter: 0; batch classifier loss: 0.070327; batch adversarial loss: 0.400287\n",
      "epoch 93; iter: 0; batch classifier loss: 0.053350; batch adversarial loss: 0.481200\n",
      "epoch 94; iter: 0; batch classifier loss: 0.077985; batch adversarial loss: 0.470970\n",
      "epoch 95; iter: 0; batch classifier loss: 0.049118; batch adversarial loss: 0.481905\n",
      "epoch 96; iter: 0; batch classifier loss: 0.034450; batch adversarial loss: 0.462998\n",
      "epoch 97; iter: 0; batch classifier loss: 0.051987; batch adversarial loss: 0.448624\n",
      "epoch 98; iter: 0; batch classifier loss: 0.037593; batch adversarial loss: 0.527258\n",
      "epoch 99; iter: 0; batch classifier loss: 0.053854; batch adversarial loss: 0.553044\n",
      "epoch 100; iter: 0; batch classifier loss: 0.053001; batch adversarial loss: 0.467083\n",
      "epoch 101; iter: 0; batch classifier loss: 0.044480; batch adversarial loss: 0.416189\n",
      "epoch 102; iter: 0; batch classifier loss: 0.074530; batch adversarial loss: 0.574448\n",
      "epoch 103; iter: 0; batch classifier loss: 0.070985; batch adversarial loss: 0.407062\n",
      "epoch 104; iter: 0; batch classifier loss: 0.066427; batch adversarial loss: 0.532862\n",
      "epoch 105; iter: 0; batch classifier loss: 0.026454; batch adversarial loss: 0.448274\n",
      "epoch 106; iter: 0; batch classifier loss: 0.039140; batch adversarial loss: 0.381562\n",
      "epoch 107; iter: 0; batch classifier loss: 0.069478; batch adversarial loss: 0.560488\n",
      "epoch 108; iter: 0; batch classifier loss: 0.017454; batch adversarial loss: 0.524473\n",
      "epoch 109; iter: 0; batch classifier loss: 0.042319; batch adversarial loss: 0.376010\n",
      "epoch 110; iter: 0; batch classifier loss: 0.050984; batch adversarial loss: 0.387281\n",
      "epoch 111; iter: 0; batch classifier loss: 0.037427; batch adversarial loss: 0.373782\n",
      "epoch 112; iter: 0; batch classifier loss: 0.037282; batch adversarial loss: 0.465652\n",
      "epoch 113; iter: 0; batch classifier loss: 0.040760; batch adversarial loss: 0.483924\n",
      "epoch 114; iter: 0; batch classifier loss: 0.057447; batch adversarial loss: 0.436426\n",
      "epoch 115; iter: 0; batch classifier loss: 0.044467; batch adversarial loss: 0.465549\n",
      "epoch 116; iter: 0; batch classifier loss: 0.078478; batch adversarial loss: 0.539614\n",
      "epoch 117; iter: 0; batch classifier loss: 0.061110; batch adversarial loss: 0.431179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 118; iter: 0; batch classifier loss: 0.054117; batch adversarial loss: 0.448472\n",
      "epoch 119; iter: 0; batch classifier loss: 0.033818; batch adversarial loss: 0.467266\n",
      "epoch 120; iter: 0; batch classifier loss: 0.044012; batch adversarial loss: 0.425561\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036190; batch adversarial loss: 0.434269\n",
      "epoch 122; iter: 0; batch classifier loss: 0.055042; batch adversarial loss: 0.468945\n",
      "epoch 123; iter: 0; batch classifier loss: 0.037077; batch adversarial loss: 0.463050\n",
      "epoch 124; iter: 0; batch classifier loss: 0.039686; batch adversarial loss: 0.471925\n",
      "epoch 125; iter: 0; batch classifier loss: 0.032300; batch adversarial loss: 0.473283\n",
      "epoch 126; iter: 0; batch classifier loss: 0.028514; batch adversarial loss: 0.516860\n",
      "epoch 127; iter: 0; batch classifier loss: 0.028376; batch adversarial loss: 0.545218\n",
      "epoch 128; iter: 0; batch classifier loss: 0.036709; batch adversarial loss: 0.511695\n",
      "epoch 129; iter: 0; batch classifier loss: 0.029138; batch adversarial loss: 0.392302\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038795; batch adversarial loss: 0.437162\n",
      "epoch 131; iter: 0; batch classifier loss: 0.024653; batch adversarial loss: 0.459529\n",
      "epoch 132; iter: 0; batch classifier loss: 0.024060; batch adversarial loss: 0.372169\n",
      "epoch 133; iter: 0; batch classifier loss: 0.032993; batch adversarial loss: 0.459995\n",
      "epoch 134; iter: 0; batch classifier loss: 0.035931; batch adversarial loss: 0.420015\n",
      "epoch 135; iter: 0; batch classifier loss: 0.014817; batch adversarial loss: 0.467173\n",
      "epoch 136; iter: 0; batch classifier loss: 0.036719; batch adversarial loss: 0.459393\n",
      "epoch 137; iter: 0; batch classifier loss: 0.015725; batch adversarial loss: 0.494631\n",
      "epoch 138; iter: 0; batch classifier loss: 0.031633; batch adversarial loss: 0.433045\n",
      "epoch 139; iter: 0; batch classifier loss: 0.020844; batch adversarial loss: 0.564702\n",
      "epoch 140; iter: 0; batch classifier loss: 0.027551; batch adversarial loss: 0.505382\n",
      "epoch 141; iter: 0; batch classifier loss: 0.015914; batch adversarial loss: 0.425570\n",
      "epoch 142; iter: 0; batch classifier loss: 0.029425; batch adversarial loss: 0.519560\n",
      "epoch 143; iter: 0; batch classifier loss: 0.043342; batch adversarial loss: 0.470568\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036324; batch adversarial loss: 0.533098\n",
      "epoch 145; iter: 0; batch classifier loss: 0.045559; batch adversarial loss: 0.583797\n",
      "epoch 146; iter: 0; batch classifier loss: 0.025146; batch adversarial loss: 0.459320\n",
      "epoch 147; iter: 0; batch classifier loss: 0.016405; batch adversarial loss: 0.423158\n",
      "epoch 148; iter: 0; batch classifier loss: 0.068169; batch adversarial loss: 0.399665\n",
      "epoch 149; iter: 0; batch classifier loss: 0.013999; batch adversarial loss: 0.508426\n",
      "epoch 150; iter: 0; batch classifier loss: 0.004343; batch adversarial loss: 0.479101\n",
      "epoch 151; iter: 0; batch classifier loss: 0.037489; batch adversarial loss: 0.499318\n",
      "epoch 152; iter: 0; batch classifier loss: 0.030742; batch adversarial loss: 0.497336\n",
      "epoch 153; iter: 0; batch classifier loss: 0.027438; batch adversarial loss: 0.376965\n",
      "epoch 154; iter: 0; batch classifier loss: 0.029824; batch adversarial loss: 0.513829\n",
      "epoch 155; iter: 0; batch classifier loss: 0.019497; batch adversarial loss: 0.458561\n",
      "epoch 156; iter: 0; batch classifier loss: 0.022435; batch adversarial loss: 0.497293\n",
      "epoch 157; iter: 0; batch classifier loss: 0.034350; batch adversarial loss: 0.511502\n",
      "epoch 158; iter: 0; batch classifier loss: 0.025809; batch adversarial loss: 0.500462\n",
      "epoch 159; iter: 0; batch classifier loss: 0.013945; batch adversarial loss: 0.403533\n",
      "epoch 160; iter: 0; batch classifier loss: 0.010328; batch adversarial loss: 0.458751\n",
      "epoch 161; iter: 0; batch classifier loss: 0.016899; batch adversarial loss: 0.507246\n",
      "epoch 162; iter: 0; batch classifier loss: 0.038580; batch adversarial loss: 0.399680\n",
      "epoch 163; iter: 0; batch classifier loss: 0.036655; batch adversarial loss: 0.433117\n",
      "epoch 164; iter: 0; batch classifier loss: 0.028535; batch adversarial loss: 0.431150\n",
      "epoch 165; iter: 0; batch classifier loss: 0.033739; batch adversarial loss: 0.468945\n",
      "epoch 166; iter: 0; batch classifier loss: 0.020889; batch adversarial loss: 0.453759\n",
      "epoch 167; iter: 0; batch classifier loss: 0.036942; batch adversarial loss: 0.378548\n",
      "epoch 168; iter: 0; batch classifier loss: 0.022612; batch adversarial loss: 0.429934\n",
      "epoch 169; iter: 0; batch classifier loss: 0.049964; batch adversarial loss: 0.366705\n",
      "epoch 170; iter: 0; batch classifier loss: 0.016866; batch adversarial loss: 0.510721\n",
      "epoch 171; iter: 0; batch classifier loss: 0.017289; batch adversarial loss: 0.514674\n",
      "epoch 172; iter: 0; batch classifier loss: 0.011913; batch adversarial loss: 0.505798\n",
      "epoch 173; iter: 0; batch classifier loss: 0.024668; batch adversarial loss: 0.382151\n",
      "epoch 174; iter: 0; batch classifier loss: 0.003840; batch adversarial loss: 0.504044\n",
      "epoch 175; iter: 0; batch classifier loss: 0.008349; batch adversarial loss: 0.446851\n",
      "epoch 176; iter: 0; batch classifier loss: 0.028575; batch adversarial loss: 0.533411\n",
      "epoch 177; iter: 0; batch classifier loss: 0.010262; batch adversarial loss: 0.507221\n",
      "epoch 178; iter: 0; batch classifier loss: 0.041584; batch adversarial loss: 0.455314\n",
      "epoch 179; iter: 0; batch classifier loss: 0.012489; batch adversarial loss: 0.426591\n",
      "epoch 180; iter: 0; batch classifier loss: 0.004641; batch adversarial loss: 0.445521\n",
      "epoch 181; iter: 0; batch classifier loss: 0.018320; batch adversarial loss: 0.498811\n",
      "epoch 182; iter: 0; batch classifier loss: 0.023072; batch adversarial loss: 0.473548\n",
      "epoch 183; iter: 0; batch classifier loss: 0.020460; batch adversarial loss: 0.432383\n",
      "epoch 184; iter: 0; batch classifier loss: 0.004505; batch adversarial loss: 0.478069\n",
      "epoch 185; iter: 0; batch classifier loss: 0.007528; batch adversarial loss: 0.550065\n",
      "epoch 186; iter: 0; batch classifier loss: 0.037625; batch adversarial loss: 0.383736\n",
      "epoch 187; iter: 0; batch classifier loss: 0.007021; batch adversarial loss: 0.489378\n",
      "epoch 188; iter: 0; batch classifier loss: 0.006889; batch adversarial loss: 0.504742\n",
      "epoch 189; iter: 0; batch classifier loss: 0.030466; batch adversarial loss: 0.423020\n",
      "epoch 190; iter: 0; batch classifier loss: 0.024782; batch adversarial loss: 0.448139\n",
      "epoch 191; iter: 0; batch classifier loss: 0.015091; batch adversarial loss: 0.453786\n",
      "epoch 192; iter: 0; batch classifier loss: 0.013432; batch adversarial loss: 0.512202\n",
      "epoch 193; iter: 0; batch classifier loss: 0.011983; batch adversarial loss: 0.496915\n",
      "epoch 194; iter: 0; batch classifier loss: 0.003172; batch adversarial loss: 0.527234\n",
      "epoch 195; iter: 0; batch classifier loss: 0.034172; batch adversarial loss: 0.433522\n",
      "epoch 196; iter: 0; batch classifier loss: 0.011065; batch adversarial loss: 0.552446\n",
      "epoch 197; iter: 0; batch classifier loss: 0.006533; batch adversarial loss: 0.522394\n",
      "epoch 198; iter: 0; batch classifier loss: 0.013217; batch adversarial loss: 0.490957\n",
      "epoch 199; iter: 0; batch classifier loss: 0.002165; batch adversarial loss: 0.391770\n"
     ]
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5c65b",
   "metadata": {},
   "source": [
    "### Experiment iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5608ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 5\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f3fa71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:27.080554Z",
     "start_time": "2024-01-04T20:53:27.072313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 500,\n",
      " 'experiment_iteration': 'Exp_iter_5',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'model_init_seed': 500,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8257cfd4f743e8887bbc74613694af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:55:49 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 03:55:49 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([ 92, 640, 589, 519, 377, 478, 298, 336, 149, 278, 343, 573, 365,\n",
      "            174, 171, 219, 469, 162, 567, 203],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 500, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2d40e5f54c4d67bf9f1e66289ae23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63535df3c576469e9e855b70194bc572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15688b8597f74cdaadb60cc93599720c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165f4884fae4f29829de3acc475dac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af2556",
   "metadata": {},
   "source": [
    "### Experiment iteration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e0b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for an experiment iteration\n",
    "exp_iter_num = 6\n",
    "experiment_seed = EXPERIMENT_SEEDS[exp_iter_num - 1]\n",
    "custom_table_fields_dct['experiment_iteration'] = f'Exp_iter_{exp_iter_num}'\n",
    "exp_iter_data_loader = copy.deepcopy(data_loader)  # Add deepcopy to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b828bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-04T20:53:16.632770Z",
     "start_time": "2024-01-04T20:53:16.629083Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Start an experiment iteration for the following custom params:\n",
      "INFO:root:Start an experiment iteration for the following custom params:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_split_seed': 600,\n",
      " 'experiment_iteration': 'Exp_iter_6',\n",
      " 'fair_intervention_params_lst': '[True]',\n",
      " 'intervention_param': 'True',\n",
      " 'model_init_seed': 600,\n",
      " 'session_uuid': '0626d80f-e288-4f16-b8ab-260eb34d62d3'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670abffe30e4a388a7a09306feb6673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Multiple alphas:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 04:49:43 experiment_interface.py INFO    : The dataset is preprocessed\n",
      "INFO:root:The dataset is preprocessed\n",
      "2024-01-05 04:49:43 experiment_interface.py INFO    : Models config is loaded from the input file\n",
      "INFO:root:Models config is loaded from the input file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervention_option:  True\n",
      "Using ROC postprocessor\n",
      "cur_base_flow_dataset.X_train_val.columns:  Index(['cat__school_GP', 'cat__school_MS', 'cat__address_R', 'cat__address_U',\n",
      "       'cat__famsize_GT3', 'cat__famsize_LE3', 'cat__Pstatus_A',\n",
      "       'cat__Pstatus_T', 'cat__Mjob_at_home', 'cat__Mjob_health',\n",
      "       'cat__Mjob_other', 'cat__Mjob_services', 'cat__Mjob_teacher',\n",
      "       'cat__Fjob_at_home', 'cat__Fjob_health', 'cat__Fjob_other',\n",
      "       'cat__Fjob_services', 'cat__Fjob_teacher', 'cat__reason_course',\n",
      "       'cat__reason_home', 'cat__reason_other', 'cat__reason_reputation',\n",
      "       'cat__guardian_father', 'cat__guardian_mother', 'cat__guardian_other',\n",
      "       'cat__schoolsup_no', 'cat__schoolsup_yes', 'cat__famsup_no',\n",
      "       'cat__famsup_yes', 'cat__paid_no', 'cat__paid_yes',\n",
      "       'cat__activities_no', 'cat__activities_yes', 'cat__nursery_no',\n",
      "       'cat__nursery_yes', 'cat__higher_no', 'cat__higher_yes',\n",
      "       'cat__internet_no', 'cat__internet_yes', 'cat__romantic_no',\n",
      "       'cat__romantic_yes', 'num__age', 'num__Medu', 'num__Fedu',\n",
      "       'num__traveltime', 'num__studytime', 'num__failures', 'num__famrel',\n",
      "       'num__freetime', 'num__goout', 'num__Dalc', 'num__Walc', 'num__health',\n",
      "       'num__absences', 'num__G1', 'num__G2', 'sex_binary'],\n",
      "      dtype='object')\n",
      "Top indexes of an X_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Top indexes of an y_test in the current base flow dataset:  Int64Index([390, 397, 375, 507, 625, 369, 245, 428, 593, 102,  49, 621,  92,\n",
      "            158, 505, 612,  29, 452,  56, 145],\n",
      "           dtype='int64')\n",
      "Path for tuned params:  /home/dh3553/projects/fairness-variance/results/diff_fairness_interventions_exp/ROC/ROC_student_performance/tuning_results_Student_Performance_Por_20240104__212802.csv\n",
      "LGBMClassifier:  {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 3, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 600, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'min_data_in_leaf': 100}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f28080438649c0aa4a0f71f4b322c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyze multiple models:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511b20dacfe5420981d3cf173f60fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a989d937f483784b5138783479302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled a postprocessing mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c5fe28a14a47118da3a7d485a77e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers testing by bootstrap:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_exp_iter_with_inprocessor(data_loader=exp_iter_data_loader,\n",
    "                              experiment_seed=experiment_seed,\n",
    "                              test_set_fraction=TEST_SET_FRACTION,\n",
    "                              db_writer_func=db_writer_func,\n",
    "                              fair_intervention_params_lst=FAIR_INTERVENTION_PARAMS_LST,\n",
    "                              metrics_computation_config=metrics_computation_config,\n",
    "                              custom_table_fields_dct=custom_table_fields_dct,\n",
    "                              dataset_name='ACSIncomeDataset',\n",
    "                              inprocessor_name='AdversarialDebiasing',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031c82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
